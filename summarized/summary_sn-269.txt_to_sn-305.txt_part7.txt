GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#269

DATE:		October 7, 2010

TITLE:		Listener Feedback #102

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-269.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 269, recorded October 6, 2010:  Your questions, Steve's answers, #102.



It's time for Security Now!, the show that covers your security online, your privacy online.  And who better to do that than our good friend, our mentor, our security guru, Mr. Steve Gibson from GRC.com, creator of SpinRite.



STEVE GIBSON:  Hey, Leo.



LEO:  Hey, Steve.  How are you today?



STEVE:  Great.  Great to be with you again, as always.



LEO:  So today I think we have, if I'm correct, we are Mod 1; right?



STEVE:  Yeah, we are odd parity today.  It's our Q&A #102.



LEO:  Yikes.  And we've got some great questions.



STEVE:  Yeah, we had, as you can imagine from last week's episode where we talked about this very troubling potential new legislation that's being pushed on Congress by the FBI, and apparently with the support of our current Obama administration, a huge amount of response.  I've tempered it to - I selected three out of literally hundreds of responses which turn out to be sort of representative of the different things everyone was saying.  So I wanted to acknowledge everyone who wrote and to thank you for that.  And so about midway through today's Q&A we've got those three people who were pretty much representative of what everyone had to say.  Not much in the way of updates, and actually not much in the way of news.  So, but I think we have a bunch of interesting observations from listeners, and questions.



LEO:  I can't wait to hear.  Now, the good news was that the piracy initiative, COICA, was dropped, was tabled.  So...



STEVE:  Yeah.



LEO:  That at least we don't have to worry about until next time because it's not - they're going to bring this up, the recording industry's going to bring this back every single session until they have a positive Congress.  But this other one, the Obama administration and the FBI said they would bring this to Congress in January.  So...



STEVE:  When it reconvenes after the midterm elections.  And I'm - we'll talk about this in the middle of our Q&A.  But many people have just said, oh, don't worry about it, it'll never pass.  And it's like, eh, you know, folks, you mention terrorism, and the problem is the FBI's not wrong about this being a problem.  I mean, this is a problem.  I mean, as we discussed last week, it's a viable issue that they can make.  And we have had troubling legislation like the DMCA pass which really causes trouble.  So I'm less sanguine about this not being a problem going forward.  So we'll see.



LEO:  Well, one way or another, you've got to pay attention to it.  I've learned never assume that something you think couldn't happen, won't.



STEVE:  Yeah.



LEO:  I mean, I never thought we'd elect a movie star President.  And so there you go.  Before we get into this subject - or a movie star governor, for that matter.



STEVE:  There you go.



LEO:  Pretty soon we'll have a movie star president of the Internet.  Maybe.



STEVE:  Nobody will know or care about him.



LEO:  Nobody, yeah.  Did you know that I am the president of the Internet?  You didn't know that, did you.



STEVE:  I'm glad, Leo.  I'm glad I know you.



LEO:  Duly elected.  By a vote of about a thousand people who heard about it.



STEVE:  Apparently nobody there at the TWiT Cottage voted for you, though.



LEO:  No, no.  They know me...



STEVE:  They're a little upset from yesterday.



LEO:  They know me far too well to vote for me.  So before we get to questions, and I'm sure we have some great ones, do you have anything you want to talk about, Mr. Gibson?



STEVE:  Well, we have some updates and some news.  Actually very few and not much of either.  But as Adobe promised, due to the fact that they had that very bad buffer overflow vulnerability - why does that surprise anybody - a zero-day which has been known for about three weeks.  As we know, last week they pushed out a quick fix to their Flash Player, which was one of the ways that this was causing problems.  This week on Tuesday the 5th they pushed a week ahead of their normal quarterly patch cycle.  Normally they've said that they're only going to be patching on the second Tuesday of the month every three months, so quarterly.  Reader and Acrobat versions 9.34 and earlier have now been brought up to date a week ahead of time.  So this fixes the zero-day vulnerability that had been actively exploited in targeted attacks since it was discovered in the wild.



And I'm seeing here that I've got a - I have Acrobat installed on this system, and so I'm seeing that it's got a little red icon on my tray saying, okay, update me, update me.  So I did notice that it said it's going to have to do a restart.  So it's like, okay, well, I'm not doing it now during the podcast, or just before the podcast.



LEO:  Yeah.  Do like Leo does, yeah.



STEVE:  Learned that lesson.



LEO:  From me.



STEVE:  And then I just wanted to mention that Google Chrome continues to quietly move itself forward.  The news that I saw was it had gone to 6.0.472.62.  And when I thought, oh, I wonder if that's what I have, mine had already moved to 63.  So it's creeping forward.  And in the move to 62, I know that they fixed two remote code execution vulnerabilities, one involving scalable vector graphics, SVG, which is one of the newer technologies.  And they're experimenting with a protocol to replace HTTP called "SPeeDY."  The letters are SPDY.  So this is sort of an experimental protocol.



Essentially many things have changed on the way the web works since even HTTP was developed, and even moved from 1.0 to 1.1.  There are problems like, yes, you can slipstream or - I don't mean slipstream.  You can issue requests sequentially ahead of time in a pipeline, "pipeline" is the word I was looking for, and get the responses back.  But many things are redundant, like the browser headers are, like, being re-sent over and over and over with every query.  And queries are small relative to the browser headers that are often much larger even than the thing you're asking for, as all this metadata that no one ever sees.  And it's highly repetitive, and it's uncompressed.



And so Google is sort of leading the way in looking at what can be done here to make web interaction better.  Of course, they've got a strong motivation for doing so because their whole model is a web-centric model, which frankly I'm finding myself more and more a fan of, this idea that apps are going to be in the cloud, data is going to be in the cloud, and we'll be using lighter-weight clients to access our apps and our data remotely.



LEO:  And updates will be in the cloud, which is the main point; right?



STEVE:  They'll just be transparent.



LEO:  They're automatic.



STEVE:  Yes.  The problem, of course, is the bad guys will be in the cloud, too.



LEO:  Oh, of course.



STEVE:  So, and there's the whole question of data integrity and safety and all that stuff, which is no small issue.  I'll go kicking and screaming into the cloud.  I like to have my data here and to move it around between devices.  But I have to say, as I'm using things - for example, LastPass.  We talked about it, of course, several episodes ago [Episode 256].  I should mention that I'm just loving it.  I mean, I'm really liking it.  And the fact, for example, that I can change a login username and password on one system and then realize when I'm using my iPad, for example, it's like, oh, shoot, I changed that, didn't it.  And I go, oh, wait a minute, I've got LastPass.  And so it's maintaining synchronization among all my instances.  I mean, it really is working.  And I've had a lot of very positive feedback from our listeners also in our Security Now! feedback mailbag about how much they're enjoying LastPass.  So that's been a win.  And so there's a perfect example of a cloud-based app that I think makes a lot of sense.



LEO:  Of course it's cloud and local because the storage is local.  So it's a nice - it's a great mix.  They've solved some of the things that you talked about - availability and issues of my data being somewhere else - by a hybrid solution that works well.



STEVE:  Right.  And so, exactly, if you're disconnected - well, on the other hand, if you're disconnected, it's not clear what...



LEO:  Well, you can't do it.



STEVE:  ...what you're going to be logging into.  But, yes, it's certainly good to have it stored locally, as well.  If they happen to be down briefly, that would be a big problem for everyone using it.



LEO:  Right, right.



STEVE:  So anyway, so Acrobat Reader updated.  Chrome is sort of just sort of taking care of itself.  And frankly, as I look at Chrome doing this, and I was thinking about this this morning, it's like, that's not such a bad thing, just to have it not making a big deal about updates, just having it doing it in the background, so that it's fixing itself for you.



LEO:  I think IE9 is going to do that, too.  And people get upset about the idea.  They don't like the loss of control that that represents.



STEVE:  Yeah, I know.  Especially, well, especially when it's, like, rebooting your machine without your knowledge or permission, or making other big changes.  It's one thing for it to just sort of like, I mean, Chrome behaves itself very well.  When you fire it up, it's already updated.  It's like, oh, okay.  It's really not ever telling you you need to reboot your system, so. 



LEO:  Can't do that with an OS, though.



STEVE:  No.  RIM, our famous BlackBerry publishers, are going 'round and 'round with India.  They have just succeeded in giving India so-called "manual access" to the BlackBerry Messenger data, meaning that if specific entities that are authorized to do so in India ask for audit trails, essentially, of BlackBerry Messenger dialogue, within four to five hours after making that request, BlackBerry is now able to provide those entities with paper printouts of Messenger text.  Then they're promising what they're calling fully automated, real-time access to the same data by the start of 2011, so the start of next year.



The problem is, RIM continues to assert their technological architectural limitation relative to email.  Email is different than Messenger, and email enjoys point-to-point encryption, where RIM's technology just simply doesn't let them provide what India wants.  So it's not clear what's going to happen with that.  I mean, it's been mentioned that alternative phone systems, for example, like the iPhone, don't use the same kind of certificate-based, point-to-point encryption which literally, I mean, there's nothing RIM can do.  They're saying the architecture doesn't permit any sort of a man-in-the-middle decryption.  So we're going to wait to see what happens.  And India is still saying that they are on the verge of approaching Google and Skype and saying, you guys are next.  We need to have access.



LEO:  Wow.  Yeah, well, this is very similar to what's going on in the states.



STEVE:  It's very, exactly, it's very...



LEO:  In fact, I think it inspired it.



STEVE:  Well, in fact, yes...



LEO:  The FBI says, well, if India gets it, we want it.



STEVE:  Yes.  I did read, in preparing the podcast last week, preparing the production of that, there were some comments where people were feeling that, behind the scenes, the three-letter acronym agencies here in the U.S. were looking at what other countries were getting, the concessions that they were getting, saying, hey, those look pretty good.  We'd like some of that, too.



LEO:  Yeah.



STEVE:  And of course we do it here by writing a law and enacting it in Congress, and then having the Obama administration sign it.  My last note of news is that Comcast, that has been testing in limited geographic markets so far an automated, proactive bot notification system, is now taking it nationwide.  Comcast is the largest U.S. residential ISP.  And they've got something on their - they have sort of an umbrella called Constant Guard, which is their service.  There's a page, constantguard.comcast.net, where they sort of talk about the different services that fall within this Constant Guard umbrella.



Under Proactive Bot Notification, that page says:  "As a new feature of the Constant Guard service, we may email a 'Service Notice' to your Comcast email address if we believe a computer behind your cable modem may be infected with a type of virus called a bot.  A bot is a malicious form of software that could use your computer to send spam, host a phishing site, or steal your identity by monitoring your keystrokes.  The email will advise you to go to the Comcast Constant Guard Center at http://constantguard.comcast.net, where you can access resources to help you remove the bot from your computer. The Service e-mail will look like this."  And then that page gives you a sample, which I think is smart because they're wanting to help you recognize it when you receive it and help you take it for, I mean, treat it as authentic email.  And it says:



"Dear Comcast Customer:  The Constant Guard service has identified that one or more of your computers may be infected with a bot.  Please read on.



"A bot, also referred to as malicious software or malware, is used to gain control of your computer, typically without your knowledge.  Online criminals can use bots to collect your personal and private data, such as Social Security numbers, bank account information, and/or credit card numbers by monitoring your keystrokes.  This can lead to identity theft and fraud."



And then lower down on that page, about "Virus-Bot Information," it explains that, "According to the National Cyber Security Alliance, bots are the Internet's fastest-growing cybercrime, and 71 percent of consumers don't even know what bots are and what they can do about them.  Comcast wants to help its customers stay educated, informed, and safe online.  A bot is a type of virus that allows an attacker to force your computer to perform actions, usually without your knowledge.  Once a bot is in control of your computer, it can be used to send spam, host phishing sites, or infect other computers.  Online thieves use bots to collect personal data such as Social Security numbers, bank account information, credit card numbers, et cetera.  When this personal data is collected without your permission, it's often used to steal your identity, withdraw money from your bank accounts, and make fraudulent purchases on your credit cards."  So I think this is fantastic.  I mean, this kind of...



LEO:  Yeah.



STEVE:  Yeah, this kind of - first of all, two things.  The fact that they're now rolling out automated detection of bot infection for their customer base is great.  But from an educational standpoint, the fact that people who are infected will be proactively notified and begin this education, I mean, this is the kind of stuff we really want people who are infected to be informed about and to take seriously.  So this is just - this is wonderful news.



LEO:  You can't see anything wrong with anything they said?  Sounds all right and sounds all good?



STEVE:  Well, yes.  It does.  And again, I mean, the reason I wanted to spend a little time on it is that this is just - this is really proactive and great news.



LEO:  I guess one of the reasons - Comcast is I think the largest Internet service provider in the U.S., with millions and millions of customers.  So it's important that they do this from the point of view of everybody else because they're protecting the rest of the 'Net from their customers, who are a prime target.  But one of the reasons they haven't done this in the past, in fact, remember they were reluctant to block port 25, outbound SMTP, which was used for spam forwarding, is because of the cost to them in tech support calls, all the people calling, going, agh.  And I know because I answer these calls on the radio.  It's literally millions and millions of dollars.  So a pat on the back to Comcast for biting the bullet and doing what they really need to do.



STEVE:  Yeah, and essentially cleaning up their own network that way, too.



LEO:  I think we've said, certainly I've said it many times, that if we wanted to stop spam, clean up the networks, the first place to start is ISPs.  If ISPs implement these kinds of policies and block this kind of stuff, it stops.



STEVE:  Well, and they're in a perfect place to do it.  They're at a point where all of their customers' traffic is focused down into one center.  If they deploy the technology which they have to do some behavior profiling, to look at the kind of traffic coming from individual customers, it's very clear when there is a bot on someone's machine.  There is specific behavior, specific easily identifiable activity.



Now, of course there will be a reaction on the bot manufacturers, or the bot makers, that the fact that this kind of profiling is happening will cause them to change the bots such that they don't show up on the radar as much as they do right now.  Because there hasn't been this kind of profiling, there's been no need for them to pretend to be more legitimate.  Unfortunately, they can do that.  So it'll be a back-and-forth.  But Comcast can follow that, too, and continue to move that bar forward.  So I think it's great they're doing it.  And I love it from a consumer education standpoint as just really good news.



LEO:  Yeah.



STEVE:  And I did have - and this is a different sort of testimonial, sort of a little sideways.  The subject was "SpinRite Acclaim," although it's a little different than the, well, like I said, the type of email I normally read.  It says, "A few weeks ago my Mac Mini claimed it could not log me on.  Nothing I could find at Apple.com could help, and I realized I had moved my home folder to an external USB 2.0 hard drive.  Along with my home folder, I had my entire iTunes collection on that drive.  It was immediately obvious that the external hard drive had a problem.  In iTunes I not only had thousands of music files, but also lots of purchased TV shows and full-feature movies.  I use this Mini only for iTunes, so I moved this hard drive to a PC and could still not access the iTunes library.



"I thought I was going to be ill after realizing the impact of losing all that data.  But I decided to spring for a license for SpinRite.  I went through the purchase and downloaded the software and set to work on another spare PC.  I had heard it could take days for the defects to be repaired.  Well, after three days, the progress was stuck at 0.05 percent.  I figured I was screwed.  I at least expected some progress, but I stopped the process.  Desperate, I went to the GRC.com newsgroups to read about this.  I saw that external drives usually took an extremely long time to be processed, and that users should attach the hard drive inside the external drive directly to a motherboard, if possible.



"So I sacrificed the drive enclosure - it wasn't exactly user serviceable - and took the hard drive out, placing it inside a spare PC, and started SpinRite again.  In less than four hours it had completed the pass, reporting that four errors could not be repaired.  Unfortunately, those were areas I needed, so I ran SpinRite a couple more times, and eventually there were no errors.  I have my iTunes library back!"  Exclamation point.



LEO:  Wow.  Now back it up.



STEVE:  He says, "I quickly moved everything to a NAS server I have at home," a Network Attached Storage server.  "Now I'm a believer and will be using SpinRite regularly to maintain my drives.  THANK YOU," all caps, "Bobby Irvin in Rogers, Arkansas."



LEO:  But I want to say something to Bobby because he said something that makes me nervous.  He moved everything to the NAS.



STEVE:  Uh-huh.



LEO:  Like that's safe.  One copy of anything, I don't care if it's a RAID 5, which is better than a regular hard drive, is still only - it's not a backup, it's one copy.  Right, Steve?



STEVE:  Yup.



LEO:  Back me up here.  So you need two copies.  Maybe three copies.  But not one copy.  And just because, you know, sometimes I think people say, well, I backed it up to a hard drive, so I've deleted it on the main drive, like they're backed up.  How is that better?



STEVE:  Right.



LEO:  So putting it on a NAS is marginally better, I guess, if it's RAID 5.  But I've had enough RAID 5 failures in my life to not think that that's sufficient.  Make another backup.  One more, at least.  All right, Steve.  I've got questions.



STEVE:  Great.



LEO:  Do you have answers?  We'll find out.  Presumably, since you chose the questions, you do.  Question 1 comes from Gary in the Motor City, Detroit.  He mourns the end of the PayPal plug-in, which we talked about not so long ago.  PayPal plug-in is discontinued.  What do we use now?  I'm very disappointed that PayPal chose to discontinue the plug-in.  It was a great feeling to be able to pay for online purchases with their secure card without revealing my credit card, and have the funds come out of my PayPal account.  Is there an alternative?  Gary.



STEVE:  Well, first of all, his sentiment was also expressed, as are many of these sentiments that I choose to share, from many of our listeners who commented that the PayPal plug-in had discontinued.  And I share the sentiment.  I mentioned a while ago that GoDaddy was frustrated, thanks to my use of a temporary credit card number which I obtained from the PayPal plug-in, when I registered a domain as sort of an experimental domain a little over a year ago.  When it came time to renew, they first sent me email.  And then, when I didn't respond, they complained that they were unable to charge my card.  And then they did it, I didn't mention it again, but they've tried several more times and complained.  Gee, we're unable to authorize your card.  We really want to charge you for a domain that you have not authorized us to renew.



LEO:  You can't win.



STEVE:  So this is a plea or a question to our listeners, who are spread far and wide.  If anyone knows of a replacement, we all want to know.  I don't know of one.  I know that some credit card companies themselves offer this service.  Unfortunately, none that I'm using, and presumably none that Gary's using, our questioner and listener here.  So if anyone knows of something like this from some accredited, reliable service, I'd very much like to know, and I know that our listeners would, and I will pass the news along because this idea of a one-use credit card, it just makes so much sense.



LEO:  Yeah.  I'm trying to think.  I think, is it American Express, one of my guys does do that, or at least used to do that.  This would be a great service to offer.



STEVE:  Yes.



LEO:  Visa does.  But again, it's not all Visa cards.  I think it's just some Visa cards.  So you should check with your credit card company.



STEVE:  Oh, in fact I'm sure, because I'm a big Visa user.  I use Chase and a couple others; and Chase, for example, doesn't.



LEO:  It's up to Chase to do it, not Visa to do it; you know what I'm saying?



STEVE:  Correct.



LEO:  Citi Cards, my chatroom is saying Citi Cards do do this.  So if you have a Citibank card.  I have to say, it would be worth moving...



STEVE:  Oh, it really would.



LEO:  ...just for that.



STEVE:  Yes, it really would.  I mean, it's such an advantage to be able to - I mean, and frankly, I'd rather use my main credit card company rather than a third party.  But if a third party is not available, then - I mean, if a credit card can't do it, and a third party can, I'd sign up for such a service.



LEO:  Right.  So, good.  So at least we know Citibank does.  Of course inquire before you transfer your account over there.



STEVE:  Yeah, make sure you qualify.



LEO:  Make sure you qualify, all that stuff.  Great question, and a great point.  Paul in Montreal, Quebec with Question 2 for you, Steve:  Some troubling information about iPhone apps.  Steve and Leo - he's given us a link to a story in h-online.com, and we'll put the link in the show notes, concerning Droid and iPhone apps.  Actually I should say "Android" because it isn't just Droid, it's Android and iPhone apps and how a good chunk of these free apps are conducting data collection from the devices they are installed on.  I've seen this story, talking about Android.  I didn't realize iPhone did it, as well.



He says:  I've never been an iPhone user.  Apart from the device being very pretty, with apps to help you find your socks, I have no urge to get one.  I've always been a little put off by its lack of security and Apple's carefree attitude when it comes to security in general.  Apple might dispute that, by the way.



STEVE:  Yeah.



LEO:  I don't think they're carefree at all.  But I do think, and I know you agree, Steve, that the next vector for malicious software is absolutely going to be portable devices.



STEVE:  It's why this question is on our Q&A today.



LEO:  So this "Study: Many free iPhone apps pass device ID to the app vendor," in the Android sphere it wasn't just the device ID.  Some of them were passing GPS coordinates to ad networks, where your user is, and in theory even phone numbers and other data, personal data.



STEVE:  Well, so this study referred to in this story echoes a number that I've seen.  And I've sort of been letting these things go by because I haven't known what to do about them.  And I just decided, okay, we ought to just take a moment to address this whole domain.  It is the case that Android may be more troublesome than iPhone, but it's also the case that a group of researchers took a look at iPhone apps which were asking for permission, and selected I think it was 30 apps that looked like they may be doing communication, and only 14 percent, so a very small number of apps, were what they called "clean," meaning no communication back to the - while you're using the app for sort of other things, back to the publisher's server.



So we've talked a little bit about this, that these apps generally do ask you for permission.  But they often don't tell you why they need the permission.  It's not clear, if you deny them permission, what's going to happen.  So essentially we're in a situation where I'm afraid that we're going to be spending more time than we want to be spending in the future talking about this particular area of application privacy vulnerability.  Everyone wants to use these phones.  It's all anyone's talking about.  It's a super hot market.  And this notion of third-party apps being added to give us additional functionality is what makes it so fun.  But I guess the only thing we can say is, and I know probably our listeners more than any others understand the inherent vulnerability of apps which are, by their nature, bound to a radio, which are able to communicate on the Internet and back to home base.



LEO:  No. 3, Sean in Woodside, New York has given a lot of thought to the technical consequences of - drum roll, please - his death.  Hmm.  Steve, I'm trying to figure out if I'm taking "trust no one" too far.  I've been thinking about how to make sure people have access to my online accounts in the event that I'm either incapacitated or die a horrible death in a blimp accident over the World Series.  I guess he's a blimp pilot.  I think we do have several blimp pilots in the audience, actually.



STEVE:  I guess we would have to.



LEO:  As a matter of fact.  But you know, we should all think about this.  I think about this all the time.



STEVE:  Exactly.  It's why I chose this.  I think he makes some very good points.



LEO:  I'm a LastPass user, and I considered giving my lawyer a one-time password.  But after thinking more about it, I've decided I want things to be a little more secure, and I'm taking a lesson from nuclear missile silos.  Here's the plan I'm thinking of using:  Generate three one-time passwords.  Select three trusted family members or friends who don't know each other well.  Divide and combine the passwords so any combination of two people have one complete password.  For example, assume that the one-time passwords are 0123, 4567, and 89ab.  Yes, I know that's really 32 characters, it's just an example.



First key is the first half of password one and the second half of password two.  So that would combine 0123 and 4567 to 0167.  Second key is the first half of password two and the second half of password three, 45ab.  The third key is the first half of password three and the second half of password one, 8923.  Give each of the three - and on.  Third key - anyway, you get the idea.  Mix and match.  Actually it's kind of clever because the first key is first half of one, second half of two.  Second key is first half of two, second half of three.  Third key is first half of three, second half of one.



STEVE:  Yeah, so as he says, he's got three family members, and he's divided the keys up so that any pair of those three are able to, together, synthesize one of those three keys because there's three ways of taking a pair of three people.



LEO:  Right.  Give each of the three trusted folks one of the new keys, tell him to hold it until approached by my lawyer.  They don't know anything else.  So they, by themselves, don't have the information they need to reconstitute a key.  Give my lawyer the URL and account name for LastPass, the list of people who have the keys, and instructions on how to assemble them.



STEVE:  Clear instructions, I hope.



LEO:  Take one from column A.  Of course, part of the appeal of this is to hand a friend a card with a 32-character key and say, "In the event of my death, my lawyer will reach out to you.  You will need this passcode."  He just wants to say that.  Most of my friends are already freaked out when I add additional authentication factors like PPP or the grid on LastPass.  Giving them a secret code with instructions to wait until contacted will have them thinking I'm in the CIA.  Is this too much?  I'd love to hear what you think.  Well, it does the job.  I can see some problems with it.



STEVE:  Well, okay.  So, stepping back a little bit from Sean's details, I do think he raises a very good point.



LEO:  Yes.



STEVE:  And that is, as we have, especially those of us who are tech savvy and listeners of Security Now!, who are probably, if anything, overprotecting ourselves from various threats, either locally physical, like with TrueCrypt, for example, or using LastPass with one-time passwords and so forth, I mean, we understand the world that we've created for ourselves, and we're having fun securing it.



But imagine, I mean, really run the scenario of you disappearing.  Let's not give you a horrible death, but you disappear.  And the people in your life need access to your world.  I mean, really, how would that be done?  How would that happen?  If you use a fingerprint to access your laptop, and there's information on it that would be necessary for people, I mean, in your disappearance, imagine that you want them to have access to these things.  I mean, you're gone, so it's important.  How does that happen?



And so, I mean, it really, in taking everything into cyberspace, and taking advantage of the uncrackable technology we have now, which of course was the controversy the FBI's trying to deal with here, you can be in a situation where you may wish that people had access to this, if you're no longer able to make it happen.  So I think it's worth just sort of pausing for a second and saying, you know, it's sort of the equivalent of a last will and testament, but it's how to get to the parts of my technology that I would want my family, for example, or my attorney, to usefully have access to, like bank account logons and numbers and where stuff is and so forth, which is all locked down tight.  And that's well and good as long as we're here to unlock it. But what about when we're not?



LEO:  I think for most people it'd be sufficient - the lawyer, look, do you trust your lawyer?  Maybe a spouse?  A close friend would be sufficient.  I think that's enough.  Although I have to admit I haven't done this.  But it would kind of behoove me to write this all up and give it to my wife and say, you know, honey, if something happens to me.  And then what if the two of us die, I guess I'd have to give it to my lawyer, as well, to go with the wills that the lawyer has.  That seems sufficient.  I'm not worried that my spouse or my lawyers are going to break into my accounts.



STEVE:  No.  And I think that's the proper level.  I think Sean's having fun dividing passwords up among his friends and freaking them out.  But the point is that, do our attorneys have this information?  And my guess is most of them don't right now.  And arguably, maybe they should.



LEO:  I don't.  I haven't.



STEVE:  Yeah.



LEO:  Edward Rosales in Springfield, Oregon wonders about the security of wireless keyboards and mice.  Steve, I use a wireless keyboard and mouse with my Dell laptop.  Just wondering if doing so creates a weakness and/or security hole.  By the way, I'm a licensed SpinRite user, thanks a bunch.  We talked about this a while ago.



STEVE:  Well, yes, and I thought it was due for a renewal because it's been a long time ago.  What we learned was that the wireless keyboards have such weak security that essentially, when you turn the keyboard on, it chooses an eight-bit byte randomly and XORs the data that's being sent with that byte.  Now, what that means is an XOR, an exclusive-or operation, inverts specific bits of the byte.  So it is the case that the data is not technically in the clear.  It's not plaintext.  But, boy, I mean, it would just be a fun and relatively short exercise to decrypt that stream.  It would be trivial to decrypt it.  You simply take a look at the data and begin to play some games with a pencil and paper, and you can pretty quickly figure out what those eight bits are.



So the encryption of wireless keyboards is virtually ineffective.  And it is transmitting at a distance of many meters, so 10, 20 feet, enough so that it's been shown that neighbors, like apartment neighbors, somebody who shares a wall with you, or a floor or a ceiling, is able to receive the output of your wireless keyboard.  Are they doing that?  Probably not.  Could they do it?  Absolutely.



Now, a mouse is a much different proposition.  It's just sending its relative movement.  As you move it up, down, left, right, it says oh, I just got moved over this far, or up this far, or over.  So there's really no information of the same kind that can be captured from a mouse.  But a keyboard is a different matter.  So it certainly is the case that there is a security tradeoff being made when your keystrokes are jumping through the air over to your computer.  There is not strong encryption happening in wireless keyboards.  It's almost no encryption, and so something to be aware of.



LEO:  Yeah.  And there are well-known attacks on this.



STEVE:  Yes.



LEO:  Although I think there are encrypted keyboards.  Wasn't - I mean, well, but not very well encrypted.



STEVE:  I do remember, yes, I think I do remember that there were some that were better than others.  The XORing is, like, of the weakest flavor.  But I think we did hear at the time from either the chatroom or from our listeners that there were keyboards that were doing a better job.



LEO:  Yeah.  Brian M. in Edmonton, Alberta, Canada says Steve doesn't have to stop writing CryptoLink.  Oh, because there's a Canadian audience for it.  Hi, Steve.  I'm glad I'm not the only one losing sleep over that proposed bill in the U.S.  But I don't think you need to stop writing CryptoLink because of it.  In fact, you likely won't have to change much of CryptoLink in order to make it comply.  Let me explain.



At some point you're going to be using symmetric crypto with symmetric keys to encipher the data.  You could just encrypt the symmetric key with a special, high-security "Steve Gibson" public key, and then include that in the stream.  You won't have to shunt the traffic off to yourself.  That way, it requires both you and the FBI to actually grab someone's data.  That is to say, they can't decrypt it without a court order to you, and you can't decrypt it as you won't have a copy of the data.  You wouldn't have to protect that key, either, as it is merely a public key and cannot be used to attack others.  My understanding is that's how PGP works already, so it should be safe.  Thanks for a great podcast.  Yeah, PGP does some wrapper stuff; don't they?



STEVE:  Well, okay.  So I'm not at all concerned about the technology of doing this.  I mean, we've got technology coming out of our ears.



LEO:  A backdoor is easy.



STEVE:  Yes, yes.  And I argue a little bit with the people who are against the legislation taking the position that installing backdoors weakens, like, will be exploited by the bad guys, for example.  I can definitely create a backdoor that no bad guy can take advantage of.  And in fact, I would do it exactly as Brian suggests.  CryptoLink, when connected, will use the symmetric key which the two instances at each end share.  They use that to negotiate a so-called "session key," a temporary session key which is used just for that connection.  All that has to be done is that that session key is encrypted with a public key which is universal for CryptoLink and which only I/GRC has the matching private key for.



So that, exactly as Brian suggests, if the FBI brought to me some captured traffic and a court order - and, see, here's where things get really screwy because it's like, how do I know that the traffic they captured is associated with the court order?  I mean, the practical side of this, the doing this safely, is so full of, is so fraught with problems that it just - it goes exponential pretty quickly.  Because then, as I've also said, how are they even going to know that the encrypted traffic is CryptoLink?  It could be Skype.  It could be anything.  Anything encrypted looks like pseudorandom noise.  So how do they know what it is, if they're on the wire somewhere?



So, I mean, if nothing else, when this law occurs, we're going to have a field day looking at what it is that it says and what it means to the industry.  We certainly can hope that it doesn't happen.  As I said, my fingers are crossed, but I'm less sure of that.  But so it's not that we don't have the technology to do this.  Certainly there are ways that backdoors could be unsafely installed.  But we've got, we're just steeped in technology that would allow all kinds of ways for this to be done.  That's not the problem.



It's what does it mean for us?  I mean, and do I - how do I feel ethically about having the master unlocking key?  I've had people say to me, since the story came out, Steve, we trust you.  CryptoLink's features are what we want.  And if all such things have to have a key, well, then, we'd rather use yours than somebody else's.  So I say, okay, well, I'll take it into consideration.



LEO:  Well, there's more to say about it.  And our next email comes from Sweden.  Dennis Astergren in Karlskrona, Sweden notes the world view according to the U.S. Congress:  Off and on during the previous years, the likes of Pirate Bay have published letters from U.S. authorities where the lawyers from the rights holders of media have stated that according to the DMCA and whatnot, they absolutely have to stop their business because they're in violation of U.S. law.  Every time the same answer is given back:  U.S. law does not pertain to companies or individuals outside the U.S., thank you very much.  Now go away and leave us be.  One sometimes gets the notion that that catches the MPAA or their attorneys off guard and by surprise.  I'm sure that's not the case, it's so obvious; and yet they try.



So in terms of your episode regarding encryption and the demand for installing backdoors, it's the same thing all over again.  What's stopping any U.S. company from merely selling their product via any other country or registering their company elsewhere?  I don't expect the big ones like Microsoft moving shop, but still....  I'm absolutely sure both you and Leo know this, but it could be worth mentioning on the air, U.S. law pertains to U.S. citizens and U.S. companies alone.  It's very easy to get the idea from listening that what you discussed has an impact on everyone.  Did I miss something obvious?  May I suggest you moving to Sweden?



Other than that, many thank-yous for everything.  Longtime user of SpinRite and constant lurker in your newsgroups.  Also many thank-yous to you for pointing me in the direction of Leo.  It was your promo videos for SpinRite, visiting with Leo and Patrick, that introduced me to the world of netcasting.  Regards, Dennis.



STEVE:  Well, so this is the other comment that I've had, both in the GRC newsgroups and from many of our listeners, who said, Steve, just move.  Well...



LEO:  Well...



STEVE:  No, I mean, they're serious.  They're saying, don't you realize this is just a U.S. law, and you could just move somewhere?  And someone was suggesting Aruba or something, which actually sounds pretty nice.



LEO:  It's lovely, yeah.



STEVE:  [Laughing]



LEO:  Trinidad and Tobago.



STEVE:  The problem is, I like it where I am.  And I don't have to do CryptoLink.  I have other things I can do.  SpinRite could use some attention.  It's been now six years since SpinRite 6.0 was launched, and it could use some updating.  And I have other ideas and things that could keep me busy, that I would find interesting.  I would love to do CryptoLink.  I'm hoping the law is not going to happen.



But for me, moving is not an option.  Nor is developing a product that I cannot myself use in my own country.  So someone had also said, well, just make one that's only for export.  It's like, well, okay, that's just not interesting to me.  I want my friends to be able to use it, and for me to be able to use it, and all of our U.S.-based listeners to be able to use it.  So I do recognize - I will say one thing, though.  And that is that it may not be elsewhere today that a law like this exists.  But if the U.S. passes such a law, in the same way that we know that the three-letter agencies are looking at what other countries are demanding from RIM and saying, hey, we want some of that, too, we're precedent-setting here.  And it might very well be that, unfortunately, we pave the way.  I mean, this is all very disturbing.  I would like to say it has no chance of ever happening.  But I think it has a chance substantially greater than none.  So we'll see.



LEO:  Well, and I'd like to point out that, yes, the Pirate Bay thumbed their noses, thumbed their noses, and then were prosecuted by Swedish authorities, no doubt due to pressure from the United States.



STEVE:  Yes.



LEO:  And you can say, well, that U.S. laws don't apply to us, which is of course technically true.  But these content rights holders are putting pressure on every country in the world.  Look at the ACTA agreement.



STEVE:  Yeah.



LEO:  The World Intellectual Property Organization, WIPO, and others.  I mean, this is - if you want to be a participant in the modern world, you're being required to be a signatory to the WIPO treaty and pass laws in your country that duplicate American laws.



STEVE:  Yes.  And the DMCA did happen specifically because of these, the rights holders like the MPAA that pushed this thing through Congress.  And we got a law which is so overly broad that it's being used, and you might argue abused, for example, to keep professors from being able to do research on copy protection.



LEO:  Right.



STEVE:  Yeah.



LEO:  Precisely.



STEVE:  Bad laws do happen.



LEO:  Yeah.  And they affect everybody globally.  So, yeah, Steve could pretend he's in Aruba, but that's not a solution.



STEVE:  Maybe I could get some palm trees in the back here.



LEO:  Well, SlySoft, which is a company that sells, a commercial company that sells, commercially available in the U.S., DVD breaking software, it's illegal in the U.S., but they operate I think out of Trinidad and Tobago.  And so there you go.  And sjeffn6 [ph] is saying that Pirate Bay was not taken down before Swedish law was changed.  But that's the point is it starts here, and it spreads like a virus, like a bad idea.



Griff in Columbus, Missouri shares his take on encryption backdoors, Question 7.  I just watched the TWiT.tv Security Now! Edition 268.  You mentioned the new proposed law might not allow point-to-point encrypted traffic.  Forcing encrypted traffic through an encryption vendor's server isn't necessary, I think, for the government to achieve real-time wiretapping.  I suspect the government intends to obtain the encrypted traffic as it goes through each ISP's servers or routers - by the way, most ISPs already are collecting this data for the government - or maybe somewhere on an Internet backbone.  Also require the encryption software vendor to provide some master key or other means to allow the government to decrypt the messages in real-time.  That's the backdoor.



This wouldn't require, for example, Skype or CryptoLink's point-to-point encryption to go through a central server somewhere.  Even point-to-point messages already go through a relatively small number of Internet backbones where the wiretapping could occur or maybe already occurs.  And that is one of the objections is, well, you've got to change the entire way Skype works.  But...



STEVE:  Yes.



LEO:  Is that true?



STEVE:  Well, the story that was written - and of course we don't have a law yet, we don't have final text of one as far as I know.  But, first of all, again, I chose this one because many people made the comment, and I've read this from people responding many times.  So this is the third of our trio that sort of represent a consensus of opinion and feedback from this.  And so there's two points.



What was specifically addressed was the nature of peer-to-peer communications, meaning point-to-point, where no third party is involved with the traffic.  Skype was highlighted or mentioned specifically because we know that Skype's technology is a point-to-point encrypted stream.  You and I right now are talking with Skype, and there's a flow of encrypted UDP packets directly between our two endpoints.  So it's certainly true that it is - I'm using bandwidth which I purchase from Cogent, which peers with Level 3.  You're using bandwidth that peers with your ISP.  So it's true that there are locations on the 'Net where this communication that we're having is available.  Virtually all the routers, I think there's 13 routers between you and me, Leo, so any of them represent access points.



But my reading of what was said indicated that re-architecting this kind of communication was what this law would require, that is, so that somehow the FBI doesn't have to go to, like, an ISP in order to get this, but is able to somehow present me with a court order saying that they want wiretap access to a given person's, a given customer of mine's use of my product.  That's the way I read this.  And frankly, I don't know how to do that.  I mean, literally, well, I can't.  The architecture doesn't provide it.



So, I mean, certainly there will be, I hope there will be Senate meetings where representatives of Skype and other high-profile companies sit down and explain to the senators or the representatives, with diagrams that are really clear, that this is just not a matter of flipping a switch.  And yes, we would like to comply, like with the FBI's well-meaning and understandable need to have access to our technology.  I just don't know how to make that happen.



LEO:  Somebody's pointing out it puts your life at risk.  If the bad guys say we'd like to know what this person is saying, and they come to you, they don't need a subpoena, they need a brick.



STEVE:  Yeah.



LEO:  And that's not good, either.  Let's not forget that.



STEVE:  Yeah.



LEO:  I'm going to take a break, on that lovely note.



STEVE:  Anyway, so this is the last we're going to talk about it.  I think we've beaten this thing to death, knowing as little as we know about what we're ultimately going to have and the way it's going to work.  So I don't want our listeners to worry that this is going to be a constant theme.  We'll probably come back to it early next year, if the legislation happens, or doesn't.  But I did want to follow up because many people had similar thoughts about here's workarounds.  And we'll just have to see what we end up with.



LEO:  Oliver Stengele in Heidelberg, Germany says welcome to the rest of the world with COICA.  We talked about this last week.  Steve and Leo, as it is common for the listenership of your podcast, I'm a computer science student in Germany, and I'm here to bring you bad news and more bad news.  The idea behind COICA, the government-controlled Internet censorship via DNA blacklists, that's not new.  Not long ago we had the exact same brain-dead proposition in our political organs.  They called it - now, let me see if I can get my German together because this is one of those omnibus words that the Germans love to make - "Zugangserschwerungsgesetz."  "Access complication law" is the literal translation.  It was headed by Ursula "Zensursula" von der Leyen and reasoned with the killer argument of fighting - they always bring this, they always truck this one out - child pornography.  You watch.  It'll be brought out again because nobody can stand up and say, well, I'm for child pornography.  You've got to say, "Of course I'm not for child pornography."



Long story short, the whole thing went through and is currently in effect in Germany.  I would like to point this out, that we take full blame in the U.S. for this because what they do, what the record industry, motion picture industry do is they try this out outside the U.S.  This is what ACTA is all about, is to get it passed across the world so that the U.S. Congress has no choice but to ratify.



STEVE:  Yup.



LEO:  And  so it's a very backdoor way of sneaking this through the U.S.  He says, well, not quite, because a short time after the proposition became law, some politicians realized what they had done and, due to an incredibly huge public opposition, which peaked with an online petition to the German Bundestag with 134,000 supporters, the largest petition to this day, they delayed the censoring part of the law, but did not cancel the whole thing.  The details are mostly disturbing, but one thing is clear:  It is a huge mess.



And guess what?  Not long after "Zensursula," a member of the European parliament named Cecilia Malmstrm got hooked on the same thing, this time for the entire European Union.  I do not need to repeat the reasons against Internet censorship.  You and Leo named quite a few in your recent episode.  But seeing now that even the U.S. is no longer safe from this Pandora's box really bothers me.  If COICA gets through - by the way, tabled for now - it will become a shining example for all those countries that want to implement Internet censorship in the future, a very scary prospect in my opinion.  I just hope the land of unlimited possibilities does not become the land of impossible limitations.  Oh, so well said.  Best regards.  Keep up Security Now! and GRC.  We really need you these days.  Oliver.  Oliver, what a great - I'm going to say that one more time.  "I just hope the land of unlimited possibilities does not become the land of impossible limitations."



STEVE:  [Sighing] Wouldn't it be sad if we are looking back, decades from now, at an Internet which is fully censored and where encrypted communications is no longer safe from random people who are prying.  It'll be sad.



LEO:  Yeah, no kidding.  By the way, for our Swedish correspondent, Cecilia Malmstrm, Swedish.  So there.  If these ideas spread, and I have to say I think we in the U.S. should take blame because most of these content companies are U.S. companies.  That's who really is promoting this agenda.



Kris Ackermans in Kortenberg, Belgium, reminds us of Rijndael's 10th birthday:  Steve, on October 2, 2000 the Rijndael cipher was announced as the winner of the contest the National Institute for Standards (NIST) held in their search for a cipher for AES.  At least that's what I'm reading in the press today.  No one has come close to cracking Rijndael in the 10 years that have passed, despite full publication of the algorithm.  I thought it would be fitting to remember this occasion on Security Now! in times when governments no longer seem to be in favor of true security.  Disclaimer:  I am a Belgian.  Ask Leo why that matters.  Well, Frederique's Belgian.  Maybe that's why.  I don't know.  I love Belgians, I don't know...



STEVE:  Well, and I think the Rijndael designers were.



LEO:  Oh, Rijndael's probably Belgian, of course.



STEVE:  Yeah.



LEO:  I really enjoy listening to Security Now!.  It's one of the few places I know of where things are actually explained.  That's true.  We pull no punches in our quest for true geek explanations.



STEVE:  We keep the propellers spinning.



LEO:  Yes.  Thank you, Leo and Steve.



STEVE:  So I did want to acknowledge, I've talked about with regard to the crypto problem that it's math.  I mean, we have now the math required and a full understanding of how to do unbreakable crypto.  And it is, again, an understandable dilemma that states, as in governments, have a problem with the fact that they are not able to police and monitor what the bad guys are doing.  And that as more communications is done digitally rather than in the analog world, this math, which is all it is, can be applied to communications in order to prevent it from being intercepted and understood while it's in flight.  This is just the way the world is.



And I love the Rijndael cipher.  We did an entire episode on it [Episode 125] where we dissected it and looked exactly at how it operates and how clean and simple and beautiful and pure it is.  I mean, it's just a spectacular piece of math.  And we're, as Kris says, we're not close, I mean, it's withstood a decade now of scrutiny.  It is the basis for most new crypto that is done because we all know we can rely on it.  And it's not going away.  I mean, it's happened.  It's existed now long enough that open source software has incorporated it.  Nobody has to be smart in order to be able to use this uncrackable crypto.  It's just available.



So the best thing that could happen, I think, when this law is up for consideration next year, is that people make the point that, yes, a huge problem could be created by legitimate publishers of software like myself and Skype and anyone else doing a VPN, if a law required that a third party be able to intercept that communication.  A tremendous inconvenience would be created.  Yet virtually no change in access to any communications that anyone was determined not to have eavesdroppable on because that technology is out there.  It's now out in the public domain.



LEO:  Rijndael, Rijndael, rah rah rah.  And for people who are wondering, it's R-i-j-n-d-a-e-l, okay?  It's definitely Belgian.  It's not just Belgian, it's Flemish.  If you're going to Google it.  I bet you - I should try this.  I bet you if you typed "Rijndael" in any kind of Anglicization of it, like "Rhine doll," it would say, "Did you mean...."  Nope.



STEVE:  Well, and I do remember in the early papers that were written, when it was first appearing, they would spell it correctly, and then, parens, it said "Rhine-doll," as in Rhine-doll.



LEO:  How to pronounce it, "Rhine doll."



STEVE:  They'd tell you, exactly, how to say it.



LEO:  R-i-j-n-d-a-e-l, Rijndael.  And I know how to pronounce it only because of one thing:  you, Steve Gibson.  Finally, our Up and Comer of the Week [fanfare].  Alec Thompson, from British Columbia, writes:  Dear Steve - he's 16 - I was listening to your recent podcast, Episode 267.  I was really enjoying listening to the response from 17-year-old JR Hallman.  I'd like to make a sort of shout-out here that I hope you'll mention on the show.  I'm 16 myself, and so far I've learned a variety of skills - C, PHP, Python, XHTML, MySQL, and even recently Assembler.



STEVE:  Yay.



LEO:  Yay.  My personal inspiration came from a site called Hell - I'm not sure I'd even want to visit this site - HellhoundHackers.org.



STEVE:  Hellbound.



LEO:  Oh, good.  Only slightly less bad.



STEVE:  That's better.



LEO:  HellboundHackers.org.  Don't be thrown by the name.  The site is full of supporters for ethical hacking.  Good.  I like hackers.  Hackers are it, man.  And the majority of the site's users are younger than 25.  That's why "hellbound" attracts them.  Actually, if you look at it, this is a very typical kind of site for hackers where it's very focused on content and text, lot of forms, lot of information.  Looks really great.  Together we have a pretty strong bank of knowledge, and I thought I'd mention this in hopes to inspire other kids my age into learning programming skills.  Henry, I'm looking at you, my son.



The site teaches the ins and outs of how to break into sites - I love it.  But that's attractive to kids.  They want the - Henry has asked me, can I learn how to hack?  I will send him to Hellbound Hackers.  But the reason they say is so you yourself can learn how to keep malicious hackers out.  Writing secure code, as you would know, very important stuff.  And I figured you might be interested in passing along the link to everybody.  Whether you're under 25 or not, there's probably something for everyone to learn.  I'm going to - thank you, Alec - I'm going to check it out.  Thanks, Steve, and keep up the great work.



STEVE:  Well, so I just wanted to acknowledge Alec.  We did hear from JR Hallman, whose site we brought to its knees...



LEO:  Oh, sorry.



STEVE:  ...by mentioning his CryptScript site last week, or I guess maybe the week before.  So we got a nice note back from him.  And I just wanted to say I think it's great that young people are listening to the podcast and, again, to encourage people just to get out there and do stuff.



LEO:  This is great.



STEVE:  Because it's the future.



LEO:  They have simulated security challenges, so you can really test your chops here.



STEVE:  Very cool.



LEO:  This is great.  Boy, you know what, I want to check that out.  That looks like a great site.  Steve, we have completed our 10...



STEVE:  Our mission.



LEO:  ...fabulous questions, and your 10 fabulous answers, once again.  If you want to know more about Steve's work, you go to his website.  You'll find out a ton of stuff there, GRC.com.  You can follow Steve on Twitter, too.  He is SGgrc.  Do you still do updates on the iPad, or Pad stuff?  Because, you know, I think there's a lot of new stuff to talk about.



STEVE:  I haven't, except initially.  For me, I mean, I'm a daily Pad user.  I absolutely love it.  But I haven't really run across anything that I thought was significant enough.  So it's just sort of a quiet account.



LEO:  Well, it's going to get active.  Microsoft just announced they're shipping Windows 7 tablets by the end of the year.  SGpad, that's that one.  And then for the official corporate account of the Gibson Research Corporation, just @GibsonResearch.  Steve also sells a very fine and must-have hard drive maintenance and recovery utility which we talk about every week, I hope you have a copy, SpinRite.  You can get that directly from GRC.com in his custom-built and hyper-secure eCommerce system.  You'll also find there lots of free stuff like ShieldsUP!, and CryptoLink will be there someday, maybe.



STEVE:  Yay.



LEO:  God and Congress willing.



STEVE:  Yes.



LEO:  GRC.com.  Go to GRC.com/feedback if you want to leave a question for our next feedback episode.  And you also, by the way, at GRC.com/securitynow, find 16KB as well as the full flavor of this show, and transcripts from Elaine, so you can read along, and all the show notes.  That's GRC.com.  We do this show, you can watch it live every week at live.twit.tv at 11:00 a.m. Pacific, that's 2:00 p.m. Eastern, 1800 UTC, live.twit.tv.  You can chat along as we go.  You hear me from time to time mention the chatroom.  That's irc.twit.tv.  And I think that's it.



STEVE:  Boy, you covered all the bases.



LEO:  All the bases, dude.  You covered all, you, YOU covered all the bases.  Steve Gibson, it's always a pleasure.  Thank you so much, and we'll see you next week on Security Now!.



STEVE:  Talk to you then, Leo.  Thanks.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#270

DATE:		October 14, 2010

TITLE:		The Evercookie

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-270.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After reviewing the past week's security updates and news, Steve and Leo examine Samy Kamkar's (<a href="http://samy.pl/evercookie/">http://samy.pl/evercookie/</a>) clever suite of JavaScript Hacks, collectively used to create an "Evercookie" for tagging web browsers in a fashion that's extremely difficult to shake off.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 270, recorded October 13, 2010:  The Evercookie.



It's time for Security Now!, the show that covers and protects your security online, and privacy, too.  And here he is, the man of the hour, the man who has done more, I think, to protect our security than almost anybody else, Mr. Steve Gibson of GRC.com, creator of ShieldsUP!, SpinRite - the world's best hard drive maintenance utility - and a great many security utilities, including the very first antispyware.  Hey, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  Nice to see you.



STEVE:  Yeah.



LEO:  Today we're going to cover something that a lot of people have been asking about.



STEVE:  Yes.  In fact, it was - I almost sort of sidestepped it because I thought, well, we talked about the EFF effort with Panopticlick and the idea that just sort of passively our web surfing offers enough hints about our identity to be trackable, which is what our Panopticlick episode of Security Now! [SN-264], I don't know, a few weeks ago, a month ago or so, covered.  But the Evercookie is different enough that - and so many people were writing in about it.  And then when I saw, a friend of mine sent a link that The New York Times had picked up on it, I thought, okay, I mean, this is what the podcast is for is to talk about these kinds of things.



And when I looked at it closely, I was very, frankly, very impressed because there are some very clever things that the developer, Samy Kamkar is the guy who did it, at samy.pl - S-a-m-y, one "m," S-a-m-y dot pl.  And his page is samy.pl/evercookie.  Basically he's come up with a cookie that is frighteningly sticky, frighteningly difficult to get rid of.  And some of the things are generic.  Some are super clever.  So definitely a great topic for the podcast, and that's what we'll be talking about this week.



LEO:  The evercookie.  I wish there were - it sounds like something that Willy Wonka might invent, a cookie that you can never finish, but in fact it's not so nice.  Before we get to evercookies, I imagine you have some updates and so forth.



STEVE:  Yeah, some interesting news.  First of all, we're just past the second Tuesday of October, which of course is everyone's favorite Patch Tuesday.  Microsoft broke their own record, which they had previously set.  I guess they would always be previously setting their own record.  Anyway...



LEO:  [Laughing] No one else is setting it, let's put it that way.



STEVE:  However, what's interesting is it was last October, last October of '09 was the previous record that Microsoft set for their own number of vulnerabilities fixed.  They have exceeded that exactly one year later, October of 2010, with 49 security vulnerabilities fixed, in a set of 16 bundles, 35 of which are remote code execution vulnerabilities.  So there's various types.  Obviously remote code execution is bad guy gets to run his own code in your machine without your knowledge or permission.  Then there's privilege escalation and information leakage and different sort of classes of problems.



This one, 35 of these 49 were things that, when exploited, would allow someone to run their code in your machine, which is never a good thing.  They're not helping you.  They're not fixing, they're not upgrading apps that you forgot to.  So many of them were publicly disclosed before the patch, so everyone is breathing a sigh of relief that Microsoft has caught up.  Several of them were zero-day surprises to Microsoft, where Microsoft first learned of them by them being found in the wild, being used.  There were two zero-day vulnerabilities which the Stuxnet worm/the zombie trojan, whatever, that we've talked about extensively, was using.  They fixed one of those two, so that's good.



IE, both versions 6 through 8, all of those versions, got 10 security holes fixed.  And interestingly, several of them were critical, even under Windows 7 and IE8, which generally has been more resistant to these problems.  So, in fact, it is more resistant to these problems, but several of them got by anyway.  And then one thing that will affect users aside from all this is that, as part of this bundle of updates, Microsoft updated their MSRT tool.  And they've finally updated it to detect the Zeus Trojan, which is that online banking, capture your credentials trojan that's been causing so much havoc.



And so I wanted to remind people that normally the software removal tool, the MSRT, is only run monthly by Microsoft.  That is, at some point after it gets updated they'll run it.  But anyone can run it on demand, and it just sort of feels good to do it.  It's not MSRT, it's just MRT.  So if you just go, like under the Start Menu, and choose the Run... option, you'll get a little field there saying, what do you want me to run?  And just put MRT in, with no extensions or anything else, and hit Enter, and that'll fire up the software removal tool, which will then offer to scan your machine right there, sort of while you're waiting.  And you can ask it to do a deeper scan than it otherwise normally does.  And it just might be a good thing to do, after they've made a major update to it, as they have this month.



LEO:  Yeah, it's important to note that they don't do a full, thorough scan every Tuesday, every Patch Tuesday.  They only do kind of a quick one.



STEVE:  Right.



LEO:  So it's a good idea once in a while to do a thorough one.  I presume that gives you a different result.



STEVE:  Well, it potentially finds things that the overview scan won't find.  So definitely worth doing.



LEO:  Right.



STEVE:  We also had a major Java technology update.  In fact, Oracle, at the beginning of this month, I think it might have been Tuesday or Monday, had a major, corporate-wide, huge update of their software across the board.  Most of us aren't going to be affected by that, except for those of us who have Java installed.  They're now at Version 6, update 22, which fixed 29 different security holes, so it was a big one.  And among other things, they did fix their TLS/SSL renegotiation hole, which their own implementation of the TLS technology, the TLS protocol had not yet fixed.  So they fixed that.  They added some new root CAs to their own private store of root certificate authorities, and otherwise just fixed a bunch of stuff.  So I did notice, on my main machine somehow I've managed to survive so far without anything installing Java, which I'm pleased about.



LEO:  You know, it used to be it came with Java.  And even if it didn't, you'd almost always have Java.  And now that's really changed.  Java is not everywhere anymore.



STEVE:  It's not.  And I'm seeing people saying that it's becoming an increasing problem from a security standpoint.  So, I mean, I'm glad it's not on my main machine.  And there have been a number of people who, following other security experts' advice, have removed it from their system, and nothing's broken.  It's like maybe something that they once installed brought it along, and then they removed it, or they stopped using it, and it sort of stayed behind, which it wants to do.  It wants to be an extension to your OS, to provide its own virtual execution environment, the whole JVM, the Java Virtual Machine, which is able to run in browsers and also execute apps natively on your platform.  But it's one of those things where, if you don't need it, you're better off without it.  In any event, it's updated.



And then I did want to mention that Foxit Reader is now at version 4.2.  Many people have switched away from the Adobe PDF Reader over to Foxit, as just something much less lightweight.  Boy, I noticed the other day how big Adobe Reader has become.  It's huge now.  I mean...



LEO:  Yeah.  I use Foxit.  I really like it.



STEVE:  Tens of megabytes of bloat from Adobe.  And they had like a classic buffer overflow problem where PDF files that contained a title longer than 512 characters, and we of course know what that number is, that's 2^9, so yeah, some programmer said, oh, 512 characters, no one's going to have a PDF title longer than that.  And so whoever that was statically allocated a buffer to contain the PDF title and apparently didn't check to see whether the title might actually be longer than that.  Turns out that it will crash the reader if you load a PDF with a title larger than 512 characters, which potentially opens a door to a buffer overrun exploitation.  So that's been fixed at v4.2 and hopefully from there on.



LEO:  Excellent.



STEVE:  In news, one thing caught my eye that I just thought I had to bring up because it was like, uh-oh.  And that was our well-known major content distribution network, Akamai, had one of their employees charged with wire fraud...



LEO:  Uh-oh.



STEVE:  ...because - his name is Elliot Doxer.  His name's been in the news.  A few years ago, actually in '06 when this began he was 42.  He approached a U.S. consulate of an unnamed foreign government, offering them insider information.  Now, the good news is the consulate immediately contacted our FBI and said, uh, this guy is offering us information from his employer, Akamai.  And the FBI set up a classic sting operation.  Apparently an agent, about a year after that first contact, got back in touch with Elliot and said, hey, I'm with the whatever-it-is consulate, and we're interested.  And so they recorded videos of him doing dead drops at a location which the FBI had set up and ended up finally arresting this guy.



The thing that brought it to my attention was that it is the case that any cloud-based services are, like Akamai living up in the Internet, being a content-distribution network, are vulnerable to insiders.  And so the thing to just remain conscious of is that you really do want a technology which encrypts anything you're storing out in the cloud, always, before it leaves your machine.  All the cloud is doing, if possible, is storing a bunch of pseudorandom data, and not having access to what that content is.



Now, that's really not possible unless the application that's running is designed correctly.  And for purely web-based applications, it's arguably not possible at all.  I mean, for example, the Google stuff is understanding the contents of what you're saving, and so we're trusting them with that.  I'm now assembling the outline for our Security Now! podcast every week in Google Docs and then exporting them as a PDF which I share with you.  But I'm trusting Google with this content.



Now, I'm only trusting them, frankly, because I don't care.  It's public anyway.  It's going to be public.  We're showing it, I mean, I'm reading it now.  You're going to be posting it on various feeds.  And I would be reluctant, frankly, to do sensitive corporate, really sensitive corporate documents this way at this point.  I don't know how you do that safely.  But it is the case that insiders have access.  And security people have been saying for a long time, I mean, like, well, like the FBI, when they're looking at things they're seeing that people inside companies represent a bigger threat to companies, arguably, than outside attackers.



Outside attackers have the advantage of being anywhere in the world, operating over the Internet, being anonymous, being able to attack with impunity in the middle of the night.  Inside employees have the advantage of access.  I mean, there may be a door that's left ajar, or they've turned somebody's keyboard upside down to get the password and then logged in and so forth.  So it is the case that all of these dangers are not from the outside.  I think on this podcast...



[Interruption]



LEO:  Just ignore that [laughing].  I didn't mean to put that in your feed.  Facebook is streaming something live from Microsoft, and I just wanted to check in to see if it was anything that we cared about.  I don't think it is.



[Interruption]



LEO:  Yawn.  Okay, we're done.  Moving right along.  Continue, Steve.  Where were you?



STEVE:  So anyway, I think on this podcast we tend, I tend to focus more on the external threats and the technology because it interests me, and what are you going to do about the internal threats?  Although for companies, certainly I think it's very necessary for them to remain diligent and do what they can.  I mean, you want to trust the people that work for you.  The problem is you're extending your trust to all your customers when you're someone who's offering cloud-based services; and somebody on the inside who has access can do tremendous damage to major proprietary interests that are moving their data out to the cloud.  So that just - it's something we're going to be talking about in the future because I'm sure there'll be more problems with it in the future.



And something that is sort of cloud-related, also, I noted that Charles Schumer, our senator from New York, has introduced a bill into Congress where it wants to extend existing electronic funds transfer consumer protections, which cap the liability for electronic funds transfer fraud at $50.



LEO:  Our liability, not the banks' liability.



STEVE:  Correct, caps our liability, consumers are capped at $50.  Chuck's bill would extend that to municipalities and schools.



LEO:  Oh, because lately that's where that spear phishing attack has been against municipalities, hasn't it.



STEVE:  Well, yes.  In fact, I pulled some numbers together here for this.  Earlier this year, for example, $378,000 was transferred from a town, not probably coincidentally, in Poughkeepsie, New York, which is Chuck's home state.  And that $378,000 went to Ukraine.  Also $450,000 was stolen from Carson City, California; $600,000 from Brigantine, New Jersey.  Not far away, $100,000 from the Egg Harbor Township, also in New Jersey.  $3.8 million from Duanesburg Central School District, also in New York, Chuck's state.  And a chunk of that they were able to get back.  They were able to get $3.3 million of it, but still lost half a million, which was never recovered.



So in most of these cases it appears that the banking credentials were obtained by what we were talking about before, the infamous Zeus online banking credential-stealing trojan.  Now, the question is, can banks absorb that kind of loss?  I mean, what Chuck's bill is proposing to do is to limit much larger entities than individual consumers, that is to say, cities, towns, and school districts who have been having their money transferred off and out of their accounts due to electronic funds transfer fraud, limiting their liability the same as consumers.



And so of course the banking industry lobbying groups are saying, whoa, whoa, whoa, wait, whoa, wait a minute, how can you make us responsible for these things?  From their perspective, they're seeing people logging in, presenting valid credentials, and asking to transfer money.  And presumably these entities are routinely transferring money in and out of their accounts, and so this just looks like another valid transfer.  So it'll be interesting.



It's not clear that this is going to get through our Congress in this session.  It may well be not till next year, in which case Chuck's going to have to reintroduce it.  But it does remind me of the advice I've given to our listeners, which is - and I know that you heard this before, Leo, and may have taken action, and I have on my own corporate accounts.  It's possible to explicitly disable those features from accounts typically with your bank.  You say, we do not use, do not need, and do not want electronic funds transfer to and from specific accounts.  So disable them.



And it's the kind of thing where, hey, they're on by default, typically.  And unless you tell your bank to turn them off, they haven't.  And so it just makes sense, from just a pure security standpoint, disable those things that you don't actively need.  And you may be glad you did.  Because, I mean, it would be nice - oh, I should also mention that this does not extend to small, medium, or large-sized companies.  So Chuck's bill is extending this to municipalities and schools, but not to businesses.  So businesses will still be vulnerable.  And I did want to credit Brian Krebs, who used to be with the Washington Post, now is blogging on his own.  He did a lot of reporting on this.  And so that was useful when I was pursuing these details.



LEO:  I was an avid reader of his Security Fix column in the WaPo.



STEVE:  Oh, and we talked about it often.  I mean, I was often saying, hey, here's something that Brian brought up.



LEO:  But I'm glad that he's still blogging and still talking about it.  That's great.



STEVE:  Yup, he'd doing a great job.  Facebook has now added one-time passwords.



LEO:  Yay.



STEVE:  Yes.  In a very recent, last couple days, blog post, they announced one-time password support, which would be very useful in situations, for example, where you want to log into your Facebook account, somewhere where you don't have 24/7 control of the security of the machine.  The way it works is, you need to register your cell phone number with your Facebook account.  So add your cell phone phone number to your Facebook account.  And when you are somewhere that you want to log in using a one-time password, you text the string "otp" to the number "32665," and you will immediately receive a password that can be used only once, to log into your account, and which in any event expires 20 minutes after that.  So they've said they'll be rolling it out gradually, meaning it may not be available immediately upon your hearing this on the podcast.  But they said it would be widely available within the next several weeks.



So that's a nice step forward.  I'm glad they're doing that.  And I also saw in the same posting, although I feel like this is something we've talked about, or maybe you talked about on another podcast, Leo, that they're adding the ability - maybe it was Google, and they're following Google - to log you out of other sessions which you may have left logged in, in other locations.  So, for example, if you were over at a friend's house and logged into your Facebook account using their system, if you went back home and then thought, ooh, shoot, I forgot to log myself out over there, you're able to log yourself in and, using your account settings page, you can see any other places that you're currently logged in and then explicitly log those out there.  So that's additional good security.  I'm glad to see them pursuing those things.



LEO:  They've done a number of things.  I know I get an email now every time I attach another device to Facebook for sending information back and forth using OAuth.  I think Facebook's paying a lot of attention to this.  I might mention that there is a press conference going on right now, I've been watching it, at Microsoft headquarters.  Facebook is streaming it on their Facebook live streaming page.  And it looks like Facebook and Microsoft Bing are going to do a deal, and there's some speculation that perhaps Facebook will start using Bing as part of its Facebook Connect.  But I do think that it's really important that Facebook pay attention to security since they are in fact now the interface for people to the web in many, many, many cases.



STEVE:  That's why I felt it was worth bringing it up here.  I mean, I know you and I have been rough on Facebook from a privacy rights standpoint and enforcement standpoint.



LEO:  Well, we'll continue to be that way.



STEVE:  Yes.  But they just, I mean, you can't get away from them.



LEO:  Right.  And I will praise them when they do the right thing, which they are doing here, yeah.



STEVE:  Yeah.  And then, in a little bit of a mystery, the UAE and BlackBerry, that is to say RIM, the makers of BlackBerry, have reached some sort of agreement.  Their disconnection of BlackBerry services that had been threatened and widely reported has been canceled.  And everybody's happy, and no one is saying why or how.



LEO:  That scares me more than the original deal.



STEVE:  And Saudi Arabia and India have also both backed down.



LEO:  Really.  Hmmm.



STEVE:  Yeah.  So the problem is, as I understand it - and maybe we'll do a podcast on this.  I pulled up all the technical documentation.  I have the PDFs which explain how the RIM technology works to be secure, so that the data is available for understanding this.  And if RIM is to be believed, and certainly I believe them, they have been saying all along that they are unable, they are technologically unable to provide the kind of access that these countries want because the way they originally designed the system didn't allow any sort of man-in-the-middle eavesdropping, which is what the UAE, the Emirates have said that they require.  So, I mean, I would like to believe that the RIM execs sat down and explained this and said, look, we can't do anything about it.  You either allow it or not.  But here's the technology.  Or maybe there is some way of establishing a man-in-the-middle server.  It's not clear.  But when deliberately asked, point blank, RIM has said we will not discuss what was decided.  It's proprietary.



LEO:  I can only think that's bad for everybody.



STEVE:  I know.



LEO:  I'm sorry.



STEVE:  I know.



LEO:  I'm just a - maybe I'm paranoid or a pessimist.



STEVE:  The good news is there are a lot of people who have time on their hands, apparently, to plow into this.  I will keep my ears peeled for any news of what's going on.  I imagine that people who look closely at the BlackBerry technology would be able to detect whether, for example, certificates have changed, or certificate authorities have changed, or what was going on.  So I don't know.  But I wanted to bring that to people's attention.



And in my errata, we haven't had any errata for quite a while, but I got a kick out of the fact that the news that jailbroken Kindles - it's now possible to jailbreak a Kindle - are able to run the original Zork.



LEO:  I love it.



STEVE:  From Infocom.



LEO:  That's a text adventure.



STEVE:  Exactly.



LEO:  That we nerds love.  That's great.



STEVE:  Exactly.  And it's perfect for a Kindle because it needs something that's textual and sort of slow, where you're typing instructions in, and then it's telling you what you're seeing and what's going on, and you're able to explore your environment.  I didn't realize that there were some apps.  Amazon apparently has a couple free applications which they've developed and made available.  And then Electronic Arts has released Scrabble for $5 for the Kindle.



LEO:  Oh, that's neat.



STEVE:  Yeah.  Now, the problem, of course, is the Kindle is very UI challenged.  And apparently the Scrabble, EA's Scrabble game is pretty good except you can't get to it because of the rather sad user interface that the Kindle has.  I mean, it really needs a touch screen if you're going to do things that are very fancy.  And frankly, typing on the keyboard is a painful process, too.  It's not something that you want to do that much.  So the Kindle's got up, down, left, right navigation and a couple buttons, but really not much more than that.  So I don't think we're going to see a big active gaming environment for the Kindle.  And when Amazon in fact announced that they'd created an SDK and opened it up for people, it's like, oh, okay, what are they going to do with this?  But, you know, maybe we'll see something clever.  It would be sort of interesting to me.  I just think it's a perfect eBook reader, so I'm happy.



And then one other little bit of news in errata is that an analysis of where people use their iPads have found that they spend one fifth of their time in bed.



LEO:  Hmm.  That's about right.



STEVE:  Yeah.



LEO:  Don't we spend a fifth of our life in bed?  More than that.  A third.



STEVE:  So apparently 20 percent of people's use of their iPads is they tuck themselves under the covers, and then they turn it on, and they read or they surf or they check their email or whatever it is they do.  Who knows?  But I thought that was sort of interesting and appropriate, yeah.



And then always on the outlook for some sort of a new testimonial for my own company, GRC and SpinRite, I have something different that I've never mentioned before.  And in fact the subject was "GRC's Tech Support:  A Different Slant on a SpinRite Success Story."  From Melbourne, Australia, Russell Phillips wrote:  "Hi, Steve.  I would like to say thank you for providing such a great product in SpinRite.  But thanks especially to Greg and the rest of your tech support team."  Well, Greg's probably looking around, saying, "What team?  It's just me."



LEO:  Well, that's a team.  A team of one.



STEVE:  Which is true, a team of one.  Russell says, "I purchased SpinRite a few weeks ago" - oh, sorry, a few years ago.  "I purchased SpinRite a few years ago after listening to you and Leo on Security Now! (love that show!!) and have used it on all my PCs and my kids' PCs and have never had a hard disk problem."  Okay, well, he's the poster boy for this is the best thing you could possibly do is believe me when I say, if you use SpinRite, your hard drives won't die, or they won't have these problems, which is exactly what has been his experience.



So he said, "What prompted this email was that I purchased two new PCs this year, a Dell desktop and a Dell Netbook, and attempted to use SpinRite on them as soon as I received them.  Unfortunately, I could not get them to boot into SpinRite, whatever I tried.  I purchased the desktop first, and after a number of attempts to run SpinRite I contacted Greg in your 'tech support department.'"  We'll put that in quotes because that's Greg at home.  "After a couple of emails back and forth, and following his advice, I had SpinRite running on the desktop without a hitch.  Apparently the problem was due to the configuration of the hard drive settings in the PC's BIOS, which Greg knew all about and was able to help me fix.



"Fast-forward a couple of months, and I purchased a Netbook.  Again, I could not get SpinRite to boot from a USB drive since this Netbook has no CD.  So I contacted Greg again.  He responded immediately, and again his advice was spot-on.  And I am now sitting here with SpinRite running on the Netbook without a hitch.  I just needed to configure a bootable USB drive correctly.



"So again, a big thanks to you, not only for producing SpinRite, but also for having such a helpful and prompt tech support 'team' standing behind you.  Keep up the good work at GRC and also with Leo.  I look forward to each episode of Security Now!, and I'm always learning something new.  Thanks again from a fan in Australia.  Sincerely, Russell Phillips."



LEO:  How sweet.



STEVE:  Very neat.  Thank you very much for sharing that, Russell.



What's cool about the evercookie is that its designer, Samy Kamkar, has produced an open source, freely downloadable, available API which exploits in some clever ways essentially what can be done with scripting.  So The New York Times picked up on it, as I mentioned, on the binary day, 10-10-10, had a story titled "New Web Code Draws Concern Over Privacy Risks."  And they focused on some features primarily of HTML5, which actually does have a number of features which are of a concern from a privacy standpoint.



But what Samy did is he developed a suite of 10 different ways - many of them clever, that we're going to talk about in detail - of inducing our computers to accept, store, and return an immutable token.  So we know what that means.  That means a means of tracking us, a means of following us as we move around the Internet, which is traditionally what standard HTTP browser cookies have done.  Many people understand the concerns about browser cookies.  They've got third-party cookies turned off.  They flush their cookies when their browser stops.  I mean, the original HTTP cookies have been around for so long that all kinds of tools have been developed to aid people who are annoyed by that behavior to get some control.



What Samy did was look at beyond what the Panopticlick guys at the Electronic Frontier Foundation did.  He said, okay, what's possible to do using scripting and all the features of a contemporary browser?  So in his own FAQ, his Frequently Asked Questions on his page, he asks the question of himself, what if the user deletes their own cookies?  And Samy replies, that's the great thing about evercookie.  With all the methods available, currently 10, it only takes one of those cookies to remain for most, if not all, of the rest to be reset again.  For example, if the user deletes their standard HTTP cookies, their LSO - that's the Locally Shared Objects data that Flash uses - and, for example, all HTML5 storage, the PNG cookie and history cookies will still exist.  Once either of those is discovered, all of the others will come back again.



So the first thing I want to make sure people get is that he's storing a single token in - he's basically squirreling it away in many different places, every place he can think of.  And then when you revisit a page that is using this evercookie technology, which is now freely available, the script on the page will look in each of those different little squirrel holes to see whether that immutable token has survived, that cookie, essentially.  And, if so, it says, ah, good, here's an instance of it.  I only needed to find one.  And then, if any of the nine others had been deleted, it refreshes them, that is, it reestablishes them so that this thing basically holds on really hard.



So let's look at where he's storing this stuff because this is where the fun and the cleverness is.  First of all, he does use traditional HTTP cookies, so standard web browser cookies he will take advantage of.  And as we know, unfortunately, even today, third-party cookies are enabled by default, and first-party cookies are.  So in general your browser will accept a cookie from a page you visit.  With this evercookie code, what that means is that, upon that happening, immediately that cookie value is spread throughout your system using scripting on the page, squirreling it away in case you should deliberately flush your cookies, disable the cookies, delete that cookie, it doesn't matter.  It's already gone many other places within your browser.



It of course uses Flash cookies, the so-called LSO, the Local Shared Objects, which is technically configurable using the Macromedia domain.  You're able supposedly to turn that off.  And we were talking just recently on the podcast, a week or two ago, that the UI seemed a little tricky for me because I thought I had turned it off, and I looked at the other tabs in the UI, and then I went back, and it hadn't taken, the offness.  However, a day later I looked, and it had stayed off.  So maybe it just needed to be told twice.  Who knows.



The one thing that is interesting about Flash cookies that's worth noting is it bridges browsers.  Since you've got a single instance of Flash installed in your system, which surfaces on different browsers - for example, IE has Flash, Firefox has Flash, Opera has Flash, and of course Safari - the idea is that that represents a single point of contact.  So if the evercookie had stored itself, among everywhere else, in Flash, and you brought up a different browser and went to the same site, then on that domain multiple browsers are sharing the same instance of the Local Shared Objects in Flash, which means that the evercookie would be able to jump into a different browser.  So that's worth noting, as well.



Silverlight, which of course is Microsoft's next-generation, essentially sort of competitor to Flash, Silverlight offers something called "isolated storage," which is essentially local shared objects from Microsoft.  And on Microsoft's page they say, "In Silverlight, there is no direct access to the operating system's file system, except through the Open File dialogue box.  However, developers can use isolated storage" - that's their name for it - to store data locally on the user's computer.  There are two ways to use isolated storage.  The first way is to save or retrieve data as key/value pairs by using the IsolatedStorageSettings class.  The second way is to save or retrieve entire files by using the IsolatedStorageFile class."  So here we have...



LEO:  Is that kind of a sandbox, the isolated storage?



STEVE:  Well, it's actually - it's Microsoft's solution for wanting some means for allowing their Silverlight technology...



LEO:  [Indiscernible] storage.



STEVE:  Yes, to store - to be persistent.  And the bad news is, it's tracking.  I mean, it's absolutely tracking technology.  And I haven't discovered any sort of a UI that Silverlight has.  I don't know if there is one squirreled away somewhere.  But I haven't found it.  And so, I mean, it would be nice if there was some way of disabling that, or examining it, browsing it, looking at it, filtering it, controlling it somehow.  Otherwise we don't even have as much control as the little control that we have with Flash cookies.



LEO:  Well, those two are the obvious methods.



STEVE:  Okay.



LEO:  Now it gets sneaky.



STEVE:  I love this one.  So Apple first introduced something in WebKit which they called the HTML Canvas, which was used for dashboard widgets and also in Safari.  An HTML Canvas is a scriptable rectangular area of space on your browser page where JavaScript is able to draw.  Now, we've had scalable vector graphics, SVG, for a while.  And that's cool, that's vector based, sort of like Adobe Illustrator or Corel Draw.  Instead of being pixels, it's lines and arcs and curves and so forth.  And what's cool about that is, as the name implies, it's physically scalable.  You're able to stretch it out if your screen is larger, or it's able to squeeze itself down by doing everything with vectors.



Apple wanted to essentially have the same sort of power, but with bitmaps, with regular pixel images.  So they introduced it.  Then it was adopted by the Gecko browsers, so Firefox has it, as do Opera and Chrome.  It's then moved into the HTML5 standard.  IE9 doesn't quite have it.  It's not clear whether it's going to get it or not.  But I wouldn't be surprised because Microsoft's making a lot of noise about IE9 being so standards-compliant and passing all the various torture tests and so forth.



LEO:  And it's HTML5.  Everybody's - right?  Canvas, it's the same one as HTML5 Canvas; right?



STEVE:  Yes, yes.  Okay.



LEO:  If you going to support HTML5, you've got to do it.  You don't have a choice.



STEVE:  So here's the idea.  A web page using this technology has an image on it.  And it asks the server, hey, what's the value?  It makes a standard request for the image.  The server that has obtained or knows what the cookie is for this session, as it would, designs an image where the value of the cookie is stored in the RGB, the red-green-blue pixel values of the image, which it returns to the browser with a 20-year expiration.  So this PNG image, for all intents and purposes, doesn't expire.  It turns out that scripting is able to load a browser image into the canvas, this HTML Canvas.  And the HTML Canvas API is a full pixel-drawing API that allows you not only to set pixel values, but to read them.  So this is a means of storing a cookie in an image which the script has access to.  And by reading literally the color values...



LEO:  Oh, my god.



STEVE:  [Laughing] By reading the color values in the image, it's able to extract the cookie's value.



LEO:  You mean they store it in the RGB.



STEVE:  Yes.  Yes.



LEO:  That's steganography.



STEVE:  Yes, it is, exactly.



LEO:  Wow.



STEVE:  Exactly.  So you could, again, as Samy indicated earlier in his FAQ, you could flush everything else.  But if you forget one thing, if you didn't also flush your image cache for that domain, living in the image cache is a tiny PNG with the cookie stored in it.  And when you come back to the page, script will load that into the HTML Canvas and take advantage of this pixel-level drawing API to obtain the RGB color values.  And those are the value of the cookie, which then recreates all the other ones that you did delete.  Okay, now that was good.  This next one is beyond good.  And this is the one where I said, okay, this guy gets an award.



LEO:  It's pretty - actually, I can see why he published this because it's like, look what I did.  I'm not happy about it, however.



STEVE:  Now, back in '06, Jeremiah Grossman, and we talked about this then, four years ago, came up with a very cool hack where he could tell you what sites you had visited because CSS has this notion of visited links.  And as anyone using a web browser knows, oftentimes you'll look at a page, and some of the links will be colored differently.  And you look at it, and it's like, oh, yeah, I've already been there.  So it's a nice visual cue to allow you to see what links, what URLs you have already gone to.  So CSS colors them differently.



JavaScript, being very powerful and being a full language, the JavaScript language allows the programmer to query the color of a URL, thus telling you whether you have - telling the script whether you have been, sort of by implication, to that URL or not.  JavaScript doesn't even have an explicit way of querying that, so this is a hack.  This is like information leakage that was never intended as part of JavaScript.  But by saying what color is this href on the page, the script can infer.



So here's what Samy figured out.  He says, okay.  How can I store a cookie with that information?  And he figured out how.  Once he has the cookie value that he wants to store, he converts it, he uses base 64 to convert it just to ASCII, so that the cookie could be like a URL.  Just upper and lowercase A-Z, 0-9, and a couple other characters gives you 64 different - an alphabet of 64 characters.  He has his script manually access a URL.  And for the sake of example, we'll say google.com/evercookie/cache.  And then say that, for example, after he's converted the cookie into ASCII, say that the first character, and I'm using his example because it's simple, is "b."  So he attempts to access, with his script, Google.com/evercookie/cache/b.  Then he accesses the same thing /bc, if the second character of the converted cookie was "c."  Then he accesses /bcd.  Then he accesses /bcde, and finally /bcde-, that being the cue that that's the end of the cookie.



Now, so what he's done is he has set history, he's said, I have visited those four URLs ending in /b, bc, bcd, and bcde.  And then - I'm sorry, five URLs, and bcde-, those five URLs.  He's set the history memory in the browser so that, if it ever encounters those URLs again, CSS will color them differently.  And this can all be done, you're not seeing any of this on the page, this is done sort of at the script level.  So now here's what he does.  When you next come to the page, he successively tries /a, okay, wrong color.  That is, his script builds a URL, then checks the color of it.



LEO:  All behind the scenes, none of it visible.



STEVE:  Right, none of this is visible.  His script builds the URL with /a, checks the color of it.  And that's like, oop, that's the non-visited color.  So he disables, he deletes that one and builds the same URL /b.  Oh, that's the visited color one, which means /b is the beginning of the cookie.  Then he says, okay, I got the first character.  So he takes that URL apart, and now he goes to /ba.  Nope, that's not visited.  /bb, nope, that's not visited.  /bc, oops, that's visited.



So now he has the first two characters.  And you can see the reason he visited those URLs in succession, he's left himself a trail of breadcrumbs through this history that allows him to essentially brute-force explore, but character-by-character reveal, the ASCII value of the cookie, until he gets to bcde, and then he gets - so he tries the hyphen, and he says, ah, I've reached the end.  Now he's got the ASCII which he uses to, with base 64 again, to turn it back into what it was before, if it wasn't already ASCII; and he's recovered the cookie using the history of where you have browsed.



LEO:  So if I, right now, and we've only covered, what, four out of the 10...



STEVE:  Uh-huh.



LEO:  But if I cleared cookies, cleared Flash cookies, cleared Silverlight storage - I don't know what I'd do about PNGs.



STEVE:  Flushed your browser cache.



LEO:  Flushed cache and flushed history.  I've now deleted those four techniques.



STEVE:  Yes.



LEO:  But we're not done.



STEVE:  And you have to do all of them because any one, any one that survives...



LEO:  That's what's interesting.



STEVE:  ...reconstitutes the rest.



LEO:  Repopulates it.



STEVE:  Yes.



LEO:  So only one of the 10 has to survive.



STEVE:  Yes.



LEO:  Wow.



STEVE:  There's also a tag, a standard HTML tag which I don't think we've ever had occasion to talk about.  It's been around for a long time.  I've seen it.  Anyone looking at browser headers will have noticed it.  It's called the ETag.  The idea is that browsers want to know if their copy of something that they have cached, like images for a page, is still current.  The way that's normally done is that, when the server issues a resource, like an image, there will be an expiration date associated with it.  We were just talking about expiration dates relative to this PNG cookie.  There'll be an expiration date associated with it, and it'll say - and it's called the Expires Tag.  And it'll say "Expires 01-01-2020," 10 years from now.  And so the browser stores not only the image, but the expiration date, which allows it to say, okay, I've got a copy, and I don't need to ask for it again.



It's also possible for the browser to make a request and store the date that it cached this object, and it's able to make a request called If-Modified-Since, where the browser then says, here's the date that I have this.  Give it to me if it's been modified since.  And if it hasn't been - the server checks.  And if it hasn't been modified since that date, the server responds with a return code of "304 Not Modified," telling the browser, hey, it's good to go, use the one you've got, we don't need to take up time with me sending it to you again.



Well, there was a concern that it would be nice also to have something more like a signature so that, if something was changed, even though, I mean, the date thing ought to be enough.  But the developers said, hey, let's create like a digital signature that's called the ETag.  And so it's just an arbitrary string which the server is also able to provide.  So when the browser says, hey, I need this image, the server says, well, here's the Expires Tag, telling you formally how long I think you could keep it.  But here's also an ETag, which is just an opaque token.  And the server can generate it any way it wants to.  It could be like a digital signature, like a hash of the contents of that image.  So if anything changed in it, and then it was rehashed, it would create a different signature.



So the browser stores the image, the expiration date, and this ETag value all together.  And when it's later bringing up a page, it sends the ETag back to the server with the header If-None-Match.  So the idea being, this is the one I've got.  If it doesn't, if the ETag I have doesn't match the ETag you have, then I want a fresh copy.



Well, what Samy realized - and I guess it seems, in retrospect, obvious, but apparently no one's done it before.  It's an opaque token.  It's a cookie.  I mean, and this one scares me, you don't even need scripting for it.  So far the stuff we've talked about is heavily scripting based.  HTTP cookies are not.  And, well, and to some degree Flash and Silverlight are because, if you had scripting disabled, they're not going to run.  And the other things are heavily scripting based.



But this ETag is just like an HTTP cookie.  The browser asks for something, and the server sends it an ETag which it stores.  So you would need scripting to read the ETag value.  So it wouldn't work without scripting, but it definitely is an opaque token which we're not thinking about right now, I mean, we haven't been for all these years.  So Samy thought about it and added it to his JavaScript, which allows it to be used for tracking.  So there's another one.



LEO:  Wow.  So I'm sure at the end we'll talk about ways to fight this.  But I guess NoScript would fight the ability of a site to retrieve that cookie.  But they could set it without JavaScript.



STEVE:  Correct.  Correct.  It could be set.  And then if at any time later you had scripting on...



LEO:  There you go.



STEVE:  Oh, but wait a minute, no.  That would only be if the script cared, for the purpose of reconstituting all the other ones.  Even without...



LEO:  Ah.  But at least you could get the cookie without rebuilding.



STEVE:  Correct.  Well, even without scripting, a given instance of the browser would be sending back that same ETag.  So for tracking, the ETag is 100 percent effective, just like an HTTP cookie is, and you do not need scripting.  So even if NoScript was enabled, unless something was explicitly filtering ETags, you're trackable.  You can't - the scripting on the client side, on the browser, would be necessary for repopulating all the other cookies and keeping all these multiple ways of tracking you synchronized.  But the ETag by itself is all you need for tracking.  And we have no control over it, no control through the user interface at all.  So there, only flushing your cache, flushing the browser cache, would flush the images and the associated ETags.  



LEO:  Wow, amazing.



STEVE:  Yeah, yeah.



LEO:  And we're not done.



STEVE:  We're not done.



LEO:  There's more.  But wait, there's more.



STEVE:  Turns out that the Document Object Model, the DOM, for standard state-of-the-art browsers, has an actually not very often used property for windows called "name," where a window can be named.  Most windows - and by "window" we mean, like, the surface that programmers call, like, the page you're seeing a "window" from a standpoint of, like, that's the terminology used in the scripting internally.  And it's not very useful because no one's ever really cared before.  But someone realized, hey, you know, that's sticky.  So, like, it would be a way of creating a session cookie.  It doesn't persist across browser restarts.  But it persists as you move around in a site.  So it's not useful for, like, intercession tracking, but it's very useful for tracking a user moving through a website who might have disabled first and third-party cookies.  Most people have first-party cookies enabled because so many things don't work at all if you don't enable first-party cookies.  And so this is sort of an alternative first-party cookie.



The one thing that's a concern about this is that the name of the page, like the tab, or the page, is what's named.  And if you click a URL to go to a different domain, the page name doesn't change.  So it does create an opportunity for cross-domain leakage, and that's a bit of a privacy concern; whereas, for example, cookies at least are domain specific.  If Amazon.com gives you a cookie, then there's no way that Microsoft.com is able to read it.  It's only using third-party cookies with assets that are appearing on a page that someone like DoubleClick.net, for example, is able to track you across domains.



But again, Samy's taking advantage of it.  And if, for example, you were on a page, and then you deleted a bunch of stuff, and you thought you'd cleaned yourself up completely, well, he's named the page the value of the cookie.  So the next thing you do on that site that's using his evercookies would - it might say, wait a minute, I don't seem to be finding any of my cookies here.  But if it looks at the page, that would be where the cookie had - the one place you couldn't get to, and actually you can't.  There's no way a user can delete that when they're sitting there on the site.  The page has been named sort of secretly.  It's not the title, not the title that you see.  It's sort of an internal, programmer-level handle that scripting could use.  And we have no - we as users have no access to it.



So you might think that, whew, I just successfully deleted everything.  And then everything would just instantly come back because the page has a name, and it's squirreled away the value of the cookie there.



Also, Internet Explorer has its own UserData extension.  And for years I've just sort of turned off in IE, back when I was an IE user, UserData Persistence.  And you may remember, Leo, like in the Advanced tab of Internet Explorer, there would be, you know, you could disable UserData Persistence.  And it was like, okay, that sounds like a good thing to do.



LEO:  Yeah.  Well, yeah, if you knew what it was, maybe.



STEVE:  Thank you very much.  I don't know what it is, but I don't want it to be persistent.



LEO:  Yeah.



STEVE:  We'll turn it off.  Anyway, it's disappeared from the UI.



LEO:  Oh, can't turn that off anymore.



STEVE:  No longer available to turn it off.



LEO:  I presume it's a cookie-like function, though; right?



STEVE:  Oh, yeah.  It's not sinister.  It's a way, well, the good news is it's Microsoft only.  No one has adopted it.  It hasn't gone into standards or anything.  And maybe it'll fade away, sort of the way VBScript has, something Microsoft tried to do, and it didn't take.  So it's just one more way.  And Samy is using it because most people are still using IE in the world, and now you can't even turn it off through the user interface.  So it's the same sort of thing.  It's a site-specific place where script is able to squirrel away some information, and it's persistent, as its name implies, UserData Persistence, which allows it to identify you or basically whatever information it wanted to store about you and obtain it at some later session.



So there's all of those.  I think we're at six now.  There are four more that we can kind of lump together.  Unfortunately, they're part and parcel with HTML5, HTML5 in the formal spec.  So far everything we've talked about has sort of been, well, they've been out in left or right field somewhere.



LEO:  Proprietary in some way.



STEVE:  Yeah, well, or...



LEO:  Not standards based.



STEVE:  ...screwy, like setting bit values and pixels and things.  These are formally part of the HTML5 spec.  There's session storage, local storage (which is inherently persistent), global storage, and then even an SQLite for people who have installed SQLite, you know, SQL database on their system.  In the HTML5 spec is the SQLite subset for allowing scripting to do database things on your computer.  Now, the good news is most people probably aren't installing it.  On the one place I was playing with this, this morning, it said, okay, I don't know about that.



Oh, in fact, I should mention, Samy's page lets you do these things.  He has an "Explore the Evercookie" feature.  So you can go samy.pl/evercookie.  And up at the top of the page is a button that you can press to set yourself an evercookie, which is just...



LEO:  On your system.



STEVE:  On your own system, which is just - so basically he's using his own script on his own page, at your request, to establish a cookie.  It's just an integer-value 1-1000.  And he says, don't worry, I'm not using this to track you.  This is just for demo.  And then you can press another button to try to read back the cookie that's been stored.  And it all works.  I found several things that it - it didn't get my PNG image value correct.  It was off by 300.  Actually my cookie value was 447, and the PNG recovery was 147.  So there's a little bug in his code somewhere.  And I'm using a high-color system, so I don't think that's what it was.  But I'm sure he'll fix it.  And I had just, like, yesterday he added the Silverlight technology.  So this is still a little bit of a work in progress.  I think he's at, like, 0.4 of his beta or something.  So...



LEO:  Oh, I'm so glad it's going to get better.



STEVE:  Yeah, isn't that nice.  And it's public domain and open source, and everyone's free to grab it and use it to log on...



LEO:  I'm sure they all have by now.



STEVE:  Uh-huh.  And so in his FAQ, at the very end, he asks the question, can it be stopped?  And he did say that private browsing in Safari will stop all evercookie methods after a browser restart.  So Apple Safari private browsing is robust enough to just shut all this down.  I mean, private browsing creates a sandboxed environment such that nothing persistent leaks.  And that's good news.  And for the rest of us, for example, Firefox users, our good old friend NoScript is highly effective.



LEO:  Oh, good.



STEVE:  But, for example, it doesn't deal with ETags.  I've never seen anything that does.  So ETags look like a very nice, well, nice in a...



LEO:  For him.



STEVE:  Yeah, nice for anyone who wants to track you, means of tracking people.  And now that this has spread, I'm sure we'll see it popping up as a tracking means all over the place.  Maybe our NoScript friend will add that and...



LEO:  I was going to ask.  So you could, in theory you could protect against all of this, now that people are aware of it, by building it into NoScript.  Or something like that.



STEVE:  Well, yes.  Now, okay.  So here's the real takeaway from all this.  I mean, because what we've seen is a bunch of very clever things that a script can do.  I mean, this notion of hiding a cookie in RGB values of an image, which the HTML Canvas API allows you to access, or very cleverly hiding it in a hierarchy of visited links, which again scripting allows you to access, what this is really telling us is we've lost the war.



LEO:  Yeah.



STEVE:  That, if you've got scripting running in your browser, you've got code which you've accepted from the sites you're visiting.  And they can pretty much do what they want to, if scripting is allowed to run.  It's code.  And if it wants to store things on your system for the purpose of identifying you when you come back later, it's pretty much going to be able to.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Well, it's a fascinating subject, I have to say.  And I guess you can't really fault Samy for releasing the information because presumably others could have figured this out. 



STEVE:  Yeah.  It's better that it's in the public domain.



LEO:  Better that it's out there.



STEVE:  And that we all know what can be done so people don't have a false sense of, oh, look, no one's going to be able to track me.  I'm sneaky.  It's like, yeah, well, I mean, what it really says is something like a fully sandboxed browser, or as we've talked about before, booting an environment from a CD and doing your surfing, I mean, if you're really that concerned about it, doing your CD in an environment where nothing is written to your hard drive, but it's all in RAM.  And then when you shut that session down, you've disappeared.  Nothing persistent from one visit to the next.  Basically this raises the bar to the point where that's now the only way to be safe.  Or I guess a virtual machine, too, if you...



LEO:  Well, let me ask this question.  So when you say "safe," what is the risk of this kind of thing?



STEVE:  Good point.  Good point.  And it's absolutely worth reminding people, is all we're talking about is tracking.  We're talking about some site knowing that they saw you, you uniquely you, a week ago.  And maybe not who you are, but just same entity came over and visited the site.  Which many people kind of shrug off.  It's like, eh, I don't care. 



LEO:  Well, no.  In fact, it's kind of functional for a lot of sites.  That's why persistence...



STEVE:  It can be very useful.



LEO:  I mean, right from day one Netscape created cookies.  They called them "persistent client-side state information."  "Cookies" is probably a little bit more colloquial.  But persistence is something a browser wants.  It's convenient.



STEVE:  Certainly, yes, certainly within a browsing session, today you virtually need it.



LEO:  Would have to, yeah.



STEVE:  I mean, the whole concept of logging onto a site is one of establishing state and identity.  And now as you move through the site, and we think Amazon or eBay or MSN or Facebook...



LEO:  You wouldn't want to log into every page as you go.



STEVE:  No, you'd literally, well, it wouldn't work at all.  I mean, you couldn't do anything we use the web for now unless there was a way of you identifying yourself, even for that session, and then having that be sticky.  Because remember, each display of a web page and a query for the next web page, when you click a button or click a link, that's a whole separate transaction that isn't linked to your prior page unless - I guess the only way to do it would be to encode your identity in the URLs.  And that's...



LEO:  Right.  Yeah, that's even worse.



STEVE:  ...a nightmare.



LEO:  But so it's important.  People need to understand that.  And if you don't know how the structure of surfing works, you may not understand that each transaction is separate and unattached.  So you need something persistent across transactions, even within a single visit to a website.  Otherwise it's hideously inconvenient or unusable entirely.



STEVE:  And frankly, it is also useful to then be able to say, leave me logged in for today, for 24 hours.



LEO:  Right, or just remember my password.



STEVE:  Right.  And so you're able to...



LEO:  Or my email or something.



STEVE:  You're able to come back within a reasonable time and say, hey, it's still me, and without having to go through the burden of being logged in again.



LEO:  So some persistence is necessary.  Persistence in and of itself is not necessarily bad.



STEVE:  And so here is the problem.  We would like, in a properly working world, to give the power to the user, to say - for users to be able to say, I only want specific sites that I permit to track me.  And we don't have that today.



LEO:  Right, right.



STEVE:  That's what you'd like.  You'd like to say...



LEO:  And that's NoScript.  That's what NoScript does.  It says, "No scripts unless I say okay."



STEVE:  Right.



LEO:  But again, against this it's only partially effective.



STEVE:  Yeah.  And not enough.



LEO:  Yeah.  Very, oh, just fascinating.  I'm glad you decided to cover this.  Samy's got it all.  We've got links to everything.  Samy's got a discussion of it all, and you can go there, it's samy.pl.  He's a prolific son of a gun.  I mean, I'm looking at all his little projects.  He's a very busy guy.  I like his website, too.  It's like a Windows start page.  It's very clever.  Samy.pl.



Steve Gibson doesn't use so many scripts on his page.  So it doesn't look like a Windows start page.  If you go to GRC.com, you'll see what I mean.  But let me tell you, it's all there including SpinRite, the world's finest hard drive and maintenance utility; all of the great free programs Steve gives away; and, of course, this podcast, 16KB and 64KB versions available.  Full transcriptions and notes, as well.  And we do it, as well, because it's a TWiT podcast you'll find it at TWiT.tv/sn.  And you can watch live.  We record live every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC at live.twit.tv.



Next week, because Apple is having an event on a Wednesday, we're going to flip-flop with MacBreak Weekly.  So Security Now! will be Tuesday at 11:00 Pacific, 2:00 p.m. Eastern.  And MacBreak Weekly will be in this slot next week so that we can cover the live Apple announcement, whatever it might be.  Steve, great to talk to you.



STEVE:  Always, Leo, a pleasure.  Talk to you next week, on Tuesday.



LEO:  On Security Now!.  Bye bye.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#271

DATE:		October 21, 2010

TITLE:		Listener Feedback #103

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-271.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 271, recorded October 19, 2010:  Your questions, Steve's answers, #103.



It's time for Security Now!, the show that covers your security, your privacy online, protecting you from the bad guys that inhabit the Internet.  Here he is, the star, our security guru, Mr. Steve Gibson of GRC.com.  Good morning, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  Good to see you.  We've got a Q&A episode today, I think.



STEVE:  We do, #103.  And no updates, but lots of news.  And some great questions, lots of follow-up, actually, from things that have been on our listeners' minds sort of communally in the last couple weeks.  So we'll address those and have a nice conversation.



LEO:  You can always ask a question of Steve.  People want to know sometimes, why don't you take questions from the chatroom and stuff?  And some of our other shows do.  But I'll tell you, I'll speak for Steve because I know why - because Steve likes to prepare his answer.  He likes to make sure he's got it right.  He's an engineer, and he doesn't like to do what I do, and what some of our other hosts do, which is answer off the cuff.



STEVE:  Well...



LEO:  But you were doing it before the show today, which I was surprised.



STEVE:  Well, I mean, I can.  But there are questions, like we have several today, where I had to go do some research for it.  And so in order to provide a useful, detailed answer - which I love to do because, I mean, I'm learning, too, or I'm finding out things.  I learned about what Logitech is doing in detail for the encryption of their keyboards, which I just wouldn't be able to answer on the fly; but I'm going to explain exactly how it works because now I know everything about it.  So...



LEO:  Right.  Well, I think this, of all the shows we do, it's the most technical show.  And so, rightly so, you want to give technically complete and accurate answers.  And sometimes that does take a little prep.



STEVE:  Well, yeah.  And, look, someone could have said, well, what about LastPass?  And in fact I put off a LastPass episode until I could lay out a huge amount of time.  I have invested more in learning LastPass than I've done for a long time for the podcast.  But I was able, as a consequence, to really deliver a thorough review of exactly how it works, what the scripts do, blah blah blah.  I mean, so there's a ton of time I'm spending behind the scenes that, as you say, I hope it shows in the content.



LEO:  Absolutely.  Very valuable.  So you said there's lots of news.



STEVE:  Lots of news.  After a couple weeks of rock 'em sock 'em updates, the industry seems to have gotten that out of its system for now.  So nothing happened over on the update side.  Nothing at all of any particular note.



However, Microsoft, the senior program manager, Holly Stewart, made a posting on Microsoft's security blog saying - I think the title was, "Have you checked the Java?"  What they found in looking at the numbers - and we'll be talking about their numbers here a little bit later in news because their big half-yearly security intelligence report is now out for the first six months of 2010.  In looking at the numbers, they discovered a somewhat surprising leap in the amount of exploits and attacks against Java.



Now, not JavaScript, which of course is my favorite whipping-boy on this podcast, forever.  But the Sun/now-Oracle Java, which is a very nice late-model advanced language, which has a runtime engine which needs to be installed in a machine in order for it to operate - it doesn't produce native code, like not Intel instructions, but rather the Java language compiles to its own byte code, which is then interpreted by this interpreter.  And of course, as with anything really complicated, and convoluted to some degree, there are problems which surface over time with the details of the code.  Paraphrasing a little bit from SANS Security Newsletter about this, SANS wrote:



"Many of these vulnerabilities are created by flaws in the low-level implementation of the Java Runtime Environment [the so-called JRE].  Although Java is intended to be type safe" - meaning that it's intended to sort of protect you from these sorts of things, I mean, and some care was given to that - "low-level code sometimes writes user-defined strings [into] buffers, giving an attacker the opportunity to overwrite return addresses and execute [their own] code.  Vulnerabilities like these allow Java applets, which start without user interaction when a target navigates to a malicious site, to execute ... the permissions of the Java process running them.  Normally applets run with restricted privileges."



So the point is that this is - it's a variation on the same problem we have with JavaScripting, but the details are different.  You go to a site which is using Java as opposed to JavaScript.  It is still giving you an applet, a so-called Java applet, which then runs under the supervision of this runtime environment.  The concept is that that encapsulation, created by the runtime environment, would give you protection.  And it certainly gives you a lot of protection, but there's little mistakes in it.



Well, our friend Brian Krebs, who did the security column for the Washington Post for so long, has been following this.  And he noted recently that Java exploits, exactly what Microsoft's blog posting is talking about, now exceed Adobe-related exploits...



LEO:  Wow.



STEVE:  ...as an attacker's preferred method of breaking into PCs.  And Microsoft said that they had gone from hundreds of thousands per quarter, that is, in terms of exploits against vulnerabilities, to millions.  And we're talking, when you look at the exact numbers, more than six million.  So a real ramp-up.



LEO:  That's not individual exploits.  That's attacked PCs.



STEVE:  Correct.  Absolutely, yeah.



LEO:  Six million exploits would scare the hell out of me.



STEVE:  Yeah, well, we'd just unplug our machines at that point.



LEO:  Yeah, no kidding.



STEVE:  They'd be Swiss cheese.  And Brian believes, Brian Krebs believes he understands what the difference is.  What's happened is that Java has gotten onto the radar of those who make the exploit kits.  And so Java exploits have been moved into the exploit packs, which makes them, like, turnkey easy for malware authors to use.



LEO:  But here's the thing that baffles me.  Java was always pitched as secure because it has sandboxing.  And we had malicious applets, but they never could do very much.  Are these real exploits?



STEVE:  Yes.



LEO:  Like root exploits?



STEVE:  Yes, yes.  And that's the point is that it was pitched as secure.  As I said, this runtime environment provides some containment.  But if there's mistakes, then you lose containment.  And as we know, mistakes happen.  So there are some ways that it is possible for a user-provided string to be loaded into an unmanaged buffer, which can cause a buffer overrun.  And we know that once that happens, all bets are off.  So the problem is, there are mistakes.  Now, remember...



LEO:  Mistakes in the JVM.



STEVE:  Yes, yes.



LEO:  Okay.



STEVE:  Yes.  There are mistakes in the containment.  And last week Oracle, what was it, 29 security fixes in Java when they went to version 6, update number 21 or, no, 22 I think we're at now.  So here's the bottom line is you can look at, in your Add/Remove Programs, for Windows at least, Java will be there if it's installed.  It will tell you what version it is.  You want to make sure you're at update 22.  The question is, do you need it?  I don't have it installed on my main workstation here that I'm sitting in front of, that I use day and night for everything.



LEO:  Yeah.  There are very few things nowadays that use Java.  Used to be much more omnipresent.



STEVE:  Yes.  And so the danger is that it's sort of sitting there, really not being necessary, yet still representing an attack vector for people's machines.  If you don't know that you need it, I would just say remove it.  You can use Add/Remove Programs in Windows and just click on Remove, and it's gone.  And this ramping-up exploit vector is just eliminated from your system.



Now, in fairness, the attacks that are being made currently, that is, the known vulnerabilities that are being exploited, have all been patched.  So patching - well, as of last week.  So Oracle is trying to stay current and keep these things patched.  The bad guys are leveraging unpatched versions of Java to get into people's systems for drive-by exploits.  And we'll be talking about drive-bys here in a few minutes, extensively.  So it is the case that, if you know you need it, you can increase its rate of checking for updates.  By default, it only looks for updates once a month, on the 14th of the month.  You can change that to weekly or daily, if you like.  So there is a Java Updater which is configurable.  And Brian Krebs suggests, if you do need it, then there's really no - there's very little overhead with it checking more often.  And I would say that makes sense.  Just have it check more often.



LEO:  So, okay, good.  So it does auto update.



STEVE:  Yes.



LEO:  And it's part of Windows Update.



STEVE:  Well, and Brian's also - oh, no.  Java is independent from Windows.



LEO:  There isn't a Java Update in Windows Update?



STEVE:  No.  Microsoft sort of washed their hands of that.  And there was a big battle, remember, back in the early days, when Microsoft had their own?



LEO:  Oh, that's right, that's right, that's right.



STEVE:  And Sun said, no, no, no.  We're unhappy with you.



LEO:  So you have to make sure the Java Updater itself does the job.



STEVE:  Yes.  And Brian noted something that I had, too, which unfortunately we always note with a lot of these updaters.  Sometimes it just sort of doesn't.  There is a new one around, and for whatever reason it just didn't get the message somehow.  So if you want to make sure, you can look in Add/Remove Programs, make sure you're at 22 - version 6, update 22.  If not, then manually update.  You can go to Oracle's Sun site and update to update 22, which you definitely want to do, especially with this thing becoming as prevalent as it has.



Now, I was just talking about mistakes in containment.  Adobe Reader, the next version, apparently Reader 10 - I'm seeing it referred to as Reader X.  I won't call it "Reader X," as I was calling it "OS X" in the case of...



LEO:  I wish they'd just call it 10.



STEVE:  Yeah.



LEO:  C'mon, we're not Romans, for crying out loud.



STEVE:  Well, because it's 9 right now.  It's not VIII.  So...



LEO:  It's just fancy stupidity.



STEVE:  Or I guess it would be IX, wouldn't it, yeah.



LEO:  It's just ambiguity.  That's annoying.



STEVE:  Yeah.  So the big news - drum roll, please.  It's that Adobe's management have said that next month, coming in November, Reader will get sandboxing.



LEO:  Yay.



STEVE:  And it'll be on by default.  And they're saying, well, I mean, thank goodness.  And they're saying initially only write calls will be sandboxed.  Reads will come later.  Now, I say, well, this is all good because more is better.  But mark my words, here we are, middle of October.  It won't matter.



LEO:  Right.  Why not?  Why isn't that enough?



STEVE:  Well, it's better because it means that Adobe is focusing a lot of attention and resources on this.  If they're talking about it happening next month, it's something they've been working on for quite a while because it's not an easy thing to do, to go in and retrofit containment where there hasn't been containment.  The problem is, it won't be perfect.  They'll make mistakes.  Just as the Java Runtime Engine was designed from the beginning to be a contained environment, and it isn't.  It's got mistakes in it, flaws in its containment, which are now being exploited like crazy.



So Adobe's got problems with the quality of their code.  The policy that they're implementing of sandboxing is a good thing.  It represents progress.  It doesn't mean this is going to get solved.  So with any luck we'll be talking about Adobe less often.  Maybe the exploits will be less bad.  But...



LEO:  Less bad.



STEVE:  We couldn't be talking about them any more often than we are.



LEO:  Adobe Acrobat - less insecure.



STEVE:  Less horrible than it used to be.  Yeah, yeah.  Well, and speaking of the first half of 2010, Microsoft's Security Intelligence Report is out with a bunch of interesting numbers which are always sort of fun to actually see because we always use superlatives here.  It's nice to have some actual numbers.



LEO:  The most secure in the history of this week.



STEVE:  Yeah, exactly.  So Microsoft, with the combination of Microsoft Software Removal Tool, MSRT, and the Microsoft Security Essentials, MSE, which I'm now using on my various Windows machines...



LEO:  Oh, interesting.  Ah.



STEVE:  ...very happily.  Yeah, I mean, it's my antimalware.  I never was a third-party malware user.



LEO:  You've never, yeah, we've never used antiviruses; right?  I mean, it wasn't merely third party.  You just didn't use them.



STEVE:  Didn't use them at all.  But now that it's sort of there with Windows, and Microsoft's going to do it, it's like, okay, fine.  I'm happy to have it.  And it's what I'm recommending to other people, so I figure I should be using what I'm recommending, much as I'm using LastPass, for example.  So between those two tools, Microsoft has data from 450 million PCs that are running those things worldwide.



LEO:  Wow.



STEVE:  During the first half of 2010, nearly 1.9 million PCs were infected, some multiple times.  In fact, many multiple times.  Of all of the machines out there, the U.S. is number one in infections.



LEO:  Really.  Huh.



STEVE:  Their tools did 2.16 million bot cleanings, which is 5.2 per thousand runs of the MSRT.  So the Microsoft Software Removal Tool, which we've talked about, in fact last week I was even saying to people, just go to the Start Menu and just run it.  Type "MRT," no "S,", "MRT."  That pops it up, and you can just sort of do a manual deep scan of your system.  Microsoft runs it monthly after it updates itself with each month of security updates.  For every thousand runs of that MSRT, they find and remove 5.2.  I don't know how you can have 0.2.  I guess it's like...



LEO:  Well, there's a million runs, and so they got 52,000 or whatever.



STEVE:  ...0.3 kids or something.  Yeah, 5.2 bot cleanings in the U.S.



LEO:  That's not such a high rate.  That's less than 1 percent.



STEVE:  Yeah, exactly.  Yeah, it's, what, 0.52 percent.  So 0.52 percent.



LEO:  That's fairly low.  One half of one percent, that's not so bad.



STEVE:  But Leo, I mean, you know, bots are not good.



LEO:  Now, and by the way, this is just its kind of quick scan that it does.  There is a more thorough scan that it doesn't do automatically.



STEVE:  Correct.  So, yes, it's doing the quickie one, and it's during those quickie ones that it's finding these.  Although our listeners, who are doing it deeply, they probably get some credit for doing that, too, although they're hopefully not finding bots on their machine.



So Brazil, whereas the U.S. machines experienced 2.16 million bot cleanings in the first half of 2010, Brazil is in the second place with 511,000.  And also, interestingly, the same number of cleanings per thousand MSRTs, also exactly 5.2 cleanings of bots per thousand runs of the MSRT.  Korea is in number four place, and it's distinctive because it's got substantially more bots per thousand runs.  It's the highest of any region, 14.6 cleanings per thousand runs of the MSRT.  And so Microsoft reports that, overall, the infection rate of machines they're seeing is 1.4 percent.  So that is a high number.  I mean, 1.4 percent, that's a lot of machines.  14 machines out of every thousand have stuff on them.



Now, looking at demographics a bit, in terms of drive-by-download pages - drive-by downloads of course mean that you visit a website, and it infects you.  It does something to you, running JavaScript, typically, through whatever vector is available, JavaScript or Java, something executable, maybe an ActiveX control that gets downloaded.  It could be anything.  So what they're seeing is that in general on the 'Net, three out of every 10,000 pages is a drive-by download.  So three out of every 10,000 pages.



LEO:  Oh, that's a lot.



STEVE:  That's a lot when you consider all the good pages out there, yeah.  Three out of every 10,000.  And they're saying that out of every thousand search results pages that a search engine pulls up, two of those thousand search result pages will contain links to sites with drive-by downloads.  So two out of every thousand searches results in a page containing malicious sites.



LEO:  So it's worse if you're searching?  I don't understand.



STEVE:  Oh, they're saying that three out of every 10,000 web pages...



LEO:  In general.



STEVE:  ...in general will infect you.  But in terms of search results, which is different...



LEO:  Why would that turn up more bad things?



STEVE:  Which?



LEO:  Search results.  Why would searching...



STEVE:  Well, because they've got so many links on one page.



LEO:  Oh, yeah, yeah, yeah, okay.  



STEVE:  Yeah.  So the thing that...



LEO:  Okay.



STEVE:  Yeah, yeah.



LEO:  I thought, is there some magic thing happening?  Well, maybe they're targeting certain common searches.  It actually may be, I mean, how many links are there?  15?  They may be actually targeting common searches, which would raise the...



STEVE:  And that would make sense...



LEO:  ...the hit rate, yeah.



STEVE:  ...that they would try to do that.  Because of course that's the way people go to web pages now is they do a search, and they click on links.  So not surprisingly, in terms of top-level domains, the .cn domain, the China domain, has the most infected sites by domain name.  And get this, Leo - 5.8 percent.



LEO:  One in 20.  One in more - wow.



STEVE:  Yes.



LEO:  Now, how do you get a .cn?  Do you have to go through the Chinese registrar?  You do.



STEVE:  Exactly.  So their top...



LEO:  So these are Chinese sites.  These are not bad guys in Poland pretending to be Chinese.



STEVE:  Well, all we know is that their URLs end in .cn.  So they are the Chinese registrar.



LEO:  It's like, to get a .ca you have to verify that you're doing business in Canada or a Canadian.  I would bet you the Chinese registrar is at least as restrictive as the Canadian registrar.



STEVE:  I would imagine that's the case.



LEO:  And then so now you have to wonder, well, how many of these are rogue sites, and how many of them are government sites?



STEVE:  Well, and remember, we have talked in the past that China's not happy about the state of affairs, and that they've begun to make some noise about checking people's credentials more.  It had traditionally been incredibly easy to just register whatever you wanted to .cn.  And now they're saying, we want to see you.  We want to see who you are and check your identity.



LEO:  It's also conceivable that more Chinese machines are hacked because, if you hack into a web - it's very frequent, at least it has been in my experience, that sites that have malware on them aren't always - the owner isn't always the guy putting the malware on there.  They've found a security hole in the server, and then they put malware on all the sites.  And it may be that's what's going on.



STEVE:  Well, and we know that, for example, Network Solutions has had huge problems with that recently, where there was a mistake, and because Network Solutions has a big web hosting service, a huge number of their sites were being infected with malware through some exploits that people used.  So all of those would count as infected domains.  So, yes.  So 5.8 percent...



LEO:  That's appalling.  That's terrible.



STEVE:  ...of .cn domains have drive-by-download pages.  Second and third place are tied: .ru, Russia; and .de, Germany.



LEO:  Hmm, now that's a surprise.



STEVE:  Are both tied.  Yeah, you wouldn't expect Germany to be up there so high.  And they're both tied at 2.8 percent of their domains.  But still, that's a big number, yeah.  And interestingly, the U.K., the .uk top-level domain is in fourth place at 1.7 percent.



So, overall, when you stand back and look at the trends from '08, so where things were two years ago, the number of security breaches, that is, breaches reported by companies of people getting into their networks and stealing credit card information, stealing database data and so forth, that's - the good news is, that's been on a continual downward trend.  And it's about half, frankly, of where it was two years ago.  So there's really been progress made.  We've got laws now that require this to be reported.  So you'd almost expect to see some inflation of those numbers rather than deflation because we're being much more strict about requiring companies to acknowledge when information gets away from them.



But the good news is, I think it's probably because it has been - they have to report it, and the news agencies are covering breaches, that we are seeing that decrease.  So people are tightening up their networks; they're being better about educating their users; they're training their own IT security people more thoroughly.  So overall, for the last couple years, a downward trend.  And so we're seeing about half the breaches that we were before.



And also vulnerability counts have been falling, since actually now in this case Microsoft's tracking back since the second half of '06, so over the last four years, in general we're seeing the counts coming down in terms of number of vulnerabilities per half-year, which is how Microsoft aggregates these, that is generally coming down over time.  Not dramatically, but trending that way.



And the top threats - won't be a surprise to anybody listening to this podcast - are trojans and worms.  The top of the trojans and worm threats are, interestingly, gaming password stealers.  There's two in particular, a Win32/Taterf trojan and a Win32/Frethog, F-r-e-t-h-o-g, I guess it's Frethog.  Those two are at the top.  Those are the two most commonly detected malware families.  And they focus on stealing gaming passwords and sending online gaming passwords back to their trojan and worm masters.



And the number one way that malware gets money from people, and this also we've talked about many times, is so-called "scareware."  It's the stuff that pops up on your machine.  Typically you visit some website with scripting enabled.  It takes advantage of a scripting opportunity, or just using scripting on that site to pop up windows, which often is done with the script's permission, even with the browser's permission, to pop up a notice that says, oh, we've just detected malware on your machine.  Go here, click this in order to get taken to a site, and we'll tell you how you can clean things up.



Doing that, of course, typically actually is the event that installs something bad on your machine.  Up until that point, all you had was a scary notice.  Then ransomware takes over and requires that you give them some money in order to do something.  So anyway, that kind of scareware is the most common method that bad guys get money out of victims, is basically people say, I mean, they believe all that, and they enter their credit card information.  And, you know, god help them.



LEO:  It's a protection racket.  Without any protection.



STEVE:  Exactly.  And lastly, I mentioned a week or two ago that I had seen the blurb go by, but I hadn't been able to backtrack it afterwards, about the ongoing drama of the laptops-spying-on-students story.  Remember I said that I was sure I'd seen that someone had decided that there was no criminal intent.  And so the news is finally all in.  What happened was that a settlement was reached over on the civil side because there's the federal suit and the federal felony stuff, and civil complaint side.



So what happened was the federal authorities announced that they would not prosecute the administrators, and we're talking about the Lower Merion County Pennsylvania School District, which was caught sending out laptops with webcam spyware installed, ostensibly to allow the laptops to be recaptured or reclaimed if the students lost them.  But what was found was that people within that school district were turning on the webcams of non-stolen, non-misplaced, not-lost laptops, and basically spying on the kids.



So lawsuits were filed by the parents of the kids that had been spied on.  So the federal authorities, there's a Zane David Memeger, who's the United States Attorney for the Eastern District of Pennsylvania, said that they found no criminal intent in the alleged surveillance.  So that moved, essentially, the feds off the table; but that still left the civil suit and the need for a civil settlement.  Now, get this, Leo.  The school district has agreed to pay a total of $610,000 to make this go away, to settle the civil side.  Of the $610,000, the attorneys get $425,000 of that.



LEO:  Geez.  Well, that's normal, though.



STEVE:  I guess so.  And the students get the remaining $185,000.  So this would have been the plaintiff attorneys who were bringing the suit.  I'm sure the parents went to some attorneys and said, hey, we really don't have any money to pay you whatever it's going to cost to go sue the district, so how do you want to arrange this?  And the attorneys said, well, it looks like you're got a case.  We'll take it on contingency, and take a percentage, a heavy percentage, looks like two thirds, of whatever it is we're able to get for you.  And the parents at that point said fine, we accept that.  And to defend itself from the plaintiffs, the school district's insurer, a company called Graphic Arts, has agreed to pay the defense attorneys $1.2 million.



LEO:  I'm confused.  I thought they - oh, the - who got the money then?  I thought attorneys got money.



STEVE:  Oh, yeah.  All the attorneys made out pretty well on this.



LEO:  Yeah.



STEVE:  So the school district is insured against this.  So they've got some sort of, I don't know...



LEO:  No, that's normal, an umbrella insurance.  I have insurance, if you sued me.  I shouldn't have said that.  But no, that's normal.  You'd have...



STEVE:  We love you.  No one's going to sue you.



LEO:  You can have liability or, you know, you'd have definitive insurance.  And any business would.



STEVE:  Exactly.  So, I mean, I'm in a condo association.  Our association has insurance because some homeowners went off the deep end a few years ago.



LEO:  Right, it's normal.



STEVE:  And were pissed off.



LEO:  You've got to have an umbrella liability policy.  I'm sure even a school district would.



STEVE:  Yes, they do.  And I would imagine their rates have gone up recently.



LEO:  Oh, yeah.



STEVE:  So their insurer agreed to pay $1.2 million for the school's defense costs.



LEO:  Oh, I get it.  The defense cost more than the $425,000 they got from the settlement.



STEVE:  Yes, the whole extent...



LEO:  It cost 1.625 million.  Geez, Louise.



STEVE:  Yeah.



LEO:  You know, though - okay, fine.  This is nothing new.  We've seen this before.  It still bugs me a little bit that the court found there was no intent.  Because, I mean, we didn't see the evidence.  But the anecdotal evidence I heard sure sounded like there was intent.  Some of the quotes from the IT people...



STEVE:  It sounds wrong.  Yes.  There were 400 photos taken of the one student...



LEO:  That one boy, yeah.



STEVE:  Yeah, the one boy who was confronted by the school officials saying that he was popping pills, and it turned out it was Ike and Zike or...



LEO:  Ike and Mike's, yeah, it was candy.



STEVE:  Ike and Mike.



LEO:  And the thing is, the camera was supposed to be if the laptop was reported stolen.  So it seems to me there's intent.  If they're taking pictures of students, and they haul the student in, I think that's criminal intent.  I'm sorry.



STEVE:  And not just one.  Multiple students, also.



LEO:  And then there was - now, and again, maybe this wasn't entered into evidence.  But there was a transcript of comments on the web.  One of the IT people said it's really fun watching the kids.  So I'm - not criminal?  I guess it's not criminal.  It's offensive.



STEVE:  Yeah.  Well, the good news is there's been enough money rolling around in this, and enough headlines and press, that - I mean, what we would want is this never to happen again, anywhere.  And you have to imagine that any schools that are using, I mean, this was commercial software.  So you can imagine that the Lower Merion County Peninsula School District...



LEO:  They're not the only ones.



STEVE:  ...are not the only ones.



LEO:  Oh, no.



STEVE:  Yes, not the only ones.  So the good news is, I would imagine this will not happen again.  There's no excuse to happen again.



LEO:  So just to make it clear, there was a civil lawsuit.  That's where the settlement was.  The feds declined to criminally prosecute because they couldn't find that evidence of criminal intent.



STEVE:  Correct.



LEO:  Or, you know, it's very hard to prosecute government agencies.  It's certainly hard to sue them.  They may have decided that, even though there was some evidence, there wasn't sufficient evidence, something like that.  That happens all the time.



STEVE:  Yeah.



LEO:  Anyway, yeah, you're right.



STEVE:  Or maybe the evidence was tainted, I mean, who knows what was going on?



LEO:  It's hearsay.  You put it on the web, it's not real.  Anyway, I think the good news is you're exactly right, this ain't gonna happen again.  And, you know, my kid's school handed out laptops, MacBooks, with cameras on them.  And you'd better believe that immediately the question was raised, well, is there any software on there that could monitor it?



STEVE:  Yeah, and the first thing you want to do...



LEO:  And there isn't, by the way.



STEVE:  We've talked about this before.  Laptops really need to start installing...



LEO:  Shutters.



STEVE:  ...a physical shutter, a little slider.  I noted that there's laws which require sufficiently high-powered lasers to have a mechanical shutter.  Actually they require three things.  If your laser is above a certain number of milliwatts in its brightness, it has to have a lock and key, that is, an electrical key.  It has to have a mechanical shutter which physically blocks the aperture of the laser.  And when you turn it on, there has to be a delay of several seconds between the time you press the "on" switch and the beam actually begins.  So there's, like, three requirements for a sufficiently high-powered laser.  I know because I own one.  And I was curious about all of that rigmarole.  And sure enough.  So you can imagine that...



LEO:  Just out of curiosity.  You're not building a new...



STEVE:  No, no, no.  No.  No.  No animals are going to be...



LEO:  Which color is - did you get a green one or a...



STEVE:  Yeah, it's really very bright.



LEO:  They're really cool, yeah.  Yeah, Woz had a green one a couple of years ago...



STEVE:  I mean, this thing will pop balloons.  So you want to be careful with it.



LEO:  Ooh.  Where do you shop for something like that?



STEVE:  I don't remember where now.  But on the 'Net is my standard reply.



LEO:  So it's legal, but you have to have these restrictions, like a gun lock.



STEVE:  It's legal, and certainly you need to use it responsibly.  Because, I mean, if it'll pop a balloon, it'll burn your retina, too.  So you don't want - this is not a toy to mess around with.



LEO:  Geez.  Holy cow.



STEVE:  Yeah.  And I'm close to the Orange County Airport, too, so I can't even aim it out in the sky or anything.



LEO:  You shouldn't, rightly so.



STEVE:  I'd have satellites zooming in on me, I'm sure.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  Yeah.



LEO:  Did you get the 1W laser?



STEVE:  It's, yeah.  It's pretty bright.  Pretty good.  So on that note...



LEO:  Oh, man.



STEVE:  ...we have a nice SpinRite testimonial.  Last time Greg was the subject of compliments, and I had something about Sue this time that I thought I would share.  From a David Speigner, he spelled his name phonetically for me, it's S-p-e-i-g-n-e-r, Speigner.  He wrote, and he said - actually he wrote to Sue saying thanks for your assistance in completing my SpinRite order.  It's churning away and will not be ready for a while.  Would you please forward this to Mr. Gibson?  So he said, "Dear Mr. Gibson," and then he put (Steve).  It's like, yes, David, we're on a first-name basis.  It's quite fine.  He says, "I appreciate all your great efforts on security and Windows and Internet vulnerabilities over the past years.  I've used a lot of your freeware and tools, such as ShieldsUP!, OptOut, and many others.  I just recently used Securable.  Actually, Securable is our #1 freeware right now.



LEO:  Really.  What's that one do?



STEVE:  People are using it to see what capabilities their chips have for going to 64-bit Windows because it's just super secure and lightweight, and it shows you if your BIOS has virtualization locked on or off, whether you've got 32-bit or 64-bit, identifies your chip by name, like what type of chip it is.  And, yeah, people are getting a lot of use.  And the news of it is passed around the Internet.  It's like, oh, just go get Securable.  You don't have to install it, you just run it, like all of my stuff.  And it tells you good things about your processor.  So people are using it a lot for that.



Anyway, he says, "Thanks for all your great work and expertise.  I also very much enjoy Security Now! with yourself and Leo Laporte.  Now my SpinRite testimonial.  I just got off the phone with your helpful, knowledgeable, and nice sales/customer service lady," and that would be Sue.  He said, "Today I had my SpinRite moment - a major catastrophic hard drive failure caused by power outages and surges from a fast-moving lightning storm system here in the East, 70 mph winds from heavy thunderstorms, and the surge protector did not work."



LEO:  That's not unusual.  Lightning, I mean, imagine how many volts are coming through a lightning strike.



STEVE:  Yeah, yeah.



LEO:  That will jump over anything.



STEVE:  He says, "The drive was caught in an endless loop, and I knew there were disk errors from using other lame third-party utilities," he says, "three different ones.  My OS files were there, but my efforts to repair did not work.  One tool said I had 'disk errors,' and the restore points in XP Pro of course would not work.  The drive controller chip was possibly fried, as well, and my drive seemed toasted, as well.  Of course, I had an image that was about three weeks old, but the drive had the image on it in a different partition, and both were now unreadable.



"So I purchased SpinRite 6 after hearing about it frequently on the Security Now! podcast, after figuring it was my only option, as the malfunctioning disk could not be restored from my saved image or backup, and the reinstallation was also inaccessible, and I needed to get it working again so I could image or do a repair installation of the OS.



"I used your well-designed program to create a bootable SpinRite disk.  I started it up, after following the easy-to-follow instructions, and waited.  Well, 14 hours later, on a 320-gig drive, there were 12 recovered sectors.  And I was then able to boot and have the disk detected in another machine as my motherboard was RMA'd to Intel."  So it really did fry things on his machine.



LEO:  Yeah.  And that'll happen.



STEVE:  He said, "I did a repair installation, and the machine is back to normal with no files lost.  It boots fine, and SpinRite saved the day.  It was well worth the cost and time saved, easy to use, and after nearly 20 years of making systems, this was the first time I needed to use it.  But I know it will not be the last.  Thanks for a great and easy-to-use product.  David G. Speigner.



LEO:  That's what's neat about SpinRite is, yeah, you buy it, and you have it.



STEVE:  Forever.



LEO:  And you will absolutely use it again.



STEVE:  Forever.  Yup.



LEO:  Yeah.  It's just always going to be there.  Steve, I am ready, if you are.



STEVE:  Absolutely.



LEO:  We've got some questions for you, Steve.  Starting with Vegard in Norway, wondering about the security of Bluetooth keyboards.  We talked last time about wireless keyboards in general.  He says, Steve, what about the security on Apple's Bluetooth keyboard?  This is a very widely used keyboard now because it works with the iPad.  I've used it.  Isn't anything Bluetooth more secure than that simple 8-bit XOR that you were talking about with some of the other RF keyboards?



STEVE:  Yeah, I wanted to quickly calm everyone's nerves over the issue of keyboard security.  We have another question later on about Logitech wireless keyboards that I mentioned earlier in the show.  But, yes, anything Bluetooth is, well, okay.  Anything Bluetooth is way more secure than a simple 8-bit XOR, if for no other reason than almost nothing could be less secure than...



LEO:  Than 8-bit XOR.



STEVE:  ...than an 8-bit XOR.  I mean...



LEO:  It's not saying much, in other words.



STEVE:  Well, exactly.  So...



LEO:  But it does have the pairing and the authorization, I mean, it has some security model in it.



STEVE:  Oh, Bluetooth is good security, very good security. And in fact one of my - it's on my short list of future topics because a number of people have asked over the years.  And so we're going to absolutely do an entire Security Now! podcast on the technology of Bluetooth security, since Bluetooth is getting increasing use now all the time.  I also have one of those Bluetooth wireless keyboards.  It's great with the iPad, it just works beautifully, and I like the keyboard very much.  And so...



LEO:  Oh, it's beautiful.  It's small.  It's, yeah, it's very elegant.



STEVE:  Yeah.  I mean, so it just makes it - it pairs beautifully.  And there is absolutely no problem with using a Bluetooth keyboard from a security standpoint.  So I did want to let people know, it's not certainly the case that anything wireless is a problem.  It's just that first-generation sort of cheesy, very inexpensive wireless keyboard was found to be really insecure because, I mean, literally zero encryption, just flipping some bits that were always flipped the same way.  So very uninspired.



LEO:  Yeah.  And we hear about Bluetooth snarfing and stuff.  There are ways to hack Bluetooth.



STEVE:  Yes.  In fact I remember, Leo, that we discussed, in general we discussed the problem of leaving Bluetooth in discoverable mode.  We did a segment on your Screen Savers show up in Canada once, or Call For Help, I guess it was.  And just turning on Bluetooth in our laptop, we saw that everybody had left their phone that way.  Everybody's phone was discoverable.  There was, like, 12 of them or something.



LEO:  Wasn't that funny?  Yeah.



STEVE:  Yeah.  And so...



LEO:  But we learned our lesson, however, at that time.



STEVE:  Yes.  And that is the danger.  You do not want to leave your Bluetooth devices discoverable.  I've never understood why the user interface isn't set up so that it just flips it back off.



LEO:  It is now, I think, in almost every device I've ever seen.



STEVE:  Yes.  And I've really seen a change over the last few years where you manually make it discoverable, and then it takes responsibility itself for flipping it back off because that's how Paris Hilton loses her phone book and so forth.



LEO:  Oh, Paris has many ways to lose her phone book.  She's discovered every technique possible.  Al Murray, Gainesville, Florida wonders about Computrace's LoJack for laptop security.  We've seen a lot of ads for this.  Steve, I just bought and received a Dell notebook, noticed in the BIOS configuration it had a Computrace option that was not activated.  Seeking more information, I did a search and found it's a product from Absolute Software.  They also do the LoJack software.  I think they license the LoJack name because it's the same idea.  LoJack's for a car.



STEVE:  Right.



LEO:  I would really like your thoughts on using this product on my Netbook since we all know how easy it is to have a laptop or a Netbook lost or stolen.  Should I use Computrace or the LoJack?  Are they the same product?  By the way, I can't remember when I first bought SpinRite, but it has saved my bacon many, many times.  Love your podcast.  Thanks, Al.



STEVE:  Okay.  So in general I think it's a good idea.  I love the idea of this being in the BIOS because that moves it to a place where it's just not prone for deletion or discovery or removal.  What it does is it takes advantage of the increasing size and sophistication of contemporary BIOSes to actually build a network client into the laptop itself.  Meaning that, when the laptop is on, without, I mean, in an OS-independent fashion, I mean, you don't even have to have an operating system loaded because it's not using the OS at all, it's just using a block of code in the BIOS and the fact that the network adapter, whether WiFi or wired, is part of the hardware, so the BIOS knows how to talk to that hardware.  Again, it doesn't need drivers.  Drivers are used to interface the operating system to the hardware; but in the BIOS, the BIOS knows what it's got.



So Computrace has licensed to Dell their technology, and Dell builds it in, as do many Netbook and laptop makers, build it in as a feature which you can turn on.  Now, it's not free.  The whole deal is you need to subscribe to this.  And so I guess the issue of, is it worth it, should I turn it on, which Al is asking, is a function of your use of your laptop, your likelihood of it getting away from you, the possibility that it's got confidential data on it, the likelihood of recovery and so forth.  What it costs is $40 for a single year, or $90 for three years.



So what happens is, when your laptop is turned on, once a day - because again it also has access to the clock and calendar, so it knows how often it's being turned on, when it's being turned on, if it's already been turned on that day and so forth, it won't do it more than once a day.  When it's turned on and hasn't been for 24 hours, the laptop itself, separate from your operating system, is able to use your network adapters and contact Computrace.  It essentially sort of sends them a ping and identifies itself by serial number.  And this is something set up when you activate this feature in the laptop.  There's an account number and identity and so forth.



And so Computrace is receiving pings from all the laptops which have subscribed to their service all over the world.  Every day they're receiving these.  So if you lose your laptop, or your car is broken into and it's stolen, or you leave it in the airport, which is where most laptops get lost or misplaced or stolen, or you leave it in the seatback - I know, Leo, you've gone through many Kindles that way.



LEO:  Yes.  Yes.



STEVE:  So if one way or another it gets out of your control, and it doesn't look like it's going to come back, you the subscriber contact Computrace and say, hi, I'm Al Murray in Gainesville, Florida.  Here's my account number.  I need you to figure out what we should do.  So you give them your account number, and they now wait for your stolen laptop to be used by the bad guys, to be turned on, to be plugged in, to be whatever.  And as soon as that happens, if your laptop can reach the Internet, if it's near a WiFi or if it's plugged into the bad guys' hub, it reaches out, pings Computrace as it always does.  This time they're primed.  Computrace is able to tell the laptop immediately that it's been stolen, so the laptop knows that it's in, like, I've-been-stolen mode.



That does a couple things.  One thing it does is it increases its communications from once a day to every 15 minutes, so that they're able to track it.  It also is able to use standard - we've talked about this several times - the amazing geolocation of WiFi to figure out where it's located.  So it's able to report its physical location to Computrace.  And of course they get the IP address that it's pinging them from.  So they have the IP address.  They have the WiFi-based geolocation data.  And Computrace is then able to deal with the local (to the laptop), local law enforcement authorities and set about seeing if they're able to get it back.



Now, the other thing that Al could ask Computrace to do, if he is more concerned about his information, depending upon what kind of information he's got on the laptop, he can ask Computrace to lock down the laptop and/or wipe the hard drive.  So that can all be done remotely at his desire, based on the conditions of how it got lost and how long it's been gone and so forth.  So the laptop can lock itself down and refuse to function, simply putting up a notice of some sort saying I've been stolen, you're bad guys, you're not going to get access to me, sorry.  And so for 40 bucks a year, 90 bucks for three years, depending upon your use of the laptop, sounds like it might be useful.



LEO:  There's a program for Macintosh called Undercover that's very similar, but it uses some other techniques.  It uses Skyhook to locate itself, but it also knows all the IP addresses for Apple stores.  And since people often bring their stolen laptops, I guess, to Apple stores, it immediately goes, I know where I am.



STEVE:  Interesting.  Interesting.



LEO:  It sends pictures from the camera of the person who stole your Mac.



STEVE:  Oh, that's a good one, too.



LEO:  Yeah.  Every eight minutes.  And then, if you can't get it back, it simu- I love this.  It simulates hardware failure by making the screen gradually darken to unusable, and hoping that the thief will then bring it somewhere...



STEVE:  Toss it out.



LEO:  Yeah, toss it out.  It also does - you know, iPhones now, and iPads, have the Find My iPhone, and I see Android phones do this, too, with Lookout.  They scream if they're lost.



STEVE:  I've been stolen, agh.



LEO:  I've been stolen.  Or you can find it, if you dropped it, you left it in a seat cushion, or you left it in a restaurant, you can have it scream.  It's interesting, I mean, people lose these portable devices so often that it's not surprising there are many solutions now for this.



Question 3, from Krister Jonsson - we've got a lot of Scandinavian listeners - in Lycksele, Sweden, wonders about anonymous web surveys.  Hello, I've been asked to fill out surveys and questionnaires at work.  The surveys are supposed to be anonymous, but quite often I get a link containing a unique ID so that the person who made the survey can see who finished the survey and who hasn't done it yet.  I always ask, how can I trust that the survey really is anonymous, and so far the answers I get are along the lines, well, yeah, you can have a unique ID.  That's so I know if I you fill out the survey.  But I can't connect that ID to you.  Of course they could have a list with all the IDs.  And they know who got what ID, and it wouldn't be too hard for them to store the IDs with the answers.



To me this feels like playing cards with somebody saying, "Trust me, I don't cheat," while they leave the room to supposedly shuffle the cards.  I like that.  Is there a way to design a web survey so that respondents can trust the system, while at the same time those offering the survey and wanting the results can know who has answered or not?  This actually ties to something The Wall Street Journal has accused Facebook of doing, or actually Facebook third-party game and applications are doing.  They also send, need a unique ID of some kind, and often send the Facebook userID, which can then be used to scrape public information from the page.  The Journal considered that a privacy violation.  You know, it's public, it only scrapes the public information, so I don't know if that's as bad as it sounds.  A lot of pages do this.  This is not unusual; right?



STEVE:  Well, and I thought about this question.



LEO:  Interesting problem.



STEVE:  Yeah.  And the problem is, if you don't trust the survey-taking system - so it sounds like, for example, this is at work.  So management is saying, okay, all you minions, we want to know what you really think.  And we're going to help you to tell us what you really think by making this anonymous.  And the minions are suspicious, of course, saying, well, but if I tell you what I really think, and you know it's me, and I tell you that you have bad breath, then you might hold it against me when it comes for my next job review or whatever.



So you can imagine, you can see that this sounds like it's a potentially adversarial situation where management really does probably want to know what the employees really think.  The employees probably really want to tell management what they really think.  But the anonymity barrier and this lack of trust in the survey system is preventing both sides from getting what they want.



So the only thing I could think of, and I pondered this for a while, is if, first of all, if people could approach a computer without having to identify themselves, that is, not log on because obviously then they know who they are.  If they could, like, use any computer, or like say it was in the coffee room or something, so it was like it was there to be anonymous.  And they fill out the survey, and then they receive some sort of a unique token, like write the following thing down, these numbers and digits.  And that's to prove that you filled it out.



Okay, now we still have the problem that that is tied to them, to their answers.  So the only thing I could think was that, I mean, and this is annoying.  But if everyone really wants anonymity, if management really wants the truth, and the employees really want to be able to tell the truth without being identified, is everybody then who says they filled out the questionnaire writes down these tokens, and they all throw them in a hat and scramble them.  So that process disassociates the people with the tokens.  Management is able to say, okay, we know everybody who threw the tokens in the hat.  And we know that we have the same number of tokens as we have people.  And all the tokens are valid.  So we know that everybody answered the questionnaire.



LEO:  That's a good idea.



STEVE:  So we don't, I mean, there has to be some decoupling somehow between answering the questionnaire, I mean, if you really don't...



LEO:  But you wouldn't...



STEVE:  If you don't...



LEO:  You would only know somebody didn't answer it.  You wouldn't know who.



STEVE:  Correct.  And that's the problem.  And but that's the benefit is - so you would know that someone didn't answer.  But you couldn't know who.  But if you had, if everyone said I answered, and they threw their little tokens in the hat, then you scrambled them up, and you saw that the right number of people...



LEO:  Answered them, yeah...



STEVE:  ...answered them, then you wouldn't know who was associated with what.  You would only know that, yes, that everyone had taken the questionnaire.  I mean, it really is a problem to disconnect that kind of verification from the questionnaire in a system you don't trust because that's the problem is we're assuming that this is not an anonymous system.  I mean, if the software were designed correctly, absolutely, it would be possible to give someone a token which is completely disconnected from who they are.  But that would require that the employees being given the questionnaire trust the management not to want to try to figure out who they are.  I would suspect it's in management's best interest not to know so that they get the truth from the employees.  But again, if there isn't that trust, throwing the tokens in a hat and scrambling them up, it says, okay, now I don't have to trust you.  We just know that the right number of people did answer the question.



LEO:  You'd get that information if you just look at how many people answered.



STEVE:  Right.  Yeah, very good point.



LEO:  It's not going to get you any farther than you are, really.  It's an interesting question.  Somebody in the chatroom said, well, I have the same problem when I'm told this is an anonymous phone survey.  But they've got my number.  It's not really anonymous.



STEVE:  Right.



LEO:  So Krister, there is no answer for you.  And if you're going to answer surveys, you're going to have to assume that it's not necessarily anonymous.



STEVE:  Well, and again, web-based is a problem because it's online.  If you print the survey out...



LEO:  Then it's anonymous, yeah.



STEVE:  ...and then fill it out with your other hand, so even your handwriting is wacky, then put all those in a hat and scramble them up, then it's anonymous.



LEO:  Right.  Yeah, the problem is the web.  And this was kind of the response to the Facebook issue is you're not anonymous on the web.  All websites know who you are.  They know your IP address.  So you're fundamentally not anonymous.



STEVE:  No.  And last week's episode was the Evercookie, so...



LEO:  Right, you could even get worse.



STEVE:  ...it's hard to shake this stuff off.



LEO:  Scot in Seattle wonders about the security of his Windows Gadgets.  Is there any danger, Steve, with Windows Desktop Gadgets?  Those are the things, if you use Windows Vista or Windows 7, they're the little doohickeys you could put on the screen.  I use a clock, a CPU monitor, weather, that kind of thing.  I see a ton of them listed on the Microsoft website.  Some are from Microsoft, but most are not written by real companies like Amazon or Google.  They're just individuals.  Is it dangerous to download and use a Desktop Gadget written by someone you don't know and not by an established company that signs their gadgets?  Scot in Seattle.  Yeah, I'm guilty of that.  I download third-party - I download them from Microsoft.  But I don't know how much vetting is done, and I don't even know how secure the gadget model is.  Have you looked into that?



STEVE:  Yeah, I have, actually.  And it's not.



LEO:  Oh, okay.  There we go.



STEVE:  Not secure.  It's just the same as running...



LEO:  It's JavaScript; right?



STEVE:  It's JavaScript and XML and CSS.  Basically it's sort of web-ized gizmos.  And they're subject to all the same security problems as everything else.  Microsoft goes to some level of effort to try to educate the authors about checking the buffer bounds, making sure you use a specified character set, UTF-8, for example, I mean, they go to some lengths to try to help people write secure gadgets.  But we know how well that's going to work.



So the gadgets could be deliberately malicious, or they could unfortunately be flawed.  So if a gadget were very popular, for example some weather gadget, it might be possible to send it bad data which causes a buffer overflow in it, and would allow someone remote access to your machine.  So that kind of vulnerability exists in the Windows Gadget Desktop space just as it does in regular applications.  Unfortunately we're getting more gizmos, and they're vulnerable.



LEO:  And by extension, in case you're interested, on the Macintosh Yahoo! Widgets or the Macintosh Dashboard Widgets, they're also JavaScript, CSS, and XML.  They're all done the same way.  So they're exactly the same security issues.



STEVE:  They're modern.



LEO:  Yeah.  And I presume on the Mac side it's WebKit that renders that gadget.  I don't - I presume it's IE that renders the gadgets on the Windows.



STEVE:  Yup, exactly.



LEO:  Jason Crow in Rochester, Minnesota wonders about an Evercookie workaround.  If you listened to the last episode, you know about the Evercookie.  Question for you, Steve:  If I have an image of my OS partition - like a ghost - and I restore that image on a regular basis, say every three days or four days, does Evercookie have a way of working around the ghost and saving its supercookies?  Could Evercookie be storing information, let's say on somewhere not part of the image, on the boot partition or on a D: drive?  Do you think other tracking schemes could?  Thanks, Jason.  And I guess by extension Microsoft SteadyState or Faronics Deep Freeze.  These are all programs that restore your system to a previously known good state automatically.



STEVE:  Yes.  And so here's the problem.  We know what Evercookie is doing because it's open source, and freely available, and clearly documented.  So the author has said, here are all the things I'm doing.  And he sort of did it more as a capability demonstration, but just to show how sticky these things could be.  So it may not be that today it's looking around at other drive letters, other places to squirrel away its data.  But gee, that's a handy idea.  So tomorrow it certainly could be.



LEO:  Yeah, it's just a question of whoever maliciously implements it thinking of other ways to do it.



STEVE:  Yes, yeah.  The idea is, when you've got scripting on your system, anything that scripting can do can be done. 



LEO:  Yeah.



STEVE:  And that's all I have to say about that.



LEO:  That's all there is to say.  Yes, the answer is yes.



STEVE:  Yeah, it's bad.



LEO:  We've seen viruses that go into BIOS, into the CMOS nonvolatile memory of BIOS.  We've seen viruses that sit on master boot records.  They're always going to try to be somewhere that is not overwritten.



STEVE:  Yes.  The only thing, the only thing I can imagine that would really give containment, essentially, it would seem to me that, for example, VMware has that snapshotting feature where you're able to run an image, but snapshot it first, and save no changes.  If you were careful to circumscribe the environment, that is, not map external drives into that, not allow other things to have access, in a virtual machine you're always sort of starting with a generic system, that is, all of the VMs from VMware look like the same hardware.  They look like pretty much they're identical because the VM brings that characteristic with it.  It's masking all these details of the outside externalized system.  So that's a really good way of preventing tracking.



And if you set up that snapshot feature, then nothing that changes in the VM is kept.  It's very much, as Leo was saying, like SteadyState.  And then we talked about this before, but I'll remind our listeners because, I mean, there was a lot of concern raised about this, is booting a temporary desktop, booting one of the Linux boot CDs that fires a system up and gives you a desktop with Firefox on it...



LEO:  That would work.



STEVE:  That works.



LEO:  There's no way that could - because it doesn't reference anything in, you know, you'd have to get stuff in RAM.  I don't know how you'd do that.



STEVE:  Yeah.  Well, exactly.  And so it's going to clean out an area.  It's going to load into that.  You can surf in there.  And when you shut it down, again, so long as you don't deliberately penetrate the bounds of that, I mean, there are ways, like, to map external drives in and things.  But if you don't do that...



LEO:  Don't do that, yeah.



STEVE:  ...then you have an absolutely transient surfing experience.  And every time you boot it, it's going to start over, just like it did before.  And no cookie will be able to hold onto you.



LEO:  No cookie can survive.  Steven Musumeche, or something like that, in New Orleans...



STEVE:  Boy, you're good with those names, Leo.  That's swell.  I couldn't do better than that.



LEO:  You say that, but who knows?  It could be pronounced Sade, I don't know.  Musumeche, Musumeche in New Orleans wonders - I know how to say that, New Orleans - wonders about wireless keyboard encryption.  Steve, I use the Logitech K320 wireless keyboard.  They say it's not using 8-bit XORs, it's using AES-128.  What do you think?  That's pretty good.



STEVE:  So, yes.  I...



LEO:  I'll take that.



STEVE:  I decided there was a lot of concern, as I mentioned earlier, raised about the whole issue of wireless keyboards.  So I did some research, read some whitepapers and some security evaluations and so forth.  And the good news is Logitech got it 100 percent correct.  They did a beautiful job.  I sort of smiled when they were talking about how they don't bother encrypting the mouse because all it does is send relative movement.  And I thought, wow, why does that sound familiar?  That's exactly what we said last week.  There's no need to encrypt mice.  Keyboards, however, of course, is a different story.  And they handle that beautifully.  There's nonvolatile memory in the keyboard and in what they call their little unifying receiver.  This is Logitech's new technology.



LEO:  Oh, yeah, yeah.  I use that, yeah.  It's a little tiny dongle.



STEVE:  Yes, you and I have a lot of those because we love those little MX mice.



LEO:  Yup.



STEVE:  With the frictionless wheel.  I've got them in all my laptops.  So this is a little tiny receiver that just looks like a little bit of a head on top of a USB connector.  You stick it in your USB port of your laptop, and you just leave it alone, or your desktop or whatever.  And the idea, they call it a unifying receiver because one receiver is used for multiple devices.  Up to six can be paired with a single receiver.



LEO:  Now, it's not Bluetooth, is it.  It's some proprietary thing.



STEVE:  Yeah, it's 2.4GHz.



LEO:  Oh, interesting.



STEVE:  And they make the comment that 2.4GHz has a range of several tens of meters so encryption of keyboard strokes is very important.  So at the factory, nonvolatile memory in the keyboard and in the unifying receiver are synchronized with the same 128-bit symmetric key, which the AES algorithm uses to encrypt keystrokes.  So if you repair the keyboard, because for example you might pair it with a different receiver that hasn't seen that keyboard before, the pairing process does exactly the right thing.  There are pseudorandom number generators at each end.  They are able to...



LEO:  Really.



STEVE:  Oh, yeah.



LEO:  That's amazing.



STEVE:  They're able to establish a new key without it ever going over the wire, over the air, in the clear, in order to synchronize a new key that they agree upon on the fly.  That's written into nonvolatile RAM and kept there.



LEO:  That's mindboggling, that that little thing can do that.



STEVE:  Yes.  They did a beautiful job.



LEO:  Wow.  I guess if you could put it in a VeriSign card or a PayPal football, you could put it in a little dongle there.



STEVE:  Or, well, and I'm thinking of the YubiKey, too, that's like super thin and does all that same kind of stuff.



LEO:  Right, right.



STEVE:  So, yeah, this does...



LEO:  That's impressive.



STEVE:  It's really nice.  Very nice.  So I haven't looked at anybody else's.  But I know that the unifying receiver technology that Logitech has is doing this.  And it does say in the specs, just in the regular top-level specs, 128-bit AES encryption.  So that's the way they implemented it.  I would imagine anything that Logitech has done, even if it's not the K320 wireless keyboard, that also says that would be using the same technology, which means you can trust it.



LEO:  I am impressed.  And kudos to Logitech because they used XORing in some of their earlier stuff.



STEVE:  Yup.



LEO:  But they've obviously learned their lesson.  So you could use that with confidence.  Wow.  That's amazing.  David Eckard in Durham, North Carolina, wonders about IP space depletion.  And we ain't talkin' the Shuttle here.  He says, "Subject:  95% used up."  He said, according to this article, and he quotes a CNET article, IPv4 addresses are now all but 5 percent done.  And they're calling for an orderly move to IPv6.  This is something Vint Cerf, the father of the Internet, has been saying for a while.  Although he's been saying it for years, and it turned out it wasn't really a crisis until recently.



Our correspondent David says, I still say there hasn't been enough work done on the transition.  IPv4 devices like my iPod Touch simply can't go to an IPv6 website and vice versa.  This requires a translator computer.  Translator computers are still in the development stage, as can be seen by various articles.  We have seen Comcast in particular working on this very issue.  I also expect cell carriers to participate when those come available as 16 million class A addresses are simply NOT enough.  Can you talk about this?  What do you think?



STEVE:  Okay.  So if you haven't, Leo, click that link and look at the chart.  That CNET article has a very nice graph of where we stand and where we've been since the beginning of '06.  One way, okay, we know that IPv4 addresses are 32 bits long.  So, and we know that IP addresses are in the so-called "dotted quad" format.  192.168.0.1, for example, is one we've all seen for private IPs.  So the top, that first number is - it identifies a block of IPs where the other three numbers are sort of subsidiary to it.  So anything starting with a 4, for example, Level 3 owns all of the 4-dot space.  And, for example, 5-dot has been unallocated, and as far as I know it still is.  That was what the clever developer, Alex of Hamachi, was using because there were no five-dot IPs out on the public Internet.  It had never been allocated.



So to give our listeners a sense for where we are, at the beginning of '06 there still remained 62 unallocated, what's called a "slash eight network," meaning only the top, specifying just the top eight bits of the network address out of a total of 256 of them, which is how many combinations in a single byte.  62, even in '06, were still unallocated; so, what, just shy of one quarter of the entire Internet, because 64 is one quarter of 256 possibilities.  So 62 were unallocated in 2006.  One year later, that number had dropped to 49 in '07.  One year later, in '08, to 41.  In '09, to 32.  At the beginning of 2010, we were at 22.  Today we're at 12. 



LEO:  Wow.



STEVE:  So, yeah.



LEO:  That's a dramatic drop.



STEVE:  Yeah.  And so things like 5-dot will not be available for long.  In fact, my feeling is, my summation to sort of sum this up overall for David and our listeners, is I think 2011 is going to be very interesting.



LEO:  Interesting in not a good way.



STEVE:  Yeah.  I mean, at the rate it's been dropping, we burned up, between '08 and '09, we went from 41 to 32.  So that burned up nine.  From the beginning of '09 to '10, to 2010, we went from 32 to 22.  So we burned up 10 more.  Between 2010 and now we went from 22 to 12, meaning we burned up another 10 in less than a year.



LEO:  It's accelerating.



STEVE:  Yes.  It was nine for the prior year, 10 for the year after, and now we're already at 10, and we're not done with this year.  Which says, and this is what the predictions are, that before this time, before October is through of 2011, we're done.  We're out.



LEO:  But it sounds like, I mean, at least from our correspondent, we're not ready.  Are we not ready?



STEVE:  I completely agree.  We're not yet using IPv6.  My cable modem has an IPv4 address.  When I look in my iPad...



LEO:  And you know it is because it's four dotted quads; right?



STEVE:  Yes, exactly.  Now, and that's the difference.  IPv6 goes from 32 bits to 128 bits.  Now, again, we glibly talk about bits.  But remember that every single bit doubles the number.  So if we just went from 32 bits to 33 bits, if we just added one bit, that would double the number.  I mean, that would last a long time.  Well, they didn't just add one bit.  They went from 32 bits to 128.  They added 96 bits.



LEO:  So instead of...



STEVE:  96 doublings.



LEO:  Instead of 192.168.1.1, we're going to see 192.168.1.1.1.1.1?  Is it eight?



STEVE:  The new IP addresses are insane.  They're insanely long.  Now, what they did was they folded the IPv4 space, as you would expect, into the IPv6.  So IPv4, what we have now, 32 bits, it occupies one little infinitesimal microscopic nano-size corner of, I mean...



LEO:  Of the space, yeah.



STEVE:  ...everything we have now.  It's just - it's vanishingly small.  It disappears in the IPv6 space.  Which is fine, except that we're not really using IPv6 yet.  I mean, the specs are solid.  The hardware is there.  For example, XP, old XP that I'm still sitting in front of, it has an IPv6 TCP/IP stack.  You can literally, there's a command you can give to a command prompt that turns it on.  And then it works.  I mean, it's there.  But it's not turned on by default.



And when I go out with my iPad and look under network settings, when I'm hooked into some WiFi, I've been given an IPv4 address.  So, like, a public IPv4 address, meaning some public IP, not 192.168.something or other.  So what that says is that the world is still actually using IPv4 because no one wants to do anything until they absolutely have to.  Which is why...



LEO:  Well, we have to.



STEVE:  Which is why 2011 is going to be so interesting.



LEO:  So I'm looking at an IPv6 address.  First of all, it's in hex.



STEVE:  Yup.



LEO:  And instead of dotted quads, it's eight, dotted octos.



STEVE:  Yes.



LEO:  And it's colons, not dotted.  So it's four hex digits in eight groups of four.  So it is a - I guess it's a quad still.  But it's - so okay.  And that's huge.  I mean, if you just even look at it, it looks huge.



STEVE:  Oh, yeah.



LEO:  It's hex.



STEVE:  People had a hard time remembering IP addresses.  Well, you don't even try with this thing.



LEO:  Oh, you don't.  This looks like a MAC address times two, basically.



STEVE:  So the idea is this IPv6 space is so big, everybody who wants some can have it.  The problem is...



LEO:  You can have your own Class A address.



STEVE:  ...you can't do anything with it right now.



LEO:  Right.  Well, so are they going to go to universities, I mean, there are people who have Class A addresses that aren't using them.  Are they going to go to these guys who are, you know, there's the bandwidth hogs.  Now there's IP address hogs.  Are they going to go to them and say you've got to release them?



STEVE:  Yes.  Even four years ago, when I signed up for my - when I moved things away from Verio because Verio was shutting down their T1 business and I didn't want to move all my stuff to Cogent, and I tried XO for a while but I kind of got scared off, and I went to Level 3, just a big Tier 1 provider, I had to fill out an IP - they had a name for it.



LEO:  Justification form.



STEVE:  Yes, it was a justification.  It's like, prove to us why you need 16 IPs.  What are you going to do with them?  Justify your use of the space.  So already they were feeling jealous of their own space.  And I know that chunks are still available because Alex down at Sunbelt, he has a Class C.  So he's got a full block of 256 IPs.  But those are becoming hard to get because that's a chunk of space.  But as you say, Leo, there are old-time universities that, I mean, Stanford I think has two Class A networks, or no, Hewlett-Packard...



LEO:  HP has a ridiculous number of addresses.



STEVE:  Yes, because they were in very early.  And they said, oh, well, we'd like a chunk, please.  And so they got given a chunk.  Well, I'd be very surprised if they're actually needing and using those IPs.



And so, and here's the other thing, Leo.  Yes, it's the case that in theory the original concept of the Internet architects, and we're going to be discussing this in detail when we start in on our How the Internet and Networks Work series, which will be the next series we do, their original concept was every single endpoint on the 'Net would have its own dedicated IP.  And so you could get to any machine from any other with an IP.  Well, the fact is the world's changed.  People have networks at home that these gurus back then never imagined.  It's true, under IPv6 we could return to every single endpoint has its own IP.



LEO:  But there's no need.



STEVE:  Exactly.



LEO:  Because we have routers.



STEVE:  The fact is, yes, every single endpoint doesn't need its own IP.  And so universities, Hewlett-Packard, corporations, I mean, the fact is, I think what we're going to see is a scrambling towards NAT routing to a much greater degree.  The pressure to move to, I mean, ultimately we'll be on IPv6.  But when the screws get tightened, sometime around summer of 2010, people are going to have to justify their use of IP space.  And they're probably, I don't know if there's a provision for recovering IP space from someone who has it.  But...



LEO:  Well, they can say, look, be a good Internet citizen, HP.  Can you give up 10 of your 14 million IP addresses?  Although 10 million new addresses aren't going to really solve the problem.



STEVE:  See, and that's just it, is that everyone understands, ultimately we need to switch.  Or we really need to be a lot more aggressive about NAT routing.  I mean, the purists, they see red when we talk about NAT routing.  They're like, just get it done.  Just switch over.  The problem is, it's not easy.  I mean, I've got routers that are running IPv4.  And so, I mean, it's a huge amount of work to make this change.  I mean, it really, it changes the fundamental plumbing of the Internet in a way that it doesn't want to get changed.



LEO:  So we'd all have to get new routers.  Or our internet service providers would have to get new routers.  Who has to do this?



STEVE:  Our routers right now do not support IPv6.  So they need firmware updates, assuming that they can be updated.



LEO:  Probably can't.  I mean, I would imagine that you've got to assign a certain number of registers for the number.  That's really, that kind of thing is hard-wired in.



STEVE:  Yes.



LEO:  A 32-bit number is your IP address, that's hard-wired in.  To go to 128-bit, that's architecture.



STEVE:  It may very well be.  Sorry, you can no longer use your router.  You need to go get a new router.  That's a big deal.



LEO:  Now, somebody must be making routers with IPv6 compatibility.



STEVE:  Oh, yes.  And...



LEO:  So if you're buying a new router, you should make sure of that.



STEVE:  That would be a very good thing to check off.  Make sure you're not going to be obsoleted when the world actually does move, whenever that is.



LEO:  Oh, it's going to be ugly.



STEVE:  It's going to be fun.



LEO:  Ah, may you live in interesting times.



STEVE:  Yes.  I really do think we're going to see NAT happen big-time.  It's just it's the path of least resistance for quite a while.



LEO:  And is there a robust Dynamic DNS solution for people who want to run their own servers, but don't have dedicated IP addresses?



STEVE:  I mean, Dynamic DNS works.  And that really is the - that's the argument that is a good argument against NAT, is that NAT works as long as all you have is clients behind the NAT router.



LEO:  Servers want their own address.



STEVE:  Servers need a way, you need a way from outside uniquely accessing the machine behind the NAT.  And port mapping and things are kind of a kludge.  They're just - they're bad.



LEO:  Ken, did the new switch we just got, does that support - anything new, I would hope - of course these Linksys routers have become a commodity, these cheap, $30, $40 home routers, they're a commodity.  I wonder if they, you know, they're cranking them out at a rapid clip.



STEVE:  I do know that looking at the UI of mine, there's no sign of IPv6 support - none.



LEO:  And Alexandre Garcia in Portugal with our last question of the day, he says maybe the Evercookie is not so Evercookie, not so "ever."  Hi there, Steve and Leo.  I've been listening to Security Now! since Episode 1.  I want to thank you for all your efforts in explaining so well the problems with security in the computer world.  Regarding your last topic, the Evercookie, I just want to remind you that Sandboxie is perfect for people concerned with this kind of menace.  I've visited the site under a sandboxed instance of IE, and let it set the Evercookie.  This is Samy's site, samy.pl.  Then I've closed the browser and run it again under Sandboxie.  Sure enough, the site was able to set the Evercookie on my system, of course, inside the sandbox.  Then I've just flushed the sandbox, visited the site again, using the same IP.  The Evercookie site was no longer able to track me at all.  So it worked.



Sandboxie was able to prevent that the Evercookie could write into my "real" system anywhere.  And once again I was happy to be browsing under Sandboxie.  Of course if the Evercookie were to store at server side my IP, they could have regenerated the cookies.  But at least they weren't able to create permanent changes on my computer.  Sandboxie blocked them.  Keep up with the good work.  Alexandre in Portugal.



STEVE:  Yeah, I wanted to just add that Sandboxie, which we have done a podcast on in the past, and I'm very impressed with, I thought it was a nice data point that we had, which is the Evercookie does not currently penetrate the sandbox.  And given what I've seen, it's probably up there, not quite as robust as a full heavyweight VM, but so much more convenient because it's not a full heavyweight VM.  And remember, a VM requires that you give it a chunk of RAM to run another instance of your operating system from.  So it doesn't come at zero expense, whereas Sandboxie is way more economical.  And, I mean, it just sort of automatically sandboxes your browser.  So Sandboxie is a great solution.  And when you flush the sandbox, as Alexandre showed, the Evercookie is lost.  So that's great news.



LEO:  Yay.  Happy news.  Happy, happy, joy, joy.  Steve Gibson is at GRC.com.  That's where you should go to get, of course, SpinRite, the best hard-drive maintenance, the must-have hard drive maintenance utility and recovery utility.  GRC.com.  Somebody asked if it works with these new eight-bit sectors or something?



STEVE:  Oh, 4,096-byte sectors.



LEO:  Yeah.



STEVE:  Yes, it does.



LEO:  Because you use - anything that BIOS works with, you'll work with.



STEVE:  Right.  And those drives do a great job of looking like existing drives.  All existing software is compatible with them.  The idea was that drives had sectors divided up into 512 bytes, 4,096 bits per sector, with individual sector header information interleaved with every sector.  And the manufacturers realized, wait a minute, we're wasting a lot of space with overhead here.  We can cut down the per-sector overhead by making jumbo sectors.  And so that's just what they did.  They're 4,096-byte sectors instead of 4,096-bit sectors.  So many fewer physical sectors.  But they simulate the same 512-byte sort of subsectors, just by dividing the physical sectors up into smaller pieces.  So, yes, we're completely compatible.



LEO:  Yay.  And then you were saying that your most popular program now at GRC.com...



STEVE:  Securable.



LEO:  ...is Securable.  That's interesting.  That tells you how secure your hardware is.



STEVE:  Well, I designed it because it tells you how securable your hardware is.  That is, what features your hardware has.  But the world realized, hey, it's a simple, fast way of knowing if I've got a 64-bit-capable system.



LEO:  Right.



STEVE:  For, like, Vista 64 and so forth, or Win 7 64.



LEO:  I put Win 7 64 on my Mac Pro, runs beautifully.



STEVE:  Yeah.



LEO:  Although I think I'm right in saying this, I think Sandboxie will not work with 64-bit.



STEVE:  Yeah, I remember that was the case last time we talked about it, yes.



LEO:  I'll have to check.  Sometimes you move ahead too fast.  So get Securable.  That's free.  ShieldsUP!, all sorts of great stuff, free at GRC.com.  And you can get the show there, too:  GRC.com/securitynow, 16KB versions for the bandwidth-impaired, transcripts for those who like to read along, of course the full show notes.  We also have them at TWiT.tv/sn.  And I always put the show notes on the wiki.  I should mention that, wiki.twit.tv.  Most of our shows either have show notes where our hosts put them there, or our volunteers.  We have a lot of volunteers working on that wiki.  It's a media wiki, just like Wikipedia.  And so a lot of people know how to do that, and they keep that up to date.  And that's a really great resource, if you want more information, as well - wiki.twit.tv.



Let's see, what else?  If you want to watch us live, we do this show live normally, and we're doing it on Tuesday because tomorrow's a big announcement for Apple, but we do normally record Wednesday, the day before the show comes out, Wednesdays at 11:00 a.m. Pacific, 2:00 p.m. Eastern, 1800 UTC.  You can watch that live.twit.tv; chat with us at irc.twit.tv.  It's kind of fun to do it live.  But of course if you can't make the live broadcast, you can always download audio and video at TWiT.tv/sn.  And I would just subscribe.  That way you always have it.  Steve - oh, next week, do you know what you're going to talk about?  Or is this a surprise week?



STEVE:  Next week we're finally going to talk about "Benchmarking DNS," how to know how fast your DNS servers are.  It's been my sort of project for, boy, like a year and a half.  And I'm finally ready to take the covers off and show everybody what I've got.



LEO:  Yeah, because you wrote a DNS benchmark program, and you've been...



STEVE:  THE DNS benchmark, Leo.



LEO:  THE DNS.



STEVE:  THE.



LEO:  THE DNS benchmark program.  Good, that'll be fun.  That's next week.  If you have questions for Steve, we do that every odd episode now.  It's back to odd; right?  I can't even tell.  We're odd today, aren't we?



STEVE:  Oh, we're definitely odd.



LEO:  So go to GRC.com/feedback to leave questions for Steve, and we'll get to as many as we can.  And I think that's all I need to say.  But have a great week, and we'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



LEO:  Bye, Steve.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#272

DATE:		October 28, 2010

TITLE:		Firesheep

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-272.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 





DESCRIPTION:  After catching up with a very busy week of security-related news and events, Steve and Leo celebrate the game-changing creation and release of "Firesheep," an add-on for the Firefox web browser which makes online web  session hijacking as easy as it could possibly be.  This WILL change the world for the better.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 272, recorded October 27, 2010:  Firesheep.



It's time for Security Now!, the show that covers your security online.  And no man better prepared to do that, I think, than this man here, Steve Gibson.  He is the guy in charge at GRC, the Gibson Research Corporation, GRC.com.  He's the author of SpinRite, which is a fantastic hard drive utility, a must-have for anybody who has hard drives, but also of a host of free and useful security solutions at GRC.com.  And he's been doing this show nigh on, well, we're on our sixth year, almost five-plus years now.



STEVE GIBSON:  Well, I guess no one that you could get who's any better who you could get on short notice.  So, yeah.  I was available.



LEO:  Short notice?  We got you five years ago.  Hey, Steve.  How are you today?



STEVE:  Great, Leo.  We were - I promised last week that we were going to finally, I was going to finally be able to unveil a passion of mine for the last 18 months, the Benchmark, the DNS Benchmark that I have been working on.  And it got preempted, as things are wont to do on our podcast when something even more fun and sometimes fantastic comes along, as happened this week.



We need to talk about something which was a surprise to everybody at a security conference in San Diego this last Sunday, that took everyone by surprise, which is being downloaded at a frenetic pace.  300,000 copies of this little Firefox add-on was where the count was earlier this morning when I began putting my final notes together for this.  Last time I looked it was at 322,000.  So in the last couple hours another 22,000 copies have been downloaded.



This is going to - the reason I'm excited about it, the reason we're talking about it, the reason it's my favorite Firefox add-on ever, is that it's wild, and I think it will finally force change.  We've talked so often, I mean, till we're blue in our virtual faces, about the problem with open WiFi and the lack of SSL security and what it means that logon credentials in the form of cookies are hijackable.  Well, until now it's been arcane.  It's been difficult to do.  This thing, anyone can run, and it shows you everyone who's using social networking sites, Web 2.0 stuff, in the same hotspot where you are, and allows you to hijack their session, logging on as them with a single click.



LEO:  Wow.



STEVE:  So, yeah, it's big.



LEO:  Wow.  That's amazing.



STEVE:  Yeah, we've got lots to say about it, lots of news and updates, and a great podcast today.



LEO:  So let us start, I guess, with our security updates here.



STEVE:  Yeah.  A couple things.  Our listeners will probably - our listeners using Firefox may have noticed that their Firefox jumped up to 3.6.11, if they're on the 3.6 train, or 3.5.14.  It's interesting, I thought we had announced, because they had announced, that they were going to stop moving 3.5 forward.  But they keep doing that.  I guess they just haven't had the migration over to 3.6 series that they were hoping for.  So they have been continuing to fix 3.5 and moving that forward.  This was fixing a bunch of vulnerabilities, 12 in total, five of which were rated critical, remote, that is to say, remote code execution vulnerability.  And it affected Firefox, Thunderbird - both the 3.1 and the 3.0 train of Thunderbird - and SeaMonkey.  So pretty much across the board that's been fixed.



Now, unfortunately just two days ago they, that is, the Mozilla folks were informed of a new zero-day vulnerability, which we don't often see in Firefox, in Firefox itself.  Turns out that there's a mistake in Firefox's implementation of some aspects of JavaScript which were first seen being exploited on the Nobel Peace Prize website.  So people just...



LEO:  Whoa.



STEVE:  Yeah.  Innocent Firefox users who visited the Nobel Peace Prize website were getting malware installed into their machines if they were using XP.  The malware has been analyzed, and it looks like it's specific to the Firefox version.  So it figures out what version your Firefox is.  And this is because, when you go to the site, the bad guys have installed - probably using some CSS or cross-site scripting, XSS, something, some technology, maybe an SQL injection - they got their JavaScript onto the Nobel Peace Prize website.  So when that JavaScript runs, it checks the version of Firefox and then uses that with some version-specific exploits which Mozilla is now aware of, but for which there is as yet, while we're recording this, no fix, to install code on your machine.  But it also checks to make sure you're not using Vista or Windows 7, so it looks like it's XP specific.



Not much is known about it right now.  The problem is both in 3.5 and 3.6, and actually in 4, the as-yet-unreleased beta of Firefox, although you can't get exploited under 4.  What they're in the process of doing is fixing it very quickly.  I imagine maybe by the time our listeners hear this there may be a 3.6.12 and 3.5.15.  So my announcement of this just-updated Firefox may already be obsolete.  Mozilla's own site says the only thing they know to suggest people do is, not surprisingly, either disable JavaScript or use NoScript to run without scripting by default.  But again, had you gone to that site and needed scripting, then you would be in trouble if you turned it on.



Now, this is the only place it's been seen.  I saw some other reporting saying it is being used at other sites.  So, again, NoScript is your friend.  Run without scripting if possible.  Turn it on only for sites you trust.  And with any luck this will get fixed very quickly.  I mean, the Mozilla guys have known about it now for a couple days.  They know where the problem is.  They're fixing the code across their code base.  So the 4 version of Firefox will get fixed even though it's not vulnerable to the same attack.  So it'll get fixed as part of them fixing their major code base.



RealPlayer we haven't heard about for a long time...



LEO:  Because nobody uses it.



STEVE:  Exactly.  And I was going to say, my advice is much as it is with Shockwave, which is less needed.  Unless you know, unless you really know you need RealPlayer, because your corporate media is only in .RM format or something, now is a great time to remove it, rather than updating it, unless you know you need it.  They have released across-the-board patches for all of their various annoying versions of RealMedia.  They've got corporate and executive versions and other stuff.



There are seven remote-code exploits which they patch with this.  So you could either, if you know you need RealPlayer, definitely want to update yourself because here's the problem:  Even if you're not using it, if you installed it four years ago, and you haven't clicked on any RealMedia since then, it's still in your system, and it can be invoked when you go to a malicious website through JavaScript, which is the method of entry here.  So it's the kind of thing where, unless you really need it, it just represents a vulnerability which you don't need to have.  So just go to Add/Remove Programs in Windows or over on your Mac, and just get rid of this thing because it's doing nothing for you if you're not actively using it except creating a vulnerability that you could well live without at this point.  As you said, Leo, no one is using RealMedia anymore.  If I see something that I really want, and it's .RM...



LEO:  Which frequently happens with, like, older sites and stuff.  And it drives me crazy.



STEVE:  Too bad.  I'm not going to view that, whatever it is, because it's just not worth it.  It's a bad viewer.  And just a note that Google, very much under the radar as always, has continued to creep Chrome forward.  They fixed some more things.  We don't know what, but Google moved to v7.0.517.43.  So fixing things as they do, with their sort of low-drama, low-disclosure, continuous self-repairing on-the-fly security updating.



Adobe is in the doghouse yet again with a...



LEO:  It's hard to believe.



STEVE:  I know.  It's a big surprise.



LEO:  How could this happen?



STEVE:  I think we skipped them last week.



LEO:  One week off.



STEVE:  They got one week off, exactly.



LEO:  Geez, Louise.



STEVE:  They've got a zero-day vulnerability.  And the good news is it's in Shockwave Player.  Which, again, you probably can live without.  Once upon a time, if you were a Windows user who looked under Add/Remove Programs, the naming, that is, the nomenclature they used for describing Flash and Shockwave was confusing.  The good news is, they've simplified it.  If you look under Add/Remove Programs, it'll just say - the one you want is, and probably can't live without - I mean, I can't live without it even on my iPad, unfortunately, I'm forced to - is Adobe Flash Player 10.  That's what you'll see, Adobe Flash Player 10 plug-in and Adobe Flash Player 10 ActiveX or something.  That's what you need.



Anything that now says Shockwave is vulnerable to a zero-day problem.  There is no update for it.  So if you have to have Shockwave, then running with NoScript, again, scripting is the way all of these things get invoked.  So running with NoScript will provide you some protection until Adobe is able to catch up and fix it.  You can go, if you want to see whether it's installed, go to adobe.com/shockwave/welcome.  And that will - it'll show you what version you have, if it's installed, or try to give it to you if it's not.  Don't accept it, if you don't have it installed.  You'll just know if it doesn't show you what version you have that you're safe from it.  And you can also just go to Add/Remove Programs.



And again, it's one of those things like it's falling into disuse.  It's their sort of higher power authoring platform for really sort of heavyweight fancy stuff, sort of higher end above what Flash does.  Flash is generally, of course, what everyone is using to a much greater degree.  So again, very much like RealPlayer, Shockwave is aging and is falling into disuse.  And obviously here it's representing problems because it's creating vulnerabilities which, unless you need to have it installed, just get rid of it.



LEO:  You know what's funny, the new Apple little - the MacBook Airs, for the first time ever on a Mac, don't come with Flash.  And really the reason is probably just that, if they build it in, it'll be an old version.  And since there's so many updates these days they figure, well, if you need it, you'll just install it.  Some people are interpreting it as a backhanded slap at Adobe.



STEVE:  Or maybe a forehanded slap.  I mean...



LEO:  Well, but I also understand, okay, so they ship it with Flash on it.  Tomorrow Flash could - there could be a big security flaw, and it could be updated.  So wouldn't it be better just to let people install - and they do the same thing with Java, by the way, there's no Java installed on it - let people install it, the most up-to-date version?  I haven't installed it yet.



STEVE:  Well, and I was just going to mention that, speaking of Java, one of my notes here in news is that Apple has formally said they're going to stop independently supporting and providing Java in the future.



LEO:  Right.  They used to do their own JVM.  And so they're going to let Sun do it.  And why not?



STEVE:  Exactly.



LEO:  Why take responsibility, especially now that there have been problems?



STEVE:  Well, and they're going a little further.  They're saying that they're going to reject any apps written in Java in the future.



LEO:  Oh.  See, this bothers me.



STEVE:  Yeah, on their app store, if it's - this is going along with their same on the iPhone issue.  Remember Adobe tried to do the whole cross-platform app development thing; and Apple said, no, no, no, you've got to develop using our tools, not some third-party interpreter thing.  Their argument is that such apps that try to be cross-platform don't take advantage of specific features on that platform.  So Jobs is taking a very hard line on this.  And this is very much along the same lines.  Java itself falls under that same umbrella of being an interpreter.  And Apple is saying, no, we're not going to allow people to do less than really good apps, by their definition.  So, yes, so Java will not in the future be supported.  I guess, what, 10.7 will have it, but not the future?  Or does 10.7 not have it?



LEO:  I would guess it's not - because 10.7 is not out until next summer.  So I would guess it's 10.7.  But it doesn't come on these new Macs, either.  But that doesn't mean you don't get Java.  It means you could just install it yourself from Sun.



STEVE:  Right.  And what typically happens is you will install an application which was written in Java.  And so its installer will drag Java along behind it in order to create the platform that it needs for running.  I mean, no one just goes and gets it because they have nothing better to do that day.



LEO:  Actually, I went and got it, and that's because I wanted to do development for Android, which requires not only the JVM, but also the SDK.



STEVE:  But this is you, Leo.



LEO:  That's me.  That's a little unusual, I agree, yeah.



STEVE:  Okay.  So Wall Street Journal has for some time now been doing a series under the umbrella title, "What They Know."



LEO:  Oh [sighing].  Okay, go ahead.  I just had to breathe a sigh [sighing].  You've got to remember, they own - they're owned by News Corp., which owns MySpace.  And they never disclaim that.  I wish they would.



STEVE:  Yeah.  It's funny because they did mention in one of these stories that The New York Times owned one of the properties that was being hit upon here.  So in the latest story on tracking, the Wall Street story begins: "In the weeks before the New Hampshire primary last month, Linda Twombly of Nashua [New Hampshire] said she was peppered with online ads for Republican Senate-hopeful Jim Bender.  It was no accident.  An online tracking company called RapLeaf, Inc. had correctly identified her as a conservative who is interested in Republican politics, has an interest in the Bible, and contributes to political and environmental causes.  Mrs. Twombly's profile is part of RapLeaf's rich trove of data, garnered from a variety of sources, and which both political parties have tapped [in the past].  RapLeaf knows even more about Mrs. Twombly and millions of other Americans [including] their real names and email addresses."



LEO:  And where does it get this information?



STEVE:  Uh-huh.  It turns out that they do deals with companies which use email addresses as part of their sign-on, logon user IDs.  So when you sign onto one of these sites, RapLeaf - and it's funny, I've been thinking of them as RapeLeaf, and I have to keep reminding myself, Rap, Steve, Rap.



LEO:  It might be appropriate, yeah.



STEVE:  Yeah.  RapLeaf has a deal with them where they will disclose through a back channel connection your email address and the cookies that you're using with that site, whereupon RapLeaf installs their own tracking cookies that are synchronized, and now they have your email address.  They also, of course, have what other personal information that site has about you, including perhaps your real name, if you identified yourself at some point to that site.  So they are, I mean, this is what we knew was going on.  We've talked about it before.  It's finally getting some top-of-the-fold press now, which is I think all for the best because people have to understand what's going on.



LEO:  But the thing to underscore is in almost, in fact, as far as I know, in every case this is material that they've publicly volunteered; and, for instance, a lot of this is gleaned from Facebook, which is why I brought up MySpace.  It's from stuff that's public on Facebook.  So...



STEVE:  Well, although what it turns out is, and this was another story under the same umbrella, it turns out that the top 10 Facebook apps, even against the privacy settings that the user has set, a user on Facebook who is using maximum privacy everywhere, the top 10 Facebook apps - unfortunately, Leo, Farmville is among them - is sending...



LEO:  Don't look at me, I don't play Farmville.



STEVE:  Oh, I thought...



LEO:  No, I gave up Farmville literally a year ago.  It was driving me crazy.



STEVE:  What was that thing you played?



LEO:  I play We Rule.  That's not Facebook and Farmville.  That's a standalone app on the iPad.



STEVE:  Okay, but what was the thing you were playing, went nuts over with the iPad?



LEO:  Yeah, that's We Rule.  I don't play Farmville.



STEVE:  Oh, okay.



LEO:  In fact, I don't actually use apps on Facebook for this reason.  But the point is, and I think the Journal actually was disingenuous on this, they did, against Facebook's own policy, reveal the userID in some cases.



STEVE:  Correct.



LEO:  Which can then be tracked to the user.  But only information that is public, that is set to "public," can then be viewed.  So this isn't information that isn't already available to anybody who just goes and searches for you on Facebook.



STEVE:  Okay.



LEO:  That's the point.



STEVE:  So using your userID, you're able to get the person's Facebook name.



LEO:  Right, which you could find by a search, as well.



STEVE:  But even - and also their friends?  Because...



LEO:  No, that is something that is leaked by apps, and that I think is a big problem.  And I don't think that's against the rules.  I think that that's something that apps do do, all the time.



STEVE:  Okay.  So RapLeaf declined to disclose who they're working with, citing NDAs.



LEO:  Guarantee you it's Facebook.



STEVE:  Exactly.  Nondisclosures.  But The Wall Street Journal found sites installing RapLeaf cookies, including About.com, Pingg.com, TwitPic and Plixi and Flixster, Tester-Rewards.  And then both apps on Facebook and MySpace are hosting RapLeaf cookies, essentially performing this kind of aggregation.  And to give our listeners a sense for what this means, The Wall Street Journal reported, saying:



"The Journal decoded RapLeaf's information on [some random guy named] Gordon McCormack, Jr., a 52-year-old who lives in Ashland, New Hampshire.  RapLeaf correctly identified Mr. McCormack's income range, [the] number of cars [he owns], his interests in gardening and the Beatles, and his interest in playing the online game Mafia Wars, among other topics.  Mr. McCormack says he plays Mafia Wars almost every day before going to bed.  RapLeaf also identified Mr. McCormack as someone with an interest in online personals.  He says he isn't currently [doing] online dating, but might have a couple of profiles 'lurking out on the Internet.'"



LEO:  All right, okay.



STEVE:  "When Mrs. Twombly, a New Hampshire Republican, registered at Pingg.com using her email address, RapLeaf matched her to dozens of 'segments' [as they call them], according to a Journal analysis of the computer code transmitted while she was on the site.  The Journal was able to decode 26 of the segments, including her income range and age range and the fact that she is interested in the Bible and in cooking, crafts, rural farming, and wildlife.  Mrs. Twombly says all the decoded segments describe her accurately.  In Mrs. Twombly's case, RapLeaf transmitted data about her to at least 23 [other] data and advertising companies after she logged onto Pingg, according to the analysis of the computer code.  Twenty-two companies, including Google's Invite Media, confirmed receiving data from RapLeaf.  RapLeaf declined to comment on its relationships with the companies."  And then I did a little poking around RapLeaf.  And of course there is an opt-out page.  You have to create an account with them.



LEO:  Oh, great, and give them all the information, yeah, okay.



STEVE:  And give them your information, including your email address, in order to opt out.  And it's like, okay, this seems annoying.  And due to all the attention that this company has received, thanks to The Wall Street Journal's analysis, there's a link on the front page, not surprisingly, www.rapleaf.com, to a blog posting from their CEO that starts out:  "There has been a lot of press recently about RapLeaf's efforts to personalize experiences for consumers.  The following are some thoughts by RapLeaf's CEO, Auren Hoffman."  Anyway, I loved the - and they're big on, well, we're trying to personalize your web experience.



LEO:  Yeah, here's the value, right.



STEVE:  Yeah, and here's all the money we're making by helping you doing that.



LEO:  A couple of things we should point out.  First of all, this kind of information, I remember doing a radio show with a company, I can't remember its name, 20 years ago, where if I gave you my zip code, they'd know what magazines I subscribed to, what car, because...



STEVE:  Yeah, probably DoubleClick, Leo.



LEO:  Yeah, a lot of this - well, no.  It was pre-Internet.



STEVE:  Pre-Internet.



LEO:  Yeah, a lot of this stuff has been available and known to marketers for decades, literally for decades.  The other side of this is, I guarantee you this guy, for instance, all of this stuff is public stuff that he's put publicly on the Internet.



STEVE:  Right.



LEO:  So I guess it's a good word of warning to us, if you don't want people to know this stuff, they are collecting it.  I'm not sure that they're doing it in a nefarious way.  They're just - they're using databases to aggregate information that we're putting out there.



STEVE:  Yeah.  And so the takeaway, in the case of Mrs. Twombly, she was unhappy when she found out what was being done, and started blocking cookies, and commented that some sites didn't work as well as they used to.  But she was unnerved.



LEO:  It ain't cookies, lady.  It's your - if you have a Facebook profile that reveals all this stuff, well, you shouldn't be surprised that somebody else knows it.  Anyway...



STEVE:  Yup.



LEO:  Anyway.  Sorry.



STEVE:  SANS, the very good, the excellent cybersecurity outfit, in their most recent newsletter they had a quote from a recent RSA Europe conference where our Homeland Security secretary Michael Chertoff said something that I found a little bit disturbing, I wanted to share with our listeners.  Quoting from the SANS newsletter:



"At the recent RSA Europe conference held in London, former U.S. Homeland Security Secretary Michael Chertoff has called on countries to develop doctrines to deal with cyber warfare in the same way Cold War doctrines were developed for nuclear conflict.  He told delegates at the conference that over 100 countries are now actively involved in cyber espionage and cyber attacks, and that clear rules of engagement need to be defined.



"While stating that countries should be able to respond to cyber attacks 'with overwhelming force,' he added countries need not 'respond to virtual attacks with real attacks, but I do think it's important to define when and how it might be appropriate to respond.  Everyone needs to understand the rules of the game.'  Acknowledging that attribution of attacks is difficult, Mr. Chertoff posited that countries that are victims of persistent attacks against their critical infrastructure should be permitted to incapacitate the platform used as the source of the attack, regardless of who is controlling the attack."  Which really makes me uncomfortable, Leo.



LEO:  Yeah, I'm with you.



STEVE:  Yeah.  So he's saying that Internet attribution is a problem, which we understand, that is to say, the fact that attacks are coming from IP addresses in China, as we well know on this podcast, in no way means that this has anything to do with China, only that a whole bunch of their machines have had zombies installed unwittingly, and that those machines are being used as the attack platform.



LEO:  So they should be able to take them out with a Predator drone?



STEVE:  And Chertoff is saying at some point this stuff does need to cross from the virtual world into the real world.



LEO:  This is saber-rattling.  I don't know if this is...



STEVE:  I know.  Just disturbing, that there's this - and I have to say, though, I saw another note that the U.K. was finally beginning to allocate serious money for cyber warfare, cyber defense initiatives.  The feeling in general is, I mean, and I still feel like I'm a little caught up in a little bit of a sci-fi world here; but, I mean, it's becoming very real as we talk about, for example, trojans that are able to infiltrate nuclear reactor sites.  It's really clear that, I mean, look at all the trouble people have keeping this stuff off their own computers.  And we know that the government is no better at it than individual end users.



LEO:  Right, right.



STEVE:  I mean, there really is penetration being made into sensitive networks.



LEO:  I mean, you have to think, if they're going to start taking out these computers, that they're going to take out a lot of innocent people.



STEVE:  Yeah, that's frightening.



LEO:  People who are just zombied without their knowledge.



STEVE:  And France has passed and begun to enforce their newest anti-piracy law.  The acronym is HAPOPI, and they've hired a third-party company in order to enforce this because they're not the enforcers themselves.  The law is now in place that provides for enforcement.  So a third-party company has been hired to monitor popular downloading sites like eMule and BitTorrent, to capture the IPs of the users of the sites, to send those - and we're talking 125,000 a day is what they're ramping up to - send the captured IPs to the relevant ISPs to obtain the email addresses of the people who currently have those IPs and send them a first warning email which reads:  "Warning, your Internet connection has been used to commit acts, recognized by police authorities, which could be regarded as in breach of the law."



So the first email reminds users that they're legally responsible, regardless of who actually downloaded the film or song onto their machine.  And if there's another infraction within six months, offenders will receive a registered letter warning them to stop downloading.  Then a third offense can lead to legal proceedings and a one-year Internet connection blackout.  So France is the first big country to actively adopt a law and start enforcing it.  And a lot of other countries are watching to see how this goes.



LEO:  Yeah, and a lot of other countries are considering a similar law, so that's scary.



STEVE:  Yeah, exactly.  I had a friend, for errata, who suggested - he was using Safari's private browsing.  And  he sort of assumed that, when he turned on private browsing, he would suddenly go anonymous.



LEO:  No.



STEVE:  What he realized - exactly.  What he realized was that what it meant was that, while in private browsing, nothing that happened during that session of private browsing would be sticky.  Nothing would be, for example, written to disk.  But going into private browsing didn't immediately anonymize you from your non-private browsing session.  In fact, you brought all your cookies with you that you would have had before browsing.  It's just that anything that happened during that time was not saved.  And he said, "You know, Steve, it might be worth pointing that out to people who assumed that they were anonymous while using private browsing."  I thought, yeah, that's a really good point.  Ought to mention that.



And then also in errata, we were talking about IP space depletion as probably being next year's recurring theme and news.  Ars Technica carried an interesting story where they mentioned that one of the major /8 networks, in this case the 45 network, meaning all 16-plus million IPs beginning with 45-dot, so 45.anything, they were previously all allocated to Interop.  And Interop gave back to ARIN 99 percent of them...



LEO:  Oh, good.



STEVE:  ...just now.



LEO:  Just as we were asking, couldn't they just ask for these back?



STEVE:  Yes.  And so it was - so there is no provision for ARIN to, like, force unused IPs back.  Apparently, behind the scenes, ARIN is going around to people who have huge allocations from the original allocation of the first digit of the IP, and saying, hey, you know, you're not really using all 16 million of those, and...



LEO:  Give us a few back, just a few.



STEVE:  ...we'd really like to have some.  Now, there was an interesting chart, I provided the link to you in our notes, Leo.  



http://arstechnica.com/business/news/2010/10/embargoed-interop-gives-back-a-months-worth-

of-ipv4-addresses.ars



On that page is a really nice map which shows the allocated networks, and those which are still not allocated.  So the free ones are 5, 23, 37, 39, 100, 102, 103, 104, 105, 106...



LEO:  It looks like a bingo chart.



STEVE:  It does.  179 and 185.



LEO:  And then there's a bunch of unusable ones, 127 and 224 and up.



STEVE:  Yup, 224 and up.



LEO:  And of course 10-dot, yeah.



STEVE:  And of course 10 is unusable, that's the whole 10-dot RFC 1918 reserve network.  And interestingly, despite Interop, I mean, Interop doing this was very nice.  What it bought us was one month.  So giving back 99 percent of a full /8 network bought us a month.  So we're in trouble.



LEO:  So there you go.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  Yeah.  And I have a very short note from a happy user of SpinRite that I wanted to share, Dianne Dunnett, who wrote - and just very quickly, she said - she called it "GRC Post Sales Statement."  She said, "GRC, I've used my copy of SpinRite 6 to correct two of my home computers, one that would not load into Windows after the Windows scrolling bar screen" - whatever she meant by that, "after the Windows scrolling bar screen" - and then she said, "and the other with a Windows registry hive error that kept it from booting.  SpinRite has without a doubt saved my bacon."



LEO:  That's great.



STEVE:  "Thanks so much."



LEO:  That's great.  Yeah, those hive errors are horrible.



STEVE:  Oh, boy, yes.  I've had 'em, and you've had 'em.



LEO:  Yeah.  Well, it's just this opaque binary blob that you can't fix.  So obviously there was a bad sector somewhere in that blob, and SpinRite was able to recover the sector, which is just great, yeah.  All right.  Let's talk about Firesheep.



STEVE:  Okay.  So this last Sunday, on the 24th of October, the ToorCon 12 Annual Security Conference occurred, from Friday through Sunday.  And there were a number of presentations, as there are at these security conferences.  I got a kick out of two of them, that our friend Samy Kamkar - who is of course notorious for his creation of the Evercookie.  I love the title of his.  I didn't bother to go dig into what it was.  But the title was "How I Met Your Girlfriend."



LEO:  Okay.  Sounds like a sitcom.



STEVE:  Exactly, I just - I got a kick out of the title of his, "How I Met Your Girlfriend."  And you can imagine at a security conference it's something you didn't do right...



LEO:  Gets your attention, yeah.



STEVE:  ...that gave him access to her.  And then Julia Wolf had my favorite presentation title.  It was, all caps with underscores, OMG_WTF_PDF.



LEO:  Say no more.



STEVE:  Say no more.



LEO:  Say no more.



STEVE:  OMG_WTF_PDF.



LEO:  I love it.



STEVE:  But at noon on Sunday, the last day of the conference, Eric Butler and Ian Gallagher, both security guys who operate out of Seattle, Washington, delivered their presentation which pretty much brought the house down.  It was titled "Hey Web 2.0:  Start protecting user privacy instead of pretending to."  And the description of their presentation online is worth sharing.  This is what they wrote ahead of time.  It says:



"Despite growing public concern over web privacy, especially within social networking sites, companies including Facebook, Twitter, and even Google all fail to protect users against session hijacking attacks.  These attacks are nothing:  Session hijacking is one of the oldest, simplest, and most widely known attacks against the web.  An interested attacker can view your private Facebook photos, broadcast Tweets as you, see your web history, and anything else you can do while logged in to your own online accounts. 

 

"We're bringing up this tired issue to remind people of the risks they face, especially when on open WiFi networks, and to remind companies that they have a responsibility to protect their users.  To drive this point home, we are releasing an open source tool at ToorCon 12 which shows you a 'buddy list' of people's online accounts being used around you, and lets you simply double-click to hijack them."



LEO:  Okay.



STEVE:  This is fantastic, Leo.



LEO:  You think this is good?



STEVE:  Oh, this is the best thing that ever happened.  This is, I mean, if I had a different security profile than I do, this is what I would write.  I can't write it, but I can cheer it.  This is great because this is finally going to really put, I mean, this is what it takes to force change.  We're never going to move from IPv4 to IPv6 until we run out of IPs.  We're never going to get online Web 2.0 sites to just switch over to SSL exclusively until they have to.  And this makes them do it.



LEO:  You know, when I used to go on - I still do, I go on geek cruises with a guy named Randal Schwartz, you know Randal, he's a programmer, does our This Week in Open Source, FLOSS.  And he's also a hacker, from years gone by.  And we got him to stop doing this.  But it was the same thing, it was very effective.  I'll never forget, the first time I went on a cruise with him, he came up to me and gave me a piece of paper.  He said, "Is this your email password?"  I said, "What?"  He said, "You're sending it in the clear every time you're on the ship's WiFi.  Just thought you should know."  Same idea; right?



STEVE:  Well, yes.  And look at the trouble Google got themselves into by capturing unencrypted WiFi.  I mean, just driving around.  They weren't even doing anything with it.  Okay.  So to frame this a little better, ConsumerAffairs.com today wrote:



"Computer security specialists have issued a warning about Firesheep, a new downloadable add-on to the Firefox browser. If the person in a coffee shop with you has it, they can see exactly what you're doing online. 

 

"The feature was reportedly created by a Seattle software developer, whose purpose was to demonstrate how vulnerable unsecured networks are.  Unfortunately, he's unleashed a tool that can turn a computer amateur into an accomplished hacker.  With Firesheep, a computer user can log onto a public network, in an airport or coffee shop, and get a list of all the computers that happen to be connected to the network at that moment.  Simply by double-clicking on one of the names...."



I mean, and this thing, it shows you a list of all the users on your WiFi hotspot, the social networks they're using, and their pictures, which it goes and retrieves from their Facebook page and MySpace and anything else, Twitter for example, and literally you browse them.  You click this - and I'm going to explain how in detail in a second.  But you are then them.  You're logged on as them to their Facebook page, to their MySpace domain, to their Twitter account, able to do anything they are.  This is chaos, Leo.  This is fantastic.



LEO:  You're sounding like a black hat.  What's amazing is how easy it is to use.  I mean, you have this extension installed, and you just see the list.



STEVE:  That's the point.  I mean, yes, you could be a Linux user with Cain and Abel, and you could type a bunch of arcane crypto commands and see this stuff going on.  I mean, I've done that.  I mean, it's possible.  But this is game changer because of how easy this makes it.  Now, when I went there this morning there were 300,724 downloads.  Can you click the link now?



LEO:  Holy cow.  Wow.  Yeah, let me go back to it and see how many there are now.  This is at GitHub.  It's not, by the way, an official Firefox extension.



STEVE:  Correct.



LEO:  He does not offer it through Firefox.  They'd probably block it.  325,985 downloads.



STEVE:  Okay.  So since this morning another 25,000 downloads.  Mozilla is on record as saying of this extension that, well, this is not a Firefox vulnerability.



LEO:  Right.  Any browser could do this; right?



STEVE:  Yes.  And in fact the cat's out of the bag now.  If Firefox were to block it, it's trivial to create a standalone application that will do this.  And I'm sure we're going to see one shortly.  There's just no doubt about it.



LEO:  Now, this works because these passwords are being sent in the clear.



STEVE:  Well, not - no, no.



LEO:  No?



STEVE:  No.  And that's what session hijacking is.  We'll talk about it in one second.



LEO:  Whoa.



STEVE:  So just to finish the Consumer Affairs story, they said, "Simply by double-clicking on one of the names, the Firesheep user can access whatever that computer user is doing online.  If they are updating their Facebook account, the Firesheep user is also logged in.  Firesheep works by intercepting Internet cookies, which websites place on your computer when you visit so they will recognize you when you return.  Professional hackers have had that tool in their arsenal for years.  Now, thanks to Firesheep, anybody that has downloaded the add-on can do it," too.



And so here's the deal.  On all these sites they switch you to SSL to log you in.  But then they give your browser an unsecure cookie, take you back out of SSL just because they can.  They don't have to, but they do.  And now that cookie is the way your session is authenticated.  That is the only way you're identified.  So anybody sniffing your unencrypted traffic, which all traffic is at an open WiFi hotspot, has always, has long been able to use that cookie, pick up that cookie which is sent with every request your browser makes.  That's the way - that's your entire session state is that cookie, just some random gobbledy-gook, doesn't matter what it is.



All a third party has to do is use that cookie, and they are indistinguishable from you at that location.  And even your IPs are the same because you're all being NAT'd through a single IP out onto the Internet.  So you look just like the person sitting next to you at Starbucks.  So currently supported is Amazon, Basecamp, bit.ly, eNom, Facebook, Foursquare, GitHub, Google, Hacker News, Harvest, The New York Times, Pivotal Tracker, Twitter, ToorCon, Evernote, Dropbox, Windows Live, Cisco...



LEO:  Crap, all the stuff I use.



STEVE:  ...Slicehost, Gowalla, and Flickr.  And coming soon is Yahoo!, eBay, LinkedIn, Digg, Reddit, Wikipedia, Blogger, GoDaddy, Posterous, Tumblr, Netflix, YouTube, Slashdot, MobileMe, PayPal, Salesforce, Craigslist, MySpace, Match, and AOL.



LEO:  This is terrible.



STEVE:  It's fantastic.



LEO:  Holy cow.  I mean - okay, okay.  Proceed.



STEVE:  First of all...



LEO:  I'm terrified.



STEVE:  There's, okay, some of this is a bit of an exaggeration.  For example, PayPal is on the "coming soon."  But PayPal never has you in the clear.  I don't think even using SSL Strip, which would remove the HTTPSes from the links, I don't think PayPal will function.  And we know that PayPal is an early adopter of STS, the Strict Transport Security protocol which, for example, Mozilla is supporting.  And what Mozilla, in Mozilla's formal comments about this add-on, they said, well, this is not a mistake in Firefox.  This is because sites are not using SSL to transact session state in cookies.



If we turn the clock back a few years, you may remember that at one point I was needing to allow my employees, Greg and Sue, to roam away from home where I had them locked down for secure access to GRC.  I wanted them to be able to roam around.  And what I used was a feature that browsers have always had, where cookies can be tagged as SSL-only, so that when a cookie is given to the browser, there's a flag that's just called "secure equals," and you say secure equals [indiscernible] yes or something.  And so the browser tags it.  It will never send it out unless the session is secure.



So part of my means for - Sue, for example, could be using an open WiFi hotspot.  First of all, GRC enforces SSL for these things, and never accepts a non-SSL connection.  But even so, the cookies that we use for maintaining state are tagged as SSL-only.  But if anything, for example, if Strip SSL were used to strip that out, even though at my server side I refuse to accept a non-SSL connection, so even Strip SSL wouldn't work, the browser at that location would never divulge the session state over a non-SSL connection.



So it is entirely possible, it's not rocket science, just to force SSL.  It's just all of these sites are not doing it.  They're switching people back over.  And I'm excited about this, obviously, because this is going to create major ripples.  I mean, the idea that, I mean, there will be a half a million of these things downloaded by tomorrow.  This thing is going to take off like wildfire.  People are going to experiment with it.  They're going to load it into Firefox, go to Starbucks, and say, wow, it works.  I mean, maybe mischief is going to be created by this.  I imagine some will be.  I mean, I would never, ever touch anyone's web, Facebook site settings or anything.  Unfortunately not everyone are you and me, Leo.



And immediately people like Amazon, I mean, Amazon is guilty, too, of taking us back out of SSL for - we've discussed this before with Amazon.  Important transactions are back to SSL.  In fact, just like last month I was talking to Mark Thompson about this.  He's working on a project, and we were talking about security, and he had looked closely at what Amazon does and mentioned to me that they were - that Amazon took you back out of SSL, and it was only for things that mattered.



And I said, "Mark, listen to me.  Absolutely without equivocation never accept a non-SSL connection.  There is no reason in this day and age not to always be using SSL."  He's doing something where there will be sensitive information.  And I said, just from day one never make this mistake.  Always be SSL all the time for the kind of stuff he's doing.  I think I made the point with him so that that's the way his system will be designed.  These other companies are just going to have to make the change.  I mean, and we're talking within days.  This is, I mean, this is huge.  And this represents a major, major positive lesson.  Now that this exists...



LEO:  It's called a spanking.



STEVE:  I mean, this is really - this is really big.



LEO:  All right, let's get back to Security Now!.  Steve Gibson has been telling us about a Firefox extension.  It's on GitHub, it's not on the official extensions page; but if you search for Firesheep you'll find it right away.



STEVE:  Yup, if you just Google "Firesheep," you'll find it on GitHub and a bunch of stories about it.



LEO:  You said not to install it.  You told me not to install it.



STEVE:  I'm going to install it.



LEO:  It's a little buggy?



STEVE:  Yes.  It is raw.  It's 0.1.  It's the code that they released at the show on Sunday.  They're in the process, it's right now supported for Windows and Mac.  For Windows you need to install the WinPcap sniffing library, thanks to me, actually, because Windows doesn't have raw sockets, which is what WinPcap provides.



LEO:  Oh, how interesting.



STEVE:  Uh-huh.  But...



LEO:  You don't need to do that on the Mac; huh?



STEVE:  Correct.  The Mac does support standard UNIX raw sockets.



LEO:  Oh, interesting.



STEVE:  And so it's able to sniff.  I saw a note from the developer that he's got it running under Linux, so he's in the process of getting it up under Linux.



LEO:  So if my understanding is correct - let me just, to recap, people are tuning in or whatever - you install this extension.  You go anywhere where there's an open access point, anywhere, a coffee shop, Starbucks, whatever, and it will show you on the left...



STEVE:  Or driving down the street, Leo, also.



LEO:  Yeah, actually, there's a lot of open access points all around the street.  So it will show you, on the left, a bar opens up, and it will show you other people sharing that open access spot with you, and what they're logged into.



STEVE:  Yes.  The idea is, it's sniffing the traffic, just the way Google did when they were roaming around doing their mapping.  It sniffs all the traffic that's available on the WiFi at that access point.  It looks at the transactions.  It sees www.facebook.com, twitter.com, amazon.com, New York Times, Foursquare, and so forth.  It has a little bit of JavaScript which tells it how to interpret those specific sites that it knows about, and it has a separate file of handlers which is growing now as it's becoming more able to deal with additional sites.  And so what it does is it starts populating like a list, like a sidebar, of all the things that people are doing on that WiFi hotspot, their name, it goes and shows you their photo.  So you can sort of turn around and go, oh, yeah, there he is over there on the side.



LEO:  Ay, ay, ay.



STEVE:  And so...



LEO:  So it pulls these photos from Twitter or Facebook or Flickr or wherever the profile photos exist.



STEVE:  Right, because it knows everything about them.  It's able to log in as them, get that information.  And then you simply, if you want to impersonate them, literally hijack their session, you just double-click on it, and you're logged in as them, on their Facebook page.



LEO:  And it does that because it doesn't give you the password, it's not that the password is out in the clear, but the cookie, the authenticating cookie is sent in the clear.  And so you have the cookie.  You just say "I'm them."  



STEVE:  Correct.  Now, okay.  The thing that Starbucks could do to fix this immediately, I mean, and it would be wonderful if they did, is simply to bring up WPA encryption with the password "Starbucks."  It doesn't have to be unknown.  We don't have to have per-user passwords or anything.



LEO:  Oh, interesting.



STEVE:  We already discussed how WPA provides inter-client isolation.  We discussed this a couple months ago under a different context.  So right now you walk into Starbucks, and you're online.  They're unencrypted, and they're open.



LEO:  So use WPA.  You can tell everybody the password, including somebody running Firesheep, doesn't matter.



STEVE:  Yes.



LEO:  Oh, that's a simple fix.



STEVE:  So it's a huge fix.  And it's the kind of thing that Starbucks, that is mentioned in these articles over and over.  And I keep saying their name because I'm at Starbucks all the time.  I would love them to bring up WPA encryption across all of their newly free WiFi, and just let people know, I mean, everyone would know, as soon as you try to log on, it'll say, what's your password?  Just type in "Starbucks."



LEO:  Put a sign over the counter.



STEVE:  And the problem is solved, completely solved, period, because...



LEO:  So if you're - I'm going to go over to my local coffee shop.  My friends over at the bakery over here have - in fact everybody in town now has WiFi, open WiFi.  And just say, this is all you have to do, please do this.  Use the name of the establishment as the password, and it would fix it.



STEVE:  Well, and in fact, Leo, have this installed on your Mac, walk over there, show them that right now...



LEO:  Oh, that's a good idea.



STEVE:  ...all the users that are using it are exposed because they're using their WiFi, and tell them it's this easy to fix it.



LEO:  Now, if I logged in as somebody using the cookie, let's say I got into their Facebook account, could I just change their password?



STEVE:  Absolutely.  You're them.  I mean, we're talking - this is havoc.  This is chaos.



LEO:  Wow.  Now, some sites would say, well, what's your original password, and would need that.



STEVE:  Ah, good point, yes.



LEO:  So you hope that they do things like that.



STEVE:  Yes.



LEO:  Good lord.  But even if they can't change your password, they can read everything as if they're you.



STEVE:  They could change your photos.  They could change your privacy settings, drop all your privacy to zero. 



LEO:  Oh, this is horrible.



STEVE:  It's horrible.



LEO:  We're going to see people using this like crazy.



STEVE:  I know.  I mean, what's the download count now?



LEO:  It's like the count and the amount.  Let me go back.  Let me see.  Downloads, it was 325,985.  I think thanks to this show alone you probably - 327,940.  Another 2,000 people have downloaded it just since we looked last time.



STEVE:  Yeah, it's going to go exponential, Leo.



LEO:  Ay, ay, ay, ay, ay.



STEVE:  Yeah.  And again, this is just the first.  Now that this concept is out, we're going to see it go like crazy.  And so, okay, so the thing that - the remediation for the wireless access providers simply bring up encryption, finally.  Again, it doesn't have to be a secret password, just Starbucks can make it "Starbucks."  And that solves the problem.  However, the providers of these services, the Facebook, the Twitter, the MySpace and so forth, they can't rely on that.  They have to simply enforce SSL, just like Google did.  While you were reading that last sponsorship spot, I went over to docs.google.com, which I had just been using to prepare the docs for this, and tried to remove the "S" from HTTP, and it bounced me, it redirected me right back over to HTTPS, forcing me to have a secure connection while I was doing these things.  So Google is enforcing it.  There's no reason everyone isn't.



LEO:  Yeah.  Nowadays machines are - even these Netbooks are fast enough to do SSL full-time.



STEVE:  Actually there's never been a question.  Remember that, I mean, and I've already seen this by people who aren't up to speed on encryption.  SSL used to be expensive back with HTTP 1.0, when browsers were dropping and reestablishing connections.  Now browsers are maintaining those persistent connections to web servers.  The only expense is during the public key negotiation at the beginning of a transaction.  And SSL now caches credentials.  So even browsers that drop connections and reconnect, you're able to use a cached credential.  The overhead is negligible because of other advances that have been made in the protocols.  So it's not expensive for the end user, and it's not even expensive for the aggregation of all those connections at the server.  There's just no reason not to do it.



LEO:  Wow, very interesting.



STEVE:  And this is - I'm sure we'll have some news next week because this thing is just making everybody go nuts.



LEO:  Well, yeah.  I mean, if you were malicious, you're going to go out there, and I'm just thinking, I mean, I'll probably use - I'm using an open access point right now.  I mean, holy cow.  We're going to lock down our access points here at the studio.



STEVE:  Yup.  Just use a simple - all you have is a simple password because, as we discussed, WPA does enforce inter-client isolation.  Individual clients negotiate their own private keys with the access point, even though they're using a common password.  The password gets them in, but then their sessions are individually isolated.  So that provides you protection against this kind of passive eavesdropping.  So it's trivial for Starbucks to fix the problem, and it'd be great if they did.



LEO:  Yeah.  Let's hope they do.



STEVE:  And in the meantime, Firesheep, Firefox add-on, have fun.  Don't be bad with it.  Don't be bad.



LEO:  Don't be bad.



STEVE:  But just have fun because this is...



LEO:  And [indiscernible], don't be bad.  I wonder how many people in the TWiT Cottage have already downloaded this.  Wow.  Steve Gibson is at GRC.com.  That's his website.  That's a place you can go to get - you can, the DNS Benchmark is out, in beta, and I'm presuming we'll talk about it.



STEVE:  Oh, and no, it's out of beta.  It's at v1.2.  I did want to mention to our listeners - thank you for reminding me, Leo.  It's linked from the main menu.  It's on our freeware page.  I took it public for this podcast before this...



LEO:  Oh, good.



STEVE:  ...before Firesheep happened.  And it's like, oh, shoot, now we've got to wait two weeks.  But this would be good because our listeners ought to grab it, take a look at it, familiarize themselves with it.  Frankly, I think you'll be blown away with what I did in 162K of code.  And I'm going to...



LEO:  That's amazing.



STEVE:  In two weeks we will talk about all the technology that's underneath the covers there and what it does and how it works.



LEO:  Truly amazing.  That's GRC.com.  That's where Steve lives, Gibson Research Corporation.  It's also where ShieldsUP! is and a whole bunch of other free useful utilities for security.  And of course one paid utility that you must have, Steve's bread and butter.  It's called SpinRite, the world's best hard drive recovery and maintenance utility.  And you should be using it if you've got hard drives.  Not on solid state, but on spinning drives, absolutely should be using it.



STEVE:  Yup.



LEO:  And when you go there you can also visit the show notes; the 16KB as well as 64KB versions Steve hosts.  He has small versions for people with bandwidth limitations.  He also has a complete transcription of every show, which is great.  That's all GRC.com.  And if you have a question for next week's show, because we usually do a Q&A show every odd episode, GRC.com/feedback to ask that question.  If you heard something today or on any show that you want to know more about, that's a good time to do that.  GRC.com/feedback.



You can watch us do the show every Wednesday at 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC at live.twit.tv.  And join us in the chatroom at irc.twit.tv, always fun.  But of course most people listen after the fact, at your convenience, just by downloading the show, TWiT.tv/sn for Security Now!.  TWiT.tv/sn has a list of all the different RSS feeds, the iTunes, the Zune, and all of that, so you can get it that way.



STEVE:  It's at five downloads per second right now.



LEO:  Holy geez.



STEVE:  328,556.



LEO:  I love this idea.  I'm going to put it on the little Air, bring it over to my local coffee shop, good friends of mine, and say, you know, you might want to turn on WPA.



STEVE:  Yeah, and then just put up a little sign, "Here's our password."  Because, I mean, it's so easy to do.  As we know, when you go to - there's an Italian restaurant that I go to, and they're encrypted.  And so the first time I walked in with my iPad, I said, oh, I can't remember what's your password.  I think it was, like, "realgoodeats" or something like that.



LEO:  That's great.



STEVE:  And it's just, they tell everybody, and that way they're not exposing their own customers to this kind of liability.  So it doesn't have to be secret.



LEO:  Realgoodeats, I like that.  Thank you, Steve.  We'll see you next week...



STEVE:  Thanks, Leo.



LEO:  ...on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#273

DATE:		November 4, 2010

TITLE:		Q&A #104 & The Firestorm

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-273.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 273, recorded November 3rd, 2010:  Your questions, Steve's answers #104, and The Firestorm.



It's time for Security Now!, the show that covers your security needs, watches out for you on the Internet, protects your privacy.  And the guy who does it all for us, Mr. Steve Gibson of the Gibson Research Corporation, GRC.com.  Steve, good to see you again.



STEVE GIBSON:  And I guess we keep you on your toes in open WiFi coffee shops...



LEO:  Oh, man, oh, man.



STEVE:  ...and similar places.



LEO:  Yeah, the Firesheep adventure of last ep- if you did not listen to last week's episode, Episode 272, do, because that Firesheep - I installed it, you know, it was so easy to install.  I put it on my Mac, on my little MacBook Air, brought it to the friendly neighborhood coffee shop.  I didn't want to bring it, you know, it's illegal to use; right?  I think it is.



STEVE:  Well, I don't know if it's illegal to view.  It would definitely be illegal to double-click on anybody and acquire their credentials because then you really have intercepted their communication, like, proactively.  But I would argue, if this is just being broadcast, as it is, then the broadcaster has some responsibility.  And if you've got a radio that receives what someone's broadcasting, and it shows it to you, it's like, well, okay, how is that wiretapping?  So, I mean, it does get - there has been, well, first of all, the Firesheep has caused a firestorm, essentially...



LEO:  Yes, yes.



STEVE:  ...of reaction.  It's been - the developer was overwhelmed by the reaction from it.  He didn't expect anything like it.  At the moment we're at 571,600-plus downloads, so we crossed half a million some time ago.  When we did the podcast one week ago, we were at 300,000, just a little over 300,000.  So as you mentioned before we began recording, it's slowing down a little bit.  But there's been all kinds of havoc as a result.  And actually we'll be talking about a lot of that during this podcast today.



LEO:  Yeah, I was - so I installed it very easily.  In fact, I installed it at the coffee shop, it was so easy.  First I wasn't getting a result.  And then I realized, oh, I hadn't set the preference about which network card to use.  Once I set that...



STEVE:  Yup.



LEO:  ...I saw myself right away.  But I didn't see anybody else.  I guess nobody else in the coffee shop was using the WiFi.  So I asked the friend I was sitting next to to fire up her Facebook, and she did.  And immediately I saw her on the list.  I said, watch this.  I double-clicked it, and I was in her Facebook page.  And I said, I could leave a status update.  I could do everything but change your password.  I could even change your privacy preferences right now.  And then we called over the owner of the shop, explained the situation, showed her.  And she immediately went upstairs and turned on WPA.



STEVE:  Oh, that's good.  Well, and we ought to just say right at the top of the show, I loved the idea that you had for setting the SSID.



LEO:  Oh, yeah, because of course the concern is now you're adding a password to your open access point, oh, no, what do we do?  So I said, just change your SSID to "della," which is the original one, or maybe it was "bakery," I can't remember, and then in parentheses, "password is password," or whatever it is.  Because you don't need to have a secure password, do you.



STEVE:  No, you don't.  And that was the whole point is essentially everyone can know the password, but that still gives them individual encryption.  Now, there are problems with that that we'll be talking about today.



LEO:  Oh, good.



STEVE:  But I just thought it was very clever, Leo, that you put - you disclose the password in the name of the network because that's what comes up when you go to a network for the first time.  It lists them all.  And if it said, like,  "della (password is 'free')" or something, then you're, like, you don't even have to go to the management or have it posted anywhere.  Everyone would know what it was.  I just - that's a very - that's a neat idea, to put the password in the SSID.



LEO:  So we will get an update, the Firestorm on Firesheep.  And we also have questions and answers.  All right, Steve.  Let's I guess start with our regular updates.



STEVE:  Well, I did have a little comment.  I got a tweet from someone named Ken Papp, who tweeted, following up from last week's episode, he said, "I did my good deeds today.  Showed managers at Starbucks, CornerBakery, B&N" - which must be Barnes & Noble - "and Sheraton Firesheep in action."



LEO:  Fantastic.



STEVE:  "Jaws hit the floor."



LEO:  Yep.



STEVE:  And, see, and again, that's why I last week was jumping up and down about this.  I mean, yes, I recognize that it creates a problem.  But it's a problem that exists whether Firesheep is there to demonstrate it or not.  And you saw the eyeballs on the manager at your bakery.



LEO:  Oh, yeah.



STEVE:  You said, look, this is what is happening.  And what I imagine will happen is this news will spread.  There's, like, an initial adoption frenzy.  But we have to know that, behind the scenes, organizations like Facebook are saying, whoa, we really need to step up our activities.  I did receive a quote from them stating that they are working towards moving to pure SSL, and they are projecting that they're a few months away.  And later on in the podcast we're going to talk about the costs of moving to SSL because there were some listener questioners about that.  And I managed, actually I followed on from something, either you said it during the podcast last week, or I heard you mention it some other time, but about the cost that Google experienced.



LEO:  They did a blog post, and I'll see if I can find that for you.



STEVE:  Oh, I have it.



LEO:  Oh, you've got it, okay.



STEVE:  Yeah.  So I tracked it down, and I got the actual numbers on Google's experience in moving, for example, Gmail to 100 percent SSL.



So of course we've got the regular culprits in updates for the week.  Firefox, remember that we talked about a just-discovered zero-day vulnerability that was used to hack people who went to the Nobel Peace Prize website.  We mentioned it last week.  And I knew at the time that they were working on an update.  They have done that, and they've pushed it out.  So what I found was I don't normally start my machine every day.  It runs 24/7.  And I leave, I mean, Firefox is like my portal to the world, so I leave it running.  And that may be why I'm not getting updates all the time.  But when I went under Help About, or Help Check for Updates, it said, would you like to install the downloaded update?  So mine received it, but it didn't automatically, like, do its thing.  So...



LEO:  I think Chrome does it automatically.  And that's one thing I like about Chrome is that it doesn't have to be restarted.



STEVE:  Oh, Chrome is stealth.  In fact, I have a note here that, behind the scenes and silently as usual, with no fanfare, Chrome went up to v7.0.517.41.



LEO:  I mean, that's a major, major jump.  And they didn't say a thing.



STEVE:  Yup, just do-do-do-do-do-do, you know, all done.  And the obligation, of course, is one of they'd really better not make a mistake because if they, I mean, they must have a...



LEO:  I think you can turn it off.



STEVE:  ...a rollback.  And they must have a rollback scenario where they're, like, able to recover from an update that damages the browser because then you wouldn't know, if you didn't know that you updated deliberately, or that it was just updated, you wouldn't know why it broke.



LEO:  Yeah, what happened?



STEVE:  So, yeah.  So Firefox is now at 3.6.12, 3.5.15;  Thunderbird, because this was an across-the-board fix, two Thunderbird version chains, 3.1.6 and 3.0.10; and SeaMonkey at 2.0.10.  So if you've got those, you've got the latest.  And that fixes this, you know, emergency little update that our friends at Mozilla did.



Now, Shockwave did get fixed.  Remember that we talked about it last - we talked about it on the podcast that I wanted to make sure people understood the difference between Flash and Shockwave, and that unless they knew they needed Shockwave, it may have been some debris that their machine collected over the last few years which, even though they weren't using it, was still creating a vulnerability because the nature of the attack was that your browser knows that it has access to the Shockwave plug-in.  And so if you go to a malicious website that invokes that plug-in, the browser goes, oh, yeah, I've got that around here somewhere.  Haven't fired it up for a few years.  But oh, yeah, here you go.  And then you're exploited.  So it's a perfect example of something where, if you don't know you need it, get rid of it because you're just better off.



If you do need it, though, on Friday after the podcast, Friday, October 29th, Adobe did update Shockwave to fix the problem.  So it's now at v11.5.8.612 for both Windows and Mac.  And again, you can, either way, if it's installed or if you want to update it, you can check by going to Adobe.com/shockwave/welcome.  And if it gives you the whole animated song and dance, that's Shockwave Player doing that for you, which means it is currently installed.  If instead it says, oh, you need a plug-in, well, this is where I would just say, back away from your computer.  Do not click yes.  And you're better off without it.



LEO:  Yeah.  I don't think there's much stuff anymore that uses Shockwave.



STEVE:  No, no.  And it's - it was sort of the higher power platform that really didn't take hold.



LEO:  It was mostly used in CD-ROMs.  I mean, that's how old it is.



STEVE:  Yeah.  Once again, we have a zero-day vulnerability hot off the press, actively being exploited in the wild, by our good friends at Adobe.  And I want to ask them, how is that quarterly update cycle going for you?  My goodness.  They are scrambling because another vulnerability was found in Flash.  The vulnerability is in Flash.  But just like one we talked about earlier this year, I mean, not that long ago, it's invoked via the Reader app, and/or Acrobat, if that's what you're using for your reader.  So pretty much across the board, everything is vulnerable.  There's no fix for it now.  This just happened, like, yesterday.  Flash Player, well, the current version of Flash Player for Windows, Mac, Linux, and Solaris are vulnerable.  The current Flash Player for Android is vulnerable.  Notice that the Flash Player for iPad is not.  But anyway, that's a different matter.



LEO:  [Laughing] I got it.



STEVE:  And also Reader 9.4 and Acrobat 9.4 for Windows, Mac, UNIX and - yeah, Windows, Macintosh, and UNIX, those platforms are.  The only thing that gets by is v8.x is not vulnerable.  Adobe's acknowledged the problem.  It's in our old friend the authplay.dll, which our listeners will remember us talking about last time there was a problem in authplay.dll.  It's right now limited scope, targeted.  Adobe is scrambling to address it.  They have said that they will have it fixed for all those major OSes on the 4th of November.  So we're recording this on the 3rd.  The podcast normally comes out on the 4th.  So maybe on the day people are listening to this it's available.  So you'll want to make sure that you're running the latest version of Flash when you get the podcast.  Android, the Flash Player for Android they're going to have pushed out and available on the 9th.  And that's for the v10 versions of Flash.  The v9 updates will be available on the 15th.  And I won't rub it in to Adobe any more than I have that their next scheduled update was February 8th of 2011.



LEO:  Okay.  We can wait till then.  No hurry.



STEVE:  Exactly.  Well, and Adobe's not the only one in the doghouse.  We also have a brand new zero-day vulnerability discovered just, again, just now by Symantec security researchers.  It's been confirmed by Microsoft.  It's in IE.  It affects versions 6 and 7 and 8 of IE.  But because IE8 has DEP, the Data Execution Protection, enabled by default, that is preventing data segments from being executable, IE8 is not obviously exploitable, or not nearly as easily exploitable.  But it's still got the inherent problem in it.  However, IE9 beta is not vulnerable.



What was found was emails being sent to companies with some questionable-looking language.  I mean, I look at this, and it's like, okay, this is really not an English speaker who wrote this, we've all seen those, which contains a link to it.  The link went to a well-known popular site.  And I think it would have been a travel-related site based on the - it was blacked out in the sample that I saw.  But the idea would have been it looked like it was travel arrangements and lodgings and things.  And so right there the link was this well-known travel-related site where that would tend to give you a sense of, oh, I'm not really sure what this is about.  I didn't know I was going on a trip.  But I know about this travel-related site.  So I'm going to click the link.



Well, the problem was, that site had been compromised with some malicious script which then checked the version of IE the user was running.  And in the event that it was version 6 or 7, it bounced them to a site, I can't remember where it was, I want to say Poland I think is where this site was, which then that leveraged this brand new, previously unknown, zero-day vulnerability in IE which allowed a trojan to be installed.  And they actually watched, they did a packet capture when they - the Symantec guys did, when they deliberately followed the link and saw what happened, and they watched someone connect to the trojan and then begin typing commands from wherever they were located into this machine.  You wouldn't normally see it.  It was going on in the network traffic, connected to essentially an invisible console that was running provided by the trojan.



So Microsoft's aware of it.  I received by email, actually after I'd already put this together, in came a security alert noting that they were acknowledging this new problem.  So where are we?  We're still, it may not be time for second Tuesday of November.  But so maybe they'll fix it by next Tuesday.  Or maybe if it becomes a problem they'll fix it faster.  Otherwise we may wait five weeks for it.  But at this point no idea how to mitigate it; no idea of what to do to turn it off.  If anything happens that's significant, I'll of course let everyone know next week.



There was, and I'm sure you probably saw this, Leo, a new iPhone lock screen bypass was discovered for iOS 4.1, that is, for iOS 4.1 phones.  You tap, on a locked iPhone, you tap the Emergency Call button, then enter three pound signs...



LEO:  Actually you can enter anything.



STEVE:  Oh, okay.



LEO:  Yeah, you don't have to enter, you know, it just says you don't want to enter 911, obviously.  So just any number of pound signs is good because it won't dial anything.



STEVE:  Ah.  And then you hit the green Call button, and then immediately press the Lock button.



LEO:  Yeah.  The timing is tricky.  So the first time it may not work.  You've got to do it just right, but it's easy to do.



STEVE:  And then it unlocks the phone, and you have access to the phone, voicemail, call history.



LEO:  Yeah.  You don't get access to everything on the phone, just the phone app.



STEVE:  Right.



LEO:  But that's enough to really screw with somebody.



STEVE:  Well, and I just wanted to let our listeners know, for the sake of their awareness, that if you're assuming that your phone lock is doing what you want...



LEO:  It ain't.



STEVE:  You might hand it to somebody or leave it somewhere, and it's not.



LEO:  Let's see if I can do this here.  So you press Emergency Call.  And it really doesn't matter what you dial; but, yeah, three pound signs is fine.  And then the key is to press the green button, the Call button and the top button, the On/Off button, pretty much in a timely way.



STEVE:  Yeah.  But what I read was hit the green Call button and immediately press the Lock button.



LEO:  Yeah.  And it just takes a little practice.  But it's - whoops, I unlocked it.  Let's lock it again, and slide to unlock, Emergency Call...



STEVE:  Sorry.  What Apple said was that they were not going to do a patch.



LEO:  You see, I got right into it.



STEVE:  It worked, huh?



LEO:  Yup, yup.



STEVE:  That they were going to fix it in v4.2.



LEO:  Well, and 4.2 is due soon.



STEVE:  Right.



LEO:  So that's good news.  But right now, without entering in the password, I was able to get into my phone app [indiscernible].  Isn't that nice.



STEVE:  Well, you've got skills, Leo.



LEO:  Yeah, I've got mad skills.



STEVE:  Wait, wait, wait, did you just break the law?  No, I'm sure it's not.



LEO:  No, it's my phone.  I think it's okay.



STEVE:  So India has now joined the UAE in announcing that they're dropping their promise or threat to ban Blackberry services.  Which always was - we've talked about it before.  I was a little uncomfortable about what was going on behind the scenes here.  The direct quote was, "BlackBerry parent company Research in Motion (RIM) and the Ministry reached an interim agreement regarding government access to data sent over the BlackBerry network.  RIM has promised a final proposal by January 31, 2011."  And then what the UAE had said, similarly, was that "RIM had offered a workable solution."



What I, in digging around some more, I found an Indian newspaper online which had some details.  And the concern had been raised that this interim solution wasn't very secure.  Apparently what has happened is PCs have been installed in telecom providers, that is, so you've got whoever it is that's anchoring your BlackBerry wirelessly to the land.  There's a PC installed there in which RIM installs some proprietary software which is able to reach out to RIM and contact them so that they perform the decryption.  And then the decrypted data is sent back to that machine.  So essentially it's a sanctioned man-in-the-middle architecture, which I got the sense that it was temporary, like they're going to come up with something.  Everyone keeps talking about a formal or final agreement or resolution will be made by the end of January 2011.



So it does look like RIM came up with a technological means for weakening what was believed to be very strong endpoint-to-endpoint encryption because it was either that or succumb to the service being shut down throughout the region.  So I was hoping that they were able just to say no, sorry, we can't do it, the technology won't let us, and we hope you won't disconnect us.  But apparently the suits won, as suits do.



LEO:  Suits have lawyers by the dozen.



STEVE:  Yeah, yeah.  One other little bit of news I saw that I thought was interesting was that Amazon won a very important privacy battle with North Carolina tax collectors.  North Carolina has been pursuing Amazon for some time, saying that we want complete records of every purchase every North Carolina resident has made from 2003 through 2010, that is, through now.



LEO:  They want to collect sales tax.



STEVE:  That's exactly what they want to do.  And just I know you're aware of this.  I wasn't until relatively recently, that the fact that we don't pay sales tax on goods that we purchase over the Internet from out of state doesn't relieve us the obligation...



LEO:  Oh, no.



STEVE:  ...of paying them.  It only relieves the sender the obligation of collecting them.



LEO:  In fact, in California on your income tax return it asks you, is there any tax you want to give us?  And you're legally bound to give it to them.  If you don't declare it, you can go to jail.



STEVE:  Yeah.  So we owe, we who are buying things on the Internet, it's called "use tax."  It's not sales tax, it's use tax.  It's the same, they just use a different word for it.  But so, I mean, you can imagine the issue is that here's all these companies that are not taxing the customers; and they're saying, well, we can't possibly deal with all of the different state, county, city sales tax variations in order to do this.



And there's been a lot of effort in Congress to keep a taxation moratorium on the Internet under the interest of not doing anything to upset the apple cart of how nice eCommerce is growing, and the Internet's wonderful, and it's good for the economy and all that.  Yet states are looking around and saying, wait a minute, look at all the money that we're not collecting because our residents we know are not reporting fairly the sales tax on the goods they're purchasing from out of state.  Now, Amazon has no facility in North Carolina.  So by law they don't have an obligation to collect that tax.



A U.S. District Judge Marsha Pechman in Washington state said that North Carolina's request went too far and, quote, "runs afoul of the First Amendment."  So she granted Amazon a summary judgment on this suit.  And it actually was Amazon who sued North Carolina, basically to buzz off and leave them alone.  And Amazon stressed in its lawsuit that purchases - like, reminded everyone in North Carolina that purchases of books, DVDs, Blu-ray disks and other media enjoy special privacy protections.  And so the reason I wanted to bring it up, not only is I think it's interesting relative to eCommerce, but this turns on issues of privacy because there's three different rulings and law that pertain.  In a 2002 decision, the Colorado Supreme Court ruled that the First Amendment protects, quote, "an individual's fundamental right to purchase books anonymously, free from government interference."



LEO:  Yes.



STEVE:  Yeah.



LEO:  I love that.



STEVE:  Yes.  And in this case the justices tossed out a subpoena from police to the Tattered Cover Bookstore requiring them to provide information about all the books that a specific customer had purchased.  So they were trying to, for whatever reason, what books has this guy bought?  Well, it turns out that a First Amendment right is that we can buy whatever books we want without the government finding out what they are.



And then in a 2007 case, federal prosecutors tried unsuccessfully to force Amazon to identify thousands of customers who bought books online, but abandoned the idea after a judge rebuked them.  Judge Stephen Crocker in Wisconsin ruled that "the subpoena is troubling because it permits the government to peek into the reading habits of specific individuals without their prior knowledge or permission."



And then finally there's actually a formal law above and beyond what the First Amendment of the Constitution provides called the Video Privacy Protection Act, which makes it illegal for anyone selling - ILLEGAL for anyone selling movies to disclose customer information to anyone, including state tax collectors.  The 1988 law specifically covers prerecorded videocassette tapes, but also sweeps in similar audiovisual material which of course would include DVDs and Blu-ray disks.  So I thought that was just interesting info.



LEO:  Of course as you I'm sure know, the Patriot Act does allow the federal government to find that stuff out.



STEVE:  Yeah.  A little override.



LEO:  Yeah, there's a little override there.  Yeah, I got a letter from the state of California this year saying, we've decided not only do you have to pay use tax, but we want you to pay quarterly installments on your use tax.  But it's interesting, now, can they, in this North Carolina judgment - not everything Amazon sells is books and movies.



STEVE:  Correct.



LEO:  But I guess they can't pick and choose and say send us everything that's not books and movies.  Or can they?



STEVE:  Well, it's not clear that this is over.



LEO:  Oh, boy.



STEVE:  Basically, Amazon lost this one.  But apparently there's also some - what had happened was, Amazon tried to satisfy them by providing the material anonymously, and in some sort of aggregate, like there's this much tax in this county and this much over here.



LEO:  But they want to know who.



STEVE:  Exactly.



LEO:  C'mon.  They can't - now, I have to say, in their defense, if you had a bookstore in the state of North Carolina or in California, you have to collect sales tax.  You see it as a real competitive disadvantage to a company like Amazon that doesn't.  And it's putting bookstores out of business.  So there is an argument to be made that, you know, maybe Amazon should be collecting sales tax.



STEVE:  Well, and if - Amazon is Seattle-based; right?  And if you are where Amazon is, then Amazon does have to collect sales tax for you.  So that's a little weird, too, so...



LEO:  Right, but that's normal, I think.



STEVE:  Yes.



LEO:  If they do business in that state, then they have to collect sales tax.



STEVE:  Yes, exactly.  Okay.  So the cost of ubiquitous SSL.  Following from a comment that you made, I did some research because I was curious what Google's experience was in switching themselves over to SSL because there are a number of different gotchas in doing this.  And of course this all relates tangentially to the whole Firesheep issue.  For example, why is it that Facebook is needing several months of exploration and work to turn on SSL?  Like, what's the problem?  Well, the one thing that I always hear is that there is a computational burden.  And we've always sort of, I mean, it's like one of those urban legends that you just can't shake loose because it was once upon a time true, a long, long time ago, and it hasn't been for a long time.



So I want to just take the opportunity to dispel this with a little more data to back it up.  The reason I have known it could not be true that there was a computational burden to SSL that was significant in this day and age is not only that, of course, processors are much faster than they used to be.  You could argue, well, yes, but bandwidths are much higher, many more connections are coming in, so the load on the servers has scaled at the same pace that their power has increased and so forth.  It's like, okay, fair enough.  But what SSL acquired, and we talked about this in our podcast where we delved into the minutiae of the SSL protocol, is the ability to resume an existing session, that is, resume already negotiated credentials.



So what happens is the first time a client contacts the server, if the client already has in its own cache the credentials which are like, for example, less than 24 hours old for the domain, and like otherwise in every way qualify, when it's negotiating its handshake, it will provide the ID to the server of this negotiation that it already went through, which was the expensive part.  Normally, if that isn't the case, there is a one-time cost to do the public key work to verify the signature on the certificate and to use public key encryption in order to set up this negotiated credential.  But that has to be done one time and doesn't need to be done for every other connection.



So SSL now has, and clients all are able to cache, that credential, which means that, for example, we'll take Facebook.  When you initiate a connection, you're going to have to log on.  So that's going to take you into an SSL connection where your username and password is exchanged, and you get the controversial unsecure key.  And then the way Facebook currently operates, it takes you back down to a nonsecured, non-SSL connection where this cookie is transacted in the clear, which is of course the hook that Firesheep uses for being able to hijack or sidejack the session.



So the point is that client and server had to have a brief SSL connection anyway.  So if Facebook instead kept the session, that is, all communications secure, then every time the client connected, as the user is clicking buttons and moving around the site and doing things, the client would be handing back to the server the ID that they had agreed on for this cached session, and there's zero overhead.  No public key, no computationally expensive public key work needs to be done again.  So the fact is it's just not expensive.



What I loved was I actually found a quote from the Google engineers who were responsible for moving Gmail over to pure SSL.  And they wrote:  "If there's one point that we want to communicate to the world, it's that SSL/TLS is not computationally expensive anymore.  Ten years ago it might have been true, but it's just not the case anymore.  You, too, can afford to enable HTTPS for your users."



LEO:  I love it.



STEVE:  "In January this year (2010), Gmail switched to using HTTPS for everything by default.  Previously it had been introduced as an option, but now all of our users use HTTPS to secure their email between their browsers and Google, all the time.  In order to do this, we had to deploy no additional machines and no special hardware."



LEO:  That's key.



STEVE:  "On our production front-end machines, SSL/TLS accounts for less than 1 percent of the CPU load, less than 10K of memory per connection, and less than 2 percent of network overhead."



LEO:  Now, that can add up if you do a lot of transactions, though.  That's not necessarily negligible.



STEVE:  Well, no, that's percent.  So that's a fixed percent...



LEO:  Yeah, but if you do a million, I mean, 10K is a lot of memory if you do a lot of transactions.  I'm just saying, there is a cost.



STEVE:  Oh, sure.  Sure, sure, sure.  And it's not clear to me what the cost would be without SSL.  That is, that 10K, that could be connection overhead.



LEO:  Oh, maybe it's 8K, right, yeah.



STEVE:  So it may not just all be SSL overhead.  Anyway, so they say, "Many people believe that SSL takes a lot of CPU time, and we hope the above numbers (public for the first time) will help to dispel that."  Then they finally - and this blog post goes way on.  But they said, "If you stop reading now, you only need to remember one thing:  SSL/TLS is not computationally expensive anymore."  So that was their message.



LEO:  And they released that shortly after Firesheep came out.  I mean, I think it was clearly a message to people like Facebook and Twitter:  You don't have an economic excuse for not doing this.



STEVE:  Yes.  And, you know, there was some flak that I received last week from people who didn't quite understand the whole notion of SSL everywhere, HTTPS ubiquitously, because they said, well, you know, but certificates are not free.  And I have a web server, and why should I have to secure it?  It's like, whoa, whoa, whoa, whoa.  We're just talking about servers which have something to protect.  You know, if you're running a web server, and you don't have an SSL certificate, then there's no security that your server is offering, and obviously therefore, I mean, hopefully, no need for it.  Hopefully you're not doing anything over unsecured connections which would ever need to be secured because you're not able to take the person into SSL.  So I was by no means meaning to say that HTTP needs to go away and be completely replaced by HTTPS.  Not at all.  I'm just saying that all of those scenarios which we talked about with Amazon and Facebook and MySpace and Twitter, in those scenarios it absolutely makes sense to switch to HTTPS.  If you are ever using it, always use it, is the point.



LEO:  Right.



STEVE:  So there's no - it's not like you're having to buy a certificate that you don't already have.  You need one in order to allow people to logon securely.  Well, you ought to also protect...



LEO:  Just turn it on all the time.



STEVE:  ...everything else.



LEO:  Yeah.



STEVE:  Exactly.  Now, of course it does create some problems, for example, the famous mixed content problem.  Browsers have always been warning us if some of the content of a page is secured and some isn't.  That is, for example, if a secure page, an HTTPS page, asks for, like, even JPGs and GIFs and PNG images, which are HTTPS, then the browser will say, whoa, not all this page is coming securely.  And it's like, oh, okay.  It worries people.



It's not clear to me that it needs to, although you could design exploits that would take advantage of it.  For example, if CSS or if chunks of script was being pulled, then while the page itself was secure, important pieces of the page could be pulled that were not secure.  The reason I bring it up is that I can see a problem with third-party providers of content to a page, for example advertising sites.  Advertising is almost exclusively nonsecure right now.  And if you were going to switch your site over to SSL, exclusively to HTTPS, and you were going to be hosting ads, then you would need to be using advertisers that were also able to provide the ads over SSL.  Otherwise your users would be getting these scary boxes saying not everything on this page is secure.  And in this day and age where we want people to be more security aware, you'd like that to concern people.



So I can see Facebook needing some time to get their act together.  I'm really glad that they are.  And I think it's very clear.  I mean, Amazon - actually, when I was talking to Mark Thompson about exactly this issue because he's setting up a very large and comprehensive web system for a deal that he's working on, he was talking about the issue of SSL.  And I said, well, you know, turn it on all the time.  And this was, like, months ago.  I said, "Just have it on all the time.  It's not expensive anymore.  Just do it, and you'll never have to worry about it."  And he said, "Well, I've been looking what other sites do."  And he said, "I noted that Amazon doesn't normally keep you secure as you're poking around doing things.  But anytime you do something important, like you want to check out your shopping cart, they require you to reauthenticate right then."  And of course that is over SSL.



So Amazon's engineers, for whatever reason, decided it was worthwhile really moving people back out of SSL the rest of the time, and moving them into it - literally you're jumping back and forth as you do things on Amazon.  It would be wonderful if one of these days we'd just see Amazon staying green up in the bar all the time, knowing that no snoopy people can see what I'm doing on Amazon.  They may not be able to purchase something on my behalf, but they're able to watch where I wander around and what I'm looking at and what I'm searching for and so forth, which is no one's business.



LEO:  Yeah, just turn it on.  Costs nothing.  Turn it on.  Leave it on.



STEVE:  Exactly.



LEO:  You've already got the cert.



STEVE:  And I did have a fun story, I always try to find something different, about SpinRite.  Gary Harris wrote - the subject was "SpinRite Testimonial:  Too Hot to Handle."



"Steve, I first crawled out from under a non-podcast-aware rock last Christmas, when my son bought me an iPod.  I had no idea the wealth of tech information available until then.  Where had I been?  I immediately latched onto Security Now! podcast and promptly OD'd on the first 60 or so episodes until I finally caught up with the current flow sometime last February.  I have been SpinRite-aware for many years, but I kind of forgot about it; and when I got out of the business for a while, I just had no need for it.  While guzzling down your show episodes at an alarming rate, I decided to purchase SpinRite.  I immediately went online, bought a copy, downloaded it, and then sat in wait for my first hard disk failure.  I didn't have to wait long.



"I had a client who had a computer that was running much too slowly.  I immediately expected spyware, viruses, yada yada, but I found no evidence of this.  She said the computer had been running like this for at least a year.  Before becoming SpinRite re-aware, I would probably have simply cleared the drive and reinstalled.  But I decided to put the drive through my newly acquired 'spin cycle.'"



LEO:  I love that, the "spin cycle."  I like that.



STEVE:  The "spin cycle."  "About 20 percent into a Level 2 check, SpinRite told me the drive was too hot to handle.  It stopped scanning and let me know there was a problem.  So I let the drive cool down and resumed the scan.  It halted a few minutes later with the same message.  I determined that, based on the client's statement about when it started, this drive had been in a state of near failure for probably a year, becoming slower and slower as it dealt with all the error conditions caused by its overheating.



"When I powered down the computer to remove the drive, it was literally too hot to handle.  I had to let it cool.  Since I had determined the slowness was due to the hard drive itself and not any malware residing on it, I was able to image this hot potato and apply the image to a new hard drive.  The client called me a few days later and told me the computer was probably running 10 times faster than ever before.  In reality, it was now running normally for the first time in a year."  And he said, "SpinRite is, pardon the pun, a cool product.  Thanks, thanks, thanks."



LEO:  Yeah, I mean, I think when you look at something like the MacBook Air you really realize that the speed of your computer is often I/O bound.  And something, a hard drive that's laboring, is going to really slow it down.



STEVE:  Yeah.  I have noticed, when I've been purchasing state-of-the-art SATA drives, they really do seem to be running cooler than drives used to be.  So I think we're getting heat under control.  One of the things that SpinRite does is it polls the drive's smart data constantly while it's running.  That allows it to do a whole bunch of cool things that nothing else has ever done, like monitoring the rate at which error correction is being used, monitor the health of the drive on the fly, and show you in a series of bar charts which are displayed while SpinRite's running.  If these health parameters are being pushed down by using SpinRite, that shouldn't happen.  And it's a really very sensitive, very cool early warning system that the drive's fine, but it's having more trouble than it ought to.



And one of the things SpinRite does is check the drive's temperature because of course we all know that people's fans or vents get clogged.  Some people actually stick their computer in a closet, as if that's going to keep the machine cool.  So many people have been surprised that the problems they were having were just that the drive was getting too hot.  So although SpinRite was useful for keeping the drive in good shape, it also said, yeah, and do something about ventilation here, buddy.



LEO:  Yeah.  Now, are you ready, Steve?



STEVE:  Absolutely.



LEO:  Questions, answers, Steve Gibson.  He's on the hook, ladies and gentlemen.  Of course he chose these questions and answers.



STEVE:  Is it on the hook or off the hook?



LEO:  He is off the hook, that's true, too.



STEVE:  Okay, okay.



LEO:  Question 1 comes to us from Todd Karwoski.  Steve - actually, he tweeted this one.  Thought you should know, Microsoft's Security Essentials wants to "protect" my computer from the Firesheep add-on.  And he sent us a TwitPic of the message he's getting from Microsoft's Security Essentials.  I'll give you a view of that here, and we'll zoom in.  It says "HackTool:JS/Firesheep, alert level medium.  This program has potentially unwanted behavior."  So they think of it as malware.



STEVE:  So Microsoft was very quick to respond to this.



LEO:  I think that's not unreasonable.



STEVE:  Okay, except that remember that a user would install this himself, or herself, on their own machine deliberately, thinking that it's cool.  And then Microsoft Security Essentials is saying, wait a minute, this thing is potentially undesirable.  So it's sort of - I guess it's protecting you from yourself, or protecting you from getting in trouble.



LEO:  It doesn't say - it says it's medium threat.  It doesn't say it's malware, exactly.



STEVE:  Well, see, I salute the fact that Mozilla chose not to block this.



LEO:  Oh, interesting.



STEVE:  And they've got a blog posting where they discuss this.  And they said, you know, this is not doing anything that the user who installs it doesn't expect.  It does what the user does expect.  It's open source.  It's available.  It's not taking advantage of exploits or flaws in Firefox.  It's a utility.  And we don't block utilities.  So, and I think...



LEO:  It is turning on raw sockets.  I mean, are there some potential risks from using it?



STEVE:  I really can't see any risks to the user.  It's something that the user wants.  Now, the good news is that Microsoft Security Essentials does allow you to say, oh, thank you for watching out for me.  Spend your time...



LEO:  It's more informational.



STEVE:  Spend your time patching Windows bugs, please.



LEO:  Yes, by the way.



STEVE:  Yeah.  It's just more informational.  So I did get a kick out of the fact that MSE is saying, oh, wait, you've got Firesheep.  Well, are you sure you want that?  Uh, yeah, I'm having a lot of fun with it.  Oh, and Leo, I didn't mention.  College campuses just went insane...



LEO:  Oh, I bet.



STEVE:  ...over Firesheep.



LEO:  Well, and there is a risk that you'll be arrested for using it, so maybe that's what they're talking about.



STEVE:  Yeah.



LEO:  I mean, if you misuse it, anyway.  I wonder, do you get an error in MSE if you install things like Cain & Abel?  Or Wireshark?  Other hacking tools?



STEVE:  That's a good question.  I don't know.  I don't know.



LEO:  I don't know, but I'm sure somebody will tell me.  Paul Kawolski in Seattle, Washington with Question 2.  He wonders whether WEP is enough.  Steve and Leo, would using WEP encryption be sufficient to protect from Firesheep?  We've mentioned that WPA works.  In fact, somebody asked me, do you need WPA2 or just regular WPA?  So clarify what will protect us from Firesheep, what won't?



STEVE:  Well, we've got a bunch of questions that sort of take us through that that are coming up.  So what Paul was asking was about WEP.  And sort of the answer is yes and no.  Any encryption will protect you because Firesheep relies upon you using no encryption.



LEO:  Unencrypted packets, otherwise it can't see what's going on.



STEVE:  Exactly.  It's just passively sniffing the network.  Now, the problem, however, with WEP is that, unlike WPA, which does negotiate a per-connection encryption - and we'll be talking a little bit more about that, actually extensively more about that, here shortly.  Remember that the way WEP works is that everybody on the same WEP access point uses the same WEP key, and that that allows you then to decrypt all of the traffic on the access point.  So even though this is encrypted, it would protect you from Firesheep if the hacker did not have your password.  But it would not protect you from Firesheep if the person running Firesheep did have your password.



So in other words, in a public WiFi hotspot scenario, we could never recommend turning on WEP encryption as a mitigation to the threat because it would provide none.  In fact, Firesheep would work perfectly on a WEP-encrypted hotspot where everybody had the password in order to be on the hotspot because all the packets are encrypted identically and decrypted identically.



LEO:  So there you go.  Okay, there you go.  So really WEP is not a good solution because that's - we're talking about turning it on in public access points; right?



STEVE:  Correct.  And just to remind Paul that WEP is so badly broken now, in fact that was the title of one of our podcasts, that I think it takes 60 seconds to crack it.  So it's just...



LEO:  It's pretty easy.



STEVE:  Even if you didn't have the password, you could get in and then use Firesheep, yeah.



LEO:  Chatroom is telling me that Microsoft Security Essentials does flag Cain & Abel, the hack tool Cain & Abel, but does not flag the packet-sniffing tool Wireshark.  So there you go.



STEVE:  Oh, yeah.  I've got Wireshark everywhere.  And so I don't - yeah.



LEO:  Yeah.  Question 3 from Doug Johnson in Orem, Utah.  He suggests using WPA might not help much.  He says:  In your last episode you mentioned that turning on WPA solves the problem of session hijacking via insecure cookies, as Firesheep does.  This is a great step in the right direction, but it really isn't a cure-all.  Even with WPA turned on, networks are still susceptible to ARP cache poisoning.  Used in combination with Cain & Abel, Firesheep would still work even with WPA encryption turned on.  A malicious user can send instructions to other computers to tell them to direct all Internet traffic to their machine, and that computer pretends to be the network's gateway, at which point client isolation becomes meaningless, and Firesheep is able to capture all packets from targeted computers, just as if the network was unencrypted and had no protection.  The only real solution is for websites to force use of SSL for all authentication information.  Is he talking about the cache poisoning that was a problem in the TKIP version of WPA?



STEVE:  No...



LEO:  This is something else.



STEVE:  I want to, first, I want to acknowledge the last sentence of what Doug wrote:  "The only real solution is for websites to force use of SSL for all authentication information."  That's absolutely right, but we don't have that today.  We're going to wait a few months.  Maybe we'll get it from Facebook.  Who knows what Amazon's going to do, and so forth.  So I don't want anyone to misunderstand that I'm suggesting that turning on WPA solves the problem completely and forever, and that it's as good as or equivalent to individual websites really doing what they should be doing, which is protecting that credential which was negotiated during secure time, and they're spreading it around when you're not secure.  So I agree with his last line.



But he's wrong about the use of Cain & Abel with WPA.  And so this highlights a really good point, which is why WPA is so handy in this case.  And it's what makes it different from WEP.  With WEP, as I just said, all the packets are encrypted and decrypted with a single identical key.  With WPA, each client negotiates their own - it's called a Pairwise Temporary Key, PTK, on the fly when they associate with the access point.  When they connect up, they get their own pairwise temporary key, which is unique to their connection.  And everybody's got their own, and that's what's used for [indiscernible] the AES cipher.



So what Cain & Abel does, and what ARP spoofing does, which we've talked about, is it allows you to essentially make yourself look like the base station to a user so that their traffic comes through you.  The problem is, under WPA, even if you did that, and you can with WPA because it is an Ethernet protocol, which means there is a broadcast, there is the GTK, the Group Temporary Key, which is how broadcast packets are handled since there is a need to be running like Ethernet, and Ethernet has a notion of broadcasting, which is necessary for things like ARP to function because a station needs to say, hey, where's the gateway here?  So it needs to send it out without knowing where it's going.  It needs to just broadcast it out into, literally, into the ether, and allow the gateway to respond.



So WPA provides this Group Temporal Key as a means for ARP to function, which means that's exploitable by anyone using that access point.  So that would allow them to redirect somebody else's traffic to them instead of to the gateway.  The problem is, once the traffic gets to them, it's encrypted with their pairwise temporary key, which the attacker doesn't have.  He's got his own.  And so the only thing he can do, if he wanted to, would be to forward it on to the gateway, in which case he's really not a man in the middle, he's sort of a shuttle in the middle.  He hasn't achieved any sort of interception at all at that point because WPA does provide that individual encryption keying per station, which makes it very useful as a mitigation against Firesheep.  You turn on WPA, bang, Firesheep no longer works.



LEO:  All right, moving along.  You ready for more questions, Mr. Gibson?



STEVE:  You betcha.



LEO:  We're going to talk about WPA-NoPSK mode for WiFi, the Pre-Shared Key.  Steve, I just got done watching the Firesheep episode - our last episode.  Since WPA came out I always thought they should have an encrypted version of open access - oh, wouldn't that be a good idea - where you only have a secure connection to the access point, indicating with the SSID that it's open, something he would say called NoPSK mode.  Personally, I think we need to completely ban open WiFi and WEP and possibly require user access control even in order to connect to them, as it is in fact very insecure, especially now that we have a Firesheep plug-in.



Now, I can't see any more vulnerabilities with having NoPSK than telling everyone the password or making it the same as the SSID.  I think they need to add this to part of the standard - good luck with that, you know how long that takes - as we already have PSK and Enterprise 802.11x with a radius authentication.  Why not this one?



I want to make one final comment that this does not protect us against man-in-the-middle attacks where the WiFi access point is impersonated.  That's what we were talking about before; right?  The only way you could prevent this is to use trusted certificates that are already installed on the machine, as is done with SSL in the first place.  But I think it would still be a huge step forward in wireless security.  Does that sound right?



STEVE:  Okay.  So here's the problem.  This is the final piece of this complex puzzle with WPA.  If you don't have authentication - and authentication is the most, is the single critical thing that SSL and certificates provide.  It's the authentication that we get when we receive the certificate from the server that we check versus our own list of certificate authorities, validating that the certificate we received is legitimate, and was hopefully issued by a responsible certificate authority, that allows us to believe that the connection we have we can trust.  Without authentication, there is always nothing we can do about it, always a vulnerability to any kind of impersonation.  If you think about it, there just isn't a way to avoid it.  And WPA has that problem, even when it's encrypted.



So here's the vulnerability that exists if we tell open hotspots, like Starbucks, to turn on WPA.  I say it's better than not.  But here's why it's not perfect.  Someone listening in while a new user is connecting is associating with the access point; will be able to see all of the traffic going in each direction.  Which means that there isn't anything, fundamentally there isn't anything either the new user or the access point can know that the attacker cannot know.  So if you have an attacker who's able to eavesdrop from the beginning, think about that.  There's nothing either of the endpoints can know that the attacker doesn't because the attacker is equivalent to just being another user.



LEO:  Right, it's a participant.



STEVE:  Yes.  And so in practical terms, what that means is that the way WPA negotiates is that the access point invents a random number, generates a random number, and sends what's called the "anonce," a one-time use random number, to the access point.  The access point, essentially it knows what the shared password is.  So it generates a random number, its own, called "snonce," the station nonce.  And it merges that with the anonce, the access point nonce, and the password, and then digitally signs that and then sends the access point back its snonce.  So the access point, now, the access point knows the anonce that it sent, the snonce that was received, and it's able to verify the signature which was signed using the shared password, in order to verify that it wasn't interfered with in transit.



So the access point has the two random numbers, the one it generated and the one it got from the station.  The station has the same two random numbers, the one it generated and the one it got from the station, which allows them then to generate from that the pairwise temporary key.  And they're able to then encrypt everything under that.  The problem is an eavesdropper saw the anonce go to the station and saw the snonce come back from the station of the access point.  It can just assume that it was properly signed.  But since it has the password also, it can even verify the signature.  That is, if it's in from the very beginning of the conversation and is sniffing the traffic, although it has to do much more than Firesheep does, it's absolutely able to get that particular connection's key.



Now, an open access point is just unencrypted traffic flying everywhere.  So, I mean, that's what Firesheep leverages.  So turning on WPA I still say is very useful to do because you're bringing up encryption, and you're raising the bar much higher than it is now.  There certainly could be Firesheep Pro, which is able to watch stations associate and obtain their per-station pairwise temporary key.  You could even have a fancy one which deliberately goes in and disassociates a station, forcing it to reassociate, which would cause it to renegotiate a new key.  That way you could get the key for even existing stations.



So having everyone using the same password has the liability that, yes, there is still a way around it.  But that's, inherently, that's always going to be true unless you have authentication.  And the only way to add authentication would be, for example, to give the access point a certificate which the station could check.  And there we're talking about a huge change, way more than turning on a feature which all access points already have, but just have disabled by default.



So anyway, that's the one thing I wanted to say that I didn't get across last week, was that turning on WPA is not utterly absolute protection.  You could have Firesheep Pro, which would be much more involved and a much higher level plug-in to create.  But just turning on WPA shuts down Firesheep and brings up encryption, which I still think is a very worthwhile thing to do.



LEO:  Couple more questions, starting with Iain Cheyne.  Steve and Leo, want to share this very nice chart at DigitalSociety.org showing their analysis of their security under the Firesheep threat.  Basically it's a report card for online services, red being no SSL authentication.  And then they actually cover sidejacking and full hijacking...



STEVE:  Yeah, it's a really neat grid.  I wanted to let our listeners know.  There's a short little bit.ly link that we can just say it, it's bit.ly/cJ8Xig.  And that'll take you to this much longer URL at DigitalSociety.org, which is a cool analysis they did in lieu of Firesheep.  This was created in the wake of Firesheep to take a look at where major sites that are targets of Firesheep, like Amazon and Facebook and so forth, stand.



[http://www.digitalsociety.org/2010/11/online-services-security-report-card/]



LEO:  POP mail is bad unless you have SSL turned on.  SMTP, bad unless you have SSL turned on.  IMAP, bad unless you have SSL.  FTP bad.  So turn on SSL on everything, obviously.



STEVE:  Yeah.



LEO:  But a lot of these sites you don't have that as an option.  And so that's the really - that's the issue, isn't it.



STEVE:  Exactly.  And it's not under our control, as this next questioner asks.



LEO:  Right.  Moving along to our next question, Dean in North Dakota, he's asking about secure cookies.  I'd like to hear about ways for individuals to enforce cookie encryption.  Ah, there'd be a solution; right?  One possibility is, no surprise, NoScript.  In the NoScript options under the advanced tab is an HTTPS tab where one can enforce secure cookies.  NoScript tries to append a ;Secure flag to cookies.  I'd like to hear your advice on this or other solutions.  Thanks for a great show.



STEVE:  Okay.  So this is what I've talked about before.  It is possible for a cookie to be, when it's issued, when it's given to the browser, to be flagged as secure, meaning essentially that tells the browser, send this cookie back to me, the server, every time you make a query to the domain which qualifies, but only if you're doing it over a secure connection.  So the beauty of that is you don't have to worry about, for example, we've talked about SSL Strip, which is the man-in-the-middle attack that removes the S's from the HTTPSes, essentially turning an otherwise secure site into an insecure site.



In that case, even if the site was trying to be secure, but its cookies had been flagged as not secure, that is, had not been flagged as secure, then those cookies would be exposed any time a non-HTTPS query was made.  If you simply flag the cookies secure, the browser - and all browsers support this, it's been there from the beginning - will never send a cookie unless the connection is known to be secure.  So the problem is, if you turn that cookie, if you turn that flag on all cookies, then you would starve a site that wasn't expecting that of its cookies.



So the site would just be sending out the cookie.  NoScript would force the cookie to be secure.  But then, if the site took the browser back to nonsecure, the browser would say, oh, I can't send this cookie back because it's been flagged secure.  It's because NoScript flagged it secure.  The server didn't flag it secure.  So the browser's not going to return it.



So it's of some value.  It's the reason I never talked about it before is that I'm not really clear what this buys you.  If you knew that you were always using HTTPS, then if that site wasn't flagging its cookies secure, by all means, absolutely, that's a cool thing for NoScript to do.  But until we're always using HTTPS, it doesn't make sense.  And if we're not using HTTPS, then we don't have security anyway.  So it's kind of valuable, I mean, maybe useful.  But I would say use it with caution because you could find it breaks things.



LEO:  One last question.  And this comes from Robert Walker in Atlanta, Georgia.  He shares GitHub's post-Firesheep changes.  Steve, I'm guessing you're already aware of this.  But in case you haven't heard, check out the following.  GitHub, by the way, is where Firesheep is stored.  But it's used - don't think that it's somehow some spooky thing.  It's used by programmers all the time.  Even Apple uses it.  It's a place, a code repository where shared code can be stored.  Go ahead.



STEVE:  What I liked about this was that GitHub is one of the sites that Firesheep was aware of.  And so they said, whoa...



LEO:  Oh, I didn't know that.  Oh, that's interesting.



STEVE:  Yeah.  And so they said, whoa, we've got to fix this.  And so what they did was they made some changes immediately afterwards where they did exactly what we were talking about with secure cookies.  They flagged secure cookies, that is, essentially they created a session cookie for when you're not doing important things, and a secure cookie for when you are doing important things.  So they used to have just one cookie which was used universally, whether you were over a secure connection or not.  Now they've got two.  And the one that is over a secure connection is flagged as being secure.  So they have proactively made sure that they were going to be safe against this.  And I think I misspoke, Leo.  I meant the ToorCon, I meant that the ToorCon conference was supported by Firesheep.  I don't know whether GitHub is now.  But they said, well, we're not going to be caught out by this...



LEO:  Just in case, yeah.



STEVE:  ...because we're hosting this.  So we want to make sure we're safe against it.



LEO:  Yeah, yeah.  That probably is a good idea.  And you don't want somebody checking in as you and changing your code.  Actually has a huge security implication because a lot of code is stored there.  And if you weren't aware of it, and somebody checked in and put a bug in your code, I mean, and by "bug" I mean a trojan in your code...



STEVE:  Yeah, it's open source.



LEO:  Yeah, you'd have some problems.  I'm going to save Tom's Cocoon and Bob Bent's question about NASes for another time because we're out of time.



STEVE:  Sounds great.  We'll do them in two weeks.



LEO:  You can, of course, always visit Steve's site, GRC.com, for 16KB and 64KB versions of this show.  You can get the transcriptions there, so you can read along as Steve talks.  And of course that's where SpinRite lives, the world's best hard drive maintenance utility, a must-have for anybody.  If you've got a hard drive, you need SpinRite.  Lots of free stuff there, too.  GRC.com.  Steve, we'll be back next week.  Do we know what we're going to talk about?  I think you had a topic, didn't you.



STEVE:  The Benchmark.



LEO:  The DNS Benchmark.



STEVE:  The DNS Benchmark.



LEO:  Great.  We had to defer that last week for breaking news with Firesheep, and I'm glad you did.  Couldn't have been a more topical topic.



STEVE:  That was perfect.



LEO:  So thanks for your questions, folks.  You can leave questions for Steve at GRC.com/feedback.  GRC.com/feedback.  And we record this show, normally, when we're not delayed by a Facebook announcement, every Wednesday at 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC, at live.twit.tv.  Actually next week, because we're going to switch back from daylight savings time, I think then we're going to be at 1900 UTC.  I'll have to do my math later.  I'll let you do the math.  11:00 a.m. Pacific time.  And Steve, I thank you.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



LEO:  Bye bye.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#274

DATE:		November 11, 2010

TITLE:		Benchmarking DNS

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-274.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's security updates and news, Steve formally unveils GRC's latest freeware, the DNS Benchmark.  Steve explains the value of the program's many features and discusses the operation of this "long time in coming" freeware offering.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 274, recorded November 10th, 2010:  Benchmarking DNS.



It's time for Security Now!, the show that covers your security and privacy online.  And the man who does it for us, the great Steve Gibson from GRC.com.  Hey, Steve, how are you today?



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.  And you promised me that the recorders are running for this; right?



LEO:  Everything is recording.  Well, let's put it this way.  If you are hearing or watching this show after the fact, we recorded it.



STEVE:  I guess by default, yes, sir.



LEO:  Actually we missed - last week I [indiscernible], I was kind of flustered, and I forgot to record the show.  We did a whole show.  But one good thing, because we do stream everything live, one of our partners, Justin.tv, records everything.  Actually two of our partners do.  BitGravity also records everything.  So we're able to go to their site and get, not a super hot, not the highest quality, but as good as you would see if you were streaming it quality.  And so we were able to put out the show...



STEVE:  Yay.



LEO:  ...despite Leo's stupidity.  We had, you know, we had a backup system, and I don't know, I guess - that's embarrassing, isn't it.  The system that we had, which was recording everything, has failed, and we didn't put another one in place.



STEVE:  And I think I heard you mention yesterday that you're not now mentioning that by name because the people presumably who created it are a little sensitive to it being dissed for the fact that it keeps [indiscernible]. 



LEO:  Ah, yes.  We're talking - that's the "thing that we use."



STEVE:  The thing that shall not be mentioned.



LEO:  The thing that shall not be named.  I just, you know, I realize...



STEVE:  Is that the Tri-something?



LEO:  Yeah.  We use this to switch.  That's how I switch.  And it's really remarkable, I mean, given the cost, what it will do.  And we couldn't really do these shows without it.  However, because it's on 24/7, it does crash from time to time.  And I think the people who make it are a little sensitive to the fact that it crashes in public because it's not really designed to be used the way we use it, full-time, 24/7.  It's designed to switch a two-hour show, then go to bed for the night.  And we really use it like a hardcore studio.



And actually, what people don't know because TV seems so reliable is that television studios go on the fritz all the time.  That's why TechTV had dual studios.  We built two one-million, I think it was $1.5 million, studios for redundancy.  So if one goes down, you stay on the air.  If you're a network, you have to stay on the air.  We're running the whole thing on a $10,000 TriCaster.  But we are - eventually we'll get some redundancy.



So I'm excited about this week because finally we're going to talk about something you've been working on for some time.



STEVE:  Well, it's been a - it's a project that actually had its beginnings a long time ago.  Back in 2001, shortly after the 9/11 attacks, I was asked by the White House to explore the idea of a communication system for the Internet, which didn't exist at the time.  Well, the Internet existed, but something that could sort of, like, put out a flash announcement, an emergency sort of thing that could somehow deliver a message across a huge number of, or to a huge number of devices in a very, very short time.



LEO:  That was kind of prescient.  I mean...



STEVE:  Much faster than email, yeah.



LEO:  We could use that right now.  Everybody now carries a portable device with them.



STEVE:  And I remember you and Mark Thompson and I were walking around the streets of Iowa on October - I mean, after the September attacks, and in fact for that first Gnomedex that I keynoted.  And we weren't even sure if Gnomedex was going to happen because the airlines had been shut down for that purpose.  But and so what happened was I created something called DNSRU, the DNS Research Utility.  And I worked with a large group of people in GRC's newsgroups to experiment with the way DNS was working.  And although it wasn't directly relevant to the research I was doing, I sort of, while I was there working with DNS, I wrote sort of some benchmark-y stuff for DNS which did a sort of an initial job of benchmarking DNS servers.  And when I had finished with that work, I just sort of left this DNSRU in the state that it was, which was sort of, like, it wasn't ever meant to be polished and made public or anything, it was just sort of an internal tool.



But the people at GRC, hanging out in the newsgroups, just they kept it alive.  And, like, years would go by, and every so often someone would say, "Gee, you know, are you ever going to finish that?"  And I said, "What?  Why?"  Well, and the answer was always, "Well, there's nothing else like it."  And so, like, the people who, like - we had switched over to using Level 3's famous DNS servers - 4.2.2.1, 4.2.2.2 and so forth, up to .6.  And people who were sort of more on the guru side, they had continued to use this thing that was never meant for primetime because that's all there was.  There was no other way to do this.



And so a couple years ago, when the whole Dan Kaminsky DNS spoofability thing happened, and I jumped onto creating a facility for looking at how spoofable name servers were, I thought, well, I guess I ought to finish that old DNSRU thing.  Well, what happened was it acquired a life of its own, and it became a really beautiful piece of work, a piece of freeware that I'm really, really proud of.  And so I wanted to talk about the task of and the technology of benchmarking the domain name system and sort of introduce this to our listeners, which is now available for everyone for free.



LEO:  That is exciting.  Its debut in just a moment.



STEVE:  Yeah.



LEO:  Well, I'm looking at your show notes, and we have a few updates to talk about.



STEVE:  Yeah, not too much.  We are at or just past the second Tuesday of the month, which of course we all know means that Microsoft will have done something.



LEO:  Not much this time.



STEVE:  Not much this time.  And in fact the one thing that they didn't do is the one thing that they really wish they had, which was the very bad zero-day vulnerability in IE is becoming increasingly widespread.  And we got no fix for it.  I'm not surprised, though, because this caught them by surprise just, like, almost on the eve of this second Tuesday of November.  So there's a bunch of fixes for Office.  One is critical, where just previewing email in the preview pane of Outlook could allow an infection to load code and commandeer someone's machine.  So that's fixed.



Unfortunately, the big zero-day flaw, as I mentioned, in IE is still not fixed.  Several people, including Brian Krebs, noted that this has now been moved into one of the more popular all-in-one hacker kits.  So it's now in a toolkit.  So the use of this unpatched zero-day IE flaw is expected to increase greatly above the few targeted attacks where it was seen before a week ago.  And of course that's what we expected.  IE6 and 7 are vulnerable.  IE8 is not so much vulnerable.  Technically the flaw exists in IE8.  It involves a problem in the parsing of CSS, of the cascading style sheets on websites.  There's some token parsing problem.



And Microsoft has one of their Fixit updates, actually they have two different Fixit buttons for this.  But really, if you upgraded to IE8 - which I would at this point.  It's mature enough.  We're in IE9 beta right now.  I would say anyone using IE6 or 7 should just update to IE8.  It runs data execution protection, DEP, by default.  And that's enough to thwart this problem.  Even though technically the browser still has it, it isn't exploitable due to DEP locking this down.  It's doing exactly what it was intended to do.



So if for some reason you can't go to IE8, then you can turn on data execution protection for IE6 or 7 by manually turning it on.  Or you can use Microsoft's little Fixit thing to do that.  They also have kind of a funky other Fixit that involves CSS somehow.  But the problem is it may break some websites that you go to because they've, like, turned off the parsing for some aspects of CSS.  So I'm not so jazzed about that.  Of course you could also just not use IE, which would be a fantastic solution.  Switch over to Firefox or Chrome.  I would say that's an even better solution.  But for the sake of completeness, Microsoft's Knowledge Base that has these Fixit tools, it's support.microsoft.com/kb/2458511.  So again, that's support.microsoft.com/kb/2458511.  So that's where the little Fixit things are, if you're stuck with using IE6 and 7 for some reason.



And meanwhile, Chrome continues to sort of silently slide itself along.  Last week remember that I had noted that it had moved itself up to a big long number ending in .41.  This week we're at .44.  So the SANS Security Institute newsletter reported:  "Google has released patches for multiple unspecified vulnerabilities in its browser.  The vulnerabilities include two use-after-free errors, two unspecified memory corruption errors, a bad cast, an invalid memory read, integer overflows, and an out-of-bounds array access.  These vulnerabilities exist in [the] libvpx [library] and the code for handling text areas, XPath, fonts, and [Scalable Vector Graphics].  Some of these vulnerabilities may be exploitable for code execution if an attacker can entice a target to navigate to a malicious site."



So it's like, okay, well, so this is sort of the Chrome model is they're just quietly fixing these things in the background.  And I note that whenever I fire Chrome up, it knows what the latest is.  I mean, it's already updated itself to the latest and greatest.  So this is a different approach than Microsoft's lumping things together and dropping them sort of en masse on a monthly basis.  Google is just keeping Chrome up to date.  Interesting, Google paid a total of $8,674 U.S. for 11 of those 12 vulnerabilities.



LEO:  Really.



STEVE:  Broken out into the researchers who reported them.  Google has, as I'll mention in a minute, a bounty program where they pay developers for responsibly, which is to say quietly, reporting bugs to them that are found.  And they give them public credit and dollars for doing so.  Which is, I think, an interesting model that seems to be working for them.



And speaking of Google, there is a proof-of-concept demonstration out for Android's browser, the down version one, Android v2.1 and earlier.  And although we are now at 2.2, it turns out that at least two thirds of all instances of Android are still at 2.1 or prior.  And so a security researcher at a company called Alert Logic essentially got annoyed that this has been a long-known flaw in WebKit, which is being used by the Android browser, which has been fixed in 2.1, but it isn't fixed - I mean, sorry, has been fixed in 2.2 of Android, but not in down version instances, of which, as I mentioned, more than two thirds of the market still is.



And so this guy is saying, look, I want to put some pressure on Google to - well, and through the whole chain - to get these old problems fixed because a substantial market are still using those.  And in fact Gartner just came out with a report showing that Android is now the No. 2 mobile OS.  Symbian still has the first position.  But Android - I think they had, like, 38 percent of the market.  But Android is now up to 25.4, I think it was, with iOS in third place.  So it's really doing well.



And also, a company called Coverity apparently took a developer's build from the HTC website and ran their automated kernel-testing tool against it, and exposed hundreds of flaws, 88 of which they said were high risk.  And these are, like, buffer overrun, uninitialized variables, just sort of runs the gamut of different problems.  They've informed Google of all these problems and given Google 60 days to respond, saying that they will release nothing additionally about this for the next two months, giving Google a chance to look at these and figure out what they want to do.  But again, they're saying that they found a whole bunch of flaws in - and it's interesting, it's in the portion of Android which was inherited from Linux more than the newly written code, which seems to be in much better shape.



And, finally, Google has expanded the Bug Bounty program.  I was just mentioning it in Chrome.  They've expanded it to cover Gmail, YouTube and Blogger, that is, those web-based facilities; not Android, Picasa, and Google Desktop.  But anyone finding a flaw, and reporting it responsibly, in Gmail, YouTube, and Blogger, and that means cross-site scripting or any sort of CSS vulnerabilities, anything of any sort that is found, Google will pay $500 for, in addition to giving public recognition.  And in cases where the flaw is really severe or particularly clever, they'll pay up to $3,133.7, which seems like a strange number except that that's "leet."



LEO:  1337.



STEVE:  So they said, okay, we'll make it worth the people's time, if they come up with something really good.



Many people tweeted me today something that hit the news, which I actually knew about last week.  The folks at Anonymizer are in the process of finalizing something called "Nevercookie," which is an add-on to Firefox to deal with the Evercookie exploit, which our friend Samy Kamkar we've talked about now several times.  Of course the Evercookie was a disturbingly capable identity-tracking technology that used JavaScripting in all kinds of ways to squirrel away some sort of identity about a user everywhere possible in a browser.  And so the Anonymizer folks said, well, okay, let's block that with the Nevercookie.



I have a copy of it.  And my preliminary analysis says, yes, it's doing the job, although I told them I wanted to do a detailed packet analysis to get a better look at it.  And they expect to be releasing it here within the next few days.  Maybe we'll be able to announce its availability next week.  So it's just an add-on that will be available; as soon as it's available you will be able to add it to Firefox.  And it just forecloses all of those various things that the Evercookie is doing.  Which sort of seems like a good idea.



LEO:  No kidding, yeah.



STEVE:  Firesheep continues to be in the news.  I did a little refresh of the download page, and every time I look it's gathered another thousand downloads.  I think we're now at about 703,000 downloads.



LEO:  Geez.



STEVE:  703,000.  So we're well past the half million point, approaching three quarters of a million, and we're going to get there at the current rate.  Probably by the time our listeners hear this I would imagine we will be at, well, maybe almost.  But 703,000 at this point.



Briefly, last week, someone had produced a piece of response software which attacked Firesheep in someone's machine.  That is, it somehow put out packets on the network which, like, crashed it or something.  But by the time - and I read about it a couple places.  By the time I went looking for it to figure out what was going on and what it was about, it had already been taken down.  It had already disappeared.  So I think whatever, I mean, it sounded like a bad idea.  And I think it was so bad that it didn't last long.



However, there is something which is a clever response to Firesheep known as Blacksheep.  And Blacksheep is also an add-on to Firefox which detects the presence of somebody, anybody, using Firesheep on the network, like on the hotspot where you're located.  And the way it works is clever.  So it's called Blacksheep.  It's a Firefox add-on.  When you run it, it periodically, and you are able to configure how often it does this, it periodically creates a fake credential, that is, a fake account which it puts out onto the network, knowing that Firesheep will pick up on it.



LEO:  With a bogus cookie.



STEVE:  Well, exactly.  And so, well, and then what Firesheep does is, it's as if somebody had just come onto the network, for example, some new Facebook user.  So Firesheep, as Firesheep does whenever it sees that, it attempts to log onto that person's Facebook account to get their picture from their Facebook page to post it in the little buddy list that Firesheep maintains.  So what happens is Blacksheep detects that attempt to log onto the bogus account which it deliberately created and put out there sort of as bait.  So basically Firesheep falls for the bait.  Blacksheep detects that something fell for its bait and alerts you that somebody somewhere on the network is running Firesheep.



So the bad news is, of course, if you were a Facebook user, or Twitter or whatever, there's still a good chance that, in logging onto the network, getting onto the hotspot, you may have already exposed yourself.  But at least it does let you know that someone's using Firesheep.  And if you aren't a user of those services, but you're just sort of curious about the prevalence of Firesheep, you could easily run Blacksheep for a while, while this is all going on, just to have a little pop-up notice that, hey, by the way, somebody's running Firesheep somewhere on this hotspot.  So I thought it was a clever hack.



LEO:  Yeah, I like it, I like it.



STEVE:  And Microsoft is the first, that I'm aware of, responder to Firesheep for Hotmail.  They have just announced on their blog yesterday, and it is now available, an option to turn on pervasive SSL encryption for Hotmail.  So the Hotmail no longer...



LEO:  Yay, yay, yah.



STEVE:  Oh, yes.  Hotmail no longer only uses SSL for logging on.  You are able to turn it on so it will persistently use it and protect all of your email traffic, all the time.



LEO:  Excellent.



STEVE:  And I had a nice little note from a Security Now! podcast listener, actually a Jonathan D. Kramer, who's the director of technology at St. Mary's High School in Manhasset, New York.  He said, "Steve, I just wanted to thank you for your wonderful product, SpinRite 6.  I'm a loyal listener to your Security Now! podcast and have heard you talk many times about SpinRite.  Well, this week it happened.  After a weekend of thunderstorms and wild weather, I arrived at work to find a colleague at my door, sweating and explaining that his computer was dead.  When I went to investigate what was going on, I was horrified to find, or should I say hear, what his computer was doing.  There was chirping, buzzing, and downright singing coming from his hard drive."



He said, "Like Superman, I put my hands on my hips and said, 'I know what to do.'  Of course the fool had no backups.  Well, I downloaded the software, let it run, and it brought back his desktop.  SpinRite literally saved years' worth of his work.  Thank you for what you do for the industry, and keep up the great work.  Jonathan Kramer."  And thanks, Jonathan, for the great report.



LEO:  All right, Steve Gibson.  I'm ready to hear.  This is a program you've been working on since 2001.



STEVE:  Well, certainly not continuously.  But, yeah.  This is sort of - this is something that would not die.  And I was just, because I was back working on DNS stuff, when I was working on the spoofability analysis system that we'll be talking about next, and shortly, and because users, I mean, like GRC's newsgroup people had fallen in love with this funky, not-really-ready-for-primetime DNSRU thing that just sort of did some benchmarking on the side, I thought, okay, well, I'd invested already in a lot of that technology.  If I didn't ever finish it, then the world would never have a really good DNS benchmark.  And so I decided it is a useful thing to do.  There are expert users who want to know how fast Level 3 servers are compared to their ISPs.  We know that ISPs often have slow DNS servers because DNS is just sort of something you stick in a closet and you don't think about it, unfortunately, which is in fact why so many DNS servers are still exploitable for, like, the Kaminsky spoofability problem.



LEO:  Shamefully, but...



STEVE:  Shamefully, yes.  But also, for example, we now know that there are an emerging set of alternatives.  There's OpenDNS, which provides true value-added DNS services.  The question is, okay, how fast is that?  Am I sacrificing speed if I switch to OpenDNS, compared to my ISP's servers?  And we know that the Sunbelt Software people have got a security-enhanced DNS where it blocks you from going to known malicious websites.  Symantec is getting into it with something that they're calling Norton DNS.  And there's UltraDNS.



And then we have the other problem that we've talked about where many ISPs are seeing DNS as a new revenue-enhancing model, where if you put in a typo, you don't get an error, but you get redirected to their own up-selling marketing page, where they're trying to turn your typos into some sort of revenue model for them.  So what they're doing is, they're redirecting errors.  So I thought, hey, it would be nice to be able to detect that, as well.



So it made sense to me that, I mean, I could understand why GRC's newsgroup mavens were saying, hey, you know, we'd really like a finished DNS benchmark product.  There seemed to be a lot of different things to do.  And then we were talking recently about this whole DNS rebinding problem, the idea that a script in your browser could fool your browser's protection which restricts what that script can do by causing a remote DNS server to return your own IP as if it was part of that script's domain.  And in the process, that would allow the script to have access to your local resources, maybe your router or your own machine, which would normally be reserved only for it to act with its own source domain.  So this rebinding protection, I realized, hey, that's something that I could detect from the benchmark side.  So I ended up building all of this into this nice piece of freeware.



So it runs natively under Windows.  But we have a whole bunch of people who are UNIX users, who were involved in working with me on the development of this, over on sort of like on the testing and kibitzing side.  And so I spent some non-insubstantial amount of time making sure that this would run under Wine, and run under Wine on the Mac.  So you can use it if you're a Mac user, and you have the Wine-is-not-an-emulator emulator for Windows.  And it runs under Wine under Linux with no trouble at all.



I did write the whole thing in pure assembly language.  It is, with all the features that it offers, 163K in size, so really small for - when you look at what this thing does and see it running, the idea that it's 163K, I mean, JPEG images are much bigger than that these days, it sort of reminds everyone how much can be done in assembly language and how inefficient so much "modern" software has become.  It's also fully scriptable, so that people could, if they wanted to, like, run it in the middle of the night, run it a couple times a day.  It's able to export its results to a CSV, to a Comma Separated Values file, so that you can use it to, like, log the performance over time.  It's just got features coming out of its ears.



But primarily what I wanted to do was give users a useful sense for how fast DNS is.  And there are several different parameters for DNS performance.  There's how quickly you get a response when the thing you're looking up, the domain name you're looking up, is already in the DNS server's cache.  We've talked about DNS caching a lot, the fact that in fact this is the whole problem with spoofing is, if a DNS server can somehow have its cache poisoned, then it's got the wrong IP for a domain that you're looking up.  And so when you go to, for example, Amazon.com, your browser could actually be looking for www.amazon.com, receive the wrong IP, and be taken to somewhere completely wrong.  And so that's one of the main ways that very strong phishing can operate is this kind of cache poisoning.



So we know that resolvers cache.  The reason they do that is that they tend to be close to you, network-wise.  That is, most ISPs, probably all ISPs, provide a DNS server, the idea being that, since it's your ISP, in terms of networking distance it's very close to you.  And since the ISP has this hopefully large server, all of its users are using the same server.  So you would imagine that Amazon.com is already in the DNS server's cache because somebody else who's also a user among many users of a given DNS resolver, they will have within, like, for example, the last day asked for Amazon.com.  If it wasn't cached then, Amazon.com would be cached, the IP for Amazon.com would be cached, so that your request would then come from the cache.



So one of the things that this Benchmark does is it makes two queries for, for example, Amazon.com.  It makes the first one in order to make sure that it's loaded into the cache, and ignores the length of time that query requires.  Then it makes a second one to essentially know that that query will be in the cache.  It turns out that there is a bit in the response which indicates whether it was from cache or was not.  So the Benchmark verifies that that second query did come out of the cache because technically you could - that first query could occur just as the copy was expiring from the cache, meaning that the Benchmark would be fooled by the second query being cached rather than non-cached.  So I make sure that that doesn't happen.



And so that gives us a measure of how fast the performance is out of cache.  And we really weight that much more highly than non-cached queries because the theory is you're using a large DNS server, as I said, that many other people are going to be using.  So primarily I would imagine the huge majority of queries that an actual user is making will be coming from the DNS server's cache.  But it's certainly the case that some wouldn't.  That is, if you make a request for some obscure domain that is either - no one else has ever asked for, or they're asking for so infrequently that it tends to expire, or it may be that the domain for whatever reason has a very short expiration.  For example, there are domains that expire every hour because they tend to be victims of denial of service attacks, and so they're having to move their IP around from time to time.  Therefore they don't want DNS servers to keep an old copy of the domain records current for a long period of time.



In any event, what the Benchmark does is it deliberately asks a dotcom server for a known invalid machine.  For example, it might ask of Amazon.com, it would look for the domain, just some gibberish, 13 or 14 characters of gibberish, .amazon.com.  It asks a DNS server for that, knowing that it cannot be in the cache because it just made up this machine name.  So your DNS server looks to see whether it's there.  It isn't because it's a completely unique name, which forces the DNS server to go ask the Amazon.com server whether it knows the IP for this.  The Amazon.com server will say, no, that's an invalid name.  But that allows us nevertheless to measure the length of time required for this particular DNS server to reach out onto the Internet for something not in its cache to any of these various dotcom servers.  So that's the non-cached lookup parameter, which the Benchmark measures separately.



And finally, I also ask for - I have the Benchmark ask for a gibberish name dotcom, which is to say a primary dotcom domain that does not exist.  What that forces it to do is to go ask the dotcom servers, which are one level up in the DNS hierarchy, whether they've ever heard of this dotcom domain name.  Which again, they won't have, because we just made it up.  But again, it gives you another measure.



Essentially, both of those last two, the non-cached lookups and the dotcom lookups, are a measure of how well connected this DNS server is to the Internet because on one hand you want to know how well connected it is to you.  And the cached lookup measurement gives you that.  But you also want to know how well connected it is to the Internet.  It could be very close to you, for example, being your ISP's DNS server.  But it might have a really clogged, buggy, slow, whatever, bad connection to the Internet, meaning that anytime you ask it for something it doesn't know, it's going to take a long time to get that reply back.



So the Benchmark measures essentially three parameters of performance - the cached lookup, the non-cached lookup, and the dotcom lookups, independently - and shows you in a very nice graphical display how this group of name servers that it checks compare with each other.  It also measures the reliability of all of these name servers in response to the queries.  Basically, it knows how many queries it's issued to each name server, and it looks to see how many responses it gets, looking to see whether the name server may be dropping them, and having a problem with reliability.



So we have a built-in list of, I think it's about 70 sort of well-known name servers, which we test against 50 very well-known domains.  So, for example, I actually got the list from Alexa's list of top domains:  Google.com, Yahoo.com, YouTube.com, Live.com, Facebook.com, MSN, Wikipedia, Blogger, MySpace, Yahoo.co.jp, Baidu, Google.co.in, Google.de, Microsoft.com and so forth.  So basically the top 50 most popular domains on the entire Internet.  There were some that I had to remove because they were sort of questionable domains, things that you might feel self-conscious having a program running in your computer going and asking the IP for.  Adult content websites were removed just for the sake of propriety.



So once we've got that, though, there's another question that comes into play, which is I can rank and do all of these resolvers, which are built into the Benchmark.  The Benchmark has, as I said, about 50 very well-known resolvers - a bunch that belong to Cox, Google's two resolvers 8.8.8.8 and 8.8.4.4, the OpenDNS resolvers, UltraDNS, the Symantec Norton resolvers, sort of all of the ones that are very popular, all six Level 3 resolvers.  The idea being that you want to see how those compare, not only to each other, though, but also to whatever ones you're using.



So the Benchmark determines which resolvers your system is using, and benchmarks those right alongside this other list of very well-known, sort of publicly known popular resolvers.  And it ranks the ones your system is currently using relative to all these alternatives to see whether switching to one of these alternatives or one or more might make sense.  But the question is, even if we get sort of average values which appear to indicate that one resolver is better than the other, the question is, is it reliably better?  That is, is it statistically significantly better?



So the Benchmark goes beyond just taking average values.  What it wants to do is it wants to verify that we're sure that the 50 samples we took create statistical significance.  For example, say that we took five measurements, and that a given resolver came back with a rating of 50, just 50, where faster is a lower number; and this was, like, 50 milliseconds to respond.  If we did five measurements, and they were all 50, well, we'd have a strong confidence that if we took another five measurements, they would also all be 50.  So we could say, okay, this is the performance of this resolver with very low sampling error, that is, high confidence that, if we sample again, we're going to get the same thing.



But say that we took five readings that were 10, 30, 50, 70, and 90.  Well, the average of those five is still going to be 50.  But our confidence is much lower now that, if we took five more readings, like a different five readings, that we'd still get an average of 50.  We might get, since we saw that one sample came back at 10, well, we might get 10 five times, or we might get 90 five times because we've seen a big spread in the return.  Well, statistically there's a measure known as a standard deviation, which is a measure of the spread of samples around the average.  The Benchmark takes that into account, and it tells you whether it would make sense with 95 percent confidence, that is, it's able to say we are 95 percent confident of the following conclusions.



And in fact, one of the nicest things that the Benchmark does is there's a lot of data being presented in bar graphs, and there's also a tab that gives you a sort of a detailed statistical analysis, all the numbers that back up all the data that's being shown.  But I wanted to also simplify this for the typical user.  So there's a conclusions tab where, once the Benchmark is finished, in English, I basically do all the work for the user of figuring out what this means.



I heuristically, using a bunch of algorithms, write in English a set of conclusions about what the Benchmark found, telling you, for example, whether you're using resolvers which are redirecting errors and not returning them to you, but sending you to a different page; noting, for example, that X number of publicly available resolvers are with 95 percent confidence faster than the ones you're currently using, whether the ones you're currently using are faster than all the known alternatives.  Basically, I do all the work of interpreting these results in English so that anyone can just look at the conclusions tab and read down and see what it was that the Benchmark found.



And then lastly, near the point that this thing was finished, Google announced that they were getting into the DNS business with their two resolvers, 8.8.8.8 and 8.8.4.4.  They also hosted somebody's program called Name Bench, which was a benchmark that was hosted on the Google code codebase.  People thought that it came from Google because it was located there.  But it's not an official project of Google.  I had the people in the newsgroup who were testing my benchmark program try Name Bench.  And the conclusion was that it really was really not ready for primetime.  Basically, it crashed everybody's routers, which...



LEO:  Oh, that's not nice.



STEVE:  Not a good thing to do.  What happened was it sent out so many queries that it overflowed the NAT routing table in the routers.  And it just took - it knocked everybody off the Internet.  One thing that it had, though, was pretty cool.  Thanks to it having access, I guess, to some resources from Google, it had thousands and thousands of DNS servers.  That is, it had a list of some 4,400, I think it was, DNS resolvers.  And so I thought, well, okay.  What if there's some good ones in there?



LEO:  Right.



STEVE:  So I made an experimental version of the Benchmark, mine, because I normally had it set up so that you could benchmark 200 at a time, figuring, wow, that's more than anyone's going to need.  We're benchmarking, I think, 70.  But you do have the ability to set up a custom list, like of your own resolvers, that you'd like to benchmark.  You may have, like, some corporate resolvers that you want to test.  So you're able to add those and then save an .ini file, an initialization file, so that the Benchmark will automatically load those back in every time you use it.



So I made a temporary, just sort of a real hack to expand the number of resolvers that could be benchmarked to 5,000.  And this is not something you would ever want to do because it takes a long time to run.  But what we found was there were obscure resolvers that no one had ever found before, or that we didn't know about.  Every single person who did this found some surprises.  So I thought, oh, shoot, you know.  I've got to do something with this because, I mean, basically this meant that there was a huge list of potentially better resolvers than a given user might know about.



So I took the list, we added a bunch that we knew about, and I ended up with 4,854 global resolvers.  Because one problem was that the list that the Benchmark has tends to be a little U.S.-centric.  I mean, it's Level 3 and OpenDNS and Cox, and it's clearly biased toward the U.S.  But I wanted the Benchmark to be useful to people in the U.K. and in Australia, everywhere, globally.  So I added a complete new feature to it where, in a separate phase, a user of the Benchmark is able to build their own custom list of resolvers to benchmark out of a master list which GRC maintains.  So the GRC server has a master list.  Currently it has this 4,854 global resolvers.  And you're able to ask the Benchmark to build from that list a custom list for you.  It takes a while.  It takes, like, 37 minutes because we're literally going out and sending five performance tests to every single one of 4,854 possible name servers.



LEO:  Wow.  All right.  So you got 4,500...



STEVE:  4,854.



LEO:  Awesome.



STEVE:  What happens is, when you run the Benchmark the first time, and it uses just the built-in default list of 70-some well-known servers, that'll give you a good sense for how the DNS servers you're currently using, whatever you've got configured, whether it's your ISP's, or your system is using your router, and Lord knows what your router's using, whatever it is, it'll compare that to this well-known list of sort of U.S.-centric resolvers.  When it's done, it pops up a notice and says, hey, I notice that you're just sort of using the built-in list, which is fine.  But there are resolvers all over the place, some which may be much better for you.  The one thing we learned is nothing matters more than distance.  So...



LEO:  Oh.  So you want a resolver that's geographically close to you.



STEVE:  Exactly.



LEO:  Interesting.



STEVE:  I mean, it really, really matters.  And so anyway, this offers you the ability to build a custom list.  You only have to do it once, and it does take a while.  As I said, it takes about 37 minutes.  And, I mean, I've got all kinds of spinning numbers and flashing lights, and so it's entertaining while it's doing it.  You get to see the progress as it's going along, and how many of what it's found, and, like, what the fastest and the slowest that it's found so far are.  Once it's done, it sorts that entire list of 4,800-plus resolvers and takes the top 50 and builds for you an .ini file, this little initialization file, so that those are - and all the normal resolvers, all the resolvers on the normal master list, they're in there, too.  But you get the advantage of just an amazing potential DNS resolver database.



The other thing we do is the top 200 are sent back to GRC anonymously.  And that's something for privacy reasons you can suppress, if for some reason you don't want to have anything go back.  But it's useful for us because over time I would like to make that build-your-own-list process faster.  It annoys me that it's 37 minutes long.  You only have to do it once, but still it would be nice if it were a lot quicker.  What I'm doing by having the Benchmark send back anonymously the top 200 is I'm counting how many times those resolvers were useful to anybody.  Because certainly there are some that are just in this master list that are never useful to anybody.



So after about a year, maybe, I'll take a look at this database that we've accumulated, and I will throw out all the ones that, for example, never even made it into the top 100, or maybe even into the top 50, depending upon, like, how the distribution of them turns out to be.  That will allow me to hugely reduce the global resolver list and forevermore speed up the process of people producing this personalized list.  But so once this is done, the Benchmark then has a customized list that will be different, I mean, truly different for every single person who uses it.  Very different in the U.K. than in Australia, than in Singapore, than in the U.S.  And what our users found is surprises.  When they then run the Benchmark against that, they find faster resolvers than they ever knew about before.  So it really is a learning experience, as well.  Some of them you may not want to use.  I mean, it might say John's Muffler Shop or something.



LEO:  Well, I'm getting, for instance, the top right now is NTT America Technical Operations.  That's the Japanese phone company.  Now, I don't know if I'd want to use their DNS.  Now, Google is still pretty high on the list.  But you know who the highest is, Level 3.



STEVE:  Yeah, Level 3 does perform very well for a lot of people.  And again, it's a function of where you are.  You may be geographically close to a Level 3 server.



LEO:  Right.  This is on the EFM network that you're on.  In fact, I think I'm breaking you up a little bit just by doing - does this use a lot of bandwidth, or no?



STEVE:  It was a tradeoff for me.  The problem is, you wouldn't want packet collisions to lower the reliability.  Nor would you want running a benchmark to, like, get in its own way.  So it's self-throttling.  There's a lot of time was put into the development of this.  But frankly, I'm really proud of it.  It's just, for 163K, all assembly language, more than anything I'm happy that it's done.  It's got...



LEO:  Now, are you allowed to use whatever you want?



STEVE:  Yeah.  Well, that's the other thing.  I mean, these are all publicly available DNS servers.  So...



LEO:  They don't have to make them public.



STEVE:  They don't, exactly.  Anybody who wanted to could easily lock them down so they're only available to smaller networks, or only to their own users.  In fact, some people may find, I show red ones where they're just not available at all.  So some people will find, for example, that, like, Cox DNS servers are not available to them, whereas they are for other people.  And in my case it happens that Cox has a couple of very fast ones near me, even though I'm not a Cox user.



LEO:  I'm getting Neustar.



STEVE:  Ah, that's the name for UltraDNS.  That's UltraDNS's new name.



LEO:  What is UltraDNS?



STEVE:  They're a commercial DNS provider.



LEO:  Well, they're fast.  Wow.



STEVE:  Yeah.



LEO:  Yeah.  NTT is still number one.  Then Symantec Corporation.



STEVE:  Yeah, Symantec's server is very fast for me, too.  Which is interesting.



LEO:  We may be on Level - you're on Level 3.  I may be on Level 3, as well.  So maybe...



STEVE:  Actually, I'm not.  GRC is, but I'm on Cogent's bandwidth.  So, yeah.  And people will find that their mileage varies, that it varies from - based on where they are.



LEO:  You may prefer OpenDNS for the features it offers.  And by the way, OpenDNS is right in there in the top 10, along with Google.  And Google I do because I can remember 8.8.8.8 and 8.8.4.4. easily.  So I use Google whenever I can't remember anything else.  And I use...



STEVE:  And Google actually is on Level 3's bandwidth.



LEO:  Ah, no wonder they're coming in so close to each other.



STEVE:  Yeah.



LEO:  Yeah.  And OpenDNS I use because I use it for the filtering for my family.  And it's certainly better than my Internet Service Provider, which isn't on the list at all.



STEVE:  Do you see some little green or blue rings around OpenDNS?



LEO:  Let me look.  I see green rings around NTT and Level 3.  OpenDNS is, no, it's just a neutral beige or orange.



STEVE:  Okay.  The reason I ask is that OpenDNS does have that feature which allows you to do DNS rebinding attack prevention.  And if you turn that on, you'll see it.  This Benchmark does detect when servers have DNS rebinding protection in them.  But what's interesting is it tests both over IPv4 and IPv6.  And OpenDNS is only blocking IPv4.  And I'm hoping, one of the things that I'm hoping is, as this benchmark becomes more well-known and popular, that it will exert pressure on providers, like OpenDNS, I'm sure they'd like to close down the fact that you can bypass their DNS rebinding protection just by using an IPv6-style query, and you still get back a private IP, which you can't get over IPv4.



LEO:  So now I've run it.  And it says "Consider creating a custom name server list for yourself."



STEVE:  Okay.  And so if you click that...



LEO:  And build custom list.  And so it's going to build a list based on the results, the 72 resolvers who have the best performance in what I just ran.



STEVE:  No.  It starts from scratch.  It's going to scan all 48 - it just pulled a master list, a current master list from GRC.  And it'll now run through all 4,800 of those, showing you also elapsed time and how much time it's anticipating it'll take.  So that'll be counting down.



LEO:  How big were the differences between the best and the worst in your tests?  I mean, is there a significant difference?



STEVE:  Yeah, really significant.  I mean, we don't have time to let this run right now because it'll take about 37 minutes.



LEO:  Right.



STEVE:  But you will find resolvers you never knew about that are, like, around the corner from you somewhere that somebody has open and available.



LEO:  Isn't that great.  Well, I'm going to - yeah, I won't keep this running because it's also eating your bandwidth, I can tell.



STEVE:  And if you do click the Conclusions tab, you'll see that from having run the Benchmark, it'll, like, give you a summary in English of, like, exactly what it found.



LEO:  Really neat.  Really, really a neat project and a fun thing to do.



STEVE:  Ah, and it's done.



LEO:  Well, somebody said that the best part about writing, like for a book, is having written.  I imagine it's true for programming, as well.  The nice feeling of completion.



STEVE:  Completion.  I'm glad it's done.  It's a beautiful resource.  It's free for everyone to use.  I think people will get a lot of benefit from it.  And there's a ton of web pages on GRC to back it up.  I've got complete, thorough documentation for the entire thing.  So I think it's a nice resource now for the Internet.



LEO:  Well, that's great.  Well done, Steve.  Thank you for nine years in the making.  The DNS Benchmark, it's done.  It is good.  Thank you, Steve.



Steve Gibson is at GRC.com.  That's where you'll find 16KB versions of this show, along with the 64KB versions, along with the text versions because he gets the great transcriptions done, along with show notes, along with DNS Benchmark and all his other great stuff.  But you know, you can take advantage of Steve and do all those free things.  But if you do, it wouldn't be a bad idea to buy a copy of SpinRite, too, because that's the world's best hard drive maintenance utility.  It's fantastic.  Recovery, too.  People often wait till they need it for recovery.  Get it now to maintain your hard drive so you never need the recovery part of it.



GRC.com.  Follow him on Twitter, @SGgrc.  And next week we'll be doing a Q&A session.  And I'm sure there are people with questions about this and all the other things we talk about.  So if you go to GRC.com/feedback, you can ask your questions there.  GRC, Gibson Research Corporation, GRC.com/feedback.  And Steve Gibson, thank you for being here.  We'll see you next week.



STEVE:  Oh, we should just mention, too, that you can find the Benchmark just in the menu under - if you go to GRC.com, under Freeware, and then Utilities, and there's the DNS Benchmark, so.



LEO:  Very good point.  We almost left them to find...



STEVE:  Easy to find.



LEO:  It is easy to find.  Hey, you know, we're doing - because I'm going to take the week after Christmas off, and most of our shows are going to go dark, and we were doing "best ofs" for a lot of the shows.  In fact, if you go to TWiT.tv/bestof, you can vote for the "best of" for TWiT, for TWiG, MacBreak Weekly, and just something you remember that happened during the year that you liked, anything that happened in 2010.  And we were going to do it for Security Now!, and then we realized, wait a minute, we don't need to.  There's one episode of Security Now! that stands above all others.



STEVE:  Oh, I know which one.  How fun.



LEO:  One episode that should be repeated every Christmastime, every year.



STEVE:  How fun.



LEO:  You know what I'm talking about, the Portable...



STEVE:  I love it.



LEO:  ...Dog Killer.  And I want to thank the person who sent me an email saying, well, you're going to rerun that; right?  I said, solves that one.



STEVE:  Perfect.



LEO:  So on, I don't know, December whatever that is, I think Christmas is Saturday, so whatever that Wednesday is following Christmas, in between Christmas and New Years, I'm not going to be here, most of our shows are dark, a few won't be.  I think Sarah says "I'm doing a show, darn it."  So I think, I imagine they will be on.  But most of the other shows will be in "best of."  And Steve Gibson, everybody can hear the Portable Dog Killer episode.  That'll be great.  Thanks, Steve.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#275

DATE:		November 18, 2010

TITLE:		Listener Feedback #105

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-275.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 275, recorded November 17, 2010:  Your questions, Steve's answers, #105.



It's time for Security Now!, the show that covers your privacy, your security, your online safety.  And the man, the myth, the legend, Steve Gibson is here from GRC.com.  Steve is the guy who discovered the first spyware, coined the term "spyware," wrote the first antispyware program.  He long since handed that off.  He's probably thanking his lucky stars right now.



STEVE GIBSON:  I'm laughing that I'm the myth.  I'm not quite sure - the man, the myth, the legend.



LEO:  The man, the myth, the legend.



STEVE:  Every time you say "myth," I think...



LEO:  Hmm, what is the myth?  No, there's myths about you, Steve.



STEVE:  Okay.



LEO:  Many people think you wear steel underwear.  That's not true.



STEVE:  No, it's not.



LEO:  No.



STEVE:  Never has been true.



LEO:  There's myths about Steve.



STEVE:  Not even reinforced in any way.



LEO:  Steve is also the guy who wrote SpinRite, the world's best hard drive utility out there.



STEVE:  That's not a myth.



LEO:  That's no myth.



STEVE:  That's definitely true.



LEO:  That's all at GRC.com.  And of course we debuted last week your free DNS Benchmark program.



STEVE:  Yes.  It's been a big hit.  I have a couple little comments in the errata section today to share, just little brief things.  We've been seeing about 1,100 downloads a day, so it took off...



LEO:  Wow, that's great.



STEVE:  ...really nicely, yeah.



LEO:  Not as big as Firesheep.



STEVE:  Nope.



LEO:  And you could have written Firesheep, but I'm glad you didn't.



STEVE:  I'm glad for that, too.



LEO:  Yeah, this is a Q&A episode, so we have lots of questions, lots of answers.  We also have security news, security updates and so forth.  All right, Steve.  I see some errata, some stuff to cover here.



STEVE:  Yeah.  Well, we don't have too much in the update category, though I guess when weighed by the megabyte we actually do.



LEO:  [Laughing] Whoo, yeah, this is a big patch.



STEVE:  Oh, my goodness.  I love that it's the "Double Oh Seven" (007) patch.  It's the seventh patch of the year for Apple's OS X.  And in my case, 572MB.  So over half a gig.



LEO:  Yeah, mine was like that, too.  I couldn't believe it.



STEVE:  Yeah.  Well, 130 different security vulnerabilities.  Although, in fairness, 55 of them were in Flash.



LEO:  You know, it's weird, but I guess that Apple has taken it on itself to patch Flash, as well.



STEVE:  Yes.  Now, if people had patched Flash before this manually, then this would have been redundant.  But among this was a new copy of Flash Player that brings OS X current with where Adobe is with Flash.  So it was a huge update.  The Apple page that enumerates all these things just scrolls on and on forever and ever.  It brings OS X up to 10.6.5, or 10.5.8, depending upon whether you're back at the .5 or .6.  So, and that was now a week ago.  So I would imagine most Mac people have already encountered this.



For me, I turned this one little mini on that I use for our podcasts only once a week.  And I fired it up, and I knew this was happening because I had already encountered the news about this.  And it's like, oh, here it is, baby.  And so luckily I turned it on a few hours ago so that it was able to download this thing and update itself and get going.  So also there were fixes to QuickTime, Time Machine, Safari, just pretty much across the board, 130 different vulnerabilities patched.  So the 007, seventh patch of the year.  Probably the last big one, I would think, given here we are mid-November.



And then the other important one was that Adobe has fixed their - this was the patch to v9 which we knew they were going to be coming out with.  We've been following this for the last couple weeks as Adobe's been trying to do this out-of-cycle patch to get Reader updated.  So this is the v9 of Reader, which was lagging behind their fixes for v10 and of Flash, all of which they had already patched.  So if people were back on v9, then just yesterday from when we're recording this, so let's see, we're recording this on the 17th, so on the 16th they released their v9 catch-up.  So they're now current with this zero-day vulnerability which had been seeing a lot of exploitation.



In news, the U.K. has backpedaled a little bit from what we discussed, it was in the last couple weeks we talked about the U.K. passing the Digital Economy Act, which among other things, remember that it had that three strikes, then you're disconnected from the Internet provision.  Well, now they're saying, whoa, whoa, whoa, wait a minute, you know, yes, that's in the law.  But I guess it caused a lot of furor over there.  So they're saying that they're not going to be disconnecting people, that technically there's a provision for that, but they really don't expect to be actively pursuing that.



LEO:  Good, good, good, good.



STEVE:  Yes, that is good news.  The still-unpatched zero-day IE6 and 7 flaw, we've talked about this weekly now because last week we mentioned it had made itself into some of the most popular hacker kits, and it's seeing more widespread use.  I picked up a little note that it had appeared, that the exploit for this had appeared on Amnesty International's Hong Kong website, such that people who went to the Hong Kong website of Amnesty International using IE6 or 7 would get themselves infected because there's no patch for this yet.  Still no word from Microsoft about when they're going to get this done.  This came out just after the second Tuesday of November, so it caught Microsoft off-guard.  And they're still saying they don't feel this is a big enough deal to do an out-of-cycle patch.  So we'll see if this gets worse before the second Tuesday of December, when let's hope they get this thing fixed.



A little bit of news is that Sweden is considering legislation to require ISPs to retain all of their customers' email and cell phone text messages for six months.



LEO:  What?



STEVE:  I know.  We keep seeing these data retention legislation threats floating around.  And I hope that the legislators understand the burden that this creates.  I mean, it's easy for them to sit in their council chambers and say, yeah, let's have everyone - let's require everyone retain everything for six months.  But, I mean, that's a huge technological burden to impose on, like, just out of the blue on a carrier, which is what an ISP is currently.



They may be doing some filtering.  We know, for example, that ISPs block various ports.  For example, I know that the cable modem provider here in Southern California, it blocks the traditional dangerous Windows ports 137, 138, 139, and 445 that were the file/printer-sharing ports.  They also block 25, which is SMTP, to prevent, to some degree, bad things from being able to be used for spamming, botnets and so forth for spamming.  But it's very simple from a technology standpoint to block traffic on a port.  I mean, it takes nothing.



It's a whole different scale of obligation to ask an ISP to intercept, which is what they have to do, and record all of the email transactions, and in this case cell phone text messages, of all their customers, to hold them for six months, and then somehow age them and let them go away after six months.  So this is, again, let's just hope this doesn't happen.  This would be a bad precedent to have.  I mean, bad not as much from a privacy standpoint, I mean, that's a problem, too.  But mostly just it's a phenomenal, from a technology standpoint, a phenomenal change to impose on ISPs.  So I just - I hope this just doesn't happen.



LEO:  Didn't the FBI put those Carnivore, or propose to put those Carnivore boxes in?  And as I - the Carnivore did the collection and aggregation itself; right?  It was kind of less of a burden on the ISP.  They just had to pipe stuff through it.



STEVE:  Well, and it wasn't doing everything.  So it was a tap where they were able to say, we want to start monitoring this particular customer.  And so it would filter out traffic to a given customer and feed it off.  So, I mean, and so that's being done in real time.  It's being stored elsewhere.  It's not saying to the ISP, we want you to record everything for six months so that we can later come back to you and say, oh, we'd like all the email of this particular person.  So, yeah, it's a whole different scope of obligation, so [shuddering].  I think that the legislators get very cavalier about this idea.  It's like, well, Google is indexing the whole Internet, so why can't you store all the email from all your customers?  And it's just like, wow, there's no infrastructure in place for that.  That's a huge, huge deal.  So let's hope it doesn't happen.



One million Chinese cell phones have been infected by something that they're calling the "zombie virus."



LEO:  Oh, great.



STEVE:  It masquerades as an antivirus application, which users have installed.  It then propagates by text-messaging links to itself to everyone in the infected phone's phone book.  So this thing spreads like wildfire.  It is currently costing Chinese users, because it sends texts to premium text messaging, it's costing Chinese users an estimated $300,000 U.S., equivalent in yuan.  $300,000 U.S. per day...



LEO:  Crikey.



STEVE:  ...is the cost.  And so it's just sort of a little cautionary note.  I've seen some commentators talking about this, saying here's - it's like, yes, that's happening over in China, so it's not affecting our listeners in the U.K. and Australia and in the U.S. and so forth.  But this is bound to happen.  This is going - it's not a matter of if, but when.  And so our listeners who are security conscious, I would just say when you're looking at your new phone, and you're thinking, wow, isn't this cool, this is a computer, and you're looking at the application stores which are available, ask yourself, do I really need this, and how long has it been around?



We know that new things tend to cause more trouble than old, proven things.  So, sure, it's fun to download all these toys onto your phone.  But with every one of them, they're taking up space, they're in that phone's ecosystem.  And if they're brand new, there just isn't any way for everyone, for the people who are hopefully vetting these to some degree, to actually know what this can do.  So just use caution.  Just use your best judgment, I would say.



LEO:  It's just a matter of time before we get something like this.



STEVE:  It's going to happen.  I mean, we're seeing bits of this happening.  Applications are being taken away that are found to be behaving badly.  They haven't done anything like this yet, but they certainly can.  So it's, as you say, Leo, it's a matter of time.  I would hope that our listeners won't get bitten badly by this.  And this particular thing also sends all the SIM card data from the phone, texts it back to some server somewhere of the people who created it, basically allowing them to take over your phone.



LEO:  Did this get installed, I mean, that's a lot of phones that got on it.  Did it get installed by people downloading a rogue app?



STEVE:  Yes.  It started as - it's masquerading as an antivirus.



LEO:  Oh, that's why it got so many people.



STEVE:  Yup.  They installed it, thinking, oh, this will be really good.  And then it propagates by sending links to itself to people that they know.



LEO:  Oh, here's an antivirus you ought to have for your phone.



STEVE:  Exactly.



LEO:  One million people is a lot of people.  I mean...



STEVE:  Coming from someone you know.  Yeah, it's a huge infestation.



LEO:  It's huge, yeah.



STEVE:  Meanwhile, Symantec has been very patiently continuing to reverse-engineer the Stuxnet worm.  And finally we're beginning to see some really interesting data.  I've resisted drawing any sweeping conclusions because there were lots of things being said early on, before there was really ever any justification for it, from a standpoint of what the Stuxnet worm does.  Well, now we have enough specific information that you really can begin to say with a reasonable degree of certainty that this was targeted at Iranian nuclear enrichment.  It really looks that way.  Symantec has...



LEO:  But it did have to affect the Siemens equipment; right?



STEVE:  Yes.  Well, even more specifically, it turns out that - and it just takes time.  It takes time to reverse-engineer the code.  They don't have the source.  They're looking at the object code which has been disassembled back into the assembly language.  They have to, of course, it's not just Windows, but it's the specific Siemens process control technology.  So arguably, or I'm sure it's the case that Symantec has experts on Windows and Mac, but probably not on Siemens process control hardware.  So they had to reverse-engineer that, figure out what it was doing.



So now they know, for example, that it targets something called "frequency converter drives" which are power supplies, crystal-controlled, digital-controlled power supplies whose frequencies can be set.  And the frequency of the power supply drives process control motors.  It intercepts commands to vary the speed of these motors wildly, but only intermittently.  And only if this thing, now that we see how the code works, only if it was in a plant's network, where it found at least 33 frequency converter drives made specifically by manufacturers Fararo Paya in Tehran or Vacon in Finland would it come to life.



So, again, it's incredibly narrowly targeted.  And it only targets frequency drives from those two companies that are running at speeds between 807 Hz and 1210 Hz, which are the speeds that the uranium enrichment centrifuges run at.  So it looks like it's absolutely certain, I mean, as much as anyone could be, that somebody who really knew what they were doing, I mean, this is not hackers, random script-kiddy-type people.  I mean, this raises the bar and lends further credibility to the people who are stating that this really looks like state-level actors, I mean, government-type empowered people were in fact targeting Iran's nuclear enrichment facility.



LEO:  Wow.



STEVE:  And it was also noted independently that I think they had - I remember a number like 4,300 centrifuges.  And for an unspecified reason, about a third of those went offline.  They were taken offline.  And so as I understand it, the way this worm infecting the process control of the enrichment process, it would cause these centrifuges to appear to be malfunctioning.  So, like, they would bizarrely run at very wildly different speeds, like as low as two cycles, which would basically shut it down.  It would just sort of stop.  And then it would spin up to a much higher speed than it's supposed to go.  And so somebody looking at this would think, okay, this is broken, and turn it off.



And apparently about a third of these 4,300 total centrifuges were taken offline during this period of time.  So it looks like it was effective, unfortunately.  Now, of course, it's all public knowledge, and it's been unearthed.  So I'm sure that they've cleaned this off their systems and are back to work.  But that does look like, I mean, with something this specific, I think it's clear to be able to say now that's what Stuxnet was about, was it was targeting that specifically.



LEO:  That's pretty amazing.  I mean, and what great detective work, too.



STEVE:  Yeah, yeah.  And a lot of work to pull that kind of thing off.  Oh, I had three little notes.  When I pulled today's mailbag to get caught up on all the submissions that people have had, it wasn't till afterwards that I realized, wow, I didn't see any feedback about the DNS Benchmark.  And then I looked again, and I realized that something had interrupted the hundreds of pieces of email that I was downloading, and stopped like a week ago, just before last week's podcast, that is, stopped in terms of the dates of the email submissions.  And so I grabbed a bunch more, like, just half an hour ago, and there was another couple hundred.  And there were lots of people who were talking about DNS stuff.  But I had already found three little pieces of feedback.  So I just wanted to share them as errata, to basically encourage people to take a look at the free, completely free Benchmark that we discussed last week, if you hadn't.



One guy wrote, the subject was "DNS Benchmark - U.K."  And he said, "In a word, marvelous.  I'm going to inform everyone I know about this.  Configured my home router and all computers to use the same Primary and Secondary resolvers after running several custom benchmarks.  Amazing difference.  Without this tool, I thought I had a marvelous broadband connection.  It has been an eye-opening experience, and page-refreshes and loads are visually better without any need for precise measurement.  It made such a difference.  Thank you, Steve."



Someone else wrote, "163K worth of digital voodoo magic.  Loving DNS Benchmark, enabled me to optimize my network further.  Found a lot faster DNS servers than OpenDNS."  And finally, this third guy said - his subject was "DNS Benchmark success."  And he said, "Hi, Steve.  I often listen to Security Now! and always enjoy it when I do.  Today I watched the live podcast and heard DNS Benchmark mentioned, so I gave it a whirl on my Linux machine at home.  Home is Dublin, Ireland.  The tool found 40 servers faster than my..." current default, which was 8.8.8.8, so that he was using Google's DNS.



LEO:  But of course Google in the states, probably; right?



STEVE:  Yeah, although I would expect Google to be...



LEO:  They have a big Irish facility.



STEVE:  Yeah, exactly.  Anyway, he said, so 40 servers faster than that, "...and the fastest was, surprisingly, my ISP's.  I say 'surprisingly' because I moved away from using their DNS server last year because it was taking one to two seconds to resolve many IP addresses.  Obviously they have fixed their problems.  Thanks for an interesting and useful tool.  I work in an electronics engineering company.  Pretty much everyone in the department I work for has configured their machines to use some other public DNS server, not the company one.  It'll be interesting to see who has chosen well.  Cheers."



LEO:  Very good.



STEVE:  And then I wanted to make a note about a beta of Google Chrome which caught my eye, just also in errata.  This is still beta, so it's not in the normal production Chrome stream.  But Chrome is adding, that is, Google's Chrome browser, now in the beta stream, has their own PDF document display, which I thought was really interesting.  In their posting they said, "With every Google Chrome release, we hope to bring new features and improvements that will make your life on the web speedier, simpler, and more secure.  Today, we're excited to introduce the integrated PDF viewer to the beta channel.  PDF is a popular file format that's used for delivering documents on the web (such as the IRS W-4 tax form)" - that's sort of an odd example, but that's what...



LEO:  Well, it's something probably people use more than anything else.



STEVE:  Yeah.  "To open a PDF document, you'd typically need to install additional software or a browser plug-in in order to view it in a web browser.  With the integrated Chrome PDF viewer now available in Chrome's beta, you can open a PDF document in Chrome without installing additional software."



LEO:  That's awesome.



STEVE:  Yes.



LEO:  You know, Google does that in Gmail.  They have a viewer built into Gmail.  I'm sure it's the same code.



STEVE:  Yes.  "The PDF document will load as quickly and seamlessly as a normal web page in the browser.  Just like we do with web pages viewed in Chrome, we've built in an additional layer of security called the "sandbox" around the Chrome PDF viewer to help protect you from malware and security attacks that are targeted at PDF files.  For now, the Chrome PDF viewer is available only in the beta channel, but we look forward to adding more polish and features, as well as making it widely available in the stable channel soon."



LEO:  That'd be great.



STEVE:  So I just think that's definitely a hats-off.



LEO:  Yeah.



STEVE:  And I know that you're now using Chrome as your main production browser.



LEO:  All the time, yeah.  On Mac and Windows.  I just love it.



STEVE:  Yeah.  I'm still - I'm so hooked on the Firefox ecosystem, with so many add-ons that I'm liking, like hierarchical tabs down the left-hand side and other goodies.  But I also like, I have to say, I like what Google's doing with Chrome.



LEO:  Chrome has Flash built in, too.



STEVE:  Yes.



LEO:  But Adobe, I don't know how much Adobe likes what Google's doing with Chrome.  I mean...



STEVE:  Yeah, they're basically commandeering their plug-ins and building them into their browser, and then sandboxing them to make them safe.



LEO:  Smart.  So of course Flash is Adobe's code.  But is the PDF Reader Adobe's code, or is it Google's code?  Did they say?



STEVE:  Good question.  No, they didn't say.  That's the entire content of their posting.



LEO:  Interesting.  I bet it's their code, since they have a - but who knows.  Maybe they're licensing something, I don't know.



STEVE:  Apple, we know that Apple does their own rendering of PDFs; right?



LEO:  Yeah, because PDF is a standard.  An open standard that Adobe - I don't know if Adobe owns it, or if they're giving it away.  I'm not sure exactly what the deal is with that.



STEVE:  Yeah.  I did have an interesting bit of feedback about SpinRite.  This is a little longer than usual, but there's an interesting lesson here that occurred to me after I read this.  And this just came in on November 8th from Paul Oaten.  He said, "Hi, Steve.  I'm an IT...."  Oh, and the subject was "SpinRite saves the linguini."  He said, "Hi, Steve.  I'm an IT guy in business for myself, listener since Episode 1 of Security Now!, and SpinRite owner.  As well as doing break fix jobs" - and I don't know, he doesn't spell it like "brake" as in fixing someone's brakes, but I'm not sure what a break fix job is - "I'm also a web designer.  Six months ago I took on a new website client.  She's a wonderful Italian chef with a passion for cooking and food writing, but not very tech-aware, and she wanted to share all this with the world via a new blog.  I duly created a custom site for her, and it now has over 400 posts, all of which are well-written, entertaining to read, and extremely practical.  She's using the blog as a promotional tool for her upcoming book."



LEO:  I hope he gives the address of this.  I want to go now.



STEVE:  Well, we originally had it, but she objected to being portrayed in this light, so we have removed it.



LEO:  All right.



STEVE:  So he says, "She's writing a blog as a promotional tool for her upcoming book.  Trying to attract a publisher can be enormously difficult.  When I visited her house, I discovered that she was attempting to write blog articles on a very old and tired laptop which really was not up to the job.  A deal was struck, and I provided her with a brand-spanking-new HP G72 laptop with a nice, big, bright screen and large 320GB hard drive.  As I was setting up the new laptop in my office, I noticed my copy of SpinRite sitting on a desk.  I always keep it handy nearby.  It occurred to me that I ought to run SpinRite on the laptop before delivery.  Sadly, however, time did not permit this.  And also, hey, what could possibly be wrong with a brand new drive; right?



"About two weeks after delivering and installing the laptop to a happy customer, I got a phone call from a very distressed cook, who was now not able to boot the laptop, and who was staring at a message on the screen indicating imminent drive failure."



LEO:  Uh-oh.



STEVE:  "Mamma Mia," he says, "were the words used over and over when I told her that potentially all data, i.e., chapters of her new book, recipes, unposted blog articles, et cetera, might have been lost from the drive.  I collected the laptop, immediately removed the drive, and plugged it into a Linux box to see if I could access any data and hopefully recover it."



LEO:  Oh, she's lucky she knows this guy, I've got to say.



STEVE:  Yeah, this guy knows what he's doing.  He says, "A worrying Linux message told me that there was no way to mount the partition, so I plugged the drive back into the laptop and reached for my SpinRite disk.  My heart beat a little faster when the laptop refused to boot from the SpinRite disk.  I then loaded SpinRite onto a bootable Flash drive and eventually got it running.  SpinRite recognized the partition and got to work.  Almost immediately the DynaStat screen appeared.  Not good.  After two days, SpinRite had completed 0.983 percent of the drive."



LEO:  Now, does it work on the - go from the inner to the outer?  I mean, is it going in order?



STEVE:  Yeah, it starts at the beginning.



LEO:  So it makes sense it would hit system files early on.



STEVE:  Yes, yes.



LEO:  So I bet you this happens a lot because, when it's not booting, people then go, oh, it's the system.



STEVE:  Yeah.



LEO:  So I bet you that's when you often get those long delays.



STEVE:  Right.  And it means that it often gets the work done that it needs to...



LEO:  Right away, yeah.



STEVE:  ...quicker rather than later.  So he says, "Not good.  I let SpinRite run a few more days, all the while fending off frantic inquiries from the Italian cook by telling her that if anything could recover the data, SpinRite could.  After seven days straight, I looked at progress."



LEO:  Oh, she must have been crazed by this time.



STEVE:  Oh, yeah.  "Seven percent of the drive had been processed..."



LEO:  Oh, it'll only take three months to get the...



STEVE:  Yeah, "...and there had been multiple unrecovered sectors.  I decided to halt the process and try one last time to access the drive via my Linux box.  Guess what?  Despite the many unrecoverable sectors, I was able to recover all the documents now, and most of the photos, from the drive.  Fantastico," he says.  "The drive is now being replaced by HP under warranty.  My chef has her data back.  And I'll be getting a fancy Italian cake as a reward."



LEO:  I'd want more than that.  I want a whole meal.



STEVE:  Yeah.  He says, "Thanks, Steve."



LEO:  I've been looking at her pictures.



STEVE:  He says, "Thanks, Steve, for a great podcast that never fails to impress me.  Ciao.  Paul Oaten in Bath, U.K."



LEO:  Oh, he's in the U.K., okay.



STEVE:  And then also, "P.S.:  It's great to know, when the aliens come, the U.S. government will be able to call Mr. Gibson to deploy his big green laser as a last line of defense."  Now, okay.  Given - the reason I've shared this story is I'm suspicious.  The drive was working probably just perfectly.  And it was serious, something really bad happened to it.  I'm suspicious that this thing got dropped.



LEO:  Yeah.



STEVE:  That it was - maybe there were a little too many things on the chef's cutting board, and the laptop got dropped on the floor, or it fell over, or something happened to it.  Because, I mean, for it to have gone from just fine and brand new, I mean, yes, it's the case that a drive can be flaky from day one.  But this just - it's too suspicious that it took seven days to get 7 percent; SpinRite was finding all these problems after two weeks.  I just think that this thing got some abuse, and SpinRite did everything it could.  Luckily, it was enough to get the critical management portions of the partition recovered so that he was able to get these files off, which probably nothing else would have been able to do.  But still, you see something like this, and you think, okay, this got dropped.  And in that case, you're doing the best you can to get anything from a drive that's in that kind of shape.



LEO:  Right.  He was very fortunate.



STEVE:  Yeah.



LEO:  All right, Steve.  I've got questions.  I know you've got answers.



STEVE:  We've got some great feedback from our listeners.  So let's do it.



LEO:  Let's get to it.  Starting with Question #1 from Jon H. in Excelsior, Minnesota.  He wonders about mixed security.  Steve, I'm wondering if you can comment on the security implications - you see this warning a lot - of mixing secure and insecure elements on a web page.  Obviously, fully secure would be best.  But is it reasonable to send most or part of the content securely, but then send image content in the clear?  Or is there no way to do this that doesn't compromise the session cookie?  Your podcast is a great resource and has clarified numerous details of encryption techniques, best practices, and vulnerabilities.  Thank you both for the years of great content so far.  I can look forward to hearing more.  Best regards, Jon.  So we see this in the browser.  It'll say, just wanted to warn you this page has a mix of insecure and secure content.  What does that mean?



STEVE:  Yeah.  What that's telling us is that the page itself, the base page was secure.  And some elements of the page which the browser then fetched were not.  I don't think you get that warning if the base page is not secure, but some of the things that are on the page are secure.



LEO:  Right.



STEVE:  I don't think it works the other way.  I think it's only saying that this page has said that it wants its contents to be secure.  But remember that the way the browser works is we first load the base page.  That contains the HTML, which then has references to other assets, like images and other chunks of text, the cascading style sheet, other things which the browser then separately goes out and fetches in order to assemble the whole page.  So the idea is that, if those references refer to insecure things, then what Jon is asking is, is that a big deal?



Well, we know from this whole Firesheep escapade that what browsers are often doing, what websites are doing with the browsers, is not keeping the session cookie secure.  So the other way cookies operate is they're sent by domain.  So say that we're getting a page from Amazon.com, as a site that is typical of having many other assets that are being loaded on the page, all those little pictures and chunks of menus and things that Amazon is loading.  So the main page comes from Amazon.com and is secure.  And with your logon information, after logging onto the server, there would be a cookie which is always being sent, every time your browser notices that it is requesting something from the Amazon.com domain.



So the problem with insecure pieces, which might also be coming from Amazon.com, is that when your browser asks for those, it will send the session cookie.  It'll send whatever cookies it has from Amazon.com unless they were marked as secure.  So cookies can be marked as "this is a secure cookie, only return this to the domain if it's over a secure connection."  So if somebody were deliberately trying to, for example, minimize their use of SSL, then they could mix the security of the page if they were careful to make sure that the credentials were only being exchanged over a secure connection.  And that would mean flagging those credentials as requiring security, that is, flagging that cookie as only send this over a secure connection.



The problem, however, is that then users of the site that had carefully and deliberately made itself sort of optimized so that the page was being secure, the credentials were being secure, but other assets were not, were deliberately being insecure, every time the user brought up such a page, they'd be getting a warning from the browser saying, oh, warning, this page has mixed security content.  So that would be concerning the user  that maybe this is a bad thing, when it fact it was deliberate, and it was being safe.



So it would be nice, and there is no such protocol for this, but it would be nice if there were a way for a page to say to the browser, like with a response header, in the same way that the server sends a cookie to the browser, if there were a response header that said, hey, this is a deliberately mixed content page, don't bother anybody about that.  Now, that's a safe thing to do because you could require that that header only be honored if it was being received over an SSL connection.  So you wouldn't have to worry about it being injected or inserted by a man-in-the-middle attack over a nonsecure page.  You could say, only if this page comes to us via SSL securely, and if there's this extra flag in there saying this is deliberately mixed content, don't bother the user about it, then I could see how that could be a nice addition to HTML, or the HTTP protocol, that would allow this kind of optimization, but wouldn't be sending off warning messages all the time.



LEO:  All right.  Question #2.  You never know [laughing].  I never know if there's more.  Mark Cyrulik in Oshkosh, Wisconsin wonders about network masking on networks.  Whatever that is.  Steve, I lived in an apartment complex that gave us free Internet while we lived there.  It's all past tense.  I guess he's moved.  They ran the switches and the connection, and all we had to do was plug our devices into a wall jack.  In trying to share music with my roommate, however, we ran into a lot of problems because the admin had done something I'd never seen before.  He had set up the DHCP server to give out IP info as such:



IP Address: 10.1.3.24

Subnet mask: 255.255.255.254

DNS:  10.1.3.1

Gateway:  10.1.3.1



So the gateway and the DNS were the same.  What I found very interesting was that he had set up the subnet mask in such a way that your computer thought it was the only computer on the network.  So 255.255.255.254 allows for one IP address.  And I was not even able to see any other machine on the network.  I know you mentioned in 272 that Starbucks could enable WPA2 as a partial interim solution to solving the Firesheep problem.  I'm wondering whether a solution like the one above could also help to solve that problem.  That's interesting.  I never thought of that.  So the subnet mask is set to allow but one IP address.



STEVE:  Yeah.  Actually two because...



LEO:  Yeah, you'd have to have two.



STEVE:  Yeah.  What this is doing, it was an interesting configuration.  So imagine an apartment complex where they're giving you free Internet access.  And as we know, a 10-dot network - so it's behind its own NAT router, there's a NAT router somewhere, probably a big one, in the manager's office somewhere, which is basically creating a 10-dot network.  And we know that that's 16 million IPs because the 10 is the first eight bits of the IP, and then the other 24 can be anything.  The first eight of the 32-bit IP have to be 10.  Then the next 24 bits can be anything.  So that's 16 million IPs.  So of course there aren't 16 million apartments, nor 16 million connections.



But so what they did was, if they simply set up a big LAN with a normal 10-dot network, there would be this problem that individual connections in different rooms and different apartments in this apartment complex were on the same 10-dot network.  So they could see each other, they could ping each other, and there was some connectivity there.  Now, probably they were using a switch rather than a hub.



LEO:  A managed switch, probably; right?  I mean, you'd need some intelligence here.



STEVE:  Yeah.  Well, so the point is, if you just did a packet sniff on your connection, you probably were not seeing everybody else's traffic.  But you'd be seeing their ARP requests, which are broadcast, and a switch inherently broadcasts everything.  So you would see other machines on the network announcing themselves.  And with a little bit of cleverness you could get other IPs that other people were using.  You could play ARP games.  I mean, there are things you could do.



So what this particular installation did was interesting.  They, instead of - oh, and I should mention that on a normal 10-dot network, your subnet mask would be 255.0.0.0, meaning that the 255 portion of the subnet mask specifies the network, the so-called network number, which is 10.  And those three zeroes, the 0.0.0, say that all the other bits are variable within this 10-dot network.  Well, what this subnet mask does in this particular apartment complex is it's all ones except a zero at the very end, meaning that essentially every connection in the apartment complex sees itself on its own network.  It says, only my IP - and technically there's one other IP because the last bit could be a zero or a one, but probably they were always zero - essentially, only my IP is on this network.  So things like pinging other IPs would not work because they would, if you tried to - normally, if you ping another IP in your own LAN, then that packet is sent to the MAC address of that IP.  And if you're pinging an IP not on your LAN, then it's sent to the MAC address of the gateway.



Well, what this apartment complex cleverly did was they set a subnet mask that said there are no other IPs on this network.  So everything, if you sent anything to anywhere, it's going to go to the gateway.  So what that does is create some isolation.  Which I think is really very clever.  It's an interesting way of taking a large private network, which a lot of untrusted people are sharing, and allowing them, dividing this private network up so that it creates interperson privacy to a much greater degree than you would normally have.  All that said, he then asks, what does this do for, like, Firesheep and the Starbucks open network hotspot example?  And unfortunately, not much, because wireless is always like a hub.  And that's one of the problems is that...



LEO:  Right, right, right.



STEVE:  ...when you broadcast anything, everybody can receive it.  So this solution that the apartment complex used works because it's essentially created a very - there's a notion in LANs known as the broadcast domain, that is, when you broadcast, for example, ARP, an ARP request for, hey, who has this IP address, it's sent out to the broadcast IP of the network, which in this case would be - that's where the other IP is.  It's like all ones in the IP.  So whereas the IP, for example, was 10.1.3.24, the broadcast would be 10.1.3.25.  So even ARP broadcasts would be constrained within these little individual networks.  Not so in the case of using this approach on a wireless hotspot because you could still receive everything.



Now, it would be trickier to impersonate a person because you'd have to be - you're not all on the same network.  So you're on individual little networks.  But it does not provide you the same level of isolation that this does in the apartment complex, which actually is a very clever solution.



LEO:  But it has to be hard-wired to make any sense.



STEVE:  It's got to be switched, and that's the deal, is a switch.



LEO:  That's what a switch does.



STEVE:  Yes.  A switch isolates so that you're only providing traffic that is intended for any of the devices connected to that physical port.  And the switch itself learns which MAC addresses are connected to that physical port.  But if you were to use this system in the apartment complex on a hub, then you would see everybody else's traffic, even though they're all on their own little individual itty-bitty networks.  But still, very clever.



LEO:  Yeah.  That really is the key to the whole idea of managed switches is to isolate traffic.



STEVE:  Right.



LEO:  But most hotels and other areas don't want to spend the money because switches aren't cheap.



STEVE:  Switches are much more expensive, yes, especially in a big, like in a large complex.



LEO:  Yeah.  And it's a VLAN.  It's a Virtual LAN.  Chris in London, United Kingdom, was shocked - shocked - by the WPA key setup.  Steve, I was amazed by your description of WPA's initial key exchange on the current Security Now! podcast.  Diffie-Hellman key exchange has existed for the best part of 30 years and is a straightforward solution to this problem.  Why don't they use Diffie-Hellman? 



STEVE:  Okay.  So what Chris was concerned about was when I explained that the reason that everybody sharing the same key still was a problem, I mean, it would encrypt connections, but if you had an attacker who was listening in, they would know everything that either party knew and be able to reconstruct a client's individual session key themselves.  Now, Diffie-Hellman key exchange, which we have covered in the past on this podcast, is a very clever means for achieving this without the vulnerability of anybody listening in.  So the way Diffie-Hellman works, just as a brief reminder, is you take some number and raise it to a power.  And then the other end takes the same number and raises it to a different power.  They exchange this intermediate result, and then they raise that to another power.  So the idea being that mathematically a given number, say X raised to the power of A, raised to the power of B, is mathematically the same as X raised to the power of B, raised to the power of A.  That is, the order in which you do these power functions is commutative.  It doesn't matter which way it's done.



So what that means is that each end is able to come up with a random number as their own power, raise the common number to that, exchange the intermediate result, which is all done modulus some other number - and that's the key, it's within what's called a "field" - and then raise the exchanged intermediate again to their random number.  And that's a way for them both to get the same result.  And somebody who is watching the conversation has no help here.  There's nothing they can do.  They can see these intermediate results go by, but that doesn't help them in order to - it doesn't help them because there's no way from the result of this number being raised to a power modulus another number, that they're able to determine what's going on inside of either endpoint.



Well, the reason this wasn't done is, as you can tell, it's complicated.  Also, these numbers have to be big.  The numbers that are being used, the random numbers that are chosen as the powers, have to be on the order of a hundred digits long.



LEO:  Yikes.



STEVE:  Yes.  So you're raising something to a power that's a hundred digits long.  Which is to say you're multiplying it by itself a huge number of times.  And the modulus, to be effective, has to be a prime number that's about 300 digits long.  The point is, this is public key technology.  And the one thing that we know is public key crypto is slow.  It's processor intensive.



So the reason the WPA designers, the people who were replacing the very badly broken WEP encryption, could not use public key technology is they had to have this stuff still able to run on much lower-powered hardware.  In order to make WPA practical to sort of upgrade low-end hardware, they had to use only symmetric crypto.  They could not use asymmetric crypto.  They could not use public key crypto, which is what Diffie-Hellman key exchange essentially is.  And that's the cost of public key crypto is it uses - it has to use really long keys in order to obtain its security.  And that means that it's going to - you only have to do it once.  For example, once these endpoints exchanged their keys in a normal Diffie-Hellman exchange, now they've got something that they can use for all kinds of other purposes during communication.  But you've got to do it once.



And the designers of WPA protocol just said, wow, we'd love to use it.  It was developed in '77.  The patent was issued in 1980.  So that's 30 years ago.  So the patent expired 17 years after that, so in 1997.  So it was in the public domain, that is, Diffie-Hellman key exchange was.  But even so, it's just too computationally burdensome to be able to retrofit older hardware and have it work.  So they had to use something.  Which really the only problem of using it is that there is this potential for it being sniffed on, which is a problem only in a scenario where you do know what the shared key is.



Remember that we're sort of creating a synthetic situation here with WPA.  Most people, like all of us who are using WPA at home, we know that we need to keep our key secret.  So we were suggesting that the key be made public only to get some crypto on the connections to defeat Firesheep as an interim measure until sites like Facebook are able to go 100 percent SSL.



LEO:  Well, speaking of Firesheep, nice segue.  Shawn Poulson in Middletown, Delaware talks about some of the challenges of going full SSL, which we have prescribed as a solution to the...



STEVE:  Ultimately, that is the solution.



LEO:  Yeah.  Steve, you made another great episode of discussion in the latest Security Now! podcast Q&A.  I enjoyed all the talk about the technology required to secure websites from Firesheep attacks, or basically cross-site cookie stealing, I guess.  I think you made a great point that SSL is not computationally expensive these days.  Google made that point for us.



However, as a web developer and having been part of a production deployment of a commercial website using a Content Distribution Network, or CDN, I can offer to you that switching to SSL is not always as easy as just throwing a certificate on your servers.  Site owners can be compounded with significant server and bandwidth costs.  If a site were just a handful of web servers, it would be as easy as installing certs and going full SSL.  However, some amount of additional bandwidth throughput will be utilized because browsers and intermediate caching proxies cannot cache secure content like it can with nonsecure content.  Browsers will temporarily cache in memory during a session.  Of course that's still allowed.  But afterwards it has to be thrown away.  Returning to the site under a new session requires redownloading all the images, scripts, et cetera.



Furthermore, when implementing a CDN, as Facebook has for pictures at sphotos.ak.fbcdn.net, certificates will not come cheap.  CDNs work like a giant distributed caching proxy server.  By the way, our files are all distributed by CDN, via CacheFly.  Actually, your audio is distributed - your video is through CacheFly.  Your audio is distributed by AOL.  But I'm almost certain AOL is using something, probably its own CDN.  A user hits a link hosted by a CDN.  The DNS resolves to a CDN edge server which is geographically close to the user.  That's the benefit of a CDN.



STEVE:  Right.



LEO:  The edge fetches the requested content from its source server at Facebook and caches it.  The edge server delivers the cached content back to the user.  Edge servers will synchronize caches to gain greater geographic coverage.  SSL caching at the edge is still possible because SSL is only between the user and the edge server.  The edge requests the content from the source server in a separate session, hopefully also using SSL.  Every edge server in the CDN needs an SSL cert installed for your hostname, and that could be hundreds, if not thousands of them, depending on the CDN provider.  It's true, everybody who's getting a video copy of Security Now! ostensibly from CacheFly.net is actually getting it from a different server.  There are servers all over the world.



If your organization requires the $1,000 per year VeriSign certs, that can quickly become cost prohibitive.  One alternative is that CDNs may offer a shared secure hosting wildcard cert with a shared domain name that may be free or cheap to use, for example, Facebook.somecdn.com.  That's an example, that's not an actual URL.



STEVE:  Right.



LEO:  My suspicion is Facebook needs to rearchitect their CDN infrastructure to avoid these excessive costs.  Hope this helps shed some light on the situation.  Thanks again for the excellent podcast.  That's a good point.  Is he right?



STEVE:  Well, he's absolutely right.  And the point that he also made about, even short of CDNs, for example, cable modem, we know that cable modem providers often have their own caching proxies, a transparent proxy such that when you're making requests, for example, for Amazon.com, many of Amazon's own page components are the same no matter who you are, no matter what user you are.  So if I use my cable modem to access Amazon.com, my own browser will cache a bunch of these pieces.  But the ISP's got its own cache inline, which is also caching.  So that if some other customer of the ISP pulls up Amazon.com, this transparent caching proxy at the ISP says, oh, wait a minute, this user has asked for the same image that that user asked for, so it provides it out of its own cache.  The ISP does that primarily because it saves its bandwidth costs.  It's not having to pay for as much transit bandwidth as it otherwise would, and the advantage for the user is that image is being served by the local caching proxy rather than remotely.



So the problem with all of that is, if the caching proxy is only able to see into non-SSL connections, that ISP's caching proxy, it's completely blind to anything SSL.  So if the page and all of the page's objects are over SSL, it can't proxy them at all.  It can't cache them at all.  So all of the fetches out from the browser to Amazon have to be direct and cannot be intermediately cached.  And so this is sort of a variation on the full-scale content delivery network, which is very much the same concept, but it's done explicitly by the website provider, like Facebook in this example, as opposed to sort of implicitly, and even in sort of a hidden fashion, helping the user's browsing experience and limiting the ISP's bandwidth.  So it is the case that there are bandwidth costs, and there is some performance hit for pages that are providing all kinds of content because you're no longer able to cache them in any intermediate location.  It's always got to go back to the origin server in order to provide the content.



So he does make a good point.  There is some cost, not to the SSL connection, but to the fact that it does defeat caching along the way, unless you do something like, as he was suggesting, there are wildcard certificates.  I got one about a year and a half ago from GoDaddy that I've mentioned before, where it was *.grc.com.  And I learned quickly that it wasn't the same as *.*.grc.com, which is actually what I needed.  You can only have one level of uncertainty in that wildcard certificate, so it didn't end up serving my purpose.  But that is one way of defraying some of this cost.  But yes, there is going to be some performance hit, not from the public key aspect of SSL, but just from the fact that more bandwidth will end up being used.



LEO:  And for somebody like Facebook, which serves a huge amount of data, especially pictures, that's not insignificant, frankly.



STEVE:  Yeah, it'll be interesting when, I mean, I'll be interested to see, when they do this, how they do it.  And I'll probably take apart a Facebook page to see how they've solved the problem.  I imagine they'll be providing somehow SSL CDN content, which I imagine, I mean, I'll be they're working on it right now.



LEO:  I guess they wouldn't have to SSL everything.  You could have one of those mixed pages; right?



STEVE:  Yeah.  And that, again, that's why I really wish there was a means for a server to say, allow these non-SSL pieces, because there's no security downside to them providing images and other chunks of their, like, large chunks of their site that are going to be the same for everyone over a content provider that's not SSL.  But again, doing so would bring up that warning saying, oh, no, some of this is not secure, even though it's just not a problem.  It's by design.



LEO:  Couple more questions.  Question #6 from William McMahon in Toronto, Ontario mostly has a question about router DNS configuration.  Actually, maybe the "mostly" goes with the "question."  I don't know.  We'll find out.  Steve, I've been using your DNS Benchmark tool.  Great job, by the way, he says.  I'm a little curious about some of the settings.  I've never used a custom DNS server before and always just used my home router as my DNS, which uses my ISP's DNS servers in turn.  My network at home is running DHCP; so, as you know, it pushes the DNS servers as well, in my case the router gateway.  I was wondering if there's a way for my router to push the public DNS server's IP instead of pushing the router's gateway address to the machines in my home.  I can statically configure my DNS IPs on my router, but it still pushes the router's gateway address as the DNS IPs.  The only other way around this would be for me to go to each computer and manually type in the custom DNS servers I want to use.  But that's a pain.



Lastly, a comment.  Now that you're done with DNS Benchmark, you should have all the time in the world to work on CryptoLink.  Right?  Any updates?  I'm dying to hear more.  William.



STEVE:  Well, actually that mostly was that he had a SpinRite testimonial at the beginning.



LEO:  Ah.



STEVE:  And I thought, okay, we've talked about SpinRite enough.



LEO:  So here's a happy customer.



STEVE:  So I cut it out, and I forgot to remove the "mostly."  So...



LEO:  Now we know.



STEVE:  So that's what that was.  Okay.  So most routers, I can't say all routers because it would be up to the router manufacturer, but to sort of clarify what he's saying, he's saying that he's used the Benchmark, and he's found better DNS servers than the ones his ISP is providing.  And that's often the case.  So he knows he could go and manually configure those DNS servers in all of the computers in his network.  But what if he changes his mind?  He uses the Benchmark tool in six months, and he finds different ones.  What he'd like to do is have his router provide those to his computer, rather than have his router always provide its own address as the IP which his computers use for their DNS.  And I concur.  It really is a better thing to do.  It's not clear to me that there's a tremendous benefit for, like, routing your DNS through the router.  And in fact, as we're going to learn next week, there are reasons not to because it turns out that some routers crash when being asked to do just regular DNS.  So...



LEO:  Really.



STEVE:  Yes.  I have seen, in the routers I've looked at, there is typically a setting that allows you to turn off sort of this router proxying.  It's just, it's not caching.  It's not powerful enough to really add any value to DNS.  All it's doing for some reason is giving you its IP as DNS.  I believe that our own endpoint client machines do a better job with having two DNS servers than the router providing it only with one, meaning its own IP.  So, William and other listeners, I think, if you look at your settings, you'll often see a setting that says "Use router for DNS."  That you can turn off, and then you can still manually configure which DNS servers you want it to offer to all the machines in your network.  And that's, I think, the optimal configuration, once you've got the IPs of the DNS servers that you want to use, which of course GRC's Benchmark provides.



Oh, and as for CryptoLink, I've got some more stuff I need to do before I start CryptoLink, which is just as well because I am seriously perturbed about the FBI and what Congress may be doing relative to requiring wiretapping technology in anything like this.  I'm hoping that a standalone product which just provides endpoint encryption would not be subject to this; whereas something like GoToMyPC or Skype, which is involved as a third party, I could see where they may have a requirement to provide that kind of wiretapping.  But, yeah, I'm hoping that something that isn't a third-party involvement, and CryptoLink won't be, it'll just be point to point, I'm hoping that would not fall under this kind of legislation.  It's hard for me to imagine that it would.  So I've got my fingers crossed.  But I do have other things to work on in the meantime.  I'll be getting to it as soon as I can.



LEO:  I'm just looking at the configuration of our D-Link router here.  I think this is maybe where I would do this.  It says at the bottom, DNS in advanced settings, use these DNS servers.  And you can see I've put in the IPs for OpenDNS.  I presume that that means, don't use me.  But I don't know.  I'll have to - would it be in the DHCP section?



STEVE:  Well, yeah.  Now look at your own computer and see what the computer using the router, does it have the gateway IP, or does it actually have the OpenDNS IPs?



LEO:  I see.  I see what you're saying.  All right.  I'm not sure I want to waste everybody's time doing that.  But I will check and report back.



STEVE:  And that's what our listeners can do.



LEO:  Yeah.  That's how you would know.  All right.  Moving right along.  Question #7 - oops - comes from Pete [laughing], listening in Rochester, New York.  He wonders about GRC's transcripts.  Steve doesn't know what happened there.  He's not watching.  So don't tell him.  I have a limp microphone.  Steve, I enjoy reading the PDF of the show.  Do you use a software program to transcribe from the audio recording?  And if so, could you please give us the name?  Great show, learned a lot about SSL from the Firesheep discussion.  What is the name of that software you use to transcribe, Steve?



STEVE:  It's fantastic software, Leo.



LEO:  Isn't it good.



STEVE:  It never makes a mistake.



LEO:  Never.



STEVE:  We can fumble around and humble and mumble, and one way or another, even our misspellings get fixed for us.



LEO:  Isn't it amazing.



STEVE:  Yes.  The software's name is Elaine.  On-Site Media is the name of the company that Elaine is [elaine@on-sitemedia.com].  And she's been doing all of our...



LEO:  Transcriptions.



STEVE:  ...all of our transcriptions from day one.  And so, Pete, unfortunately, if it were software, boy, it'd be really popular because it'd be fantastic, but it wouldn't work nearly as well as Elaine does.



LEO:  We've all seen the lousy job Google does on YouTube transcription.  We've all seen - even if you watch TV, you can always tell when the closed captioning is done by a human versus a machine.  The humans don't do a great job, but the machines, really, it's ludicrous.  No, you need a human to do this right.  And, you know, Elaine charges.  Steve pays it, by the way.  Credit to Steve because he really wanted to have written transcriptions of the show, and so he pays Elaine out of his own pocket to do that.  So thank you, Steve.  [Elaine thanks Steve, too!]



STEVE:  Glad to.



LEO:  Finally, our last question.  Dave Solon, in Lancaster, PA, will share his podcast survey results.  Steve, huge fan of your podcast for years, along with This Week in Tech (TWiT).  I was wondering if you might help me out with a grad class research project.  I'm a K-12 Instructional Technology Specialist in Lancaster, PA, also an avid podcaster.  His show is TwentyForTech.com.  I'm a huge advocate for teachers and students to start their own podcasts.  As am I.  I set up a podcast studio for my kid's high school.  And I'd like to help guide them to create podcasts in formats that most folks like to listen to or watch.  I've developed a short survey to try to find some things out to help me in my quest for podcasting proliferation.  He'd like us to share the survey URL for the good of the education and podcasting community.  The page is davidsolon.wikispaces.com.  He says, I'll share all my data and paper after it's complete.  Thanks for your consideration.  And if Leo could share this study, I'd be forever indebted to you both.



STEVE:  So it's davidsolon.wikispaces.com.  And what I found interesting about this, I mean, first of all, the survey is neat.  I'd love our listeners to give him their feedback.  He promised to email it to me so that I could share the results back with our listeners.  So we'll close that loop.  But he used some Google spreadsheet technology.



LEO:  Yeah, we've used this.  We use this, too, for our surveys.  It's really great.



STEVE:  It's interesting.  I hadn't seen that before.  But I thought that was really neat, that you're able to use just a - somehow, like, simply format a spreadsheet and collect the data and see what everyone had done.  So...



LEO:  Yeah.  So it looks like a real survey, but then the results end up in a Google spreadsheet at Google Docs.  We're actually using - I'll tell you what.  This is his survey.  And once again, there's a short link for this, which is bit.ly/podcastresearch will take you right there, bit.ly/podcastresearch.  But if you want to take our survey, using exactly the same technology, we're compiling "best of" shows for the holidays, the week after Christmas.  Your show we've already got solved, that's the Portable Dog Killer.  But for TWiT and TWiG and some of the other shows, if you'd like to participate, tell us your best, your favorite episode.  That's TWiT.tv/bestof.  And it's exactly the same technology.  We embedded it in an iFrame on our TWiT site.  But this also gives us a Google spreadsheet.  It's powered by Google Docs.



STEVE:  Very cool.



LEO:  And kshep set that up for us.  So you can choose the four shows that we're doing best-ofs are TWiT, MacBreak Weekly, This Week in Google, Windows Weekly, and Tech News Today.  If you know the episode number or the air date, that'd be great; what time it occurred, that'd be great.  If not, just put what you know.  And we will thank you, and you'll hear the Best of TWiT then the week after Christmas.  Most of the shows are going to go dark for that time.  Including this one, but this one will not miss a show.  We've never missed a show.  We'll just provide you with a repeat of one of our favorite Christmas classics.  And you know what we could do, Steve, we could record a kind of an intro and some information.  In fact, even if you wanted to do the tech news and errata and stuff as an intro to it, you could update that part.



STEVE:  Okay, cool.



LEO:  Yup, the Portable Dog Killer.  It's the best.  Steve, you're the best.  Steve Gibson is at GRC.com.  His Twitter handle:  @SGgrc.  You can follow him there.  GRC of course is the home of SpinRite, the world's finest hard drive maintenance and recovery utility.  If you have a hard drive, you really ought to have SpinRite.  But lots of free stuff there, including the new DNS Benchmark and many other useful utilities.  GRC.com.  That's also where you'll find the 16KB versions of this show for the bandwidth-impaired; Elaine's great transcriptions; the show notes.  And if you want to ask a question, that's where you'll find the feedback form, GRC.com/feedback.  Do you know what we're going to do next week?  Is it a surprise?



STEVE:  Well, I do know what we're going to do because on the heels of the DNS Benchmark, the thing that actually was the stimulus for that was the revelation of how many DNS servers were vulnerable to spoofing that Dan Kaminsky provided.  And I created a complete, rather amazing, frankly, piece of technology at GRC which is a system which allows people to check the spoofability of their own DNS servers.  So GRC's DNS Spoofability Testing System is our topic for next week.  And lots of technology in that, so it's going to be a propeller-spinner.



LEO:  Yeah, that sounds fantastic.  Steve, you're the best.  Thank you for being here.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#276

DATE:		November 25, 2010

TITLE:		Testing DNS Spoofability

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-276.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's security updates and news, Steve and Leo revisit the continuing concern over DNS Spoofing by examining the technology behind Steve's quite comprehensive, free, online DNS  Spoofability Testing system at GRC.com.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 276, recorded November 24, 2010:  DNS Spoofability Test.



It's time for Security Now!, the show that covers your privacy, your security, everything you need to know to keep yourself safe online.  And this is the guy who does it, the guy to my left, Steve Gibson, the man behind GRC.com, SpinRite software, and a whole bunch of really useful utilities, including that DNS Benchmark that we talked about a couple of weeks ago.  Hey, Steve.  Good to see you again.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  Happy Turkey Week.



STEVE:  Yes.



LEO:  What are you doing tomorrow?



STEVE:  It's T-Day.  I have a few bachelor friends who are, actually, they're cooks, and I'm not.  And I'm not even going to supervise.  I'm just going to stay out of the way.



LEO:  Just show up, that's the best.



STEVE:  And none of us are going to deal with our families tomorrow.  We're just going to get together and make a nice meal.



LEO:  That's wonderful.



STEVE:  So it'll be very nice, and we'll deal with families on Christmas.



LEO:  I'm leaving as soon as the shows are done today.  We're going to drive down to Santa Cruz, where my father-in-law lives, and we're going to stay in a nice little hotel down there, and we're taking them to the hotel's restaurant for Thanksgiving.  So that'll be fun.



STEVE:  Simple.



LEO:  Simple.



STEVE:  Perfect.



LEO:  No dishes to clean.  The only negative, no turkey or stuffing leftover.



STEVE:  That's true.



LEO:  That's my favorite part.  I love those turkey sandwiches.



STEVE:  There will be sandwiches for us.  We have a 14.28-pound bird.



LEO:  Wow.  So, now, what is our topic of the day today?  I think we have something kind of interesting to talk about.



STEVE:  Oh, I think everyone's going to find it interesting.  We talked two years ago, actually about two and a half years ago, about the problem that Dan Kaminsky brought up when he realized that a huge percentage of the Internet's DNS services, the domain name servers, were much more vulnerable to spoofability than people recognized.  Around, I guess it was that summer, while this was being unveiled, around the Black Hat conference, I realized that, in a vein very much like ShieldsUP!, which has been around of course forever...



LEO:  And that tests your router for holes.



STEVE:  Well, yeah.  Actually it tests your connection.  So it's GRC's server.  It's a free service that of course GRC.com makes available where you inherently need something on the outside to be probing back towards you.  So I realized many years ago that it was a service that a website or a web server could offer.  Similarly, I realized that it would be possible to create a service that tested the spoofability in exactly the way that Dan Kaminsky understood it, and the way the industry came to realize, oh, my goodness, 25 percent of the DNS servers on the 'Net are currently very spoofable.  I realized that, similarly, a service could be created to check the DNS servers that people were currently using.



So in short, you could go to GRC.com, click a button, and my servers would check your DNS servers to see how spoofable they were and then produce a report on the fly, much as ShieldsUP! does, which provides you a complete diagnostic analysis of the way your DNS servers are behaving relative to spoofability.  So I set about creating such a facility back then.  And I've had various things that came up in the meantime, the Benchmark, and of course I got all entranced with PDP-8 technology, remember the old computers, and built...



LEO:  They're right there behind you, over your shoulder, yeah.



STEVE:  Flashing behind me and so forth.  And then of course the Benchmark that we talked about two weeks ago fit into this because it was about DNS.  And so essentially this is the other side of that.  The Benchmark is something you run on your computer to help you choose the right DNS servers.  But after having done so, you want to make sure that the result of that choice is not spoofable.  So then you use GRC's free DNS spoofability testing system to analyze the queries that those DNS servers you've chosen are emitting out on the Internet.  So today we're going to talk about how it does that.



LEO:  Sounds great.  Sounds very cool.  I'm kind of excited.  All right, Steve, I'm ready to start.  We will start first with, what, security updates, yes?



STEVE:  Yeah, we've got some updates and sort of some news, or some update news.  It's been a very quiet week.  The only thing that happened was that Apple did update Safari.  When I turned my Mac on this morning it said, oh, we've got a new Safari for you.  I think it was 37MB.  So we're now at v5.0.3 for both the Windows and the Mac platforms.  They fixed a bunch of vulnerabilities.  I saw the number 27 somewhere.  So they cleaned things up.  There were some things that were fixed also in Chrome's browser, I guess due to the WebKit commonality, that is, that they both use some of the same core libraries from WebKit.  I had read that four of the 27 flaws had been fixed in Chrome already.  So Apple was catching up and fixed 27 things.  So Safari is updated.



Also, just yesterday, the EFF introduced a new updated version, still at beta, I think it's 0.9.0 is their version, of their HTTPS Everywhere add-on for Firefox.  That's something which it's a little tricky because it involves some customization per site.  As we've talked about before, it's not possible to simply force every website to use SSL connections, that is, HTTPS connections.  However, many sites which don't explicitly do so, can do so.



So what the HTTPS Everywhere plug-in for Firefox does, and this was specifically updated to deal with Firesheep, which we've talked about, which is of course the non-HTTPS sniffing, session-hijacking add-on which has now been around for a month and a half or so, which continues to be downloaded, and people are getting up to no good with it.  It was created, as we know, to highlight the vulnerability of people using insecure websites which maintain their logon state in an insecure fashion.  So HTTPS Everywhere - which is a free download from the EFF, you can just put in "HTTPS Everywhere," and Google will take you right to it - now has been enhanced to support Google Search, Wikipedia, Twitter, Facebook, bit.ly, GMX, Wordpress.com blogs, The New York Times, The Washington Post, PayPal, the EFF's own site, TOR, Ixquick, and many others.



LEO:  That's most of the stuff Firesheep does; right?



STEVE:  Yes.  And so they literally, they went after those things that Firesheep was doing.  And they specifically worked on those sites which were vulnerable.  And so the idea is that you just can't force, you can't just stick an "S" on the end of all the HTTP's on a given site.  But individual sites can be customized with some scripting which the HTTPS Everywhere comes with and which individuals are also able to customize, in order to sort of understand the URLs, maybe look at patterns which can be moved over to SSL in order to increase the security.  So it is something that I recommend without hesitation to any user of Firefox.  Add this, and it'll just add security where possible, where it's known to be possible, on all of the sites that it supports.  And that's a growing list.  So this is something that is very nice.



LEO:  Yay.  Thank you, EFF.



STEVE:  Yes.  Adobe just took their PDF Reader to version X.



LEO:  Because they hit DEFCON 3.



STEVE:  Burying it deeply would be nice.  So they had been at v9.  We've talked about X several times, saying that it was coming, and that we expected it sometime before the end of November.  So that did happen.  What's significant about this is that they've added sandboxing.  So Adobe Reader now has sandboxing.  It won't solve all the problems.  We will continue to have problems.  But it does raise the bar.  And it will probably mean that, in the future, the rate of problems hopefully is lower.  Although I got a kick out of you, prior to us starting to record, Leo, one of the problems that you had run into on the system was that you had found that something had installed McAfee's Secure Scan.



LEO:  Oh, yeah, I was really mad about that.  I think it was Firefox, wasn't it?



STEVE:  It may have been.



LEO:  Because they give you little stuff, you know.  And if you're not careful during the install and don't uncheck the boxes...



STEVE:  Yup.  And when I went to Adobe's site, which is just get.adobe.com/reader, again, to move up to Adobe Reader X, which they use a Roman numeral "X," it's get.adobe.com/reader.  In the upper right-hand corner, checked by default, is a sneaky little checkbox for "McAfee Security Scan Plus"...



LEO:  That's probably what it was.  It was Adobe.



STEVE:  ...to be included in the download.  And I also noted that this thing includes Adobe AIR.



LEO:  Well, I'm annoyed because I don't know who put - I didn't want that on my system.  Not McAfee.  I'm not worried about McAfee.  Get Adobe off of my system.  We use the other one, that I like much, much better anyway, Foxit.



STEVE:  Yes, Foxit.  I was going to say that, with this getting just bigger and bigger, and now with them dragging Adobe AIR along, which many users will not need, and they're just doing it because they want to establish that platform on more people's machines, and that will of course induce developers to do AIR-based things.  It's really long past time to look at a different reader, I think.



LEO:  Foxit's quite good, I think.



STEVE:  The PDF format is now universal enough that it's not as if you're going to have big compatibility problems if you don't use the original solution.  And the other readers are just not going to be as large a target.  We don't know that they have fewer security problems.  We do know that fewer are being reported, and fewer are being exploited, because Adobe has the big bulls-eye painted on it.  So it really looks to me like it makes sense to use something else.



In the news, Washington Post covered a story that began with - this was on Stuxnet.  "A malicious computer attack that appears to target Iran's nuclear plants can be modified to wreak havoc on industrial control systems around the world, and represents the most dire cyberthreat known to industry, government officials and experts said Wednesday."  So this was some testimony in front of Congress about Stuxnet and what it means to everybody else.  Of course we now know, as we talked about last week, that it really does appear that Stuxnet was designed deliberately to mess up the centrifuges being used to enrich uranium for Iran's - hopefully only their commercial nuclear reactor projects and not for bomb-making, not for taking it to a weaponizing level.



LEO:  Maybe we could do this to North Korea.



STEVE:  Yeah.  And so what the testimony basically did was serve to pretty much horrify members of Congress about the concept that Stuxnet could now be and would be reverse-engineered.  Whereas it had been targeted specifically to Iran's process control systems for nuclear enrichment, nothing prevented it from being retargeted at other segments of the process control industry - power stations, nuclear reactors, all kinds of things that are using Siemens-based control systems.  I mean, basically the template is all there now.  And reverse-engineering is possible, and it is entirely foreseeable that many of the tricks that Stuxnet pioneered, I mean, now that it's spread, and now that everybody who wants a copy has a copy, it's certainly possible to retarget it.



So it's looking like this may result in some legislation from the government beginning to enforce a wall, essentially, I would use the term "firewall," the idea being the separation of offline process control things from sort of online, civilian use, Internet-connected stuff.  What everyone is recognizing is that it's the sort of lazy, oh well, it's like the computers in the ER, in the operating room theater in hospitals being on the Internet just because it's convenient.  It's like, oh, well, they get their updates and so forth.  Well, we've seen what happens when operating theater, hospital-based computers get infected with malware.  It can literally be life-threatening.



Well, this is the same sort of problem where Stuxnet is crossing from the Internet and machines that are on the Internet into process control systems.  The only way that's possible is if there's connectivity.  So it's looking like the government is beginning to say, hey, we need to do something about these critical infrastructure systems which are on the 'Net.  They really need to be taken off the 'Net.  Yes, it's not going to be as convenient for people not to have all of the PCs that are running Windows hooked to the Internet.  But if they're in charge of running nuclear reactors, we really don't want the rods pulled.



LEO:  Please.



STEVE:  Please.



LEO:  Please.



STEVE:  And also in the news, I thought it was interesting, and a number of people wrote in.  There was some news about China having last April briefly rerouted 15 percent of the Internet's traffic through their country.



LEO:  That's weird.



STEVE:  Well, we'll be covering this in detail, that is, the technology for this, when we get into our forthcoming, and still forthcoming, basics of how the Internet works series, where we're going to start right back at first principles, bits and bytes, and work up to the whole Internet and how it functions.  It actually wasn't 15 percent of the Internet's traffic.  It was 15 percent of the Internet's routing network prefixes.



Essentially, we know generically, sort of in an overview, that the Internet is made up of routers scattered far and wide that are interconnected to each other; and that packets put onto the Internet are then bounced from one router to another, each bounce taking them closer to their destination.  Well, the way that's done is that the routers contain multiple interfaces, each interface connecting it to one other router.  They have multiple interfaces, so each router is typically connected to many other routers.  And routing tables in the router, when a packet comes in, the destination IP address is examined.  And it's examined against this routing table which tells the router which is the best direction to send that packet towards its destination.



So there's a protocol called BGP, Border Gateway Protocol.  It's the protocol which routers use to communicate among themselves who has the best routing direction for given packets.  Well, there's been some problems in the past.  BGP uses the TCP protocol.  And some of the early routers had easy-to-guess sequence numbers in their TCP communications, which allowed TCP connections to be hijacked and spoofed, and allowed bad guys to poison the routing tables of routers, causing traffic to get misrouted.



Well, it also is the case that mistakes can be made.  And it's most likely that someone in China made a mistake and essentially published, because that's the term that's used, published the incorrect information that particular routers in China were the best place to send packets, like for U.S. .gov domains.  And it turns out that many very sensitive domains were, for the period of about 15 minutes, were routed through China.  And so what happened was this information got published.  And as happens with routers, they propagate and update each other.



So this misinformation propagated through the routing infrastructure of the Internet, causing all the routers everywhere to say, looking at their packets, just, like, "Oh, apparently China is where we want to send this."  And they did.  When China routers got it, they thought, I mean, they saw the packet coming in and thought, wait a minute, we don't know what to do with this.  This needs to go over there.  So they dutifully bounced it back out to wherever the packet was bound, many of them bound for sensitive domains in the U.S.  And an analysis of this really makes it look like it was a mistake more than it was deliberate.



But it certainly is an interesting warning to people that what can be done by mistake can also be done on purpose.  And this is yet another reason why encryption is a good thing to have on all your communications, because, literally, unencrypted traffic was all sent to China for a while before it got sent back where it should have gone.  Which raises the hairs on our Homeland Security folks, who watch these things.



In other news, our friend Charlie Savage at The New York Times, who reported on the FBI's increasing interest in wiretapping - which raised the hair on the back of my neck because of my interest in doing a highly secure, encrypted VPN product that we've talked about, CryptoLink is what it will be called.  He updated with an interesting story recently.  And I'm just going to quickly read this rather than trying to paraphrase it.  He wrote that:



"Robert S. Mueller III, the director of the Federal Bureau of Investigation, traveled to Silicon Valley on Tuesday to meet with top executives of several technology firms about a proposal to make it easier to wiretap Internet users.  Mr. Mueller and the FBI's general counsel, Valerie Caproni, were scheduled to meet with senior managers of several major companies, including Google and Facebook, according to several people familiar with the discussions.  How Mr. Mueller's proposal was received was not clear. 

 

"'I can confirm that FBI Director Robert Mueller is visiting Facebook during his trip to Silicon Valley,' said Andrew Noyes, Facebook's public policy manager.  Michael Kortan, an FBI spokesman, acknowledged the meetings but did not elaborate.  Mr. Mueller wants to expand a 1994 law, the Communications Assistance for Law Enforcement Act (CALEA), to impose regulations on Internet companies.  The law requires phone and broadband network access providers like Verizon and Comcast to make sure they can immediately comply when presented with a court wiretapping order. 

 

"Law enforcement officials want the 1994 law to also cover Internet companies because people increasingly communicate online.  An interagency task force of Obama administration officials is trying to develop legislation for the plan and submit it to Congress early next year."  That would be early in 2011.  "The Commerce Department and State Department have questioned whether it would inhibit innovation, as well as whether" - in my case it would.



LEO:  Yes.  Yes, the answer is.



STEVE:  "...[A]s well as whether repressive regimes might harness the same wiretapping capabilities to identify political dissidents, according to officials familiar with the discussions."



LEO:  Some might say it turns our own regime into a repressive regime.



STEVE:  Uh-huh.



LEO:  But that would be a cynical point of view.



STEVE:  "Under the proposal, firms would have to design systems to intercept and unscramble encrypted messages.  Services based overseas would have to route communications through a server on United States soil where they could be wiretapped.  A Google official declined to comment.  Mr. Noyes said it would be premature for Facebook to take a position."  So as our listeners know, I will be watching this and reporting on this as we move forward.



LEO:  You know, Dvorak has always said that Facebook is a CIA front.  And it's a very flimsy thing.  But the CIA is a big investor in Facebook.  Did you know the CIA has a venture fund?



STEVE:  Okay, that's annoying.



LEO:  Yes [laughing].  The CIA has a venture fund and is in fact a Facebook investor.  Now, I mean, if you really want to be a conspiracy theorist, what better way to surveil people than Facebook?  Because they voluntarily give you everything.



STEVE:  In fact, I was listening to your live feed while things were getting set up for us recording this show.  And one of the news blurbs that Tom brought up, Tom and Becky mentioned, indicated that insurance companies, life insurance companies, were now going to be increasingly using Facebook to check on publicly available information which people had posted about themselves in order to get information about them which would then be used in some fashion to further profile them for life insurance purposes and health insurance purposes.



LEO:  See, that's really who's most interested, I would guess.



STEVE:  It all gets kind of creepy.



LEO:  I don't know if it's a conspiracy theory or if it's real.  But it's just something to be aware of.



STEVE:  Yeah.  So we know that 64-bit versions of Windows have been designed from scratch to be dramatically more secure against malware of all kinds, and specifically against rootkits.  We've talked about how Microsoft has this dilemma, that it is difficult for them to immediately secure 32-bit versions of Windows because they can't impose the same level of security without breaking things.  64-bit Windows thus, until now, has been virtually immune to really nasty attacks like rootkits.  Well, the Alureon rootkit, which has until now only been found on 32-bit Windows, has now successfully compromised 64-bit Windows.  That was the rootkit which we did discuss earlier this year, I think it was, when a version of Microsoft's updated software caused crashes on 32-bit Windows, just regular Windows Update, which ran, and suddenly people couldn't boot their Windows anymore.



Well, that was caused by the fact that their machines had already been infected with a 32-bit version of this Alureon rootkit which had infected their boot sector and was assuming hard-coded entry points into Windows kernel.  The update patch from Microsoft changed those hard-coded entry points, causing Windows to no longer boot because the rootkit was crashing Windows; whereas before that it had been carefully designed not to do so.  So 64-bit Windows has specific, rigorous, driver-signing protection and kernel PatchGuard protection, all designed to make it bulletproof.  The problem is, if something is running before Windows, and if it's cleverly designed, there's nothing Windows can do, literally nothing Windows can do to protect itself.



And that is exactly what has happened here.  The security people who have really looked at this understand this problem.  That's why the Trusted Platform Module (TPM) is called the Trusted Platform Module.  The idea behind TPM - which is still not fully implemented.  We have the hooks, we have the hardware, we have the technology.  But it hasn't yet happened.  The idea behind that is that from the first moment power is turned on, there is a verifiable protected environment that, step by step, cannot be compromised.  It's because we don't yet have that, that it is still possible for the boot sector of the hard drive to represent a point of compromise.



And so it is this altered boot sector which gets control as the system boots before Windows does.  The BIOS turns over control to the boot sector, which runs some code that is able to find the rest of the rootkit, and on the fly it patches the kernel protection to disable it, allowing an unsigned device driver to get into Windows, which then flips a switch, which is a development time switch used to bypass driver signing in 64-bit Windows, and then your 64-bit, much-more-hostile-to-malware Windows is rooted.  And it's happening today.  So just FYI [laughing].  The good news is that...



LEO:  Sorry, I was just running in the other room for a moment.  That's very scary.  But didn't Microsoft say that the 64-bit version of Windows was, like, preliminary to a fully secure version, but just kind of a warning shot across the bow of companies?  I mean, this is something they'll fix, presumably.



STEVE:  They know about it.  Their various security tools are aware of it.  But essentially what it means is that this notion that 64-bit Windows is impervious, I mean, it is as impervious as they were able to make it.  The point was...



LEO:  Without breaking everything.



STEVE:  No, no, no.  That was the 32-bit problem.  They were able to start fresh with 64-bit Windows.  And they did say that PatchGuard is here, drivers must be signed, address space layout randomization is here, I mean, basically they were able, because they were starting late in the game on 64 bits, they were able to do everything they possibly could.  And so while doing everything they possibly could, they've been rooted.  And so that's significant.



LEO:  I do remember, though, there were workarounds for PatchGuard even when they first announced it.



STEVE:  Okay.  So here's the problem.  This is software.  There will always be workarounds.  It's spy vs. spy.  You've got other software fighting against Windows.  We're never going to have perfect security on an open platform where users can install software which they download from anywhere on the Internet.  We're just never going to have it.



LEO:  That's nice.



STEVE:  Also in the news, Google quickly fixed a little glitch in their Google Apps scripting API.  A 24-year-old Armenian who was using the handle "Vahe G," created a demo on Google's own Blogspot blogging platform.  And actually it probably had to be on Blogspot because visitors who went to his blog page who were sort of simultaneously logged onto Google accounts, so like if you were using a Gmail account, or you were a Gmail user, and you had, like, checked the "yes, keep me logged on" so that you could go back and still be logged on, his little demo used a mistake in Google's scripting API to obtain the email addresses of anyone who went to his blog page, despite the fact that they hadn't given it to him, and sent email to them from Google with fully valid Google headers.



So this quickly came to Google's attention.  They removed the page, and then they fixed the little flaw that he had found.  But it generated a lot of news in the security community because it was like, whoa, whoops, wait a minute.  My Gmail address has been leaking.  I mean, essentially, he could have been harvesting them and using them for whatever purpose he wanted.  So that was fixed.



And lastly, our old friend Phorm, which we gave a whole podcast to a couple years ago, this was the very nasty technology which, I think it was BT, British Telecom in the U.K. was testing without its customers' knowledge.  It used equipment installed at BT to, in real-time, intercept their customers' communications and install cookies, Phorm cookies, on every single domain in their browser that they went to in order to tag them and track them and profile them deeply and pervasively.  This is the so-called Deep Packet Inspection.  And we, hopefully, had thought we'd seen the last of this.  The bad news is it's trying to make a comeback.  The Wall Street Journal in their ongoing series, "What They Know," on Internet spying, had a story titled "Shunned Profiling Technology on the Verge of Comeback."  And now Phorm...



LEO:  Like a zombie.



STEVE:  I know.



LEO:  The undead.



STEVE:  It will not die.  Now they're saying that they're going to opt in, rather than opt out, because you could use an opt-out cookie, except that doesn't work because no one does that, no one knows about it.  And apparently now you'll be able to opt-in, and users - get this, Leo - can pay $10 a month not to be profiled and "Phormed."



LEO:  Well, that's not opt-in, that's opt-out.



STEVE:  Yeah.



LEO:  I don't understand.  If you have to pay not to be profiled...



STEVE:  Well, the idea is you opt into using it, which saves you a $10 a month surcharge.



LEO:  Oh, I see.  Oh, good.  I don't have to pay if I let you steal my stuff.  That's good.



STEVE:  Exactly.



LEO:  Good deal.



STEVE:  Exactly.  And they're looking at your searches.  They're looking at, well, basically, it is ISP-installed and sanctioned tracking, because ISPs want a piece of the action.  And the idea is, you'll remember how nasty this is, this is modifying web pages which you are downloading, where the ISP is now inserting ads into web pages that were not delivered from the web server you're visiting.



LEO:  Well, and I'd be annoyed if I were that web page.



STEVE:  Exactly.



LEO:  If my ads were getting replaced.  So I guess, I'm trying to think of how the spin would go.  So your Internet service provider, you'll get a message from them saying, great news, we have a new technology that will customize the ads you see so you only see ads you're interested in.  Now, if you don't want this, you can pay $10 not to get it.  No, no, they won't do that.  Oh, if you let us turn this on, we'll give you a $10 discount.  That's how they'll do it.  All right.



STEVE:  Yes.  After raising your rates $10.



LEO:  Yeah, first they have to raise your rates.  Is this only in the U.K. right now, or is this going to be...



STEVE:  No, this is coming to an ISP near you, apparently.



LEO:  How nice.



STEVE:  Now, the good news is, once again, SSL blocks it.  HTTPS.



LEO:  Can't do it.



STEVE:  It creates a secure tunnel from your machine to the server.  And there's nothing your ISP can do to spy on you, as long as you haven't accepted a certificate from them.  If that starts to happen...



LEO:  They can intercept.  They're the man in the middle then.



STEVE:  Then we've got a whole 'nother can of worms.



LEO:  But nobody's going to know to do that.  Comcast wants you to accept this certificate.  Okay.



STEVE:  Exactly.  That'll be really - that'll be the day.



LEO:  So it's not illegal - I know there was some investigation going on when this first came around about a year ago.



STEVE:  Well, what happened was BT had done it without their users' knowledge or permission.  It was being done behind their backs, and it caused a huge outcry.  And, I mean, lawsuits flew because people said, hey, you're spying on us.  So the idea is, this time it'll be done in an opt-in fashion with end-user knowledge.  And there are statistics saying, oh, 60 percent of the people who we asked said they would opt in if they didn't have to pay $10 a month more.  It's like, yeah, well, I guess so.



LEO:  So if you're on British Telecom...



STEVE:  Well, I don't think this is BT again.



LEO:  They've learned.  They've been burned.



STEVE:  We're still early on this.  I will keep an eye on it and let our users know where this begins happening.  But it was being done for a while in the U.S., and U.S. carriers dropped it quickly because they realized this was just going to cause them trouble.



LEO:  Terrible.



STEVE:  I did want our iPad users to know that iOS 4.2.1 is now available for iPads, adding all those cool new features that the iPhone has had for many months.



LEO:  Including printing, which I've been playing with, and that's pretty nice, to be able to print.



STEVE:  Yeah, for me, I was able to condense all of my many apps onto just two pages, down from I think five.



LEO:  Huge, yeah.  I had 10, yeah.



STEVE:  So being able to have folders and aggregate them is really nice.  And then I did have a fun "SpinRite saved me" story from a Security Now! listener.  And the subject was "SpinRite Saved Me."  Harry Lindenfeld wrote:  "Steve, let me start by saying I've been a fan of Security Now! with you and Leo since Episode 1.  Up until this past week I've never had a need for SpinRite since I have listened to you and Leo about backing up.



"I work at a courthouse here and inherited the security card access server and system for the courthouse from the county.  Their solution to back up was CDs on a CD writer.  The database was over 500 people, and the number of CDs required was getting out of hand and no longer made sense.  We had a computer crash about two years ago, and I gave the county the backup CDs at that point.  They were unable to restore the database, saying that some of the CDs were corrupt.  So we had to manually reenter the complete database, which took days of painstaking work.  I promised that would never happen again.



"So I purchased Norton Ghost and another hard drive and ran Ghost.  Then I would do just weekly backups of the data files.  Lo and behold, the main hard drive failed on the server, and I rebooted the system off the ghosted hard drive and was up and running in minutes.  Two days later, that hard drive started to have issues, and I had not purchased yet another hard drive to replace the dead one on the main system.  And the county still wants to use CDs.



"I was in fear of losing everything.  So I purchased SpinRite for myself, because the county wouldn't buy it, and immediately started it in Level 2 mode.  That was at 10:00 a.m., and it ran for just over four hours.  By 3:00 p.m. that same day, I booted the system back up, and everything was back to normal.  But here's the best part.  The original hard drive that failed and wouldn't boot up, after running SpinRite on it, it booted up normally and was faster than before.  SpinRite to the rescue once again.  I have once again Ghosted the main hard drive and also have a second Ghosted hard drive offsite in a secure storage, just in case.



"Thanks again, Steve, for all your hard work.  You've saved me days, possibly weeks, of data recovery.  P.S.:  SpinRite is now included in my bag of PC tools.  Harry."



LEO:  As it should be.  Absolutely.  All right.  We're going to talk a little bit about DNS spoofing and how, well, we talked about how it worked in the past, but this is a name server spoofability test that you've got here that should be very interesting.  Is this a new app from you?



STEVE:  Yes.



LEO:  You're just cranking them out these days.  Yes [laughing].  All right, Steve.  I think we are ready to talk a little about spoofability.  You want to recap a little bit the story behind all this?



STEVE:  Oh, of course.  So here's the problem.  When a user types a domain name into their machine, into their client, their computer, it needs, as we know, to look up the IP address of that domain if it isn't already known to the computer.  So the computer sends a DNS query to the DNS servers that it's registered to use.  Those servers either themselves then go about looking up the answer, or in many cases hand that off to, like, a master big-iron ISP server that does the work.  But one way or another, some server gets the job of looking up the IP address.



So DNS was designed many years ago, at the beginning of the Internet, when, as we've often said, security wasn't even on the map.  It wasn't even a consideration.  Literally.  I mean, it's hard to imagine that now.  But it was absolutely the case that security wasn't even a consideration.  Remember that Netscape introduced SSL on their later browsers.  There was no way to even exchange information securely with a web browser.  Truly, security wasn't considered in the beginning.



So a DNS query has a 16-bit query ID which was used by the server to identify the responses.  That is to say, it would have a counter which would increment the 16-bit value, and it would send a query off to another DNS server asking it if it knew the IP address for this domain.  And when the response came back, it would use this 16-bit query ID to verify that it was the proper response, to sort of segregate all of the outstanding queries with the returning replies.



What bad guys figured out was that, if the queries were always being sent out from the same port, and if the ID was just being incremented linearly, as they were originally, then it would be possible to spoof the reply coming back from a remote server.  So the DNS server that's asking the question would generate its query.  But because the query was predictable, because the port it was coming from was predictable, and the ID was predictable, it would be possible to beat the remote DNS server's reply with a spoofed one.  So what that would do is it would be accepted, because it would be what the querying DNS server was expecting.  It would be accepted as the truth.  And that would poison the cache, poison the cache memory, the DNS memory of that DNS server, with the wrong IP.



So, literally, I mean, the way this would happen is a user could be going to Amazon.com, and the DNS server would have the wrong IP, deliberately, maliciously have the wrong IP for Amazon.com.  It just wouldn't be correct.  That would then take their browser to some malicious site masquerading as Amazon.com, and the site could do whatever it wanted.



So DNS spoofing is a very potent and powerful attack which the industry needs to prevent.  So what Kaminsky suggested was, first of all, that the query IDs not be linear, that they be generated in a pattern which is extremely random, and the same thing for the port.  The ports that the queries come from can be any of almost 65,536.  65,536 is 2^16, the number of combinations of 16 bits.  And the query ID can be the same thing.  It's 16 bits.  So together that makes up a 32-bit source of randomness.  As long as the DNS server is randomly choosing ports to issue its query and query IDs, both of those at random, then there's no way for an attacker to be able to predict a given query's port and ID; and it dramatically, to the point of it no longer being practical, dramatically lowers the spoofability of that particular DNS server.



So what I decided at that time, the summer of 2008, was that it was a perfect free service for GRC to offer, much as we've always offered the ShieldsUP!, test your ports, port-probing facility, which also was something that inherently had to be done from the outside in toward the user because that's of course the way attacks came at people.  Similarly, what I realized was I could have GRC pretend to be a name server, and have the user's DNS server ask GRC for an IP.  And I would then analyze the port and the query ID of the queries coming from the user's server.



LEO:  Very clever.



STEVE:  Well, it gets way better.  The first question I had to ask myself was, okay, I need a bunch of queries from the user's DNS servers.  How do I generate those?  How do I get - because if I give it a domain that I have control of, that it's never seen before, it won't be in its cache.  So it'll have to ask for the IP.  So I thought, okay, but I don't want just one.  I need inherently, to do a good statistical analysis, I need hundreds, if not thousands, of queries in a very rapid order.



So I came up with a really cool solution.  You simply go to GRC.com/dns, and that will bounce you to the Spoofability Test page.  There's a button at the bottom.  The button basically just takes you to another page.  In order to display that page, which is the testing page, the web server tries to display, tells your browser to display the image for a really funky named, little tiny GIF image.  It's 13 random characters.  Actually, they're pseudorandom, and they never occur twice because they're based on a 64-bit counter back at GRC.  So that way we know that the domain name that begins with those 13 characters has never occurred before.  Then it's .dns.grc.com.  So that's sort of a pseudo domain where this GIF image on the page that we're trying to display is located.



So that, of course, the page comes to your browser, and your browser says, oh, I need to display this GIF image in order to show the user this page.  So it says, wow, look at that domain, I never saw that before.  13 random characters .dns.grc.com.  So your computer asks your DNS server to get the IP of that domain where that GIF image is going to be served from.  Your DNS server says, hmm, funky-looking 13 characters .dns.grc.com.  So it's never seen the dns.grc.com in the same way that, for example, www.grc.com is a subdomain of GRC.com; dns.grc.com is a different subdomain.



So it asks GRC's name servers for the IP address of dns.grc.com, and it gets a special IP for a pseudo name server that I wrote.  It says, okay, now I've got the IP of dns.grc.com.  What's the IP of this funky 13 characters .dns.grc.com?  It is a subdomain of that subdomain.  Well, there's a record, there's a type of reply in DNS called a CNAME, a canonical name, the idea being that, if you ask for a domain name, that could be an alias for something else.  So when you ask the GRC.com pseudo DNS server for this funky 13 characters .dns.grc.com IP, this pseudo DNS server that I wrote returns an ungodly alias, that is, the actual canonical name.  It is a.a.a.a.a.a.a.a.a.a - 43 a-dot subdomains, then that same 13 characters .dns.grc.com.



So think about that, Leo.  It's as if you had a 43-deep hierarchy of domain names.  And what this forces is, this forces individual DNS queries to enumerate each of the IP name servers for that entire hierarchy of sort of fake DNS.  So the user's DNS server receives this canonical name which is incredible, I mean, it's never seen anything like it before.  But it's valid.  And it says, oh, my goodness, okay, let's see.  I need to get the name server for the a.13characters.dns.grc.com.  And it asks that name server for the a.a.  And then it asks that name server for the a.a.a, and so forth, basically exploring all the way out to the end of this insanely long, deep domain name where - I used a.a.a. because that's a single character, which is the fewest you can have between dots.



And so what this does is this forces a flurry of queries in very short order between the user's DNS server and my pseudo server, which is the name server for all of those subdomains, down that path, allowing me to collect in a database for this user, for that particular querying name server, all of the ports that the queries come from and all of the IDs that the queries have.



And so on the fly I build databases for all the DNS servers heard from.  This is also deliberately slowed a little bit because, I mean, we're doing a lot of work here with this going back and forth.  but we also don't want to respond too quickly because one of the other things that happens is, because I want to discover all the name servers that might be brought to bear, not just the particular name server this time, but I want to do a comprehensive discovery of name servers.  So the system also throttles its replies so that at least some number of seconds, typically five seconds, will be required for this entire resolution process.



What happens is the client that asks the question of its DNS server gets impatient.  After a second, it asks it again, thinking that maybe its query got dropped.  And then, if it still doesn't hear back after another second, it says, well, maybe that DNS server has died.  So that's where the secondary name server, or more name servers, because some users - there's no practical limit to how many name servers you can configure on your computer.



So what Windows and Mac and UNIX and normal protocol-obeying clients do is, if they haven't heard back after two queries a second apart, they then ask all the name servers that are registered for them to use the same question.  So suddenly more name servers are being asked for this domain.  They start querying GRC.  I collect all of this stuff together.  Because this 13 characters is changing every time, I track which ones are associated with which users trying to run the spoofability test to aggregate all the data.  And essentially that approach allows me to discover all the name servers which might generate public queries out on the Internet for a given user, based on their current DNS configuration.  And I collect this rich database of associated query IDs and query ports, each being 16 bits, and assemble that into a report.



So the processing done, once this has all happened - oh, and this actually happens multiple times.  What we discovered during the testing of this is that the longer you waited, the more name servers you found.  So this test continues.  It shows you little progress dots as you're performing the test, as it moves along, so you can see what's going on.  Shows you how many name servers have been discovered so far, accumulates all this data, and then grafts them in paired scatter charts.



I display the results visually because, good as software can be, nothing is better than the human eye for picking out patterns.  And so you can instantly see whether this just looks like true scattered queries with no pattern, or whether there are any kinds of, like, zones of queries, or vertical or horizontal or diagonal lines.  It turns out that we're very good at seeing these results.  And in fact a ways down the page, where lower down I'm explaining all of this, I give a link to a gallery of sample DNS name server scatter charts that are really bad, which our users, which users during testing of this found their own DNS servers were producing.  And, I mean, it's a source for some worry.



And then in addition to that, in addition to these scatter charts, since there are anomalies that the human eye might not see - for example, say that the query IDs were always odd.  Well, you couldn't see that in a scatter chart.  But you could notice, that is, software could notice that the least significant bit of the query ID was always zero, meaning that it would be - wait, no, it was always one, meaning that it would be an odd number.



So I then also create some charts showing the bit predictability of each of the 16 bits of the query ID and the source port, and indicate, if the predictability is not near zero, then some person could profile the server, just as I have, a malicious attacker could profile the server as I have and notice that there are bits that are stuck in some cases, or highly predictable.  And then what that does is that lowers the effective entropy, the effective randomness of these queries, making that server more spoofable.



Then, additionally, I do some statistical analysis to determine the maximum entropy, the lost entropy, a bias in the direction of the bits, and basically fully characterize and profile the name servers which are producing public DNS queries on behalf of the user out onto the Internet, and summarize it, and actually just tell you flat out if your antispoofing safety is very good, good, moderate, not so good, and so forth down the scale.  And then the balance of the page explains everything that happened above.  And it turned out very nice.



LEO:  Yeah, I have to say, I'm looking at the scatter charts.  If you go to GRC.com/dns, you can read all about this.  There's all the details and so forth.  And then there's just a little button at the bottom that says "Initiate Test."



STEVE:  Now, one glitch happened as we were developing this, Leo.



LEO:  Yes?



STEVE:  We crashed some people's routers.



LEO:  Oh.  You should have told me that before I pushed the button.



STEVE:  Yeah.  We crashed some people's routers.  And people were like, wait a minute, I tried to run your test, Steve.  This was organized in our newsgroups during the development of this.  And it was like, okay, wait a minute.  I wasn't getting myself crashed.  Other people weren't.  I was only issuing valid DNS queries.  It turns out that some firmware in some routers is buggy.



LEO:  Well, in fact you'd probably want to know that; right?



STEVE:  Exactly.  Because what we know...



LEO:  By the way, I'm killing your Skype right now.  I'm sorry.  Does this send a lot of traffic?



STEVE:  Oh, my goodness, yes.



LEO:  Okay, sorry about that.  Just keep talking, it's okay.  I probably should stop the...



STEVE:  No, I'd love to see what you see in terms of your own results.



LEO:  Yeah, well, now you've got me going.  I'm not sure which - I don't know whose system we're using right now.  We have so many different ISPs in The Cottage.



STEVE:  Do you have little dots?  You're looking at little black dots move across?



LEO:  Little dots are going across, yeah.  We've got three query rounds so far.  Found four servers in the first round, 649 queries received.  No servers in the second or third round.



STEVE:  Okay, good.  So it looks like you found them all in the first round.  What I do is I keep doing additional rounds because sometimes there are reluctant DNS servers that kind of, like, finally appear.  So we get four rounds of zeroes.  And then I've decided, without finding any new DNS servers, then I decide that we've found them all.



LEO:  I suspect I'm OpenDNS on this one.  And of course they patched BIND right away.  In fact, I don't think they were ever vulnerable.  As I remember.



STEVE:  You're right, I think that they were always very safe.



LEO:  Well, we don't have time for me to go through all of this.  But I'll keep - oh, wait a minute, it's done.  Oh, it's done.  Oh, that was fast.  As soon as I said we don't have time, it finished.  Okay.  809 queries from server at - oh, I guess we're not, 68.87.76.180.  That's not OpenDNS.  Antispoofing safety good.  It is Comcast's server.



STEVE:  Okay.



LEO:  And the distribution looks completely random, all over the place.  So query source port analysis looks excellent.  Transaction ID analysis, excellent.  So I have no idea what any of this means.  But it looks pretty good.



STEVE:  But that's only one server.  Scroll down to the next one.



LEO:  Oh, my God.  And here's another one.  Two of those were in the San Francisco - that was San Jose, San Francisco.  Utah, Salt Lake City.  This is all Comcast.  And they all look good.



STEVE:  That's very good.  Well, so what this did was this found DNS servers all over the place that have the ability to serve your DNS queries because this page was crafted to generate a huge number of DNS queries and then analyze the results.



LEO:  The only reason I think I got "good" instead of "excellent" is lost entropy.  There's a little lost entropy on all of them.



STEVE:  Okay.



LEO:  I don't know what that means.



STEVE:  It would be a function of, like, maybe the bit predictability on either side are not, like, really down near zero?



LEO:  It's pretty low - .18, .2, .24.  That's pretty low; right?



STEVE:  I don't think you have anything to worry about, obviously.



LEO:  It's funny, though, that it's just not binary, that it's not like, oh, it's okay or it's not okay.



STEVE:  Well, because it isn't.  In fact, you could have, for example, some servers, it happens that when I brought this page up for myself, I didn't have any source ports below, it looks like maybe below 4,000.  So it was only from 4,000 up to 65,536, which that's still a large range, but it means that none of the source ports were from port 1 up to 4,000, which eliminates a huge clump of possibilities, meaning that an attacker wouldn't bother guessing any of those.  So it really is a variable thing.  It's not just go or no go.  It really is how variable is it.



And in fact, Leo, now that you've got a page there, you scroll down to the bit predictability chart description, right above it you'll see the gallery of sample DNS name server scatter charts.  If you click that, it'll give you an idea of what some users who are listening to this podcast will see because, even now, DNS servers have not been fixed because there's been no pressure put on them to get these things fixed.  So my hope is, one of the reasons I did this, was this would give end-users a tool to say to their ISPs, hey, I'm using spoofable DNS servers.  Fix these.



LEO:  Just looking at the scatter chart tells you right away.  If it's totally random-looking, that's good.  But the less random, the worse it is.



STEVE:  Yes, sometimes you'll see diagonal lines, meaning that there are counters running instead of something being pseudorandom.



LEO:  So this is how that whole spoofing occurred, because it wasn't a random assignment.



STEVE:  Yup.



LEO:  So the more random, I mean, if it looks random, it probably is.  And if you see any patterns there, that's not good.



STEVE:  Right.



LEO:  Look at that diagonal line.  That's wild.



STEVE:  Yeah, isn't that?  That just had a simple counter, just like...



LEO:  Terrible.



STEVE:  It couldn't be any worse.



LEO:  Terrible.



STEVE:  It could be a straight line, which would mean it was always the same thing.  That would be worse.



LEO:  That's pretty predictable.



STEVE:  But on the issue of router crashing, as we know, exploits start out as things that cause crashes.  And then the bad guys analyze the crash and figure out a way to execute code instead.



LEO:  So if it crashes your router, that's not good.



STEVE:  Yes.  What we've discovered is that it is possible to crash some consumer routers by returning to them a DNS query that is legal, but the router doesn't like.  So what happened was, we found two different sources of trouble.  One was the length of the query, which is why I trimmed it to 43, so as not to crash people's routers.  And also, when we finally gave the answer to the final question, when they went all the way out, the a.a.a.a.a, all the way out to the end, if I gave them the final IP, that would crash people's routers.  So the normal test, the Spoofability Test, deliberately doesn't crash anyone's router.



But I created a second test called, not surprisingly, the Router Crash Test.  And the Router Crash Test is also there at the same location.  You can find a link to it at the bottom of all of the DNS spoofability pages called Router Crash Test.  When you click that, what it does is it issues the most aggressive, still legal, but most aggressive queries, only a few of them, and a huge number of Belkin routers just go belly-up immediately.  They just die.



LEO:  Oh, that's good to know.



STEVE:  And a number of others.  In fact, what we have is there's a feedback page for people to let me know if their router does or does not crash, and is or is not listed among those that do.  And so I'm maintaining on the site, on this page, a list of all the routers by model number and firmware version which are known to be crashable by this Router Crash Test.  And again, my hope is that this will put pressure on the router vendors to fix their firmware because nobody wants a router that my website is able to crash.  Because if I can crash it, and I'm doing so non-maliciously, somebody else could crash it maliciously, and they may be able to do more than crash it.  We don't know.  But they may be able to execute code, which would be an external code execution on your router from the Internet.  And that's about as bad as it gets.



LEO:  Wow.  Very interesting.  GRC.com/dns, that's where to go to do this.  I've stopped now, so I'll stop screwing up your Skype.  Great stuff, as usual.  If you want to know more about this stuff, GRC.com/dns, in great detail on how it works and also how the spoofing attack works.  If you want 16KB versions of the show, you can get them at the same spot.  Of course full transcriptions are available, too.  Steve pays for those - thank you, Steve - at GRC.com.  While you're there, buy yourself a copy of the fabulous SpinRite.  Everybody ought to have a copy.  If you've got a hard drive, you need SpinRite.  And we will be back next week.  Have a great Thanksgiving, Steve.



STEVE:  Thanks, Leo.  We'll do a Q&A, talk about maybe the Benchmark and the Spoofability Test, follow up any questions that our users have.  And we'll go from there.



LEO:  Good.  Just if you have a question, GRC.com/feedback is the place to go.  We'll see you next time, Steve.  Have a great Thanksgiving.



STEVE:  Thanks.  You, too, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#277

DATE:		December 2, 2010

TITLE:		Listener Feedback #106

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-277.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Before plowing into this week's Q&A content, Steve and Leo catch up with the industry's security and privacy related news.  Steve shares a vitamin D researcher's reaction to a troubling new report about vitamin D, and shares his recent science fiction reading discoveries and opinions.



LEO LAPORTE:  It's time for Security Now!, a wide-ranging episode, this 277th.  Steve's going to talk about his favorite sci-fi novels; a little response to a New York Times article about Vitamin D; and, of course, your questions and answers, including the Firefox Add-on Tip of the Day.  It's all coming up with Security Now!.



It's time for Security Now!, the show that protects you and your loved ones on the Interwebs.  Here he is, the star of Security Now!, the man, the myth, the legend - I love saying that.



STEVE GIBSON:  You're now making me self-conscious about the myth part.



LEO:  Steve Gibson.



STEVE:  Ah, yes.



LEO:  There are myths about you.



STEVE:  We'll do a little mythology over the Christmas break.  We'll have a mythological episode.



LEO:  Yeah, we should tell everybody that.  For the first time ever, I've convinced Steve to take a week off.  First, it'll be - you don't have to, if you really don't want to.  But everybody else is going to be gone the week after Christmas.  But, no, we can get somebody in here.



STEVE:  Hello, hello.



LEO:  We'll just turn on a camera and let you do the show.  But since you have this great episode that's so appropriate, I think it's going to end up being kind of our Christmas goose, you know, where...



STEVE:  Does make sense.  And there is some churn in our listeners, so there are certainly people hearing this podcast that are going, "The portable dog killer?  What the hell are they talking about?"



LEO:  Although the notion of a rerun in podcasts is a trifle ridiculous.



STEVE:  Leo, you are a pioneer.  If anything can be said of you, it's that you are a pioneer.



LEO:  I am a pioneer.



STEVE:  Pioneered the podcast rerun.



LEO:  Yes, my wagon wheel hath broken.  Let us - what are we doing today?  We're doing a Q&A; are we not?



STEVE:  We have a Q&A.  This is a broad-spectrum Q&A.  I remember saying yesterday - it just feels like yesterday - last week that I imagined that our Q&A would be focusing on DNS.  I don't think one of them was about DNS.



LEO:  Oh, isn't that funny.



STEVE:  Because we had done the prior two podcasts about, first, the GRC DNS Benchmark, and then the Spoofability Test.  And I thought, oh, well, we'll do a bunch of Q&A about that.  But I just started, I found so many interesting questions and so much to talk about this week that I didn't get around to that.  So no DNS.  Well, actually there was one question, but it only tangentially rates DNS.  It's more about the nightmare of routing on the Internet.



So, but I got a ton of people, listeners, and twits and tweets and everything happened because there was a report on Vitamin D that was on the front page of The New York Times, The Wall Street Journal.  NPR covered it.  Local radio.  People at Starbucks this morning were asking me.  And so I wanted to talk about that a little bit because it was a very bad, bad report that came out.  And we've got some news.  And a number of people have asked for a sci-fi update, like what I've been reading lately.  So I thought I'd...



LEO:  Oh, good.  Always like that.



STEVE:  ...update people on that.  So we've got tons of fun stuff to talk about.  I think a great podcast for everybody.



LEO:  And just a word of warning.  I just saw a twitter that Denise Howell, who hosts our This Week in Law program, is listening.  She says, "I must be the first Security Now! listener to ever listen in a kindergarten classroom."  I don't think that's true, but I'm glad you're listening, Denise.  So, Steve, let's start with our security updates.  Are there any?



STEVE:  Well, we don't actually have any security updates.



LEO:  Really?  What?



STEVE:  We had another slow week.  However, I did note that Adobe has updated their v10 of Flash, not patching security problems, but reportedly working to essentially lower its power consumption.  It's interesting.  So they're at 10.2 now.  And it was maybe like last week I was at a Starbucks, operating on batteries, I think with a PC, and I don't remember now what it was.  Something Flash was going on, and I have my battery meter set so that it's showing me how much remaining time it estimates I have.  And that's something where it's looking at the history of the battery use.  It's dynamically measuring the current that the whole system is pulling from the battery and extrapolating based on the current current draw, if things stayed the way they are now, how long would that last?  Sort of the same way SpinRite estimates how long it's going to take to get done.  Which, you know, it's the best you can do, even though it can be fooled.



So, for example, if I turn the screen brightness way up, and I wait a few seconds, I'll see that it's like, oh, that seems to be big, you know, it's drawing a lot of power.  And suddenly my battery is projected to last a lot less long as opposed to turning the screen brightness down.  Well, what I noticed was when Flash was doing whatever it was doing - I don't think I was watching a video.  I think it was some other application was jumping around.  It seriously dropped the performance, the battery life of my system.



So this is what we've heard.  It's what Jobs was complaining about.  His justification for not putting Flash on the iPad was that it was just a hog in terms of performance.  And, I mean, the fact that just video movement is drawing so much power tells us, well, tells me as an engineer the degree to which there has been a huge effort already in minimizing power consumption.  That is, if changing stuff on the screen makes that big a difference as opposed to having your screen static - in fact, I then played around with just, like, scrolling.  And sure enough, if I was scrolling all the time, I could see an impact on my battery life compared to not.



So our systems have become so sensitive to anything going on, in order to get the battery life that we want and that they claim - in fact, that's one of the reasons that, when people were benchmarking the iPad after its release, the iPad was claimed to have a battery of 12-plus hours.  People played videos on them for that long to see, if you kept it alive and kept it busy, how long the battery lasted.



So anyway, it's good news that Adobe is sensitive to this.  Our listeners may remember that with v10 they were beginning to not do all of their video rendering in software, but they were going to be tied more directly to the hardware.  Which of course makes it bigger still.  But given that you've got some hardware that Flash can sink its teeth into and hook into, the potential is that you would be able to see less power consumption hit with Flash doing what it's doing.  So it's a good thing that they're moving forward.  I think I might still be on 9 and haven't moved to 10.  So it's probably worth doing that and see if I see an improvement.  So that's changed.



We do have some news.  Not surprisingly, Windows is in trouble once again.  Just a few days ago news came out of a privilege escalation zero-day vulnerability, meaning that malware was found in the wild that was using a hitherto - hitherto?  Is that right?



LEO:  Yeah, hitherto.



STEVE:  Hitherto.



LEO:  I don't know if "unhitherto" is a word, but "hitherto" is a word.



STEVE:  A hitherto...



LEO:  A not hitherto.



STEVE:  Not previously known [laughter], but henceforth known.



LEO:  There you go.  I'm sure Denise Howell would know how to say that.



STEVE:  Yes.  Notwithstanding, never did quite get my hands around that one.  But anyway, problem with the kernel in both 32 and 64-bit XP, Vista, Win7, and Win2008/SP2, which allows software which has already made it onto your machine, allows software to increase its privilege, so a privilege escalation vulnerability.  There's a stack overflow error that was found in the NtGdiEnableEUDC function, which allows an attacker who calls that function to inject their return address as a return address into their own code so that, when that function, which is a privileged function, returns, it returns to their code, maintaining full system privileges.



And this is significant because proof-of-concept code is in the wild.  And it then would allow full system privileges to be obtained by code which would normally be running with restricted privileges, which much more code does these days, for example, especially under Vista in Win7.  And this is, like, exactly what code wants in order to install rootkits because it is, by running with limited privileges, that the kinds of things you want to do, like writing to sector zero of the hard drive or installing hooks into the operating system, those things you cannot do under limited privileges, but you have much more ability to do that if you've got system privileges.



So the bad news is that we're recording this on December 1st, which is Wednesday, meaning that we missed by one day having Tuesday be the first day of the month, which would have meant that the second Tuesday, if yesterday were December 1st, would have been the earliest possible second Tuesday.  Instead, it's the worst possible second Tuesday, meaning that the second Tuesday doesn't occur until December 14th, which is as late as it's ever possible to have it occur, which is this month.  Meaning that, even if Microsoft - of course they could go crazy and respond to this in an out-of-band patch.  But I don't think they're going to.



LEO:  Well, it also takes a while to do a patch.  I mean, you can't just whip it out.



STEVE:  True, because it's all of their operating system platforms.  It's both the 32 and 64-bit version.  They want to make sure they don't break something else when they fix this.  I mean, a stack overflow mistake on a parameter of a function call like this, that's just about as easy to fix as anything I could imagine.  I mean, there's going to be one compare instruction which is responsible, which is missing, which they need to stick in to prevent this.  So this is about as simple and clean a fix as I can imagine.



I just don't think they're going to see that this is crucial unless something horrible happens between now and two weeks from yesterday, which would really make them jump faster.  So I expect to see this thing fixed in two weeks, probably not before.  There's nothing really actionable that our listeners can do.  There's no workarounds.  There's no patches or anything.  It's not crucial, but it has happened.  So I wanted people to know.  And as a little bit of additional explanation of why these things are bad, this is exactly what rootkit installers live for is this kind of thing.



And just in other news, relative to topics we've covered several times, you may have seen that Ahmadinejad has acknowledged publicly that the Stuxnet worm did in fact infiltrate the nuclear fuel enrichment processes in Iran and took some of their centrifuges offline.  He of course downplayed the significance and vulnerability.  It'll never happen again, he said.  Well, that one probably won't.  But it's very hard, as we know, to keep these things from creeping around in people's computer systems.  But so essentially, very early on, before there was much evidence, people were suggesting that this was the case.  I didn't talk about it then because there just didn't seem to be nearly enough evidence to make that claim, though it was certainly feasible.



hen, thanks to Symantec's great reverse engineering, they demonstrated convincingly, which is when I finally said, okay, this really does look like there's enough to believe it, they convincingly demonstrated how narrowly targeted and focused the actual exploit end of this worm was.  And then, a week later, it was acknowledged that, yes, in fact, it had been effective to some degree in slowing them down.  So for those people who've been worried about Iran's nuclear enrichment, I guess - the problem is, millions of systems got infected with Stuxnet in order to just target one, essentially.



LEO:  Oh, you think all of the Stuxnet worms are from the same source.



STEVE:  Yeah.



LEO:  And probably, let's face it, Israel.



STEVE:  Yeah.  Well, yeah.



LEO:  It's funny because I was at dinner last night with smart, but not particularly technical people.  And that was a topic of conversation.  It was so interesting to hear people talking about Stuxnet, whether Israel had anything to do with it, what its impact was.  I thought, wow.  This has gone mainstream.



STEVE:  And in fact, I don't know what it was, it was on one of the programs I watch, regular broadcast TV.  And they were, like, saying "Stuxnet" like they were trying to pronounce it correctly.  And it's like, wow.  This, as you say, Leo, really has gone mainstream.  But for good reason.



Speaking of mainstream, also in the news was WikiLeaks and this massive leak of more than a quarter million previously secret cables between countries.  And I thought - my angle on it was to see what I could find and share about the Siprnet, which is the acronym for Secret IP Routed Network, which is the government's global non-Internet Internet, essentially.  That is, it uses IP protocols.  It has TCP/IP.  It uses existing router technology.  But it's a network that exists physically disconnected from the regular Internet.  And unfortunately, one of the consequences of the U.S.'s post-9/11 attempt to get agencies to communicate much better - "stovepiping" was the term that we heard in Congress, the idea being that individual stovepipes were sort of, if you can imagine it visually, dropped around different departments that were containing their information and not communicating.



Well, here's, I mean, this is a classic example of what happens when you do create much greater degrees of communication.  Apparently they believe that it was some Private First Class in Baghdad, a security analyst, a junior security analyst who, as a consequence of this much-enhanced interdepartmental communication, had on his own machine access to all this.  And he had some gripes against things that he saw going on, and so he took it upon himself to send all this stuff off to WikiLeaks.  What's interesting is that there was some immediate reaction, saying, oh, well, we're going to disable writing to removable thumb drives on these Siprnet-equipped, high-security systems.  And it's like, oh, you're going to do that now?



LEO:  Surprising that they didn't do it...



STEVE:  Oh, my goodness.  I mean, and on all removable devices.  It's like, well, why do these computers have removable devices?  It's just nutty that it's like, oh, well.  And then they're going to require that two people be present in order to transfer any information from a classified machine to a non-classified machine.  And so now they're going to take a bunch of measures to deal with really what should have been done before.  But that's the nature of the government's involvement with technology largely is it just sort of doesn't get it right the first time.  So this was certainly a huge diplomatic catastrophe.  People are saying that not that much was learned that wasn't known before.  Certainly some embarrassment and problems.  And it does hurt the U.S. from a diplomatic standpoint.  So not a good thing.  And we'll talk about this a little bit later on, relative to some concerns about the U.S.'s clamping down on domains they don't like because...



LEO:  Now, that bothers me, this ICE thing, yeah.



STEVE:  Yes, it does bother me.  And you can imagine that they could say, oh, well, we don't want WikiLeaks to be available either because we think they're bad.  And so that suddenly disappears from the Earth.  Which I agree with you, Leo, it's really a double-edged sword.



In errata, I noted that the Supreme Court had declined to hear the Whitney Harper case, which I was distraught about, but not surprised, unfortunately.  The Whitney Harper case is a 10-year-old RIAA/MPAA lawsuit against a girl, a student, who at the time was 12 years old, when she was using...



LEO:  Oh, please.



STEVE:  Yeah, when she was using Kazaa to download music and share it with friends, which she didn't understand she could not do 10 years ago.  She thought it was like Internet radio.  And under the law there's something known as the "inadvertent innocent infringer," which carries a fine of $200 maximum; as opposed to the non-innocent infringer, which carries a fine, which is what the RIAA is seeking, of $150,000 per song.  So they're saying that she and her family are liable for $150,000 per song, for I think it was 40-some songs that they identified at the time, making this a huge problem.



Now, the first trial judge agreed with her defense attorneys, saying that she was innocent, first of all, because she really didn't understand this was illegal, and no copyright notice of any kind was present in or on what she downloaded.  So here she was saying, and her defense attorneys were saying, wait a minute, the RIAA...



LEO:  How was she supposed to know?



STEVE:  Exactly.  The RIAA is saying that these are copyrighted.  But the beginning of the songs didn't state that.  And it didn't say so anywhere during her experience.  So this went to appeal, and the federal appeals court judges concluded that a copyright notice anywhere trumps the innocent infringer defense, meaning...



LEO:  Oh, my goodness.



STEVE:  I know.  The RIAA was saying that the labels on the original CD cases, which had to have been opened in order to take the CD out of the case to upload it to the Internet, where she found it, those cases contained a copyright notice.  And that's enough.



LEO:  Well, I can understand that.  If they're being pirated, the pirate's not going to reproduce the copyright notice in any event.



STEVE:  Right.  But, now...



LEO:  But this is a 12-year-old girl.  I mean, if this is not the definition of an innocent offender, I don't know what is.



STEVE:  And so the problem was that the federal appeals court judges agreed with the RIAA's plaintiff attorneys that she was guilty under the non-innocent infringer case and could be fined as much as $150,000 per song.  So everyone was holding their breath, hoping that, now that this had gone to the appellate court, that this would be heard by the Supreme Court.  And they declined.  So...



LEO:  I can understand that.  I mean, you don't want to set a precedent that, if a pirate strips out the copyright, then you don't know anything about it.  Because you could strip a copyright out of everything.  And certainly music, we don't want it to say at the beginning of every song, copyright 2010 by Madonna, all rights reserved, at the beginning of every song.  So I can understand that.



STEVE:  Well, and of course, if they did that, then the people uploading it would just trim that off the front.



LEO:  Exactly, exactly.



STEVE:  This is out of control, unfortunately.



LEO:  You've got to wonder, though, if you're a recording artist, how you would feel, how you feel about the fact that your label - your label - is going after a 12-year-old girl, asking for $155,000 fine for the download of your song - your song.



STEVE:  Per song.



LEO:  How would you feel?  How do you feel, artists?  Why do you put up with this?  Why do you allow this?  Because to me all it would do is encourage, frankly, people to steal.  I don't think this is a good way to win goodwill in any way.



STEVE:  Over the holidays, well, the first holiday, Thanksgiving, I encountered the notice on Wikipedia about donations.



LEO:  Yes.  You couldn't miss it.



STEVE:  Yeah, you could not miss it.  It was very much in your face.  And I gave the guy a hundred bucks.  I gave Wikipedia a hundred bucks.



LEO:  Me, too.  That's funny, that's exactly what I gave them, too.  Yeah.  I've done that before, too.



STEVE:  Yeah.  And so I just wanted to make a mention of the fact that, I mean, you and I can afford a hundred bucks.  I don't expect all of our listeners to do that.



LEO:  No.  But a dollar is fine.  Anything.



STEVE:  Yes.  But only if you use Wikipedia.  My point was that I encountered it because I use Wikipedia.  I mean, I don't know if there's a day, frankly, now...



LEO:  Exactly.



STEVE:  ...that goes by.  It's the first link that you see in Google when you put anything in, virtually.  And I find it highly useful.  And I know there are skeptics who say, oh, well, anybody can go in there and modify.  It's like, whoa, whoa, whoa, wait a minute.  I mean, yes, there's a bunch of nonsense on the Internet.  There's also a bunch of high-quality material.  And I would say, it's free, but it sure beats anything else that I know of, if nothing else as a starting point for research.  And in fact it contains so much valuable information that I'm thinking that maybe the way I will spend my retirement is in dumping everything I've learned in my life of technical and useful nature into Wikipedia.



LEO:  That would be an even bigger contribution than a hundred bucks.  That would be of great value.



STEVE:  But still, I just sort of wanted to mention to our listeners...



LEO:  I agree, I agree.



STEVE:  ...just say, hey, if you find yourself using it, if you rely on it, if you value it, give it a few bucks because, I mean, we don't want it to have to become advertising supported.



LEO:  No.  That's one of the neat things.  I mean, Jimmy Wales has said, I've been told he says, we could make hundreds of millions of dollars a year by putting ads on Wikipedia.  We don't want to.  But in order to avoid that, we need to ask for support because these servers aren't free.  And I think it's one of the great resources of the 21st Century.  Absolutely everybody who uses it should contribute a little bit, as much as you can.  I agree with you a hundred percent.



STEVE:  So yesterday, as I mentioned at the top of the show, I got flooded - actually I encountered it in the morning on the front page of The New York Times.  And I thought, oh, goodness.  I mean, the headline was essentially, I don't have it in front of me, but it was "No Need to Supplement With Extra Vitamin D and Calcium."



LEO:  Really.



STEVE:  Yes.  And New York Times, Wall Street Journal, NPR, it was on ABC Good Morning something or other, I got email from friends, I got - you can imagine my Twitter feed went nuts with our listeners.  And then a ton of email, which I knew was going to happen.  Anyway, so I wanted to share with our listeners the reaction that I knew would be coming from the founder of the Vitamin D Council, John Cannell, who's an MD, whose video I have on the Vitamin D page, because he nicely summarizes this.



I'll say first of all that this was a sort of a quasi-governmental - in fact that's his term - agency, the Food and Nutrition Board.  And they only addressed the bone strength aspects of Vitamin D.  So to the degree that they addressed this, they were correct.  I noted that two weeks ago there was a news blurb where it was found that one in five children in the world had symptoms of rickets.  So it's certainly not the case that everybody is getting even that incredibly low-level minimum amount of Vitamin D required to prevent that.



But this spring, as I've mentioned before, I received an awful lot of email feedback from our listeners saying that last winter, because I talked about Vitamin D last August, and many people started supplementing, that they were reporting in the winter that it was the first - or in the spring following the winter.  It was the first time they'd cruised through the holiday season without catching cold and the 'flu.  Mark Thompson, my good...



LEO:  Me, too.



STEVE:  Yes.  Mark Thompson, my good buddy who does the AnalogX website, who's in Phoenix, of all places, well, he actually does live like a bat.  I visited his home the other day for the first time, and he has box shutters, all of which are closed.  So no light comes in the house at all.  He is actually running wacky programmer hours at the moment.  He gets up in the middle of the afternoon, and he works all night long.  And sleeps during the day, so he has to do that in order to get some sleep.  But he was, a couple years ago, he was sick every single time I talked to him on the phone.  He'd be coughing and sneezing and wheezing.  I mean, so that I was really actively getting concerned about him.  It's like, Mark, you're sick all the time, every time I talk to you.  And he's like, oh, yeah, well, I just got back from a trip somewhere, blah blah blah.



He started taking Vitamin D after I learned about it last summer.  He hasn't been sick once since.  I mean, it completely changed his life.  And of course we know that that's immune system boosting.  But remember that - and so not getting colds and 'flu is the short-term consequence.  But the long-term consequence is not getting cancer.  Because it's our immune system that is protecting us all the time from little cancers that are trying to start, and are getting zapped before they ever have a chance to get going.  So anyway, this - and I'm not going to do a SpinRite testimonial because I want to read this instead.  John writes:



"After 13 years of silence, the quasi-governmental agency, the Institute of Medicine's Food and Nutrition Board today recommended that a three-pound premature infant take virtually the same amount of vitamin D as a 300-pound pregnant woman.  While that 400 IU/day dose is close to adequate for infants, 600 IU/day in pregnant women will do nothing to help the three childhood epidemics most closely associated with gestational and early childhood vitamin D deficiencies:  asthma, auto-immune disorders, and as recently reported in the largest pediatric journal in the world, autism.  Professor Bruce Hollis of the Medical University of South Carolina has shown pregnant and lactating women need at least 5,000 IU/day, not 600.



"The FNB also reported that vitamin D toxicity might occur at an intake of 10,000 IU per day" - which is 250 micrograms per day - "although they could produce no reproducible evidence that 10,000 IU/day has ever caused toxicity in humans and only one poorly conducted study indicating 20,000 IU/day that may cause mild elevations in serum calcium, but not clinical toxicity.



"Viewed with different measure, this FNB report recommends that an infant should take 10 micrograms/day" - that is to say 400 IU - "and a pregnant woman 15 micrograms/day (600 IU).  As a single 30-minute dose of summer sunshine gives adults more than 10,000 IU, the FNB is apparently also warning that natural vitamin D input  as occurred from the sun before the widespread use of sunscreen  is dangerous. That is, the FNB is implying that God does not know what she is doing."



LEO:  I like that.



STEVE:  "Disturbingly, this FNB committee focused on bone health, just like they did 14 years ago.  They ignored the thousands of studies from the last 10 years that showed higher doses of vitamin D helps:  heart health, brain health, breast health, prostate health, pancreatic health, muscle health, nerve health, eye health, immune health, colon health, liver health, mood health, skin health, and especially fetal health."



LEO:  And health health.



STEVE:  And health health.  "Tens of millions of pregnant women and their breastfeeding infants are severely vitamin D deficient, resulting in a great increase in the medieval disease, rickets.  The FNB report seems to reason that, if so many pregnant women have low vitamin D blood levels, then it must be okay because such low levels are so common.  However, such circular logic simply represents the cave man existence (never exposed to the light of the sun) of most modern-day pregnant women."  Which of course is what has happened, is we've all gone indoors.



LEO:  The sun is bad for you, don't you...



STEVE:  And when we're outdoors we're wearing clothes and/or sunscreen.  He says, "Hence, if you want to optimize your vitamin D levels, not just optimize the bone effect, supplementing is crucial.  But it is almost impossible to significantly raise your vitamin D levels when supplementing at only 600 IU/day.  Pregnant women taking 400 IU/day have the same blood levels as pregnant women not taking vitamin D; that is, 400 IU is a meaninglessly small dose for pregnant women.  Even taking 2,000 IU/day of vitamin D will only increase the vitamin D levels of most pregnant women by about 10 points, depending mainly on their weight.  Professor Bruce Hollis has shown that 2,000 IU/day does not raise vitamin D to healthy or natural levels in either pregnant or lactating women.  Therefore, supplementing with higher amounts  like 5,000 IU/day  is crucial for those women who want their fetus to enjoy optimal vitamin D levels, and the future health benefits that go along with it.



"For example, taking only two of the hundreds of recently published studies:  Professor Urashima and colleagues in Japan gave 1,200 IU/day of vitamin D3 for six months to Japanese 10 year olds in a randomized controlled trial.  They found vitamin D dramatically reduced the incidence of influenza A as well as the episodes of asthma attacks in the treated kids, while the placebo group was not so fortunate.  If Dr. Urashima had followed the newest FNB recommendations, it is unlikely that 400 IU/day treatment arm would have done much of anything, and some of the treated young teenagers may have come to serious harm without the vitamin D.



"Likewise, a randomized controlled prevention trial of adults by Professor Joan Lappe and colleagues at Creighton University, which showed dramatic improvements in the health of internal organs, used more than twice the FNB's new adult recommendations.



"Finally, the FNB committee consulted with 14 vitamin D experts and - after reading these 14 different reports - the FNB decided to suppress their reports.  Many of these 14 consultants are either famous vitamin D researchers, like Professor Robert Heaney at Creighton; or, as in the case of Professor Walter Willett at Harvard, the single best-known nutritionist in the world.  So the FNB will not tell us what Professors Heaney and Willett thought of their new report?  Why not?



"Today, the Vitamin D Council directed our attorney to file a federal Freedom of Information (FOI) request to the IOM's FNB for the release of these 14 reports.



"Most of my friends, hundreds of patients, and thousands of readers of the Vitamin D Council newsletter (not to mention myself), have been taking 5,000 IU/day for up to eight years.  Not only have they reported no significant side-effects, indeed, they have reported greatly improved health in multiple organ systems.



"My advice, especially for pregnant women: continue taking 5,000 IU/day until your 25(OH)D is between 50-80 ng/mL (the vitamin D blood levels obtained by humans who live and work in the sun and the mid-point of the current reference ranges at all American laboratories).



"Gestational vitamin D deficiency is not only associated with rickets, but a significantly increased risk of neonatal pneumonia, a doubled risk for preeclampsia, a tripled risk for gestational diabetes, and a quadrupled risk for primary cesarean section.



"Today, the FNB has failed millions of pregnant women whose as yet unborn babies will pay the price.  Let us hope the FNB will comply with the spirit of "transparency" by quickly responding to our Freedom of Information requests."



And I should just mention that the story in The New York Times produced a phenomenal response in people posting to the story.  When I looked in the morning, there were already 255-some responses, and many had been redacted by the people at The New York Times, I mean, saying that they had protocols, they couldn't allow the level of fury that was being expressed, no doubt expletives and obscenities.  So they were deleting these things.  But there were a number of very knowledgeable responses from people who were saying, okay, this is just really irresponsible to be in the news.



LEO:  It's so odd.  And I noticed, since you raised my awareness on this, that my own doctor started testing for Vitamin D when he does blood tests.  It's just kind of part of the routine blood tests now.  My wife got hers back, and she was low.  And she recommended supplementation.



STEVE:  Anyway, I know that it's been a big interest of our listeners ever since I did the podcast, August before last.  And this generated so much feedback that I wanted to cover it today and just say they looked only at bone health.  It is the case that much less D is necessary for bone health, much more necessary - essentially the level you would have if you were spending your days out in the sun, and you were a young person near the equator - to keep you healthy.



LEO:  I'm taking my supplements.  At least I know they're not harmful.  But you should, obviously, folks, we're not doctors, you should consult your physician.  



STEVE:  Yes.



LEO:  And if you're worried, ask for a Vitamin D test.  All right.  So a little sci-fi.



STEVE:  A little sci-fi.  So I read science fiction when I'm on my stair climber, which I do most days for about 66 minutes a day.  It works up a good sweat, gets my heart rate up and so forth.



LEO:  Why 66 minutes?



STEVE:  It just sort of evolved that way.



LEO:  That's interesting.



STEVE:  I think I was at an hour.  And I looked at the calories I was burning, and I was, like, 643...



LEO:  You wanted to get to 700?



STEVE:  And I thought, yeah, I'll go to 700.  And I think I hit 700 by about 64.5 minutes.  And then I thought, well, 66 is a prettier number than 64.5.  So I just kept rounding up, one parameter or the next, until I ended up at 66.  And that takes me on the high side of 700 calories.



LEO:  That's awesome.  That's great.



STEVE:  So I just sort of stay there.  So consequently I'm needing a source of something to read.  And so I went looking for some more stuff.  And I'm constantly getting feedback from listeners, saying, hey, Steve, what's happening in the world of sci-fi?  So as it happens, still the very best things that I have found are what we've talked about before.  If listeners are not familiar with Peter Hamilton, he's at the top of my list.



LEO:  Me, too.  And you introduced me to him, and I love him.



STEVE:  Oh.  "Fallen Dragon."  You get an introduction.  It's a standalone volume.  He's very wordy.  But so these books are long.



LEO:  But they're all good words.



STEVE:  Yes, they are.  And he paints such a rich environment that, I mean, I still see all of these worlds that he has created for me.  So "Fallen Dragon" is a perfect introduction.  Then my second favorite series, it's just a two-volume series, is "Pandora's Star," followed by "Judas Unchained," which is the sequel to "Pandora's Star," which is just - I've read "Fallen Dragon" I think three times.  I've read both "Pandora's Star" and "Judas Unchained" twice.  Because these are things you can reread, or I can.  They're just spectacular pieces of work.



Then my second favorite we've also spoken of before, and that's Michael McCollum's books.  He has a website, Scifi-AZ.com, Michael McCollum.  He also writes multi-volume series which I very much enjoy.  Because, again, if I read one book, it's like, okay, well, that's gone.  It's annoying if the series isn't finished, and then you're, like, stuck waiting, which happens to me from time to time.  But his Antares Trilogy - "Antares Dawn," "Antares Passage," and "Antares Victory" - is just fantastic.  I read them all twice.  And I'm just sort of waiting now for it to be long enough for me to reread them.



And then the Gibraltar Trilogy I've mentioned:  "Gibraltar Earth," "... Sun," and "... Stars" is fantastic.  And in the case of "Stars," I read it before it was published because just to be his proofreader.  So that came out.  And I reread the prior two in order to get ready for the third one to be done.  So that's great.  And he also has many individual novels.



But new stuff that I haven't talked about before, I made a posting to the sci-fi newsgroup at GRC, and I said, "Hey, guys, I'm looking for more to read.  I need, like, kind of space opera stuff.  What have you got?"  And someone mentioned what was called "The Lost Fleet" series that's written by a guy named John G. Hemry.  But he writes under the pen name Jack Campbell.  And this is a series of six books called "The Lost Fleet" series:  Dauntless, Fearless, Courageous, Valiant, Relentless, and Victorious.  And I had never read anything like them before.  And they were really effective in filling time.  I can't say that they were fantastic science fiction.  But I needed something to do on the stair climber.  But I could also recommend them.



LEO:  There are audio books of this as well.



STEVE:  No kidding.



LEO:  Tomaho (sp) says it's on Audible.



STEVE:  Great.  And this gives nothing away.  I won't do any spoilers here.  Because in the first few pages we're reviving a survivor of the beginning of a war from a hundred years before.  So we're bringing him out of cryo sleep.  And what's happened is there's been this war that's been going on for a hundred years between two chunks of human civilization that are really upset with each other.  Because so many casualties and people have been promoted so quickly, the people in the current fleet, whose side we're on, have sort of lost the art of space combat.



And so we revive this guy from a hundred years before who says, wait a minute.  This is the way you're fighting?  And he organizes space combat in a really compelling and convincing fashion.  So we don't have warp drive.  We have worm holes you can jump between star systems with.  But the laws of physics and the speed of light play into this intimately.  And the author sets up some really interesting problems and solutions that involve configurations of fleets of ships that basically have conventional weapons and some beams and missiles and interesting weapons.  But things are constrained enough that you're working within a domain, a fictional domain with real limitations, which makes it really interesting.  And I found myself being sucked along in this.  So if you've run out of stuff to read, or to listen to, give the first one a try.  And I'll be surprised if you don't get hooked and end up with all six of them because...



LEO:  Sounds like Horatio Hornblower in the 25th Century or something like that.



STEVE:  I think actually I've heard exactly that analogy being made.



LEO:  I love those kinds of seafaring novels, so...



STEVE:  Yeah.  And there's interesting - there's a lot of politics because he ends up being, because he's a hundred years ago, he ends up being the most senior officer.  So he ends up commanding the fleet.  But then there's lots of people who of course don't like that.  And then there's some political interplay, and we've got a little romance stuff going on.  But mostly really, I mean, obviously contrived because it's fiction, but satisfying space battles.  And I've never seen, I've never read anything of this scope where you've got really interesting space battle scenarios with interesting puzzles and limitations.  So I wouldn't be surprised if you read the first one and then didn't get hooked.



LEO:  Sounds cool.



STEVE:  So I did all of those.  Then I said, okay, what next?  Then I ran across something called "Helfort's War."



LEO:  You like these big long series, don't you.  You don't want just one book.  You don't want just two books.



STEVE:  Well, and here was one where I ran out before the fourth book.  This is a series of four.  And it's sort of the classic newly minted graduate from Star Fleet, I mean, it's not set in the Star Trek environment, but we do have like the academy.  He's graduated from the academy, and we follow his career through four books.  And I ran out at the end of the book three, and book four just was published on the 23rd of November.  So it's available for Kindle, which is where I'm reading this stuff.  And I haven't yet started because I'm just finishing the fourth book in another series of six, which is Gregory Benford's Galactic Center Series.



So the Helfort's War books I really liked also.  Again, I recommend them.  I mean, top of the list is Peter Hamilton and Michael McCollum.  I don't think I would read these other ones a second time, where I have read the earlier ones a second time.  Of course not that much time has gone by.  But still I feel like I'm sort of done with those.  But really, I mean, they were diverting and interesting and I think stand very well.  And then Gregory Benford actually is a UCI physics professor.



LEO:  I like that.  I like hard science.



STEVE:  This is.  His is the so-called Galactic Center Series.  I've just finished "Tides of Light," which is the fourth in the series of six.  And here we sort of - we've got the humans versus the machines is like sort of the overall scenario there.  And I loved, back in the day, Fred Saberhagen's Berserker series.



LEO:  I haven't read those, either.



STEVE:  Oh, those are really good, Leo.  Berserkers being machines left over from some unknown alien race in the past that are out to kill off all biological life.  And really interesting sci-fi that's old.  It's been around forever.  But now we've got the so-called "mechs," the mechs versus the humans.  And this is a huge scope, like tens of thousands of years of history, but really interesting new ideas that I've never read before.  And also substantial works.  So I'm liking those, as well.  So "The Lost Fleet," "Helfort's War," and Gregory Benford's Galactic Center series.



LEO:  I'm amazed you have time to read all this stuff.



STEVE:  I spend a lot of time on the stair climber.



LEO:  I guess so.  Well, that's one of the advantages of being fit.  You have more time to read.



STEVE:  Exactly.



LEO:  Now, are you ready, Steve?  Questions for you.



STEVE:  Yes, indeed.  And I just will mention that you're right about the book series.  I look for the series because I'm wanting to get engaged and have a lot to read.  So it is a reason that I'm choosing those deliberately.  When I see it's, like, book six, I go, okay, good, I'll go find number one and move through them.



LEO:  No, I know what you mean because I like to get immersed.  And instead of, you know, once you get immersed, sometimes if you get immersed in a world, and it's over, it's like, well, golly.



STEVE:  Yeah, exactly.  If Peter Hamilton kept writing, I just wish he would keep going with his various universes.



LEO:  Well, what was it, was it "Judas Unchained" went on a little long.  I thought.



STEVE:  Yeah, and I never got into "The Dreaming Void," I think that's his next one.  Because I was just sort of - it sounded a little, I mean, I really do like hard sci-fi.



LEO:  Yeah, yeah.



STEVE:  I don't want fantasy stuff and people dreaming about something.  I sort of read the synopsis, I thought, eh, don't think so.



LEO:  Yeah, no, I like the hardcore stuff.  All right.



STEVE:  When he had, who was it, Al Capone coming back to life?



LEO:  Yeah.



STEVE:  It's like, uh, no, no, no.



LEO:  Yeah.  That really - yeah.



STEVE:  Yeah.



LEO:  "Fallen Dragon," that's the one.



STEVE:  Oh, it's a great first book, yeah.



LEO:  Question 1, an anonymous listener raises a good and disturbing point:  Steve and Leo, regarding the Chinese redirection of traffic, you forgot to mention that SSL would not have prevented snooping in the latest traffic redirection incident.  China controls root certificates that are installed on our systems - we've mentioned that before, including the Hong Kong Post Office - which enables them to do transparent SSL man in the middle.  Is that right?



STEVE:  That's exactly right.  So it is the case that - I do not think this was deliberate because many mistakes have been made with BGP, the Border Gateway Protocol, in the past.



LEO:  Yes, yes.



STEVE:  So it's much more likely that it was a misconfiguration in the router tables that inherently propagate themselves to the routers that they're connected to, which then propagate those to the routers they're connected to and so forth.  So this kind of thing can ripple through the Internet, and has many times before.



LEO:  Yes, yes, yes.



STEVE:  Yet it is also the case that this protocol is not secure.  And had this been deliberate, then traffic would have been routed, and there's absolutely nothing preventing them from doing on-the-fly certificate synthesis, signing the certificates with the private keys of the certificate authorities that are installed in all of our browsers.  So this anonymous listener is exactly right, that it is the case that SSL would not protect us.  And in fact, what that means is we would be saying www.amazon.com, be looking at what appeared to be a valid certificate, and not knowing that the traffic had been redirected through someone who had control of a certificate authority that had signed the certificate that was synthesized on the fly because they knew we were connected to Amazon.  So, yeah.  Not good.



LEO:  Not good.



STEVE:  Not good.



LEO:  Question 2, another anonymous listener had a thought about defeating Phorm-style man-in-the-middle eavesdropping:  Steve and Leo, would it be possible to derive a simple protocol using certain parameters known by both the browser and the server - but I guess no one else.  That would deter some systems like Phorm, but not unduly impede security services.  I was thinking perhaps the server would know, say, the connection IP address or some header, and the browser would know both the IP address of the server and the requested URL.  XOR them, should be fast and transient enough?  John Doe.  What do you think?



STEVE:  Well, no.



LEO:  Maybe you'd better explain it to me.



STEVE:  Yeah.



LEO:  I don't know what he's proposing here.



STEVE:  Well, so what he's saying is, isn't there something, some simple way of preventing Phorm, which is essentially an ISP-sanctioned man-in-the-middle and eavesdropping entity.  Phorm is the thing which was installing its own cookies on other people's domains so that it can track us and profile us, essentially.  So he's saying, if we established a secure connection between browser and server, then the man-in-the-middle aspect and the eavesdropping aspect could be thwarted.



The problem with doing that is, and exactly as you said, Leo, is that the man in the middle would have to be excluded from information that only the browser and the server knew.  The man in the middle could see the IPs at each end, could see the headers that were being exchanged.  So...



LEO:  So now you're talking encryption.



STEVE:  Well...



LEO:  Public key encryption or something like that.



STEVE:  Yeah.  You couldn't - you'd need both encryption, and you'd need authentication.  And we've talked about how, if you don't have authentication, if you can't authenticate, for example, the server at the server end, then anybody, by definition, anybody could impersonate the server and become a man in the middle.  And the only way to get authentication is for there to be some sort of secret which the authenticating party is able to prove they have.  And the only way to do that in an open public system is to use a public key, where the authenticating party is able to prove they own the matching private key to the public key which you and everybody else have.



So unfortunately our listener is trying to come up with, like, a simpler solution, something less heavyweight, easier, faster, lighter weight, XOR - well, of course XOR is extremely weak.  Well, it's not even crypto, I can't call it crypto because it would be trivial to, even without doing anything but looking at the traffic that has been XOR'd, you could easily crack that, if you were XORing against a fixed pattern.  If you were XORing against a pseudorandom stream, like the RC4 crypto does, then, all other things being secure, this could potentially be secure, too.  But the problem is there just, there isn't a way to make it simpler.  If you make it simpler, you lose authentication.  And if you lose that, you've got nothing.  So just unfortunately we have made it exactly as simple as possible, which is unfortunately not very.



LEO:  Question 3, Rick Shepherd, Reno, Nevada, wonders about the ".p2p" TLD, Top Level Domain:  Steve, I'd like to hear your thoughts on the proposed .p2p TLD.  It's supposed to be ICANN-independent.  And this is relevant to what's going on right now with ICANN being used by the Department of Homeland Security to take down torrent servers.  It would allow we-the-people, he says, to bypass traditional DNS and thereby remove the power from ICE or whomever may wish to take down domain names.  He refers to a website, dot-p2p.org, it's a wiki, for more information on that one.



STEVE:  So this is interesting.  What is being proposed is a sort of a secondary or alternative DNS which would be decentralized.  And whereas our existing DNS is based on a hierarchy, starting at the top with root servers, the famous 13 root servers that then point to the .com and the .org and the .net and all of the second-level domain and so forth.  There's this proposal to create a .p2p, sort of like .com, .net, .org, .edu and so forth.



The problem is it's being led by the Pirate Bay guy, Peter Sunde, who was just convicted recently of, along with the two other Pirate Bay people, of being complicit in the theft of copyrighted material.  And they're appealing this judgment that did just recently come down against them.  The prison term was reduced to eight months, yet the fine was increased to, I think it was $8.8 million U.S., although it was denominated in their currency.



So in principle I'm troubled, as you are, Leo, by the idea that our government, the U.S. government, and presumably other governments, could get it into their head that removing domains from the Internet is, wow, gee, that was easy.  In the same way that we've got this problem with earmarks in our legislation, where some legislator tags something into legislation that's going by, and it gets through, you can imagine someone saying, yeah, could you remove this domain for me as a favor because they're our competition.  And it gets sort of slid into some other package of domains being removed.



I mean, to me it feels like a slippery slope.  The problem I have is that I hate the idea of this being used only for piracy and theft of copyrighted material, which is really the way this seems like it's being set up.  I'm troubled by the idea that domains can get removed.  So what this is, the idea is it would be like BitTorrent.  And in fact they're proposing that it would actually use the decentralized BitTorrent hashing protocol.



LEO:  Oh, that's interesting.  Because you have a problem, if you're not in the main directory servers, how do you get visible? 



STEVE:  Right.  And so the idea is that people who wanted access to this, it's probably going to end up being a hierarchy of pirate domains, which if nothing else would live sort of off the grid, or off the hierarchy.  You would run a client on your computer, which would link up in BitTorrent style to a mesh of other clients and share all of this .p2p top level domain, essentially share the hierarchy of DNS.  The client living on your computer would filter your outgoing DNS queries.  If the domains going out were not .p2p, that is, didn't have that on the far right side, it would let it go through.  And the regular public DNS hierarchy would resolve the IP address.



If, however, anything you put into your web browser, piratesrus.p2p, then the client running on your machine would see that, intercept it, and then use this sort of decentralized, floating in the cloud, interlinked, peer-to-peer DNS alternative for its IP resolution.  And you'd get the IP of that domain.  And it would be, from a user standpoint, rather transparent.  So it's clever.  It can work.  And it is going to happen.



It's pretty much, I mean, there's enough inertia behind this already that I think - and it's an interesting enough idea that people who are interested think, hey, that's kind of cool.  I mean, I would think it was kind of cool except that I'm afraid it's only going to be used by the dark forces and not by people who are sort of more honestly wishing to avoid government control.  But I'm sure it'll be used for that, too.  So...



LEO:  I think at some point we may need a darknet.



STEVE:  You know, the way things are going, it does seem like it.  I mean, I'm finding myself, as I was talking about, I mean, innocently exchanging some email about what's going on in airports with body scanning, and even talking about nuclear and Iran and Stuxnet, I'm finding myself a little self-conscious about the fact that I'm probably now being, I mean, I'm using words that are tripping filters somewhere, and my email is being observed by our government.  And it's a little creepy to think that that's going on.  I mean, I hope they understand I'm one of the good guys.  But it is unfortunate that this is changing.  And you know, Leo, you can almost sort of feel unfortunately this happening.



LEO:  You really can.



STEVE:  As the Internet matures, it's like, well, they're not happy about the taxes they're losing for Internet sales.  They're not happy about what happened with WikiLeaks and these cables getting out.  The government wants control.  And of course now we have the FBI not happy about encryption.  And it's poked me right in my own backyard.



LEO:  I think the forces of reaction, the reactionaries are actually gaining power.  And the good news is the people who know how to use technology can be the freedom fighters.  I think it's the 21st-century freedom fighters are the hackers of the world, and I say that in the best sense of the word, who know how to use technology.  And I think ultimately we might have to create a darknet.  But the good news is, we can.  We know how.



STEVE:  Yes, that's true.  It is true.  And the bad news is, I mean, when I look at, for example, my own intention of doing CryptoLink, I want to empower people to have secure private communications.  I'm not going to do it if the law requires that I put a backdoor into the product such that I'm not able to offer them secure private communications.  And what's so sad about this is math is what this is based on.  Math exists already.  I mean, the technology to do this exists.  OpenVPN is a perfectly fine, functional VPN system.  It's way clunky, and I could make something far better.  But the bad guys will use that if they want something that cannot be eavesdropped on.  I mean, it already exists.  The horses have left the barn.  So I don't know what my position is on something like a distributed, control-free network.  It is certainly possible to do, just like secure crypto is possible to do.



LEO:  I would say now is the time for all good men to learn a little programming and network configuration because - I actually said this about eight years ago.  I did an interview for a movie about Adrian Lamo about hacking.  And I said, I think hackers are the freedom fighters of the 21st Century.  I think instead of the right to bear arms, we need a new Second Amendment that includes the right to bear technology.  Mark Jones - go ahead.



STEVE:  I was just going to say, and I hate the idea, I hate the idea that CryptoLink might be used for a purpose that was really foul, I mean, really evil.  But that's the nature of, I mean, that's the nature of technology, in the same way that a nuclear bomb can be used for something that is really wrong, really evil.  It's not the atom's fault that it contains a lot of energy.



LEO:  I think you have to consider what the alternative is.  Yes, it's bad.  But the alternative is worse.  Or yes, it's potentially bad, but the alternative is far worse.  It's basically a world controlled by those who would assert their power.



STEVE:  And unfortunately we see that they choose to.



LEO:  And they're glad to.



STEVE:  Yes.



LEO:  Mark Jones in Midland, Michigan wonders about web fingerprinting and fonts.  You're turning me into a libertarian.  We're both, you know, it's funny.  Steve and I are both staunch liberals.  But I have a feeling we're becoming more libertarian as the government becomes more reactionary.  Mark Jones in Midland, Michigan wonders about web fingerprinting and fonts:  Steve, let me thank you for the wonderful podcast.  It's been my favorite and a must-listen for several years now.  You and Leo are the best.



Today's Wall Street Journal's front page contains another article in their on-going series on web privacy.  This one addresses - which we have decried, I might add.  This one addresses the technology of BlueCava for web fingerprinting.  The technology is clearly not unique to 

BlueCava.  It is the web fingerprinting technology you described some time ago that polls many different attributes of a particular system.  A unique 

pattern that identifies the system emerges when these attributes are viewed as a set.  I don't remember what episode we talked about that in, but it's just a few episodes ago and worth listening to.  It wasn't the evercookie, it was...



STEVE:  Unlike the other episodes.



LEO:  They're all great.  Well, you know, it's really interesting because this show is, in many says, on the cutting edge of what's going on here.  It's not just security and privacy, it's everything.  As a loyal Security Now listener, I was surprised to actually learn something from the mass media about security.  He's talking about the Journal article, not us.



STEVE:  Right.



LEO:  The article called to my attention that one of the means the fingerprinting uses is to interrogate fonts on the system.  I think you mentioned this, actually.



STEVE:  Yes, font enumeration, yup.



LEO:  Right.  Several years ago I converted my handwriting into a font.  I gave the resulting font the fairly obvious name of my name.  My name is fairly generic, but I'm betting I might be the only person to have a font with my name.  I bet you're right.  I never thought this might be a beacon for tracking me on the web.  And by itself, even if your name is John Smith, by itself it might not be.  But then if there's a universe of 12 John Smiths who have fonts named John Smith, you're the only one with this version of Flash, this version of a browser, this particular screen resolution.  By the time they add them all up, we're all one of a kind.



This prompts a couple of questions:  How many ways can the fonts on your system be interrogated by a website you visit?  Can all of the BlueCava methods be blocked by the use of NoScript?  Are there other means to block the font list from prying eyes?  I think that's it.



STEVE:  How many ways can the fonts on your system be interrogated by a website you visit?



LEO:  Is it JavaScript that does that?  JavaScript is activated by the visited site, and it says - because sites can typically query your computer about its capabilities.



STEVE:  Yes.  Now, some of the information is just in the browser headers.  But, for example - well, okay.  So the reason I chose this question was not so that I could tell him that there were three ways that fonts can be queried.  Because, I mean, who knows how many?  It's just I thought this was a great question.  Unfortunately, BlueCava is somewhere, I mean, I'm looking over my shoulder now because they're in Irvine.



LEO:  Is it a company?



STEVE:  Yeah, it's a company.  The Wall Street Journal's article is just horrifying.  I mean, it is chilling.  This guy, I mean...



LEO:  This is legal, by the way.  It's completely legal.



STEVE:  Yes, exactly.  I mean, but it's one of those things where you read the article, and it just sends shivers up the spine of anyone who's concerned about, like, their privacy.  Because he's boasting how many different fingerprints he's accumulated, and how unique they are.  And just in the news, I didn't pull this out for the podcast, but a Department of Transportation in, I think it was in Florida, was just found guilty of selling tens of millions of drivers' personal information to an Internet-based marketing company.  So it's a government agency.



LEO:  How dare they?  How dare they?



STEVE:  I know.  Including Social Security numbers, which they have.



LEO:  What?



STEVE:  Yes.



LEO:  What state was that?  Arkansas?



STEVE:  It was in Orlando.



LEO:  Orlando, Florida.  Geez.



STEVE:  Yeah.  I think if you put in Orlando, Florida - boy, I can't - I pulled it up by putting the name of the marketing company.



LEO:  That's terrible.



STEVE:  But I just - it's like, oh, goodness.  So now we have the government profiting from selling our personal information to Internet-based marketing companies.  So, I mean, they'll get their hands slapped hard, and it's wrong that they did it.  But the information is loose now.  It's gone.  You can't get it back.



LEO:  I'd be incensed.



STEVE:  So I wanted to reiterate that, yes, the number one thing that's protecting you is blocking scripting, that is, NoScript.  Because all of this stuff, font enumeration, I should say the deeper lock-onto-you technology involves scripting.  So remember that scripting, I mean, it's a mixed blessing.  Yes, more and more sites need it.  I know that a huge percentage of our listeners are running NoScript.  And, yes, it's annoying.  It gets in your way to be blocking scripting by default.  I'll go to sites that I haven't visited before, and something kind of doesn't seem right.  It happened this morning when I was going to some sites, looking around at things.  It's like, okay, this page doesn't seem correct.  Or, like, I'll fill in the state that I'm in, and then the fields on a form below didn't populate, and I go, ugh.  And so I turn on scripting, and now the site comes alive, and the form works the way it's supposed to.



Well, so it isn't transparent.  But given that there's so much power in scripting, you want it to be only used on your behalf, for your benefit, and not against you.  And unfortunately, companies like this, that are founding themselves on what scripting can do, are taking advantage of that.  So scripting is necessary for enumerating fonts.  You can't do it without it.  But even without scripting, browsers give away a lot in their headers, as we've seen.  I think it was the EFF that did their - the name's not coming to me now - Panopticlick that we talked about, again, several months ago.  Panopticlick, as I remember, was just doing passive examination of what the browser was relinquishing without scripting.  And it was comprehensive.



So even just looking at, like, the version numbers of all the things that we've got installed on our computer tend to make it unique.  And the resolution of our screens, and the obvious information that is getting away.  So somebody who really is concerned about this does need to do something like we've talked about, which is boot a browser-enabled OS from a CD, or use a virtual machine, use a VM, and to use a generic browser that you haven't customized much, and do your surfing that way, and maybe change it from time to time so that you don't have a static fingerprint.



I mean, I don't mean to overhype the issue of tracking and fingerprinting.  I know that some people just, eh, they don't care.  But increasingly, when people realize that this is going on behind their back, if nothing else, they ought to understand what they can do to prevent it if they do care.  And, sadly, scripting is the means for this happening, and disabling it conditionally is the way to get around it.



LEO:  I don't like it...



STEVE:  No.



LEO:  ...when smart techies are the wrong side of the equation.



STEVE:  Yeah, it's interesting, this guy who founded BlueCava, he apparently years ago started off because he wanted to protect downloadable music software.  And so he came up with a way of locking music software to a machine by looking for, like, the fingerprint of the machine so that it would only run in the machine with that fingerprint, and people could use it freely, try it out in a demo before purchasing it, and then he wouldn't have to worry about it getting loose.  And then he realized, hey, there's a lot here that I can lock onto that makes this unique.  And it's like now, of course, he's switched over to the dark side, going to make money by tracking and profiling and building up his big database of fingerprints.



LEO:  Oh, he's so proud of it, too, if you visit the website.  It's like, I've got a patent, and look what I can do, and blah blah blah blah blah.  Boo, hiss.  Question 5, Edward "Ted" Doyle in Columbia, Missouri wonders about the allocation of IP addresses for efficient routing:  Steve, I have been listening since Episode 1, my favorite podcast.  I've been reading a wonderful free book about TCP/IP, and neither your past podcasts introducing basic Internet concepts, nor the first 500 pages of the book, have addressed so far the notion of IP address allocation for efficient routing.



There are about 64 times 256, or something like 16,000 Class B addresses, that is, IPv4 with the first number of the IP address starting 128 through 191.  If these addresses are assigned to organizations in a disorganized fashion, the following situation could occur.  I don't know if I want to read all this.  Basically, 140.65.* goes to a company in Australia.  Then 66 to Poland, 67 to Edmonton, you get the idea.  They're all just geographically random.  There must be some order to the way addresses are assigned.  He's thinking, like, zip codes, where it narrows it down geographically.



STEVE:  And zip codes is a great example, as a matter of fact, Leo.



LEO:  Yeah.  For instance, if the IP block with 140 through 147 in the first byte were assigned to Europe, and then Europe could, say, take 140 and assign it to England, 141 to France and so on - I don't think it was anywhere near this organized, of course.  Thus the router in St. Louis, using one router table entry, could examine the first number in the IP address, see something between 140 and 147 and know the packet needs to be routed eastward toward Europe.



Is this how IP addresses are assigned and routed?  If not, could you describe how IP addresses are allocated to make routing feasible?  We need Jon Postel on.  He was the guy who made this all up way back in the - way back when, the late Jon Postel at USC.  Yeah, I know that most routers use Classless Inter Domain Routing, or CIDR, obsoleting the old class A, B, and C systems.  The book I'm reading, by the way, is "The TCP/IP Guide" by Charles Kozierok.  The full 1,600-page text is available - I love this - at tcpipguide.com.  So far I'm only about a third of the way in.  The next 100 to 200 pages I'll reach the chapters on routing protocols.  I will continue reading the book and listening to your podcast for the answer to this question.  Best regards, Ted Doyle, Columbia, Missouri.



STEVE:  Okay.  So there's a cool URL you need to put into a browser, and our listeners should if they're listening:  bgp.potaroo.net.



LEO:  Bgp.potaroo.net.  Oh, look at this.  This is interesting.  I don't know what it is, but it's...



STEVE:  Well, that's the growth of the BGP router table over time.



LEO:  So this is the table that all border gateway routers use to figure out where goes what.



STEVE:  It's the size of the table.  Currently 336,807 entries.



LEO:  How big is it?



STEVE:  Well...



LEO:  Is it 100K?  A megabyte?  A gigabyte?



STEVE:  No.



LEO:  Can't be very big.



STEVE:  These routers, well, the good news is, an IPv4 address is four bytes.  And a mask is four bytes.  So all of these, they do compress, and they are very dense, but there are a lot of them.  So to wind back a little bit and answer Edward "Ted" Doyle's question, is unfortunately, had we to do it again, we would do it differently.  But when has that not been the case?



LEO:  Nobody thought it would be this way.



STEVE:  No one thought it was going to even work, Leo.



LEO:  This, I don't know who is "potaroo," but this is a really interesting site.



STEVE:  Yeah, it's a great site.



LEO:  Wow.



STEVE:  There's a lot of interesting statistics.  So to some degree this does work.  For example, Level 3 has the whole four-dot network.  So to the degree that Level 3 controls the routing within their network, there doesn't have to be individual entries in the global BGP tables for every network within Level 3.  For example, my little 16 IPs at Level 3, they certainly aren't represented uniquely in some router table entry in Bulgaria.  Instead, anything that begins with four goes in the direction of Level 3, and that's the last of it.  So it absolutely is the case that, as we know, there is a hierarchical allocation of IP space where four-dot is Level 3.  And I think HP has 15 and 16, or they have two consecutive ones that are Class A networks.  And so everything beginning with 15 and 16 goes towards HP.



Now, the problem is HP is widely distributed geographically.  So their IPs are probably global, and there will be many more entries for things beginning with 15 and 16 than, for example, Level 3 that might be more regional.  But it's certainly the case that there is some regionality to routing.  And so when a large ISP is regional and giving their various customers chunks of address space, well, everything first goes to the ISP and is routed monotonically to the ISP.  Then the ISP's routers break it up and send it to the appropriate customers within those networks.  So if we could renumber the Internet, oh, we could radically simplify things.



LEO:  Interesting.  Interesting.



STEVE:  But we can't renumber the Internet.  I mean, no one wants to have chunks of their IPs just ripped away and changed.  So we're sort of stuck with this.  It's not clear that it's going to get any better, either.  I mean, we can see the growth is - it's not exponential, but it's certainly a little more than linear over time.  And here we're saying we need - that 4.3 billion IPs is no longer enough.  So we've outgrown 32 bits of IP space.  Unfortunately, routing is going to keep being a challenge.  So, yes, it would be nice if it were done somewhat more sanely.  But at this point the cat's out of the bag.



LEO:  Too late.



STEVE:  Yup.



LEO:  Dennis Keefe, Panama City, wonders about securely using LastPass on a work PC.  Steve, the following is a post from my blog.  What do you think?  If you love LastPass but are not exactly comfortable about having it installed on your work PC, you might like this solution.  Today I tried this approach.  First I used TrueCrypt to create an encrypted volume on the hard drive.  Most offices won't let you do that, by the way.  Many offices won't.  Mine will.  Next - maybe he works for me.  Next I went to PortableApps.com, and instead of downloading the software to a USB drive as usual, I installed it into the encrypted volume.  Now the only way to access Firefox and my LastPass vault is by mounting that TrueCrypt volume.  Of course I need the pass to do it.  If you still need Firefox installed for others in your office, just install a stripped-down version for others to use that doesn't include any personal info, and you're safe.  Keep up the great work.  Dennis Keefe, TheCommonGeek.com, Panama City, Florida.  That's actually a very clever idea.



STEVE:  It is clever.  There's one thing I would add to it.  First of all, what PortableApps does is kind of neat.  They've got portable-ized versions of existing apps, like Firefox, for example, that are specifically well-behaved in not using things like the registry.  So, for example, Firefox will create a traditional INI, an initialization-style file, where all of the things that it would normally be storing in the registry, all of its configuration information, it will store locally instead.  So these are deliberately portable-ized versions of otherwise non-portable, or maybe you say "unclean" from a standpoint of leaving fingerprints or footprints behind, applications.



So the one thing I would add is that the LastPass people themselves have done a portable LastPass.  So instead of using the normal LastPass, use LastPass Portable, which is freely available and downloadable, and then you've really got the best of both worlds.  You've got Firefox, which is itself not going to dirty up the computer leaving anything behind; and LastPass, which you can be absolutely sure isn't going to do that, either.  The problem with running non-portable LastPass and Firefox is that, although Firefox may be behaving itself, you don't know that the plug-ins you're running are going to behave themselves.  And they certainly could reach out and go put stuff in the registry, which you're saying you explicitly don't want to have happen.  So use the portable version of LastPass, and then you're good to go.



LEO:  Perfect.  Question 7, Ralph in California.  He wonders about alternatives for Macintosh for reading PDFs.  In Episode 276, "Testing DNS Spoofability," you encouraged listeners to find an alternative to Adobe Reader.  And I think we mentioned Foxit.  I use Foxit Phantom, which I love, on Windows.  What are the best-of-breed PDF readers for the Mac?



STEVE:  And Leo, this is a question for you.



LEO:  You don't need one.



STEVE:  That's what I thought you were going to say.



LEO:  Because in fact that's really what's kind of killed the whole market for PDF readers for the Mac.  Apple distributes Preview with Macintosh, which reads PDFs.  If you want to annotate PDFs, there's a free open source program called Formulate Pro.  It's what I use.  Lets you take a PDF and annotate it.  Whenever I get documents that I need to sign, I just open them in Formulate, paste my signature on them - it's probably illegal - save them out, and I've got a PDF with a signature on it.  So you don't need it.  Preview works great.



STEVE:  And, you know, Apple must have had a deal with Adobe a long time ago because of course the original Apple LaserWriter that was the first laser printer was using PostScript as its language.  And we know that that's the basis for all of this PDF technology and so forth that Adobe has.  So I would imagine some sort of license agreement was created back in the dim early days of personal computing which Apple has been able to cruise on ever since.



LEO:  The NeXT Corporation used something called Display PostScript for its display layer.



STEVE:  Right, the entire system was PostScript-based.



LEO:  It's my understanding, you know, I've asked this question because I'm not clear, did they license this?  PostScript is open.  And so I think...



STEVE:  So the specification is formally open.



LEO:  Exactly.  So I don't believe that Apple actually licenses the ability to read and write PDFs.



STEVE:  They don't need to.



LEO:  Or to use Display PostScript.  I think they wrote their own clean code based on an open standard.



STEVE:  That would explain why Adobe's not running around suing everybody, because they can't.



LEO:  Whoops.  I'm sure they would love to.  Rick in Canada gives us our last question, which happens to be the Firefox Add-on Tip of the Week.  Put echo in there later, okay?  Steve and Leo, I found a great Firefox add-on.  It's SSLPersonas.  All one word, SSLPersonas.  What it does is change the Firefox persona on the fly - I guess that's kind of like its profile; right?



STEVE:  Well, it's the way the whole UI looks, like coloration and so on.



LEO:  Oh, everything, okay.  So that you know you're on an SSL site, when you're on an SSL site it rewrites the look of the whole browser.  Instead of needing to look for a little lock or the "s" on the "http" on the address bar or the green address bar, it changes everything.  Check it out.  Listener since No. 1, and a happy owner of SpinRite.  Rick in Canada.  Did you try it?



STEVE:  I did not try it, but I'm going to.  I didn't because I've got so many tabs open that restarting Firefox is a major event.



LEO:  I don't even want to restart Firefox, says Steve.



STEVE:  But I looked at the reviews.  It looks really neat.  So I wanted to recommend it.  I mean, you might call this "in your face," SSLPersonas, because in the examples it turns the whole thing green, or the whole thing blue.  It's able to essentially verify the validity of the certificate.  So it's not just are you using SSL, but are you using SSL with a completely valid certificate, in which case it just, I mean, it really makes it obvious, which I think is nice.  I like the idea that the UI is going to be really showing me the security of the page that I'm on.  So I can't wait to restart Firefox after the podcast and give it a shot.  But I wanted to share with our listeners because I think that's a great add-on.



LEO:  Yeah.  And you could always do - it doesn't have to be green.  I mean, you could do something really silly.



STEVE:  Yeah.



LEO:  You could say "safe."  I like he's put locks and certificates and all sorts of stuff on it.  That would be a great thing to do for less sophisticated family members.



STEVE:  Sophisticated, yes.



LEO:  Say, "Mom, unless you see this, you ain't got it."



STEVE:  Right.



LEO:  I think that's good, yeah.  He has a bunch of different, I guess, templates that you can use.  No Chrome version that I know of, but that would be a nice little Chrome extension, if anybody wants to write one.



STEVE:  Oh, and speaking of Chrome, there is a portable Chrome to go with, I mean, I'm sorry, portable Chrome and portable LastPass for Chrome.



LEO:  Right.



STEVE:  So people who are Chrome users, as I know you are, Leo, can do the same portability trick with LastPass using the portable LastPass for Chrome, in addition to the portable LastPass for Firefox.



LEO:  LastPass did everything right.



STEVE:  Oh, they really - and I will take this opportunity again to say I'm loving it.



LEO:  I use it everywhere.



STEVE:  I mean, I really am.  It's just I can't imagine now life without it.



LEO:  Yeah, no kidding.  Just done right.



STEVE:  And it's free.



LEO:  Steve Gibson is at GRC.com.  That's free, also.  Lots of freebies.  Lots of great free utilities, that DNS spoofability thing that we talked about, the DNS Benchmark thing that we talked about, there's all sorts of stuff.  ShieldsUP! - why are you laughing?  What do you call it?



STEVE:  The spoofability thing.  The Spoofability Test.



LEO:  Tester, yeah.  Oh, there's so much free stuff there.  I like Wizmo.  That still works on Windows 7.  It's great.  It's like 12K of assembly code.  It's tiny.  And of course don't forget the bread and butter, which is SpinRite, the world's best hard drive maintenance and recovery utility, a must-have if you've got a hard drive.



STEVE:  I did run across three really fun testimonials just this morning when I was reading the email bag.  So I'm saving those.  I'm saving one of those for next week and for weeks to come.  So...



LEO:  Must make you feel good to get all those.



STEVE:  ...thank you for sending them.  Yes, it does.



LEO:  You're saving hard drives right and left.  You can also find this podcast there, including 16KB versions, which are only available from Steve because he actually makes them.  And he also gets the transcripts done by Elaine, so that's what you'll find there, all the show notes.  We also have it, of course, it's on iTunes and the Zune Marketplace and at TWiT.tv/sn.  We record the show every Wednesday at 11:00 a.m. Pacific, 2:00 p.m. Eastern time, at live.twit.tv.  We invite you to tune in and join us in the chatroom, irc.twit.tv.  It's fun, but you can always listen after the fact.



We have audio as well, and video, too, by the way, so you can watch Steve.  And Steve sometimes does this show with his eyes closed and his hands like this, and it's really fun.  Steve, always a pleasure.  I am not going to be here next week.  I'm in France.  Tom Merritt will fill in, I'm sure quite capably.  Have a great time next week, and we'll see you in two weeks.



STEVE:  Will do.  Thanks, Leo.  Talk to you in two weeks.  And thanks so much.



LEO:  All right.  Take care.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#278

DATE:		December 9, 2010

TITLE:		Tag Me! (with RFID)

SPEAKERS:	Steve Gibson & Tom Merritt

SOURCE FILE:	http://media.GRC.com/sn/SN-278.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up on the week's security news, Steve and this week's co-host Tom Merritt discuss the interesting security, privacy, management and technology issues surrounding the implantation of a remotely readable RFID (radio frequency identification) tag into one's own body for the purpose of being authenticated by devices and systems in one's own environment, such as laptop, car, garage door, house front door, etc.



TOM MERRITT:  It's time for Security Now!, the show that helps you stay safe online, with the man who knows security better than anybody I know, Mr. GRC.com himself, Steve Gibson.  Welcome to Security Now!, Steve.



STEVE GIBSON:  Wait a minute.  You're not Leo.



TOM:  No, I'm Leo.  A little time travel and beard growth.  No, Leo's off at LeWeb in France.



STEVE:  LeWeb.



TOM:  I am very excited to have a chance to co-host Security Now! with you here.  I don't know if you know this, but SpinRite saved a hard drive for me in 1993.



STEVE:  I never knew that, no.



TOM:  You wouldn't know unless you had some weird tracking system that...



STEVE:  No, no, no.  Not me.  I'm Mr. Privacy, so there's no tracking going on.



TOM:  I had a Packard Bell 486DX that wouldn't start up.  And then I booted SpinRite off a floppy, diagnosed, and was good to go from there on out.



STEVE:  Very cool.  Still going strong, strangely enough, amazingly enough.



TOM:  So there.  I know you have a testimonial later in the show, but there's an extra one for you.



STEVE:  Well, thank you.  So today we have Episode 278.  And it's a topic that has sort of been on my radar for a while.  And a number of technology things have sort of been happening.  I wanted to talk about sort of the technology side mostly, because of course this is primarily a technology podcast, though this also has some non-technology aspects which are sort of intriguing, the idea of RFID-tagging people.  So I call the show "Tag Me (With RFID)," which I thought...



TOM:  So this something we're just starting to see in materials and shipping containers and clothing.  We're going to be talking about doing it to ourselves?



STEVE:  Well, yes.  And in fact, believe it or not, there are even some states that have gone so far as to put legislation on their books to prohibit employers from mandatory RFID-tagging of their employees.  The FDA has approved RFID-tagging, I mean, like, subdermal, underneath your skin, so that this thing is, like, embedded in you.  The FDA has approved it since, like, for the last six years, back in '04.  And the technology exists.  But so far, from a crypto standpoint, I'm very unimpressed.



So I thought it would be fun to sort of talk about all aspects of being tagged, what it means, like from a standpoint of tracking and health and safety.  But also, primarily, what are the requirements for the technology that would, for example, have me feel - me, Steve Gibson - feel good about being tagged?  And frankly, I mean, I'm not all down on it.  The idea that my car would know me; that I could just have a simple button on my garage door so I don't have to have a key or a keypad; my front door could be unlocked whenever I'm in the vicinity and locked when I'm not.  That my laptop would recognize me, my phone and so forth.  I mean, you could imagine, if it was done right, there are some serious convenience factors associated with it.  And then of course there's always the dark side, too.  So I thought it would be fun talking about that this week.



TOM:  And that's the important thing to get into; right?  Because all technologies are tools.  And there's good and bad sides.  And so if you want to take advantage of the good sides, you need to know the bad sides.  Am I confusing Kevin Warwick here, or is there somebody who has done this, who has RFID-chipped themselves to test this out?



STEVE:  There's actually a hobbyist movement.  I found some content on the web, people talking about it, where one guy posted:  "Hey there.  Yeah, the cosmetic surgeon gave me an injection to numb the area, cut a 3mm hole in my skin, lifted it a bit using medical scissors to separate it from the underlying tissue, then gently pushed the glass tag into the hole and sealed it at least 2mm deeper into the hole by gently pushing on it with a medical instrument of some kind."  He says, "The important thing is to get it between the dermis layer and the underlying tissues, and not to go deeper than just under the skin.  Otherwise migration could be an issue, and you will likely have a much more difficult time removing it."  Or finding it.  So, I mean, you could do this at home if you were so inclined.  So, yeah, I mean, it actually is happening.



TOM:  It does make my skin crawl a little bit thinking about it.



STEVE:  I know.



TOM:  You know what, I've done it to both my dogs.  Both my dogs have tags.



STEVE:  Oh, no kidding.



TOM:  In case they get lost, they can be scanned, and there's a database where you can check and find out where their address is and all of that sort of thing, in case their collar was off or anything like that.



STEVE:  When you say you've done it, you mean you yourself had a syringe and...



TOM:  No, no, no.  I should say I've had it done.



STEVE:  Because there are syringes you can buy that inject these things in yourself.



TOM:  Yeah.  Maybe I will.  We'll talk about it.



STEVE:  And we have a little bit of updates, and of course security news.  And I have an interesting testimonial about SpinRite rescuing a RAID, which is something you don't normally run into because people think, well, if you have a RAID, you don't need hard drive data recovery.  Turns out not to be the case.



TOM:  All right, Steve.  Let's talk some security updates.  What do we have in the pipe?



STEVE:  Well, we've had a very quiet week.  I know of nothing of significance that's been updated.  I did, however, want to remind people that we still have this pending local privilege escalation exploit that was a zero-day vulnerability for all versions of Windows, which the danger is that hackers are using it.  It's in the wild.  Microsoft learned about it without any opportunity to fix it in their last patch opportunity.  And so thanks to the fact that the first of the month was a Wednesday, that means that the second Tuesday of the month, Microsoft's Patch Tuesday, is as far into the month as it can possibly be.  It's not till next Tuesday, December 14, that we have the second Tuesday in December.  Hopefully they'll have this thing fixed.



There was a function in the graphics library down in the kernel which had a classic buffer overrun that allows someone who calls the function to get their code to be returned to with full root-level system privileges.  So what that would mean is that, if something did get onto your system - as we know, we're always telling people, do not run normally as an administrator.  In the newer systems, in fact, really no one is running as administrator.  You're able to elevate yourself when necessary to those privileges.  But the idea being that you're relying on that boundary, being a non-privileged user, to protect you from, for example, anything that gets on your system from being able to install itself as a rootkit.  So this allows for rootkit-ish style attacks by getting full kernel privileges.  Hopefully this will all go away next Tuesday.  And the problem is there's really no workaround for it.



TOM:  That's what I was going to say.  So this attack happens even if you're not running as admin.



STEVE:  Correct.  You could be running as a non-privileged user, open a PDF, if you didn't have your Acrobat or whatever PDF reader up to speed, open a PDF that uses an exploit, whether known or not, but in any case still active, to run some software that would then get privileges which otherwise your software wouldn't have and which your system is protecting itself by restricting in order to go down and, for example, modify the boot sector and get control of the system prior to Windows booting, and then install itself as a rootkit, which there's a number of things that are doing that now.  So anyway, we're holding our breath for one more week.  And with any luck, next time - we're recording this next week on Wednesday after Patch Tuesday - I'll be able to say, yay, they fixed it.



TOM:  I hope so.  You know, I open most of my PDFs as Google Docs out of Gmail.  Does that provide any extra protection against this sort of thing?



STEVE:  Well, in the case of PDFs it does.  Google has that nice PDF viewer now.  And so the idea being that you're not running the PDF interpreter on your system, you're looking at the output from it.  But the other bit of news this week, or a relevant piece of news, is that the Google Chrome browser was just moved up to v8.0.  It's been in the Dev channel for a while.  It's now in their regular release channel.  In fact, anybody who fires up their browser will probably notice that they're now at v8.0.552.215, which introduces something we've talked about as coming soon, which is now available, is Google's PDF viewer running in the Chrome browser in a sandbox.



And so the idea is - Google's been talking about doing this for some time.  Their own PDF viewer, not Acrobat, not a plug-in, runs natively in the browser.  The browser knows how to view PDFs.  You don't have to add anything to it.  And it's running with its own set of privilege restrictions.  So, for example, even if you had something like this kernel flaw, nothing that was being rendered in the PDF viewer would have access to the exploit in the kernel because the browser is sandboxing the viewer itself.  So that's available now.  And coming soon is some similar technology for Adobe's Flash Player.  That's in the Dev channel code at the moment for Google's Chrome browser.  And I hope before long to be able to say that that's in the mainstream.



So but in addition to that they fixed 13 other security vulnerabilities.  So yes, using Google Docs to view a PDF, or using Chrome.  And Chrome is coming on strong.  It's turning out to be robust from a security standpoint, and it's steadily gaining market share.  I fired it up in order to take a look at this PDF viewer and see if I had the latest version.  It updated itself transparently.  And I was looking at it, thinking, wow, if I only had more flexible tab stuff - and NoScript.  I love NoScript in Firefox.



TOM:  I'm a big fan of that myself.  I run it all the time.  That and HTTPS Everywhere make me sleep a little better while I'm browsing for something.



STEVE:  Yes, there's enough of an ecosystem in Firefox that I just can't leave it yet.  But if Chrome continues to move forward and add some of these things, boy, it just looks so clean.  It's just, I mean, it's really nice looking.



TOM:  And they're really advancing with the sandboxing.  They're pushing that, not only for Chrome, but for Chrome OS, as well.  I think that's a great thing.



STEVE:  Well, it is the sort of thing - I've railed at length on the podcast before about just sort of how crazy it is that we're running operating systems that inherently are as vulnerable as they are.  That every week we're talking about one exploit or another, one vulnerability or another.  People are having to patch themselves constantly to stay ahead of it.  If the technology was inherently invulnerable to this, rather than being inherently vulnerable to it, we'd be in a much better situation.



TOM:  It seems so simple when you put it like that.



STEVE:  Yeah, exactly.  It'd be nice if it was.  I also wanted to let our listeners know that the much-anticipated first service pack for Windows 7 is now at the release candidate level.  So I expect probably within the next couple weeks I'll be able to announce that SP1 for Win7 is available.  And of course that will roll up together all the security fixes, all the incremental changes which have been done to Win7.  And there have been many of them since its release into a single update package, which for new installations of Windows 7 will be very nice because you'll just have all of this history homogenized into a single release.



TOM:  And a lot of enterprises wait until SP1 before they make the jump.  So this is highly anticipated in a lot of sectors, really.



STEVE:  Yes, I mean, like make the jump at all to a new OS, absolutely.



TOM:  To go from, well, in some cases XP, but in some cases Vista, yeah.



STEVE:  Actually I'm still on XP.  And that's what I preach, too, is any operating system that's brand new is inherently untrusted.  Steve Ballmer may jump around onstage and proclaim that it's the securest operating system they've ever made.  But as we know, security is not something that you can create by proclamation.  It's something you can only test out in the real world and have its security proven over time.  And of course they've never produced, Microsoft has never produced a secure operating system out of the box because they keep adding too many new things.  And newness is the enemy of security.



TOM:  Well, you can't create security by proclamation.  Can you create privacy by proclamation?  That's what the FTC wants to do.



STEVE:  Well, yeah, that's a good point.  You can create privacy by policy.  And so that's essentially what we're hoping to see.  The FTC is beginning to stir, frankly.  And I think this is a consequence of The New York Times.  It's been doing a fantastic series of articles.  I think it's under the umbrella of "What They Know" is what The New York Times calls their whole series.  And just week after week after week they've been pounding on many topics of online privacy, and often about tracking.



And so what the FTC has produced is, I think it's an 80-some-page document which they have given to the browser makers, to Mozilla and to Google and to Microsoft, who all sort of accepted it cautiously, wondering what this was going to mean.  What they're asking for is some sort of a mechanism, and it's still not well specified, but they look at the success of the Do Not Call registry for telephones, where people who did not want to receive telemarketing calls were able to register their phone number with the national Do Not Call registry, and telemarketers were prohibited from calling any number registered.



TOM:  And that worked.  I cut my calls down significantly.  Now, there was an exception, if you did business with that company, so your bank or your cable provider, they could still call you.  But those were the only ones I got after I signed up for Do Not Call.



STEVE:  Yeah, it was a great thing.  So what the FTC is talking about is a Do Not Track mechanism of some sort.  It's not clear whether it would be a registry.  The technology of the web session is such that it probably has to be different.  There is some not quite perfectly defined feature that Microsoft has announced that IE9, the next version of Internet Explorer, will have some sort of a list of sites.  It's not clear whether it's opt-in or it's opt-out or exactly what it's going to be.



What would be really nice, and what the FTC has suggested, is some sort of a button on browsers that is a Do Not Track button.  And so you'd press the button.  And from a technology standpoint, one thing I could imagine it would do is it would add a header to all of the browser's queries.  So we would change and we would enhance the HTTP protocol a bit to define a new header, essentially a Do Not Track header such that every query your browser made for pages, and all of the pages' assets, pictures and scripts and CSS files, I mean, everything, would have essentially a Do Not Track request or demand which would be essentially legally enforceable, if there was legislation to back this up, so that every query that went to a server would say, I am officially saying do not track me.  Do not do anything.



And again, this is where, okay, what is tracking?  We'd have to have that clearly defined.  But, I mean, I don't know anybody who wouldn't say, oh, gee, why not just have that button pressed?  Keep that button pressed in, and then you're not being tracked.  Now, everyone says, oh, but this would hurt online commerce, and there are sites that require tracking in order to offer their content for free.  I'm really skeptical, and I've always been dubious about the amount of value which is aggregated by these guys.  When you look at their databases, and you have a sense for - and this is one of the things The New York Times has been so good about elucidating is that the kind of content, the kind of personal information that is being gathered really is a little bit unnerving.



But I guess I wonder really is there an economic cost to saying I do not want to be tracked to sites.  And in fact I have seen some commentary where people have said, well, you can imagine a site that would say, wait a minute, you've got your Do Not Track button enabled.  But for this site we get so much revenue from our advertisers that we're only going to be able to offer you the content if you allow tracking.  So it sort of could evolve into a NoScript-like technology where you do not track by default, but you could run across sites that obviously they're able to sense that you've got track blocking enabled.  So they could say, hey, in the same way that sites say that you've got JavaScript enabled.  And they'll say, it's like, wait a minute, you've got JavaScript enabled.  In order for our site, you've got to enable that.  They could say, you've got tracking blocked.  If you want to use the site, we'd be happy to provide you with its features, but you're going to have to enable tracking.



TOM:  I've actually run across sites that said, because I had NoScript running, you're blocking ads.  But I wasn't blocking ads, I just wasn't executing the scripts.  And they said you can't access our content until you stop blocking the ads.  So you trust the script, if you feel like it, and then you get the content.  It would just like that; right?



STEVE:  Yes.  And if that's the way the world evolved, I think either people could say I don't care about this at all, so they would allow tracking by default, or they would say I do care about it.  And then they could make an informed opt-in decision on a site-by-site basis, saying okay, fine, I'll put up with tracking in order to have access to these sites' features.  So, yeah, it could work exactly like that.  Which would be very cool.



TOM:  Yeah, I think this would be advantageous.  In many ways you might even say it could be advantageous to the businesses who are thinking, well, I need to put in a paywall, if they could say, you know what, we're going to have a better sense of who our audience really is if we say we're only going to track the people who really read this many stories or do this kind of behavior.  Might be more valuable data that way.



STEVE:  Yeah.  Well, and you sort of see things like this, too.  I know for example The New York Times has content that they will offer to people who are nonregistered with them.  But then there are links which have a little flag on them saying, nope, this is only available, like the full content is only available for people who register.  And of course what they really want is your email address so they can send you stuff.  And so it's like, okay.  And so then again, you make that tradeoff.  Am I willing to tolerate their spam in return for full access?



TOM:  I'd rather hit a Track Me button than have to go through some long login procedure where I have to enter all that information and log in every time.  That's just a pain.



STEVE:  Right, right.  So I wanted to advise our listeners who might be using the ProFTP server.  There is an open source, very nice FTP server known as ProFTPD.  "D" is the server side, the daemon.  There was a zero-day vulnerability in their code which hackers took advantage of  because they were using their own FTP server, not surprisingly, on their website.  So the zero-day vulnerability was used to gain access to their source code, and it was modified.  It looks like the access was gained at the very end of November, on November 28th.  And the modification of the source code wasn't discovered until December 1st.  So not a big window.



But between November 28th and December 1st, anyone who downloaded this ProFTP server was downloading essentially a maliciously modified version such that a new command had been added.  Someone who logged onto the server during the initial handshake and entered a new command, "HELP ACIDBITCHEZ," would have been given a root command shell into the server running this ProFTP server, which is of course not a good thing.



TOM:  It's the server, not the client; right?  So it's when you're operating FTP on the server side.



STEVE:  Correct, on the server side.  And so I just wanted, if we've got listeners who are using ProFTP, if you didn't make any changes to it during that window, which I would say is most likely, you're okay and fine.  They do have, of course, hashes of the valid server, so you can check yours to make sure that it's working.  And they of course found the problem, fixed it, and they have not talked about what the zero-day flaw is.  And it's not clear to me that it's been fixed.  So there is a concern with using ProFTP.  You might want to make sure that they talk about having fixed the flaw that enabled their own service to be hacked in the first place.  And certainly you want to update that so that you're not vulnerable from running that service just as they were.



TOM:  So you're safe to download it now?



STEVE:  Yes.



TOM:  They fixed ProFTPD from now.  Or from December 1st, I guess.



STEVE:  Yes, exactly.  A couple security sites have sort of raised the flag that ransomware is making a comeback.  We saw ransomware a couple years ago, actually it was prevalent a couple years ago, where users were getting a popup notice - typically you'd be browsing somewhere, and script would run on your browser that popped up a notice that informed you that - it looked like it was antimalware.  The popup would say something like, we've just performed a quick security scan of your system and found something malicious on your computer.  In order to have this removed, please click here.  That would then take you somewhere else.



Then there was, for a while, there was malware even worse, which would get into your system and encrypt the contents of your file system, thus "ransomware," then saying you're not going to be able to get access to the content of your hard drive until you pay us.  Now, the good news was that the technology was not very sophisticated.  That is, once this was reverse engineered, it was found, for example, that the crypto key was embedded in the ransomware itself, and so it was in fact possible to get the drive decrypted without ever paying these clowns any money.



The bad news is, of course, we all know we've got the crypto technology now to do this correctly.  And the ransomware that's making a comeback is now doing it correctly.  It uses public key RSA 1024-bit crypto along with AES 256-bit symmetric cryptography to in fact randomly create a key which is not embedded in the ransomware.  And then it will leave only a public key where the bad guys keep the private key.  And so there is no way now to get your data back other than to accept, pay the ransom, essentially, which is as much as $120, to get the bad guys to give you the key required to decrypt your hard drive.



So the ransomware is being spotted, unfortunately, in PDF files.  People will open a PDF, believing that it is innocent and innocuous, and find that their hard drive, after some length of time, is inaccessible.  Now, we know this doesn't happen instantly.  That is, in order to encrypt a file system, it's got to run through the entire system.



TOM:  Yeah.  Anybody who's run TrueCrypt on their drive knows it takes a while.



STEVE:  Precisely.  I was just going to use that as an example.  Perfect example.  Anyone who's, like, done whole-drive encryption knows that it is not something that happens fast.  So at least one security company, I think it was Kaspersky, mentioned that, if you had reason to believe that this was happening, pull the plug or hit the reset button because you would stop that process in its tracks and then be able to recover all of your drive that hadn't been encrypted.



Now, I guess I would question that.  If something were loose in your system, well, the problem is you're vulnerable completely to whatever demands the bad guys make.  On the other hand, if you stopped the encryption partway, you could then have huge chunks of your file system, like critical portions, like the directory system, encrypted, which would really make recovery very difficult.  And it probably makes decrypting the portion that was encrypted impossible.  So I guess I'd wonder whether you're not better off saying, oh, shoot, and letting it go through in order to then be able to pay up and get your whole drive decrypted.  I mean, basically, you don't want this stuff on your computer at all.



TOM:  Exactly.  You don't want to have to face that choice.  That's no choice at all.



STEVE:  It's really bad news.



TOM:  I hate it when the bad guys follow good security practices.



STEVE:  Yeah, well, we've often talked on the show that security is, I mean, good crypto is available to everyone, the bad guys and the good guys.  So one of my recent laments is that the FBI is talking about implementing some legislation next year where they're talking about cranking up the legislation on wiretapping so that anything encrypted on the 'Net they would have wiretapping access to.  The problem, of course, is that crypto is already done.  I mean, it's out there.  It doesn't need to be - there's nothing left to invent.  It's as good as it needs to be.  And if they legislate against it, then that keeps good guys from being able to protect themselves from - just for the sake of having crypto.  And the bad guys will still use it anyway.



TOM:  All the good guys have broken cryptography, and all the bad guys have secure cryptography, is what it ends up with.



STEVE:  Exactly.



TOM:  That's not a good way to go.  Another reason to be shy of PDF files, that's for sure.



STEVE:  Yeah, yeah.  As a consequence of the ongoing saga of WikiLeaks, which is bringing news every day for the last couple weeks, the Congress immediately responded with a new legislation.  I love how they create these acronyms.  This one is called SHIELD.



TOM:  They're good at that.  If they're not good at anything else, they're good at the naming.



STEVE:  They do have good acronyms.  Securing Human Intelligence and Enforcing Lawful Dissemination, SHIELD.  And essentially what this does is to amend the existing Espionage Act to include the publication of human intelligence.  It was already a criminal offense to leak the information.  But one of the things that has annoyed the U.S. Congress is, in the case of WikiLeaks, is it's not clear that Assange - is that his name, Assange?  I think Julian.



TOM:  Julian Assange, yeah.



STEVE:  Yeah, it's not clear that Assange has broken any current U.S. law.  We know that Private First Class whatever his name was in Baghdad...



TOM:  Bradley Manning, yeah, Pfc. Manning.



STEVE:  We know that he broke the laws by leaking this to WikiLeaks.  But at the moment there's nothing illegal about WikiLeaks then publishing it.  So I don't know if this is going to pass through law.  It hasn't passed our own Congress, nor has Obama yet signed it into law.  But the immediate reaction of Congress was to amend our Espionage Act in the U.S. to make the publication of something that was leaked against the law a criminal offense.  And so I feel a little...



TOM:  There's a question about whether, even if this is put in place, whether it could pass a First Amendment test.



STEVE:  Yes, exactly.  I was going to say I feel a little queasy about this.  This begins to impinge on free speech.  And we know that once you get this kind of legislation, then the boundaries will be getting pushed.  It's like, well, okay, what are the requirements?  What constitutes information which can't be leaked and/or published?  So, yeah.



TOM:  The leak of the Pentagon Papers in the early '70s was allowed by the courts because of the doctrine of prior restraint.  You can't stop someone from publishing.  You can sue them after they've published for the consequences,  in various ways - libel, slander, those sorts of things.  But you can't restrain them from publishing.  This seems like that would violate that doctrine of prior restraint.



STEVE:  Yeah, don't know.  It does, though.  It does seem like, had this been in place then, Ellsberg wouldn't have been able to do what he did.



TOM:  Exactly.



STEVE:  And finally...



TOM:  Speaking of prior restraint...



STEVE:  Speaking of prior restraint, BlackBerry and RIM is still going around in circles with India.  We've talked a number of times about the problems that BlackBerry faces with the various governments which have demanded that they have access to BlackBerry's text messaging technology.  Apparently the audio channel is not posing a big problem.  They want email and text messages.  And the problem has been that BlackBerry's technology is such that, unless the traffic is routed through them, through BlackBerry's servers, then just intercepting the traffic does not give a third party access because the cryptographic keys are contained in the endpoint phones and nowhere else.



And so in the news this week BlackBerry explained that the enterprises that were running their own BlackBerry Enterprise Servers, BES servers, those enterprises had truly unbreakable crypto, and that India or any other government would have to go to the individual companies in order to arrange some sort of access to their crypto.  And I imagine that India would then threaten to block their use of cryptographic communications that they were unable to intercept.  So essentially the update on that is that India is going to have to go to individual companies and see about obtaining the required credentials, I guess, for all the phones.



TOM:  So what would that entail?  Would they have to go into each company and say we want to put a piece of software on your BlackBerry Enterprise Server?  Or would it just say we need to have your private key?  How would that even work?



STEVE:  Apparently there is technology, which BlackBerry has talked about before, where some software would be added to the BlackBerry Enterprise Servers, essentially installing a backdoor on the servers.  And that would allow, for specific users, it would essentially send traffic to the government which the government had the ability to decrypt.  So it would essentially decrypt the traffic as it was passing through the enterprise server from one phone to the other, and essentially allow a wiretap where a wiretap would not otherwise be possible.



TOM:  I get the feeling that this is saber-rattling on the part of India.  They just want to push to see how far they can get away with stuff.  Because every time the deadline gets close, and RIM says, you know what, we can't do this, they back off.  They extend the deadline.  They push it away.  They don't want to drive companies out of India.  They need that economic boost.  They need that job creation.  So they're going to push this as far as they can.  But I get the sense that if the companies just resisted it, that there might not be any consequence.



STEVE:  Well, and it is also the case that the reason we're only hearing about BlackBerry at this point, I mean, there has been some concern about going after other web-based email systems like Gmail, which is now fully SSL and encrypted.  But we're not hearing about other phone-based systems because none of the other ones are this secure.  So, for example, Apple's iPhone doesn't offer this level of public key, endpoint-to-endpoint security which BlackBerry, I mean, that was one of the selling points that RIM has always had is that they were able to say to corporations, I mean, it's why our own President of the U.S., Barack Obama, has a RIM which has been further hardened.  But they have proven security in this technology, and the other phone technologies don't.



TOM:  All right.  Well, we'll see.  Like I say, it's fun to watch.  I hope - and I don't think anything really bad is going to come out of this.  But you never know.  It's a lot easier to go after BlackBerry because they have the BES.  It's easy for the government to see on the Internet.  It's harder to see where to go after them, but it's actually easier to crack.



STEVE:  Yes, exactly.  Well, so I wanted to update - actually, in doing the Q&A last week I ran across a number of really fun SpinRite testimonials.  I always look for something new and different that I haven't talked about before.  And this one was from a listener of ours, Doug White, whose subject was "SpinRite Helps the Buffalo Roam."



TOM:  Oh, my.



STEVE:  And he said, "I got a frantic call from a friend that his NAS device," his network-attached storage device, "a Buffalo TeraStation..."  Thus the roaming buffalo.



TOM:  I get it.



STEVE:  Okay, "...was no longer appearing as a mapped drive on his network.  Apparently they were doing some work in the building and had switched the breakers off and on several times over the weekend.  And as the NAS was hooked to a UPS in another part of the building, they didn't hear the UPS's screams.  So it appears that the NAS was cycled up and down a few times.  I said, 'No worries.  The TeraStation is only holding a second copy of all your files; right?'  Silence.  'Right?'"  He says, "I had initially set it up so that all of their important files, hundreds of gig of music tracks that he's recorded in-house for himself and for other musicians, were being copied over to the recording PC, which contained the master copy; then to the TeraStation so that there was a second backup.



"They liked the idea of the RAID 5 protection being offered by the Buffalo TeraStation so much that they decided it would be great to use the TeraStation as a central repository for all sorts of other information, such as invoices, quotes, et cetera, as well as other soundtracks that were being modified on another workstation in the building.  So there was quite a bit of one-off stuff that accumulated on the TeraStation.  Why not, they thought, it's got four drives in a RAID 5 configuration.  What safer place to put the stuff?



"I showed up expecting a failed drive or the like, but the TeraStation's status display showed that all was well.  No failed drives.  I checked the workstations, and sure enough, the NAS device was not showing up on the network.  I pinged its IP address, which was one of the items cycling through the NAS display, and it responded to the ping.  When I tried to browse to the web-based admin interface, however, no response there, either.



"Even though it responded to pings, I wasn't entirely sure that the little Linux-based motherboard in the enclosure wasn't damaged.  So I contacted Buffalo tech support.  To my chagrin, they said that the device was so old" - and he says plus-six years old - "there were no enclosures to be had to attempt to swap the drives over to another enclosure.  Even buying a new enclosure would not work, according to them, as the newer firmware probably wouldn't recognize the old drive's RAID encoding.  I was at a loss as to where to go from there.  Maybe eBay to see if I could find an old enclosure?



"Well, while I mulled over how to proceed, I figured what the heck, I'll run SpinRite on the four SATA drives while I try to locate another enclosure.  Drive #1 flew through just fine, but Drive #2 of the four had some DynaStat action under SpinRite, and SpinRite had to recover some sectors.  Drives 3 and 4 sailed through just fine.  Curious as to whether anything had changed, I reinstalled the four drives into the NAS enclosure and fired it up.  This time the NAS display indicated that it had to do some resyncing, which went on for several hours.  Lo and behold, after it had resunc (!) I tried to attach to the network share and, voila, it was there.  I was then able to attach to the web-based admin interface with no trouble.



"I quickly attached an external USB drive to my system and copied all the files off the shared volume."  And he says, "(Well, as quickly as you can transfer 620GB across a USB device, anyway.)  I'm not sure why damage to one of the drives would have prevented us from attaching to shares or logging into the web interface, but I wasn't going to look a gift horse in the mouth.  I was tickled that the files were once again accessible, and you can imagine how my friends felt.  I was a hero.



"I'd like to emphasize with this story that many users, technically savvy and not, assume that since their stuff is on a device that is protected against a single drive failure via RAID 5 or the like, that all the data is safe.  What many don't take into account is the what-happens-if-the-enclosure-dies scenario.  So I'd like to reemphasize the 3-2-1 backup strategy that you and Leo have talked about in past shows.  My friend ended up buying another newer and larger TeraStation.  Fortunately the newer TeraStations have an option to synchronize files with one another.  So my friend now has two NAS devices on opposite ends of the building that are syncing to one another nightly.  Next up is trying to figure out how to get 600-plus gig of files offsite and backed up, either via sneakernetting a USB drive or some cloud-based backup service.  Add this to the list for yet another SpinRite success story.  My friend will be purchasing a copy of SpinRite for their own use from now on."



TOM:  So now we have to figure out if I want to be tagged.  Do I want to put a subcutaneous chip in my arm?  Is it your arm?  Where would you put it?



STEVE:  Where the hobbyists are putting it is sort of in that gap of skin between their thumb and their first finger on the backside of their hand.  One of them, I did some poking around the 'Net as I was researching, like, how prevalent was this.  And one of them made a comment about being careful when you put your hand into, like, tight jeans because you wouldn't want to catch the chip under your skin on, like, the pocket of your jeans.  And that just sent shudders through me.  It's like, oh, my goodness, no, you certainly wouldn't want that to happen.



TOM:  I don't want to have to think about that.



STEVE:  So I think the more popular place is between your elbow and your shoulder, sort of in your upper arm.  Apparently there's the question of migration, that is, a smooth capsule can tend to migrate more than one that's deliberately - there's, like, a non-migratory coating that they can receive that I think probably has, like, some fur on it, so that it sort of - it's not slippery.



TOM:  A mink capsule, perhaps?



STEVE:  It sort of locks into your location.  But I have to say, first of all, it's passive technology, so there's no batteries to replace.  It's not like a pacemaker where after some length of time it needs to be taken out and opened up again.  One of the concerns that exists currently is that we're still far away from standards.  And I always tend to guess wrong.  I went with Betamax back in the day, and of course Beta lost and VHS won.  And then I also went with HD, thinking okay, well, Sony lost last time, I'm not going with...



TOM:  I did the same thing.



STEVE:  So I've got a bunch of these red DVDs, and the blue is the one that won out.



TOM:  I've got the Xbox HD DVD player attachment, as well.  Be a collector's item someday.



STEVE:  So I'm thinking you wouldn't want to go with the Betamax of subcutaneous implants, and then have that one not win.  But really, from a convenience standpoint, okay, we've talked a lot about biometrics and fingerprints.  And one of the downsides is that you can't change your fingerprint.  And if it really became valuable for, like, someone to desperately, like bad guys, to need your fingerprint, well, there's only one way they can get it, and that never has a happy ending.



So the idea that, okay, I've got something, you can feel it, it's there under your skin.  The size of the most popular one is 2mm by 12mm.  Philips makes it.  It's called the Hitag.  So if you just Google "Philips" with one "L," "Philips Hitag," you can find some pictures of this thing on the 'Net.  It's like about the length of a - I often see it sitting next to a standard U.S. penny.  And so it's about the length of the penny's diameter, and that's 12mm by 2mm.  So it's a rounded-end little capsule.  It uses low-frequency induction so that it's powered by the reader, which generates - it essentially magnetically couples into it.  It's very much like, I'm sure people have probably seen ads now for, like, the Palm, was it the Palm Pre that doesn't need to be plugged in, you just sort of set it on its little pedestal...



TOM:  Right, does an induction charge, yeah, yeah.



STEVE:  Right.  And so these work in the same technology.  They generally have a short reading range, that is, a few inches.  There are some that can go feet or yards.  And so that's sort of a mixed blessing.  But I sort of like the idea of the convenience, if there were a standard.  I mean, I don't think I would mind being tagged if the technology made sense.  Mice have had a problem.  Mice were tagged, and for whatever reason they tended to get some skin cancers associated with the tagging.  But other medical professionals have said, well, mice get cancer.  That's what mice do.  And so...



TOM:  That's what the smoking people said, too, but...



STEVE:  Exactly.  And so before we went into this you'd want to make sure that it was safe, clearly safe for human implantation.  There was some concern that the metal in the capsule would interact, for example, with medical scanners, like MRIs, where you would have a problem with a really strong magnetic field.  But the MythBuster guys took that one on.  And they were concerned that it would overheat and would burn you or something.  Well, it turned out that doesn't happen.  It didn't even upset the technology at all.



So my problem with current tags is that they're a little unsophisticated from a crypto standpoint.  There's one guy who has a site where it's like he has had fun reverse engineering these things.  And quoting from some text on his site, he said:  "I can copy a proximity card at least as easily as I can take an impression of a key.  This means that it's not a very good idea to reuse visitor cards without changing the ID (and that it doesn't really matter whether you get the physical card back from the guy you just fired)."  Meaning that somebody who had a card could easily clone the card.  There's just no difficulty in doing so.  He says: 

 

"More insidiously, it's quite practical to read someone's card without even removing it from their wallet.  A bit of deliberate clumsiness, a reader up my sleeve, and I would have little trouble cloning anyone's card.  I could also exploit the fact that the distance at which the cards will be powered is less than the distance at which they can be read," meaning that they can be read from a much farther distance passively than they were being powered.  So he says, "If another reader is exciting the card, then my reader can read that card from the other side of a wall," for example.  He says:



"This means that a sniffer concealed somewhere near a legitimate reader could intercept real transactions at a significant distance.  This sort of attack is particularly good because the card repeats its ID over and over and over as long as it is in the field, so I could use signal processing...."  And he goes on to talk about "...signal processing techniques to combine multiple copies of the pattern to further improve my read range."



TOM:  So this is the RFID chip on a card.  But essentially what you're saying is the same could be applied to an RFID chip if it's implanted; right?



STEVE:  Well, and that's the problem is that, for example, there is this FDA-approved chip, it's called the VeriChip, which it has just a simple 16-digit fixed ID.  So there's no way that that qualifies, I mean, no listener of ours is going to accept the implantation of something that has a fixed ID, the problem being exactly that, is that everything that I just read - he's talking about access cards.  But it uses exactly the same inductive technology as one of these little implantable tags.  And so all it's doing is, when you ping it, essentially, it sends back the "this is who I am" response.  So it's trivial to clone it.  And so it just doesn't, I mean, it's got zero crypto sophistication.  So what we need is we need useful cryptography in an implantable device like this.



TOM:  So let's figure this out.  How do we get a chip in ourselves that's secure, that nobody can scan and rewrite and steal all of our information right out of our elbow?



STEVE:  The secret is we need a technology which embeds, well, a secret in this chip.  So we have a chip, and it needs to know something that never leaves it.  So the idea being that it can be challenged by the reader, whatever entity to which it wants to authenticate, it can be challenged to prove that it has a secret without it divulging the secret.  So the problem with just a simple ID of any length, even if it was more than 16 digits, is that it's unchanging.  It's just not going to be different every time.  So what we want to prevent is any sort of a replay attack where somebody passively listening to the chip respond is able to capture that.  Or even, if there's more technology going on, if there's something fancy going on, for example, where a challenge is given and the chip responds, we want a technology such that there's no way to replay that or to gain information about the secret in the chip by eavesdropping on both sides of the conversation, the outbound to the chip and the chip's response.



So we've covered crypto topics enough here to know that there's two approaches.  There's a private key approach or a public key approach.  The private key approach is going to be simpler.  It would involve a simple cipher like the AES cipher, for example, to drive an encryption function.  So, for example, the entity to which you want to authenticate, when you approach it, it would generate - you might press a button, or you might approach it.  You would respond, saying, hey, I'm here.  It would respond by generating a large random number, either that or using a counter which is never going to repeat.  So it's never going to issue the same value a second time, so you never need to worry about someone capturing its challenge and then seeing what the matching response is and being able to issue that.  So it issues a unique challenge.  And there's lots of ways to produce a cryptographically unique challenge that will never repeat.  It sends that out over the air to the chip, which uses its secret key to simply encrypt that challenge and send it back.



So the idea is that - and this is the beauty of simple symmetric cryptography, is that it doesn't help an attacker to see essentially what is the plaintext going out to the chip and the ciphertext coming back.  It would be a 256-bit string, for example.  Or in the case of if we used AES-256, it would be a 128-bit string.  But still, 128 bits is a phenomenal number of possibilities.  And the challenger would never be using the same one twice.  So there's just no way, even though you see these 128 bits going out, to determine what the function is inside, that is, what the secret key is which is producing a matching 128-bit reply.



Once the challenger received that reply, it would also have the secret key.  It would know the secret key, and so it would similarly encrypt its challenge and verify that the result of that encryption, under the same secret key, matched the one it had, and that would prove that the secret key in the chip matched the secret key that was registered with it.  So the advantage is it can be eavesdropped on.  Because you're using symmetric crypto, it's relatively simple.  It's a low computational cost to pull this off.



The downside of using a symmetric key is that you do have to divulge your secret to anything you want to authenticate against.  And anyone who has the secret can impersonate you.  So the problem with using the simplest symmetric key technology is that, if you, for example, if I wanted my garage door opener and my car and my laptop and my cell phone and all of the devices in my life to be able to authenticate me, they would have to know the secret key that I've got implanted in my body.  So we want to take it probably to the next step because...



TOM:  And so what you're saying is that ends up being a vulnerability, where they don't have to get the key out of your arm, they get it out of your garage door opener, or the scanner that you're passing by, or there's too many places where that key is.



STEVE:  Exactly.  Exactly.  It's not just in my arm, it's also - all of the devices that want to authenticate me would have a copy of it.  And so all a bad guy would have to do is compromise one of them, get the key out of there, and then it's trivial to impersonate me by putting the same key in the same kind of device and then waving it around and getting access to something that might be substantially more useful to have access to than whatever device it was that they decrypted.  I mean, you could imagine, someone who was chipped like this would probably be using it everywhere they could, just to get the maximum bang for the buck.



TOM:  Yeah, what's the point of being chipped otherwise; right?



STEVE:  Exactly.  So we take it one step further, using asymmetric key technology, which is really where I think this has to go before I'm comfortable using it.  And so what that means is that, thanks to the fact that public key technology has a pair of keys which are different, and that there is no way, knowing the public key - well, I should say, I should be rigorously cryptographically correct here and say it is computationally infeasible, with everything we know, to obtain the private key from the public key.  So in this scenario, my more sophisticated, more complex implant, which it might mean that it takes a little bit longer for the authentication to happen because literally I would have to hold this in the magnetic field which is powering the device long enough for it to crank through public key crypto, which is substantially more sophisticated than symmetric key crypto.



So I bring myself near the reader.  I again receive a challenge.  This time I use my private key to encrypt that challenge and then send it back.  The beauty is that the public key can be known to everyone.  In fact, we could even, for example, if a system like this became popular, you could stick it in a text record in your DNS server and say to everybody, this is Steve's public key to the chip he's got in his arm.  All devices anywhere could know it.  And them knowing it doesn't hurt you in any way.  It just means that you get to have more use from this thing, if that's the application that you wanted to put it to.



So essentially it allows the unlocking of the challenger side such that it's possible to authenticate the ownership of the private key using the public key at any time.  There's nothing that needs to be kept secret.  There's a higher complexity in terms of doing the math, but still certainly not out of range of what we can embed in something like this.  So it's potentially, I think, entirely feasible to come up with a workable chip which is embedded in people that would allow them to authenticate in a way that is - well, so if we step back a second and say, okay, what are the requirements that we have for this, well, we know that we want proven biological safety.  We don't want this thing to get lost in our body somewhere by migrating to some other location.



TOM:  Or give us the cancer.



STEVE:  Or we don't want it to give us the cancer, exactly.  We want a single settled standard.  That is, again, we don't want to choose Betamax and have the world go off in a different direction.  So...



TOM:  You can't get in anywhere because you picked the wrong chip.



STEVE:  Exactly.



TOM:  Like being uninvited.



STEVE:  And we've talked before about having, like, a key ring of, like, dongles, where each one runs something different.  Well, you wouldn't want to have to have a whole lineup of these things in your arm, of all different standards, in order to cover the different possibilities.  We need it to be clone-proof, meaning that it's going to use good crypto, state-of-the-art crypto.  One of the problems has been that some of these technologies, they've been proprietary.  TI designed that technology that was in the Speedpass.  Remember that for a while you could buy gas just by driving your car up to a pump, and it would light up?  I think it might have been Mobil.  I remember it was a Pegasus.  I thought it was kind of a cool thing.  I did sign up for and use the Speedpass for a while.



The problem was that the Texas Instruments engineers came up with their own cipher.  Well, we know that's never a good idea.  And it turns out it wasn't.  It turned out that it was very easily crackable.  It used a 40-bit cipher, which, I mean, the key length may have been enough.  But why not go 128 bits?  They were trying to keep the costs low.  They used their own cipher.  It wasn't ever vetted by the industry.  Turns out it was hacked and cracked in a matter of hours.  I think six hours is what it took in order for the algorithm itself to be reverse engineered from scratch.  And then some people did verify that it had cracked this.



So that Speedpass was an example of an early approach that just - it wasn't standards based.  It wasn't open.  It was a proprietary protocol.  So that's the other thing we'd want is a completely open technology so that you know what you're injecting yourself with here is, like, what the industry has agreed upon; and your laptop and your cell phone and your car and every other thing that you use is going to be able to interact with this.



And, finally, I really think it needs to be rewritable.  No matter what it is you put into yourself, you'd like to be able to change it.  If something happens, and you want to change your private key, even though there's no way that key can get away from you, being able to change it makes sense.  If nothing else, you could just zero it in order to turn this thing off if you decided you wanted to deactivate it temporarily or maybe permanently without having it surgically removed from you.



TOM:  Yeah, you want to have control over it without having to dig it out of your arm or your neck, like they do in the movies.



STEVE:  Exactly.  And also I think it wants to be small enough that it's not going to set off security scanners every time you go through some airline TSA scan.  They might be wondering what it is you've got in your right rear butt cheek.



TOM:  And you don't want them to have to try to find out.



STEVE:  Yeah.  The extensive pat down you want to avoid if possible.  And finally, operating distance.  I see that as the real bugaboo here because it's a tradeoff.  For greater security you want shorter range.  You'd like to have, for your own personal use, a few inches is probably fine.  On the other hand, if your arms are loaded with bags, and you're coming in in the rain, how cool is it that your door unlocks for you, and you don't have to fumble with your keys?  So again, if you were within a few feet of that, that would be nice.  The problem is there isn't a hard-and-fast technology for limiting range.  Range is based on signal strength.  And if some bad guy wanted to ping you at a greater distance, all they'd have to use is a bigger roll of wire, more power behind it, and a greater sensitivity antenna.



TOM:  So the distance is reliant on the reader, not the chip itself?  To a certain extent?



STEVE:  Sort of both, except that you can always get greater distance by having the reader generate a stronger magnetic field and be more sensitive to the returning signal from the chip.  So, yes, it's more a function of the reader, although you could deliberately design chips that had a lower range.  Except, again, no matter how low you made it, you could always affect that by more juice coming from the reader.  So it's just not a hard-and-fast thing.  I think I'd be more inclined to have a greater reading distance than I would a short distance, just because I would want this for convenience.  And it'd be nice if I could just approach the front door of the house and have it unlock, and approach my car and have it do the same thing.  And frankly, I think the whole idea is kind of cool.  I know it creeps some people out.  The downsides are, I guess, what, being tracked, that you might be identified or pinged even when you don't want to be.  Unfortunately, I can't see a means for sort of, in real-time, disabling it.  It'd be nice if you could, like, click it or something.



TOM:  Turn it on.  Could you wrap a Faraday cage around your arm?



STEVE:  Ah, now, there you go.  Have a big, like, copper bracelet or something you could just slip over it.



TOM:  Yeah, a security sleeve that can pull down out of your shoulder.



STEVE:  Now, there are some companies that sell silicon wristbands that have these embedded.  And as I was researching it I thought, well, I mean, it's not quite as convenient as having it in you.  But you really don't need to be scanned when you're completely naked.  And the rest of the time...



TOM:  Unless you're going to board an airplane.



STEVE:  Exactly.  And then I was thinking, well, okay, how about - it's such a tiny little capsule, you could also, like, drill a little 2mm hole in the sole of your shoe and slide the capsule into your shoe.  So I'm just sort of thinking of alternatives to embedding it in your body that would still give you a lot of the benefit of the convenience of having something that is securely authenticatable and associated with you.  On the other hand, if someone stole your shoes, then they would be you.



TOM:  Well, I guess they could saw your arm off.  But it's a lot more difficult to do something like that than to grab onto somebody's shoe or slip a wristband off a wrist or something.  Or you could just lose it.



STEVE:  Yeah.  And again, that's why, relative to sawing your arm off, why I'd be happy to tell my captors, here, there's the capsule there in my arm.



TOM:  Here's my private key.



STEVE:  Just dig it out.  Don't take the whole arm.  You only need a little one-inch chunk.



TOM:  So I agree with you.  I think the fact that the problems of cryptography on this are not insurmountable.  And it could be incredibly convenient for many different reasons.  But you mentioned something earlier that gave me pause, which was the idea of your corporation or your place of work saying, okay, we make you carry around an ID card with an RFID chip.  That's a little expensive.  We'd just like everybody to have this implanted, please.



STEVE:  Well, yes.  And so it is the case that people have been concerned about that.  And as a consequence there's at least three states that have legislation on the books now that specifically prohibit employers from requiring employees to be "chipped," as the new verb has been coined.  And frankly, if a standard existed, and your company was using access cards, and your chip used the same technology as the access card, then it'd be kind of cool.



TOM:  That's why we need a standard; right?



STEVE:  That's why we need a standard.  And I haven't thought through the downside.  I guess I'm not living a life where I'm too concerned about the tracking aspect.  For example, I would like it if, for my credit card to be used, maybe if I have to also be pinged, if I require to be physically present.  That would be nice.  Or again, back to the gas pump.  If the gas pump had the technology, and I was chipped, then, hey, it's very easy for me to authenticate to the gas pump and not have to use a credit card.



TOM:  Sit there, put in your zip code and all that crazy stuff that you have to do now.  When you talk about the tracking aspect of it, though, think about it.  You're totally trackable without a chip in you already.  There's facial recognition software that can identify you.  You're leaving fingerprints everywhere you go.



STEVE:  You've got a cell phone that is sending out a logged-in ping and all kinds of things, and wanting geo-tracking now.



TOM:  So you can't encrypt your face.  But you can encrypt a chip.



STEVE:  Yes.



TOM:  It seems like that's actually safer than just having a face.



STEVE:  Well, the public key technology, if the public side were known, then you would be trackable.  However, nothing prevents you from keeping that secret, too.  You could still have the benefit of an asymmetric crypto and work to keep the public key secret in the same way that you would much more diligently work to keep the secret key secret.  And then you may be giving off a signal, but it doesn't matter because there's no way that anyone would have of associating that with you because they wouldn't have your matching key.



TOM:  Yeah.  And I think some way to turn it on and off, even if it is just blocking it, makes it more viable, as well.  You've almost convinced me.



STEVE:  We've seen the same sort of thing with passports, where passports were going to get RFID chips, and they were going to use a metal folder.  And in fact I think that, what's the crazy site...



TOM:  ThinkGeek?



STEVE:  ThinkGeek, yeah.



TOM:  ThinkGeek sells the wallets, yeah.



STEVE:  Yes.  And those block that kind of remote access.  So, yeah, I mean, certainly we're a long way away from it.  But I thought the fact that hobbyists are beginning to chip themselves, I mean, they're using, unfortunately, low-technology chips.  This Philips chip has some sort of an encrypted challenge-and-response technology.  Unfortunately, it's proprietary, and I couldn't see anywhere where they talk about the algorithm, and it wasn't very much bit length.  It was a 32-bit response to, I think, two different 32-bit chunks.  But again, they just didn't talk about it at all.  And so for me it's got to be more than just a fixed ID that it sends out.  Otherwise you really are prone to being cloned.



TOM:  My friend Veronica Belmont has said she wanted to be chipped for a long time.  I think you've almost convinced me to join her.



STEVE:  Well, I will keep us and our listeners up to date on this.  If it happens, I think it'd be kind of cool.  I can see some upsides.



TOM:  Maybe I'll try it with the dogs first, since they're already chipped.  If I could get it to where, at certain times of day, their chip allows them to just open the door automatically, and they could let themselves out, take care of their business, that in itself would be incredibly handy.  And maybe that's a good test field.  Pets would be a test field for this, in all seriousness, to kind of work out some of the kinks because your security level is lower there.



STEVE:  Well, and it's absolutely the case that there exist today silicon bracelets that carry chips in them.  So if someone wanted to experiment with the convenience of using it, there are SD cards for laptops that can receive the RFID signal from a bracelet.  So you could tie it to TrueCrypt so that TrueCrypt won't boot your laptop unless you're physically there.  Or, that is, your bracelet is.  And so there are half-steps people could take before they committed to a surgical procedure.  But apparently it's just not a big deal to have it done.  You just use a little outpatient plastic surgery to sort of cut a slit and slip this in, and you're done.



TOM:  I just thought of one minor downside to that when you gave that example.  You know, TrueCrypt has the hidden volume that you can use if they demand your password.  You can give them the password for the fake volume.  You couldn't do that if you were authenticating on your chip.  They'd just grab you and thrust your elbow down, and you're into the real volume.  You can't make use of it.  But probably not a common problem.  But problem enough for some people if they're worried about it.



All right, Steve.  Well, I really appreciate you letting me host, while Leo is gone, with you.  This is fabulous.  I've learned a lot.



STEVE:  It's been great.



TOM:  Yeah, I hope you enjoyed it, too.  You can find, well, GRC.com; right?  That's the place where SpinRite and ShieldsUP! and all the good products are.



STEVE:  Yup.



TOM:  And you will be back next week.  Do you know your topic, or...



STEVE:  Well, this not being a Q&A, we'll be doing a Q&A next week.  So I did want to encourage our listeners, I imagine there'll be some interesting feedback from this topic.  And so GRC.com/feedback.  Please, listeners, go there, let me know what you think about this, and I think we'll have a fun episode using feedback from this rather potentially controversial topic, which Leo and I will cover next week.



TOM:  All right. Thanks, everybody, for watching Security Now!.  You can find us at TWiT.tv/sn.  Leo will be back next week.  We'll see you then.



STEVE:  Thanks, Tom.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#279

DATE:		December 16, 2010

TITLE:		Listener Feedback #107

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-279.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  It's time for Security Now!, the show that protects you online.  And boy, I can't think of any better person to do that than Mr. Steve Gibson of GRC.com, the man who found the first spyware.  Like a dinosaur hunter.  Look, spyware!  And not only did he find it, he coined the term "spyware," wrote the first antispyware program.  He's also done all sorts of security goodness for all of us, including ShieldsUP!, his DNS Benchmark - Steve, it's good to see you again.  I'm sorry I missed last week, but thanks to Tom Merritt for filling in.  I think you had a good time.



STEVE GIBSON:  Well, the only problem is, Leo, you missed a really fun and somewhat controversial episode.



LEO:  What did you talk about?



STEVE:  We talked about implanting RFID chips in people; and, if I were to have one implanted, what would be my minimum requirements from a technology standpoint.



LEO:  What a great subject.  I'm sorry I missed it.



STEVE:  Really, really neat.  It was really neat.



LEO:  Thank goodness it's a podcast.  I can go back and listen.  We should note that, while we will be here next week, that's the 22nd of December, we record on Wednesdays for a Thursday release, we will not be here the following week, the 29th, if you watch live or you download the podcast.  But the good news is we're going to repeat the world-famous Portable Dog Killer episode.  I can't wait.  No, I'm sorry, Ozzy.  My dog's in here.  He's very upset.  He said, "What are you talking about?"



STEVE:  Talk about his ears perking up normally.  Oh, goodness.



LEO:  You know he's a Papillon.  As you saw, he has giant ears.  And I don't know, I don't think it would kill him, but it might give him a headache.



STEVE:  He'd be jumping under the bed.



LEO:  He said, "I'm getting out of here."



STEVE:  You wouldn't see him for a while.



LEO:  I don't know what that sound is, but it's annoying.  So, Steve, what are we doing today?



STEVE:  Today we've got a Q&A, our #107th Q&A.  We've got, of course, some updates and some news.  One really freaky bit of news that everyone has been tweeting me about, to make sure I knew about it - and you may have run across this, although it just happened - which is the claim that 10 years ago the developers of the OpenBSD security framework, specifically the IPSec stack in OpenBSD, 10 years ago these developers were paid by the FBI to build backdoors and deliberate side channel key leakage into it.  So...



LEO:  Oh, no.  And, now, is this verified, or is this...



STEVE:  Well, we're going to talk about it.  It's an interesting story, just broke, like, as we're recording this.



LEO:  Holy cow.



STEVE:  Yeah.



LEO:  We also have questions, 12 good questions from our listeners.



STEVE:  We got some feedback from last week.  Not surprising, some feedback from the controversial embedded-chip-under-your-skin episode.  And...



LEO:  You know there's a side story to this RFID, and that's something called NFC, Near Field Communications.  I'm sure you know about that.  But I just got the new Google Nexus S phone, which has an NFC reader built into it.  And it's kind of like, I think it's very similar to RFID.  Of course it's very short range.  You have to really get up right next to the thing.  But you can pass the phone over a placard or a pay point or whatever, and data is transferred from that pay point into the phone.  And apparently it's very popular in Japan.



STEVE:  Near field is interesting.  It uses a different set of sort of parameters or terms from the original, I think it was the Schrdinger equations for energy transmission, where normal radio uses one set and has a certain characteristic in terms of distance versus power.  Near field uses a different set of equations that essentially creates an extremely low-power, short-range connection which falls off very quickly.  So it's different than just, like, low-power RF.  It's deliberately designed to have, like, a different functional curve.  And, yeah, I think we could see a lot of that in the future.



LEO:  Very interesting.  Okay, Steve.  I see we have quite a few little updates here, including Microsoft's update.



STEVE:  You know, Leo, you started off saying that you were a fan.  And it occurs to me that isn't "fan" short for "fanatic"?



LEO:  Yes, it is.



STEVE:  Is that what it - I thought it probably was.



LEO:  I am a fanatic.



STEVE:  Yes.



LEO:  There are certain things I'm a fanatic about.  And Ford has rapidly become one of those things because they've really, I tell you, this has been a banner year for the TWiT network and for all of our shows, in great part thanks to Ford and our other sponsors who've really helped us.  You know we're going to build that - we're moving into that new facility, the 10,000 square foot facility, build all new studios.  And all of that's because of our sponsors.  So thank you.  Tip of the hat.  Microsoft had a December update while I was gone.



STEVE:  Oh, thank goodness, finally.  This was the one we were waiting for.  And the good news is this ends their updates for the year, this being December.  They've broken their record.  The total number of updates in any year was in this year, in 2010.  This second Tuesday of the month, which we just had, addressed 40 vulnerabilities across 17 different security bulletins.  They did fix the zero-day privilege escalation kernel vulnerability which we've been talking about and waiting for for a couple weeks.  So the good news is that's done.  That was the one that was frightening people because it had the potential to be a means for malware to install itself as a rootkit, meaning that it would be able to get into your system in a way that, after it was in, no antimalware detection technology would have been able to see any longer.  So the good news is that's fixed.



They fixed a bunch of vulnerabilities.  Actually they completely caught up with all of the vulnerabilities that the Stuxnet worm had been using to get itself installed.  Because remember that it was discovered that it was using some that were previously unknown.  So that led people to believe that it was pretty sophisticated developers behind that worm.  So absolutely, everyone should, as soon as they get a chance, make sure that their copy of Windows is up to date after this Tuesday, which was the latest occurring Tuesday in the month that we could have, since Wednesday was the 1st.  Also just a small side note, and that is that Firefox has jumped itself forward to 3.6.13 and 3.5.16.



LEO:  I don't know how they keep track of these numbers.



STEVE:  Fixing in the process 12 vulnerabilities, 10 of which were critical.  So that was a good move there.  Now, as I mentioned at the top of the show, the big sort of controversy - and I'm very much not a conspiracy follower.  So I'm skeptical about all of this until it's been proven.  Now, I was skeptical about Stuxnet and the very, very, what I felt were premature claims that this was targeted at Iran.  It, of course, as we know, it turned out, once all the evidence was in, that it was almost certainly the case that that worm was deliberately targeted at Iran's nuclear enrichment centrifuge process control systems and was effective to some degree.



So the jury is very much out on the allegations regarding OpenBSD's Security Framework, or the OSF, as it's known, having been deliberately compromised.  But here's what we know.  Just yesterday, on the OpenBSD tech mailing list, Theo de Raadt posted the following.



He said, "I have received an email regarding the early development of the OpenBSD IPSec" - which is of course IP Security - "stack.  It is alleged that some ex-developers (and the company they worked for) accepted U.S. government money to put backdoors into our network stack, in particular the IPSec stack, around 2000 to 2001.  Since we had the first IPSec stack available for free, large parts of the code are now found in many other projects/products."



LEO:  I have to say this seems suspect because it's open source.  Wouldn't somebody notice this backdoor?



STEVE:  Well, see, this is the problem.  I mean, open source, as we've discussed many times, you have a team who are working on some chunk of this.  And first of all, I'm with you in being skeptical.



LEO:  Yeah.  I am not going to believe this story unless I hear some real confirmation of it.



STEVE:  Well, so the reason this has raised eyebrows is, he says, "Over 10 years the IPSec code has gone through many changes and fixes, so it is unclear what the true impact of these allegations are.  The mail came in privately from a person I have not talked to for nearly 10 years.  I refuse to become part of such a conspiracy and will not be talking to Gregory Perry about this.  Therefore I am making it public so that, (a), those who use the code can audit it for these problems" - potential problems I'll throw in - "(b), those that are angry at the story can take other actions; and, (c), if it is not true, those who are being accused can defend themselves.  Of course I don't like it when my private email is forwarded.  However, the 'little ethic' of a private email being forwarded is much smaller than the 'big ethic' of government paying companies to pay open source developers (a member of a community of friends) to insert privacy-invading holes in software."



LEO:  Now, this is coming, this accusation came from Theo de Raadt, who's the founder of OpenBSD.  So that does lend it some credibility; right?



STEVE:  Exactly.  So he then quotes Gregory Perry's email.  Gregory Perry is currently at GoVirtual.tv.  And the subject was "OpenBSD Crypto Framework."  And he says:



"Hello Theo.  Long time no talk.  If you will recall, a while back I was the CTO" - so the chief technology officer - "at NETSEC and arranged funding and donations for the OpenBSD Crypto Framework.  At that same time I also did some consulting for the FBI, for their GSA Technical Support Center, which was a cryptologic reverse engineering project aimed at backdooring and implementing key escrow mechanisms for smart card and other hardware-based computing technologies.



"My NDA" - that's nondisclosure agreement.  "My NDA with the FBI has recently expired, and I wanted to make you aware of the fact that the FBI implemented a number of backdoors and side channel key leaking mechanisms into the OCF" - which is the OpenBSD Crypto Framework - "for the express purpose of monitoring the site-to-site VPN encryption system implemented by EOUSA, the parent organization to the FBI.  Jason Wright and several other developers were responsible for those backdoors, and you would be well advised to review any and all code commits by Wright, as well as the other developers he worked with originating from NETSEC."



LEO:  I could guarantee there are developers, open source developers looking at all of those commits now.  And we will know by the end of the day if there's any merit to this or not.



STEVE:  We'll know soon.  He says, "This is also probably the reason why you lost your DARPA funding.  They more than likely caught wind of the fact that those backdoors were present."  I mean, here we're in, like, speculative land.  So again, take all of this with a grain of salt, as I do this whole thing until, again, until we know more.  But reading this, he says, "They more than likely caught wind of the fact that those backdoors were present and didn't want to create any derivative products based upon the same.



"This is also why several inside FBI folks have been recently advocating the use of OpenBSD for VPN and firewalling implementations in virtualized environments."  Again, we have no reason to, I mean, this is all speculation.  "For example, Scott Lowe is a well-respected author in virtualization circles who also happens to be on the FBI payroll, and who has also recently published several tutorials for the use of OpenBSD VMs in enterprise VMware vSphere deployments.  Merry Christmas.  Gregory Perry, Chief Executive Officer of GoVirtual Education."



LEO:  Wow.



STEVE:  So that's what's known at this point.  The good news is this is really on the radar and has come to the attention of the OpenBSD open source community.  I'm sure that the people who were involved are being asked.  We'll know more, I'm sure, for this podcast next week.  This just happened.  And I've been getting tweets and tons of email, and it's all over the place.  So, you know, certainly...



LEO:  No, ericduckman asks in our chatroom a legit question.  Is this only OpenBSD, or does this code extend to any other projects?



STEVE:  Well, you'd have to carefully look at where any other IPSec and security framework code came from.  What Theo was saying is these guys were first.  This was 10 years ago.  And as happens with open source, sort of by design, you can take chunks of it and put it in different places.  And we see that all the time with OpenBSD, FreeBSD, NetBSD, you know, they've all taken overtly and, you know, saying thank you very much, they've taken big chunks of each other's work and incorporated it into their own operating systems.  So again, it's going to take some time for the community to react to this.



The problem is that it - and we've spoken of this before.  It can be extremely difficult to find these things, even when you're looking for them.  That is, if they're talking about, for example, side channel leakage of key material, what that's saying is that, when the code was written, the developers, assuming that this were true, and again, I have no reason to believe it, it sounds very suspect to me.



But the way you would do this, if you were going to, is you would write the code in such a way, for example, that its timing was deliberately a function of the key which was in use at the time, so that, if you knew what had been done, then you would know how to look for subtle variations in the behavior, not overt like anything obvious, but subtle variations like timing or power consumption, but timing is the most easy to detect, where, if someone had said, okay, thanks for the check, here's what we did.  And then you could, if you knew what to look for, you could use something like variations in timing to acquire information about the key that was in use on the IPSec crypto channel, that kind of thing.



So, I mean, really what you want to do is you want to scrap this and just write it clean.  Otherwise you'll never really know for sure unless we can get statements from the people who say we have no idea why Gregory Perry is making these allegations.  They are completely bogus.  On the other hand, wouldn't the authors say that even if that was true?



LEO:  Right.  That's no proof.  But that's why I love open source.  You can verify this.  You can look at it.  You can tell.



STEVE:  Yeah, although, I mean, so many times I've drawn the - I've used the example of debugging.  When my code is doing something that is unexpected, as the author of it, and even somebody else looking over my shoulder, we can, like, be looking at the code, and it looks fine because with code comes sort of an implicit assumption that what I've written is what it's going to do.  Which is why there's this strange phenomenon when you're stepping through the code in a debugger, you can come right up to the problem.  And it's not until it actually happens in front of you that you go, oh.  I mean, it's a left shift instead of a right shift.  I can know that I mean right shift.  But I wrote down left shift.



And so it's so easy to just sort of have your eye step past it with the assumption that it's correct.  So, similarly, analyzing code to discover something that a programmer deliberately did and deliberately obscured, I mean, presumably, if this was really done, it was done in a very clever way.  So I could fully believe that someone, if this was done, could have taken a block of this as a module and just lifted it in and moved it into other, repurposed it into other operating systems, where it was a functional module known to do the following.  And it really could have spread.  So anyway, we're at the beginning of a very interesting story that we'll certainly be following for our listeners as more develops.



LEO:  I'm going to call BS on it, but we'll see.  Obviously we have to check.



STEVE:  I'm with you.  I mean, the whole thing.  I mean, first of all, I don't imagine that the FBI would pay open source developers to do this because this is not the kind of thing you can keep secret.



LEO:  I'm sure they'd pay commercial developers to do it, but that's why I recommend open source for stuff like this.



STEVE:  Well, or you could imagine that they would have somebody working for them on the inside.



LEO:  Maybe, yeah, committing that way, yeah.



STEVE:  I mean, that's the way you would imagine this would happen if that was really going to be done.  So, anyway, it is a big story.  I wanted to address it for our listeners.



LEO:  Oh, absolutely, yeah.



STEVE:  And we'll certainly follow it.  Many people have written to ask about the denial of service attacks on all kinds of entities who have been involved in many different ways, whether they were DNS suppliers - well, involved with WikiLeaks.  Whether they were DNS suppliers; donation carriers, you know, PayPal; whether they were hosting providers; I mean, pretty much anybody who has in any way been associated with WikiLeaks, who has attempted to distance themselves from WikiLeaks as a consequence of this huge controversy, has found themselves the victim of denial of service attacks of varying strength, durations, and so forth.



What's interesting is that a simple-to-use denial of service attack tool called LOIC, which is an acronym for Low Orbit Ion Cannon, was created.  And LOIC operates in a very well-known and almost traditional fashion for a botnet.  It hooks onto an IRC channel.  It joins an IRC channel in an IRC chatroom.  And then the bot herder - and that's called the Hivemind, the LOIC Hivemind.  Then somebody who is controlling that channel issues commands which will be received by all of the bots that are listening in this IRC chatroom and will then go attack whatever target has been given.



Now, at one point as many as 1,200 different bot clients were logged into the chatroom.  The problem for them is that they're making TCP connections, which are not spoofable.  There's no way to spoof those.  Meaning that anybody under attack is seeing standard Internet TCP connections from these bots.  So without getting at all into the politics and ethics of this, I want to stay out of that question, it is the case that anyone who is contributing, who feels they're contributing their bandwidth for the sake of the anonymous group, as it's called, that is attacking people around this whole issue.  Their IPs are exposed.  And several of them have already been pursued and, I mean, legally pursued.



So it's certainly the case that this is not a sophisticated DDoS client.  Many people have been surprised that websites have been so easily brought down by a relative small number of clients.  This is only in the low thousands and high hundreds.  And so one thing worth mentioning is that denial-of-service attacks are not difficult to launch.  I mean, they are pretty easy to launch, in fact.  And sites are relatively easily brought down.  I mean, we had MasterCard brought down, Visa brought down, Amazon was having trouble, smaller DNS sites that had been involved had been brought down.



PandaLabs has a really nice blog that has been following virtually blow by blow, they've been watching the management of these botnets associated with the WikiLeaks attacks.  And I created a short URL because theirs unfortunately is really long:  bit.ly, so it's a bit.ly URL, bit.ly/hyGLpy.  That expands to the Panda Security, PandaLabs blog.  I also checked with Google.  And at the time, at this time, if you put in "PandaLabs DDoS WikiLeaks," and I think I put in "LOIC," you can also find it through Google.  But if anyone's interested, it is fascinating.  They have essentially a complete chronology, a detailed chronology of who's been attacked, how hard the attack was, how long they were held off the 'Net, when they got back on, and so forth.  So if anyone's curious, PandaLabs has done a great job of tracking that from the beginning.  Which is interesting.



LEO:  Yeah, yeah, absolutely.



STEVE:  There's even a JavaScript version of this LOIC, the Low Orbit Ion Cannon?



LEO:  That tells you something.



STEVE:  You could even run it on your iPhone, if you wanted to.  And I'll mention also that, when I was visiting Mark Thompson a couple weeks ago at his place out in Phoenix, he's got, I think it's 15 megabits of upload on his cable modem.  He's paying for a high-bandwidth cable modem connection.  But, I mean, that's a ton of bandwidth.



LEO:  You get a few hundred of those, boom.



STEVE:  Exactly.  That adds up very fast.  And that's much more bandwidth than most websites are used to dealing with, like on a saturated, focused all at once sort of basis.  IE9, Microsoft's forthcoming Internet Explorer 9, which is currently in beta, I just wanted to mention does have a do-not-track technology of some sort.  It will be present in the browser.  It'll be disabled by default.  But it will be something that people can turn on.  And I'm sure that we'll have something shortly in Mozilla's Firefox, as well.  And apparently Chrome's security model is causing developers some bit of problem, just for implementing these kinds of things.  We do have something called NotScript for Chrome, which I wanted to mention that I know of.  I've not taken a look at it yet.  But many of our listeners have said, hey, Steve, we know how much you are in love with NoScript for Firefox.  Well, there is NotScript for Chrome.  And the developer mentions that he had to jump through some hoops in order to implement this for Chrome because Chrome's own high-security barriers were fighting this kind of functionality.  It wasn't something that was easy for him to shoehorn into Chrome, but he's managed to.



LEO:  And of course this is going to become more relevant with the Chrome OS, which is entirely based on the browser.



STEVE:  Exactly.  There was a note also that the SANS security letter had, saying just that the UAE, United Arab Emirates, authorities can now decrypt BlackBerry communications with a court order.  And their little blurb said that the United Arab Emirates' Telecommunications Regulatory Authority now has the key for BlackBerry services.  This means that the authorities can decrypt and monitor BlackBerry communications after obtaining a court order.  BlackBerry's parent company, Research In Motion (RIM), has reached a similar agreement with authorities in India.



Well, there was a link in the SANS article to a website with a broken link, or a broken page, when I clicked on it to follow up because I didn't understand what this meant.  This says that they have a key, but they require a court order.  But if they have the key they wouldn't require a court order.  Or it's not clear what it is they have to go through to use their key.  I mean, I wanted to get something more rigorously technical than what was in the SANS newsletter.  At the same time, I didn't want to ignore this note because this is interesting to me from a crypto technology standpoint.  So as more is known about this, I will let our listeners know because we've been following this whole issue, which I find really interesting, about what it's taking to do this.



We know that, if software is installed in RIM's servers, then it's possible for RIM as a man in the middle to perform the decryption.  But RIM has said that, so long as people are using the corporate servers, which have no dependence on RIM at all, that various entities, the government entities would have to go to the corporate endpoints and see about installing some sort of third-party technology there, or RIM's technology in those third-party servers.  Anyway, this is just a huge mess.  But as we know more, we'll certainly let people know.  And I did want to note that, unfortunately, DoubleClick and Microsoft, that is, the advertising server, rad.msn.com, were both found to be serving malware advertisements recently.



LEO:  Yeah, I saw that.  Wow.



STEVE:  Yes.  Malware got into the advertising stream.  This was a banner ad which was essentially using heavily obfuscated JavaScript to exploit at least seven previously patched vulnerabilities in Adobe Reader, in Java, and in Internet Explorer, in order to install something called HDD Plus, which was sort of semi-ransomware.  It would inform users that their system had serious errors which required the premium version of HDD Plus in order to fix their system.  So that was found and fixed.  And of course Google jumped on it immediately, Google being the parent of DoubleClick, and are trying to come up with a way to prevent this from happening in the future, which of course would be a good thing to prevent.



LEO:  Yes.



STEVE:  And quickly, a little bit of errata.  My own Sue, who handles sales support for GRC, messed up her filters in Eudora Monday evening, and yesterday morning wrote to me and said, Steve, I don't seem to be getting any email.  Well, it turns out that I went down to see what was going on, and she'd mis-implemented some spam filtering, which it turns out triggered a bug in Eudora which was deleting any email that she received in such a way that it didn't even go into the trash, where we could have recovered it.  It just went into nowhere, into oblivion.



So I wanted any listeners to know, if anyone had sent us email for any reason between Monday night and around Tuesday at noon Pacific time, we never got it.  Unfortunately, it's nowhere.  The way we had her email configured, we've changed that now, but it was pulling it off the server forever and deleting it.  So we didn't receive it.  I'm sure, I mean, we feel awkward about this because we hate not responding to anyone who has sent email to us.  But just it was lost.  So...



LEO:  These things happen.



STEVE:  It does.  It never happened to us before, and now we've taken measures so it won't happen again.  We're now keeping email on the server even for Sue's accounts.  Mine I do have kept on the server.  But Sue was just deleting hers.  So we had no problem until no.



LEO:  This is why I like IMAP.  Of course, if you had had IMAP, you probably would have deleted the originals, so never mind.



STEVE:  Exactly, it could happen, too.  Also, the blog for Adobe tracking the development of Flash, I mentioned before that Flash v10.2 was supposed to be using much less processing power.  And I had mentioned that in the context of my own experiments with Flash on a battery-powered laptop, where I was surprised when Flash was jumping around on the screen, how much battery my laptop was burning.  Its estimate of, oh, you've got eight hours left dropped down to, like, an hour and a half when I had Flash running in the browser.



The good news is we're beginning to see some metrics from this.  And they're claiming to use as little as 10 percent of the previous CPU and system power under this new v10.2.  So the good news is they're really focusing on power consumption as a consequence of wanting to get Flash onto handheld devices.  And it looks like they're being very successful with that.



And I got a kick out of something that I ran across in the mailbag that I just wanted to share with everybody.  A listener of ours, Mack Morris, says thanks again for the great podcast, and tell Leo that I think his Irish accent...



LEO:  Is terrible.



STEVE:  ...is the best of all the ones I've heard so far.



LEO:  Is this guy Irish?  Because that's the first problem.



STEVE:  Maybe not.



LEO:  Maybe not.  I love it.  We have an Adobe Gotcha! of the week coming up, too, in the questions, speaking of Adobe.



STEVE:  Yes.  We do.  I did want to share a fun SpinRite story.  I mentioned a couple weeks ago when I didn't do a SpinRite story that I had run across a number of really fun ones.  This one is "SpinRite Saves the Broadcast."  Our listener Sean McStay says, "Hello, Steve and Leo.  I work for a mobile television production company that specializes in sports broadcasts.  On Wednesday, the day before Thanksgiving, I was working an NBA broadcast in Oklahoma City.  About 12 hours into the day my technical director called me to the production area of the truck and asked me to listen to something strange.



"There is a touchscreen computer that is the user interface for the production switcher that switches the entire broadcast.  This computer was making a strange, high-pitched sound, but otherwise seemed to be fine.  The technical director and I both thought that a worn-out cooling fan was probably the source.  Other than the annoying noise it was making, I really didn't think much about it and just made a mental note to get a replacement fan.



"Well, I bet you know where this is going.  After returning from our meal break, the technical director let me know that the touchscreen computer had locked up.  Thankfully, he had already loaded his entire show into the switcher mainframe and didn't really need the touchscreen computer for the rest of the day.  Now, fearing that it might be something more ominous than a cooling fan, I took the touchscreen computer back to engineering to give it a closer look.  It wasn't a cooling fan.  The hard drive was the source of the noise, and I knew I was in trouble.



"We maintain a very expensive service contract on the switcher, and I called the manufacturer in California.  Now, realize that it is late Wednesday afternoon, the day before Thanksgiving.  I had a show in Pittsburgh on Friday, the day after Thanksgiving.  I knew that getting a replacement in time was a very iffy proposition.  The manufacturer of the switcher did have a menu panel in hand and was able to get it out that day, but could not promise that I would get it in time on Friday.



"Now, like all careful truck engineers, I do have other ways for technical directors to get their shows loaded.  But it's not convenient for them at all.  I also had a pretty recent image of that particular drive.  But I thought that if the hard drive was going bad, that image might not do me any good."  Meaning he wouldn't be able to load it on the hard drive.



"Friday morning in Pittsburgh I told the technical director that if the computer came up at all, he would need to get his show loaded quickly.  I did not trust this machine to remain working for very long.  I had a momentary good feeling when the computer made it past the POST (Power On Self Test), then displayed the Windows splash screen.  But my hopes were quickly dashed when the computer bluescreened a few seconds after displaying the Windows logo.  I sent the technical director back to my engineering computer to load his show, and I started SpinRite working on the menu computer.



"About three hours and 20 minutes later, SpinRite had finished.  It displayed two unrecoverable sectors, but did not report anything else was amiss.  Even though the drive was not making the unpleasant sounds that I had heard in Oklahoma City, I did not have a good feeling about it.  To my pleasant surprise, the menu computer booted up and loaded the switcher application without a problem.  We went through the whole show without any issues.



"I'm still surprised that SpinRite was able to take a drive that sounded like a small metal lathe and make it work again, but it did.  I have since replaced the menu PC with a new one.  I wanted to acknowledge that your product had bailed me out when I knew that I could not count on getting a replacement in time.  Add my name to the list of clients who have been saved by your very functional product.  Best regards and happy holidays to you and Leo.  Sean McStay, St. Louis, Missouri."



LEO:  Thank you, Sean.  I am a little surprised that it worked, actually, because that sounded like it was a hardware issue.



STEVE:  Sounds like bearings in the drive with that kind of a high-pitched sound.  And that could create some vibration that would cause the heads to have a problem.  So glad it got it fixed.



LEO:  Yeah.  But I think he was right to replace it.



STEVE:  Yeah.



LEO:  Who knew how long it would last.



STEVE:  And often SpinRite is, like, you use it just to pull your butt out of the fire one last time, and then that's all you need.



LEO:  Right.  And now, ladies and gentlemen, 12 questions good and true for our friend Steve Gibson.  Are you ready, my friend?



STEVE:  And comments from our listeners, too.  So, yeah.



LEO:  Comments, questions, thoughts, Adobe Gotcha! of the week, that kind of thing.



STEVE:  Good stuff.



LEO:  Start with Robbee Nelson, Raleigh, North Carolina.  He says he may have found an alternative to the PayPal virtual credit card, which we were bemoaning the loss of.  PayPal's discontinued those one-time-only, one-use credit cards.  He says it's called ShopShield.  I may be your biggest fan, Steve, and I appreciate everything you do, especially the great SpinRite.  I JUST LOVE YOU MAN! he says in caps.



To be more specific and to the point, on October 7, 2010, Episode 269, Listener Feedback #102 (I used the GRC search), you sent out "A plea or question to our listeners, who are spread far and wide.  If anyone knows of a replacement" - of the PayPal plug-in, which was discontinued.  Well, I ran across this site, shopshield.net.  I did some online checking, and ShopShield is highly regarded by the Identity Theft Resource Center.  He says it's a nonprofit nationally recognized for providing education and resources to prevent identity theft, idtheftcenter.org.  They review it on their site.  He says:  I listen to each episode every week, but I don't remember any feedback about a PayPal plug-in replacement.  Just wanted to see what you think of ShopShield and if any other listeners have similar findings.  Keep up the great work and remember, I LOVE YOU, MAN!  Cute, that's cute.



STEVE:  So I wanted to share this immediately with our listeners.  There is nothing I want more than a one-time credit card solution.  I have not yet - I just ran across this this morning as I was pulling these together for the Q&A.  So I have had no chance to do any research into the site.  It looks legitimate.  I mean, on the surface it looks like a good thing.  And everything they're saying sounds right.  I don't know quite how they accomplish what they say they're accomplishing because they talk about protecting your name and your mailing address and shipping address and, like, all personal information.  And that's like, well, okay, how can you do that?  Because, for example, Google's, I'm blanking on the name, Google's...



LEO:  Google Checkout.



STEVE:  Checkout.  Which I use and like because they're, in sites that offer that, it's one click.  And Google does perform the transaction with someone who accepts Google Checkout.  What we need is a system where someone who doesn't, like, accept ShopShield can still be used.  So...



LEO:  I presume that they use credit card numbers.  I don't know, I'm looking at it right now.



STEVE:  Yeah.  I have not pursued it.  You'd need to - there's a free trial.  And believe me, by this time next week I will have a tune-up on ShopShield.  I did want to share it because many...



LEO:  It seems like a good idea.



STEVE:  It really does.  Many people have asked for it.  So I've got my fingers crossed, and I'll give everyone a tune-up next week.  In the meantime, anyone else who's interested is welcome to do their own pursuit of this, as well.



LEO:  Yeah, we'd love to hear what you think, get your feedback.  Question 2, an anonymous listener with a great question:  Steve, thank you for your podcast.  I've probably listened to all of them.  I find them informative over the years.  I've been involved in discussions with my work colleagues about which encryption algorithm to use on a low-powered CPU.  It's running roughly 1 MIP, which is not very much in modern terms.  One of my colleagues suggested RC4.  It's simple to implement and won't take up too many CPU cycles.  The device will be battery powered, so we need to keep the number of instructions to a minimum.  What are your thoughts on RC4 for that?



STEVE:  Well, this is sort of interesting relative to the discussion we had last week of RFID crypto.  Essentially, to tie this into that, what I was saying was that an RFID chip which simply blasted out a fixed ID every time it got pinged certainly fell far short of my own requirements for the crypto that I would allow to have implanted in me because we really needed - we needed real crypto.  We needed something where no snooper could just listen to an RFID chip emitting its ID and then clone that and emit the same thing.  So that requires some kind of useful crypto.  And in something which is being powered by the radiation being emitted by a reader, you need to have something that's also very low power, very low computational overhead.



RC4 is even now, to this day, a really good cipher.  It got a bad rap from its use in the very first implementation of WiFi crypto, the so-called WEP, Wired Equivalent Privacy protocol.  But it wasn't RC's fault that WEP was so badly broken.  RC4 is very simple.  It's well known.  It's a trivial algorithm.  And when it's used properly, meaning that you discard the first chunk of pseudorandom data that it provides, and you're very careful about the way you seed the algorithm every time, if those criteria are met, the stream that it produces is extremely robust.  It produces a pseudorandom stream of data which you then XOR with your plaintext to create the ciphertext.



So I really do think that, again, as long as somebody who really understands crypto is the implementer of this, I think it makes a lot of sense for a low-power use, strong crypto in a system where you have either low CPU power, low battery power, low speed, whatever it is.  There's nothing wrong with RC4 as long as it's used correctly.



LEO:  You give it RC'll of approval.



STEVE:  I do.



LEO:  Yes, you do.  Lance Reichert, itinerant engineer in upstate New York, says, I need to convince customer service that email is public.  Recently, one of my credit card companies had the idea to show me how convenient paperless statements would be by giving me a temporary enrollment.  One of the "features" of these paperless statements was a monthly email announcing the availability of my online statement and detailing my outstanding balance, minimum due, and due date.  They were agreeable enough to remove me from the program immediately upon request, but were unwilling to accept that the practice of putting customers' balances and due dates in emails breached those customers' financial privacy and ran afoul of the Consumer Data Protection Act.  They seemed to think that, since I had to log into my email server to collect my email, it was as secure as my email password.  Is there any compelling argument to offer to them that between their server and mine, email is publicly available to anyone who cares to read it?  Signed, Lance.



STEVE:  You know, I've had email like this from our listeners before.  I mean, we have of course created an educated listenership of people who really get this stuff.  And they find themselves frustrated when they're trying to explain to people who are offering insecure services the nature of that insecurity.  And the one thing that occurred to me, the example of this that has made headlines to such a great degree was Google's inadvertent sniffing of WiFi globally as they roamed around collecting their geolocation data for Google Maps and other geolocation services.



And so what Lance, for example, or anyone else could mention is that email is not secured; that even though the login may be secured, it is typically the case that with your typical email client the contents is going across the Internet and maybe in the air unsecured.  And so, for example, if Google happened to be, or somebody else happened to be wandering around sampling what was in the air when this customer statement with this personal information was being retrieved by the customer, it could be sucked in, just in the same way as all the other personal information had been collected inadvertently by Google.



So, I mean, this is in that same classification of the kind of stuff that any third party monitoring would be able to pick up.  I don't know if that'll make sense to somebody who refuses to understand that their service is not secure.  But it is not something that's easy to understand.



LEO:  Well, yeah.  I mean, I'll be honest with you, I don't know how much of a breach of privacy having somebody see what your balance is.  It would be one thing if they sent the credit card number through the mails.



STEVE:  Yeah.



LEO:  I mean, I don't know.  I get all my balances via email now.



STEVE:  It's funny, too, because there have been, I saw just recently someone who did not have an ecommerce capability who was taking credit card information sort of manually.  Well, and they said, send your card in, like, four separate pieces of email.  It's like, okay, well, that's better than all at once.  But still, certainly not very secure.



LEO:  Yeah.  You know, I presume this is secure, but I just got a little dongle that you plug into your iPhone or Android phone into the audio piece, it's from a company called Square, SquareUp.com.  It's a credit card reader.  And I guess it turns it into audio.  And then you have software on the phone.  And without signing up for Merchant Services or anything, you just sign up for an account with them, and of course they take a cut.  You can use credit cards like that.  I could walk up to you, and you could swipe your card onto my iPhone or Android phone.



STEVE:  Yeah.  You can imagine like in all kinds of, like, little trade shows or...



LEO:  Exactly.



STEVE:  ...farmers markets...



LEO:  Precisely.



STEVE:  ...sort of scenarios, yeah.



LEO:  Jennifer, my wife told me about it.  She said, "I was at the craft fair.  Do you know about this thing?" she said.  "Everybody's swiping credit cards."  I said yeah, it's really - it's Jack Dorsey, the guy who started Twitter.  It's very interesting.  All right.  We have three questions that are all kind of about the same, about the RFID stuff.  So I'll just read them all at once.



STEVE:  Okay.



LEO:  And then withhold your applause till the last one.  Didier Stevens, our good friend Didier in Brussels, suggests an RFID tag in a wristband of a watch:  Steve, I know someone who keeps his subcutaneous RFID tag lodged into the wristband of his watch.  Then you don't need to inject it.  He always has it with him.  There's no surgery involved.  That's one way to do it.  Efrain in Miami, Florida thinks an RFID-enhanced cell phone might be an idea.  I think rather than implanting a chip in our bodies, what about a chip in our cell phones?  With the chip being in our cell phones, it can handle complex things because it's a powered device.  Seems to be a logical choice.  I think we can all agree that our phones are always within reach.  And more likely for a company to give you a cell phone with a tracking chip than ask you to get it implanted surgically.



And then Eric in Palm Coast, Florida says, concerning RFID and having the public key advertised, I know this may be unlikely for most of us, but could you not be the trigger for your own assassination?  While this may be an extreme example, could we not be targeted in many other less sinister ways as well?  Additionally, much of what you thought would be cool was available to Bluetooth users a decade ago.  You walk into a room, your music would resume, your Mac would unlock - yeah, that's from a Salling Clicker, using Bluetooth.  Presumably a little less secure, though.  And I've mentioned this NFC, Near Field Communications, in the new Google phone.  Similar to that; right?  As we talked about at the beginning.



STEVE:  Yeah.  So certainly many people suggested alternatives to implantation, which I completely agree, installing something in your body is marginally radical.  The point that I made last week was people are doing it.  There are hobbyists who are on bulletin boards, actively talking about where the best location is to put the implant.  One of our listeners has I think a wife or girlfriend who is an acupuncturist, who was concerned that the location that we've been talking about, sort of in the web of your hand between your thumb and your first finger, which is where it seems to be a popular location, that's an acupuncture point that's related to your upper intestines or something.  So maybe that wouldn't be the best location.  I mean, I don't know.



So I did like Eric's reminder about Bluetooth because, if you wanted to back away from installing, from implanting something in your body, all of our phones are Bluetooth-enabled.  And it is certainly the case that you could turn Bluetooth on, on your phone; not have it discoverable so you don't have that concern.  And then, in the scenarios like I was talking about, like being able to walk up to your garage door and just press a button and not have to use a key or a keypad, or just have your front door of your house unlocked whenever you're nearby.



Certainly a cell phone is becoming virtually ubiquitous for all of us.  We've got one on us pretty much wherever we are.  The downside is that it can be taken from you.  You could lose it; or you could imagine somehow, if someone really wanted to get their hands on it, they could snatch it from you or something, where it's much less easy to do that with something embedded in your body.  On the other hand, I mentioned last week, you wouldn't want to have someone cut this thing out of you violently if they wanted to...



LEO:  If they knew it was there.



STEVE:  If they knew it was there, if they had some access to it.  So I guess, yeah, certainly there are alternatives to embedding it.  And the idea of just sticking it on your wristwatch I think is a good one.  I talked about some silicon bands, like the...



LEO:  I think a lot of people don't wear wristwatches anymore.



STEVE:  Exactly.  As a matter of fact, I'm still a wristwatch wearer.



LEO:  I am, too.  But we're old.



STEVE:  Most of my friends are no longer using wristwatches.  They're constantly checking their phone to see what time it is, if they're concerned.  But they're just not wearing a wristwatch anymore.  I think wristwatches are kind of becoming pass.



LEO:  Well, they're jewelry now.



STEVE:  Old technology.



LEO:  They're no longer functional; they're just jewelry.



STEVE:  Yeah.



LEO:  Hmm.  I remember there were some Mexican legislators, back when there were a lot of kidnappings going on in Mexico, who got RFID tags implanted, I guess in case their body should turn up somewhere and not be identified.



STEVE:  Tom, who did the podcast, both of his dogs have RFID tags.



LEO:  So do our animals, yeah.



STEVE:  And I know that there's a nightclub in Brazil that tags its members.  I guess if you join the nightclub, then you can be tagged.



LEO:  That's funny.



STEVE:  And then walk in the back door or automatically get in or prove your membership that way.



LEO:  Better than a password.



STEVE:  I have to say, though, I'm glad that Eric reminded me about Bluetooth.  I could imagine that being an answer for me, although it'd be a little tough to hack my car.  Be nice if my car knew me.  But certainly a laptop.  You can imagine adding something to a front door lock, or even a garage door, so that if this particular Bluetooth radio was, I mean, if it's got the right amount of range, I don't have to go invent new technology from scratch and so forth.  So that's sort of a possibility.



LEO:  I'm pretty sure Schlage, the lock company, makes a Bluetooth-enabled door lock.



STEVE:  Interesting.  We'll check.



LEO:  If it's RFID, anyway.  If not Bluetooth, some sort of RF technology.  Dustin B. in Seattle, Washington wonders about Controlling Bandwidth:  Steve, I'm aware this isn't in regards to a previous episode.  Therefore it's not feedback, per se.  But I was pondering a question I felt you were the perfect person to ask.  How do ISPs limit bandwidth to specific households?  Hmm, that's an interesting question.  I hear so much about digital, meaning everything is either on or off, no in between.  So clearly the physical connection to my house isn't changing.  I'm able to change my service speed with my provider without getting a new router.  So what is Comcast doing when they say now you're 20mbs instead of 5mbs?  It's the same connection.  Thanks for all the podcasts.  You guys started the same year I graduated high school and headed to college in '04, and it made me realize I needed to switch from a business degree to web applications. 



You know, I was at Google a couple of nights ago for their media event, and I met several Googlers who said that they listened or watched shows that you and I did and others did, and that's how they got into technology.  I met one guy, he said I was in politics, and I listened to TWiT, and I realized I loved technology more than politics, and now I'm working at Google.  So we do make a little bit of an impact, Steve.



STEVE:  That's neat.  Okay.  So I mentioned Mark Thompson, my buddy in Phoenix, who's got an insane amount of bandwidth at his home.  The way Comcast and others function, and this is sort of within the realm of cable modems, is that the coaxial cable itself has an insane bandwidth capacity.  If you consider the idea that over a coax cable is flowing how many television channels?  And a TV signal, I mean, even HD is an insane amount of data.  And most of these have all switched to digital now so that this is digital data, an amazing amount of digital data flowing over this coax.



So essentially you can think of the pipe that's connected to the outside side of your cable modem as being just massive.  I mean, it's a huge pipe that's capable of carrying a phenomenal amount of data.  So all that Comcast or any other cable modem management provider has to do is tell the cable modem how much of that torrent of bandwidth to sip from, essentially.  There are channels, and the state-of-the-art cable modems are able to be scaled in terms of sort of how many of those channels of data they're going to be sipping from at one time.  And it can be scaled up to whatever the maximum data-handling capability of the cable modem is.



So even though, yes, you're receiving ones and zeroes, and there is some digital granularity to the rate of upload and download, because the pipe on the other side is so huge, this coaxial connection can potentially carry so much data, you just tell the device, the modem that's hooked to it, how much of that to take.  And it's able to.



LEO:  There's a widely used and well-known Linux program that's a proxy called Squid that is used to do this.  And we used to help people set up Squid servers in their house because their roommates were sucking too much of their bandwidth.  And for a while I think we were doing that here.  I think that one of our routers, I think it was running the Tomato firmware, had that capability.  And we had limited a router for our visitors to 900 kilobits so that they wouldn't kill our bandwidth.  So that's a fairly easy and well-known application.



STEVE:  Yup.



LEO:  We still do that.



STEVE:  There are, now, that's sort of different.  There's, like, bandwidth shaping and bandwidth throttling.  And there you may have a high-capacity single link where you're wanting to throttle the bandwidth of different...



LEO:  Individuals.



STEVE:  ...users within the link.  And, for example, you're doing it by IP or by port or whatever.  And there it actually is a little tricky to get TCP, which is the protocol, or even trickier for UDP.  Sometimes what they're actually doing is they're queuing the packets and allowing them to pile up a little bit because TCP will notice the delay in the connection and slow itself down as it notices that it's not getting acknowledgements back from the other side as quickly.



LEO:  Oh, that's clever.



STEVE:  So it turns out that it actually is surprisingly complicated to throttle TCP connections in a smooth way.  But it's a problem that's been solved.



LEO:  Yeah.  Let's talk about Chrome OS.  Question 8, Ty, Nashville, Tennessee.  He says:  I love listening to the podcast.  It's one of my greatest resources for technical learning and growth.  I know it's a little early to tell, but what do you think of the security of Google's Chrome OS?  I have the Google Cr-48 kind of demo laptop that they sent out right here with me.  I've been playing with this.  And actually I talked to some Google - the product manager about this very subject.  He says:  I know it's early, but what I've read makes it sound like it'll keep local storage to a minimum and only allow downloading of a small subject of file types, meaning it will not even be running executable code outside of the browser.  I've even read it will monitor system files for changes on startup - that's right, it actually does a hash on the firmware and the system files, and if they're modified it goes, whoa - and repair them if it sees any modifications.



It almost sounds too good to be true from a security standpoint (not privacy, of course, since Google is running the show and users are required to log in with a Google ID to even use the system).  And that's also true.  Can you think of any obvious drawbacks to the platform, or have you heard of anything that would give you pause in giving it a try?  Thanks for your work and passion for technology.



I talked a little bit, I mean, that's one of the main points of Chrome OS.  Everything, for instance, they sandbox Flash.  They sandbox the reader.  Not everything is yet sandboxed, but that's their goal.  So that's really what they're trying to do.  Every tab is sandboxed.



STEVE:  He starts off saying he knows it's a little early to tell, but what do I think about it.  What I think is, everyone who listens to the podcast knows that one of our fundamental lemmas of security is that it's not something that can be stated.  It's only something that can be proven.  And so it inherently takes time.  What I love about this is that it's been designed with security awareness from the beginning, and I couldn't ask for more.  So whereas Windows' legacy unfortunately, or the Internet's legacy unfortunately, predates security completely.



For example, where DNS - there was no concern, no thought about security back when the Internet's fundamental architecture was being created.  So it's always had that problem.  Similarly, Windows was designed as a single-user system that then became networked, then went on to be part of this global network and has suffered, well, as we just saw, in 2010 Microsoft broke their record of security vulnerabilities.  Even now, years after they've been security aware, and Ballmer's been stomping around onstage proclaiming that their operating systems are the securest ones they've ever made, well, they just broke their record this year in number of security patches.  So I couldn't be more pleased about this.



Now, I did also read, though, that there is technology, and I don't remember the name of it, but it allows Chrome to run native code.  And it's like, oops, that sounds a little scary.  Someone is pushing for more performance.  And I'm hoping that it will be sufficiently sandboxed that running native code rather than scripting can be made safe.  Scripting being inherently interpreted, you potentially have more control over it than you do if you're running native.  But also being scripted you've got a performance hit.



So I just - I love what Google is doing.  I love the idea that because they had the advantage of starting so late on this, they've been able to - and because they know that nothing matters more to us than security of this, the idea of offering this as a secure platform is really compelling.  So I've got my fingers crossed, and I'm holding my breath that it ends up being proven to be as secure as they have designed it to be.  But the fact that they have designed it to be sure gives it a head start.



LEO:  Yes.  It's certainly their intent.  And I love the fact that things like system files and firmware are hashed and protected from modification.  I think that's, I mean, now you're really starting to pay some serious attention to this.



Number 9, Christiaan Conover in Annapolis, Maryland wonders where a one-time password model would work for RFID tags:  I've been listening to your discussion on RFID tags which sound very intriguing.  You did mention some security concerns, naturally.  But the benefits and use cases of such technology do sound appealing.  What I started to realize as I was listening is that some of the uses sound similar to how I use my YubiKey.



This got me thinking.  Maybe the YubiKey model is exactly the solution to many of the concerns around RFID tags.  It's already an open protocol and an authentication standard which can be implemented by anyone.  So it would take care of the need for a standard to be developed.  It could be set to issue a one-time password at each use so that somebody trying to clone your chip with a reader wouldn't get much benefit as all they'd get from the read was that single instance of OTP (one-time password).  Plus it would give the user the ability to control authorization of use by requiring them to confirm a certain device or location to be allowed access and be able to revoke it at any time.  You could easily send a text message or email to somebody when authorization is needed, which they could reply to and within seconds a new authorization rule could be created on the fly.



Is it possible to do that with the way RFID tags work?  Or have I missed a technical detail that would preclude this?  It seems like a proven secure authentication method and a natural choice for a technology like this.  Thanks for a fantastic show.  Avid listener.  Wednesdays are now one of the more exciting days of my week.  Take care.  Christiaan.  It seems like there's not enough computational juice in an RFID tag.  Is there?



STEVE:  The problem actually is that a one-time password requires that some way of everyone knowing...



LEO:  Synchronization, yes.



STEVE:  Yes.  Some way for everyone knowing that you've used that password, and so it can't be used again.  In my use model for why it would be intriguing to implant something, it's that I'd love my laptop to know me, my garage door, my car, my phone, different devices.  It would be nice to have a physical proximity acknowledgment.  But those are inherently, or at least in some cases - my front door - not on the network, not attached to a global network.



So for one time - the whole concept of a one-time password model, the YubiKey for example, is that when we're authenticating with the YubiKey, we are connecting, the device to which we're authenticating has a real-time connection back to a central server.  And any potential device to which we want to authenticate has to have a real-time connection to a central server so that essentially what we really have in our YubiKey, or we would have in our RFID, would be a counter.  That counter would be encrypted, and that would produce the one-time password.  So the value in that counter is being maintained at the central server, so that the server knows what the last authentication was and is able to track that counter forward as it advances.  That requires everything to which we would authenticate to be tied into that server.



So unfortunately, nice as it would be, that really doesn't fit the use model for a standalone authentication.  Something like some sort of cryptographically enhanced RFID does.  Unfortunately, I don't think it's a one-time password model.



LEO:  You must have been talking about your beloved side tabs in Firefox with Tom.  Nick in Thief River says Chrome has side tabs.  Side tabs are experimental in Chrome.  But if you type about:flags into Chrome you'll get a settings page where you can enable a Side Tabs context menu option in the tabs context menu.  So, yes, you can do that in Chrome.  Is that one of the reasons you don't use Chrome is because you like your side tabs?



STEVE:  Well, I'm in love with side tabs, and I've got, like, 75 of them open right now.  And I'm not one of those people whose desktop has four icons.  I don't know what it is.  Something's wrong.



LEO:  These are kind of cool settings.  I did not know about this, about:flags.



STEVE:  They are.  There's a number of cool settings there.  There's one at the very bottom that I liked also.



LEO:  Click on a blocked plug-in to run it.  Web GL enables canvas events.  GPU-accelerated compositing.  



STEVE:  That's what it was.  It was the other GPL technologies for speeding up CSS rendering stuff.



LEO:  Wow.  Enables 3D CSS and higher performance compositing of web pages using your GPU. 



STEVE:  And so, for example, you made the comment, Leo, that your, as is mine, your wide screen on your most recent Mac...



LEO:  Right, yeah, a 16:9 screen.  And a lot of computers now have 16:9 screens, have all this real estate horizontally, and often, like in the MacBook Air, are very constrained vertically.



STEVE:  Yes.  And so you might try it.



LEO:  I'm going to.



STEVE:  You enable the first one.  Then go and right-click on a tab, and you'll see the last item on the tab's context menu says something about vertical tabs or side tabs or something.



LEO:  So Enable Tab Overview, is that the one I should enable?



STEVE:  The very first one.



LEO:  Okay.  That's the first one.  I've enabled that.



STEVE:  Okay.  And so now, if you right-click on the tab - maybe you need to restart.  Oh, yeah.  Whenever you make a setting change, a button appears at the bottom that restarts Chrome.



LEO:  Oh.  I should have probably said "okay" or something.  All right.  Yeah, it's still enabled.  So now what do I do?  I do a tab.



STEVE:  Right-click on a tab.  And the last item in the context menu should say something about side tabs.  It did work for me, and it immediately moved the tabs over to the side.  And it's like, oh, this is good.



LEO:  That's neat, yeah.  Well, I'll play with it a little bit more.  It's not doing it for me, but I'll play with it.



STEVE:  Oh, it says Use Side Tabs, and mine has a checkmark on it now.



LEO:  And does that put all the tabs - oh, yeah.



STEVE:  It creates a nice column over on the left-hand side.  It gives you, as you would like, more vertical real estate by moving them off.  And I have to say, every time I look at Chrome, I think, wow, this is just the cleanest UI.



LEO:  They've done a nice job.  I am a Chrome, exclusively  now, Chrome user.



STEVE:  Seems pretty quick, too, Chrome does.



LEO:  Oh, yeah.  Snappy.  Nathan Ramsey from Australia, now in London, has some very nice things to say:  Steve, after studying off and on for a couple of months, I just passed my Security+ exam today.  All I can say is it was a tiresome yawn.  That's not a negative on Security+, but a positive on Security Now!.  Listening to you week after week has imbued me with the ability to understand words like "honeypot," "least privilege," "DNS spoofability," et cetera, with the greatest of ease.  I was amazed at how much everything you've told us follows - sometimes word for word - with the best practices that I had to study for this exam.  It almost felt like you wrote the exam.  That's pretty neat.



Anyway, I just wanted to thank you and Leo for your devotion to such a technically useful show and your commitment to provide nothing short of the best.  That's really, I think, an outstanding trademark of Steve.  Absolutely committed to perfection.  Kind regards, Nathan (living in London, UK but from Australia where I started listening to you).  Well, thank you, Nathan.



STEVE:  I just wanted - I just ran across it.  I thought, well, that is just the neatest thing, that he took his security exam, and it was like, okay, yeah, I know all this already.



LEO:  I hope you passed it, Nathan.



STEVE:  Oh, he did.



LEO:  Oh, good.  Now, ladies and gentlemen, if you will, the Adobe Gotcha! Tip of the Week.  Steve, I really enjoyed your Security Now! podcast, says Jack D. of Port Perry, Ontario, Canada, and want to thank you and Leo for a superb job.  Let me pass along something I noticed that your listeners should look out for.  When I recently updated Adobe Reader from 9.4.1 to the new version X - which is a big "X," Mac style - unlike previous updates, I suppose because this is a new version number, it reenabled - oh, boy.



STEVE:  Mm-hmm.



LEO:  It reenabled JavaScript and reenabled "Allow opening of non-PDF file attachments with external applications."  These are the things you said to turn off because you don't need them in a PDF reader, and they're a huge security threat.



STEVE:  Yup.



LEO:  So I think all of our listeners and viewers by now have that turned off in Reader.  But it turns it back on when you update.



STEVE:  Yup.



LEO:  I'm unsure whether allowing these settings is no longer a security threat under this new sandboxed version.  But I thought I should point it out.  You know, even if it isn't a security threat, turn it off.



STEVE:  Exactly.  Again, one of our other fundamental security rules is, if you don't need it, and you're not using it, turn it off.



LEO:  And most people don't.



STEVE:  Features are bad.



LEO:  Yeah, features are bad.  I like that.



STEVE:  Features are bad.



LEO:  Turn it off.  You don't need it.  Well, thank you, Jack D., for pointing that out.  I haven't - I don't use Adobe Reader, so I have no idea.



STEVE:  Yup, and it caught me by surprise.  I checked, and it's like, ooh.



LEO:  It did the same thing?



STEVE:  Yep, absolutely, those things were back on.  It's like, oh, you bad people.



LEO:  That's not good.



STEVE:  They just don't get it.



LEO:  Yeah, no kidding.  I mean...



STEVE:  They really don't.



LEO:  Very few people need JavaScript or external third-party programs running from a PDF.  That's just not - that's an unusual usage.



STEVE:  Yeah.  I mean, and all they are is big, huge security vulnerability opportunities.  It's like, get those things turned off.  So I thought all of our listeners would want to know that, had they gone up to v10, to go back into their properties, down to trust management, and remanage their trust.



LEO:  Turn off, yeah, remanage your trust.  Turn off JavaScript and third-party apps.



STEVE:  Yup.



LEO:  Steve, as usual, a great show.  Thanks to Tom Merritt for filling in last week.  Next week, we don't know.  Oh, you have an idea of what we're going to cover?  Or is it a mystery?



STEVE:  Don't have any idea.



LEO:  No idea.



STEVE:  There are some things brewing here that may end up grabbing us.



LEO:  We can talk about that OpenBSD story.



STEVE:  Some big news, yeah.



LEO:  If you want to know more, go to GRC.com/securitynow.  Steve has show notes there.  He has 16KB versions for the bandwidth impaired, full transcripts - thank you, Steve, for paying for those and getting those done.  GRC.com.  You know, while you're at GRC, browse around because not only is there a ton of free stuff there, like the DNS Benchmark, ShieldsUP!, Shoot The Messenger, DCOMbobulator, all of those great programs Steve has written in little tiny teeny-weeny assembly code, there's also his bread and butter, the No. 1 hard drive maintenance utility in the world, SpinRite.  If you have hard drives, you need SpinRite.  And you can get it from GRC.com.



Watch us do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time at live.twit.tv.  And if you miss the live broadcast, don't worry, we make it available in audio and video at TWiT.tv/sn or on iTunes, on Zune, anywhere you can get - where finer podcasts are found.  Thank you, Steverino.  I shall see you next week.



STEVE:  A pleasure, as always, and see you next week.



LEO:  Thanks, on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#280

DATE:		December 23, 2010

TITLE:		Bluetooth

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-280.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After first catching up with a bunch of fun and interesting security and privacy news, Leo and I plow into a meaty and detailed description of the technology of Bluetooth device interconnection and its cryptographic security.  A follow-on episode will cover the past hacking attacks against Bluetooth.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 280, recorded December 22, 2010:  Bluetooth Security.



It's time for Security Now!, the show that covers your security, your privacy, everything you need to know to protect yourself online.  And here he is, ladies and gentlemen, the star of our show, via telephone today...



STEVE GIBSON:  Yes, not quite as online as usual.



LEO:  ...because Skype is down, which probably is story number one for Security Now!.  I've never heard of such a thing.



STEVE:  It would be nice to know what the cause was.  There have been so many people lately, major sites have been down because they've been involved in one way or another with WikiLeaks, and the so-called Anonymous group have vented themselves on one organization after another that has indicated any resistance to staying faithful to that cause.



LEO:  The Skype folks are blogging and tweeting and saying, yes, we know our server is down.



STEVE:  Oh, I'll bet they know.



LEO:  Yeah.  And can you imagine.  I just cannot remember that ever happening before.  Now, I think you and I have done one show via phone before, and maybe it was when I was in Canada or something.



STEVE:  In the Dark Ages, Leo.



LEO:  In the dim dark ages.



STEVE:  Yes.



LEO:  But if people will just bear with us, we'll just have phone-quality audio.  If you're watching the video, we do have a video, actually a pretty good video of Steve, as good as Skype, and that is through Google and their gTalk plug-in for Gmail.  So at least we've got video.  And we had some problems.  We were going to use it for audio, but we have some problems with the audio.  And I imagine on This Week in Google we'll be doing it, as well.  So, by the way, the Skype blog is now down.  So that I find kind of interesting.  That you wouldn't expect to be tied to the same servers that they use for Skype.



STEVE:  Unless it really is an attack on their network.



LEO:  I'm wondering now if it might be a DDoS on their network.



STEVE:  Yeah.  If it was on their network, it could bring down their whole infrastructure, which would be all of the various pieces that they've got.



LEO:  Wow.  So what is our topic of discussion this day, Steve?



STEVE:  Well, for a long time people have asked about Bluetooth security, what is the security protocol, technology.  It's something that, well, all of us are using, probably have had the occasion to use from time to time, if nothing else.  And of course some people, as laws are enacted that require that we not hold cell phones while we're driving, whether we use cell phones wirelessly with the little headsets - and of course in California there is that law now, so you see people walking around with the little Bluetooth radio stuck in their ear, blinking.



So it's finally time, here on our last episode of 2010.  I thought it'd be great to cover the inner workings of the Bluetooth function and security protocol.  And probably week after next we will - or week after that one because we'll have a Q&A week after next, since we're going to skip the episode through the holidays - we'll talk about the attacks that have been launched against Bluetooth, having first established the context for how all the crypto stuff works.



LEO:  Well, I can't wait.



STEVE:  And we've got a ton of news.  I want to, before I go any further, remind - or I want to, not remind, remind myself not to forget to thank everybody who posts things to me in Twitter.  It's like I have this huge network of people out there surveilling what's happening in the world.  And many people say, I'm sure you've already seen this several times.  It's like, yes, well, in fact I have, but I'm glad not to miss it.  So, I mean, this has really been useful for me, as it turns out, here toward the end of, what's it been, maybe six months that I've been experimenting with Twitter?  People are out there seeing stories and saying, hey, can you explain what this means?  And it's perfect because it gives me a lead to follow up.  And then I figure out what it means, and I bring it to all of our listeners.



LEO:  All right.  I'm thrilled to get to talk about that.  Let's get to the security news.



STEVE:  Tons.



LEO:  Tons of security news.  So, Steve, let's get to the news of the day, shall we?



STEVE:  Well, following up on - well, okay.  First updates.  No security updates of any sort.



LEO:  Woohoo!



STEVE:  However, we do, yeah, we do have a new problem with IE versions 6, 7, and 8.  There's a new, a so-called "use after free" problem, which is where memory that's been allocated and then released back to the system, or freed, as it's called, still has a pointer which code can maliciously use.  And then when that memory gets reused, it sort of reinvokes it.  So it's sort of zombie code.  And initially - this has been known for a few weeks and was not believed to be exploitable.  But some exploit proof-of-concept code was recently posted to the 'Net.  This is remote code execution vulnerability.  It's another one of the CSS, the cascading style sheet parsing problems.  We've seen a number of those in IE recently.  So here we are, just having done our world-breaking or record-breaking update of 40 different patches in a large number of security issues last week, and we've got another problem.  So with any luck Microsoft will be fixing this as their first act of 2011.



LEO:  It's amazing.  By the way, for those of you just tuning in, Steve is on the phone right now with us.  We do have a video of him thanks to Google Talk, but Skype is down.  And by the way, Steve, Twitter is now down.



STEVE:  Really.



LEO:  Well, I think it's related.  I think people...



STEVE:  [Indiscernible] just an overload.



LEO:  Everybody's tweeting "Skype's down," and they broke Twitter.  You know, it just shows you, we're so reliant on the Internet these days.  And we've talked about this.  It's in some ways a very fragile system.



STEVE:  Well, yes, I mean, and not even "in some ways."  One of the comments that I made last week was that people have been surprised, for example, that the Anonymous group, using that LOIC, the low orbit ion cannon, that was their name for their distributed denial of service attack tool, and all it was doing was making standard TCP connections and transferring data to, like, major sites like Visa and MasterCard and so forth.  But it turns out that normal web traffic is the way our systems are scaled, so that they're able to handle your typical normal amount of user access, which really is very spotty and not continuous.  You click a link, you ask for the page, you get the page, you ask for a few images and things, and then typically you're there sort of figuring out what you just got for a while before you do it again.  So what's interesting is that it doesn't really take that much to overwhelm many of these high-profile sites.  And as you say, we're really dependent upon it.



Which actually is one of the stories I wanted to mention is, as I'm sure you have seen, Leo, the FCC yesterday, that's on Tuesday, voted to enact the so-called "Open Internet" order, which was the long-awaited Net Neutrality bill.  However, it really disappointed a lot of people.  Net Neutrality is this notion where an ISP, someone who we pay to give us connectivity, would be formally prohibited from any sort of traffic shaping or content discrimination.  The concern is, for example, that if Comcast and, for example, NBC merged, which I think that there's discussion of that happening right now...



LEO:  That's right.



STEVE:  ...that Comcast could preferentially carry NBC's content over competing content.



LEO:  Well, it's already happened because Comcast has gone to Level 3, who provides the backbone for Netflix, and said you are going to pay more for Netflix.



STEVE:  Yes.  And there's a peering, a big peering dispute with Level 3 and Comcast.  Yeah, essentially the idea would be - so if Comcast was kept as a strict, just a conduit - which to me really seems like the right solution, is not give these carriers any motivation for preferring any Internet content over any other, just make them a pipe.  But it looks like that's not going to happen because we've got the tendency to merge companies and reduce choice, unfortunately.  So anyway, the point is that this is a very weak Net Neutrality bill...



LEO:  Very disappointing, yeah.



STEVE:  ...which has really upset the people who have been following this closely.  It doesn't do anything for mobile broadband.



LEO:  That's the real problem.



STEVE:  Yeah.



LEO:  I mean, it just basically says, okay, you do anything you want.



STEVE:  Yeah, exactly.  And you've got to worry, too, when the carriers are happy with this bill.



LEO:  Oh, yeah.



STEVE:  Because it's like, oh, okay, wait a minute, maybe we ought to read this again and see what it was we just gave them.  Also, if you read the language, it says, like, nothing.  For example, it says, "Bars wireline-based broadband providers from 'unreasonable discrimination' against web traffic."  Well, what does that mean, "unreasonable"?



LEO:  Right.



STEVE:  Unreasonable to the CEO of that company?



LEO:  Yeah, who's to say, exactly.



STEVE:  Or to you and me?  So anyway, it just seems like it's - actually it's worse than having nothing because now it seems that there is something, and so now they're not going to work on it.  And even so, apparently there's already talk of repeal of this.



LEO:  Yeah, it's funny, it made no one happy.  Which I guess in some ways means maybe it was a good compromise.  I don't know.  I was very disappointed.  And, frankly, I don't know if the government should be involved in this.  But we are seeing evidence that somebody needs to do something.



STEVE:  Well, analogies have been drawn to the idea of turning the internet into things like radio and TV and cable.  And it's like, oh, no.



LEO:  I don't want to go there.



STEVE:  Oh, yeah.  So that would not be good.



LEO:  It's really difficult to know what to do.



STEVE:  Well, when you bring big bucks and commerce into the picture, and companies get really big, they start saying, hey.  They get aggressive.  And it's not clear that the customer wins in these cases.



Just when we were recording the podcast last week, that news had hit alleging that the crypto system, the crypto framework in OpenBSD may have been compromised, as long ago as a decade ago, by a government contractor called NETSEC.  Additional news has come out in the meantime.  And as it turns out, I saw the name of an old friend of mine, who's now ex-FBI.  He was with the FBI.  His name is E.J. Hilbert, who was involved sort of in this side of the tech-y stuff.  That's why I knew him was because he was involved in the technical side and also was local.  It was over coffee when I was getting ready to do my eCommerce system that he gave me some tips about things I wanted to make sure I did in terms of configuration because he had seen lots of credit card fraud perpetrated against other organizations that had not configured things correctly.  And I've already passed all these on to our listeners over the last several years.  So there's nothing new there.  But he had some knowledge of it.



And what it appears to be is that this company, NETSEC, produced for a while - and they're gone now, but they produced 10 years ago a crypto accelerator.  So there was hardware that accelerated crypto.  And of course we needed that much more once upon a time, 10 years ago, when our processors were much less capable of just doing crypto in software with sufficient speed.  So hardware acceleration of cryptographic operations was not uncommon and was much more common back then.



And what is believed to be the case is that a fork of the OpenBSD UNIX was used experimentally by this company to experiment with modifying their own drivers for this particular card to introduce some leakage, purely as a proof of concept, does this kind of thing even work.  Never at any point was there any notion of this code being put back into the public, being merged back into the regular OpenBSD source base.  So this is, as we hoped, and as we suspected last week, a complete red herring.  It is the case that, if you parse the facts that were presented, technically they're true.  But any conclusions drawn that implies that there's something, like, out in the wild that has been compromised is, like, many steps away from being true.  So that's good news.



LEO:  Yeah.  And frankly, besides being a relief, kind of not surprising.  I just couldn't fathom that this could possibly be the case.



STEVE:  It is the case, though, that many people have been looking at the code, and some bugs have been found.  And some messy functions have been cleaned up.  So, as is always the case when you look at something more carefully, oftentimes you're able to say, oh, look, we're smarter now than we were 10 years ago.  This is a better way to do that.  So it's sort of been good.  This is, like, dusty old code that no one's really looked at for a long time.  And so in dusting it off they've said, oh, we can fix this up a little bit and make it better.



LEO:  Good.



STEVE:  So that happened, yeah.  I got a kick out of one little news blurb, and that was the way that some of the WikiLeaks fight-back guys, members of the so-called Anonymous group, had been tracked down was from document metadata which they had left into some documents that they had released.  And I thought this was a good time to mention to our listeners, who are security and privacy conscious, sort of a reminder about document metadata because, for example, Microsoft Word is famous for doing this.  And even PDF files now contain a lot of stuff.  The idea being that the data that you see in the file itself, the actual presentation onscreen is now just a portion of what the actual binary file contains, and that there's a lot of stuff that you don't see when you look at page one, page two, page three printed out and so forth, which is actually present.  And it sort of accumulates as this document moves along.



Microsoft has some pages that talk about this awareness.  And it's from there that I got a list, their list of things that they know they include in Word.  So, for example - well, Word, Excel, and PowerPoint, their main flagship products - your name, your initials, your company or organization name, the name of your computer, the names of the network server or hard drive where the document was saved, the names of previous document authors, document revisions and versions, comments and more.



So it's just sort of a little heads-up to our listeners that, if you were concerned about the history, the past, the ownership, the authorship and so forth, it really makes sense, for example, to export the document into a text file, which has no metadata, or maybe into an RTF file, which is only presentation data and not data that isn't displayed.  Or print it to - you could print an existing document, for example, into a PDF.  Then you've got it in a format where it's only containing the stuff that you printed.  Although, again, it could also know anything about the system that it was being transferred on.  So it's a little sticky these days to be completely anonymous and to maintain privacy, even with documents that don't appear to be releasing any information about you.



LEO:  It's amazing, isn't it, yeah.



STEVE:  Speaking of all the feedback that I've received from people through Twitter, someone tweeted me, a Tim Raymond, just a heads-up that a couple days ago Secunia, who produces that very nice personal software scanner called PSI, thus the acronym for personal software scanner, just took it to v2.0, with an updated user interface and now the ability, if you choose, it will take responsibility for maintaining and updating the obsolete or down version software installed on your machine.



So to remind people what this is, it's free, completely free, Secunia.  You can just put that into Google.  It'll take you to Secunia.  And in the upper right-hand corner of their page is a link either for downloads or specifically for PSI, can't remember which.  But it's easy to get there.  And this is a scanner which we've all used, anyone who was interested in this in the past, and, I mean, to very nice benefit.  I like it.  It will just rummage through your hard drive and look at the versions of virtually everything you've got installed.  It's very comprehensive.  It's also very small.  I think it's only a couple meg in size.  And it alerts you of things you've got on your computer that are no longer current.



And we're very used to things like Acrobat and Windows updating themselves, certainly Chrome browser from Google, updating themselves on a more or less constant basis.  But there's a lot of apps that don't have that built in, or that only do it when you run them, and you may be running a very old version the first time you start something up again.  So this will look at it even when it's not running and say, hey, by the way, there's a whole new version of this.  So it's nice, and I can endorse it easily.  So it's now at v2.0 with new features.



LEO:  Cool.



STEVE:  Google has enhanced their warnings.  We've talked before about how, when you do a Google search, and it brings up a page of links, you may see, and I've seen a couple times, a warning saying this site may be compromised, the idea being that Google's own bots are looking at sites, when they go into them in order to index them, and flagging when they see, for example, clear malware.  They'll warn you that this is probably not a link you want to click on.  And I think when you do click on it, it takes you to an intercept page that Google puts up, I mean, to really protect you from doing this by mistake.  And then you have to deliberately say, okay, yes, I really want to go to this place that you think is bad, in order to get past it.



Well, they've enhanced that, making it more sensitive, adding another phrase where it says "This site may harm your computer," instead of "This site may be compromised."  Wait, I got it backwards.  It always used to say "This site may harm your computer."  Now what they've added is "This site may be compromised."  Meaning that they've detected some things that they sense indicates that the site may not be under the full control of the site's owner.  So various types of not necessarily malicious stuff, but just something that seems fishy to them, they'll now warn people of.  So I think it makes so much sense for search engines to be able to take this kind of responsibility because for most of us, that's the way we view the 'Net is through the lens of the search system, which finds things for us that we want to explore further.



In the ongoing battle with Google and their inadvertent collection of wireless data, I did note that Connecticut's Attorney General Richard Blumenthal had given Google a couple weeks, several weeks ago, to turn over the data that they had mistakenly and inadvertently collected from Connecticut's residents.  And as of 5:00 p.m. Friday, which was the end of last week, that is, December 17th, Google had not done so, and is apparently refusing to do so.  Which I applaud them for.  From my bird's-eye view, I really can't see any use for Google turning this stuff over.  And it just seems to me just more stirring the pot without any particular value.



LEO:  Hmm.  Good.



STEVE:  So, yeah.  Again, I think Google can just say, look, we got this random stuff.  Just let us delete it.  In fact, they have deleted all of the UK data finally.  So that was good.



We've talked about IP space depletion and how the clock is running out for, like, late summer of 2011 for there literally to be no more IP addresses.  Everybody who's got one can keep theirs, pretty much.  But the rate at which they really have been allocated is accelerating as of course Internet becomes a bigger deal.  And we're running out of our 4.3 billion IPs.  In a little weird event, there's an ISP in Okinawa who was given a chunk of the 49-dot block.  So it used to be that there were no IPs beginning with 49.  That was one of the major class A networks that just had - it's, like, five that we've talked about before that just wasn't ever used, which is why Hamachi had been using the 5-dot network.



Well, the 49-dot network is beginning to be handed around.  And I got an interesting tweet from Brandon Carlson, who is in Okinawa, saying that a provider that he uses, GL Broadband, has a page up to explain to their users that, as a consequence of the fact that the routing tables on the Internet are taking longer than they should to be updated, that's why their users are unable to access Xbox Live, ESPN Player, LiveStrong, Meebo, NFL Gamepass, the Nova Southeastern University, and the Washington Heights Church, just to name a few.



So what's happened is that routing tables - we've been talking about the problem with inadvertent updates to routing tables, which was for some length of time diverting traffic through China.  Routing tables are something that ISPs are being increasingly careful about letting change.  And so even though the allocation of this new IP, 60 million IP space, of which this GL Broadband has received a chunk, even though it's official and legitimate and real, there are some routers that have not gotten the message.  And those are the routers of the specific sites, or routers related to the specific sites that some GL Broadband users cannot access.  So their traffic is probably able to go to those IPs of those sites, but Internet connections require a round trip in order to establish a connection, in order for any data to come back, as well.



And so packets are trying to get back to 49 dot something dot something dot something, and they're being thrown away.  It's a so-called "black hole," which means just sent into oblivion because those routers, routers somewhere along the path back, still don't know where that particular 49-dot IP range is.  So they're inaccessible, essentially.  Again, it's largely functional, but there are little patches sort of grayed-out around the Internet.  So I thought this was an interesting little anecdote for the kind of problems we're seeing as major new blocks of IP space are brought online for the first time, as will be happening for the next nine months until there is no more.



LEO:  At least that long, yeah.



STEVE:  Yeah.  Also our friends in Florida at - I'm blanking on their name.  Sun.  Alex.



LEO:  Oh, yeah, yeah, yeah.  I know who you're talking about.  Sun thing.



STEVE:  Sun something.  Ah.  Shoot.  Well...



LEO:  The chatroom will tell me in a second.  It just takes a little while here.



STEVE:  Yeah, they will.  Anyway, they were blogging about a new problem that has been picked up by a number of other people.  The next annoyance...



LEO:  Sunbelt.



STEVE:  Sunbelt Software, yes.



LEO:  And the winner is a Monkey Mind.



STEVE:  And I was also - they just got acquired by somebody, a three-letter acronym, GLT or something [GFI].  Anyway.  So Sunbelt Software, a great following and source of security information, blogged recently to people who follow their blog to watch out for fraudulent defraggers.



LEO:  Oh, geez.



STEVE:  That's the latest thing to happen.  There's so many useful free software out there, it's not surprising that the bad guys are going to be mixing their own malware in with the good stuff.



LEO:  Of course.



STEVE:  So there's HDDRepair, HDDRescue, HDDPlus, UltraDefragger, ScanDisk, DefragExpress, and WinHDD have all been identified as bogus.  They claim to be a free defragger to make your computer run faster, the way it used to.  And who doesn't want that?  What these things do, though, they're scareware.  You run them; they actually do no defragging at all, but they apparently do something.  And then they come back with a note that, oh...



LEO:  Oh.



STEVE:  ...you've got serious problems, baby.  We're going to need another $20, or an initial $20, or more in some cases, to fix this problem.  So again, this is going to catch a certain number of people who unwittingly download this and don't know any better.  So I thought I would take the opportunity to mention my top three defraggers for Windows.



LEO:  Oh, good.  Do you really need them, though?  I mean, you're the expert.



STEVE:  Not so much.



LEO:  I think NTFS and OS X on the Mac side, the HFS Plus file system, do a much better job of keeping themselves from getting fragmented.



STEVE:  Well, they do.  But my feeling is, for example, when you initially set up a system, and you install a million secure Windows patches, that process of installing all those patches and replacing all the files, it really does mess things up.  So I do like to do a post-installation defrag because, from a file recovery standpoint, if anything really bad happened...



LEO:  Oh, that's a good point.



STEVE:  ...to the master dictionaries on your drive, having the files' pieces be contiguous makes recovery possible.  I mean, it really makes a difference from a data recovery standpoint.  So but the downside is, we know for example that, as people move more and more toward solid-state drives, there you really do not need to defrag them because there's no benefit, there's nothing, no head moving at all, nothing mechanically happening, and much lower probability of there being, like, file system level problems that would be caused by bad sectors because these are solid-state drives.



But the point is that, not only are they solid state, but they don't like to be written to.  We know that solid state drives have a write limit.  Whereas physical drives aren't degraded by writing, solid-state drives are.  So defragging, which is a write-intensive thing, is something you'd rather - you'd probably not want to do on a solid-state drive as much as on a physical drive.  So...



LEO:  So what do you recommend?



STEVE:  Vopt.



LEO:  Oh, yeah.  That's been around for ages.  That's, like, Golden Bow; right?



STEVE:  Golden Bow's Vopt.



LEO:  That's, like, as old as SpinRite.



STEVE:  Actually, yes.  In fact, the author, Dennis somebody and I, were friends back in the very early days of SpinRite.



LEO:  Yeah.  I think I remember it from your recommendation, probably in InfoWorld.



STEVE:  Probably.  And it's also been our friend Jerry Pournelle's Chaos Manor choice.



LEO:  Jerry Pournelle loves it, yeah.  That's right.



STEVE:  I mean, he just can't stop talking about it.  Today it's a little pricey at $40.  There is an extremely good free one called - they used to be called JK Defrag.  It's been recently renamed My Defrag, and it's just at MyDefrag.com, which I can recommend without reservation.  It's open source.  The guy makes the source available.  Very nice UI.  I like defraggers where the resolution of the screen - where you can, like, see all the little fragments, when it's high resolution instead of low resolution, because I just, like, I'm fascinated.  I can just sit there and watch my hard drive be defragged for hours, which is typically how long it takes.  I mean, it makes SpinRite seem reasonable in terms of data recovery.



And then a very reasonable-priced product that I really like also is called PerfectDisk by a company called RaxCo.  It's $29.99, or $29.95.  And the one thing it is able to do that neither of the others do, being commercial, and being very mature, is it will do a boot-time defrag of your system files, the things that are in use that normally no other in-Windows defragger is able to touch.



LEO:  That's huge.



STEVE:  Yes.  So the directories and the MFT, the Master File Table, which is like the major table of contents for the NTFS file system, there are these major pieces of the drive that cannot be defragged.  So all you're able to do is defrag sort of the things it points to, that is, the pieces of the files, but not the directories and the major indexes.  Because this thing has the ability to do a boot-time defrag, you're able to say, yes, do all of that next time I reboot.  Then when you reboot, it takes you to a sort of a pre-boot screen and rummages around for a while, doing that work that can only be done outside of Windows, while Windows has not yet mounted that volume itself, which is very handy.  So it's unique.  Actually there are a few other programs that'll do that, but this is my favorite of those that'll do that, and it's just $29.95.  And it also does regular, in-Windows defragging, does a very nice job.  But they don't have a high-resolution display.  You see only kind of like big blocks moving around.  I like to see all the little bits if I'm doing a defrag.



LEO:  Well, that's good.  Thank you.  Oh, there's more?



STEVE:  No, no, no.



LEO:  That's it.



STEVE:  That's it.  Except that one other piece of news that I learned about from, again, my Twitter friends...



LEO:  Hang onto it.



STEVE:  Okay.



LEO:  Because I think, with any luck, Skype is back.



STEVE:  Oh.  Oh, my goodness.  That's so much better.



LEO:  All right.  So one more thing.



STEVE:  Yes.  So it's funny because I thought you were going to say, okay, hold on a second, we're going to hear from our sponsors before we...



LEO:  No, actually we want to hear from Skype.  So by the way, suddenly it's like "The Wizard of Oz," where we went from black-and-white to color.  Skype has now started working, and so Steve is back on Skype.  And this just really underscores the quality of a Skype connection, if you're feeding it with good mics and good cameras and all of that.



STEVE:  Yeah, baby.



LEO:  Yeah, baby.



STEVE:  Okay.  So thanks again to the great group of people, who are keeping an eye out for interesting things, on Twitter.  Did you hear about the SSL keys being released through this group called the Little Black Box?



LEO:  Unh-unh.



STEVE:  Okay.  Get this.  If you think about it, any device, any embedded device like our Linksys, Cisco, D-Link, whatever routers, and even something that provides SSL VPN, they need to have a private key.  And the private key, that is, in order to do an SSL connection, just as we've talked about how servers have their private SSL key, and then their public one is in the certificate which they offer in order to establish a connection.  Well, embedded devices have to have private SSL keys also.  And this has long been known as a potential vulnerability, which no one has so far taken really good advantage of.  But the SSL key is embedded in the firmware, and the firmware is downloadable, which means the keys can be found.  Which means that SSL in the case of our embedded devices is not secure.  It can't be.  Because the thing, the sole thing you have to do is keep your private key private, which is arguably impossible to do in an embedded device.



Now, it's not such a problem, for example, for our routers, because hopefully everyone has remote administration shut down on their router, so that there's no WAN-side access to their administrative interface.  And even if they did, we would hope they've by now changed the username and password and made them very strong, if for some reason they did need to leave open WAN-side access.  So the only time you would probably be establishing an SSL connection to your router, if you even bothered to, is over your own LAN, when you were using your browser to connect to it over standard SSL port 80 to the router.



But there now exists this database of more than 2,000 private SSL keys.  What they've done that makes it special is that they have associated the private keys with the public keys and made it searchable.  If you go to code.google.com/p/littleblackbox, that's where this project lives, code.google.com/p/littleblackbox.  All you have to do is you can give this code that's been written the path to any of these embedded devices' public certificate file, and it will find the public certificate, use that to look up the private certificate, the private key.  Or you can give it the SHA-1 hash of the public certificate, which is a way that public certificates are fingerprinted and communicated.  Or you can give it a pcap, for example, a Wireshark or WinPcap file of the capture of data, and it will look for the public certificate in the exchange.  Or you can give it access to the live network interface, and it will listen for the public certificate exchange.



Basically, what these guys have done is they've made it extremely easy to, I mean, it could hardly be any easier to find the private key, to look up the private key, given the public key, during any SSL exchange with up to 2,000 embedded devices and routers and SSL VPNs.  Many, for example, DD-WRT has a VPN version.  It's been possible in the past.  There have been databases like this.  But in order to do it you needed to know, for example, the specific device, the model, the vendor, the firmware version, sub-version and so forth.  And then you would need to, like, do a lot of this dirty work yourself.



Well, this has made it far easier.  We haven't really seen any exploit of this yet.  And again, I don't want to worry people needlessly, that is, this isn't the end of the world as we know it because, again, all this would allow you to do would be to, in the case of an embedded device, to potentially eavesdrop on or perform an effective man-in-the-middle attack.  I do think we're going to be talking about this in the future because I can imagine ways that this information could be leveraged further, for example, in the case of VPNs, which are depending upon a key which is static.



Now, from the standpoint of fixing this, this needs to be fixed in the long term.  As you can imagine, Leo, this is not a good thing.  What it means is that part of the installation of an embedded device which doesn't exist today would be generating its own unique key pair.  That is, there is no reason why every Linksys router of a certain firmware version needs to be using the same essentially asymmetric key pair, a private and a public key.  The technology exists for those to be generated on the fly.  But no one bothers with it yet.



I can foresee a point in the future where there will be an option, probably in the UI, of routers where you can press a button, and it will no doubt take a while, especially on the underpowered processing chips that typical embedded devices have.  But it's something I imagine we're going to be seeing before long because it's really not a good idea for a database to exist containing, I mean, essentially the private credentials of all the embedded devices that we're using.  And that exists now.



LEO:  No kidding.



STEVE:  And it's easy to use.



LEO:  It's almost like rainbow tables.  Or no?



STEVE:  It's very much like that, actually, yeah.  A rainbow table, of course, is where hashes have been precomputed.  Here the idea is that even though it's been known that embedded devices had private keys, it wasn't easy to get them.  You had to, literally, you had to have high motivation for getting the private key.  Now it's trivial because the public key, I mean, the whole point of an asymmetric key is that the public key is in the certificate that is exchanged during the beginning of an SSL connection.  And all of the crypto security comes from the fact that from the public key you cannot in any reasonable amount of time determine the private key.  Except the private key is in the firmware.  It's embedded in it.  And so, if there's a database where you could now look up the private key from the public key, just because someone went and did that work once of extracting...



LEO:  That's a lot of work, though.



STEVE:  ...the private key - yeah, but we've got a lot of little people out there running around.



LEO:  Yeah.  So obviously there was some board somewhere where they said, hey, run this program and give us what you get.



STEVE:  And more are being added to the database on an ongoing basis.  In fact, part of this Little Black Box project has a means for people to submit new public and private key pairs...



LEO:  Oh, I see.



STEVE:  ...that have been found.  And more than 2,000 already.  If you look, everything you've ever seen is already listed in this database.  So that's not good.



LEO:  Hmm.  Interesting.



STEVE:  Yeah.  Following up on last week's mention of, in the Q&A, of ShopShield, which was one of these credit card replacement deals, I told people that I had had no chance then to do any vetting of it to see what I thought about it and to check into it further.  Well, I feel a little bit mixed.  It's not inexpensive.  It's $10 a month or $100 per year to use this, which is a little daunting.  They do have a pay-as-you-go variant where it's $2 per generation of a temporary credit card.  And if I were going to use it, that's probably what I would do.  For example, if I was ordering something from someone that just seemed really sketchy, where I really, I mean, like, they didn't offer any referral to PayPal or Google Checkout; if I had no choice but to give a sketchy site my credit card information, I mean, whereas otherwise I would probably just not buy from them, but if it's something I really wanted and they were the only people that had it, and I had to give them my credit card number, this is somewhere where it's worth $2 to me to run it through this ShopShield as a third party.



Am I willing to pay $10 a month?  Well, to me, I'm not sure how much I would use it.  So that's a tradeoff that I'd have to think about.  It seems like a lot of money.  I wish it was less.  And they, in general, they're clearly trying to monetize the service that they're offering.  They offer the ability, for example, to create a one-time email connection where you give somebody an email link, and then that email is bounced to you, using them as an anonymizing service.  And that's a dollar.  It's like, oh, come on.  I mean, that seems really outrageously expensive for how simple it is to do.  So I wanted to follow up on that.  I'm less excited than I was hoping I was going to be after looking at all of the gory details.



And you'll remember also in errata that I mentioned that one of our questioners from last week, Nick in Thief River Falls, mentioned that Chrome does have side tabs.  And you went looking for them, presumably using Chrome for Mac last week, and you didn't see that option.  It's not there in Chrome for Mac.



LEO:  Oh.



STEVE:  Only Chrome for Windows.



LEO:  Oh, rats.



STEVE:  I don't know why.  But I went looking for it, too.



LEO:  Yeah.  I didn't see it, and now I know why.  All right.



STEVE:  Yes.  It's not there, unfortunately.



LEO:  But it's a nice feature, and I'm sure they'll add it eventually.



STEVE:  That would be great.  It is very nice to have tabs running down the left-hand side.  I like it a lot.  And then I just wanted to mention a listener of ours, John Newcomb, who had a nice experience with SpinRite.  He said, "Dear Steve, just wanted" - actually a nice thing to say about us, too.  Funny in this context of this horrible first half of the show.  He said, "Dear Steve, just wanted to tell you how much I appreciate you for all the great info I get from your podcast with Leo Laporte.  You have such a wonderful radio personality.  And with Leo, you guys are a great team.



"I recently bought a copy of SpinRite that I have added to my bag of tricks.  I'm a computer tech and work for a company who serves the dental industry.  SpinRite has already saved me a lot of time.  I was in an office the other day working on a machine that would not fully boot Windows.  I ran SpinRite, and it recovered several bad sectors, which allowed me to then image the drive and install a new one.  Thank you for making my job easier.  Your software works so well; and, using it and observing all the little details you took care of, I think it's clear how much care you put into it.  Sincerely, John Newcomb, Oakland, California."  So thanks very much for the update, John.



LEO:  Very cool.  We're going to take a break, come back with Bluetooth security.



STEVE:  Yes, how Bluetooth operates.



LEO:  I love that.  Steve, I'm ready to talk Bluetooth.  I use Bluetooth all the time.  I've got my Bluetooth headset on.  My Ford SYNC is using Bluetooth.  I use it on stereo headphones.  And so I'm very concerned.  How secure is it?



STEVE:  Well, and for me, I use it in tethering mode with my Blackberry when I'm away from WiFi.



LEO:  Right.



STEVE:  It's a great solution.  I have the MiFi from Verizon, but that's just one more thing you've got to pay $69 a month for.  And if you have a phone which is tethering-capable - I guess the iPhone is still not?  Is that the case?



LEO:  No, it is now.  It's always been in Europe.  And I believe you now can do it.  AT&T allowed it on the iPhone 4.



STEVE:  Okay.  So there you would be - does it tether with Bluetooth or with WiFi?



LEO:  Now you're asking me - I think it's - pretty sure it's Bluetooth.  But I don't know.  No, maybe it's just USB.  I don't know.  That's a good question.  



STEVE:  Anyway, so in my case...



LEO:  I never use it.  But on the other hand, I am using Bluetooth tethering all the time on my Android phones.  And so that's another security, I didn't even consider that, another security issue.  Yeah.



STEVE:  Yup, I was just going to say that, Bluetooth on Android.  So the technology bears the horrible age of about a decade.  When you look at it closely, first of all, this came from Ericsson, Ericsson before they became Sony Ericsson, and Sony bought the Ericsson phone line.  Ten years ago, actually I think it was in '99, so almost 11 or 12 years ago, Ericsson wanted a new technology that would allow them to link their phones to peripherals like wireless headsets, for example.  And the good news is that they really understood and appreciated the need for security.  The name Bluetooth actually comes from some Danish king who was Harald Bluetooth, who consolidated Denmark, and I guess part of Norway, back on the early 900s.



LEO:  United Scandinavia, and so this is a uniting technology.



STEVE:  Exactly.  That was the goal.  And in fact the logo...



LEO:  That's what Ericsson says, anyway.  I don't know if it's true.



STEVE:  Yeah.  The logo, apparently in whatever wacky language they had, HB, Harald Bluetooth, in some language is something that looks like an asterisk, and then something that looks like a "B."  And so that's actually, that's where that logo came from, where it's that sort of that pointy, looped "B" with funky little lines coming out the back side.  Actually, if you look at it, you can sort of see an asterisk embedded with a "B."  And so that was the source of the logo.  So they introduced this in '94, after a couple years of work.  And then about four years later Ericsson was joined by Nokia, IBM, Toshiba, and Intel to form the so-called Bluetooth SIG.  They were the original members of the SIG.  And now it's literally thousands of companies.



The spec started off a little rough because it is, as I said, it shows its age.  It is just a disaster of a protocol.  If you sat somebody down with the spec - which by the way is 1,200 pages, I mean, it's like the U.S. tax code - if you sat them down with it, there is absolutely no chance at all that they could produce something that worked with anything else.  Their stuff would work with their own stuff, but there's no chance they would have interoperability.  And not surprisingly, that was the big problem with Bluetooth in the beginning was that people would implement their Bluetooth technology, and they wouldn't be able to connect with anything else.  They could work with their own stuff, but not anybody else's equipment.



So over the years there has been a code base, essentially, that has been refined and is available to people who want to implement Bluetooth, that basically is more useful than the spec.  The specification is just - it's horrendous.  People who have used Bluetooth are aware that it's not something that you have to configure.  So the goal, Ericsson's goal, this was going to be a consumer network, something where these things could somehow find each other in a process called "discovery," and just interoperate.  However, they also wanted it to be secure.



So what they did was they created this notion of pairing, where you pair two Bluetooth-enabled things through some sort of an easy-to-use process.  Devices may or may not have screens.  They may or may not have keyboards.  It could be, for example, just speakers, where it's somehow going to just work.  Yet you still want there to be this pairing process.  So what Ericsson worked out is this notion of a device being discoverable, which if you've got a user interface that is on your device, you can typically turn that on and off.



One of the most important things to do in security with Bluetooth is have your device not be discoverable by default.  That is, you only want it to be discoverable during the period of time that two devices need to literally discover each other because having it be discoverable begins to open it up to some security problems.  Mostly they're implementation problems of the particular vendor that has put things together.  And the history of Bluetooth security has been compared to other histories of security relatively okay.  We'll talk in a couple weeks about where this has not been okay.  But the number one problem, the chief source of trouble has been that people have left their devices in a discoverable mode rather than not.



LEO:  We've talked about that many times before.



STEVE:  Yes, yes.  And in fact...



LEO:  I think we did a TV segment on it.



STEVE:  We did.  And in fact turning on a Bluetooth device - we were in Vancouver at that point.



LEO:  Right, right.



STEVE:  And there was like, everybody had their phones were discoverable.



LEO:  Now, by the way, I should point out, that was a couple of years ago.  And I think it's changed completely.



STEVE:  Yes.



LEO:  Most phones default to not discoverable.



STEVE:  Yes.  And the really nice thing is if the UI won't allow them to stay that way.  There's no reason that it ought to be like you set it to discoverable and leave it.  It ought to be, I'm going to do some pairing, so press this button, and I've got five minutes, and then it's going to turn off.  And so what that pairing mode would be, would be Bluetooth discoverability would be on.  Now, what this means is that the device responds essentially to an inquiry message in the Bluetooth protocol.  So one of the concerns has been that, even without being paired, your devices are part of anyone's Bluetooth network that has a Bluetooth device on.  So there's sort of an inherent low level of promiscuity happening between all Bluetooth devices, all the time.



So the other thing I would recommend and do is turn off Bluetooth completely, if it's not inconvenient to do so.  For example, I've got Bluetooth on my Blackberry.  It's off all the time.  Not only is discoverability off, but the Bluetooth radio is off.  And that's the case with my laptop, which is the thing that I would normally connect my Blackberry to, if I wanted to get on the 'Net when I was not near WiFi.  So, and that also has the advantage of saving some power because the Bluetooth radio, although the Bluetooth technology is very lean in terms of power consumption, it's not zero power consumption.  So if you want your handset, your handheld to run longer, and if you're not actively using Bluetooth, and if you're not going to, like, use it soon, turn off the radio completely because there's no way to be more secure than not to have it on at all.



So Bluetooth operates under what's called the "unlicensed ISM band," which is 2.4 GHz.  Nominally, it gives us about 10 meters of range.  So think of that as, like, around 30 feet is the distance between two devices which are running what's called "class 1," which is one milliwatt of power.  There is a class 2 and a class 3.  Class 2 devices have 10 times the power and substantially more range.  And then class 3 devices can go at 100 milliwatts and extend up to 10 meters.  So it is the case that, if you have a class 3 device pumping out much more power and with a much more sensitive receiver, that you can't count on that 10-meter range for security because it can be as many as 300 feet, 100 meters.  So you can get some distance out of Bluetooth.  So one of the things people generally fall back on for Bluetooth security is that it is a short-range technology.  It's something that's nice about it, but it's not something that you can count on.  And so it's meant for a so-called PAN, Personal Area Network.  Or also in the Bluetooth spec they refer to it as a "piconet," very small little networks.



LEO:  Yeah, that makes sense.



STEVE:  So every Bluetooth device has something that's exactly analogous to a MAC address on Ethernet adapters.  We've talked about MAC addresses, how they are - a MAC address is 48 bits, where 24 bits is assigned to a manufacturer, and another 24 bits is a serial number of that manufacturer, so that the concatenation of those two 24-bit pieces, in the case of an Ethernet MAC address, will be unique.



We have exactly the same thing, a 48-bit unique device ID for every single Bluetooth device.  So no two of them are the same.  So that gives us a six-byte address which will be unique.  When the two devices are paired during this initial handshaking pairing agreement, they exchange their 48-bit identities, and they also agree upon during this pairing a 128-bit key.  So that's the thing which is agreed upon during pairing and stored in each of their databases because anyone who's used Bluetooth will be aware of the idea that you pair once, then the devices are known to each other and do not need to go through this pairing process again.  The spec also allows for a 248-character, user-assignable name.



And, for example, I think I called my Blackberry a "Crackberry" when I was setting it up, and I noticed that when I was pairing with my laptop, it said, oh, I've just found Steve's Crackberry.  Is that the device that you want to pair with?  It's like, yep, that's the one.  So that's a user-assignable string just for your own human recognition purposes when you are trying to identify the device to help you find it.



So this pairing database contains the 128-bit key, which is arrived at randomly; and the 48-bit device ID of the associated device; and this 248, up to 248 character, although normally user interfaces that you work with will limit you to something much shorter.  But it's long enough for you to convey your meaning to identify what that device is.  There's that triplet which is established for each Bluetooth device.  There is a sort of a range of pairing authentication from none to extreme, based on a so-called PIN.  And I'm sure Leo, for example, if you've paired something before, some devices just have like a default of 0000.



LEO:  Right.  That would be none.



STEVE:  Which is to say, exactly.



LEO:  No security, yeah.



STEVE:  No security.  The idea of the PIN is that you want something, the only time where there is known protocol vulnerability - meaning a vulnerability that the spec understands, not a vulnerability because of a mistake made in the protocol, where crypto guys are going to attack this thing, but an understandable man in the middle, we know we have a problem at this particular moment that's during pairing because you have two devices that don't know each other, and you need some means of authentication.



We've often talked about how authentication is the only way that you can theoretically solve a man-in-the-middle problem is if each end is able to somehow authenticate.  If you don't have that, then there's no way of knowing that there wasn't a third party that inserted themselves in the middle where you're mistakenly authenticating with that third party, that is, each endpoint is authenticating with that third party, which has now successfully managed to negotiate itself a role in the middle.  So what you absolutely have to have is something out of band, "out of band" meaning some channel of information not in the band, not in the same stream as the rest of the protocol.



And that's what the PIN provides.  It provides something that you, the user, can provide to each end that no man in the middle could know.  And so the most robust thing would be a long, unique passphrase which you would type into each endpoint.  In that case, that would be merged into their pairing protocol, and no man in the middle would know what that was because they're seeing the result of it after encryption.  And only when the other side sees that the other side obviously knows the same passphrase, is pairing achieved.



The problem is, with a little headset or speakers or something, you don't have that user interface.  So there is this notion of, well, we're going to do the best job we can with pairing, given the limitations.  But the good news is you probably care much less about a man-in-the-middle attack on your headset, your Bluetooth headset, than I do, for example, when I'm pairing my phone to my laptop, and I want to absolutely make sure that no bad guy is interposing themselves in between my connection, my laptop's connection to the Internet.  So I want to stress, though, that the vulnerability that exists, to the degree that it exists, is only during that moment of pairing.  So, for example, if you went out into the desert, or you went into a large parking lot where you knew, you could visually see that there was no one close to you, if you were really paranoid, to perform your pairing, then once that's done, both sides have this 128-bit key which is plenty of strength, as we'll see, in their pairing database.  And then that process never needs to be done again.



So there's this short window of opportunity at the moment of pairing, where the vulnerability is only a function of whether you have the ability to provide information that anyone listening could not have.  So, for example, sometimes, if you are pairing your keyboard to a computer, the keyboard doesn't have a display, but your computer does.  So the computer can say, oh, good.  I see that you're trying to pair this keyboard to me.  Type the following into the keyboard.  So your computer is able to give you a nice long passphrase.  Normally what we're seeing is six characters because there's been a sort of an agreed-upon spec that says one in a million is enough.  Six decimal characters gives us 000000 to 999999.  One in a million chances of guessing that.



LEO:  Especially in such a short period of time.



STEVE:  Exactly.



LEO:  You can't brute-force it because it's over in seconds.



STEVE:  Exactly.  And there is, in the spec, is an exponential delay in failed attempts, so that it doubles for every failed attempt.  And so it quickly becomes impossible to brute-force this.  And as you said, you've got devices that are, like, saying, I'm sorry, we either succeeded or failed in the pairing.



LEO:  Yeah.  Most of these devices don't give you an infinite amount of time to try.



STEVE:  Exactly.  And so if you have a computer with a screen, you're able to type in, you type into the keyboard, which has no display, the sequence that the computer prompted you.  So in that way you have established out-of-band communications.  The weakest pairing is with something that has absolutely, it's got no keyboard, it's got no user interface.  And there you may be paired with another device that says, well, what's the PIN for this device?  And it's just, by agreement, it's 0000.  Well, so anybody could know that.  Anybody, technically, if they were listening right at that moment, was very good with radio and had the ability to intercept this communication, they could do so.  But that's the only known vulnerability in the protocol.



And it's a tradeoff that I think is entirely reasonable, Leo, as you said.  In the case of a keyboard, you can type in a long passphrase.  Between two more sophisticated devices you can do something even longer.  So it ended up being, from a consumer standpoint, an efficient and useful protocol, and I think a nice set of tradeoffs.  So once the devices have established their pairing relationship, they use an interference avoidance technology known as "frequency hopping."



In any group of Bluetooth devices, or the so-called piconets, you can have up to eight devices in a single piconet.  So, that is, you could have eight devices that are sort of essentially connected together.  One is always a master, and then you can have up to seven slaves.  A device can be a master of one piconet and a slave of another, or it can be a slave in multiple piconets.  But no device can be two masters at the same time.  This notion of a master is established because that MAC address, which is the Bluetooth address, that 48 bits, that's known, by virtue of this pairing, to every device that the master is paired with.  And that 48-bit MAC address provides the pseudorandom sequence for frequency hopping.



So the way any kind of interference is avoided is that, within this 2.4 GHz band, there's a large number of individual channels.  And the master and all of the slaves that are in the same piconet, and it's typically just two, you'd normally just have two devices that are paired together, but the spec allows for eight.  The master establishes the clock and, using its own address, and the slaves using their knowledge of the master's address and using the clock which is publicly transmitted, that allows them to do frequency hopping where they're constantly changing the frequency they operate at.



That's done not as much for avoiding bad guys, but for avoiding interference because you may have - turns out that this unlicensed frequency range, this 2.4 GHz, is very popular.  Wireless phones, like older wireless handset phones used in homes, all kinds of devices and instrumentation use this because it's a block of frequencies in this band that were set aside so that you needed no license to use it, given that you keep power at or below 100 milliwatts.



So the problem is that you may have, if we stayed on a single frequency, there might be something interfering on that one frequency.  So the idea is that we do this frequency hopping so that we're avoiding any interference.  And the later specifications have added something called "adaptive frequency hopping" where all of the devices will recognize when there's interference and avoid, while they're hopping, avoid channels that may be congested in order to improve the reliability of all this.  The data rate is nominally, the original Bluetooth spec nominally one megabit per second.  But there's enough overhead that we lose about 25 percent of that.  So you actually get about 721 kbits per second of actual throughput.



But then later on so-called EDR, Enhanced Data Rate technology, was added.  Where we used to send a single frequency-modulated signal, they added something called "phase modulation" to the actual - down at the RF level, at the radio level.  So they were able to, instead of sending a single symbol, they were able to send two or three.  And so the later technology is able to run at three megabits per second, so we get an effective data of 2.1 megabits per second through the whole technology.



Now, the final piece of concern, and it is concern, is the actual crypto.  Being 10 years ago, we did not have AES.  RC4 existed, but it was still patent-encumbered.  So Ericsson did the unfortunate thing of making up their own.  And everyone who...



LEO:  As we know, that's a bad idea.



STEVE:  Everyone listening is now going, oh, no.



LEO:  Why, why, why?



STEVE:  It's a bad idea.  The good news is they used a - okay, I don't know how to describe this.  I'll just describe it.  I don't know how to characterize it.



LEO:  Okay.



STEVE:  It's bad.  It hasn't been penetrated, but it can only be because no one has really tried that hard because there isn't anything really that valuable typically transiting a Bluetooth connection.  After all, if you're talking in your car, well, the only one who can really intercept your communication is in the car with you because you're in a steel-enclosed container, and you've got a weak radio signal at a milliwatt, which has a distance of about 10 meters.  And besides, they can hear what you're saying, so there's no need to intercept it because it's carrying...



LEO:  That's a good point.



STEVE:  It's carrying the audio that anybody with ears can hear.  So typically it's low-value stuff.  But the technology uses a pseudorandom sequence generator.  Now, that's not bad because that's what RC4, after all, is.  So you can have...



LEO:  That's all we have, really, right, is pseudorandom.



STEVE:  Yes, exactly.  Well, no.



LEO:  I mean, computers...



STEVE:  Block ciphers like AES, where you're taking and mapping 128 bits into a different 128 bits, that provides a keyed transform of a block of 128 bits into another.  But the stream ciphers, like RC4, can be very good.  I was just saying last week, and I mentioned at the top of this show, that Skype is using RC4 right now.  We're talking over RC4-based encryption.  And nothing can crack it because it's done right.  I'm not so sure nothing can crack this one.  What they did was - now, again, 10 years ago, so I forgive them, they needed something that would be low power, that is, low compute power, that could be easily implemented in hardware, even hardware-assisted software, or maybe even largely in hardware, like in a chip, instead of having a processor that's being driven by firmware.



So they used shift registers, which is never a good place to start.  There's something called LFSRs, Linear Feedback Shift Registers.  The idea is you use - a shift register is, think of it as a string of bits that shift in one direction so that there's an input, think of it on the left, and every time this is clocked, all the bits in the shift register move one to the right.  So bits that go in come out the other end the number of clock pulses later that this thing is long.  So if you had an eight-bit shift register, the bits would come in, and eight bits later they would come out.



Well, there is a technique for generating pseudorandom streams where you take multiple taps, it's called "taps" on the shift register, where you've got this string of bits, and then you look at maybe three of them, three specifically located bits, and you XOR all those together, along with the output.  And the result of that is what you feed back into the input.  So what this means is that this will, as the bits are shifted along, the bits, which are ones or zeroes, in the particular points where the shift register is tapped, they determine the next bit being shifted in.



Now, in fact, this uses four of these linear feedback shift registers with lengths of 25, 31, 33, and 39 bits, respectively.  If you add those together, 25 plus 31 plus 33 plus 39, you get 128.  Which is not a coincidence, obviously.  The idea is that the key that is being used to key this is dumped into the shift registers.  So you have a number of problems.  For example, if a shift register had zero in it, say it was all zeroes, well, if you tap it three times, and then take the output and XOR those together, you're going to get zero.  So if you feed a zero in, the shift register's never going to have anything other than zero, so it's a degenerate case.  So you've got problems with, like, looping in the shift register where you might end up with a certain combination of bits that don't generate much randomness in there.



So to deal with that problem they take the four outputs from the four shift registers and feed them into another random-looking blob of logic.  I mean, I've looked at all this, and I remember thinking, oh, this really doesn't look good.  Again, this is the kind of thing where the engineers 10 years ago said, look how confusing this is.  Nobody will ever figure this out.  I mean, that's where bad crypto comes from is from that kind of idea.  It's like, oh, this is so one-way engineered that nobody will ever be able to reverse-engineer this.



Well, again, I'm sure that it's because real crypto people have never really tried very hard.  For example, this is frighteningly like the GSM - GSM cellular?  And maybe it's not surprising because Ericsson was involved in that, too.  GSM uses four linear feedback shift registers, and it's been cracked because the feeling was there's more value in cracking cellular, digital cellular, than in digital Bluetooth.  So this is different.  It's been a concern.  My sense is, again, it's good enough for what Bluetooth is used for, which is generally low value.



Now, again, because one of the things that makes me so uncomfortable from a crypto standpoint is they keep making it more complex, rather than it being elegant.  This is the least elegant cipher system I've ever seen because, once they have that mechanism, then the key, the crypto key is derived from the secret key which was negotiated from the key that they originally shared.  I mean, there were good things they did.  For example, this 128-bit key that they agree upon during pairing is never itself used for any crypto operations, which is what you want.  You don't ever want to use that key itself.  You only want to use derived keys.



So they derive keys based on random numbers that they generate, and based on a shared random number which is publicly transmitted, and based on the 48-bit master's device address and 26 bits of the master device's real-time clock, which is incremented for each time slot.  So that means that every one of these time slots, as we hop around in frequencies, and as packets are occupying time slots, are being keyed differently.  So that's good.  That means that, horrible as this cipher kludge is, we're never using it for long.  That is to say, every single packet has a different key.  But that mess of data which is munged down to make the key is then loaded into these four linear feedback shift registers and this other finite state machine which they hang on the end of it, just like to determine what goes into the inputs because otherwise they're not stable enough.  It's then run forward 200 clocks.  And the last 128 bits to come out of it is used as the key.



So this tells you that the engineers were never really sure that this was secure, so they just kept adding stuff to it, like this wacky, run it 200 times to kind of get it warmed up.  And then we have no idea what the last 128 bits are going to be that come out, so we'll use those.



LEO:  It's like chitty-chitty-bang-bang.



STEVE:  It is.  It is just atrocious.  And now you can imagine why nobody working on their own who had the spec for this could ever make it work with anybody else's equipment because they'd get an inverter stuck in there wrong somewhere, or it'd be 201 clocks, or it'd be the even phase versus the odd phase, or, I mean, anything could go wrong with this to break it.  And you would never know.  I mean, it's just this bizarre Rube Goldberg contraption that generates, finally it generates, a stream of ones and zeroes finally emerge, confused and dizzy, out of the other end of this thing.  And that you XOR with your plaintext in order to create ciphertext.



LEO:  I love it.



STEVE:  Somehow we're able to hear you on your wireless headset, Leo.



LEO:  Amazing.



STEVE:  It's a miracle.  So that's how Bluetooth works.  That's the technology, the crypto, the pairing.  The takeaway is, never leave things discoverable; and, moreover, never leave your Bluetooth radio on if you don't want it to be.  And in a couple of weeks we're going to come back and talk about bluejacking, bluesnarfing, bluebugging, and all the things that people have cleverly come up with to subvert this system that we've just described.  And that will wrap up our coverage of Bluetooth security.



LEO:  Next week we'll answer your questions.  Actually next week we will not answer your questions.  Next week we will be...



STEVE:  We will entertain you.



LEO:  We will entertain you.  We'll have a best-of because, for the first time in memory, first time ever in six years, Steve is allowing me to force him to take a week off for the holidays.  And we will have a best-of which will be, in its entirety, the classic Portable Dog Killer episode.  And but we'll be back in two weeks, which will be Episode 282, so we'll be back on the even-numbered questioning system.



STEVE:  Yes.



LEO:  And if you have a question, GRC.com/feedback is the place to go.  Also, while you're there, get a copy of SpinRite, for crying out loud.  Make that your Christmas gift to yourself.



STEVE:  Oh, and it'd be a Christmas gift for me, too.



LEO:  And for Steve.  Make that yabba-dabba-do go off in his office.  GRC.com.  SpinRite is the world's greatest hard-drive maintenance utility.  You've got to have it.  We just had a hard drive die, and I wanted to get it SpinRited immediately because it just - it works so well.  You can also find a lot of free stuff there, including all of his free security tools.  ShieldsUP! is the best known, but there are many others there, and his DNS Benchmark.  Steve, you're the greatest.  And of course 16KB and transcriptions of each and every show, including this one.  I will snarf you next year, Steve.



STEVE:  Cool.  And you're going to Pogoplug me?



LEO:  I'll Pogoplug you, as well.



STEVE:  And we'll say Merry Christmas to our listeners, and we won't see everyone, but we'll be talking to everyone in 2011.



LEO:  Happy New Year.  We'll see you next year on Security Now!.  Bye bye, Steve.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#281

DATE:		December 30, 2010

TITLE:		The Portable Dog Killer

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-281.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  In commemoration of the 50th anniversary of the invention of the LASER, this week Steve is going to relate a story from his own past, 39 years ago, containing a strong moral about the importance of getting out from behind the video game screen and actually building something.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Special Christmas Holiday Episode 281 for December 30, 2010:  The Portable Dog Killer.



It's time for Security Now!, the show that covers everything you need to know about keeping yourself safe, secure, and private online.  Who better to do that than the man who discovered spyware, coined the term, wrote the first antispyware program?  He's been a security maven for years, the author of SpinRite, the world's best hard drive utility, Mr. Steve Gibson of GRC.com.  Steve.



STEVE GIBSON:  Hey, Leo.



LEO:  Good to see you.



STEVE:  Great to be with you again, as always.  We have today a very different episode, one that I really do believe our listeners are going to get a big kick out of, something I've never done before.  A number of - there's sort of a confluence of things that came together.  This is, actually this coming Sunday, May 16th, is the 50th anniversary of the invention of the laser.



LEO:  Whoa.



STEVE:  First time that it was done practically.  Einstein gave us the fundamental theory back in 1917, which predicted that you could stimulate the emission of radiation, which is what the SER of LASER stands for, that you could stimulate the emission of radiation from molecules.  But it wasn't until many years later, and May 16, 1960 was the day that some researchers at Hughes first made a laser lase.  There was a MASER beforehand, a Microwave Amplification through Stimulated Emission of Radiation, but never super high frequency, which is to say Light Amplification through Stimulated Emission of Radiation.  Anyway, the show is not about lasers.  This is about something I did when I was 16 years old.



LEO:  Oh.



STEVE:  That was sort of related.  The episode is called - this episode is called "The Portable Dog Killer."



LEO:  Oh, god, I can't wait [laughing].



STEVE:  Which I'm going to explain, of course.  But the anniversary of the laser got me thinking about this.



LEO:  Okay, I'm ready for the story of the dog that ate the laser, or whatever that is.



STEVE:  Okay.  Well, so it's 1971, and I'm 16 years old, a sophomore in high school.  And we had a real problem with a dog in the neighborhood.  I don't know if this dog was clinically rabid or what its problem was.  But it was about two blocks away from where I lived.  And the people who owned this dog had sort of an RV trailer or something parked in the backyard, and a fence which went right up to the sidewalk which contained, not only this RV, but this unbelievably vicious dog.  And so the fence had a gate where sort of this driveway was, right onto the road.  But this was not, like, their main garage entrance.  And the fence, the two wings of this gate were pinned just at the bottom, so that it was sort of flapping open if there was any pressure on it.



So what would happen was, for I don't even know how long this was going on, but, I mean, it was a serious problem, people walking by the sidewalk would virtually be attacked by this amazingly vicious dog.  I'm a dog person.  I grew up with dogs.  I love dogs.  Actually at the time of this going on I had a redhead cocker spaniel.  And so this dog was just unbelievable.  It would scare the bejeezus out of people because they'd be walking on the sidewalk, and this thing would hear them and come galloping through the backyard and lunge at the top of this gate, which looked like it was about to spring open.



And, I mean, and the dog, I think it was a German shepherd, I can't quite remember the breed now, but, I mean, it was big.  And, I mean, the owners, I don't know what could have been in their mind.  They must have known this was a problem.  They must have been getting complaints from people.  But times were different then.  Dogs were not on leashes.  Kids were not on leashes.  I mean, dogs roamed the streets.  Times were, as I said, this was 39 years ago.  But finally one day, as I was coming around my block, there was this elderly lady - and this all happened in San Mateo, up in Northern California, which is where I was in junior high and high school.  And this dog scared this elderly lady so much that she tripped and fell off the sidewalk into the street.  I mean, it was that big a problem.  It was just unbelievable.



And so I thought, okay.  I need to take matters into my own hands.  This dog needs some training that this is not okay to rush people and lunge at the gate and look like it's about to jump over the gate.  And the gate looks itself like it's about to give way because it's only pinned at the bottom and wasn't closed at the top.  So I thought, in order to train this aberrant canine, I need to do something that will shock it, something - give it an experience which is negative which is completely outside of its normal daily experience.  So I thought, I need some sort of a sonic, loud sonic weapon.  So...



LEO:  Oh, Steve [laughing].  I can see where this is going.



STEVE:  Oh, this - actually this has unforeseen consequences, which is part of the moral of this story.



LEO:  The case of the aberrant canine.



STEVE:  So my parents were divorced at the time, my father and his wife living up in the city, in San Francisco.  So my sister and I would jump on the train Friday afternoons and take it up to San Francisco, and then the trolleys over to the marina on the other side of the city, where Dad and his wife were.  And then Saturday mornings was sort of free-for-all time.  Basically, it was "Kids, get out of the house.  Go play."  I mean, as I said, times were different 40 years ago.  And one of my favorite areas in the city was Mission Street.  It was a couple blocks out of the city from Market.  That's one of the main - like Market Street's the main drag.  And back then Mission Street was lined with war surplus stores.



LEO:  I think it still is, actually.



STEVE:  Is it still?



LEO:  Yeah, I think there's a bunch of Army surplus stores down there, yeah.



STEVE:  Okay.  And so I was hacking when I was five.  In fact, on my rsum page there's a picture of me that Dad took before I was five years old, in the backyard building something with wiring circuits and things.  I mean, I just had this drive from forever.  So for me, I would just - I could spend hours in these war surplus stores.  I mean, radar sets, dynamometers, all just - it was like nirvana for me.  But this particular weekend I was on a mission because I had to build some sort of a sonic beam weapon in order to deal with this dog.  So...



LEO:  [Laughing] Was there no parental supervision at all?



STEVE:  None at all.



LEO:  No.



STEVE:  No, they'd given up.



LEO:  Yeah.



STEVE:  I'd beat them to - beat them senseless.



LEO:  That's just Steve.



STEVE:  They knew I was a good kid.  They knew I was not going to get them into any real trouble.



LEO:  No, right.



STEVE:  I mean, the Boy Scouts of America might disagree with that, but that's a story for a different time.



LEO:  I mean, most parents, if they heard the phrase "sonic weapon," "military surplus store," and "dog," might exhibit some concern.



STEVE:  Yeah.  Mom just said, "Okay, I don't know what you're doing, just don't kill yourself."  So I found the pieces I needed.  I don't know if it was over one week or several visits.  But I found this amazing, like, grip from like maybe a helicopter trigger handle or something.  But, I mean, it was a gun grip with a switch in it.  Which was like, okay, perfect.  And I needed a transducer, some sort of a high-frequency, high-powered transducer.  And rummaging around in these bins with my sister sort of in tow - she's two years younger than me, so she was 14 and just sort of following big brother around - I found some sort of a piezo - it was in like a black steel casing, a piezoelectric crystal with a pointed silver dome.  And I said, oh, that looks like the right kind of thing.  So, and none of this cost anything.  It was 50 cents for this, two bucks for something else.  And so I got those things.  I also found just a perfect photoflash parabolic reflector that at the widest part it was probably about maybe 10 inches in diameter.  



LEO:  This is very Tom Swift here.



STEVE:  Oh, this, I mean, this is what happened.  And so, like, then I needed a body for it.  And in San Mateo down on 42nd Avenue was, like, a real electronics store.  Not like a Radio Shack that was just kind of cheesy.  This was 42nd Avenue Electronics.  And so I found a steel little mini box to - I think it was, like, two inches by two inches by six - to be the body of the gun.  And then set about building this sonic weapon.  There was a chip at the time called the 555, the NE555.  I think Signetics innovated this thing.  It was this incredibly versatile oscillator.



LEO:  What year was this?



STEVE:  1971.



LEO:  Oh, this is very early in terms of microprocessors, yeah.



STEVE:  Yeah.  Oh, we didn't have those.  No, no, no.  I mean, and my first job was - it might have been this same year, or the year after, with - this is where I encountered the PDP-8 for the first time.



LEO:  Aha, aha.



STEVE:  So I built an oscillator.  And I wanted the frequency to be, I mean, I understood that dogs have very sensitive hearing, and they're able to hear outside of the range that we can, like the classic dog whistle where we blow it, and the dogs perk up.  We sort of hear maybe like air blowing, or maybe we can get a sense of something.  But on the other hand, I didn't want it to be supersonic because I wanted to know if it was working.  So I wanted to be able to hear it, too.  So I pitched it somewhere like around 15 KHz, is my guess, way high, but still audible to us.



And I had a - I remember that I had power settings.  Remember that at this time "Star Trek" was happening.  And so of course they had phasers.  And so I was obviously modeling this on something sort of that I'd seen in science fiction.  So I had, I remember, a knob on the back with - it had four positions:  off, just so you wouldn't hit the trigger by mistake; and then three power settings.  And I had three different colored dots that I got at the stationery store, a green dot, a yellow dot, and a red dot.  And this thing had three nine-volt transistor radio batteries in it.  So the green dot gave it nine volts on the output stage.  The yellow dot was 18 volts, and the red dot was 27 volts, all three batteries ganged in series.



And so I assembled the oscillator, built the output, the power amplifier stage that was transformer coupled to this piezoelectric transducer, and it worked.  Then I built this thing together, you know, mounted the pistol grip on the bottom of the box, this perfect photoflash parabolic mirror on the front, and then positioned the transducer in the focus of the parabolic mirror so that it would work.  And the machine was finished.  Now, back then I was 16.  I called this the "portable dog killer."



LEO:  Not worried too much about SEO, I guess.



STEVE:  Well, exactly.



LEO:  Or police.



STEVE:  And, I mean...



LEO:  Or the ASPCA.



STEVE:  It wasn't that I wanted to kill this dog.  Certainly not.  But the dog would have killed anybody walking by if it could get loose.  I mean, this thing was out of control.  So the name was more inspired by the fact that the dog was the killer than that this was going to do any killing.  I just wanted to teach the pooch that it's not safe any longer to go lunging at passersby.  I mean, literally, the fence was at the edge of the sidewalk.  And, I mean, this was a hazard to public health.  And frankly, I was probably saving the dog's life, or I hoped to, by training it not to do this because sooner or later something horrible was going to happen, and the dog would be put down.  So, I mean, it would just - that dog would be destroyed.



So this thing, oh, my god, it really worked.  Two things I remember about it vividly is I was surprised by how quiet it was off axis.  That is, it really did, this parabolic mirror really did focus the beam of sound that it produced so that it wasn't - it didn't hurt you at all to, like, be behind it, to be the shooter, or even to the side.  But boy, you aimed this at yourself, it was - it made the weirdest sensation.  There was, I think it was probably...



LEO:  You felt it.  You didn't hear it, but you felt it.



STEVE:  Well, there was, like, this - yes.  No, no.  You also heard it.  I mean, it was pitched down low enough that it was, I mean, it was really loud.  But something about the phasing of it with your ears, it made this weird sort of like bone-crunching feeling in the middle of your head.



LEO:  Oh, dear.



STEVE:  It was just strange.  Anyway, I thought, well, this ought to do the trick.  So I snuck up to the gate the first time and did, you know, "Here, doggie," or something to the effect.  And I heard [galloping and roar], as it always did.  And I blasted it in the face pointblank.



LEO:  Ooh.



STEVE:  Now, the dog made...



LEO:  Now, it's not lethal.  We should emphasize.



STEVE:  It's not lethal, no.  And the dog was never hurt.  I mean, it wouldn't hurt ants.  It might make them go around in circles, but it wouldn't hurt them.  The dog's legs collapsed, I mean, they fell out - it fell to the ground and then ran as fast as it possibly could away.  So I thought, okay, round one.  And an hour later I came back and, like, nudged the fence a little bit, and I heard [galloping and roar].  And I blasted it again.  And this went on for a couple hours.



LEO:  [Laughing] Oh, geez.



STEVE:  And then I remember...



LEO:  We are not recommending this.  And we will not - this may not be your first blog post is the plans for this device.



STEVE:  No.  So...



LEO:  I don't want the ASPCA calling me.



STEVE:  Well, like I said, this ended up working out well for the dog, I really believe...



LEO:  Oh, no.  Oh, no.



STEVE:  Because a few hours later I went up to the fence, and the dog didn't attack.  And I will never forget carefully - because, I mean, this thing was really, this would have taken your head off - peeking over the fence.  And there was the dog.  I could see its nose and one eye peering fearfully around the corner of the house.



LEO:  There's something over there, I don't know what it is.



STEVE:  [Laughing] So I was delighted with this.  And I think it took about three days before the first shot of the day wouldn't, like the dog was realizing, okay, this is just not something I'm going to be able to continue doing.  This had been its favorite thing, attacking people, for who knows, I mean, for months or years.  I mean, it was sort of a known problem in the neighborhood.  And it was finally when I saw a block away this poor elderly lady literally blown off the sidewalk...



LEO:  Oh, dear, yeah.



STEVE:  ...I said, okay, this is not okay.  So that was done.  Now, my buddies at school had sort of been aware of the project.  I was telling them what I was doing.



LEO:  Steve, you must have been such a cool kid.  I am - this is so cool.



STEVE:  So they wanted to see this.



LEO:  Sure they did.



STEVE:  So it was, I think, okay, it's show-and-tell day.  So I brought the portable dog killer to high school.  Before first period, the gang had gotten together.  We had what we called the MRC Gang, which was the Math Resource Center.  In other words, this is the...



LEO:  Nerds.  Geeks.



STEVE:  ...geek, this is the nerd group of the high school, a Math Resource Center group.



LEO:  Oh, boy.



STEVE:  And I don't remember which one of us it was, but we had a real problem in the school.  And I need to explain a little bit about the structure of the school, the layout, because this comes into play here in a little bit.  Aragon High School in San Mateo was in the form of, like, a huge square doughnut.  So it was hollow in the middle, and there was an Olympic-size swimming pool and some other concrete, sort of on a lower level.  And then sloping up from the lower level, up to the normal class level, was this huge green lawn with some trees.  And, you know, we called it "the quad" because it was a quadrangle.  And then in the inner perimeter was sort of sidewalk, and against the wall were all of the student lockers.  So it was this, you know, large square structure, one single structure was the entire high school with then classes all around the outer perimeter.  And sort of going down in spoked halls from this center quad.



Well, we had a problem with seagulls.  You know, we're not far from the ocean.  I don't really know where the seagulls came from.  But they were constantly circling around, and no doubt looking for potato chips or unguarded sandwiches or scraps of food that students would leave behind.  And of course unfortunately they created a big mess just with their own droppings.  Someone, and I don't remember now who...



LEO:  Uh-oh.



STEVE:  ...shot a seagull with the portable dog killer.



LEO:  Want to emphasize, at this point, for those just tuning in, the name "dog killer" is...



STEVE:  Euphemistic.



LEO:  It doesn't kill.  It's a sonic blast that is harmless.



STEVE:  Yes.



LEO:  But annoying.



STEVE:  Yes, well, what it did was it nearly knocked the seagulls out of the sky.  Now, we're 16 years old.



LEO:  Oh, dear.  Oh, dear.



STEVE:  Pong won't be invented for another year.



LEO:  Oh, no.



STEVE:  Until 1972.



LEO:  Oh, no.



STEVE:  We had no videogames.  Until now, we didn't have any kind of a beam weapon.  We saw it on "Star Trek," of course.  Now we had one, and it shot birds.  Now, it didn't kill them, but it definitely surprised them.  And this was the best thing that had ever happened to us because it was like, something was reacting to this.  It was fantastic.



LEO:  Sure.  The nonlethal bird stunner.



STEVE:  Yes, it was fantastic.  And so Aragon High School was performing an experiment in the district.  This was the second year of what was called "flexible scheduling."  More like college scheduling, instead of all students being in classes periods one through seven, we had blocks of free time scattered throughout the day, different times and different days of the week.



LEO:  Santa Cruz High did that, too, when I was there, at the same time, yup.



STEVE:  And so what happened...



LEO:  Very trendy.



STEVE:  Very trendy.  And we loved it.  What happened was, that meant that various of us in the gang had free time in different slots.  So then it became a matter of handing the gun from one to the other.  And basically we would, in small groups that were free during that period, lay on the grass, having target practice.



LEO:  Oh, man.



STEVE:  You know, shooting seagulls.  Which was just fantastic.  I mean, each seagull reacted a little differently.  But there was definitely a reaction.  I mean, you knew when you got a shot off.  And so that's the way we spent the day.  It was just, you know, we were having the time of our life.



So at this time I was creating curriculum for the third year of electronics.  The high school had Electronics I and II, which was the first two semesters of the first year, which taught basic electrical theory using tubes, unfortunately.  And the professor, Harold Ferrin [sp], was a neat guy, old, gnarly, ex-Navy guy, and tubes was what he knew.  For him, transistors was a big deal.  He wasn't quite sure about them.  That was Electronics III and IV in the second year of electronics.  And of course this was - I felt like I'd died and gone to heaven, to actually be in school taking electronics.  I mean, here I already knew electronics.  I'd force-fed myself...



LEO:  Apparently.



STEVE:  ...this stuff, you know, years before.  But now I was actually getting credit for it and had a lot of enthusiasm for it.  And at one point I said to him, I guess in my second year, I mean that year, my sophomore year, I said, "Mr. Ferrin, why - what about digital electronics?  Why - it's nice that we learned about tubes last year, and transistors are good, but the future is digital."  And he said, "Well, I don't know digital."  And I said, "Well, it's really not that hard."  And he said, "Well, why don't you teach it?"



LEO:  Wow.



STEVE:  And so during my sophomore year I created an entire curriculum for third-year electronics, which we created there.  And I heard years later that it had gone district-wide and was being taught throughout the whole San Mateo Union High School District.



LEO:  That's so neat.



STEVE:  So the point of this is that, after school, I would go into the electronics lab and work on this stuff.  And I had free rein.  I'd come to the attention of the administration very early on.  I think it might have been the incident with the shock machine.  I'm not quite sure what the first...



LEO:  The shock machine.



STEVE:  Oh, yeah.  Well, that's another story.



LEO:  Another story [laughing].



STEVE:  So but Mr. Ferrin knew that he could trust me.  And he would leave, and leave the doors locked.  And I just...



LEO:  Wow.



STEVE:  My requirement was just - oh, yeah, I mean, I was trusted - just to, you know, make sure that I'd pulled the door behind me.  So this afternoon of the sonic beam weapon, I was probably leaving around 4:30.  And so the school was completely deserted, nobody there.  I mean, literally, it was completely empty, the whole quad was empty.  I went to my locker, got the books that I needed, got the portable dog killer out of the locker, which is where I had stowed it at the end of seventh period.  And to this day I don't know what I was thinking.



LEO:  Oh, no.



STEVE:  Because I saw on the far other side of the quad Mr. Archibald, the assistant principal.  And so...



LEO:  No.  No.



STEVE:  ...there was good cover where I was.



LEO:  No.  No.



STEVE:  We had these big concrete containers for the garbage and big cement planters.  And so I crouched down behind one of these cement garbage can containers and shot Mr. Archibald with the portable dog killer.



LEO:  Oh, dear.  Oh, dear.



STEVE:  Now, I mean, it was a long way away, he was, and I was hidden.  What completely jarred me was his reaction.  You would think that a regular person being shot at great distance by a sonic beam weapon would be a little confused.  They'd look around, kind of like look up maybe, it's like what is going on.  Not Mr. Archibald.



LEO:  Gibson.



STEVE:  No, he couldn't see me.  So I was hidden.  I was undercover.  He spun around.  And that's what took my breath away.  It's like, oh, my god.  I just - I didn't expect a reaction like that at all.  And he stood there motionless, trying to take in the entire scape of this huge high school quad.  And he just - he was motionless.  And he was looking for, like, anything.  And so I'm thinking, oh, my god.  So I was probably starting to shake at this point.  But I kept my cover.  And he stood there, slowly looking from side to side.  And then he appeared to give up.  And he turned back around and continued walking in the direction he had been before.



[Clip] And I've gotten word that a child is using his imagination, and I've come to put a stop to it.



LEO:  Principal Skinner.  On his way.



STEVE:  So I stood up and started to get the heck out of the quad.  But I kept one eye on him, of course, because he was the danger.



LEO:  Oh, yeah.



STEVE:  Well, he had faked me out.



LEO:  Oh.



STEVE:  He spun around again and saw me.



[Clip] I saw that.



STEVE:  And pointed at me.  Pointed at me and then beckoned with his other hand.



LEO:  Oh, oh, dear.  He's smart.  How did he know?



STEVE:  Oh, this was, well, you know...



LEO:  I guess you were well known by now.



STEVE:  Well, yeah.  I was.  And so we met about halfway in front of the office wing.  And he - and I was doing everything I could with my body language to have this gun be as inconspicuous as possible.



LEO:  What did it - it had this parabolic thing.



STEVE:  Oh, it wasn't inconspicuous at all.  I mean, it was clearly a gun.



LEO:  Like a ray gun.



STEVE:  I mean, it was a ray gun.  That's the way I designed it, you know, with a power control knob on the back with green, yellow, and red, and a big reflector out the front.  So it was dangling at my side, sort of as inconspicuously as possible.  So we approached.  And he looked at me, and he said, "Steven?"  I said, "Hello, Mr. Archibald."  And he looks down at it and then back at me and said, "What is that?"



LEO:  Oh, boy.



STEVE:  And I said, "Well, it's a sonic beam gun."  I wasn't going to use its real name.



LEO:  [Laughing]



STEVE:  And he said, "I see."



LEO:  I see.



STEVE:  "And did you just shoot me with it?"



LEO:  [Laughing]



STEVE:  And I said, "Uh, yes, sir, I did."



LEO:  Well, you're very honest, Steve.  That's good.



STEVE:  Oh, yeah.  I'm, you know.  And, I mean, there wasn't much - there wasn't much choice of answer...



LEO:  Not me.  No, I didn't shoot you, no, sir, no, unh-unh.



STEVE:  ...at this point.  And so he said, "And where did you get that?"  And I said, "I built it."  He said, "You designed it?"  I said, "Yes."  And he said, "Why?"



LEO:  [Laughing]



STEVE:  So I gave an abbreviated version of the dog story, about training this dog.



LEO:  Oh, yeah.



STEVE:  So it does not attack people any longer that were walking by on the sidewalk.  And he said, "And was that successful?"  I said, "It was."  And he said, "And you brought it to school this morning."  I said, "Uh-huh."  And he said, "And were you shooting it all day long?"  And I said, "Um, well, it turns out that it also shoots seagulls and pretty much knocks them out of the sky."  And he said, "I see."  And so I said, "My friends and I..."  He said, "The MRC Gang?"  I said, "Oh, you know about that?"  He says, "I know everything."



LEO:  Yeah.



STEVE:  And I said, "Well, yeah.  We were sort of handing it around during our various free periods for target practice."  And he said - oh, and I said, "It didn't seem to be a problem."  He said, "Oh, we'll be talking about problems in a minute."  And he said, "We began getting phone calls in the morning from teachers all over the school who were reporting high-frequency sounds."



LEO:  [Laughing]



STEVE:  They didn't know what was wrong.  They thought maybe the heater system had gone on the blink.  And I said, "Oh."  And he said, "So we called the district engineers."



LEO:  Oh, boy.



STEVE:  "And they came out, and they heard these sounds, too.  We heard them in the office wing, as well.  Everyone was hearing them.  And they thought maybe it was the ultrasonic alarm system that protects the school had gone on the fritz.  And of course we couldn't close down the school with an alarm system that wasn't functional because there'd be all kinds of consequences for that.  So they worked on the alarm system, trying to figure out if it had gone wonky somehow.  So now we know what it was.  It was you and your sonic beam weapon."  He said, "I guess I'm glad you shot me because the mystery is solved."  He said, "Now, I want you to take that home."



LEO:  Oh.



STEVE:  "And I don't want to ever see it or hear it again."



LEO:  I'm amazed he did not confiscate it.



STEVE:  He did not.  Well, he knew me.  I mean, I was...



LEO:  You were a good kid.



STEVE:  I was a good kid.  I'm sure that the office knew I had permission even to stay in the electronics lab after hours and all that because, I mean, Ferrin was very much by the book, being ex-Navy.  He was not liked by most students, who thought he was way too rigid.  I just thought he was great.  So I took the gun home, put it on the shelf.  My friends and I were all very disappointed.  They were all anticipating many more days of target practice.  Although, to be fair, I have to say that by the end of the day there really weren't so many seagulls any longer, circling around overhead.



LEO:  Trained them, too, I guess.



STEVE:  Well, I think they decided this is not where we want to be.



LEO:  No.



STEVE:  So that's the story of the portable dog killer.



LEO:  Unbelievable.  Steve, what a great story.



STEVE:  And when I was thinking about this, I was thinking about all the email that I've received during the podcast from young listeners who wonder how to get going, how to get started, what would I recommend?  How do they differentiate themselves?  And the second employee at Gibson Research Corporation, one of the most brilliant engineer programmers I've ever known, a guy named Steve Ranck, went on to found a couple gaming companies.  He has one now called Specular Entertainment.  His first one was Swingin' Ape, which he sold to Blizzard.  And what stood out in my mind about Steve actually is really that, like me, he was building things from the beginning.  Nothing could stop him from building things.  He was involved.  I mean, I heard about all the projects that he had built, much as I had, as a kid.



LEO:  It's a good sign, isn't it.



STEVE:  Well, that's my point, yes, is clearly there were incredible unintended consequences from my creating this gun to train this incredibly vicious, ferocious dog.  But that's what happens when you build things.  Nothing happens if you're sitting behind a screen shooting aliens in a videogame.  Doesn't happen.  All the discoveries that have been made have been made by people experimenting.



LEO:  Do something, yeah.



STEVE:  You know, Tesla was building all kinds of things.  And you can't know what you're going to learn until you're confronted by it.  You've got problems.  Something happens you don't expect.  I mean, it's just - it's amazing how opportunity-rich the environment is.  But if you're not in it, you're not going to get the opportunity.  And so what I would encourage people to do - Steve and I are still good friends.  We get together every so often.  And we sort of reminisce about the projects that we built and think to each other, can you imagine being a 10 year old now?



LEO:  Wow.  What opportunities.



STEVE:  With all the stuff there is?  I mean, there are these things, programmable gate arrays, which are just amazingly powerful, where you can use software to program logic in, like, softly in this.  I mean, I don't know what I would, I mean, there just isn't enough hours in the day as it is for me.  But if I were a 10 year old or a 12 year old or 15 year old, I would say turn off the videogame.  That's doing nothing.  Build something.  Build anything.  I mean, the feedback you get, the fun, but mostly the discovery.  You will end up discovering things that you cannot predict, you cannot know about.  That's the nature of it.  But I just think that's something that our pasteurized world has sort of lost a little bit of.  I mean, this sounds like a wild story.  I guess it was probably a little wild in 1971.  But probably not as wild as it sounds today.



LEO:  Today the Department of Homeland Security would be coming to your door.



STEVE:  Exactly, yeah.  So...



LEO:  But it's a very good - I even have, in a very small way, a similar story.  And it did start for me with videogames.  I got an Atari 2600.  But what the game did is made me think, oh, I want to know how this works.  And it doesn't have to be a physical thing you're building.  It's easy to build software.



STEVE:  Oh, yes.  In fact, that's where I've switched to.



LEO:  Yeah.  Yes.  And everybody has an opportunity now, for free.  There are so many great choices.  There's Alice.org, a great way to start littler kids on object-oriented programming.  And there are so many things out there, just, yeah, I think - but I think there has to be that little seed in your brain, which you obviously have, Steve obviously has, where you get inspired to say, I want to make something.  So, and I think there will always be people doing that.



STEVE:  I think it's a - maybe it's a matter of empowerment.  I mean, now, I will say that my dad did encourage me.  I mean, one of the things that I did when I was five, we would go down to the docks in Oakland and buy a hunk of electronic gear coming off of the naval ships down there.  And they hung it on a fishhook, a big, huge fishhook, and you paid for it by the pound.  And the car looked like its suspension had gone broke in the back because this thing was in the trunk.  And we'd bring it home, and he'd sit it in the middle of the garage.  And he'd say, okay, go at it.  I mean, there was nothing I wanted to do more than tear that thing apart.  And he says that he knew that I was internalizing the work of the country's best engineers as I was taking this apart.  And he thought that someday I would start putting things back together again.  And it turned out that was sort of the path I took.



So there has to be, I think, some encouragement.  But as you said, also some spark.  And nothing could stop me from this kind of inquiry.  And so I would just encourage people to get involved, to do something, I mean, something proactive, something creative.  Not just passive, because passive, nothing's going to happen that way.



LEO:  I think that it's probably the case that there are people who just don't have that spark, and they're going to - look, we need people to flip burgers.  And those people, not everyone is going to be a maker.  But boy, if you see that spark in a kid, just encourage it, don't discourage it.



STEVE:  Yeah.



LEO:  It's a great lesson.  And you know what, thank goodness that Vice Principal Archibald didn't beat you up over this.  He knew, he sensed that this was something that was appropriate for you to do.  He made sure you didn't do it at the school.



STEVE:  Yes.  And he understood it was completely unforeseen, there was no way I could know.



LEO:  Right.



STEVE:  Or that, oh, I forgot to tell you one thing he said as I was leaving with the gun and breathing a big sigh of relief.  He said, "Oh, there's one thing, Steve."  I said, "Yes, sir?"  He said, "Next time something appears to go wrong with the high school, we're going to track you down first."



LEO:  We're calling you [laughing].  I think that's wise.



STEVE:  Just because, I mean, he went through so much trouble.  I mean, bringing people, engineers out from the district, crawling around to figure out what had gone wrong with the heaters, and then with the ultrasonic alarm system, I mean, I don't like to think about the expense that they went through.  But he realized, had they just said, "Steve, are you doing anything strange today?"



LEO:  What are you up to there, Mr. G?  I think that's just a wonderful story.  And I would have to ask, I don't supposed you still have the portable dog killer.



STEVE:  I have a lot of my paraphernalia.  I've got - I did do helium neon laser guns later in life, and I have some of those.  But I don't know what happened to this.  I went to Berkeley and then moved to Southern California.  And at one point there was - I actually had a lab upstairs in San Mateo.  That's where this was built was in Steve's - I'd be "in the lab," as they put it, when I was called for dinner, which is where I built this.  So, and it was just sort of an extra room that I commandeered.  I said, okay, this is mine.  This is my space.  I need a lab.  So at one point there was a purging of all the stuff I'd left behind.



LEO:  Yeah, of course, yeah.



STEVE:  I think that that happened.  I mean, I can see it clearly in my mind.  And of course many people were witness to all this craziness.  But, and my life was a series of wacky adventures like that.  We'll share one every so often.



LEO:  I love that spirit.  And you know we celebrate that spirit today with the maker, MAKE magazine, the maker faires.  And there is this notion of making which is focused, I think, on physical making, which is a great thing.  But it's fine to make with software.  In fact, more than ever we need software.  And that's perfectly appropriate.  And I think kids should learn...



STEVE:  It costs nothing.  Costs nothing.



LEO:  Costs nothing.  You don't get your hands dirty.  And most of the time the principal doesn't confiscate your program.



STEVE:  And, frankly, when people have asked me, and I've said this before on this show, how do I learn this language, how do I learn this, or how do I learn that, my answer is, solve a problem with it.



LEO:  Yes.



STEVE:  That is, you just can't sit there, I mean, reading a book about a language...



LEO:  Abstract is not good.



STEVE:  ...is dry.



LEO:  Yeah.



STEVE:  So come up with something you want to do and make yourself do it in that language.  I mean, there's no hurry.  There's no deadline.  Doesn't have to be tomorrow.  Just start.  And when you start, the rest will flow.



LEO:  Such a great moral.  I hope - anybody listening to this show is probably in that category of maker and doer.  And, I mean, you wouldn't be listening to the show if you didn't have that spark.  But it's good for us to remember, spread it around, let others get involved.  We're going to - I want to sponsor at my kids' high school a FIRST Team, the robotics competition this fall.



STEVE:  Oh, neat.



LEO:  Because that's an example of - it's an institu- truth is, it's better if the kid goes off and does it on his own and gets in trouble, like you did.  But failing that, at least if there's some sort of institutional encouragement to do that, and some opportunity to do that, that's a good - gets you started.



STEVE:  Well, and it does, frankly, it does fit today's world more than building sonic beam weapons fits today's world.



LEO:  Yes, yes.



STEVE:  So.



LEO:  Great, great show.  Thank you, Steve.  I really appreciate it.  Always a pleasure.  And this was a good one.  I'm glad you took a little time.  And I don't know how much Twitter had to do with this, but I'm glad that you were inspired.  I look forward to the blog.  I presume it'll be at your website, GRC.com.



STEVE:  Yup, it will be.  I'll announce it on the show and certainly through the followers who are following me on Twitter.



LEO:  Good, good.



STEVE:  And I'll have it up here probably by next week.  And again, it was - I want to remind people it was the 50th today, well, not the day, this week, the 16th, the 50th anniversary of the invention of the laser.



LEO:  Isn't that cool.



STEVE:  And so you can see what the tie-in was.  That's what sort of got me thinking about my own beam weapon and the story that it begat.



LEO:  Isn't that great.  Steve, thank you so much.  Go to GRC.com for Steve's stuff - 16KB versions of this show for those of you who have limited bandwidth.  And Steve's great, he edits this down and makes it available to you.  He also does transcriptions on his own, out of his own pocket, and we thank you for doing that, Steve.  That's all at GRC.com, including the show notes.  And once you're there, you've got to get SpinRite, the world's best hard drive maintenance and recovery utility.  I mean, following in the spirit of the portable dog killer, this is the portable hard drive cluster mess-up killer, sort of, 64K.



STEVE:  We know what you meant.



LEO:  Also great free stuff, lots of it, ShieldsUP! and all his great programs.  GRC, Gibson Research Corp., GRC.com.  Follow Steve on Twitter, I have to add this now, @SGgrc.  And GibsonResearch is the Twitter handle for the corporate account.  But the fun stuff is at @SGgrc.  Steve, we'll see you next week...



STEVE:  Thanks, Leo.



LEO:  ...on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#282

DATE:		January 6, 2011

TITLE:		Listener Feedback #108

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-282.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 282, recorded January 5, 2011:  Your questions, Steve's answers #108.



It's time for Security Now!, the show that covers your security and your privacy and all the stuff you need to know online.  Here he is, ladies and gentlemen, the man of the hour, Mr. Steve Gibson of GRC.com, the Gibson Research Corporation - antivirus guru, spam fighter, privacy expert.  And also we talk a lot about all kinds of technologies on the Internet.  Good day.  Happy New Year, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you, our first episode of 2011.



LEO:  Wow.



STEVE:  Absolutely.  We have a Q&A, since we did a replay in the week between Christmas and New Years of one of our favorite episodes, everyone, all of our listeners' favorite episodes, The Portable Dog Killer.  So we'll pick up where we left off.  And from now on our Q&As will be on, well, until we do another little bump, our Q&As will be on even-numbered episodes.



LEO:  Okay.  We're not tied to it.  We do whatever.  We've got some great questions for you.  We've got security updates.  And this will be the one place today that you probably won't hear any CES news, I would imagine.



STEVE:  We're just barely in front of CES.  But of course that's going to dominate the news cycle then now for the next five days, probably.



LEO:  Yeah, oh, yeah.  Certainly us.  We start our coverage Wednesday night at 7:00 p.m. Pacific, 10:00 p.m. Eastern with the Digital Experience.  Thursday we'll do ShowStoppers.  We also have other stuff going on.  I think 1:00 p.m. Thursday, Sarah and I will welcome you officially to CES, 'cause the show opens tomorrow at 9:00 a.m.  And then all day Friday, Saturday, and Sunday.  So we're going to have a lot of coverage on the TWiT network:  live.twit.tv.  And many of those shows, I think all of it, will appear on the TWiT Specials feed, TWiT.tv/specials.



STEVE:  Yay.



LEO:  Yay.  But usually CES doesn't have much privacy or security news.  It's not really a great place for that.



STEVE:  Right, it's consumer stuff.  But we have certainly, I mean, you and I both have a passion for that stuff.  I'm sure our listeners do, as well.



LEO:  Shinies.



STEVE:  Yes, toys.



LEO:  Toys.



STEVE:  Boxes being delivered to the front door.



LEO:  Yes, we do love that, don't we.  So let me ask you if there's any security news.  What's going on in the world around us?



STEVE:  Well, I half planned not to do a Q&A, only to do a major mega news update.



LEO:  Really.



STEVE:  Well, because I figured that, having missed, essentially missed a news cycle by doing a repeat last week, we would have two weeks' worth of news accumulated rather than just our normal one.



LEO:  True, true.



STEVE:  And nothing happened.



LEO:  It's kind of slow.  Even the hackers take the holidays off.



STEVE:  Even the bad guys.  Bad guys have mothers and families.  Exactly.  So, yes, we've got some news.  Over on the security side, two IE problems, actually an IE and a Windows problem.  There's a big kerfuffle going on right now with Microsoft accusing a Google employee of having not given them sufficient notice of the bug that we did talk about two weeks ago.  It had just surfaced, and we knew that it was a CSS problem of some sort.  We didn't really know what it was.  Now we know that it involves the at-import rule processing of cascading style sheets in IE, which makes everyone's eyes cross, but that's where the problem is.  And it exists in all releases of Internet Explorer, manifesting itself on XP, Vista, and Win7.



It's a remote code exploitable problem.  Unfortunately, this one DLL that it targets is called the mscoreie.dll.  It was not compiled with the so-called /DYNAMICBASE switch.  That's the switch that the compiler can accept which allows it to float around, allows that DLL to float around and load in different places in memory.  In other words, that's the famous Address Space Layout Randomization, ASLR, which is now actively working to support many of the kinds of attacks that we've seen in the past.  Because this DLL was not compiled with that switch, maybe it's incompatible with floating around, who knows, I mean, there may have been a reason for it rather than just oversight.  Or they may have just, among all the code that goes into IE, they may have skipped one.



So what happened is the bad guys figured out how to use the fact that this DLL always loads at a known location.  That allows them to use so-called ROP, or Return Oriented Programming gadgets, where they jump to the end of subroutines in that DLL, and then the subroutine finishes and returns to the caller, that is, to them.  So by cleverly using sort of the tails of existing code, that also allows them to avoid the DEP protection, the Data Execution Protection, because they're not executing data, they're actually executing code.  They're executing Microsoft's code, but certainly in a way that Microsoft never intended.



So what happened is, and I'm going to talk next week about the whole concept of fuzzing.  It's not something we've talked about before.  But this revolves around a fuzzing technology, which is to say throwing lots of bizarre stuff at code and looking for any misbehavior.  The guy who did this is someone we've talked about before, Michal Zalewski, who is a security guy at Google.  Back in July he notified Microsoft of this problem and gave them his code which made the problem happen.  He heard nothing from them.  And back then he told them that he planned to release this code in January of 2011.



LEO:  That's fairly typical from a security researcher, to say here's the code, you've got some time to fix it, but then we have to tell the world.



STEVE:  Six months.



LEO:  Yeah.



STEVE:  Six months, exactly.  And so what's happened is now Microsoft is coming back and saying, well, we didn't get - this was not responsible disclosure.  We weren't told in time.  And they're saying we were unable to duplicate the problems.  Well, they never told him that.  They just didn't respond at all when he sent them this whole care package.



LEO:  But they were busy.



STEVE:  With all their other problems.



LEO:  Yes.



STEVE:  I know.  So now they're saying that we need more time.  And he said, sorry, I told you last summer.  I gave you the whole ability to reproduce it.  They're saying, well, it didn't reproduce.  Other people, and now Microsoft, have been able to reproduce it with that July code, even though what he's now released publicly is a much more updated code.  The significant thing about this, well, so we have one more IE problem.  This tool found more than a hundred problems spread across every browser there is.  So we'll be talking about that tool next week.



LEO:  Sorry about that.  I had my mic on.  You're probably wondering why I was...



STEVE:  [Indiscernible].



LEO:  ...apologizing for driving you crazy.  Go ahead, I apologize.



STEVE:  So, anyway, so the problem we talked about a couple of weeks ago, Microsoft has now acknowledged.  The good news is, next Tuesday will be the 11th, since this last Tuesday that's just behind us would have been the 5th.  So - is that right?  Anyway, whatever it is, it's the second Tuesday.



LEO:  Yesterday was the 4th, so it'll be the 11th.



STEVE:  Perfect.  So Tuesday the 11th, that'll be the second Tuesday of January.  Maybe, if Microsoft is on their game, they'll be able to fix this.  And there's another new zero-day problem that they have found across all versions of Windows in the graphics side of their OS.  Not much is known.  They've got a security advisory posted.  But hopefully we'll be talking about these both as being in the past tense next week.



LEO:  Yay.



STEVE:  In big news that many people sent and faxed and emailed and tweeted, I mean, I was getting hit from all sides, after Christmas, on Tuesday the 28th at the Chaos Computer Club, the CCC Congress in Berlin, which we've covered in years past...



LEO:  Is that like a hacker con?



STEVE:  Yes, it is, "Chaos" being the clue to that.  Two guys with Security Research Labs, which is SRLabs.de, showed why and how the GSM Association was wrong.  About a year before, and we covered this at the time, the assertion was made that the GSM cellular network was too hackable.  And we talked about the crypto that they use, in fact I referred to them just two weeks ago because GSM, being very old technology, uses a sort of pre-crypto approach.  They also use those linear feedback shift registers, which Bluetooth uses in a relatively safe way.  GSM, unfortunately, is not so lucky with their use of the same technology.



And in fact actually it's because of the Bluetooth technology arising originally from Ericsson, that is, a GSM-oriented cellular phone designer, before Sony bought them, and they of course became Sony Ericsson.  That's why Bluetooth uses the same sort of technology that GSM uses, sort of from a common heritage.  The problem is that there is a huge amount of known, what's called "known plaintext" in crypto, in the cellular protocol, meaning that a lot of what's sent out over the wire, or sent out over the air, we know what it is that has been encrypted.  And the technology generates, uses these linear feedback shift registers to generate a pseudorandom bit stream which is then exclusive ORed with the plaintext to create the ciphertext.



As our listeners know, when you XOR the ciphertext again with the bitstream, you get back the plaintext.  That's how you decrypt it.  The other little quirk about XORing, though, is if you were to XOR instead, you XOR the encrypted data with the known plaintext, what you get back is the bitstream, that is, the original cipher bitstream.  So what's been generated in the meantime are two new technologies.  There is now, available for downloading on BitTorrent, a 2TB rainbow table for GSM.  So to remind our listeners, a rainbow table is essentially a table of some crypto operation, typically hash tables, which have been performed once.



LEO:  Kind of pre-calculated.



STEVE:  Exactly, pre-calculated.  So it's a one-way function which has been performed once, and then the results stored so that you have sort of the results of this operation stored, so you don't have to...



LEO:  In the old days before calculators, maybe not before slide rules, but you'd get these sine and cosine tables.



STEVE:  Yeah, exactly.



LEO:  Just pre-calculated math.



STEVE:  Exactly.  So what these allow you to do is they allow you to essentially perform the reverse function, even though the point of the crypto is for there not to be one.  That is, like for example a hash is meant to be a forward function such that you put all this stuff in, and you get out a result.  But it's a one-way function.  You can only go forward.  You can't go backwards.  But think about it.  If you were to record in a table all of the results of going forward, then you look up in the table the result, it's going to be matched up with what you put in to get that result out, which allows you to go backwards.  So it defeats that one-way function.



LEO:  Whoops.



STEVE:  Yeah.  So that was one part.  The second thing they did, one of the arguments that the GSM Association made where they were defending themselves, saying oh, no, no, no, don't worry, GSM technology, which is global, is still secure, don't have to worry.  They were talking about how, oh, it takes huge amounts of money and expertise and wideband technology and fancy antennas and field-programmable gate array, custom boards, the point being that there was a bar way too high.  Okay.  These two guys demonstrated the entire attack on voice and text using four modified $15 cell phones.



LEO:  Oh.  I was going to say Commodore 64s.  It's worse.  It was on the phone.



STEVE:  For a total cost of $60.



LEO:  Ai, ai, ai, caramba.



STEVE:  Four $15 phones.  They reprogrammed the phones to work differently, so they weren't still cell phones like in the old days.  But the code to do that is open source.  They added a faster USB connection so that they were able to move data at the speed they needed to.  But basically they've completely demonstrated a low bar, that is to say, less than a hundred dollars and a soldering iron, and go to BitTorrent, and you can get the - it's funny, too, because Bruce Schneier in his blog also picked up on this, as did Engadget and a bunch of other people.  Schneier mentioned that 2TB, we don't even blink when we say that anymore.  Ten years ago...



LEO:  That used to be a lot.



STEVE:  ...that would have been impossible.  It would have been, I mean, not impossible, but hugely...



LEO:  You're not going to download 2TB.



STEVE:  No.  Now people use them as doorstops.  So it's just not a problem.



LEO:  Oh, lord.  All right.  Moving on, WikiLeaks.



STEVE:  Yeah, well, there was just a couple things.  The Washington Post had an article.  One of their staff reporters, Joby Warrick, had some little tidbits that I hadn't seen before.  Apparently the CIA had been asked to put their data onto the SIPRNET.  Remember we did talk about the SIPRNET a couple weeks ago as being this secure, essentially a secure version of the Internet.  It uses Internet technology, Internet protocol, Internet routers.  It's just not the 'Net that we're all on and connected to.  It's a separate one.



And the CIA's rationale for denying that they just dump all of their assets onto that 'Net is just one of security.  They said, there are two many people, there are 2.5 million people who have access to that.  Not just government, but also government contractors have access.  And this is the so-called Net-Centric Diplomacy was the name that this system was given, which was set up when it was decided that there was just too little communication, too little interagency communication in, what's the term they use, smoke-stacking, I think, or...



LEO:  Oh, siloing or...



STEVE:  Siloing is one.  I've also heard them, like, the idea being that they're just like tubes that are surrounding the entities that are not intercommunicating.  The NSA has taken this all much more seriously.  Being the NSA, they're saying that they're...



LEO:  Stovepiping. 



STEVE:  Stovepiping, that's...



LEO:  The chatroom said stovepiping, [indiscernible].



STEVE:  That's the term I was looking for, yes.  The NSA, being the NSA, is proactively taking the stance that they no longer can trust anything in their own network and systems, and they're assuming that they've been compromised, and they're going to act accordingly.  So it sort of reminded me of our standard wisdom with PCs, is once malware gets into your computer, you really can never know that you got rid of it all.  I mean, once it's happened, you really need to just, hard as it is, pull your data off and then set up the system from scratch and then restore your data.  Because otherwise there's just no way to know that you got rid of it all.



But the way apparently this all sort of got out of control is there was a keyword flagging system in this Net-Centric Diplomacy technology such that, if the key tag SIPDIS, which is probably an acronym for something, SIPDIS, that would flag any document or communication like a cable as a appropriate for archiving in this Net-Centric database.  But what ended up happening, because embassy staff were never really given a clear protocol or guidelines, except they were told, okay, we've got to stop keeping all this information to ourselves, we're supposed to share it with everybody, so they started flagging everything with this SIPDIS since there was no clear policy.



And as a consequence, after the WikiLeaks problem happened, people who knew what this Net-Centric database should contain looked into it more carefully and closely and just saw that it was full of improper and inappropriate information, stuff that wasn't about maintaining the security of the country.  But as we've seen, all kinds of other stuff got loose.  And quoting one line from this Washington Post article, Joby wrote:  "Partly because of its design, but also because of confusion among its users, the database became an inadvertent repository for a vast array of State Department cables, including records of the U.S. government's most sensitive discussions with foreign leaders and diplomats.  Unfortunately for the department, the system lacked features to detect the unauthorized downloading by Pentagon employees and others of massive amounts of data, according to State Department officials and information-security experts."



So not only was the system a repository for much more than it was designed to receive, and anything that was transmitted over this SIPRNET that was tagged with this SIPDIS flag would automatically get archived in this Net-Centric Diplomacy system, but additionally there was no controls.  There was no monitoring.  There was no auditing or logs of any access to this database.  So it has all the earmarks of something that was sort of thrown together way too quickly, in a hurry to solve the problem, but without the kinds of mature security and privacy controls on it that all of us would know such a system would need.  And we know what happened as a result.



LEO:  It actually isn't easy to find the Bruce Sterling article.  He wrote it for Webstock, which is a New Zealand conference.  If you go to Webstock.org.nz and search for "Blast Shack," it's a fairly long piece, a couple of thousand words, and I think quite interesting, especially if you're interested in hackers and what that has to do with WikiLeaks.



STEVE:  And sort of their psychology.  I did read that piece, by the way.



LEO:  Did you read it?  Yeah.  I thought it was quite good.  He wrote it right before Christmas.  I like Bruce a lot.  We've got to get him on the show.



STEVE:  Well, and...



LEO:  Stuxnet.



STEVE:  Yeah, Stuxnet.  There's continuing to be information coming out.  I picked up a few more tidbits that I just thought I would share, which was a report from ISIS, Institute for Science and International Study, indicated that apparently as many as a thousand out of 10,000, that is to say, 10 percent of the centrifuges which were at one point commissioned and running in the nuclear facility in Iran, which it is believed Stuxnet was targeting, have since been decommissioned, it's believed because they were made to malfunction physically, essentially physically damaged by Stuxnet.  They're called IR-1 centrifuges, and they are supposed to run at precisely 1,064 Hz, that is, believe it or not.



LEO:  Is that like 1,064 RPM or RPS?



STEVE:  Well, it's not clear what the relationship between the AC frequency going into the motor, it'll be a synchronous centrifuge motor which is locked to the frequency that it's given.



LEO:  I see.



STEVE:  And so in order to exactly control its speed.  But what we do know is that Iran was apparently running theirs a little slow, about 1,0007 Hz, specifically to reduce stress.  So, as I understand it, already at the 1,064 Hz, which is the spec for these IR-1 centrifuges, they're at about the limit of what they can physically handle.  It's interesting how much, I mean, just a flywheel itself generates tremendous stresses inside of itself.  There was a project that Ben Rosen of Rosen Research fame, and then later Rosen Motors, Ben created a flywheel-based energy store for an electric car drive train.  And it turns out that advanced energy stores like that, they use bristles rather than solid disks because solid disks self-destruct when they spin that fast due to essentially, I mean, they're pulling themselves apart.  So you end up with a hub of bristles.  And that's what you spin in a vacuum because that's an architecture which is stable under those kinds of forces.



So what has been found is, relative to Stuxnet, is that it was instructing the centrifuges, which are already running near their limit at 1,064 Hz, to run at 1,410 Hz, which would either immediately damage them physically or would cause them to, like, crumble within about 15 minutes.  And so further analysis of the code has shown that it would spin the centrifuges up to this higher speed and hold them there for a while, and then bring them back down, and then go quiescent for 27 days.  So there was, like, 27 days would elapse between these attacks.  And it's believed that's just to have the thing hiding most of the time, so that it wasn't obvious what was going on.



LEO:  That's clever, actually.  That's actually very clever.



STEVE:  It's very clever.  And then the thing that really caught my eye was that it deliberately disguised this activity by sending commands to shut off the warning and safety controls that would otherwise have alerted the plant operators.



LEO:  Clever.



STEVE:  So to me, Leo, I mean, as an engineer myself, if someone said, Steve, we need you to do this, I would need one.  I mean, you know...



LEO:  You'd have to have this centrifuge.



STEVE:  Yeah.



LEO:  There's no way you could do it without - you'd need to know a lot about it.



STEVE:  Exactly.  For this kind of design, especially when I heard that it was sending commands to shut off the warning and safety controls that would normally alert plant operators, you can't do that from spec sheets.  I mean, in order to do it reliably, you would need one of these centrifuges in a system, working, in order to proof and debug and perfect your code, which to my mind really does up the ante of the notion that this was probably state-sponsored by some state, meaning government-level sponsorship of this.  To this point I was like, well...



LEO:  Is that because they're so expensive?  Is that why?



STEVE:  Well, yeah, you just don't order a nuclear refining centrifuge.



LEO:  You can't just buy it from a catalog?



STEVE:  I got some yellowcake at a yard sale.  I'd like to...



LEO:  So is that the only thing these centrifuges are used for is concentrating - okay.



STEVE:  Yeah, it's the only thing they can - that's what they do.



LEO:  I think we know it is a government [indiscernible]...



STEVE:  They're not available from eBay.  So, yeah.



LEO:  Wow.  Did they also have to have the Siemens equipment?  I would imagine they did, as well.



STEVE:  Yes.  You would need a working, essentially, a working installation of...



LEO:  So we can assume it's a nuclear power that did it; right?



STEVE:  It really has to be.



LEO:  Or somebody who really has high aspirations.  I mean, look, it's obviously Israel.



STEVE:  It's got to be.  I don't mean it's got to be Israel.



LEO:  Government.



STEVE:  It's got to be a nuclear power.  It has to have been somebody who essentially had a facility like this, so they were able to create the same centrifuges, the same controllers, the same technology.  Because you just can't write and debug code blind.  You'd have to test it.  You'd have to see that it was doing the right thing in order to know that you were going to generate a payload for this worm that was going to be effective at the other end.  So...



LEO:  So in detective work you always say opportunity, motive...



STEVE:  Means, motive, and opportunity.



LEO:  ...and means.  So the means require a nuclear power.  The motive is pretty clear, somebody who would want to slow down Iran's nuclear capability.  I mean, it's not just some hacker in a closet somewhere.



STEVE:  No.



LEO:  And opportunity, well, that could be anybody because the Internet gives everybody the opportunity.



STEVE:  Well, and we've got worms.  I mean, a lot of other people got infected by Stuxnet who weren't running any IR-1 centrifuges.



LEO:  Well, that's interesting.  So they released it to the wild.  It wasn't a spear phishing attack.



STEVE:  Correct.  It just jumped around and jumped onto people's thumb drives.  It was believed to have been brought in on a thumb drive.  But many other organizations found this curious code and said, well, we have a worm with an unknown payload.  And it's taken quite many months to peel the onion layers off this payload.  And the more we see, the more we learn, the more I'm coming to the opinion that it really took a substantial effort to put this thing together.



LEO:  Here's a question.  Could it have been accidentally self-inflicted?  Could Iran have been making such a thing?



STEVE:  No, because - oh.  You mean like to get somebody else?



LEO:  Yeah.



STEVE:  Yeah, well, certainly.  I mean, yes.  They would have had, obviously, the whole setup there if they were trying to target somebody else's equipment.  There were two countries, I think it was Iran and maybe Pakistan, I can't remember now, there were two countries that were known to have exactly this type of equipment.  So apparently there are many different versions of stuff that you can use.



LEO:  That's interesting.  I guess you could, if you were a detective trying to figure this out, as presumably somebody is, you'd say, well, who has this?  I mean, not everybody uses the same stuff.



STEVE:  Right.  And you might want to ask also, who ordered one?



LEO:  That's interesting.



STEVE:  Anyway, on the ongoing saga of IP space depletion, which is our other news of 2011, we'll be following this,  the IANA will be handing out, probably in the next few weeks, so it's expected by the end of January, the last of the /8 netblocks to each of the major registries.  So there's APNIC, which is Asian Pacific NIC.  There's AfriNIC.  There's a couple, there are like a handful, four or five major registries that each handle their region of the globe.  And they receive the netblocks from the IANA that essentially makes those then active.  And then they turn around and start satisfying the needs of the people who they supply.  So there's a multilevel tiered hierarchy of allocation of this space.  We're still, however, on target for late summer, early fall doomsday.



LEO:  Oh, good.  I'll put it on the calendar.



STEVE:  When no more IPv4 addresses are available.



LEO:  That's soon.



STEVE:  It's really soon.



LEO:  We're not ready.



STEVE:  People are beginning to scurry around.  There is a deployment guideline.  NIST has released their final version of the IPv6 deployment guidelines, which is an 118-page document.  We're going to do a podcast just on it soon because it's got a whole bunch of really interesting material in there that I know our listeners will be interested in because sooner or later we're all going to be affected by IPv6.  At this point, very few of us are.  But that's not going to be the case for long.



In a matter of errata, I wanted to respond to many of our listeners who have said, hey, Steve, whatever happened to the How the Internet Works series?  So I wanted to let everyone know that I have not forgotten about it.  There are just a few things, like this deployment guideline, and I want to talk about attacking Bluetooth next week, following up on our discussion of how Bluetooth works two weeks ago.  So there are a few more things that I've sort of just got backlogged.  And then we will absolutely plow into our very careful, basically soup to nuts, from the bits all the way up to the top-level operation of the Internet - packet flow and routing and all that stuff.



LEO:  Look forward to that.



STEVE:  Which I think people will enjoy.  And I had just a very nice short note from someone named Rick Shepherd that I wanted to share.  He says - he's in Reno, Nevada.  And he said, "I could easily give you several specific SpinRite stories and go on about how our site license has been used to save many hard drives.  I could do that, but so many already have.  Instead, I will state only this:  Of all the products I have ever bought, sold, researched, or discussed, only SpinRite holds one special title.  Nobody I have ever dealt with, anywhere and in any capacity, has ever said anything bad about SpinRite.  No other product has that kind of record."  So I thought that was neat.



LEO:  I think that's true.  And I have to say, I hear, because we advertise a number of different products, I hear whenever anybody's unhappy about any of those products.  And there is no product, however good, that doesn't get an occasional ding.  Look at Amazon, there's no, I mean, look at the Kindle, everything.  Somebody doesn't like something.  I've never seen - that's a very good point.  Nobody's - I've never, well, now, we don't want to tempt fate here.



STEVE:  Yeah.  Thank you, Rick.  Next topic.



LEO:  Next topic.  We have great questions, 10 of them, from you the listeners.  You went to GRC.com/feedback, and you asked those questions, and I'm glad you did.  And I'd like to ask you a question.  Have you taken the TWiT survey?  Now, our sponsors know exactly how many people listen to a show.  But what they don't know, and what they would love to know, is kind of who you are, not individually, but as an aggregate.  Are you young?  Are you old?  Where do you live?  That kind of thing.



STEVE:  Because we're not tracking you, so we don't know anything about you, you have to tell us.



LEO:  Yes.  Oh, that's a good point.  There's a nice spin on it.  We don't want individual information.  You will take the survey, but you'll take it anonymously, and we'll aggregate the information.  And that lets us say to our sponsors, for instance, well, we've got 53 percent males, 25-54, whatever it is they're looking for.  It is at TWiT.tv.  I made a bit.ly link because, if you're running ad blockers, and I suspect more than any other show we do that Security Now! people run all sorts of ad blockers and Flash blockers and JavaScript blockers.  So if you're running NoScript or an ad blocker, you can go to bit.ly/listenersurvey.  It's at bit.ly/listenersurvey, or just go to TWiT.tv, if you're not running a blocker, or if you're not blocking our stuff.



Right at the top there's a banner.  It's a five-page survey, take you five minutes, 10 minutes to do, depending on how long you think about it.  Should be pretty quick.  At the end we'll ask you if you want to be part of our panel, the Podtrac panel.  Our ad agency does all this.  We don't do it.  The ad agency does it.  And the Podtrac panel helps us with research about advertising and so forth.



Advertisers, I'll give you as an example, often will say, okay, we want to do a survey before you run the campaign and after, to see if there was recognition of the product, if people heard it, if they understood it.  And those panels help us an awful lot, as well.  It's one of the reasons people keep coming back to TWiT, frankly, to advertise, because we work.  So you can help us.  TWiT.tv, just right at the top there, or go to bit.ly/listenersurvey.  And we'd appreciate your support.  Are you ready for a question, my friend?



STEVE:  Let's do it.



LEO:  All right, let's do it.  Let's do this thing.  Number one from - I love his name - Ranga Reddy in Asbury Park, New Jersey, home of Bruce Springsteen, wonders about SSDs and full drive encryption.  And I wonder, now that he mentions it, I want to know about this, too.  Been a big fan of the Security Now! podcast since year one.  Security and privacy issues sometimes annoy and anger me; but, since I listen to your podcast while working out, it fuels my workout.  That's good.  Put the frustration and anger right into that Stairmaster.  You recently stated that SSDs don't need defragging.  They also don't need SpinRite.



STEVE:  Correct.



LEO:  Because the excessive writes of defragging would ruin the drive.  And fragmentation is not an issue because there is effectively zero seek time on a random-access drive like an SSD.  How about full-drive encryption?  Is that going to cause the same thrashing of bits?  TrueCrypt, BitLocker, FileVault and so on?  Does full-drive encryption affect SSDs?



STEVE:  Well, sort of.  My advice with SSDs and defragging is maybe to just defrag it once.  Once a system has all been established, and all the endless security updates are installed, and your apps have been installed on a machine, I would say I like the idea of just sort of organizing it one time, just because, if you've ever looked at the fragmentation of a drive after a full system setup, it's just a catastrophe.  I mean, it's a disaster.  And if something ever did happen to the directory structure of the file system, then having the files defragged, that is, in contiguous runs of sectors on the SSD could help data recovery software to guess where the file extents are, where the file begins and ends and so forth.  So I like the idea of doing it once.  It's absolutely something you do not need to do all the time.



Now, relative to whole-drive encryption, when you encrypt the drive, that would run across the entire drive contents once, converting every sector of 4,096 bits, every 512-byte sector of the SSD from plaintext into ciphertext.  So that's something that happens one time when you apply the whole drive encryption, and it happens again if you ever remove the whole drive encryption.  But in use there is no difference.  So it's sort of a little bit like defragging, that is, there's a cost to it to apply the encryption, but not to use it.  So there's no additional wear and tear that's occurring on the SSD because it's running through TrueCrypt or BitLocker or FileVault or any of those.  One pass across.



And again, I'm overly concerned about SSD reliability, just because I'm overly concerned about data reliability in general.  SSDs are solid state.  They are robust.  They are far more reliable than hard drives, which is why SpinRite exists and how I've made my living for the last couple decades.



LEO:  You know about it.  You know all about it.  You're the guy to ask, yeah.



STEVE:  Exactly, yeah.  But at the same time, defragging an SSD all the time makes no sense because there is a wear...



LEO:  There's no benefit.



STEVE:  There is a wear factor on solid-state drive technology, which is why they go to all this drive-leveling approach, so that even if you appear to be rewriting the same spot over and over and over, you're actually writing in different physical areas of the SSD so that you don't burn out one particular area.  You really can burn them out.  I know, for example, Mark Thompson has done so with CompactFlash drives.



And I will say again, you absolutely want to turn off your swapping.  You do not want to have a swapping file, the virtual memory on that drive.  Typically these days I think the need for virtual memory is diminishing because it's so easy to run two or three gigs of regular solid-state primary RAM on your machine, I often don't have a swap file on any of my machines that have physical drives.  It's just becoming less necessary, I think.  But you really, it doesn't make sense to have a swap file on an SSD because, even though it would offload your RAM, then you really are exercising that SSD all the time while the system is copying RAM in and out of the drive.  So that you do want to turn off.  But encryption, I think it's a good idea, and there's no downside to it.



LEO:  That's actually really good to know.  We talk a lot about SSDs on our This Week in Computer Hardware show.  If you're interested in SSDs in general, Allyn Malventano is a wiz on SSDs.  And he talks a lot about the various controllers.  The SandForce controller apparently is the one he likes the best.  There's all sorts of very interesting stuff.  And we will be talking a lot about it at CES - another plug - with Allyn.  We're doing This Week in Computer Hardware I think on Friday at around noon Pacific.



STEVE:  Cool.



LEO:  Kevin Ottum in Des Moines, Iowa offers some comments on Peter F. Hamilton books, which you and I both love.



STEVE:  Yup.



LEO:  Merry Christmas.  Avid listener.  SpinRite owner.  I heard when you were talking about the science fiction you've both been reading.  I really appreciate your suggestions.  I've read several.  I started with "Fallen Dragon" - Steve and I agree that's our favorite, certainly the most accessible - then "Pandora's Star" and "Judas Unchained" - which is a lot of work, those are long books - and enjoyed them very much.



A few weeks ago I completed listening to the audio versions of the Void trilogy - which I haven't listened to.  He says they were fantastic.  Give them another look.  I will.  In fact, I'll put them on my list.  I, too, was a bit put off by the mysticism and religious cult aspects in the synopsis.  But in actually reading the books I was pleasantly surprised.  I will remain spoiler-free, he says, but I'll simply recite one of Arthur C. Clarke's laws:  "Any sufficiently advanced technology is indistinguishable from magic."  Being a fan of hard science, I don't think you will be disappointed.  Reminds me of Heinlein.  Remember how he had cars that would grab energy from the air, and it felt like magic?  I think they even referred to it as magic.



STEVE:  Right.



LEO:  But just because it was ill understood.  Also, this takes place in the same universe as "Pandora's Star."  And since technology allows humans to live practically forever, many characters from that series return.  Well, that's good because I loved the characters.  Peter writes the best characters.  One of the thing I like about him, besides the fact that he's good, hard science, is he's extremely good at characterizations, descriptions.  He's a vivid writer.



STEVE:  So I wanted to let our listeners know, and Kevin, that I'm already up to speed with him and this.  I'm still really enjoying the book I'm reading now, the fourth in the series of the Helfort Wars, I think is the name of the series.



LEO:  Is that also Peter Hamilton?



STEVE:  No.  But I was wondering about the Void trilogy, and I did a little more digging, and I discovered the same characters from "Pandora's Star" were there, who just, as you said, Leo, I really like.  I mean, we have Paula is back, among other people who are still knocking around.  And what Kevin said, that any sufficiently advanced technology is indistinguishable from magic, he's implying that, yes, while it looks like mysticism and who knows what, it's actually technology.  So I've got the first of the trilogy, which I'm excited about because I'm looking for something really good and really long to keep me occupied while I'm exercising.  And no one can do that better than Peter Hamilton.



LEO:  Yeah, that's one of the things I really like about long books is you exercise more.  And by the way, they are all on Audible:  "The Dreaming Void," "The Evolutionary Void," "The Temporal Void."  Those are the three?



STEVE:  Yes.



LEO:  Highly rated on Audible, wow.  And they're each over 20 hours.  If you read all three of them, or listened to all three of them on Audible.com, you'd have well over 70 hours' worth of enjoyment.



STEVE:  And the good news is, they're all done.  It's very frustrating to read...



LEO:  Oh, that was hard with - yeah.



STEVE:  Yes.  He does these multivolume monstrosities.  And it's like, oh, now I've got to wait for the next one to come out.



LEO:  We finished "Pandora's Star" before "Judas Unchained" came out.



STEVE:  Yes.



LEO:  And we were just like [nervous fretting sounds].  Let's go to question #3.  Dusan Maletic in Babylon, New York suggests that "do not call" is fundamentally different than "do not track."  278 you talked briefly about "do not track" for Internet browsing and its similarities to the "do not call" list and systems for telephones.  One difference hasn't been mentioned:  "Do not call" applies to the system where every single individual is precisely defined and numbered, by your phone number, obviously.



STEVE:  Exactly.



LEO:  Hence "do not call" can be implemented without any challenges.  But the "do not track" idea on the Internet unfortunately has built-in problems.  To be tracked, you've got to be identified.  But not to be tracked also involves identification first, then a demand not to be tracked under that identity.  You cannot track who you do not know how to track.



So unfortunately, the very act of identifying yourself not to be tracked accomplishes exactly what the tracker wants most:  establishing your unique identity.  Well, that's an interesting point.  Couple that with the inability to easily determine what the other party is doing with your information.  With  "do not call," you and the government can positively track who called whom and when.  But what the backend server does with info harvested by scripts from your browser is unknown to you and the government.  The offender can claim whatever they want.  So the whole system is fundamentally flawed.  The best "do not track" option is an educated user.  Dusan Maletic.  I guess he's right.  What do you think?



STEVE:  Well, the problem is, first of all, once upon a time, when tracking avoidance was as easy as disabling third-party cookies - which is still 99 percent of the way tracking is done and still a useful thing to do, I believe.



LEO:  Oh, yeah.



STEVE:  Back then, educating the user was really all you had to do.  Turn off third-party cookies, you're not going to get tracked.  Then of course we got Flash with Flash Objects, and now we've got scripting and HTML5 that actually builds in the ability to create static tracking capability into the browser.  So we're really losing ground here in this battle, which is why I really think that it's going to be some legislation, at least in the U.S., that gives users control of this.



The good news is that - we've seen opt-out technologies, which always annoy me.  The idea is, well, if you don't want us to track you with cookies, then go click this button and get a cookie to opt out of being tracked with cookies.  Which is really what Dusan is talking about.  Now, if that was a unique cookie that you got, that obviously is really a huge problem because then you're being tracked with your unique "don't track me" cookie.  Assuming that everyone who says "don't track me" gets the same "don't track me" cookie, then you would be opaque as a group.



But the good news is all it would take is browser manufacturers, or a spec, a do-not-track spec for browsers, to create a new header, a query header.  We know that there are query headers like host, and expires if, and the main URL, and of course cookies, and a number of things which the browser is able to send out with a query.  All we need is a universal definition of another header, which would be "do not track."  And so if the user says they don't want to be tracked, they configure their browser to only issue queries with that "do not track" header.



Now, it's true that it's completely up to us trusting the other side not to be tracking us.  That is to say, does that mean we won't accept cookies from them?  Or we will accept cookies from them, but they're not going to track us with those cookies?  I mean, and this is why I think ultimately legislation is going to have to be put in place to criminalize, I mean with some serious penalties, the tracking of people who have explicitly made their intentions clear that they do not wish to be tracked.  And so we need the browser to work on our behalf, as our agent, to make that assertion.  For every single query we make, it would be flagged with "do not track this."  And then we have legislation at the other end that enforces policies of those who otherwise would wish to track us in order to give our request for non-tracking some clout.



And then we've got the problem of opting in.  Because the argument for tracking is, which I've always found a little specious, frankly, is oh, well, we need this to generate revenue.  So our advertisers are only going to pay us if we allow the people who visit our site to be tracked.  So it's like, well, okay.  I mean, it's one thing to see ads.  I've never been convinced that this whole customized ad concept works.  Have you ever felt, Leo, that you're getting ads meant for you when you go to random sites?



LEO:  Well, when I go to my Gmail, it'll give me ads that are based on the email I'm reading.  Whether that means...



STEVE:  Which is very different, of course.



LEO:  Yeah, yeah.  But that's all they can do.  I mean, okay.  So I'm looking at an email I got about CES and somebody in school.  And the ads were day trip to Kyoto, Antarctica expeditions - I am going to Antarctica.  It doesn't mention that in the email, so obviously it's keeping track of that.  See polar bears for less.  European cycling tours.  Disney's performing arts.  Transatlantic tips.  It must know that I'm going on a cruise.  So it is targeted.  Those are Google ads in Gmail.



STEVE:  Right.  And so I don't have a problem with that because they're using the context of what they know about you, not going out to a third party.  And so the argument has always - the pro-tracking argument has been that, because they will learn about who people are over time, the ads that are served by third parties will be more relevant to you.  And I have never experienced that.  You know what I mean?



LEO:  Well, they'd like to.  Look, let's face it.  That's what they want to do.  It's not that they're trying to appease us or somehow blow smoke because advertisers don't want to waste energy on advertising to people who aren't interested.  But you're right, I just went to Mashable, which has a lot of ads, and UC Davis is offering me a degree.  I guess that wouldn't be appropriate.  When it comes to support, oh, here's a web server.  Yes, you're right.  And I think that that's often the case.  But that's just because their system ain't working.



STEVE:  Well, exactly.  I think all of this is - I've always found it questionable that tracking actually works at all.  Yet it's clearly a privacy violation.  So the whole concept seems ill-advised and lopsided.



LEO:  Right.  You're distinguishing that from what Facebook and Google do because Facebook knows about you.



STEVE:  Yes.



LEO:  And Google knows about you.



STEVE:  And Google search, when you go to Google, and you put in a bunch of keywords and search...



LEO:  Right, it's tied to the search.



STEVE:  I mean, that's a brilliant, I mean, that's why Google is the size they are.  It's a brilliant use of immediate, oh, look, here's some paid ads down the column, and some things on top.  And I know what they are.  I know that they're sponsored insertions out of my search results.  I mean, I have no problem with that.  Very different from, exactly as you said, going to some random site that has ads and expecting them to be as relevant to you as opposed to somebody else.  I just - I've never seen that actually functioning, even in the days when I wasn't fighting tracking.



LEO:  Right.  Your point is tracking cookies do nothing.



STEVE:  I don't think they do anything but upset everybody.



LEO:  Right.  Good point.  Good point.  Moving to #4, Pete Burtis in New Hampshire:  One more thing for your list of "must haves" before you'll implant a chip.  We talked about putting RFIDs subcutaneously for identification purposes.  Quick and simple:  I want any implanted chip I have to be able to authenticate the remote device that's trying to authenticate me before it does anything else.  Let me load the public keys of devices I trust onto my implanted chip; or better yet, let me load my company's root certificate onto my chip.  And then I'll automatically trust every RFID door lock at my company.  If done correctly, this makes tracking you from a distance by your chip impossible because it'll ignore queries from any devices it doesn't trust, and also addresses things like replay attacks.  Sure, your device memory might be an issue.  But if it's implanted anyway, why not just make it a little bigger?  Oh, dear.  He says:  A 16-gig microSD card would implant nicely between my thumb and forefinger.  Thanks for the great show.  Pete.



STEVE:  Well, first of all, that is an absolutely great idea.  The problem is that it's not just memory, it's processing power.  And public key crypto is very expensive in terms of processing power.  We now take it for granted because we've got chips in our machines that are running at 4 GHz.  But don't forget they've got big honking heat sinks on them with fans rapidly taking all the heat that they generate off as quickly as possible.  So the only reason this technology, the public key crypto is feasible, is that we can afford to dump a huge amount of electricity into the chip, which is going to turn into heat while it's doing this processing work.



What's inherent with an implanted chip is that you certainly don't want a battery in there that is going to leak chemistry into your body, and also expire after some length of time.  So all of these chips are, from a power standpoint, they are passive in that they work as a transponder.  That is, they are excited by the magnetic field which briefly powers them enough to just barely receive something and send something back.  So at least for now, we just don't have the state of the art to bury a chunk of a computer in us.  I mean, I guess you could find someplace it would fit.  But then, still, the problem is power.  You really, you don't want something highly invasive, contacts on your skin or a socket.



LEO:  It's like a pacemaker or something.



STEVE:  Exactly.  So powering it is the problem.  I will say that, having thought about this a lot since we did the tracking podcast - and listeners I credit with reminding me about Bluetooth.  For me, I think Bluetooth solves a lot of my problems because I do have a Bluetooth-enabled Blackberry, and I could easily set up a little receiver in the garage so that, instead of a key on the garage door, I just have a button.  And the button is only enabled when my cell phone is nearby, and that's in my pocket.  So it sort of gives me - and the same thing for the front door.  So it gives me sort of the best of what I was trying to achieve, and I don't have to wait for any scar tissue to heal.



LEO:  There's another technology called Near Field Communications that Google is really pushing heavily, NFC.  In fact, my latest phone, the Nexus S, the latest Google phone, has NFC built into it.  There's very few places you can use it now.  But it's not - it wouldn't be very good for a garage door because you'd have to get out of the car.  It doesn't have much range.  It has a meter or less.



STEVE:  Right, and that's by design.  It's very low power.



LEO:  Right.  I kinda like that.



STEVE:  Yes.



LEO:  And because it's tied to the phone, you could have certificates.  You could have all sorts of information going on.  You've got a very powerful processor behind you.



STEVE:  Plenty, plenty.



LEO:  You've got lots of memory.



STEVE:  That's plenty of technology.



LEO:  I suspect that's going to win over implantation of chips.  Just, I don't know.  Call me crazy.  Let's see.  Question #5, Scott in Winters, California.  He wants to know about DDoS and spoofing the source IP.  Very few people know more about DDoSing than Steve Gibson, having fought it.  Steve, in last week's listener feedback you mentioned the DDoS - what is that?



STEVE:  Distributed.



LEO:  Distributed Denial of Service attacks and software being used by the WikiLeaks-related attacks - Anonymous was going after people like PayPal and Amazon, who had banned WikiLeaks or canceled their accounts - and how the IP addresses of the attackers are not hidden with the method that Anonymous was using.  One of the more popular tools for DDoS is a network utility called Hping at Hping.org.  It lets you send a flood of packets, a DoS attack, and spoof the originating IP address if desired.  Oh, we're getting to raw sockets, I have a feeling.  You can literally say you are Microsoft.com or 192.168.1.1 or whatever you want with a single command-line option:  "-a --spoof hostname:".  Use this option in order to set a fake IP source address.



This option ensures - it's okay for us to tell everybody this.  I guess everybody knows it.  Anybody who wants to know it knows it.  You could Google "DDoS."  This option ensures that the target will not gain your real address.  However, replies will be sent to the spoofed address.  So if you're looking for your ACK, forget it.  Most of the time people don't care about the ACK.  In order to see how it's possible to perform spoofed idle scanning, see the HPING3-HOWTO.  Yeow! he says.  I like that.



STEVE:  Well, I got a big kick out of the fact that it has its own domain.  So this is not - Hping.org, there you go.



LEO:  Yeah.  Anybody wants to do any DoS attacks, here's what you...



STEVE:  There you go.



LEO:  So does it have to use raw sockets to do the spoofing?



STEVE:  Yes.  It would need to.  So it would be unable to do that on Windows platforms.



LEO:  Thanks to Mr. Steve Gibson, by the way.



STEVE:  Yup, thanks to me.



LEO:  The reason I want to give you credit for that is you got so much heat, so many websites, oh, Steve [mumbling].  I guess Windows fanboys were mad that you were attacking Microsoft, saying you've got to take this raw socket stuff out.  It's in UNIX; it's in more powerful operating systems.  But by putting it in a consumer operating system, they were just turning Windows into an attack machine.



STEVE:  Well, and it was a mistake.  I really, I sincerely believe that it was just something Microsoft hadn't considered.



LEO:  It was on their checklist of capabilities of Linux, well, we've got to have that.



STEVE:  Well, yes.  And their 95, 98, ME, sort of that were originally their more end-user consumer line, never had full raw sockets.  You were not able to just generate any packet that you wanted to and stick it on the Internet.  The stack, the so-called TCP/IP stack, it provided your local machine's IP address automatically as that packet was leaving the machine.



What happened was that Microsoft ended the life of what was sort of originally the 16, then the 32-bit machines, and they took NT, which they had evolved into Windows 2000, and then they evolved that into XP.  And so my concern was that they were taking a more of a commercialized operating system, which did have full raw sockets, that technology existed in Windows 2000 and in NT, and without thinking, they gave it the XP candy coating, making it look more friendly because Windows 2000 was more of a server platform originally.  And so they were going to be putting it out, it was going to be preinstalled in all these machines and laptops, and it just didn't need this capability to allow software on the machine to just arbitrarily set the source IP of the packets that it was sending.



There is no, in the original Internet design, there is no defensible real reason for ever lying about the source of a packet because the whole point is communication.  And you can only have that if the remote end, the recipient of your packet, knows how to communicate back to you.  So it made sense that, I mean, it's the reason the earlier Microsoft operating systems worked so well is that they just did this for you.  They didn't have any problem doing anything on the Internet.  They were full Internet citizens without this capability.



And so my argument to Microsoft was don't let this go out into the mass market because it's just going to cause trouble.  And it really did.  In fact, it was the MSBlast worm that blasted Microsoft with their own raw sockets, at their own IP address.  And it was after getting burned by that they finally understood, oh, that's what Gibson meant.



LEO:  Right.  And there are powerful operating systems that you can do the things you need to do if you need raw sockets.  But let's not put it in a machine that's ill protected, in the hands of a consumer that doesn't understand security.



STEVE:  Well, and look how many machines are infected with bots now.  All of those bots would be capable of dramatically worse attacks.  Now, the fact is, many sites were taken down by the Anonymous group using their tool which did not do spoofing.  And so that was one of the arguments against my argument was, wait a minute, you don't need spoofing to do denial of service attacks.  That's true.  But if you don't use spoofing, then you can be backtracked.  And that is what happened for users who unwittingly were wanting to support the attack on people who were acting against WikiLeaks.  They were using the, what was it, it was that low earth orbit thing...



LEO:  Yeah, LOIC, yeah.



STEVE:  ...LOIC, in order to attack people who the group Anonymous wanted to go after.  And the consequence of that was that they were creating standard TCP connections and just moving payloads of data.  So it was just a data saturation attack.  But to create a TCP connection you have to have a roundtrip.  And if you're going to have a roundtrip of data, then you are by definition having to disclose your IP in order for that roundtrip to get completed.  So it's, yes, there are tools like Hping out there.  They run under Linux OSes are typically where they're being used.  And they work well.  And the good news is that it's becoming common enough that this is no longer fringe available.  That's why I didn't mind talking about it here.



LEO:  Question #6, Mr. Gibson.  And this one comes to us from Jim Stevens in Massachusetts:  Thanks for the incredible podcast.  I've been a big fan since the beginning.  In a not-so-distant episode, Steve described his frustration regarding the losing battle we all face attempting to make our machines secure.  I personally am sick of spending half my life making sure friends' and families' computers receive the latest updates for all software, educating them about Sandboxie and NoScript, and trying to explain why antimalware software in general is a "reactive" approach to problems, not a proactive approach.  Life is too short for this.  The analogy I use for malware is cancer.  Once you have it, it's almost impossible to get rid of.  It's much better not to get it in the first place.  I wouldn't disagree with that.



My question:  You recently spoke about completely re-architecting our machines to prevent security problems in the first place.  I think we talked about the Turing or the von Neumann model where data and code are combined versus other models where they're not.



STEVE:  Right, the Harvard architecture.



LEO:  Harvard architecture.  It seems a major cause of our problems are caused by buffer overruns in stack space.  It's true.  In your stack episode, you described how the stack is used for both the return address for functions and for data, for local variables.  If too much data - and by the way, often for code, as well.  If too much data is written to a local variable, it can overwrite the return address of the function and, if carefully designed, could cause undesired code to be executed off the stack.



Why don't we have two stacks?  One stack contains only return addresses for functions and would allow recursion and all the other functionality we use today.  The second stack could contain data for local variables.  Overflowing a buffer, while bad, would just cause data corruption, and not unintended code execution.  Of course, we'd have to synchronize the two stacks so that the correct local variables are popped when a function returns, but this problem seems minor compared to the frustration we have to deal with now. What do you think?  Jim Stevens, reinventing computer technology on the fly.  What do you think?



STEVE:  Well, I would say that's a useful idea.



LEO:  It's a restating of that same concept of not mixing data and code.



STEVE:  Yes.  And it's also the case that, if we were really good about enforcing the structures we have now, for example, we have data execution protection.  And in the Intel architecture is the so-called "non-execute bit," where any page of memory can be flagged as this should not be executable.  So even though we don't have the physical architecture of a Harvard machine - the Harvard architecture was named after the university, Harvard University Mark I computer, which used paper tape and relays.  So it was, like, a really early machine.  But there was - so there was no concept that instructions and data were the same.



All of the machines we have today, even like when we were talking about my favorite old PDP-8 back in the early '70s, that's a single block of memory which is homogeneous.  It contains instructions and data.  The instructions can refer to themselves, to their neighbors, to data.  And there's nothing, there's no division between instructions and the data.  In a Harvard architecture, the hardware itself enforces this differentiation so that instructions, even if they're, like, referring to their own location, they're not referring to themselves, they're inherently referring to data in another physical space, which may happen to be the same offset, the same address as the instruction.  But the instruction can't refer to itself.



In fact, I remember some time ago we were talking about a voting machine whose design I liked and admired because, even in this day and age, they deliberately created a Harvard architecture in order to increase the security of the voting machine so that no instructions could be executed out of the data space.  There was no way for data to, like, bring instructions along and modify the instructions that were in a physically separate place.



So, first of all, if we just did what Jim suggested, that would be a solution.  If we kept return addresses in a separate space, not on the same stack as data - and in fact there are microcomputers, smaller machines today that have their own return stack separate from a data stack.  Not really for security, this was more done just for cost saving and because they are sort of toy machines, not big industrial PC mainframe sort of machines like what we're all sitting in front of.  So Jim's idea would work.



But as you said, Leo, there are many ideas like this.  And essentially we have all the tools we need now, even with the Intel architecture, which is a von Neumann architecture, where everything is mixed together, because we are able, if we only did it right, and if we only did it consistently and thoroughly, we are able to cause data never to be executed.  And remember, we talked earlier, too, about the return-oriented programming where bad guys are able to avoid data execution protection by executing the little tail ends of existing subroutines.  So there's another example where even this doesn't solve the whole problem because it's really a big problem.



LEO:  Question #7 is Daniel in Provo, Utah:  You mentioned in Episode 278 that hard disk-encrypting ransomware is making a comeback, this time with public key encryption.  It seems that for something like an entire hard drive, known plaintext attacks may be helpful in determining the decryption key even if cipher block chaining is used.  So the potential quantity of known plaintext on a whole hard drive makes it very likely that enough information can be determined to make a strong attack and get back the original data, especially given good reverse engineering of the code that did the encryption in the first place.  In other words, the bad guys who aren't using strong encryption aren't going to be very effective if somebody really needs to get back in.



So the best remedy to avoid getting snared by these guys and to use whatever governmental remedies may exist to get their operation shut down and provide the necessary disincentive against similar operations in the future - oh, that's the best remedy.  Sorry.  The best remedy is to avoid getting snared and shut their operations down.  But the technological approach may still be helpful for some.



Thank you so much for the podcast and your other great products.  I found Security Now! a few years ago and made a point of going back and listening from the beginning.  It's been instructive and entertaining.  What is he trying to say?  I'm not sure I understand.



STEVE:  Well, he's suggesting that one of the known ways that cryptography can be attacked is if you know what the non-encrypted data is.  And we were just talking about that earlier in this podcast relative to GSM.  With the GSM system, the technology they use is a simple XORing of their cryptographic stream of pseudorandom data with the plaintext to get the ciphertext.  And it is because so much of the GSM protocol is known that, if you XORed that with what was in the air, you'd get back the cipher stream.  That's the Achilles heel of GSM when you've got those rainbow tables that allow you essentially to reverse a one-way function, go the other way on the one-way function.



What's different here is, assuming that the guys that did the ransomware did a good job, this doesn't really apply.  First of all, think TrueCrypt.  TrueCrypt is whole drive encryption.  It is, for example, what the ransomware people might use.  And it's open source.  So here you've got an industrial strength, I mean, TrueCrypt is as good as we know how to make hard drive encryption.  And it's open source.  So bad guys, I mean, as far as I know they did.  I have no knowledge of that one way or the other.  But if you have TrueCrypt out there, and they've solved all the problems for you, why not just take it and use that cryptography?



So the way TrueCrypt operates, even under a strong cipher with, like, AES, 128 or 256-bit AES, is it's taking blocks of 128 bits at a time and encrypting them.  And it is probably using, I don't remember now whether TrueCrypt uses cipher block chaining, but that's the technique where you use the results from the prior encryption, mixing it in with the next one, which creates a dependency from the start all the way down through the end of the sector, so that it's not just like you're encrypting each of the 128-bit blocks standalone, so that they would not be interdependent, but instead you're, immediately after the first block, you're mixing the results of that into the second.  And it is, fortunately, a reversible process, allowing you to perform decryption.



So the result of that is that we're sufficiently removed from the environment of GSM, that even if you had, even if you knew a huge amount of what was on the hard drive, you're still not going to be able to reverse the enciphering that ransomware does, anymore than you could reverse what TrueCrypt has done.  And we know how strong TrueCrypt is.  Governments have pounded on it, trying to decrypt the contents of bad guys' hard drives.  And unfortunately, in that case, they've been unable to.  It's just it really is the case that even a known plaintext attack against a hard drive is ineffective if the encryption is done correctly.  And with TrueCrypt we have an open source model of how to do it correctly.



LEO:  Question #8, Charles in Houston, Texas, he's wondering about something called FHSS:  I just purchased a Lorex LIVE Snap wireless video baby monitor because I found it on sale in a local store.  It looks really convenient.  I haven't opened it yet because I'm not very sure about the security of the wireless video feeds from the cameras.  That was a problem some years ago.  Somebody noticed that there was no security on those videos.  You could drive by and see anybody's baby monitor.  And the company's not responding when I ask for more information. 

 

The fellow I spoke with on the phone sounded like he was reading the information for the first time himself.  He was in a call center, didn't seem to be a company employee.  And they haven't responded to email.  Well, I'm sure they're a Chinese company.  I mean, c'mon.  How much did you pay for that baby monitor?  The only information I find about the product from their website is that it uses something called "FHSS," and they advertise that, "The long-range digital wireless signal has a range of up to 450 feet with clear line of sight and is secure and interference-free.  It won't interfere with your cordless phone, microwave, or router, and no nosey neighbors will be able to eavesdrop on you and your family."



Their lack of response of specific details violates my TNO policy.  I need more information.  My look into FHSS doesn't give me much of a warm fuzzy.  On the other hand, it isn't just a simple broadcast on one frequency that anyone could tune in to.  The convenience factor for this system is why I haven't returned it and moved on.  What are your thoughts?  Here's hoping you can help me before it's too late to return the system.  Charles.



STEVE:  Well, the acronym he's using, FHSS, is well known.  It stands for Frequency Hopping Spread Spectrum.



LEO:  Oh, well, that would be effective.



STEVE:  Yes.  So long as the bad guy doesn't have the same receiver and/or the same key.  I tracked it down, looked at the website, looked at the documentation.  The fact that they're talking about using frequency hopping spread spectrum, that's something you do, you get security from it, but you probably do it more for interference prevention because the idea, just as we were talking with Bluetooth, Bluetooth is also a frequency hopping spread spectrum technology.



In the Bluetooth case, we'll remember from a couple weeks ago that the hopping, the frequency hopping sequence, which has to be known in order to eavesdrop, is based on essentially the equivalent of the Bluetooth device's MAC address and the secret key which was established between the endpoints during the Bluetooth pairing.  At that point, then, they're able to use the clock from the master of the Bluetooth in order to synchronize themselves and agree about which frequency they're going to be on from one packet of Bluetooth to the next.



The question is, how has this technology in this I'm sure inexpensive - as you've commented, Leo, and we don't know who designed it - baby monitor, how has it been designed to create a unique hopping sequence between any two pairs of monitor and receiver, if it has been?  It seems to me unlikely that it has been.  It's probably got a clock.  The receiver probably looks at the clock and essentially has a hard-wired frequency hopping sequence.  Again, I have no knowledge of this.  I don't know for sure.  But I wouldn't be at all surprised if somebody else with the same monitor could receive your signal from yours.



Maybe not.  Maybe there's some pairing procedure, or they come from the factory pre-keyed in pairs so that you can't buy another pair, and they would be the same.  That would be great, if that were the case.  In which case, if there's any evidence of that, that there's a pairing between them of some sort, same code, for example, then I would say it's very secure.  Absent that, if another one of the same make and model monitors could receive the same signal, then it's obviously the case that all of them are running the same frequency-hopping, spread-spectrum sequence, in which case you've got good immunity from noise, but no effective security.  Probably they're set up as pairs, I would hope, in the factory, which would make them a nice device.



LEO:  Yeah.  I mean, c'mon, what are they going to see?  Presuming you're not wandering around naked in your baby's bedroom.



STEVE:  Right.



LEO:  And you'd have to work pretty hard to get it.  Aaron in Oregon says "about 154 nonillion years."  That's a number I don't hear a lot, nonillion.  That's how long the website howsecureismypassword.net says a desktop PC would take to create your Perfect Passwords, your GRC-generated passwords, which are, to refresh people, 64 bytes, right, 64...



STEVE:  Characters.



LEO:  ...characters long, including alphabetic and punctuation and numeric; right?



STEVE:  Right.  So it's saying how long would it take to crack a GRC-generated password, is what that howsecureismy password.net...



LEO:  And I presume he's talking about something like RSA or some sort of prime number encryption.  But the question is, how do you calculate it?



STEVE:  Right.



LEO:  That's his question.



STEVE:  Right.  And so the good news is, first of all, it's a fun little site.  I would commend our listeners to go check it out.  It's howsecureismypassword.net.  And don't take it very seriously, but it's cute.  You have to have scripting enabled, or it won't do anything.  In fact, it tells you in huge lettering on your screen that you have to turn scripting on, if you don't.  Even so, the lettering is pretty large.  And it's very cute.  It runs JavaScript.  And you type a password in.  And if you use any of 500 most common passwords, then it'll say, well, that's one of the most common passwords, so that's not going to take long at all.  Otherwise, as you enter your password, it's continuously estimating how long it would take to crack.  What's nice is that the source code for the whole thing is provided, so I was able to look at it and answer the question, how does one calculate something like this?



Now, the fact is there's no set rule for how you calculate this.  This site is doing a nice job, but not a fantastic job.  What the code does is it looks at the string you have entered so far.  And if it finds anything that is lowercase, then it assumes you have an alphabet of 26.  If it finds anything that is uppercase, it assumes you have an alphabet of another 26.  If it finds any digits, then it assumes that you have an alphabet of another 10 because you've got digits zero through nine.  If it finds any of a set of special characters, 13, like exclamation point, at sign, pound sign, dollar sign, percent sign, and so forth, then it assumes you've got special characters in your password from an alphabet of 13.



So that tells it in its estimate, in its estimation, how large the alphabet is from which the number of characters you have entered are taken, and it does some simple math to figure out how many combinations then.  Essentially it raises the alphabet size to the power of the number of characters you've typed, which would give us the total number of possible combinations of that password.  Then it assumes that your computer, your PC-scale machine, can test 10 million of those a second, which is pretty fast, depending upon what it's actually trying to do.  I mean, that's a lot of testing.  If you were cracking into a website, you certainly can't do 10 million attempts per second.  So again, that's why I don't take any of this very seriously.



Also this doesn't check to see whether you have alternating upper/lowercase, how many special characters you have, how many digits.  If you have one digit, it doesn't change it, really, or it doesn't give you a different calculation than if you had two digits.  So it's a sort of a simple-minded approach.  Mostly what I was interested in was what the heck is "nonillion."  And...



LEO:  It's like, well, billion, trillion, quadrillion, quintillion - how many zeroes is in a nonillion?



STEVE:  So the code answered that question for me because he has a thousand years, then we've got a million, then a billion, a trillion, quadrillion, quintillion, sextillion, septillion, octillion, and then nonillion.



LEO:  And then there's decillion, and I don't know what you do when you get to 11.



STEVE:  Yeah.  So...



LEO:  It's Latin.



STEVE:  But for what it's worth, nonillion is probably about as far as you need to go.  First of all, we're all long dead many, many nonillion years before this thing has cracked your password.  And if 154 nonillion years is the result of this calculation for one of GRC's passwords, which is 64 characters long and looks like absolute gibberish with all of those different character sets engaged, then I don't know how you get anything more complicated than that.



LEO:  Sufficient.



STEVE:  Yes.



LEO:  Sufficient is the word.



STEVE:  It is, indeed.



LEO:  Our last question, Steve.  Jared in Australia doesn't understand why software flaws are so hard to find.  Gosh darn it, every day, every month, a new flaw.  Regarding the possible trouble with BSD's security from as far back as 10 years ago - by the way, I think we're all in agreement that that was BS.



STEVE:  Yes.  Not even D.  Just BS.



LEO:  No D.  I don't understand how it's even reasonable for something that might be wrong to exist within BSD's code for that long.  Why wouldn't people know?  It's open source.  Why aren't these problems just seen and fixed, if they exist?  What am I not getting?  Well, don't confuse open source with closed source because that's a big difference.



STEVE:  That's a big difference.  But of course it is the case that - and I've mentioned this before.  And this also leads us into next week's topic, which is this fuzzing technology, which is very interesting and very powerful.  You may remember, Leo, that back when we were talking to the guys at eEye, that they had a whole roomful of machines that they were just - they were, like, throwing parameters at different network protocols and finding bugs when the machines crashed.  So they were keeping a log of what was going on.  And when a machine would crash, they would say, ooh, that's not good.  What did we just ask it that made it crash?  And can we leverage that into an exploit?  That was one of their approaches.



So that's sort of the opposite side of the spectrum from sitting down with the source code and staring at it.  And the reason that's effective where staring at the source code isn't is that source code is communication.  Source code tells you what it's trying to do.  And so when you're reading it, you're sort of agreeing with it.  You get sucked into its own intent.  The intent of the programmer is communicated through the source code.  In fact, the better the coder is, typically, the better their intent is.  We've all seen examples like Forth, which is very difficult to read.  Now I'm going to get hate mail for having said that.



LEO:  If it's properly written, it reads just like English.  In reverse.  Always.



STEVE:  And what was that, there was a wacky, oh, PL/1 was another language.



LEO:  PL/1, yeah.  APL you had to have a special keyboard.



STEVE:  And APL.  And in fact there were contests.  I'm sorry, I meant APL, not PL/1.  PL/1 was actually very Pascal-like and easy to read.  It was APL.  There were contests to see who could, like, do the most work in a single line of APL.  So incredibly dense, very powerful operators that didn't communicate clearly.  But most code, and you see this in open source code, the programmer is trying to communicate, is actively trying to communicate what the code's intention is for the purpose of, at some point in the future, communicating it to other people.  And so fuzzing, which is our topic for next week, is sort of the opposite side of that.  It knows nothing about the programmer's intention.  It's just trying to see what it can find.



And so, to answer Jared's question, as a non-programmer, I can really understand why it would be confusing that something just - you could have these bugs in code that no one can see.  And I'm, as a developer, having done a lot of bug-hunting myself, I know that I get seduced by what I'm reading.  I'm reading the intention of the programmer rather than the detail at the level that the computer executes it.  And there's a surprising difference between those two things.



LEO:  And so this leads us to next week.



STEVE:  It does indeed.  Fuzzing.  Fuzzy-wuzzy.



LEO:  Fuzzy-wuzzy.



STEVE:  Fuzzy-wuzzy had a...



LEO:  Fuzzy-wuzzy [indiscernible].



STEVE:  ...had a computer.



LEO:  Steve, well, it's been great, a great way to start 2011.  I love it.  If people have questions for next time, which will be Episode 284, if all holds true, you go to GRC.com/feedback, and you can ask those questions there.  It's not exactly an email, it's a form.



STEVE:  Yup.



LEO:  Makes it easier for Steve to parse.  But you can find many other things there, so it's worth going, including SpinRite, the world's finest hard drive and maintenance, recovery and maintenance utility.  Everyone should have SpinRite, if you've got a hard drive.  Also let's not forget all those freebies Steve gives you, that great software, including the DNS benchmarking utility, I love that; Perfect Paper Passwords, his passwords utility.  GRC, as in Gibson Research Corporation, dotcom.



Steve also has the full show notes there, the 16KB version for the bandwidth-impaired, which he himself does, edits himself with his own little hands; the transcriptions, which he pays for himself because Steve is devoted to you.  You'll find it all at GRC.com.  Steve, thank you so much.



STEVE:  Thanks, Leo.  And have a great week in Las Vegas at CES.



LEO:  We're off tonight.



STEVE:  I'm sure I and our listeners will be following you closely.  Looking forward to it.



LEO:  Can't wait.  Thank you, Steve.  We'll see you next time on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#283

DATE:		January 13, 2011

TITLE:		Bluetooth Hacking

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-283.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's security and privacy news, Steve and Leo complete their analysis of the Bluetooth security by examining the history and current status of Bluetooth hacking exploits.  They conclude with a set of recommendations for minimizing the Bluetooth attack surface.



LEO LAPORTE:  It's time for Security Now!, with Steve Gibson, Episode 283, recorded January 12, 2011:  Hacking Bluetooth.



It's time for Security Now!, the show that protects you online, your privacy, your security, your way of life.  And here he is - he's kind of a superhero.  He doesn't wear a cape.  He wears a shirt that says, "No, I will not fix your computer," Mr. Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again, as always.



LEO:  Always a pleasure.



STEVE:  Back from CES, for you.



LEO:  First time I have actually ever gone to the Consumer Electronics Show without killing myself, I have to say.  And I guess it's because I had such great help with Tom Merritt and Becky Worley and Sarah Lane, our editors Tony Wang and Jason Howell that edited and produced, and Eileen Rivera, who's absolutely the best producer in the world, produces this show for us.



STEVE:  And you came back in one piece.



LEO:  And they worked, and I didn't.  And Lisa Kentzell, who is our financial person.  And, yeah, it was just a - it was really fun to go with a team like that and hit the ground.  Tom Merritt said, "This is the most fun I've ever had at CES.  I actually got to see some of the show."



STEVE:  Very cool.



LEO:  Yeah, so it was fun.  Now, we were talking before the show, and you said you didn't see anything to knock you out at CES.



STEVE:  Yeah.  I watched you guys, and I watched the news.  And I am a BlackBerry user, so I'm interested in their little tablet.  I mean, I think I like the size that they're talking about because it's enough smaller than the iPad to be more portable, and enough larger than the iPod Touch or the iPhone to give you more browsing space for the web.  So that's interesting.  Although I didn't see what the resolution of it was.  But probably enough.  I did hear it was high resolution.



LEO:  Yeah, it's funny, I should know that.  I'll have it somewhere, and I'll find out for you.  But, yeah, just - I think that's, to me, the RIM PlayBook - I guess they're calling it the BlackBerry PlayBook - was the product of the show.  But I liked the Samsung Galaxy Tab.  I know you like Android, and that's pretty nice, too.  I think we're going to see some great Android and other - because the BlackBerry's QNX based, of all things - operating systems in addition to iOS.



STEVE:  And QNX is an old-time, old-school, really solid, strong, embedded OS.  So I was...



LEO:  And real-time; right?  It's a real-time OS.



STEVE:  Yes.  It was what people, it's what engineers would license when they needed to do, like, real heavy-duty, process-control, real-time work.  And so I was delighted when I saw that RIM had grabbed up QNX.  It's like, oh, there could be some good results from that.  So basically it was a kernel that was very mature that they've built this GUI tablet on top of, so...



LEO:  Well, wait'll you see the multitasking capabilities.  And I guess this is where having a real-time OS makes a big difference.  It's incredible.  And they've added a great touch interface.  It feels very modern.  But you're right, it's stable and well-tested.



STEVE:  And I do love that they don't miss an opportunity to mention that it runs Flash applications.



LEO:  Yeah.  Everybody says that.  I actually didn't look at the - I should have - at Flash performance.  It does have - get this, Steve - dual 1GHz processors.  So if it can't run Flash, what can?  And it's a Tegra 2 chip.  They wouldn't - it's funny, BlackBerry said we don't talk about that.  But AMD, I'm sorry, Nvidia, which makes the Tegra 2, has been trumpeting it all week.  That's an amazing processor with Nvidia-class GeForce GPU in addition to the two GHz processors, and a gig of RAM.  That's a real computer.



STEVE:  Wasn't it around the CES timing that we first really learned that Microsoft Windows was being ported over to the ARM architecture?



LEO:  Yeah.



STEVE:  Yeah.  So that's interesting, too, where they're saying...



LEO:  That was one of the stories, I think, of the show is the decreased dominance of Wintel.  And Intel's got to scramble at this point.  I mean, now Intel's completely in charge.  I'm not saying that.  It's funny because Microsoft and Intel still are the big guys.  But what you see is a movement away from them to ARM instead of Intel.  And frankly...



STEVE:  Yes, to Android.



LEO:  To Android and iOS and maybe even QNX instead of Windows.  And I think that that's telling.



STEVE:  Yeah.



LEO:  Anyway, very - there were, as always, it's one of those things where you go to the show, and it's hard to see the forest for the trees.  And maybe when you come back you start to say, hmm, ahh, hmm.  And one of the things I thought was, Microsoft had a big booth; Intel had a big booth.  But that's not where the story was.



STEVE:  Right.



LEO:  What else is on?  Shall we get to Security Now!?



STEVE:  Maybe we should do that.



LEO:  All right.  It's your show.  I'm sorry.  What...



STEVE:  I was just about to start talking about the odd Nintendo warning about young kids who aren't supposed to look at their 3D display.  And a lot of orthopedic - not orthopedic, pediatric ophthalmologists have said, what?  We're unaware of any such phenomenon that would affect eye development.  And so it's like, okay, it just sounds like Nintendo's hedging their bets and...



LEO:  It's a CYA, yeah.



STEVE:  Exactly.  They just want to say, hey, if anything ever does turn up, they'll say, hey, we warned you, we told you.  So it's like, okay.



LEO:  I'm almost tempted to put a warning on all our shows saying, if you're epileptic, don't watch because there might be strobe action.  I don't know.  It's funny, on The Screensavers we used to get emails from people saying, "I'm epileptic, and whatever that was you did really is dangerous."  And I'm sensitive to that, but I don't know what it is; you know?



STEVE:  Please don't wave your arms around at 13Hz.



LEO:  Right.  So maybe there are some people who are at risk of the 3DS.  But who knows.



STEVE:  Well, eventually we're going to talk about hacking Bluetooth.  



LEO:  Hmm.  That's our subject of the day today.



STEVE:  That's our topic for the day.  Three weeks ago we covered all of the, in propellerhead-winding detail, the technology of Bluetooth, how the protocols operate, how the crypto operates, the nature of pairing of Bluetooth device addresses and all of the minutiae of that.  And I promised then that we would next talk about the dark side, that is, the hacking side.  And there has been a huge amount of work done by the bad guys, and some of the gray hat hackers, too, people who say, well, we don't want to really do anything bad.  We're just curious what we could do if we wanted to.  So our topic today is hacking Bluetooth.  And of course we've got updates and news and even a little bit of errata.



LEO:  So let's talk.  Patch Tuesday happened while...



STEVE:  Yes.



LEO:  Yesterday.



STEVE:  Yup, couple days ago.  We had a relatively uneventful Patch Tuesday.  Just two different things were fixed.  There was a problem with Microsoft's Data Access Components, which was a critical rated vulnerability across the board.  So all versions of Windows that Microsoft is currently supporting, because that's a common component across their platforms, had some problems that they fixed.  And then a so-called "important" as opposed to "critical" vulnerability in the Windows Backup Manager.  So both of those are a little bit of a yawn.



What's interesting is that that means many of the zero-day vulnerabilities which have just surfaced, there's the CSS stuff and some other exploits that we've talked about in recent weeks, were not addressed by this.  There are, as we said, some quick-fix, single-button, click-on-the-announcement fixes for those things, which Microsoft has suggested while they're working on permanent fixes.  But I was surprised that actually we had as little done for this first update of the new year.  But that's all.  And nothing from anybody else.  Adobe didn't have anything happening...



LEO:  Because everything's perfect; right?



STEVE:  Uh, yeah.  Actually, there was news, but I thought, well, I'm not sure this quite makes the bar.  There was news of someone who found a way around the Flash 8 sandbox in Flash.  Adobe has put a sandbox around, and there was an information leakage exploit.  But it's like, eh, okay.  We're all at Flash 10, and there's a sandbox there that is not workable around in the same fashion.  So I said, okay, we'll leave that one, see if anything develops there further.  But otherwise, not that much.



We talked a little bit last week about the topic in two weeks, which is the so-called "browser fuzzing," which Michael Zalewski, who works for Google, did, which revealed more than a hundred problems across the board.  Every single browser that he fuzzed, and we'll be talking about what that is in two weeks, was found to have problems.  And you'll remember that there was some confusion because he provided Microsoft with his proof-of-concept code back last summer in July, and they were unable to reproduce the problem, so they said.  Then he ended up telling them, I mean, with lots of notice, that he would be going public with this at the beginning of 2011, as he did.  And it wasn't until halfway through December that they apparently woke up and said, wait a minute, we don't want you to do that because now we're able to reproduce the problem.



Well, it turns out, I was curious about what was going on.  And Microsoft has now said more about why they're not considering it a huge concern.  And again, we'll talk about this a little more in two weeks when we go into this in detail.  But it turns out that it takes a series of specific HTML pages to be loaded, one after the other, in order to incrementally destabilize Internet Explorer to get it to the point where the final problem of the last page to be loaded manifests in this exploit.  So they're saying, well, yes, you were able to destabilize IE, and we agree that's not a good thing.  But if you just do the page that makes it hurt, like all by itself, there's no problem.



LEO:  No big deal, yeah.



STEVE:  You have to precede it with all these other things.  Which, to his credit, Zalewski's fuzzing program does find.  And so, yeah, hopefully Microsoft's going to take this seriously and find out what's going on.  But that sort of explains how this fell through the cracks and what the controversy was between Microsoft's position and his.  And for what it's worth, I think he really did give them sufficient notice and that they probably should have been paying a lot more attention to this, rather than trying to stop him here at the last minute.



Just in sort of generic worrisome news that affects our listeners sort of tangentially, I did pick up a little note that the California Supreme Court came to a troubling ruling on Monday, January 3rd, right off the bat here in 2011.  They ruled that police can search cell phones without a warrant.



LEO:  Oh.  You know, it's funny, at CES I met three different cell phone forensic people, including the guy who did the Scott Peterson cell phone.  It's a big - it seems like that's the thing you want is a cell phone.



STEVE:  Well, yeah.  And exactly, because people have - think about our own use of the cell phone, which is why I wanted to bring this up from a privacy standpoint and technology impact.  It's really not a phone as much anymore as it is a computer.  I mean, there's email, there's texting logs, there's all your contacts.  I mean, a chunk of who you are and what you have done in the last couple years, in some cases, can be stored there.  And what is very troubling - and I don't know that this California Supreme Court ruling is going to stand.  The defendant Gregory Diaz, who was caught in a sting operation purchasing drugs from a police informant, the defense attorney intends to appeal this to the United States Supreme Court.  Because what happened was, at the time of his arrest, police seized his cell phone and found text message logs implicating him in additional drug-related activities.  And it's the Fourth Amendment to the Constitution is what protects us from so-called "unreasonable search and seizure."



The California Supreme Court disagreed with his defense, stating that cell phones are similar to personal effects such as clothing, which can be searched by arresting officers.  Which many people, I mean, this has generated a huge backlash on the 'Net and in privacy rights blogs, and even other judges have felt that, well, in fact the dissenting opinion, it wasn't a unanimous opinion, the descending opinion from the California Supreme Court argued that this really raised some concerns.  Other people are saying, well, if this, if cell phones qualify, then what's to prevent it from being PDAs and laptops, if the person's carrying them at the time of their arrest?  So anyway, it's worrisome.



LEO:  Yeah, no kidding.



STEVE:  It turns out that they likened it to a previous ruling that equated it to police inspection of a cigarette pack taken from a subject, which was...



LEO:  No, that's not.



STEVE:  Exactly.



LEO:  It's not the same.



STEVE:  I mean, a phone is now a computer.  So...



LEO:  That's like, you know what?  Liken it to the wallet.  How about taking my wallet and searching it?  How does that feel?  Is that legal?  Hmm, wow.



STEVE:  Yeah.



LEO:  This just shows you how clueless the courts are.



STEVE:  Well, the good news is we've got people standing up for our rights.  And I'm sure this will not, I mean, this is too, too troubling a ruling to go unchallenged.  So I think it's probably likely that, I mean, to me it feels like something that might interest the Supreme Court from this standpoint.  I hope that that just doesn't make it set further in stone.



Also, there was buzz since we last talked about something that's still very ill-defined and is worrisome, which is this so-called "identity ecosystem" which the current presidential administration, our Obama administration, is continuing to talk about.  Now we're apparently a few months away from them unveiling something which is, first of all, it's not mandatory, it's optional, whatever it is.  But I was reading some statement from Obama talking about how, with the increase in eCommerce - this season it was up, I think, 5.5 percent over the holidays over a year ago, which is a huge increase.  And so it's people in the government beginning to awaken to many of the things that we've talked about on the podcast, like OpenID and multifactor authentication.  And we've been dealing with the technology side of, absent any legislation, absent any formal solution, what can we do to solve the problem now? Well, even my own little Perfect Paper Passwords and similar things.  So now we're beginning to see, at the governmental level, them rummaging around and saying, well, we need to do something about this.  We need to provide solutions to our citizenry.  I just hope they don't really screw things up.  So we'll keep our eye on whatever this "identity ecosystem" is.



Many people who are following me on Twitter sent a note about something that Reuters picked up, and then it was echoed by many other news feeds, which talked about a new WPA vulnerability.  It was really troubling because it isn't a new vulnerability.  The Reuters headline said:  "A security researcher" - I'm quoting.  "A security researcher says he has figured out a quick and inexpensive way to break a commonly used form of password protection for wireless networks using powerful computers that anybody can lease from Amazon.com over the web."  So the question is, is WPA vulnerable to this new password-cracking tool?  And the answer is no.



So the story behind this is interesting, though.  A German computer security consultant named Thomas Roth essentially used the Elastic Computing Cloud, which is one of the services that Amazon offers - we've talked about AWS, the database in the sky, in the cloud, for example, which Jungle Disk is able to use.  Well, they have the ability also to do something called Elastic Computing Cloud, they call it EC2, which allows you to essentially grab or commit a large number of processors and get them all working at your beck and call.



So essentially what this guy has done is he's demonstrated the fact that, with this cloud computing, where we're actually talking about computing resource, not just storage resource in the cloud, that you could grab a bunch of computing resource that could potentially be used for brute force attacks and get the benefit of parallel computing without having to spend tens of thousands of dollars to do that.  We've talked about in the past other people have used, like, walls of PS3, PlayStation 3 systems which have very powerful graphics processing units, GPUs, to, like, do brute-forcing attacks on crypto.  So what he did was he - and I don't think I would have admitted this, were I this person.  But he says he cracked the crypto of a WPA-protected WiFi network in his neighborhood in I think he said 20 minutes.  And then he subsequently improved the technology so that it ought to be able to do it in six minutes.



So the reason this is not a concern for anyone who listens to this podcast is nobody who listens to this podcast will still be using, hopefully, an easy-to-crack password.  This is all about the password being easy to crack.  If it is random letters and numbers, and if it is long, then it will not be easily cracked by a brute-force cracking tool.  And again, the number of bits per character in a large alphabet password, that is, a password whose characters are upper and lowercase, special characters, and digits, basically just looks like just jumbly gibberish, the kind of thing that my own password generator at GRC generates for people.  Take a chunk of as much of that as you want and use that as your key, and you're safe against this.



But this does demonstrate something that actually we'll come to a little bit later when we're talking about hacking Bluetooth, and that is that assumptions have been made in the past about the available computing resource that were available, not to nation states, but to individuals.  And we've seen the walls of PS3s that have gone after cracking.  The good news is that we have so many bits, and many bits create so many combinations, that there's concerns about the future of quantum computing that's supposed to be so much more powerful.



Well, this guy, using a chunk of computing resource, was able to test 400,000 potential passwords per second.  So that's a lot more than you can test on a PC.  But it's still, that doesn't even begin to get close to the number of passwords that we're able to test or we're able to have as potential when you have a huge number of bits that is potential in the password.  So this generated a lot of news.  Anybody who's got an insecure password was already insecure.  This demonstrates, though, now that individuals for - apparently this was costing him 28 cents a minute to use that much computing resource.  So the lesson being that computing resource is now elastically available, it's rentable, and it does up the ante for the need to make sure that your passwords are bulletproof.



LEO:  Yeah, as if you needed an encouragement.



STEVE:  Exactly.  But as I was going to say, anybody who's listening to the podcast already will be using a password that is not in a dictionary and would just take, still, hundreds of thousands of years, even at this level of computing, to try your random gibberish passwords.  It's just not going to happen.



And lastly, I just thought I would check in on Firesheep and note that it has crossed a million downloads.  When I looked this morning before sending the notes to you, Leo, it was 1,043,468 downloads of Firesheep, which is the...



LEO:  Oh, man, oh.  It's not slowed down.



STEVE:  No.  It's continuing to crank along.  So that's our download add-on for Firefox which allows people to go into any open WiFi hotspot and, unfortunately, with shocking ease, hijack many of the social networking sites and other services that people are using, unfortunately, without encryption on open WiFi networks.



I did have one little bit of errata from a Swedish listener of ours who's actually located in Orangevale, California, Peter Jakubicki.  He wanted just to mention that Sony had not bought Ericsson, that Sony Ericsson...



LEO:  Partnered.



STEVE:  ...is a joint venture, exactly.



LEO:  They corrected me on - they have a new phone, the Xperia, and I said the same thing.  And they said, no, no, we're a joint venture.



STEVE:  Yup.  I'm sure back then when I first heard it, what I read was Sony bought Ericsson.  I had this clear image in my mind that big fish had swallowed little fish.  But nope, not the case.  And so he said, "We Swedes care about these details, so please fix this."  And I said, "Okay, Peter, I will definitely do that."



LEO:  Even though it's a Finnish company, isn't it?  Oh, I'd better not say that now.



STEVE:  Yeah, that's a really good point, yes.  Oops.  And I did have a fun note from a Martin Parrott, who wrote to say SpinRite had saved another system.  And he said, "Steve, I've written before, but SpinRite has done it again.  And I wanted to send another email to say how much I appreciate a great product.  A friend of mine had a machine with SCSI drives" - don't hear that that much these days anymore - "with SCSI drives installed that are around six years old.  One drive recently started showing errors in Windows' event viewer, and I took my SpinRite disk over to check it out.  Indeed, it appeared the drive was starting to fail.  The drive has always had blocks marked as bad, ever since it was new.



"I ran a Type 3 scan" - that's a SpinRite level, SpinRite Level 3 scan - "on the drive, and four hours later it finished.  I checked the status of the drive, and not only had it refreshed the entire drive, all the bad blocks had been recovered, and the map showed all sectors as good and working.  We rebooted the server, and Windows is happy again.  After a few hours of use there were no more warnings in the Windows event logs.  The machine was stable enough now to allow full backups, which could not be done before.  And it appears it will see a bit more use until new drives can be ordered and installed.  If only other software was as dependable and useful.  Thanks again.  Martin Parrott."  So thank you, Martin, for the report of SpinRite's success.



LEO:  We're going to get to - it's not snarfing - Bluetooth hacking.  It's kind of - some of it's snarfing; right?



STEVE:  Oh, well, we've got BlueJacking, BlueBugging, BlueSnarfing, BlueDiving.  We've got something called HeloMoto.



LEO:  Hello, Moto.



STEVE:  The Carwhisperer, BlueTooone, BluePrinting, and Redfang.



LEO:  Oh, my.  I love it.



STEVE:  The hackers have been busy.



LEO:  Yes, they have.  Now, let's see.  Let's snarf, or whatever it is.  Bluetooth time.



STEVE:  So when I began three weeks ago to dig deeply into Bluetooth, my eyes just crossed when I ran across the history of hacking of Bluetooth.  And I thought, okay, there's no way we can cram all of this into the same podcast.  So I decided to do the deep technology and operation of Bluetooth first and then swing back around and talk about the dark side, the hacking side, the history of all this.



If it was six years ago, in 2004, 2005, we'd be in trouble because there were, looking at sort of the characterization of the problems that I found when I looked at what had been possible in the past, it was clear that it was a case of people throwing Bluetooth onto existing platforms, like PDAs, that were not about Bluetooth, they were about being a PDA.  But then they said, oh, the competition has Bluetooth.  We'd better add that on.  So they threw in a little Bluetooth radio and dropped in a Bluetooth stack for providing the insanely complex protocols that the committees had worked out.  And they said, oh, yeah, we've got Bluetooth also.  The problem was that, I mean, our listeners, again, who are getting a sense for the nature of security and how much a conscious effort security requires, could already guess that security wasn't even a consideration, unfortunately, for these people.  Functionality was; getting it out the door; making it sell.



And so what was discovered back then was that there were all kinds of problems.  One of the developers or hackers who was looking at this in '05 had a PDA which did not need to be paired, but was able to provide filesharing functionality when it was just in discoverable mode.  So it was essentially wide open, if he left his PDA as discoverable.  So none of the security which Bluetooth always provided from the beginning was engaged in many of these early devices.



The concern is that, and I'll remind us from three weeks ago, that any connection to a Bluetooth device, even absent any pairing, does actually create a protocol flow.  It's called L2CAP.  L2CAP is the lowest level protocol which has to be established before you can do pairing, which implies that there is a handshake and a protocol level connection, even without pairing.  What pairing does is establish, allow, essentially, the establishment of a secret shared symmetric key which the Bluetooth devices on each end of the connection use in order to drive their crypto system, in order to turn the plaintext that they would be sharing into ciphertext.  But the packets always, even when they're encrypted, they contain the MAC address, the Bluetooth essentially ID, the hopefully unique ID of the Bluetooth device.



It turns out that one of the problems has been that many of the Bluetooth IDs historically were not as unique as they should be.  In some cases the manufacturer shipped them all with the same one, which was a problem because the first 24 bits of the ID identifies the manufacturer.  The second 24 bits is supposed to be unique for that manufacturer.  But that meant that, if someone noticed the make and model, or just the brand of device, they could often guess your ID.  And it turns out that even a nondiscoverable device will respond to its correct MAC address even when it's in nondiscoverable mode, which allows you to establish a connection to the device if you know its MAC address, which normally you're only able to get because the device won't respond to an anonymous query saying, hey, can anybody within my coverage range hear me?  So, okay.  So things have gotten a lot better since then.



BlueJacking, which unfortunately was - when we think of BlueJacking, we would think "Bluetooth hijacking" because that's what is implied by the use of the suffix "jacking."  Turns out it has nothing to do with hijacking.  It's that it was done first by a guy whose name was Ajack, so he named it BlueJacking because he had come up with it.  It turns out that was nothing except the ability to send unsolicited text messages to someone.  So some of the early devices would accept unsolicited text messages.  It was just the ability to pop something up on someone's screen.  And often these text messages would identify the name of the sending device.  So if you named your sending device something, for example, like "I'm watching you," then that's what would pop up on the screen and upset people.  So BlueJacking turns out to be much less of a concern than, for example, BlueSnarfing, which...



LEO:  Which sounds so much worse anyway.



STEVE:  Exactly.  Now, snarfing is 'Net slang for unauthorized copying.  When you snarf something, you're essentially sucking in information which is unauthorized.



LEO:  And afterwards you have to go "num, num, num."



STEVE:  Precisely.  So there's an interesting site, www.bluesnarf.blogspot.com, that talks about BlueSnarfing and how, when this was available, when this could be done, the Bluetooth calendars, contact lists, email, text messages, photos, basically the contents of people's phones were available.  And, for example, we all remember, in fact we've talked on the podcast about how Paris Hilton famously had her phone BlueSnarfed.  That's what was done to it.  She left it in discoverable mode.  And in her case there was a bug in the implementation of Bluetooth on her make and model of phone that exposed it to BlueSnarfing.  So in this case it required both being discoverable and having a problem with its Bluetooth protocol stack.



It turns out that the Bluetooth technology implements something that will be familiar to us old-school modem users.  You remember, Leo, the famous Hayes AT command set.  The "AT" was short for "attention."  And the idea was that you wanted to be able, with a modem, to mix commands and data through the same channel, that is, that you didn't have, like, a control command channel separate from the data channel, so that you needed a way in order to mix the commands and the data together.  And so the so-called AT command set was originally conceived to allow commands to sort of be intermixed in data and have them treated properly.  And that AT command set has survived and been extended over time.



And so a lot of what I ran across when I was looking in detail at this hacking, many of the hacking tools require Linux.  They were all done on the Linux platform, and tools were developed; source code is freely available.  But you saw a lot of AT commands passing back and forth through, essentially, the term that they used for all this was BlueBugging, which was sort of a catchall for the ability to read/write the phone's SMS store, get read/write access to the phone book.  And this was done through access to the Bluetooth AT command set which, if the phone was discoverable, and if there were some known problems with it, that sort of gave a low-level hacker access to this.  Interestingly, there are not many high-level tools, no simple-to-use GUI tools for this.  It all sort of stayed down in the hacking level.



Most of these things have now failed to be useful.  I would say anyone who's purchased a Bluetooth phone in the last couple years, or who's kept their firmware, their phone firmware up to date, really doesn't have much to worry about.  There are penetration-testing software suites available, which you can either install on phones or on personal computers running Linux, which will poll the area, look for discoverable phones, and then essentially fingerprint the phone or, as they call it, BluePrint the phone in order to determine...



LEO:  Of course they do.



STEVE:  Of course they do - the make and model of the phone.  There's a protocol called SDP, Service Discovery Protocol, which, if your phone is discoverable - you're able to make that first low-level connection over that L2CAP protocol.  Then the service discovery protocol enumerates which services that Bluetooth device offers.  And turns out that there's a lot of additional information that is leaked there which gives the hacker more of a foothold.



I talked about this HeloMoto attack, which is a classic example of the bugs that were unfortunately in the early Bluetooth implementations.  Reading from the description that I found of the HeloMoto attack, it says that it "takes advantage of the incorrect implementation of the 'trusted device' handling on some Motorola devices.  The attacker initiates a connection to the unauthenticated OBEX Push Profile, pretending to send a vCard."  And you may remember, Leo, remember that OBEX was that vCard protocol...



LEO:  Oh, yeah.  Right.



STEVE:  ...that was around where you were able to, like, beam somebody else essentially the contents of your business card.



LEO:  It was a Microsoft thing; right?



STEVE:  Don't remember. 



LEO:  Seems like it.  Maybe not.



STEVE:  Probably they had some partners because I remember certainly non-Windows devices did support that.  And so it turns out that, if you initiated a connection through OBEX, pretending to send the user a vCard, and then interrupted the sending process prior to it being finished, there would be no alert on the phone because you hadn't finished what you started.  However, this required no interaction on the receiving end.  And as a consequence, the attacker's device was stored in the Motorola phone's list of trusted devices.



LEO:  So it's done.  You always have access from then on.



STEVE:  Exactly.  Then you're essentially trusted, and that allows you to bring up a trusted connection.  And then you're able to use those AT commands to dump the contents of the contact list, to send and receive SMS messages.  Basically, you turn their phone into your modem.  And also the database in their phone you have full access to.  By initiating that OBEX send them a vCard and abort it before its being done, because this wasn't happened properly in Motorola devices, you were then added to their trusted list.



Now, the one thing, I mean, so basically I'm sure Motorola has fixed this years ago.  That's what the HeloMoto hack had been.  There are people who do something called BlueTooone to, essentially, they're talking about tuning as in tuning an antenna, where they use a high-gain antenna to hugely increase the range of Bluetooth dongles, where they'll take a little Bluetooth dongle apart and essentially hook up a coax cable to it, to a high-gain antenna.  We have talked about how Bluetooth sort of uses its limited range as one aspect of security, the idea being it's sort of, people feel comfortable with the, oh, well, this only goes 10 meters, so I don't need to worry about attacks from further away than that.  The idea being that, if this was global in distance, you'd be much more subject to hacking than just being a personal area network.  So this BlueToooning does weaken the argument that Bluetooth has limited range because there have been people successfully hacked over distances up to, for example, a mile away.  Now, the one thing...



LEO:  That's a - wait a minute.



STEVE:  Yeah, a mile.



LEO:  I thought Bluetooth was 10 meters.



STEVE:  Yes.  However, there are three different classes of radio power, Class 1, 2, and 3.  And Class 1 devices do operate over a larger distance by default.  But just as in the case with WiFi, we've also seen this with WiFi, you can take - remember the famous Pringles can with WiFi.  And essentially it's just the size that you want in order to create a directional antenna.  So inherently, Bluetooth is radiating in all directions.  And so when it's omnidirectional, you get about a 10-meter radius.  But if you took the same amount of power and made it unidirectional, that is, aimed in a tight beam, then instead of the power radiating in all directions, you're forcing it down a specific direction.  And you can, just by doing that, get much more distance out of the same radio.



LEO:  Interesting.  Wow.



STEVE:  Redfang is the name for...



LEO:  I love the creativity of hackers.  I just...



STEVE:  Yeah, Redfang.  Don't know why it's not Bluefang.  I guess they got tired of blue, finally.  Redfang finds devices that do not want to be discovered.  In other words, it finds Bluetooth devices that have not been left discoverable.



LEO:  Ooh.  That's a problem.



STEVE:  That's a problem, and it's still a problem today.  Now, what's interesting is there's been a huge evolution since Bluetooth was designed in what hackers have access to.  We've talked a few times about the notion of a wideband receiver, that is, the frequency hopping that Bluetooth does, the so-called FHSS, Frequency Hopping Spread Spectrum technology, where the master Bluetooth device uses its own MAC address, coupled with the clock and the shared secret, which it shares with the slave device, which then knows the clock and knows the MAC address of the master.  That determines the pseudorandom sequence of hopping.  And Bluetooth hops 1,600 times per second over 79 different channels, the idea being that it was believed that once upon a time this would, like, render it impossible or, you know, much more difficult to hack.



Well, it turns out that this is all being done within a relatively narrow band.  So all you need is a radio which is able to simultaneously receive all the signals within that band.  And some digital signal processing makes this whole frequency hopping a joke.  I mean, it doesn't even care that it's doing frequency hopping.  It's essentially listening to the entire Bluetooth spectrum and sucking the entire spectrum in at once.  And using very inexpensive, off-the-shelf technology now, it's possible to essentially monitor all 79 channels at the same time so that this frequency hopping spread spectrum, as a security measure, is rendered completely useless.



Now, the attack that Redfang uses is a brute-force attack on the MAC address of the Bluetooth device.  The MAC address for Bluetooth is identical in size and composition to the MAC address we're familiar with with Ethernet, which is most significant 24 bits is manufacturer, least significant 24 bits is the device ID.  However, it turns out that, when the device IDs were looked at more closely, it was found that the manufacturers, many manufacturers had gotten sloppy.  They were, for example, reusing only a subset of the potential 24 bits.  24 bits is 16 million possibilities.  So 16 million, while a lot, is not an impossible number.  Meaning that, if you knew, if you could, for example, see that somebody was using a BlackBerry or was using a Sony or was using a whatever well-known brand of phone, hackers have indexes of all of the MAC addresses associated with a phone.



Now, if the person is on the phone, then you have no problem discovering their MAC address because the MAC address is in the clear.  It's never encrypted.  It's part of sort of the wrapper outside of the encryption.  So Redfang is only necessary to be employed for devices that are not discoverable and not in active use.  But if you know the manufacturer number, then you've got the first 24 bits cold.  Then you only need to deal with the second 24, which gives you 60 million possibilities.  The problem is, for example, all of the Sony Ericsson phones start out with an E, that is, the E is the first nibble of the three bytes that compose those 24 bits of device ID.  Well, if you know it's an E, that eliminates those four bits.  So now you're down from 24 bits to 20 bits, and you've eliminated 16 times the number of possibilities, so you've dropped it down to a million.  And we know that a million, that is, 20 bits, is no security in this day and age.



So given a relatively short time, it's possible to get access to a phone through a tool like Redfang, even if the phone is not discoverable.  Once you have that, though, you are limited to what you can do without having established a pairing with the phone.  And the good news is, as far as we know, there are no existing security compromises for very popular present-day Bluetooth-enabled devices.  The stacks have solidified, the protocols are established, and Bluetooth, to a much greater degree, is not something being thrown into the mix afterwards.  It's something that, especially in today's security climate, there's much more attention being given to.



So that brings us to Carwhisperer, which is still in use and still a problem.  You may remember that three weeks ago, when I was talking about pairing, I mentioned that, in order to do secure pairing, we must have an exchange of information out of band, that is to say, through a means that an eavesdropper cannot detect.  And the way Bluetooth devices do that is they'll put up like a six-digit code on one of the screens and ask you, the pairer, the human person doing the pairing, to enter this code into the keyboard of the other device.  What you've done by doing that is you've synchronized the devices.  You've informed them of something unique which an eavesdropper cannot know.  So you've seen the screen, and you've manually moved that information, not over the air wirelessly, but using your own body you've moved that information to the other phone.  That allows them to perform a maximum security pairing.  And as far as everyone knows, there's no way to break that.



The problem is that Bluetooth, the Bluetooth spec deliberately scales security down as necessary to deal with devices that lack keyboards or screens.  Now, if you're pairing a Bluetooth keyboard, just a keyboard with no display, then you're still secure because, if you're pairing it with a computer that has a display, then that's where it's able to say, type the following thing into your keyboard.  So you type it into your keyboard.  Now, that's not going through the air, that is, no hacker can capture your keystrokes.  That's going into the Bluetooth stack on the keyboard, and it's being absorbed by the pairing technology, the pairing protocol.  Then the result of that, mixed with the computer's MAC address and a long pseudorandom number and the master device's clock, that generates the pairing.  So no attacker eavesdropping is able to crack that.



The problem is, if we come back another notch to a device that even lacks a keyboard, and/or devices with no display, so they're unable to show you a number.  Now, the good news is, to deal with this weakness, there are devices now which do not use a fixed pairing number.  But unfortunately, just the other day I was messing around with some Bluetooth speakers, and the manual said, when asked for the ID, the passcode of this device, enter 0000.  That's what it is.



LEO:  I see that all the time.  Or 1111, yeah.



STEVE:  1111 or 1234.  So the problem is that Bluetooth headsets are probably the biggest culprit.



LEO:  Yeah, because they have no keyboard.



STEVE:  Exactly.  They've got no keyboard.  They have no display.  And it turns out that, even today, if they are left in discoverable mode, or if cars, if the technology in the car for doing, like, hands-free phone is left in discoverable mode, and it turns out that, for the sake of user convenience, many of them just have that on by default, this Carwhisperer technology, which people have been successfully using from overpasses on freeways, are able to eavesdrop on the occupants of the car, just with cars driving by.  And so that is...



LEO:  That's really scary.



STEVE:  Isn't that?  Yes.  I mean, because we were talking about, we sort of laughed it off three weeks ago, saying, oh, well, if you're close enough to have a Bluetooth connection, you're close enough to hear the person anyway.  Except, if they're inside their car, and they've got Bluetooth technology for doing hands-free, and that's discoverable, then because there isn't, probably isn't a unique ID, it's possible to pair.  And unfortunately, even 0000, well, what?  That gives us 10,000 combinations - 0000, yeah, four zeroes to four nines, 9999, so that's 10,000 combinations.  So in a relatively short time you can try all of those pairings with a device.  And even if it was a random number, if it's not a long random number, you're vulnerable again.



And so that is an existing problem.  If any of these devices that used a fixed or a short pairing key are left in discoverable mode, then you can pair them, typically without any notification of their owner.  And I saw demos while I was researching this of people sending audio out and receiving audio back from those devices.



So the conclusion from all this is, with Bluetooth, pairing, the security of pairing, is our only line of defense.  The technology was designed with that understanding.  That is, remember from three weeks ago that Ericsson, who initiated this originally, then generated a handful of followers until this thing exploded, and there are more Bluetooth radios now in existence than there are 802.11 WiFi radios.



LEO:  Oh, that's interesting, wow, yeah.



STEVE:  Yeah.  I mean, it's just been phenomenal.  They deliberately wanted to create a consumer-friendly system.  So the only thing that I could wish for is that there was better discipline on the part of the manufacturers for not allowing pairing to stay enabled by default.  Yes, it's an ease-of-use thing.  I can see why manufacturers do it, because they want to minimize their tech support calls.  But it makes them vulnerable to any mistakes that they may have made anywhere else in their software.  You're just much better off if you're not pairable.



Certainly you are trackable if you're pairable.  And that's one thing to remember is Bluetooth tracking is being done.  There are devices being sold which, like by marketing-related companies, where they advertise that, stick this in your showroom window, or stick this by the door, and we will log all the Bluetooth-equipped people, customers, who come in and out, and we will let you know if they come back, having visited once before.  So it's very possible for someone to say, "Oh, hi, you were here a week ago," which would be a little unnerving, actually.  And the way that would happen is you had left your cell phone Bluetooth on and discoverable.  So pairing is the only line of defense.



Historically, pairing could be bypassed, just due to mistakes that had been made in the software, in the Bluetooth stack.  I did run across some references where hackers were talking about how it was easy to pair hack if the device had ever been paired with anything else.  Meaning that if the pairing database had an existing pairing in it, then it was easier to hack.  So what that argues for, and this is another piece of advice I would counsel, is remove any unused pairings because, apparently, existing pairings which you're not using do create a little wedge point for someone wanting to attack your phone.  So rather than just letting them accumulate forever - which they would otherwise probably tend to do.  I noticed the other day I had four or five in a little laptop of mine from some mice that I was experimenting with once, that I had long since stopped using.  So now it is useful to remove pairings you do not need.



LEO:  Good to know, yeah.



STEVE:  The other exploit against Bluetooth involves someone briefly having access to your device.  So, for example, kids or spouses or ex-boyfriends or girlfriends or something, you want to make sure that you have removed - again, it's another reason for removing unnecessary or unexpected pairings from your device.  If someone briefly had access to your phone, paired it with their Bluetooth radio, and then gave it back to you, then that pairing persists.  So one vulnerability is that pairings would sneak into your Bluetooth-equipped device without your knowledge, which would then give them access to that device in the future.  So it's worth looking to see - and as far as I know, all display-equipped devices will allow you to look at the enumeration of devices that have been paired with it.  And it's worth just removing any that you don't need.  It's very much sort of like changing your password after employees that knew it have wandered off.  You just don't want to allow that access to persist.



Let's see.  So remove any old ones.  And finally, as I said three weeks ago, turn off the Bluetooth completely if you're not needing it.  Just not having it on at all will save battery power.  And that's the only real way to be completely invulnerable to any kind of mistakes that the manufacturer may have made, any mistakes, human error, pairings that were left in that create vulnerabilities.  Just having the radio off completely is really your final line of defense.



LEO:  Yeah, most people don't do that because you want it to join automatically, when you get in the car or when you get within range, you want it to join up.  So turning off the radio is, hmm.



STEVE:  Yeah, I know.  Again, it's a function of use.  If you're a person who's not using a Bluetooth headset all the time...



LEO:  Turn it off.



STEVE:  ...then turn it off.  If you do need it on for convenience, you really do need to leave it on, but absolutely make sure that it is not discoverable because that can potentially create some problems.



LEO:  Yeah.  I mean, if you have a smart phone, you're probably turning - if you want to save your battery, you're probably turning off Bluetooth whenever you can anyway.



STEVE:  Right.



LEO:  You shouldn't have it running for no reason.



STEVE:  So the takeaway from all of this, from the research I did into the dark side, is that it's technology which is mature enough now that, if you take a few precautions, you're really safe.  There are no known really bad security problems today in Bluetooth.  I was carefully looking at the dates of all of the hacking stuff that I was finding, checking to see whether these problems had been solved.  Just across the board, it's a technology that I'm actually very bullish about.  I think it's very useful, very handy.  If you keep your phone or your devices nondiscoverable, you're really going to be very safe.



LEO:  Good to know.  Steve, you're so good at this stuff.  Thank you for giving us the - the thing is, I know when people listen to this show, and you cover a topic like this, they know they've got it; that, you know, that's the landscape.  There's nothing left off.  So thank you for doing that.  Next week, Steve Gibson, it's a Q&A.



STEVE:  Yep, we'll do a Q&A.  I'll ask all of our listeners, again, to send any thoughts, questions, comments, stuff, to GRC.com/feedback.  And I will check the mailbag and update everybody on any other news of the day.  And we'll have some fun dialogue with our listeners.



LEO:  Always.  I love the mailbag episodes.  GRC.com/feedback.  While you're at GRC, of course, check out SpinRite, the world's best hard drive maintenance and recovery utility.  Check out all of Steve's freebies, too - ShieldsUP!, Shoot The Messenger, DCOMbobulator, Perfect Paper Passwords, the DNS benchmarking utility and a whole lot more.  It's all at GRC.com, along with show notes, 16KB versions for the bandwidth-impaired, and transcripts thanks to Elaine.  It's all there, GRC.com, Gibson Research Corporation.



I should give you a little plug, since you mentioned your Twitter handle.  Steve is @SGgrc on Twitter.  He also has a - I don't know, did you tweet with the CES stuff at...



STEVE:  No, I really didn't find anything that I felt was tweet-worthy.  I do want to reiterate that I'm getting great feedback from my Twitter followers.  I crossed the 16,000 level a couple weeks ago.  And, I mean, I read all of the @mentions that are coming in.  And, for example, some of the things that we talked about today I first picked up on from Twitter folks.  So I really appreciate that.  It's a great way of getting little thoughts and notes back to me.



LEO:  And, by the way, Ericsson is Swedish.  Nokia is Finnish.



STEVE:  Oh, that's right.  Yup, good.



LEO:  That was me, not you.  But we just want to forestall some emails for next week.  Thank you, Steve.



STEVE:  Thanks, Leo.



LEO:  Have a great week, and we'll see you next time on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#284

DATE:		January 20, 2011

TITLE:		Listener Feedback #109

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-284.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 284, recorded January 19, 2011:  Your questions, Steve's answers #109.



It's time for Security Now!, the show that covers your security and privacy online.  And here he is, ladies and gentlemen, the man in charge, the key keeper, Gozer, the Keymaster - no, Steve Gibson of GRC.com, the Gibson Research Corporation; the creator of SpinRite; the man who discovered the first spyware, named it spyware, and created the first spyware fighter, a task which he has handed off, of course, to many other companies since.  Hey, Steve.  How are you today?



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  A Q&A today.



STEVE:  Yes, our 109th Q&A for Episode 284.  And not much has happened, happily.



LEO:  Yeah, that's always good news.  No news is good news in the security world.



STEVE:  Exactly.  I'm never complaining when that's the case.  We have, I mean, the other culprits, we had Microsoft, of course, with their second Tuesday, Patch Tuesday as it's become known, last week.  But Adobe and, I mean, I imagine Google's Chrome browser is probably continuing to sneak forward and just keep itself updated in a stealthy fashion, as they have designed it.  But we've got a little bit of news and some errata, and then 10 great questions and comments and thoughts from our listeners.



LEO:  We should remind people that every other show we do a Q&A, and you can always leave your questions for Steve at GRC.com/feedback.  And that's where you got the questions for today.  Steve culls the questions.  We'll get to those in a second.  But what's happening in the - there is some security news.



STEVE:  There is a little bit of news.  I noted, actually I chuckled to myself because our listeners may remember that last week on our podcast I made the claim or the statement that, given what was still coming out about the Stuxnet worm, which was believed to have been designed specifically to go after Iran's nuclear enrichment program, when I learned that it was masking its presence by sending back information to the monitoring systems indicating that the systems were still running, that the centrifuges were still running at the specified and correct speeds when in fact it was screwing around with them to make them run faster so they would damage themselves, I said, okay.  If this is all the case, there's no way that this wasn't tested extensively beforehand by someone who had access to exactly this equipment.  That is, you could not theoretically design this software just from specs and not put it through extensive testing.



So what I got a kick out of was the front page story of The New York Times Sunday said that Israel and the U.S. - and it named the locations where exactly this equipment was set up and used for developing and testing the operation of the Stuxnet worm.



LEO:  They had the centrifuges.  It was exactly what you posited two weeks ago.



STEVE:  Right.



LEO:  In fact, somebody sent me an email saying, "Well, the Times finally caught on."  So, well done, Steve.  You predicted it.



STEVE:  You just couldn't design something that was this specific to this hardware without having, like, a lab set up that had exactly, I mean, a prototype of what existed in Iran had to be somewhere else.  And so, and I noted that John Markoff was among the reporters that was in this.  And of course he's been with the industry for a long time.



LEO:  He's the most technically sophisticated reporter in the business, mainstream reporter in the business, I would guess.



STEVE:  Then I got a kick out of another little bit of news, and that is that on June 8th, which happens to be a Wednesday, so we'll be recording a podcast on June 8th, is the first global-scale IPv6 trial date.



LEO:  Yay, we can be there.  It'll be like the Y2K; right?



STEVE:  Well, and what I noted was it's like, wait a minute, we're running out of addresses in November.



LEO:  Yeah, they're not wasting - they're not, hmm, getting on it that quickly.  You know we're going to have iPocalypse November; right?  I mean, it's just going to melt down; right?



STEVE:  Well, actually one of the questions that we'll be getting to later on in this podcast is what exactly is it that's going to happen when we run out.



LEO:  Right.  Good.



STEVE:  And so...



LEO:  Imageddon.



STEVE:  ...we'll talk about this.  So what's happening on June 8th is that Facebook, Google, Yahoo!, Akamai, and Limelight, at least those five services, are going to be making their facilities available over IPv6.  Now, actually Google has had search on IPv6 for quite a while.  You could, if you had an IPv6 address, you could go to ipv6.google.com and come into Google through IPv6.  So they're already been there.  But the idea is that, for 24 hours on June 8th, all of those services will be available specifically through IPv6.



And again, while that's good, I mean, this should have been, like, a year ago.  And so it's like, okay, I guess, I mean, it's like, well, let's see, June, July, August, September, October, November.  I mean, we're guessing November timeframe for running out of this.  And I saw someone trying to explain to someone who didn't get it what IPv4 depletion was.  And I had tried to describe it myself to some friends not long ago.  And someone said, well, just imagine, like, the phone system running out of phone numbers.



LEO:  Which it kind of did.  Remember, we got all those new area codes?  That's what happened.



STEVE:  Exactly.  The original structure, it used to be, for example, that an area code, the center digit was either a zero or a one, which is why we had 714, 405, 213...



LEO:  Right.  And the bigger metros had a one because it was faster to dial a one than it was a zero on the dial.



STEVE:  And the primitive electromechanical dialing systems, they used that key of whether the center digit of three was a zero or a one to determine whether it was an area code because none of the prefixes had that.  And so that allowed them to disambiguate those two things.  But the other thing, the other place where we ran out, remember the 800 numbers.  It used to be that toll-free numbers were only 800 and then something.  Well, they did run out of 800 numbers and then had to add [888] and a few others.



LEO:  Oh, right, yeah; 888, yeah.



STEVE:  So we've sort of seen that before.  But anyway, so we'll talk about the consequence of that later in the show.  But I did sort of think, yes, well, it's good that we're having a global-scale trial of IPv6 this summer.  But it does seem a little bit late for relative to, you know...



LEO:  I can't wait.  So a little later on in the show we're going to find out what that means, what the consequences would be in November or whenever this runs out.



STEVE:  And then another very good piece of news, apparently there has been pressure from the Federal Trade Commission, FTC, the U.S. FTC and others about the fact that Flash is being so pervasively used to store tracking data in the so-called LSO, the Local Storage Objects which Flash supports.  And we've talked about the fact that there are companies that specialize in reconstituting deleted browser cookies from the so-called Flash cookies, which are these LSOs, and that there's no obvious or simple user interface for Flash.  Flash is a browser plug-in, so it's sort of transparent.  You go to a site that's using Flash, and things happen.  Ads jump around.  In fact, their whole website could be Flash-based, as is the case in some cases where - but Flash itself doesn't have a user interface.  It's just meant to be used as a plug-in.



So what Adobe has done, and I'm led to believe that Chrome within several weeks will be the first to have a UI for it, Adobe has published an API, an Application Programming Interface, for access to their local storage objects for the sake of allowing them to be deleted by browsers which could be providing a user interface to that, Chrome apparently being the first.  But Mozilla, Google, and Adobe - I'm sorry.  Mozilla, Google, and Apple teamed up with Adobe to do this.  So I would imagine that Firefox will offer the same sort of thing very quickly since they were part there, and presumably Apple with their Safari browser.  So that's just good news.  That gives users the ability to do this.



The reason browsers are involved at all is that browsers are essentially presenting this facility through Flash to the user.  So it does make sense, since browsers have a mature user interface of controls and settings and toolbars and so forth, why not allow the object which is instantiating the Flash object, which is the browser, to also give it the control that it otherwise lacks?  So that's good news.  We'll keep an eye on that.  And as announcements of browsers that are supporting this LSO deletion occur, I'll let our listeners know.



LEO:  Very good.



STEVE:  I've been a user of the eBay and PayPal dongle, which we talked about quite a while ago, ever since we talked about it.  It's that little football, as we've often referred to it, which you press the button, and you get a six-digit code, which you then enter into, for example, PayPal when you're logging into PayPal to authenticate yourself.  It's a one-time password approach that gives multifactor authentication.  But the problem is, being a physical token, if you ever want to, for example, in my case, purchase something on eBay or through PayPal when it's not with you, that's a problem.



Just the other day I decided - I was, like, browsing around and noted that VeriSign, which is the source of these things, supported a BlackBerry client.  So I added it to my BlackBerry and was very pleased and impressed with how simple this is, and essentially how functional it is.  And this is now available for many of the different smart phones.  I didn't think ahead to check to see if it's Android.



LEO:  Yeah.  I think it's - yeah.



STEVE:  I think it's iPhone.



LEO:  I think both.



STEVE:  I know it's - yes.  And so essentially, when I run this on my BlackBerry, run the little app, it comes up and shows me the serial number for this instance, which is unique, of this instance of this little authentication app that I'm running, and a six-digit code, and also shows me a little expiration timer, which counts down from 30 seconds.  And every 30 seconds it changes this number.  And so they show me that so that I'm able to see whether I have time to type it in before that expires.  And I simply registered the serial number that was presented on the screen with PayPal, telling them, look, I have a second authentication dongle now.  And now I'm able to do the same level of multifactor, one-time-password-style authentication wherever I am because I've always got my BlackBerry with me when I'm out roaming around.  So...



LEO:  Yeah, I think that's better than a dongle, I really do, because...



STEVE:  I agree.



LEO:  ...people have their phones all the time.  I really like doing it that way.



STEVE:  Yes.  I think it's terrific.  And in fact now I'm back having to tell PayPal which of the two objects I'm using, which is annoying because it makes me go through that step.  Whereas when I only had one of them, it knew which one I had, and that allowed me to just add that six-character or the six-digit passcode after my password in one phase.  So I'm now seriously considering deregistering my football and always using my BlackBerry.  So I wanted to let our users know that this has all actually really happened.  Because I know when we talked about the football originally there was a huge amount of interest in it as an opportunity for increasing security.  And now that VeriSign has pushed all these little clients out to smart phones, as you say, Leo, it's just a terrific solution.



LEO:  Yeah.  Yeah, it is on my Android, I believe.  And I believe I saw an iPhone app, so I think it's everywhere.  I mean, it would only make sense.  If they're going to put it on BlackBerry, they're going to put it on iPhone and Android.



STEVE:  Right.  Probably first, in fact.



LEO:  Yeah, exactly.



STEVE:  So finally, in errata, I got a note from someone who didn't disclose his full name.  He called himself Ken F.  He's a cybersecurity manager with an undisclosed government agency.  And he said:  "Steve, huge fan of TNO" - which of course is my acronym for Trust No One - "and been listening for the past two years" to Security Now!.  "A few episodes ago you were discussing the exfiltration of the data from the government's classified networks relating to WikiLeaks.  I wanted to provide you the correct pronunciation of that classified network."  I was calling it sy-per-net, SIPRNET.  And he sort of breaks it up phonetically, and he says it's pronounced sip-per-net, so SIPRNET.  He says, "Thank you for all your stellar work in this field, along with breaking down the many complex issues to usable and understandable chunks."  Ken F., cybersecurity manager from an undisclosed government agency.



LEO:  I love that.



STEVE:  So, SIPRNET.



LEO:  SIPRNET.



STEVE:  Now we know.  And I did have a short little note from another listener of ours, Tom Leonard, who said he wanted to drop a note to let me know about SpinRite.  He said:  "I just recently purchased it as I provide computer tech support for the South Dakota School of Mines and Technology in Rapid City, South Dakota."



LEO:  I always loved that name.  It sounds so 18th, so 19th Century.  Mines and Technology.



STEVE:  Yeah, South Dakota School of Mines and Technology.  He says, "I found out about" - well, it's sort of like 3M, you know, the well-known 3M Corporation?



LEO:  Right, Minnesota, what is it, Minnesota Mining and Milling?



STEVE:  Manufacturing.



LEO:  Manufacturing, yeah.



STEVE:  Yeah, that's what 3M actually stands for.  It's like, okay.  Good thing they shortened it.  Anyway...



LEO:  And you know KFC stands for Kentucky Fried Chicken.



STEVE:  Right.



LEO:  They didn't like the "fried" part anymore, yeah.



STEVE:  "I found out about your product from watching you and Leo on the TWiT network," which is what's happening right now.  "Specifically, your Security Now! segment.  I truly missed Leo and his time he spent on The Screensavers and Call For Help.  But now I think he's found his niche and is truly the best for us geeks.



"Anyways, on to my story.  I purchased your product about six weeks ago and thought, when am I going to try this out?  Well, this morning I went to boot my personal Netbook, and the Blue Screen of Death shows up.  Well, since there's no floppy or CD drive, I had to create a bootable USB flash drive.  The first flash drive I tried wouldn't boot, so I went to your FAQ page for SpinRite and found that some flash drives don't work properly.  So I tried another flash drive.  This one worked fine and booted right into SpinRite.



"I ran the recovery and repair level, No. 2, I believe, and it started checking things.  It got to about 7 percent and just seemed to stall, but it appeared to be continuing to work.  It moved the files and sectors, declared one sector to be unrecoverable, but apparently recovered most of that sector's data.  After about four hours total, it finished.  I rebooted, and up came the computer.  It now starts up and shuts down much faster.  So this area of the disk must have been going bad for a while.  Steve, thanks again for SpinRite.  And I plan to keep on watching you on TWiT with Leo.  Thanks, Tom Leonard."



LEO:  Aw.  I think that's generally the case.  A lot of people complain about their systems slowing down.  And many times it's merely one or two bad sectors on the drive which Windows spends a lot of time trying to read in order to boot or whatever.



STEVE:  Exactly.



LEO:  So moving stuff off of that one sector can make a huge difference.



STEVE:  And then SpinRite will remove that sector from use, causing the drive to swap in a spare.  SpinRite will then replace the data.  And one of the things that SpinRite can uniquely do is, even if it's finally absolutely unable to recover every last bit of data, it will return as much of the 512 bytes as it was able to read, even if not all.  And sometimes that makes a difference.  It'll let you know that that's what it did.  But, for example, if that's a chunk of directory space, it may actually be that the part that it couldn't read wasn't necessary, but was just slowing things down.



LEO:  Could be slack space, yeah.



STEVE:  Even an unrecoverable sector, it's able to get most of it.



LEO:  Right.  Rob in Melbourne with our first question of the day.  Are you ready, Steven?



STEVE:  Absolutely.



LEO:  He says:  NoScript is already adding do not - I shouldn't do my Australian.  It's terrible.  And every time I do it, I get an email from somebody saying, "Hey, mate, we love the show, but don't try to talk Australian."  Steve, just thought I'd drop you a line to tell you that NoScript seems to be adding headers to my HTTP queries regarding web tracking, specifically a header "X-Do-Not-Track" and "X-Behavioral-Ad-Opt-Out."  Cheers from sunny Australia, Rob.



STEVE:  Well, when I saw that...



LEO:  First of all, somebody has to abide by those headers; right?



STEVE:  Well, yes.  You may notice that, I mean, I've asked for this, I mean, suggested that this would be a great solution for dealing with the problem with tracking.  But this was the first I had heard that NoScript might be doing that.



LEO:  But is this a standard?  I mean, are these headers standard?



STEVE:  No.



LEO:  No.



STEVE:  Well, so, but that's fine because we have a chicken-and-egg problem here.  I mean, someone has to start doing this so that these things exist.  And so I fired up my packet capture, refreshed a Google search page that I had up, and sure enough, those two headers are being, ever since the 28th of December, 2010, so not yet for a month, so I think it was v2.0.9 is when Giorgio added this to NoScript.  And so I shot him a note saying, "Hey, this is fantastic," and we corresponded briefly about it.



What he wrote on his posting was, he says:  "From now on, a web browser with NoScript installed warns every HTTP server it contacts that its user does not want to be tracked, i.e., that his data must not be collected for profiling and persistent identification purposes.  I believe this is a safe assumption about the feelings of most, if not all, NoScript users.  As stupid as it may sound (why parties who are interested in tracking you would comply?)...



LEO:  True.  I mean, it's not in their interest.



STEVE:  Correct, "...a means to clearly express your will of not being tracked is going to be useful, especially when backed by law or industry self-regulation, as explained here.  Therefore, it seems in the interest of NoScript users and privacy-concerned netizens in general to participate in this effort.  In its current release, NoScript allows the 'Do Not Track' feature to be disabled or tweaked by opening about:config and editing the noscript.doNotTrack.* preferences...."



And so he's got three preferences where you can enable it, the whole system, or not, meaning that you could disable it if you just didn't want that to be added to your queries.  Then you can list a set of URL patterns, which are space-separated, of destinations, query destinations which are not to be sent the do-not-track-me message.  And then you can also - so that's called "exceptions," where you can have exceptions to the add-the-do-not-track header.  And then, thirdly, you can force specific ones that do qualify to still be forced.  And he says, a graphical user interface, "A GUI for these options, and possibly finer grained controls (e.g., to allow some or all of the third-party trackers on certain websites only) will be added in future releases."



So anyway, I just - this is great.  This is something - we know, for example, do-not-track legislation is being considered.  There's talks of this happening.  I can't think of a better place, as I have said often before, than for our browsers to simply add a header that says "I do not want this query to be tracked."  And it's here.  So, yes, it's true, no one obeys it yet.  But we have to have it for anybody to obey it.  So it would be great, for example, if Safari and Chrome and Opera and the other browsers, and IE, were to pick up on this and implement the same thing.  Then it would be a simple matter of legislators saying, look, if somebody has this in their headers, you're not to track them.



And then of course sites would have then the ability to say, well, we really do need tracking in order to support ourselves.  So then they would be able to present to the user a notification saying, whoa, you've tried to enter the site with tracking blocked.  You're going to have to make an exception for us if you want our content.  In which case the user could decide, eh, don't need it that much, and vote by saying no, thanks.  Or they'd say yes.  And then, again, Giorgio and other UI designers could make it simple to add an allow-tracking exception on a site-by-site basis.  So if this all happens, we're beginning to get to where we want to be.



LEO:  Another great reason to use NoScript.



STEVE:  Yes.



LEO:  You know, just as a side note, I've seen these X headers in email.  You can have an arbitrary X header in email.  And whether the server sees it or not or acts on it or not is completely up to the server.  I didn't realize you could also do the same thing with HTTP requests.  It's the same mechanism, I guess.



STEVE:  Yes.  The idea is that the X- as the prefix says this is not part of the standard.  So, for example, we'd have query headers, for example, like the expires or the referrer, the HTTP referrer header.  And so any query does have headers which are part of the so-called metadata.  There's not something that the user sees, but it's something that the browser is sending.  And in the spec it says non-spec-specified headers, that is, sort of optional headers, can be included just by sending X- and then the header name.  And in this case what I saw in the packet capture was that they were the header:1 for X-Do-Not-Track, and the same thing for X-Behavioral-Ad-Opt-Out was a :1, so essentially saying true that I do not want to be tracked.  So, yes.  Exactly in analogous fashion, as you said, Leo, to email, this can be done.  I know, for example, because I've done a lot of work over in NNTP, the Network News Transport Protocol that newsgroups, for example GRC's newsgroups, use has the same sort of facility.  And I invented some headers for our own purposes that run in the same vein.



LEO:  Okay.  Question #2, Jamie in England - I won't do an English accent, either, or a phony one, anyway - wonders about IPv4 doomsday.  Steve, when you were recently talking about IPv4 address depletion, you said that the day we run out of all IPv4 addresses would be doomsday.  Well, how can this be the case?  Surely all the equipment we already have on the 'Net will be fine and continue to talk to each other.  It's just that no one new will be able to join us.  Am I correct?  So it's only a mild concern; right?  Could the new clients joining the 'Net not simply go through an IPv4 proxy to talk to the rest of us?  Thanks, love the show, keep up the good work.  So what does it mean, IPv4 Doomsday?



STEVE:  Okay.  So first of all, I wasn't...



LEO:  I guess we should say upfront, just to set the stage, anybody that listens to the show I'm sure knows that IPv4 dotted quad allows for, what is it, two billion addresses?



STEVE:  Four.



LEO:  Four billion addresses.



STEVE:  4.3 billion different unique IPs.



LEO:  Every computer that is on the Internet has to have a unique public address, just like a unique phone number.  And we're running out.  We've gone through, we'll have gone through four billion addresses in November, roughly.



STEVE:  Right.  Essentially, back when the Internet was being designed, there was - it's very much like the same story with RAM.  Remember that, for example, the Apple 4 allowed you, the original - I mean, Apple 4.



LEO:  II.



STEVE:  The original Apple computer allowed you to have 64K of RAM.  And we all knew no one would ever need more than that.



LEO:  Plenty.



STEVE:  Plenty, exactly.  I mean, what could you possibly do with more than 64K?  So this is not the first time we've ever, like, run out of resources one way or the other.  We tend to do this because the technology lives much longer than we expect.  It ends up not being obsoleted as quickly as we expect.  It just wants to grow forever.  So back when the original designers established 32-bit addresses, even then they allocated it inefficiently.  So there are big chunks of that 4.3 billion addresses which cannot be used.  We've talked about this several times in the past, so I won't go all the way through it.  But we are, around the end of this year, running out of space.



Now, if I ever said "doomsday," then I'm not happy with myself for having declared it doomsday because it's not doomsday, just exactly as Jamie in England asks.  It is exactly like you suggested, Leo, if we ran out of phone numbers.  Well, if we ran out of phone numbers, then people wanting new phone numbers would have a problem because all the existing phone numbers would be in use.  But the ones that were already there would still work.



So the bad news is that the transition from IPv4 to IPv6 is going to be an incredible mess.  There isn't an elegant way to do it.  I think it's one of the reasons everyone is dragging their feet as much as they are, the reason we're not even doing this full global test of only five large sites until summertime.  It is a catastrophe just that everyone wishes and is hoping somehow we're not going to have to address.  I mean, even for me, my entire infrastructure, GRC.com's infrastructure is all IPv4.  ShieldsUP!, all the code that I've written, all of my packet management stuff, everything is 32-bit IPv4 addresses.  And so the day that I have to bite the bullet and implement this as all IPv6, I'm not looking forward to.  I mean, I can because I wrote all this code.  It's all my own raw packet stuff.  So there's nothing preventing me from manufacturing IPv6 packets except I'm going to have to go off and write a whole bunch of code that I'm not looking forward to.



So certainly on this podcast during 2011 - as I have said before, 2011 is going to be the year that IPv6 really does happen - we will be talking about transitional things a lot.  We'll be talking about the conversion from IPv4 to v6, proxying and NATing and gateways.  There are things like IPv4 tunneling, where you tunnel IPv6 content through IPv4 through network segments that aren't IPv6 aware, but they still can support tunneling.  I mean, it's just going to be a real nightmare.  So we'll have lots to talk about.



Obviously we'll get there someday because this IPv4 depletion really is going to be putting, finally putting a lot of pressure on our ISPs and network engineers to start taking this very seriously.  Everyone, including me, has been able to ignore it until now and wants to continue ignoring it as long as we possibly can because it's just going to be a lot of work without any feature change.  Basically, it's not like we get anything, any great new benefits from it.  It's just a lot more address bits is essentially all that happens.



So the world doesn't end.  And I'm sure what we're going to see is IPv4 having a presence on the Internet probably forever.  I don't think it's ever going to go away.  It'll just be always there.  I hope I get to keep all my IPv4 IP addresses, and IPv6 users will still be able to get to me that way.  So, and I already have had people asking, hey, when is ShieldsUP! going to support IPv6?  And it's like, uh, I don't know when.  But...



LEO:  So is there a workaround if somebody - okay.  So in November we run out.  And...



STEVE:  Okay, so for example...



LEO:  Well, everybody has pools of numbers that aren't allocated.  So your Internet service provider probably has plenty of free numbers that they can allocate.



STEVE:  Yeah.  Look, for example, at cell phones.  You could argue that cell phones are probably a class of device that really doesn't care what its IP address is.  The user doesn't even know.  There's, like, there's no transparency to the end user about the IP address of a cell phone.  So that's a place where you could easily - a high-growth place because that's where lots of these, like Verizon is adding support for iPhones.  And so that's a place where you could easily sort of transparently bring up IPv6 in a way that end users would not be made uncomfortable at all.  And so, yeah, a place where you could have a huge increase in space.



LEO:  Okay.  I guess I won't worry about it.



STEVE:  It'll just happen.



LEO:  I'll let you wise guys figure it out.



STEVE:  And we'll be talking about it all year long.  It's going to continue...



LEO:  Oh, yeah.  There'll be a lot to say.



STEVE:  ...coming up.  And in fact, what I'm planning to do, when we do, as we will this year, as I've promised, our from the ground up how the Internet works, we'll have a huge chunk of new content which we've never discussed, which is IPv6, all the gory details and all the transitioning nightmares that we're going to be going through.



LEO:  Woohoo.  Question #3, Tom Zerucha in the Detroit area brings up a good point about SSDs, encryption, and the TRIM command:  Steve, if the whole disk is encrypted in such a way that every sector is marked used, it will increase wear and maybe slow things on SSDs since it will have to shuffle full blocks.  If only the used sectors are encrypted, instead of the whole disk, then the TRIM command can work to erase blocks for the unused sectors.  Windows 7 is, of course, the only OS that currently supports TRIM.  This will make it faster, more reliable.



By the way, I guess we should explain that there's a weird effect on SSDs that kind of is like fragmentation, and it can - slows the SSD down.  I asked at CES, I talked to two of the guys responsible for Intel SSDs.  And Intel is really the crme de la crme of solid-state hard drives.  And we're talking about those flash-based hard drives.  And I asked about TRIM.  And Windows 7 is the only OS that supports TRIM.  And most of the controllers, except for the SandForce controller, maybe a couple of others, don't support TRIM anyway.  So most hard drives don't support TRIM.  And they said, well, what happens with most hard drives is there's this peak theoretical speed.  There's a drop as you use it.  And then it levels out, and it pretty much stays there.  All TRIM does is get it back.



They actually, the two guys debated each other.  One guy said, oh, it's important.  The other guy said it's not important in real world.  So there is debate even whether you need TRIM.  But now let's continue on with your answer.  I'm sorry, I didn't mean to interrupt.  But I just thought that was kind of interesting.  They don't even agree.



STEVE:  Yeah, that's great background, which I didn't have.  I have the low-level technology side of it.  So here's the deal.  Tom's question is a good one, and it raises a very good point because he's responding to my answering a question two weeks ago about the whole idea of full-disk encryption on an SSD.  And I think the question was would that slow things down in the same way that fragmenting might on a hard drive.  And I said no because, once you were encrypted, the whole drive was encrypted, then you were just reading the same sectors from the SSD that you would otherwise.  And this issue of TRIM means that I was incorrect two weeks ago because of the way SSDs work.



So here's the deal.  When you write a sector to an SSD, it must erase the contents due to the nature of the physics of the way an SSD drive works.  It has to erase the sector before it can write it.  The problem is that, again due to the physics of SSDs, an SSD cannot erase a single sector.  It is forced to, architecturally, erase a much larger block of sectors.  Now, if the SSD knew, if it had a way of knowing that the other sectors in the block were not in use, did not have data in them, then it would not have to first read them and cache them inside itself, then modify the sector to be written, and then write them all back.  Because, again, we're trying to change or write to one sector.  But to do that we have to erase that sector, which means we have to erase the whole block that that sector is part of.  And if we're going to erase the whole block, we have to first read the whole block, then erase the whole block, then write it all back.  So you can see there's much more work being done if the other sectors in that block have valid data.



What the TRIM command - oh, and so I should also mention that, in order to deal with this, in order to make SSDs functionally identical to hard drives, they manage all this internally.  It's amazing.  And you referred to the SSD controllers.  That's the job of the controller inside the SSD package which does all of what I just said transparently.  It maintains its own proprietary bitmap of every single sector in the space of the SSD and whether that sector has ever been written to.  So as you write to sectors in the SSD, those little bits get set, telling it that that sector contains valid data.  So over time, as you're writing to more and more of the SSD, more of these little bits are being set.



But at the operating system level, you may be deleting files.  When you delete files, as we know, we're only marking those sectors or clusters, because modern file systems allocate in cluster sizes, which is a cluster of sectors, we're marking those clusters as no longer in use.  We know that the file system is not going out and actually erasing them because that's how undelete utilities work is they come back and say, well, let's get the data.  If it hasn't been overwritten, we can recover the data that was deleted, and the user regretted making that deletion.



What TRIM support in the - well, okay.  So file systems are marking areas deleted, but that information is not being given to the SSD.  So as the evolution of the ATA, the AT Attachment specification, has progressed, the designers of SSDs wanted to provide a means by which the operating system using the drive could reset those little bits, saying these sectors are in use.  So that's what TRIM command does.  The TRIM command is an extension to the ATA, the AT Attachment specification, providing a means for communicating to the drive that the following sectors no longer contain valid data as far as the operating system is concerned.



So when we say that only Windows 7 supports the TRIM command, we're meaning that only Windows 7 is a popular operating system in use which, when and as you delete files from the file system, Windows 7 sends a batch of TRIM commands down to the SSD, telling it that those sectors are no longer in use.  And so the beauty of that is that it prevents these bits, these little in-use bits from just accumulating without end, which they otherwise would in the SSD, telling the SSD that, as you've deleted files, those sectors are no longer in use.



So getting back to Tom's exact question, he said, if you ran TrueCrypt, for example, to encrypt the entire drive it would set every single one of those in-use bits in the SSD because you have written to every single sector of the drive in order to encrypt the whole thing.  And he is exactly right.  So what you'd really like to do is run whole-disk encryption and then have a means for sending a full drive worth of TRIM commands telling the SSD, reset all of your sector-in-use bits which you're using to manage those blocks back to zero because, even though we just wrote to the entire drive to encrypt it, we didn't store any valid data there yet.



LEO:  Okay.



STEVE:  So there is a Linux utility called hdparm which has that facility.  There is some driver support.  There's a utility that Intel has, like an add-on utility where you can manually scan the file system, and it will look at the clusters that are in use and then issue TRIM commands for those that are not.  But I've tried to purchase two SSD drives from Intel which offer this support, and I've failed both times, which is really annoying because I care about this kind of thing.  So, and as you said, Leo, it's not even really clear that this is more than sort of a theoretical problem.  The controllers are doing a very good job of managing their SSDs.  It's not like performance continues to descend forever until it becomes really, really slow.  You do see a drop as these bits are being set.  But then at some point it's not such a big deal afterwards.



LEO:  I asked Allyn Malventano, who's the guy who discovered this and kind of publicized it on PCPer.com and who is of course a regular on our both PC Per and TWiCH podcasts.  And I said, "Well, Allyn, in order to create this benchmark, and to show this, you had to really kind of create this synthetic, make a lot of small files, erase a lot of small files kind of a situation."  So it's not even - the question is not whether this happens, because you can demonstrate it.  But the question is whether in real-world use it would be a significant degradation in performance.  And even the Intel guys disagreed.  That's what I liked about it.  One guy said, oh, no, it's a problem.  And it's completely moot unless you're using Windows 7 because no operating system except Windows 7 does it anyway.



STEVE:  Correct.



LEO:  So unless your operating system does it, it's not - you're not going to - so it's a really actually kind of an angels dancing on the head of a pin argument.  And yet I think it's fascinating, and it certainly is something that is relevant, if you want to use an SSD.



STEVE:  And now...



LEO:  I've never - I'm using it in OS X, so I've never noticed.



STEVE:  Right.  I was saying, and now all of our listeners understand what the whole TRIM thing is with SSD.



LEO:  Yeah.  Now they're in, man, they're in, they're with it.  Jamie Hunt, England - did you write this, or did he write Jamie Hunt in England, UK?



STEVE:  That's the way he wrote it.



LEO:  Okay.  I mean, I know they're not the same thing, but I just think it's funny.  It's like saying in the United States, North America.  Wonders about driver update scanning:  Steve, there seem to be millions of sites scattered about the Internet saying they will scan my PC for outdated drivers.  Oy gevalt.



STEVE:  Uh-huh.



LEO:  Thanks, but no thanks.  But 95 percent of these programs seem to be from an unreputable source, or at least a source with no reputation.  My question to you is, do you recommend using a program that will scan for outdated drivers and tell me to update, sort of like Secunia PSI for drivers?  And, if so, which one?  Thanks.



STEVE:  Well, you said it, Leo.  I wouldn't say that 95 percent of them are unreputable.  I would say 99.9.



LEO:  It's basically giving them permission to see what you've got.



STEVE:  Yeah.  And, okay.  So here's the deal.  It is so tempting to want to have the very latest drivers for your machine.  But it makes me feel like - I feel even more strongly about this than I do about the temptation not to always update to the latest software because drivers are even providing less incremental functionality than new versions of software.  And it's not clear that you get a lot when you update to a new version of software.  So I guess what I'm saying is that my feeling is, if some device on your system is not working, then certainly try updating the device driver and see if that fixes the problem.  But if it's all working, then I don't know what you gain from updating drivers to the latest versions, hoping that they're going to work better, because drivers don't have that much ability to sort of, like, only work part way.  They're generally working or not.  And so my feeling is I've never done a scan through some third-party site to, like, have it look at all my drivers.



LEO:  Yeah, it's a bad idea.



STEVE:  I really agree.  I think it's a very bad idea.  I know that - I'm a Lenovo user.  And the Lenovo system has some, for several years now, a facility for checking its own drivers versus its own database and notifying you if things have changed.  And invariably what I notice is it's trying to give me new versions of drivers where the only difference is it now supports laptops I don't own.  And so it's like, well, okay, why do I care about changing this driver to support a laptop that Lenovo now offers that I don't own?



So I look carefully at what the benefits are of updating a given driver.  If it says, oh, we've made great strides in power management, it's like, oh, I need that.  That sounds like a good thing.  But if it's we now support 16 new laptops, it's like, okay, I don't think I'm going to be making the move for that reason.  And again, I would stick with the source of my machine, rather than some random site that says let us scan your machine and let you know if there's something new.  Seems like a bad idea.



LEO:  Right.  Windows itself actually does a pretty good job of keeping drivers up to date.  They're not in the critical updates, they're in the optional updates.  But that's what I do.  I just run Windows update, and I look and see if there's any driver updates because I generally will use the ones provided by Microsoft just because they're tested for Windows.  I mean, they may not be the latest always...



STEVE:  But known to be compatible.



LEO:  But they're known good, yeah.  And I find that that's fine.  It's funny how old habits die hard.  And people who've been PC users for a long time have all sorts...



STEVE:  Skeptical.



LEO:  Yeah, well, they have all sorts of things that they do that were maybe needed, like defragging and updating drivers, checking your video driver.  And I think as we've gotten to be a more mature system, if you're using Windows 7, I think you probably can eliminate a lot of the stuff that we used to do to make, you know, you don't have to edit your config.bat anymore.



STEVE:  And defrag your registry.



LEO:  Yeah.



STEVE:  Pretty much, if you're using Windows 7, you've given up.



LEO:  Yeah.  Well, that's another matter.  You know, yesterday I did "Live with Regis and Kelly," and we taped a second segment that'll air in a couple of weeks.  They're going to do a Twitter week all week long.  And so I went up to Regis's office to tape this segment on teaching him how to use Twitter, which was fun, and he was using Internet...



STEVE:  Oh, how fun.  When is it going to air, Leo?



LEO:  January 31st.



STEVE:  Okay, great.



LEO:  I don't want to tip it.  But it was really fun.  And I think what's most interesting, you know, yesterday he announced that he was leaving the show at the end of the summer, which was a big shock to everyone.  No one knew this.  I didn't know it.  None of the producers knew it.  Everybody went - because they're all going, uh-oh.  What do we do?



STEVE:  Well, and Regis is such a fun non-techie that I can imagine...



LEO:  He's wonderful.



STEVE:  ...you guys must have just had a ball.



LEO:  I adore him.  First of all, he's 80 years old.  He is sharp as a tack.  I mean, there are very few 80 year olds who are as quick and as with it and on top of it as he is.  I read this after he announced the retirement, which was breaking news everywhere, said he is currently the longest-running on-air talent, you know, ever, in the world.  I mean, there's nobody been doing it longer than Regis Philbin.  He started with Joey Bishop in the '50s; you know?  So in any event, so it's a real honor.  And I have always liked Regis.  I've just - we hit it off very well.  And so we're doing this thing.



And after it's done, he's using IE, it crashes.  It crashes on him.  And he says, "What's this, Leo?"  I said, "I don't know, we were just tweeting and it crashed."  And Gelman goes, "God, I hate Internet Explorer."  It's, like, it's so sad that normal people have to go, huh?  I was just tweeting.  What happened?  And it crashed the browser.  I'm sure he was using, I didn't look, but I'm sure he was using, like, XP with IE6.  But I didn't really even want to know.  It was like, I just stepped back and said, "I guess we're done."  I don't think that will make it into the tape, by the way.



We have a long one.  This is from Charles Victorian in Houston, Texas, a follow-up on what he learned about frequency hopping spread spectrum.  Which - this sounds like it's apocryphal, but I believe it's true - was invented by Hedy Lamarr, the movie star.  Did you know that?



STEVE:  No.



LEO:  Doesn't sound right.



STEVE:  Sure doesn't.



LEO:  It doesn't sound right.



STEVE:  Unless he's a secret genius.



LEO:  She was a starlet, a gorgeous woman.  Orson Welles dated her for a long time.



STEVE:  I did hear this once somewhere.  I remember thinking, what?



LEO:  She invented spread spectrum.  I don't know how.  I'd like to know more about this.  Frequency, I mean, Wikipedia talks a little bit about this.  It was patented earlier than that.  But it says in Wikipedia, "The most celebrated invention of frequency hopping was that of actress Hedy Lamarr and composer George Antheil, who in 1942 received [a] U.S. patent" during World War II "for their 'Secret Communications System.'  Lamarr had learned at defense meetings she had attended with her former husband Friedrich Mandl that radio-guided missiles' signals could easily be jammed."  They "used a piano roll to change among 88 different frequencies ... to make radio-guided torpedoes harder for enemies to detect or jam."



STEVE:  Wow.



LEO:  And this patent came to light when ITT and other private firms began to develop CDMA.  And they did the patent research, they said, whoa.  Hedy Lamarr owns this.



STEVE:  And 88 keys is the number of keys on a piano.



LEO:  Yeah.  Isn't that interesting?



STEVE:  Yeah, yeah.



LEO:  Others, there's prior art.  But independently, Hedy Lamarr thought of it.  I think it's fascinating.  Steve, thank you so much - just historic note.  Steve, thank you so much for taking on my question about the Lorex Live Snap and its use of Frequency Hopping Spread Spectrum (FHSS) technology.  I was encouraged by your comments on the security which might be implemented by the camera system.  He had a baby monitor, I think; right?



STEVE:  Right.



LEO:  And he didn't want people to watch his camera, his baby.  And he said, well, what is this FHSS they say they use?  Enough that I not only opened the one I had already purchased, but went out and bought a second system immediately after hearing the podcast so I could do a little intersystem testing of my own.  Now, this is our listeners.  This is why I love our listeners.  He didn't just say, oh, okay.  He said, let me see.



Reading over the User's Guide, which I previously didn't have access to, explains how to pair up cameras, which gave me hope.  The guide states, "The camera(s) included with the monitor have already been 'paired up' with the monitor."  So that's why he didn't have to do any configuration with the new one.



STEVE:  Right.



LEO:  It goes on to explain how to pair up additional cameras since the base system comes with two cameras, yet the monitor supports up to four.  I won't bore you with the details of the relatively simple process.  But I will note in particular it requires you to begin with the camera turned off.  Additionally, under the "Tips" section, the guide states, "The camera and monitor should be around a foot apart during the pairing process." 



So, with some confidence gained by your coverage of FHSS on the podcast, and a better understanding of how the product works from reading the included User's Guide, I tore into the second box.  While using a camera and monitor from the first set, I put the second monitor in "pair" mode.  It responded with "Pairing" and some symbols indicating to wait.  The process exited with "No Device Found" even though this monitor was as close as I could get to the 

currently broadcasting camera (they were plugged into separate outlets, and I didn't have an extension cord handy).  Nevertheless, any neighbor, et cetera, is not going to be able to get closer than I was without being inside my house.  So it is clear that, once the camera is paired to a monitor, another stock monitor can't just show up and receive the signal.  A good start.

 

It seems like, as in Bluetooth, the pairing process could leave you vulnerable for a few seconds, when you're discoverable, effectively; but then the signal, once it's locked in and paired, should be inaccessible.  It also seems that you would know if someone had hijacked your camera since your monitor would then say "No Device Found," and that would be a clue. 



I know that this doesn't address reverse-engineering the system or building some sort of separate hacked monitor, but at least it isn't going to be easy thing for somebody to drive by, set up a monitor, and watch my baby.  Thanks for doing what you do.  I always look forward to listening to every episode.  I really miss Tech TV, but at least we still have you and Leo.  Regards, Charles Victorian.  I like that kind of listener.



STEVE:  So, well, yes.  And the fact that they referred to pairing, of course, that's the first really great piece of news.  Our listeners will probably remember that basically we covered frequency hopping spread spectrum several times relative to Bluetooth.  And then when I first entertained Charles's question he was - he hadn't even opened the box because he wanted to know whether it could be safe enough, or whether it was just a scam.  And of course we couldn't answer the question, but I looked at their website and explained what frequency hopping spread spectrum was.  Then that encouraged him to open the box, where he found the manual.



And then they do take him through a process by which the transmitter and the receiver need to get to know each other.  And then he further, as his note indicated,  further tested this by taking, not only just some random monitor, but the company's same brand of monitor and tried to see whether it would be able to receive the same signal when it hadn't been paired with the camera, and it wasn't.  So again, I think this is just a great example.  I wanted to follow up, but also to give our listeners a sense for how you can determine this kind of thing on your own for anything else of this nature in the future.



LEO:  Yeah.  It's a little inductive reasoning, really.



STEVE:  Yeah.



LEO:  Question #6, Brian Voeller in USA.Oregon.Medford - I like how people are identifying themselves.  That's great.  Planet Earth in the Milky Way.  No, Solar System, Milky Way, Universe.  Universe X394.



STEVE:  Now you realize that's how I'm going to get these things sent to me in the future.



LEO:  From now on.  Narrow it down.  Hello, guys.  Regarding Episode 282 and the question about the security of a wireless baby monitor camera that touted frequency hopping as a security mechanism, I would not regard that as effective, particular in a video transmission context.  Being a cheap camera, it's probably sending analog NTSC, which is what standard definition television in the U.S. is, or EIA, that's a low quality version of NTSC, and hopping frequency on the completion of each frame, since the vertical blanking interval would make a convenient opportunity to let the tuner lock onto the next frequency.  All that makes sense.  Individual frames could be captured by scanning the frequency range slowly.  Assuming 256 channels, once you found one of them, you'd get one frame every 8.5 seconds.  Oh, that's an interesting point.



STEVE:  So, yeah.  I saw Brian's question or comment and thought, well, this makes a good companion to the one we just read, and that is to suggest that frequency hopping is not security, as he does.  And of course he's right.  Frequency hopping is not encryption.  It is mostly used to avoid jamming and interference.  This is exactly what Hedy Lamarr apparently developed this concept for back in war time, was not so much for security, but for avoiding interference, the idea being that, if one particular frequency is being jammed, you're not going to spend much time there.  You'll still be able to get the bulk of your signal through.



So I feel, I mean, Brian's point is that, if somebody was absolutely determined to monitor this information, what they'd be getting is essentially a very nonstandard signal.  They wouldn't be getting a video signal, they'd be getting one frame of video.  Assuming that it's not digitized, and it's not encrypted - which we don't know, it could be digitized and encrypted in addition to the frequency hopping spread spectrum - but they'd be getting one frame on a given frequency, as he said, every 8.5 seconds.  But again, you'd have to then capture that and figure out how to display it because no regular monitor is going to display that.



So anyway, I still feel that this makes great security, much more so than just having a video transmitter sending video out on a single frequency where, as we know, it's very possible to easily eavesdrop.  So, yes, not what we would call NSA-grade security.  But you really have to work in order to get a useful picture back out of this thing.



LEO:  Every eight seconds.



STEVE:  Yeah.  And then you're just getting a frame of data that you then have to go to a lot of work to reconstruct.



LEO:  Right.



STEVE:  My feeling is, if you can't use the manufacturer's own monitor to receive it, then you're pretty much out of luck.



LEO:  Yeah, that's sufficient.



STEVE:  And that's what our prior questioner verified.



LEO:  Right.  Bill Bolton in Australia raises a great point about IPv6 modem routers:  Steve, if the world is going to be forced to move to IPv6 by year's end, why are almost no IPv6-capable consumer modem routers available as yet?  He's talking about, when you get a DSL line, often case they'll give you the DSL modem with a built-in router since they know you're going to hook up a router anyway.  There must be well over a hundred different models of various makes on the market.  I guess it's true also of cable modems, but...



STEVE:  Yeah, just, exactly.  And just other NAT routers.



LEO:  Yeah.  Any time you're getting online, it's not unusual to combine the two.  Only three of the hundred different makes on the market have the necessary features.  It seems more than a little strange to me, with one group crying we're running out of IP addresses, that the manufacturers are saying, "Huh?  What?"



STEVE:  Yeah, I completely agree.  Here's another example of it's not going to happen until it has to happen.  If you look at NAT routers, they're still IPv4.  I've not yet seen one that is supporting IPv6 features.  It's just like no one's actually doing it yet.  Yet we're running out of space.  So it's going to be a really interesting year, Leo.



LEO:  Yeah.  We talked to - at CES we had Bob Frankston on.  I know you know that name.  Bob...



STEVE:  Oh, cool, yeah.



LEO:  ...yeah, along with Dan Bricklin wrote VisiCalc.  Actually Bob did the coding many years ago.  Probably, if you were to say there was one application that put personal computing on the map, it was that.  Because initially the Apple II was a toy.  And as soon as you put VisiCalc on it, the first spreadsheet program - nobody'd written a spreadsheet.  Nobody even thought of a digital spreadsheet.  Soon as you did that, it was like, business was now, okay, now I'm interested.  Now I might want to buy one of those things.  Anyway, Bob, after his stint at VisiCalc, went to work for Microsoft as probably a high-level fellow.



STEVE:  Thinker.



LEO:  Yeah, thinker.  And this, he said, in these days the ISPs wanted to charge you for each user in the house.  And I do remember those days where basically each one would have a static IP address, and you would have to pay the full freight, or maybe a slightly discounted rate.  He said, we were starting to create routers at the time.  Or it was his suggestion to put NAT in.  And he said, I knew, but I didn't tell anyone, that this would effectively make it impossible for ISPs to charge per user.  They'd have to charge per household because of course the NAT would hide all the additional users.  He said, I never mentioned that feature.  I just said it'd be a good thing to put NAT in these routers.



STEVE:  And that's what connection sharing is, of course.



LEO:  Right.  And so he says, you can thank me for the fact that you are paying what you're paying for your Internet access.  He had some other very interesting things to say.  We decided to invite him in for a full hour interview for our triangulation show because he's a fascinating guy.  And what I like about him, yeah, he created history 40 years ago with VisiCalc, but he's not sat on his laurels.  And he's doing something very interesting right now, really about taking back the Internet, that I thought was fascinating.  He said the Net Neutrality conversation is misguided.  That's not what we need.  He said there's a way to handle this.



STEVE:  The other thing, too, is that by putting NAT in all these routers, not only were we preventing ISPs from charging per user, but we did hugely slow down the depletion of the IPv4 address space.  Because, you know, we've got, I mean, I'm sure probably all of our listeners have many different machines behind their single IP that's out there, their public IP.  And we always are talking about 192.168.x.x addresses, which we're all sharing, but which are kept separate.



LEO:  Yeah.  Very good point.  Thank you, Bob.  Bob Frankston.  Aloke Prasad in Ohio has a question for you.  He notes that Microsoft disagrees with you about swap files on SSDs.  Okay, this I've got to see.  You said it was unwise to use an SSD for the Windows swap file.  You're not alone, by the way.  We mentioned Allyn Malventano.  You talked about your friend, our friend...



STEVE:  Mark Thompson.



LEO:  ...Mark Thompson.  The following article from Microsoft says otherwise.  It's blogs.msdn.com.  It's a May 2009 article, "Support Q&A for Solid-State Drives."



"Should the pagefile be placed on SSDs?  Yes.  Most pagefile operations are small random reads or larger sequential writes, both of which are types of operations that SSDs handle well.  In looking at telemetry data from thousands of traces and focusing on pagefile reads and writes, we find that, one, pagefile.sys reads outnumber pagefile.sys writes by about 40 to 1."  Well, that's good to know.  That's interesting.  So in other words, there's a lot more reading going on than writing, 40 times more.



"Two, pagefile.sys read sizes are typically quite small, with 67 percent less than or equal to 4KB, and 88 percent less than 16KB.  Three, pagefile.sys writes are relatively large, with 62 percent greater than or equal to 128KB and 45 percent being exactly a megabyte in size."  This is Windows, of course, only we're talking about.  This is how Windows behaves.  "In fact, given typical pagefile reference patterns and the favorable performance characteristics SSDs have on those patterns" - in other words, SSDs are faster with reads, they're really great with lots of small reads because the seek time is zero - "there are few files better than the pagefile to place on an SSD."  Well, that kind of makes sense.  The issue really more is this thrashing of the SSD.  But if the files are megabyte most of the time, does that ameliorate that?



STEVE:  Well, this is a perfect example of a person answering a question from their perspective, but not a different perspective.  That is, if all you were asking was about performance, then I completely agree.  But my focus has never been on performance in this discussion.  It's been on burning the things out, which this doesn't address at all.



LEO:  So all of those extra writes, regardless of the size of the writes, are not good.



STEVE:  Correct.



LEO:  Reads we don't care about on an SSD.  Lots of reading we don't care about.  It's the writing we care about.



STEVE:  Correct, because writing is a physically fatiguing process for an SSD.



LEO:  You can say that again.  As the author of 13 books - no, I'm just kidding.  Never do it again.



STEVE:  And Mark Thompson and I have discussed this at length.  He's performed the experiment of using an SSD for a swap file and watching it burn out the SSD.  I mean, in a relatively short time it just killed it.  And so, anyway, so my advice stands, which is, if you're using an SSD, hopefully before you have gone to the expense of using an SSD, which is still much more expensive than a hard drive, you will have invested money in as much RAM as your system can handle because RAM is much less expensive, and you'll get much more, you'll get huge benefit from going to the most RAM you can possible get.  And if you've done that, then turn off pagefiles.  And if the only drive you have is an SSD, I stand by my advice.



I agree that, from a performance standpoint, the SSD is a perfect device for containing the pagefile.  Unfortunately, Microsoft thrashes their pagefile.  I mean, they're writing to it a lot.  Yes, 40 times less than they're reading, but it's something that's going on all the time, pretty much.  I mean, we've all seen, we've watched the hard drive light flickering there, like when nothing is going on.  It's like, what is it doing?  Well, who knows.  But we know that it's writing to the pagefile, which it does a lot.  So anyway, I think it's a perfect example of two different people with very different aspects of the problem that they're addressing.  I'm looking at long-term life.  Microsoft's looking at performance.



LEO:  That's really great.  What a great illustration of that.  Depending on your point of view.  I love that, yeah.  So we stand by our suggestion not to use the SSD for the pagefile unless you don't mind buying SSDs regularly.



STEVE:  Yeah.  Not so much.



LEO:  It will be faster, though.  It will speed it up.  Could you put a pagefile in a RAM disk?  I guess you could.  That would be a good thing to do.



STEVE:  Well, it would make much more sense to leave that RAM disk free for RAM.



LEO:  Well, yeah, right, of course.  The more RAM you have, the less you need a pagefile.  Pagefile is all about what happens when you run out of RAM.



STEVE:  But if you had a RAM-based hard drive, that is, if you had a RAM-based physical drive that wasn't part of main memory and couldn't be part of main memory, then, so that it's like a separate paging device, then absolutely.  That would make a lot of sense.



LEO:  Our last question, Steven, from Jim Sanders in Irvine, California.  He wonders about iPod and iPad solid-state hard drives.  Because most iPods, only one, the Classic, has a moving drive.  And all the iPads are solid-state.  In fact, the MacBook Airs are also solid-state.  Steve, you talked about the finite number of write cycles on solid-state hard drives, which I presume includes the array of portable devices like the solid-state iPod and the iPads.  Given that, should we be thinking about minimizing the number of times we sync the devices?  Hmm.  Does syncing with the desktop shorten the lifespan of the SS hard drive?  Long-time SpinRite owner.  It's saved two machines for me.



STEVE:  One of the things that I thought I should do, I liked this question because I think maybe I've concerned people unnecessarily.  The least robust technology for SSDs is called the MLC, the Multi-Level Cell, as opposed to the SLC, the Single-Level Cell, which is a much, much more expensive drive, but also more robust.  But even the multi-level cell, the lesser of the two technologies in terms of robustness, has a guaranteed minimum number of write cycles of about 10,000.  Now, I just divided 10,000 by 365, which is roughly the number of days in a year.  And I get 27.397, which is to say that, if you rewrote the entire drive daily, that drive would last for a minimum of 27.397 years.  So, yes.  SSDs have a limited life.  But so does the universe.



LEO:  [Laughing] In a nutshell.  You know, what can you do.



STEVE:  So don't worry about it.



LEO:  Okay.  That's good, that's good, I like it.  Steve, you're always - I love this show.  And I actually love the Q&As because of the wide range of topics.  I know it's fun to drill deep into a subject, as we did last week with Bluetooth hacking.  But it's also fun just to cover a wide range of topics.  I always learn so much on this show, and I thank you for it.  Do you know yet what we're going to do next week?



STEVE:  We're going to talk about fuzzing, fuzzy-wuzzy, about browser fuzzing.  It's the work that was done recently by the Google security researcher who, using fuzzing, found interesting and in many cases significant problems, more than a hundred, with all of the browsers we're currently using.  So we're going to talk about fuzzing...



LEO:  Fascinating.



STEVE:  ...a different approach to finding security vulnerabilities.



LEO:  I love it.  Next week on Security Now!.  Meanwhile, if you want 16KB versions of this show for the bandwidth impaired, if you want full transcripts and show notes, you can go to GRC.com, that's Steve's site.  While you're there don't forget to take a look at SpinRite, the world's finest hard drive maintenance and recovery utility for - not for SSDs, for spinning drives.  You're going to have to come up with something for SSDs, Steve.  I hope you're thinking about that.



STEVE:  Yeah, I'm thinking about it, actually.



LEO:  Yeah.  That should be interesting, an interesting challenge.  Also, lots of free stuff - ShieldsUP!, DCOMbobulator, Don't Shoot The Messenger, just a ton of - actually Shoot The Messenger.  Kill it dead.  And tons of great stuff that Steve just does out of the goodness of his heart and because he loves to write software in assembly code.  You can find that all at GRC.com.  You can also watch this show, we do it live every Wednesday at 11:00 a.m. Pacific, 2:00 p.m. Eastern time, at live.twit.tv.  Or subscribe.  You really ought to.  In fact, you ought to go back and listen to all 284 episodes because it's a graduate degree in computers and how they work.  That's at TWiT.tv/sn for Security Now!.  Steve, have a great week.



STEVE:  Will do, Leo.  Thanks very much.



LEO:  See you next week, right here.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#285

DATE:		January 27, 2011

TITLE:		Fuzzy Browsers

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-285.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's security updates and news, Steve and Leo examine the use of "code fuzzing" to locate functional defects in the web browsers we use every day.  Surprisingly, every browser in use today can be crashed with this technique.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 285, recorded January 26, 2011:  Fuzzy Browsers.



It's time for Security Now!, the show that covers your security, your privacy online.  And who better to do that than the man at - I was going to say SGgrc.  That's his Twitter handle.  It's GRC.com.  It's good to talk to you, Steve Gibson.



STEVE GIBSON:  Leo, great to be with you again, as always.  For Episode 285 we're going to talk about fuzzy browsers.



LEO:  Are the browsers fuzzy?  I mean, are they actually fuzzy?



STEVE:  Well, actually they're fuzzier than we wish they were.  We wish they were really solid and sort of in one piece, and not something you would characterize as being fuzzy or furry or flaky.  Unfortunately, they are, it turns out.  And we're going to talk about the details of browser fuzzing, which is the practice of writing scripts for browsers specifically for the purpose of stressing them and demonstrating where there are unknown problems.



LEO:  Very interesting.



STEVE:  Turns out it's frighteningly successful, that is, this whole process.  So much so that Mozilla has incorporated browser fuzzing into their standard test suite now.



LEO:  Wow.  Well, we'll get to that in a second.  But I imagine there's a few security updates on your plate today.



STEVE:  We've got some updates and some news.  And speaking of Google, Chromium, or the Google Chrome browser, just got itself updated, like about a week ago.  And they gave their so-called "Elite" Chromium Security Award to Sergey Glazunov.  And he won, actually they call it a charity, so he received a charitable contribution for this particular problem that he found.  He found a handful of them.  But it was $3,133.7, which of course is eleet...



LEO:  Eleet in leetspeak.



STEVE:  And they had announced, and we've talked about it before on the podcast, that they would reserve this amount for people who found really bad problems because they wanted - or, like, really difficult to reproduce, I mean, basically for a security researcher who really earned the discovery, which he apparently did.  This is a critical problem, the Google Chrome people felt, with a problem with stale pointers in the speech handling for the Chrome browser.  There was this one critical problem, 13 other problems rated high, and two that were rated medium.  High security problems receive $1,000, and medium ones receive $500.  And actually Sergey got a handful of them.  So he pretty much cleaned up.  This was a good month for him.  And of course all of us who are using - all of the people using Chrome get the benefit of it having fewer problems now than it did before.



LEO:  Very nice.



STEVE:  I received, speaking of SGgrc, through Twitter was the first channel that I saw the notice, then I saw it elsewhere, really nice news.  Starting today, probably not this moment for people who are listening to this live, but I would imagine anyone hearing the podcast later this evening or, like, for example, Thursday the 27th, Facebook has just announced this morning in their blog, their security blog, that they are now offering 100 percent SSL and HTTPS option.



LEO:  Oh, that is awesome.



STEVE:  Yes.  The URL for that page, I've got a short URL:  on.fb.me/ihQZiv.



LEO:  Oh, that's easy.



STEVE:  Yeah.  Well, I did tweet it.  I tweeted it immediately when I saw the news and gave credit to the guy who'd sent it to me.  And then immediately afterwards a few other of the main tech channels picked up on it.



LEO:  That's fantastic.  This is in response to Firesheep, obviously.



STEVE:  Exactly.  Now, in fairness to Facebook, they responded so quickly after Firesheep that they were already working on this, that I think this was an issue that was already on their radar.  We might imagine, though, that they gave it more acceleration, that they put some more effort into it to make it happen.  Quoting from this page, they said:  "Starting today we'll provide you with the ability to experience Facebook entirely over HTTPS.  You should consider enabling this option if you frequently use Facebook from public Internet access points found at coffee shops, airports, libraries, or schools.  The option will exist as part of our advanced security features which you can find in the 'Account Security' section of the Account Settings page."  I did go there after having someone else respond to my tweet, saying, eh, I don't see it.  And sure enough, because I've got a Facebook account that I maintain just for exactly this purpose, I don't actually - I'm not active there, anymore, Leo, probably, than you are.  But...



LEO:  Oh, I wish I could say that, but I am.  I got sucked back in.



STEVE:  Once again.  Anyway, so when I last looked it wasn't there.  But presumably sometime today, on January 26, 2011, this feature will be added.  And I don't have to tell any of our listeners who are Facebook users, check for it over the next few hours or days.  Turn it on.  And the good news is, wherever you are using Facebook, Facebook itself then will work to keep you over an HTTPS connection whenever possible, which will, as we know, with threats like Firesheep lurking around, will enhance your privacy and security.



LEO:  Very good news.  It also I think could have a one-time password, they say.



STEVE:  Well, they mention that they're going to.  I got excited about that and read the rest of the blog and could not find it anywhere.  So I think they're talking about getting there.  I mean, even the fact that they're talking about that is a good sign.  It means that they're beginning to be more serious about security.  So being as big as they are, and as significant as they are, that's just good news.



I picked up a little bit of news relative to the privacy of employee email.  You and I have talked several times, Leo, about how people need to remember that email that you use when you're at work really is not private.  You need to consider it as you're using your employer's equipment, your employer's bandwidth and connectivity.  So don't consider that private.  There was a suit raised when a secretary, I don't know what the exact whole story was, but something about her becoming pregnant shortly after she began her employment.  Her employer got upset because presumably, shortly after being hired, she would now need maternity leave or something.  But anyway, the lawyers got involved.



And what happened was that it went up to an appeals court that ruled, quoting from their ruling, the way they phrased it:  "The emails sent via company computer under the circumstances of this case were akin to consulting her lawyer in her employer's conference room, in a loud voice, with the door open, so that any reasonable person would expect that their discussion of her complaints about her employer would be overheard," the court wrote.  So that is what the court said relative to the issue.  And the issue was attorney-client privilege.  At some point they were trying to take the position that this could not be used as evidence in the suit because this was attorney-client privilege, protected under attorney-client privilege.



And what the appeals court said, and this actually does change some law or some prior decisions, which is why it got to the appeals court, previously there had been some instances where, for whatever reason, attorney-client privilege in a situation like this was held.  And in this case the California Appeals Court said, nope, exactly as they expressed it.



LEO:  Cool.



STEVE:  So be aware.  If someone has to have a secure email dialogue at work, our users know, that is, our listeners know that you could use, for example, Gmail over HTTPS, which would prevent it from being eavesdropped on, so long as your browser has not received a security certificate from your employer that would specifically allow them to filter SSL connections.  And again, the way to check that is, when you have established an HTTPS connection to Gmail, then check the certificate associated with the page, typically by right-clicking on it and checking properties and looking at the certificate, and see whether the chain of certificate authorities goes directly from Google to their root authority and not through something that looks like some third-party SSL eavesdropping monitoring system.  In which case you really would not be able to have any kind of communication that would not be eavesdropped by the corporate network.



We have talked about Net Neutrality a lot, and I think that'll be not a huge topic for us because it's a little bit off-topic.  But I wanted to mention that Verizon is challenging that ruling that we did talk about a few weeks ago where the FCC took the position that providers could not selectively throttle broadband traffic over their networks.  And it's not been clear that the FCC has the authority provided by statutory law that's in place now to do that.  And so Verizon is saying the FCC doesn't, which will probably force legislation to be created that gives the FCC or somebody that kind of regulatory power, which it may or may not have, depending on how Verizon's suit comes out.  So that's unfortunate.



And speaking of unfortunate, this week a U.S. congressional panel is holding a hearing to consider reviving the impossible-to-implement ISP Data Retention Bill, which we have talked about, which would, if it were enacted into law, would require ISPs to retain their customers' Internet data for two years.  Which, I mean, anytime hearings are held I'm sure the ISPs must sit in front of our representatives and senators or whomever is in these meetings, these hearings, and explain to them that it's just a physical impossibility.  Of course, immediately, and as part of the story, they talked about, well, we want to be able to track down child pornographers.  And so they march out child pornography as the gotcha.  It's like, well, you're not *for* child pornography; are you?  Although in fact what we know is that, as you and I were discussing, actually before we began recording this, Leo, electronic data and electronic privacy seems to be something we're losing very quickly.



LEO:  Yeah, I hate it when they conflate child pornography with all of this because it's not - it has nothing to do with it.  It's just an easy out.



STEVE:  Right, right.  It's something that everyone is going to vote to...



LEO:  Yeah, who's for that?



STEVE:  ...prevent, exactly.



LEO:  Nobody's for that.  But that's not what this is about.



STEVE:  Yeah.  And the idea that an ISP would need to record two years, essentially we're talking about two years of all the traffic through their network.  That is, because of course their network traffic is the sum of their customers' traffic.  And what the people who are pushing the bill want is the ability to go back for a given customer, presumably under warrant, and rummage through everything that that person has done for the two prior years.  So, I mean, if you were Google, sure, you've got a database that's large enough to hold two years of all your customers' traffic.  But that's - nothing that's in place like that is happening now.  They're not talking about a real-time tap.  They're talking about recording everything for two years.  So hopefully, much as somebody wants this to happen, saner heads will prevail and say, look, we can't do that.



LEO:  This is an issue we were talking about before the show began.  But at some point I'd love to talk more about these pen register search warrants and how they're being, I think, misused by law enforcement, and really unconstitutional ways we're being spied upon.  And it's just getting worse.  And it's because it's electronic, and so it's just deemed somehow less private.  It's just appalling.



STEVE:  Yeah, and unfortunately it does make it easier.  It's not like you have to - you don't have go install transmitters in someone's home and car.  You just hopefully give them a subpoena.  And as you're saying, in this case now, subpoenas are no longer even necessary.



LEO:  Right.



STEVE:  Cisco's Annual 2010 Security Report indicated that cybercrime appears to be migrating from desktops, which as we know are becoming increasingly well secured, as are the desktop users, I think, to mobile devices which are inherently much more vulnerable.  So it's probably not a surprise to anyone, but I thought it was interesting that Cisco is seeing this and noting that our mobile devices, which are becoming increasingly powerful, are becoming magnets for cybercrime.  Not good, and certainly not surprising.



Now, the big news, and interesting news, I held for last.  And that is that both Mozilla and Google have stirred on the issue of do-not-track behavior.  We talked last week about Giorgio's adding this feature, the do-not-track, the "X-Do-Not-Track" header to NoScript.  It had been there actually since a little bit before the beginning of the year, and someone brought it to my attention.  I checked my  outgoing headers from my browser when I'm using Firefox, and sure enough, those headers were there.  Just in the last couple...



LEO:  Of course.  You have to pay attention to it; right?  It doesn't mean anything if somebody doesn't understand it.



STEVE:  Exactly.  So, okay, there's two different approaches.  Mozilla is introducing, unfortunately, a different do-not-track header.  Yeah.



LEO:  You know, why not, because it's always been good when there have been many, many standards that you have to adhere to.  It always makes sense.



STEVE:  Exactly.  So theirs is called X-Tracking-Choice.  So X-Tracking-Choice.  And then you add to it.  Then it's colon and, like, don't track me or something.



LEO:  Don't track me, bro.



STEVE:  Oh, I'm sorry, it's Tracking-Preference: do-not-track.  So Mozilla's is Tracking-Preference: do-not-track.  And it's Giorgio who replied to the Mozilla blog posting.  And he said - I'm sure English is not his first language.  He said:  "Why inventing yet another header (X-Tracking-Choice) rather than reusing the 'X-Do-Not-Track' proposal," which of course is what he adopted with NoScript, "which is already implemented in NoScript and AdBlock Plus, and also endorsed by Mozilla?"  So who knows why.  Many cooks are involved.



So what Mozilla is doing, and they recognize that following this is optional, that is, is not something that they're mandating, they're just saying we're going to allow a user to turn this on and send this tracking preference header out with all queries.  Now, I'm all for it.  I like this solution.  And as I've said many times, in fact months ago I've been talking about just adding a header like this.  And this has all finally come to pass.  It does require voluntary compliance until legislation, which does seem to be rumbling around in the U.S. Congress at this point, legislation would then make obeying and honoring a header like this mandatory.



Now, Google has taken a different approach with their Chrome browser.  And I've studied what they've done, and I think I understand it, but it's not at all clear.  They've got a new extension called "Keep My Opt-Outs," which is an optional extension that can be added to Chrome.  And from what I can see, "Keep My Opt-Outs" must have the effect, although they didn't say so anywhere, so I can only guess this from the name, of preserving opt-out cookies when they exist.



Now, by looking at the blog and following some links, I discovered a site I had not seen before.  There is a site called aboutads.info, where you can go, which sort of appears to be an advertising industry sort of communal site that's talking about the nature of tracking and online behavioral profiling and so forth.  What's interesting is that there's another page, aboutads.info/choices.  You need to have scripting enabled, that is, when you go there.  So when I went I saw that something wasn't working.  In fact, it told me that I had to turn on scripting.  So using NoScript I enabled scripting for that page.  And then what happened was it enumerated a large number of known advertisers.  And this site allows, sort of provides a UI that allows people to create opt-out cookies for all of the advertisers that support opt-out cookies.  So if we didn't have this, you'd have to go manually to each of these different advertisers and go wiggle around through their websites and figure out how to opt out of each individual advertiser's tracking.



What's nice about aboutads.info/choices is it pulls it all together into one place.  So I've experimented with it, and it works.  You're able to just say "select all," or choose the ones that you sort of - that don't have a good-looking taste for their cookies and then say, okay, I want opt-out cookies.  So what happens is, since only the site which owns the cookie can set the cookie, this script doesn't have the ability to do so.  So it must be going out to each of these different sites, using some sort of protocol that they have agreed upon, to have each of those sites plant a new opt-out cookie in your browser, which did happen, and I confirmed that it happened.



And so that's what aboutads.info/choices does.  And if you're using Firefox you can do it.  You can actually use it with any browser that supports scripting.  So presumably, then, Chrome's new extension, Keep My Opt-Outs, does something to prevent them from being lost or deleted.  So, for example, if a user flushes all their cookies, this would take priority, and it would keep these opt-out cookies in place, even if you otherwise cleared all your cookies.



Now, the one thing I did note was that DoubleClick.net is not listed among all of these advertisers at aboutads.info.  There's something like, I don't know, 60 different advertisers.  And the script that ran had some problem enumerating some of them so that I was only able to end with, like, eight or so that I was able to opt-out of, and with, like, 39-some were still, they were sort of there, but not working yet.  Who knows what's going on.  But anyway, so aboutads.info/choices is something interesting to look at.



Now, so Chrome is not adding a header.  I would rather they added a header like Firefox is going to do, the Mozilla guys are doing, like NoScript and Giorgio have already done for us.  But this is something.  Microsoft and IE have an entirely different approach.  They've got something called Tracking Protection Lists, or TPLs.  They've just recently blogged about this.  This will be a feature in IE9 which is - in some senses it's better.  And, unfortunately, in some other senses it's not so good.



It's better in that these tracking protection lists are XML files, which are a moderately confusing syntax, unfortunately, but powerful, that allow both enable and disablement for IE to go to a third party.  So you have the ability to block third parties, that is, to block IE9's following links to sites that you have blocked.  And this doesn't, as I understand it, it doesn't even allow IE to go.  It's not a matter of it, like, blocking tracking.  It's blocking you going, which I think is fantastic.  Websites may object to this.  Something like this was going to be in IE8, but Microsoft removed it under pressure from advertisers, and so we didn't get that.  So from IE's blog they say:  "IE9 will offer consumers a new opt-in mechanism ('Tracking Protection') to identify and block many forms of undesired tracking.  Tracking protection lists will enable consumers to control what third-party site content can track them when they're online."



So the reason this is troublesome is that it's not clear where these lists come from.  For example, you might go to a site that is able to sense that you are not following its links to its ads, which scripting at the site could do, in the same way that a site is able to say, hey, you've got to turn JavaScript on if you want to use everything we're doing here.  So a site could say you must load this TPL, and they would provide you with their own customized tracking protection list for them, which would get merged in, in some fashion, to provide overrides to your otherwise disabling this.  Anyway, you get a sense for this, Leo.  I mean, this just sounds like a disaster.  I mean...



LEO:  It is.  It's worse than I thought, and I thought it was bad.



STEVE:  Yeah.  So I don't know how this is going to settle out.  I mean, again, it's why I just love the idea of a do-not-track header.  Just, for users who know they don't want to be tracked, turn that on.  I don't even care if it's off by default.  Just turn it on once and have it be sticky, and so that way the browser is broadcasting, with every query it makes, it's saying do not track me.  And then, yes, the argument is, well, but that requires compliance, voluntary compliance.  And it's like, yes, until we have legislation in place, which it seems like we're going to have to have anyway.  So the only alternative would be something like NoScript or cookie management or something like these TPLs, the IE9 tracking protection lists, which also seems like a big snarled nest of mess.



So anyway, this is - we're at the beginning of solving a problem which I'm glad the industry is looking at.  I'm glad Congress is making noise.  I'm so glad the browser vendors, I mean, everybody, this is like, it's not like no one's paying attention to this.  Everybody is paying attention to this.  Unfortunately, what that means is we've got 19 different approaches, and we haven't reached a consensus.  But we've been there before.  And in fact we'll be talking about the Document Object Model a little bit later when we talk about browser fuzzing.  And boy, that was a disaster in the beginning.  And it wasn't until the World Wide Web, the W3 Consortium stepped in and said, okay, here's how we're going to do it, that we finally got some sanity there.



And speaking of lack of sanity, Bruce Schneier blogged just the other day, I think it was yesterday, that a group of students at the Chinese University in Hong Kong have figured out how to store data in bacteria.



LEO:  [Laughing] Okay.



STEVE:  They have an article, a web page that I have a link in our show notes, which talks about, they say, its "massively parallel bacterial data storage system, error tolerant data encoding and decoding system, recombination module for data encryption."  And then, clearly, again, English is not their first language, not surprisingly.  And then they said "Ready for the exciting future of Biocomputer."  So in Bruce's blog he cites some other people that have looked at the article and scratched their head about what it is that they mean when they say "bioencryption," which is the term they've coined.  Bruce's comment, predictably, was, "Well, I hope they haven't created some sort of new encryption, but rather they're using traditional encryption before they use their bacterial storage to store the encrypted data."



LEO:  Yeah, because you can't encrypt bacteria.  That's next.



STEVE:  Anyway, that's in the wacky - I guess I should have put this under errata.



LEO:  Or just wacky.  Wacky would be good.



STEVE:  Wacky, yeah, the wacky category, data storage in bacteria.  And apparently, Leo, the bacteria can store a lot of data, so these students are quite excited about this.



What I do have in errata is a note about an interesting IPv4 countdown tweeter, or Twitter, or whatever that is, "@" sign.  I guess it's...



LEO:  It's a Twitter handle, yeah.



STEVE:  It's a Twitter handle.  So it's @IPv4Countdown, just all run together.  And this person is tracking the surprisingly rapid disappearance of IPv4 addresses.  So I just thought our listeners, any listeners who are Twitter followers, and I know we've got about 16,000 because they're following me, might get a kick out of adding @IPv4Countdown to the handles that they follow.  It's very low traffic.  It only posts when there's been some loss of IPv4 address space.



LEO:  It looks like it's every six hours, roughly.



STEVE:  Yeah.  And it's dropping by millions.



LEO:  Yeah, every six hours another million down.  Wow.



STEVE:  I think we're, what, it's like 37 million, I think?



LEO:  No, 29 million.



STEVE:  Ooh, wow, yeah.  I guess it was yesterday that I looked.



LEO:  Another one just came in, 28 million.  That's really interesting.  I mean, literally every - it's roughly every, well, it's every million, but that's roughly every six hours.



STEVE:  Yeah.



LEO:  Wow, so somebody do the math.  It ain't good.



STEVE:  Yeah, get your cell phone now.  No, actually, it won't be a problem.  Don't everybody - don't hyperventilate.  Don't worry about it.  In fact, when I posted this - I did tweet about this, and I said, don't get upset, I mean, this looks like we're running out of IPs very quickly.  What this actually is, is this is the IANA allocating from their final batch.  And we talked about this...



LEO:  Is this, like, the last Class A?



STEVE:  Well, yes.  This is, now, this is them giving away their blocks to the registries.  This is not the registries giving those away.  So this is - and we've expected that in the first couple months of 2011 the IANA would discharge the balance of the blocks that it had available to the major registries, ARIN and so forth, all the major NICs.



LEO:  Is it IANA still, or is it ICANN now?  I thought ICANN superseded IANA.



STEVE:  Okay, I think you're right, it's ICANN.  I'm showing my age.



LEO:  Jon Postel is no longer with us, I'm sorry to say.  It used to be, it wasn't so long ago, there was one guy.  Jon Postel at USC was the guy.  That was it.



STEVE:  And all of those early RFCs had his name on them.  I mean, when I was reading about, originally reading about the TCP/IP stack, that's where it came from, and email protocol and so forth.



LEO:  By the way, Tom Johnson, who does our MailRoute stuff, worked for Jon, so he knows Jon - knew Jon.



STEVE:  No kidding.



LEO:  Yeah.  Which is a pretty good pedigree for somebody who does email spam fighting.



STEVE:  Yeah.  And I do have a short note from another satisfied SpinRite customer who wrote to Greg/GRC, Greg of course being my tech support guy, who said:  "I just wanted to send along a message of thanks for a great product.  I was able to assist one of my customers in recovering data off a drive that I did not think was recoverable.  When I got started, the drive was recognized by the BIOS, but that was about it.  And setting the drive up as a slave drive in another machine caused Windows to claim that the drive was not formatted.  Chkdsk failed to run completely."



He said:  "SpinRite started out saying that it would take 4,500 hours to repair and recover the drive.  So I basically gave up, but decided to let SpinRite run for a while.  After 26 hours, SpinRite claimed that it was...."  Well, SpinRite would have been 16 percent done, although I guess he's saying "claimed" because obviously the estimate is coming down rapidly.  If it did 16 percent in 26 hours, then it's not going to be 4,500 hours for the whole drive.  That's typically something that does happen when SpinRite...



LEO:  Is slow at first.



STEVE:  Exactly, runs into trouble immediately.  There's nothing SpinRite can do except assume that the drive's condition is going to be what it has seen so far.  So it's continually reevaluating its estimate for completion based on the history of what it's seen so far.  So at 26 hours it claimed to be 16 percent done.  "On a whim," writes Peter, "I interrupted the process and tried the drive in a slave scenario again.  At this point I was able to recover much of the data.  I have since let SpinRite go back to work to finish the process.  Even if it takes a few days, you have impressed me and made my customer extremely happy, as they had no backup of their data.  Thanks again, Peter Elkins at Omnitech Computer Services."



LEO:  Isn't that nice.



STEVE:  And Pete, thank you for the note.



LEO:  We are going to get to the fuzzy browsers next.  Steve Gibson, just a word of warning, you have about a half an hour.  Is that enough time to get the fuzzy browsers unfuzzed?



STEVE:  I'm watching the clock, yeah.



LEO:  Thank you.



STEVE:  That'll do it.



LEO:  Steve Gibson today is talking fuzzy browsers, or browser fuzzing.



STEVE:  Yes.



LEO:  What are we talking about?



STEVE:  We touched on this a couple times in recent weeks because Michal Zalewski, who is a Google security guy, released his what he called "Cross_Fuzz" for browsers.  And our listeners will remember that Microsoft tried to - lobbied him to not release this at the beginning of 2011, as he had notified them six months before he was going to, because he provided them with his tool in June or July of 2010 with the plans to release this at the beginning of 2011, and telling them that his browser fuzzer found some fuzziness in their browser, that is, in Internet Explorer, and that they should take it seriously and see about fixing the problem.  He never heard back from them until the middle of December, shortly before it was deadline time for him to release his browser fuzzer.  And they said, hey, wait a minute, now we're able to reproduce the problems which we weren't able to reproduce before.  So we haven't yet had a chance to fix them, so please don't let the world know about these problems, which would happen when you release the fuzzer.



However, it turns out that some malware authors, it is strongly believed, independently discovered the problem because, looking at Google search history, Michal was able to see that there had been some people, I don't remember if it was Russia or China, I think it was in China, that had been doing some search queries that clearly indicated that they knew where this problem was in IE.  So it didn't come from him.  It was already out in the wild.  So he defended his decision to release, I mean, notwithstanding Microsoft's rather lame, well, you only gave us six months, and we didn't take you seriously until two weeks before you were going to release this approach.



Okay.  So was is all this fuzzing?  Fuzzing is a software-testing technique which essentially sends malformed junk, maybe invalid data, unexpected data, or just pseudorandom data, or all of the above, to the inputs of some sort of interpreter or parser, which is expecting to receive normally good data that it's been designed to receive, specifically for the purpose of seeing whether that software can be destabilized by inputs that it was not designed to handle.



Wikipedia tells us that the term "fuzz" originated for the first time in the fall of 1988 from a class project topic in a Professor Barton Miller's graduate University of Wisconsin advanced operating system class.  The assignment was titled "Operating System Utility Program Reliability - The Fuzz Generator," which is where the term first arose.  And so his group of graduate students experimented with this concept of throwing junk at operating system utility programs to see if they could break them.



And, famously, we'll remember that Mark down at eEye in Aliso Viejo, and eEye themselves, had a lab set up where they were essentially doing fuzzing of Windows and finding Windows problems, problems in the Windows API, by calling functions in Windows, providing it with unexpected data, and then when one of - and they had a whole lab set up of machines running.  And every so often one would crash.  And when that would happen, they would look essentially at the  audit trail of what had been sent to cause Windows to crash.  And then that would give them clues for looking closely at what it was that their automated basically noise generator had done to cause the crash.  And this is one of the ways that eEye has found and uncovered many security problems in the Windows operating system.



Now, this is a different approach to normal code testing than has traditionally been done.  What normally happens is that there are essentially two parallel coding efforts.  First you have a specification for some software that you want written.  And the specification determines, specifies what it is that the software will do.  So you have one team, normally the big team, of coders whose job it is to code that spec, that is, to turn that specification into functioning code.



You then have normally sort of like the also-ran group, and they don't get as much glamour.  They're not normally held in as high regard.  But they're the test suite coders.  I would argue that, in this day and age, they need as much glory and as much attention as the main product coders.  The test suite coders have the job of writing code to test the code that the main code writers write.  So they're also working from the same specification.  But their job is to essentially create an automated test suite which, once the product coders say, okay, we've read the spec, we've very carefully coded it, our code does what it's supposed to.  Well, so how do you know that?  Well, a user could play with it and click on things and see.  What's much more efficient, though, is if you have, I mean, one for one, for every chunk of code that you have, you have a test suite.



This is very common, for example, in the crypto field, where you have a bunch of known test data which you encrypt under a given key, and then you know what you should get out if the code is correct.  It's the way we verify that cryptographic code is working the way it should, is we run standard patterns through.  So formal test suite development is something that has been done for years.  It's sometimes called "regression testing."  It's something that Microsoft does is they have a huge test suite, so they want to make sure, when they're in Windows, rummaging around and changing things, they haven't broken something that used to work.



Well, the only practical way to do that, you can't just have a ton of users sitting there trying to see if Windows is broken.  You need something to exercise Windows.  So these exercisers, these test suites have always been created.  But notice that they're being created from the same specification that the coders use.  And while the test suite guys can try to find problems, generally they have the same motivation that the main product coders do, that is, they're working to show that the code meets the specification, rather than not.



LEO:  There's a kind of a theory in coding these days, test-driven programming, where you start by writing a test, which fails immediately, and then you write the code to fulfill a test.  But it doesn't test for these kinds of things.  It tests exactly, as you say, I mean, it's a good way to code.  You have fewer bugs, but it really only tests to see if the code does what it's supposed to do.  Doesn't see if there's a buffer overflow or something like that.



STEVE:  Well, in fact in my own history, a little bit of GRC lore that no one knows, is after SpinRite was up and running and launched - and remember, Leo, I've talked about how I got - GRC grew to about 23 people, I think it was, at its largest.  Well, I had an R&D department with four or five programmers.  And we were working on something to do next.  This was back in the days before caching was even part of the operating system.  You had, like, Windows had SmartDrive, or DOS had SmartDrive that it came with later.  And then there was SmartDrive in Windows.  There were third-party caching utilities which dramatically sped up the operation of the system.



Well, GRC developed one called Propel.  And it was, as you might imagine, better than all of the others.  The programmer who wrote it was really gifted.  I mean, this guy was a spectacular, world-class programmer.  Unfortunately, Propel, to do what we wanted it to, was very complicated.  Well, I was the guy who wrote the tester for it.  And so I wrote sort of a generic program which read and wrote in a very pseudorandom, confusing, worst-case, data-pattern-checking kind of thing, to and from the disk.



The idea would be that, if the cache was not there, then the program would be writing actually to the hard drive, and it would be creating sectors with pseudorandom data and reading and writing and overlapping.  And then when it read it, it would check, it would read back the data to verify that it was what it expected to have stored in that sector.  The idea being that we needed to verify that inserting this cache in between my program and the hard drive didn't change anything.  That is, everything still worked.  The problem is, it would run for a while and crash.  That is, there was some problem that introducing Propel, this never-shipped - and now we know why - never-shipped hard drive cache into the chain caused to fail.



LEO:  Well, timing is so complicated in hard drives.  I mean...



STEVE:  Oh, my goodness.  And actually for all kinds of reasons Propel never saw the light of day.  I wouldn't say that it was ready.  It wasn't like this was the only thing that kept it from being a product.  But I had my own experience with this kind of approach and can vouch for how good it is.



So, Cross_Fuzz.  When Cross_Fuzz was created last summer, it found more than 100 problems in every single browser.  No browser was unscathed.  The largest number of bugs were identified in Firefox.  Michal himself found 10, and then another 50 were found by the Mozilla people when they integrated Cross-Fuzz into their existing testing platform.  The Firefox issues have since largely been addressed, so we're talking, like, 60 problems that have been found have largely been addressed.  But some more obscure and hard-to-analyze crashes are still occurring.  So even today, six-plus months later, if you run Cross_Fuzz on Firefox, you can kill Firefox.



LEO:  Really, wow.



STEVE:  All WebKit-based browsers were brought to their knees, with approximately 24 crashes found.  The developers were notified in July of last year, 2010.  And since then all relevant patches have been released, yet some very subtle problems persist.  And Opera was the other target of Cross_Fuzz.  And Opera's authors were notified also at the same time in July of 2010.  And all of the frequent crashes found by Cross-Fuzz were fixed in Opera 11.



So, what is Cross_Fuzz?  How does it work?  To understand that we need to dip a little into a topic we've never covered before, which is the so-called Document Object Model, or the DOM, of browsers.  When scripting was first created, that is, JavaScript, which was originated by Netscape for the senior Netscape browser at the time, I think it might have been 2 or 3, one of the very early Netscape browsers, the idea was they wanted to create scripting on the client side so that a website could download, not only a static page, but also some scripting which the client, the browser, would execute, it would interpret, in order to make the experience more dynamic for the user.  And of course we know that that's been a mixed blessing because scripting is a real security problem, also a tremendous benefit.



The problem is that pages at the time were described by HTML, the so-called Hyper Text Modeling Language.  And HTML would describe paragraphs and frames and tables and forms and basically all of the content of the web page.  But there was no means for a script running on that page to access the elements of the page, for example, to do fancy effects if you rolled your mouse over something; or to be able to notice, like, check an input field when you were asking for a credit card number, to quickly check to see whether it meets that rule of nines, the way credit cards sort of have a built-in checksum where you can instantly tell whether there might be a typo, a digit transposition, for example.  So there were useful things that you would want to do, but no way for the script running to access the content of that page.



So the good news is we are many years forward from those bloody early days where Microsoft had their own approach, which was incompatible with Netscape's, and browsers that were emerging were inventing their own.  It wasn't until we finally got some standards imposed and the browsers rather reluctantly, over the course of years, began to converge on a single unified standard.  We have that now, called the Document Object Model.



And essentially what browser layout engines which receive HTML, they've basically become HTML parsers, which parse the incoming HTML into the Document Object Model description.  That is, the way things have evolved is that browsers have become so complex; pages have become so complex; HTML, especially with the addition of CSS, cascading style sheets, have gotten so complex that there is now sort of a formal tree-structured container for a page.  And when I say it's tree-structured, the root of that tree is sort of the anchoring document.  And it goes by the term "document."  And then the tree form is sort of described through dotted suffixes.



So, for example, you'd have document dot, and then the name of a form, and then dot, the name of an input field [document.formName.inputName].  Or you might have a table, and then rows and columns, essentially forming what's called a namespace where every single element of the page can be described through this dotted textual representation.  And that's incredible powerful because that then allows scripting, which is running on the page, part of that page, a means for manipulating the page's content.



That is, so while the website loads down the initial HTML, the browser layout engine parses the HTML into this Document Object Model description of the page; and then scripting, which is also part of that HTML download, is itself able to access the entire contents of the page because the HTML describing the page has been translated into this DOM, this Document Object Model, which because there is this textual namespace representation, allows the scripting to sort of access itself.



So what Michal's Cross_Fuzz algorithm does is it opens two windows containing the same document.  And this could be an HTML window, an XHTML, or an SVG, a Scalable Vector Graphic document, which itself is a distressingly complex format.  It then - and I'm reading from his description.  "It crawls the DOM hierarchy of the first document, collecting encountered object references for later reuse.  Visited objects and collected references are tagged using an injected property to avoid infinite recursion; a secondary blacklist is used to prevent navigating away or descending into the master window."  And then, "Critically, random shuffling and recursion fanout control are used to ensure good coverage.



So what that means is basically he's written a script which explores itself, that is, it explores the window that it's being targeted at to basically build a database of all the contents of the window."  Then he says he "repeats the DOM crawl, randomly tweaking encountered object properties by setting them to one of the previously recorded references, (or, with some random probability, to one of a handful of hard-coded 'interesting' values)."  Like a super-large value, super-small value, negative one, zero, positive one, so he's got a collection of things that generally cause problems.  Then he repeats this crawl of the Document Object Model again, randomly calling any object methods which he has encountered.  So he's also invoking JavaScript on the page that he's basically giving a real hard time to.



He calls parameters, or "Call parameters [to those object methods] are synthesized using collected references" and, again, "interesting values," as he noted above.  "If a method returns an object, its output is subsequently crawled and tweaked in a similar manner."  So if calling one of these methods, which is code on the page, if the method returns an object for the page, then he grabs that and crawls that, as well.



So essentially what he's done is he has built something to just give a seizure to, I mean, to just work the heck out of the code, which is hopefully always going to behave itself, never going to have a problem and, you know, just say, yeah, okay, fine, what you asked for was illegal.  Or, yeah, that value doesn't make sense.  We're going to ignore it.  Instead, what often happens is, well, in fact there is not today a browser which can survive.  One way or another, this thing is so horrendous to what it does, it just wrings the code out, and ultimately browsers collapse.



So there are problems with this, that is, and there have always been problems with the fuzzing approach because making something mysteriously break is very different from finding a bug.  You haven't found a bug, you've found a symptom.  And so...



LEO:  Yeah, but you've got a foot in the door.



STEVE:  Yes.  You're right.  And what he's doing is he's auditing what he does.  He uses pseudorandomness.  And we know what that means.  That means that, if you remember the seed, the pseudorandom seed that you used for driving your pseudorandom decisions, and if you start from a known good fixed condition, you can theoretically exactly reproduce what happened because it should be deterministic.  So still, though, this is the problem is that this thing might run for a day, and then the browser finally gives up in defeat.  It says, okay, I just can't do this anymore.



LEO:  I can't do it, I can't do it.



STEVE:  Now, the problem is, you haven't found the bug.  You've just made something die.  And, for example, we never found the problem with Propel.  I mean, this drove Mike, the brilliant coder, to distraction.  I mean, it would run and run and run, and then it would have a problem.  It's like, oh, this sector didn't match.  It's like, well, we don't know why.  And we're sorry, but all we can tell you is it didn't work.  But we don't know why.



So the good news is there is this insanely aggressive tool that now exists which the Mozilla guys, to their credit, have incorporated into their own test suite, which kills Firefox, kills Opera, kills Chrome, it kills anything you let loose.  I mean, it's the destroyer.  It has succeeded through the last six months of its use in rendering our browsers far more robust than before.  That is to say, it takes it a lot longer to kill them than it did before, meaning that all of the problems that sort of were findable have been found.  And the coders learned a lot from having this thing, turning this thing loose on their browsers.  And they now turn it loose routinely, hoping to see - hoping it takes a long time before it brings the browser to its knees.  Ultimately, it does.  And that's browser fuzzing.



LEO:  That's really interesting stuff because it is so closely related to test suites, but it's just going the extra mile, really banging on it.



STEVE:  Right.  The test suites are - and this is what - the advantage of fuzzing is that, although...



LEO:  You're testing it for something else, I guess.



STEVE:  Well, now, it's certainly not just throwing noise.  I mean, that is to say, a huge amount of code had to be written to implement this technology which walks this Document Object Model hierarchy.



LEO:  Is it safe to say it's a stress test?



STEVE:  Oh, it is really, yes, that's exactly what it is.  It is really a stress test.  Browsers should be able to pass it.  None can.  The reason is that this is, I mean, if nothing else it demonstrates how incredibly complex browsers have become in order to do everything that we ask them to do.  I mean, browsers really are - there's a huge amount of code in them.  I mean, in order to run JavaScript, they're doing just-in-time compilation of a language into the native machine's tokenized pseudo-language, which an interpreter then runs.  I mean, we take it for granted.  We go to a website, and it just works.  But, I mean, there is a huge amount of stuff now under the covers.  And we know for the sake of security that it has to be robust.  The problem is, it's difficult to make it so.  So this Cross_Fuzz system, I mean, I'm really happy that it exists because...



LEO:  And it's not just, I guess the point is it's not just used by bad guys.  It would be used by anybody who wanted to test their system; right?



STEVE:  Yes.  And in fact that was the controversial aspect of it is that Microsoft didn't want it released because IE was being brought down.  And if the bad guys - so everybody could run it.  The bad guys could run on IE and use it potentially to find new problems.  So now there's a race on, can Microsoft - I mean, and here's the problem, is when it brings the browser down, again, I mean, I can't emphasize this enough, you really don't know why.  You just know that it died.  And this was why Microsoft couldn't make it fail last July.  They really - they didn't wait long enough, or...



LEO:  Give it time.



STEVE:  ...give it time, exactly.  And what they found was that it required several different documents to be fuzzed in a row before the final document fuzzing caused the problem.  So that meant that you couldn't just run, you couldn't just fuzz the last document.  You had to, like, reproduce the footsteps that Michal had used to get there, which meant that some state somewhere was, like, bleeding across between documents.  The point is that, as we know, crashes beget malicious attacks.  Crashes beget exploits.  And so Microsoft was worried that a bad guy would run this and be better than they were at figuring out exactly what it was that the fuzzing found and then turn that into an exploit that they weren't ready for.



So anyway, this thing exists.  Browsers today, six months after its release privately to the browser authors, are substantially more robust than they were.  And that's why then Michal said, okay, it's 2011.  I'm going to publish this, let it out for the world to play with.  And browsers are ready for it, much more so than they were six months before, when it just knocked them all on their butts.



LEO:  Very interesting stuff.  Browser fuzzing.  Steve Gibson is at GRC.com.  That's the place to go for SpinRite, the world's finest hard drive maintenance and recovery utility, kind of does both.  He also has a lot of free stuff there.  But you'll also find show notes for this show, transcripts.  You'll also find 16KB versions there for the bandwidth-impaired, and a whole lot more.



Somebody in the chatroom said we should someday get a tour of Steve's bookshelf.  If you watch on video, you see all those books behind Steve.  I bet there's some classics there.  And the blinking lights, those are the PDP-8s.



So, Steve, thank you.  We will see you next week.  And we'll do a Q&A.  So if you've got a question for Steve, maybe about this subject or anything else we've covered, just go to GRC.com/feedback.  GRC.com/feedback.  Steve, see you next time on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#286

DATE:		February 3, 2011

TITLE:		Listener Feedback #110

SPEAKERS:	Steve Gibson & Tom Merritt

SOURCE FILE:	http://media.GRC.com/sn/SN-286.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



TOM MERRITT:  This is Security Now! with Steve Gibson, Episode 286, recorded February 2, 2011:  Your questions, Steve's answers, #110.



It's time for Security Now!, the show that helps you stay safe online.  And joining us, as usual, the star of our show, Mr. Security, the man behind GRC.com, Steve Gibson.  Welcome, Steve.



STEVE GIBSON:  Hey, Tom.  Great to be with you this week while Leo is off wherever he is.



TOM:  That's right.  If you were expecting to see Leo Laporte, I'm sorry for the shock.



STEVE:  Or hear Leo Laporte, I guess.



TOM:  Or hear Leo Laporte, if you're on the audio version.  Or read Leo Laporte, if you're reading the transcript.  I don't know if I read different than Leo.



STEVE:  I don't think I took that into account, actually, back in the day when I was writing the code that creates the transcripts.



TOM:  But we've got some good stuff to get to today.  Some security flaws getting handled, I hope?



STEVE:  As always.  And this is a Q&A episode, so we've got questions from our listeners, and comments, and feedback in general.  So we'll go through that and have a good podcast.



TOM:  Yeah, I'm looking forward to the Q&A.  Haven't done a Q&A with you before.  And as I was mentioning before the show, one of the parts of the show where you find the unexpected, when you get some of the most valuable tidbits, I think.



STEVE:  Oh, yeah.  And our listeners, I have a feedback location, GRC.com/feedback, where we remind people they can drop their comments and questions and thoughts.  And very often, in some cases, they're correcting something that I have had said, or asking a great question for an issue that I didn't highlight strongly enough in a prior podcast.  So just lots of good stuff.



TOM:  Yeah, I love that sort of hive mind that you can take advantage of with crowd sourcing, and people pointing out - and some people have more tact than others on it.  But the end result is you learn a lot more because you take advantage of everybody's specialties.



STEVE:  Well, and when you've been out in front of an audience who are doing target practice for a while, your skin gets thick, and you don't take anything personally.



TOM:  Right, you just pay attention to the information.



STEVE:  Just take the value where you can find it.



TOM:  Exactly.  I learned that in journalism school the first time I started doing reports and got ripped to shreds by the editor.  I learned very quickly, don't listen to how he says it, just listen to what he's saying, take that, and learn from it.



STEVE:  Exactly.  Just say, "Thank you very much for your input."



TOM:  But we always try to say things in a very nice and acceptable manner.



STEVE:  Why not?  Well, we've got a couple updates, security-wise, and a bunch of news.  The big news since last week is that a new flaw has been found in IE.  Microsoft has about five other problems that they've been tracking since the beginning of the year, which we ought to be fixing hopefully before long.  This one is something that most users of Windows won't need to be concerned with, if they're not using IE.  It's in the so-called MHTML module of Windows, which actually is not a formal part of Internet Explorer.  This is that feature which only IE has, which allows you to save an entire web page with all of the other assets of the page as a single file.  It creates that HTM, is that what - no, I'm sorry, the MHT file is the so-called "IE archive."



And what someone discovered, and there is proof-of-concept code now in the public, and exploits are expected to be happening before long, someone discovered that there was a mistake in the way this MHTML module was rendering pages that were stored in this format when they were redisplayed, such that you could exploit scripting in this stored archive in order to get arbitrary malicious code to execute.  So Microsoft is working on a fix.  But first of all, anyone using another browser - I'm not sure about Opera, though, because Opera also supports this compressed format.  But I know that Firefox and Chrome - Firefox requires a plug-in and has a different format; Chrome doesn't support it at all.  Safari doesn't support it at all.  So other non-IE users are almost certainly safe.



Microsoft does have one of their little Fixit buttons which can be deployed.  And frankly, if anyone's concerned about this at all, it's easy to use this Fixit, and there's almost no side effects, meaning that there isn't really a downside.  What you're doing is you're turning off scripting support in these MHT files, these IE archives.  And it's hard to imagine that when you want to save the whole page with all the stuff in it, it's hard to imagine that disabling scripting whenever it is you get around to looking at it again would be much of a problem.



TOM:  So this means that, when you save one of those pages as an archive, it won't execute it when you view it later?



STEVE:  Correct.  It won't execute the script, any JavaScript that you saved along with that.  I think...



TOM:  So it doesn't affect the saving, it affects the viewing.



STEVE:  Correct.  And in IE it's that option that IE has always had.  They added this in IE5, which is "save web page complete" I think is what it actually says in the dropdown box.  I've used it in the past.  It's kind of handy to save - if you've got a page, you really want to keep it, not just the HTML, but all the other pieces of it, it bundles them all together.  In fact, MHTML stands for MIME HTML.  MIME is the multipart extension of email, where you're able with MIME to essentially attach different types of objects, binaries, and pictures and code and so forth into an email.



So this is MIME HTML, which is a non-standard format.  This is not part of any larger web standard.  This is just IE which has created this.  What users can do is go to support.microsoft.com/kb/2501696.  So again, that's support.microsoft.com/kb/2501696.  You'll find there one of those little one-click Fixit buttons that Microsoft is doing now, which what it does is it adds some lines to the registry to disable scripting for files with this MHT file extension.  That is, it disables the script handlers, JavaScript, for those documents.  And it does nothing else.  So it's an innocuous, worthwhile fix, I would say, if you're a person who is more likely to encounter malicious stuff; if your habit is to be browsing around out on the Internet, maybe in some shady areas.



It's not clear how soon Microsoft's going to fix this, when that's going to happen.  We are, what, we're February 2nd, so we're not yet at the second Tuesday of February.  So we don't have perhaps too long to wait.  Of course yesterday, Tuesday, was February 1st.  So the second Tuesday of February will be the 8th, which is as soon as it could possible come.  Maybe Microsoft will have it fixed by then, although that's a short window.  This just happened in this last week.  So this may not be time for them to fix it.  We may be waiting till March.  Or they have said they may push out an out-of-cycle update if this thing goes exploit-crazy in the wild.  So the way it's exploited is there is a way that a user can simply visit a website which uses cross-site scripting in order to exploit this MHT problem without a user having to store and view something.  So it's not as if it's necessary for you to store a bad page and then play it back and get zapped.



TOM:  It's not side-loading an MHTML document itself, it's just exploiting the functionality?



STEVE:  Well, the page that you go to and load can say to your browser, load this little snippet of MHT file, and then use the JavaScript in order to execute that and exploit it.  So it is still a one-click deal.  It's where you visit something malicious on the web, and you're toast.  So my feeling is, if you're concerned - first of all, only if you're using IE bother with this because, if you're already on Firefox or Chrome, or probably Opera, then for sure you have nothing to worry about.  And Microsoft, I'm sure, I mean, there is exploit code out.  They're aware of it.  They're working on it.  So with any luck this thing will be fixed pretty quickly.



TOM:  And if you're running NoScript, presumably that protects you, as well; right?



STEVE:  Exactly, because it does require scripting in order to invoke this problem.  But if you're running NoScript, then you're on Firefox, so you're safe anyway.



TOM:  Exactly, it's sort of a catch-22 there.  I use Firefox to save web pages complete anyway because it just saves them as HTML and then puts all the assets in a folder, which I find is much more convenient for being able to look at it again in whatever browser I'm using.  Whereas the MHTML is not handled by all browsers.



STEVE:  Right.  So what Firefox does is it saves the page, and it converts the web links into relative folder references.  So it pulls it out of a folder located right underneath where it's saved the page.  And so you're able to, as you said, redisplay the page not having to have an Internet connection.



TOM:  It's a great way to cache pages, as well.  Speaking of Opera, Opera now has a new version.



STEVE:  Yes.  They had 11, actually hasn't been out for long, when a problem was found that caused them to do 11.01, which is where they are now.  Opera doesn't have a huge market share, but I know that we've got listeners who really like Opera.  They've gotten used to it.  They like the features that are unique to Opera.  So I wanted to advise them that, first of all, that 11.01 has happened.  So make sure that that's what they're running.  That one fixes a bunch of cosmetic UI problems, a handful of minor security issues, and one worrisome remote code execution vulnerability in Microsoft's handling of the "Select" element in HTML forms.  If you loaded a web page that had really long input in the forms, and you could use script in order to load the input, which is what a malicious page would do, that there was an integer truncation problem that would get overwritten.  And we know the rest.  Then the bad guys got control of your machine.



The problem is that Security Focus is also reporting another integer overflow problem in the option, the form "Option" element that still exists in this latest 11.01 release.  It's not clear that there's any active exploitation of it.  Opera does not have a patch.  But they are working on it.  And with any luck they'll have a .02 release that'll fix that one.  But just so I wanted to give Opera users a heads-up, first of all, that Opera had recently gone to .01, that is, v11.01; and that there is still - and there's a known problem with this one, but I imagine Opera will be getting to it and fixing it quickly.  So, because it's very related to the other one.



TOM:  So there are your security updates.  Let's move into the security news.  Google today had a big announcement about new features in Honeycomb.  But we've got some issues with Android's v2.3, Gingerbread, which a lot of people are very excited to get on their phone.  If you're running the Nexus S, you actually have it on your phone right now.  What's going on with this?



STEVE:  Right.  What happened is that there was a known problem with the previous release of Android 2.2 and a data disclosure vulnerability, as it was called, which allowed a malicious link, essentially, either in email or browsing.  So the email link would take you to a web page that was configured to exploit a problem in the browser that would give this malicious site access to your device's SD memory card.  And that might contain financial information, photos, banking records...



TOM:  Anything you store on there, yeah.



STEVE:  Yes.  Essentially they had access to all the files on the SD memory card.  So Google fixed it and said, ta-da, here's Gingerbread v2.3.  Well, an associate professor at North Carolina State University recently informed Google that he had found a way around their fix in this most recently released v2.3.  So essentially this thing has the same problem.  Google is aware of it.  They have verified it, and they're moving to fix it.  The only thing users can do is you could disable JavaScript.  That's one course of action.  Because as, I mean, all of our listeners, Tom, are used to my saying, well, if you disable JavaScript, that solves the problem because of course scripting is just such a problem from a security standpoint.  So here, even over on Android, disabling JavaScript, or using a different web browser.  Instead of using the default web browser, use one of the alternatives that doesn't have the problem.  I'm sure Google will get this fixed and pushed out quickly, but there is a known vulnerability in Gingerbread that they thought had been fixed.  But turns out there's a way to work around that.



TOM:  As with anytime you're using JavaScript, be extra careful about where you're clicking.



STEVE:  Exactly.  And SourceForge, the major open source archive and project management site, was hacked.



TOM:  Oh, yeah.  I heard about it.  This is horrible because SourceForge, if people don't know, is a great place to find open source software.  I mean, if you're ever looking for a free version of anything, if you have an idea of a utility that you wanted, go search SourceForge because chances are, like Google Code, one of those two places has somebody who's been working on something.  But you may be a member of SourceForge if you're a developer, if you're uploading things.  And your data may have gotten hacked here.



STEVE:  Well, yes, and that's the question.  There are 230,000 open source projects that are being managed over at SourceForge.  And what happened was they discovered that somehow a malicious SSH, a secure shell daemon, had gotten into their servers, and it had been maliciously modified to perform password capture of anyone logging into SourceForge over SSH.  So they immediately blocked all logins, and they just shut down login because they could no longer trust the integrity.  They sent email to everyone who had a password, telling them to please change their passwords, after expunging this known malicious SSH daemon from the servers.



And now they're in the process of going back through and performing some sort of audit of the code base because, I mean, as you said, a huge number of high-integrity, highly used open source projects are being managed there.  And the question is, and many people have posed the question, did the bad guys use the password capture to give them access to any major open source projects and modify the source code maliciously so that what was once good source code is now - it's got some hidden backdoors in it.  And that's the question that these guys need to answer.



So we don't really know how bad it is.  I'm hoping that they're actually able to perform an audit.  Bad guys have a way of, especially bad guys who know what they're doing, of covering up their own tracks and, for example, changing modification dates and erasing modification logs and so forth in order to not be found.  So it is scary for a big major site like this to have found themselves with a backdoor that was in active use at the time that they encountered it.



TOM:  Now, can they crowd source the analysis, the code audit, and ask people to kind of pitch in and look for things?  Or is that untrustworthy in this case?



STEVE:  Yeah, that's the problem.  The only way I could see they could do it, they could run maybe a source compare versus offline backups, see whether anything has changed that doesn't look like it's changed.  And that would allow them to find it because they probably have offline backups that would inherently have been unavailable to a bad guy.  So if they were to do a mass comparison of files that showed that they had not been changed, to actually see if they had been changed, then I would think that's partly, probably, one of the things that they're doing.



TOM:  Quite a mess.  I mean, you can still go and download source code from SourceForge.  You can download things from the accounts.  But is that safe?



STEVE:  Yeah, that's the question.



TOM:  I mean, you're always taking a risk when you download anything on the Internet, of course.  But you've got a little extra risk to frost the cupcake, in this case.



STEVE:  Well, yes.  And, for example, we heard, our listeners heard, there was that rumor toward the end of last year that OpenBSD's crypto library had a backdoor installed in it a decade before by the FBI.  And people ran around and really scrutinized the OpenBSD source code.  That rumor was debunked.  It was found that there was nothing bad that happened.  And in fact they did find, by looking at it so closely, they found some things that they wanted to fix because this is code that hadn't been looked at for 10 years.  So they said, oh, well, while we're here we'll fix these other things.



So people feel very good about source being open because it allows scrutiny.  But of course it also requires scrutiny, or you're not getting any value from the source code being open.  So I will keep my eyes out for any further news about this.  And I hope that maybe the bad guys were discovered, this backdoor with the SSH daemon was discovered before anyone had had a chance to do anything bad.  Or that the passwords which were captured were to minor projects.  Hopefully they know which passwords were captured, and then they would know where to look.  That would hugely narrow down their search.



TOM:  That would make things a lot simpler.



STEVE:  Yeah.



TOM:  All right.  We are scraping the bottom of the barrel of IPv4 bucket.  Well, wait.  We're scraping the bottom of the IPv4 barrel.  It's not a barrel and a bucket at the same time.  In any case, the last two freely assignable /8s were given to App Nic.  And now they're down to five, which triggers an interesting rule; right?



STEVE:  Well, I wanted to just - alarm bells have been going off with people because last week I told everybody about the Twitter user which is @IPv4Countdown.  And shortly after bringing that to everyone's attention, the countdown really seems to have accelerated.  I mean, it just started going.  It was like almost every six hours they would be announcing that another /16 had disappeared, and they were down to - I think we were at 32 million IPs, and now it's like it's almost gone down to nothing.  And so I wanted to assure people that there's a little bit of a misnomer to this.  This is the Internet-Assigned Numbers Association, the IANA, handing out, as you just said, Tom, to the major registries the final remaining big blocks of otherwise not previously allocated space.



TOM:  The five families of the Internet.



STEVE:  Right.  This we knew was going to happen early in 2011.  This is different than what is expected to happen late in 2011, which is actual exhaustion.  So the idea is that, out of the 256 possible, zero to 255, first byte of the IP address, there had been a big chunk, well, not a big chunk, but a sizeable number that had never, ever been given out.  And so early this year, and this is what this countdown has been watching, is the IANA finally essentially relenting and handing out the remaining large, never-before-allocated blocks of the Internet space to these five registries.  Then they, during the next six or seven or so months, will be handing these newly received  blocks they just got from the IANA, they'll begin doling out chunks, I mean, jealously and carefully and with minimal waste, doling out just what IP blocks they have to.  They're going to want to conserve this remaining space.



So, I mean, for several years now there's been back pressure on people who wanted IP blocks.  I remember when I first got on the 'Net a decade ago, you could just say, oh, yeah, give me 256.  I want a /24 network.  You could get large allocations with no problem.  When I moved GRC over to Level 3 about three years ago, I had to fill out what they called an "IP Justification Form."  And I was begging for the 16 IPs that I have.  Whereas on my two T1s, I've got 64 sitting here.  I mean, me, where we just connected with Skype.



TOM:  You're on a wealth of riches.



STEVE:  And it's funny, too, because when I switched over to Cogent from Verio, I said to the two tech guys who had gone from Verio to Cogent and so who knew me really well, I said, guys, I really don't need all these.  And they said, well, you've had them before.  You might as well just still have them.  It's like, okay.  So they were being very free and loose with them at the time.  That is certainly not the case anymore.  Now you've got to beg and plead for what few IPs you're able to get from an ISP.  Generally, as long as you're using them, you can keep them.  But there still are all kinds of people, I mean, major corporations and networks, that are hoarding their IPs and don't want to let them go.  And of course the pressure is increasing on them giving them up.



So I did want to make sure people understood that what this IPv4 depletion was showing was really only the obviously visible depletion that's being monitored where the IANA is saying, okay, we've peeled off the last of these, handed them out to the registries.  Now they will individually hand those out over the next six or seven or eight months.  And I've said on this podcast many times in the last few, actually few weeks, that we'll be watching this IPv6 drama unfolding.  And in fact we've got a couple interesting questions from our listeners about that, too.



TOM:  Yeah, June 8th will be IPv6 Day, when several big websites are going to test out their IPv6 capability.  But the interesting thing is, even after that day, they're switching it back off.



STEVE:  Exactly.  And in fact we talked about that a couple weeks ago, saying, okay, so the Internet is running out of IPv4 IPs, like maybe in October or November?  And they're waiting until summer of this year to do, like, the big test?  It's like, okay.  So, yes.  We're in for some very interesting times.



TOM:  If you go to IANA.org you can find the page that has the address space registry and what blocks are allocated and what aren't.  There's only five listed as unallocated right now.  Those are the ones Steve has mentioned are going to be given to the five different regional Internet registries, the RIRs.  And then once those are there, different ones have different policies.  But APP NIC, the Asia Pacific one, says that they think they've got about three to six months before they get down to the very end, and then they're just only going to use what else they haven't allocated as sort of transitional material to try to get people by until they move to IPv6.



We were talking to Dane from Sonic.net last week.  He thinks we'll never get off IPv4.  He thinks we're just going to continue to dual use.  And it will slowly trend towards being predominantly IPv6.  He doesn't think we're going to have a place where suddenly the Internet breaks.  But he also thinks we're never going to get off the crack.  There's still going to be IPv4 addresses used out there.



STEVE:  Well, actually I'm of exactly that opinion.  Consider that there are four billion of them.  And while, yes, there's a problem, for example, with all the cell phone usage, where every cell phone needs an IP address.  IPv4 has a subset on an IPv6 address.  So if you have, I think it's all zeroes, and then two blocks of FFs, and then an IPv4 address tucked in at sort of the least significant bits, the least significant 32 bits of the IPv6 128-bit address.  So there is a formal spec for the way the entire IPv4 address space can always, for all time, it will always live in a small corner of the formal IPv6 address space.  So you could either use IPv4 to get to GRC, for example, I'm 4.79.142.200, so you could use that.  Or you could use this 0000.FFFF.FFFF and then the same thing, 4.79.142.200, which is an IPv6 address that will take you to the same place.



So I'm in complete agreement.  I don't see a day ever, ever, where IPv4 stops being routed.  It'll always exist.  We'll have it in our machines.  And the sad thing is that this is going to be a mess.  We've got some questions in today's Q&A that sort of highlight just what a problem we're probably going to be dealing with.  So, I mean, it's going to be great topic fodder for this podcast as we move through, wade our way through this whole IPv6 and v4 conversion.



TOM:  Do you think anybody's going to come knocking at your door, asking you to spare an IPv4 address?  Would you be able to hand some over, if they did?



STEVE:  Absolutely.  And I would be glad to do so.  If Cogent ever says to me, hey, Steve, we were once really generous, but how many do you really need, I could get by with just a very few here.  I mean, I'm using all the ones that I've got at Level 3.  I don't need more, but I couldn't survive with fewer.  But, yeah, I'd be happy to give Cogent back a block.



TOM:  I think that'll happen in a lot of corners, and it'll extend the life of IPv4 a lot longer than maybe it looks on paper right now because you're not the only one who received them in that time when people thought, eh, there's plenty, take a bunch.



STEVE:  Right.  And probably what'll happen is, I mean, it would be obvious to an ISP who was monitoring traffic, for example, that I'm using three or four IPs out of my block of 64.  I mean, they would just simply see no traffic over those addresses through some length of time.  And I would imagine, if they then - so it's very easy for them to see IP addresses that are not being used.  That would allow them then to come back to me and say, hey, you don't seem to be using these.  Are we wrong?  Or do you just have 54 computers that you haven't turned on or so forth.  Then I'd say no, you're not wrong.  I don't need them.  And they'd say, well, we want them back.  And I'd say, fine.



TOM:  Wait till the IPv6 crunch comes, once the...



STEVE:  Well, it'll be really interesting to see what happens.  But I really think you're right.  And of course we've got NAT, and we'll be talking about that in our Q&A today.



TOM:  All right, let's move on to Google and Connecticut.  Connecticut got a new attorney general.  The old attorney general was really after Google over this WiFi slurping.  The new attorney general has settled.



STEVE:  Well, yeah.  I mentioned this once before.  We've sort of been following the whole Google WiFi-sniffing mistake on the podcast from its very inception.  And I did mention a couple weeks ago that the previous Connecticut AG was demanding that Google hand over all the data that they had captured during their inadvertent sniffing of WiFi in Connecticut.  Google refused, and so it looked like they were going to roll up their sleeves and go to war.  What happened was Google settled, essentially, without needing to go to court, with the formal acknowledgment that Google had inadvertently collected information, including partial and complete email and addresses of requested web pages.



And so essentially Google formally acknowledged what anyone looking at the raw data would have concluded.  I mean, this is entirely reasonable that Connecticut would be satisfied with Google's disclosure and acknowledgment of that, rather than actually requiring the disclosure of the raw data itself.  I mean, it made no sense to me at all when Connecticut was saying this is what they wanted.  And so I was glad to see that Google said no, and then was able to get agreement with Connecticut.  Who knows whether Connecticut's going to go any further with this.  I'm hoping this whole thing blows over because it was clearly just a configuration mistake on their data collection side.  And so much more has been made of this than needed to be made.



TOM:  More privacy violations have happened with governments insisting on looking at the data than would have happened if Google had just deleted it immediately.



STEVE:  Right, right.  So in what I would have to call the "looney tunes" announcement of the week - which many of our listeners sent to me.  I got a bunch of Twitter input from the people who are following me on Twitter.  Computerworld reported a story from the Intel CTO, the chief technology officer of Intel, saying that they, Intel, have new technology on the burner, coming along soon, that will stop zero-day attacks in their tracks.



TOM:  From the chip side.



STEVE:  Yes, some sort.  It's not clear that it's only hardware.  And they did say that this was underway prior to Intel's acquisition of McAfee.  So this is not something that they got from McAfee.  They're claiming that some new feature of their chips will prevent zero-day attacks.



TOM:  Steve?  I hate to say it, but this almost sounds too good to be true.



STEVE:  Gee, you think, Tom?  Okay.  I call it "looney tunes" because, okay, a zero-day attack, as our listeners know, is nothing but a vulnerability which is first discovered because it's found in the wild, being exploited, rather than found by a researcher and divulged to the people who are being potentially exploited, or who are maintaining the whatever it is, the software that is vulnerable, that allows them to patch it before the problem is known.  So...



TOM:  You've got zero days to prepare for it, in other words.



STEVE:  Precisely.  Everybody learns about it when they see it actually being exploited.  So I have to share with our listeners what Computerworld wrote because it quotes this guy from Intel.  So the article, January 26 Computerworld, says:  "Intel's chief technology officer says the chip maker is developing a technology that will be a security game changer.  Justin Rattner told Computerworld on Tuesday that scientists at Intel are working on security technology that will stop all zero-day attacks.  And, while he would give few details about it, he said he hopes the new technology will be ready to be released this year.



"'I think we have some real breakthrough ideas about changing the game in terms of malware,' Rattner said."  Continuing the quote, "'We're going to see a quantum jump in the ability of future devices, be they PCs or phones or tablets or smart TVs, to defend themselves against attacks.'



"He noted that the technology won't be signature-based, like so much security is today.  Signature-based malware detection is based on searching for known patterns within malicious code.  The problem, though, is that zero-day, or brand new, malware attacks are often successful because they have no known signatures to guard against."



Still reading from this Computerworld article, "Intel is working around this problem by not depending on signatures.  And the technology will be hardware based, though it's still unclear if it will have a software component."



And then Rattner again was quoted:  "'Right now, anti-malware depends on signatures, so if you haven't seen the attack before, it goes right past you unnoticed,' said Rattner, who called the technology 'radically different.'  'We've found a new approach that stops the most virulent attacks.  It will stop zero-day scenarios.  Even if we've never seen it, we can stop it dead in its tracks,' he said."



TOM:  So what it sounds like to me, if I had to read the tea leaves, is that they've figured out a way to prevent against some attacks based on not having a signature.  And that's not entirely new.  People have claimed that before.  But the idea of coming out and saying they've solved zero-day vulnerabilities, that's just grabbing for press attention.  They can't have done that.



STEVE:  Well, yes.  What they're doing is they're saying, if we take it literally, they're saying we're preventing there ever from being an attack which is not known.  Which, I mean, is nutty.  And, for example, we've talked about the so-called "execution disable flag" which exists now in all Intel architectures, where, for example, you can set this flag for the pages of memory which the stack lives in, and the pages of memory which contain data.  And the Intel chipset will refuse to execute code from those memory pages that have that bit set.  So there we have hardware which is enforcing and preventing stack overflow execution problems.  Yet we still have those problems.



I mean, so, yes, it's better than not having it.  But it didn't, like, immediately solve buffer overrun problems.  We've got the bits.  Everyone's using them now.  And we still have buffer overrun problems.  So, I mean, on one hand you're sort of tempted to go, wow, Intel, how could they be wrong?  On the other hand, how could they be right?



TOM:  It's not like Intel is like Steorn, the perpetual motion machine company from Ireland, just making some ridiculously crazy claim that no one will ever believe.  It's Intel.  There's something behind this.  They've just - they've notched the rhetoric up a couple times, as indicated by using the word "quantum" to mean some sort of amazing advance.  It's just all puffery.  I'm sure that they've got something that is pretty interesting, and hopefully will advance security.  But you know more than anyone else it's an arms race.  Nothing is ever going to prevent everything.



STEVE:  And frankly, I mean, for a company as big as Intel, I'm sure the CTO means well.  But he's a C-letter executive who probably heard something interesting from the lab and doesn't really understand it himself.  So anyway...



TOM:  Yeah, there's a difference between, "Yes, sir, this will stop zero-day vulnerabilities," and "This will stop all zero-day vulnerabilities."



STEVE:  Or we've come up with an interesting idea that may help us to improve the security of future chipsets when operating systems and all programmers behave correctly.



TOM:  Well, because you're not going to fix the user.  I mean, even forgetting everything else, the biggest vulnerability is the person using the machine.



STEVE:  Yeah.  A lot of really smart people have been looking at this problem for a long time.  And it still escapes us, that is, the solution to it still escapes us.  So it would be nice to have maybe some sort of hardware support that will give us a better handle.  Claiming that it stops zero-day attacks is just nutty, and it makes for great press.



TOM:  Yeah, exactly, makes for good headlines.  Call me when they have a patch for PEBCAK.  All right, let's move on to - actually this is a little bit of a patch for PEBCAK - Facebook finally implementing the ability to have a secure connection, have an SSL connection all the time.



STEVE:  Well, I announced it last week, yes.  I announced it in our podcast last week.  That morning, literally just a few hours before the podcast, Facebook's blog, their security blog, announced that they would allow users to optionally set the enforcement of SSL secure connections whenever they're using Facebook, whenever possible.  However, at that time my own Facebook account, which I use for testing purposes, did not yet show that checkbox.  We saw a screenshot of it in the blog posting, so I knew what it was going to look like.  And I did get some Twitter feedback saying, "Hey, Steve, I saw your tweet about this, but I don't have it yet."



So I did want to let everyone know that now, a week later, I know you said you found it.  I have found it on my Facebook page.  So, although I did, just in the chatroom chat before we began recording this podcast, someone mentioned that their dad's Facebook page still didn't have it.  I consider that anecdotal.  I bet it's there now, as long as they go look for it in the right place.



So I did want to follow up and just say, if any listeners excitedly went to their accounts after hearing about this announcement last week and were disappointed not to find it, check again if you haven't.  I'll bet it's there now.  Turn that on.  And of course what that does is, it means that you have an SSL connection for all of your use of Facebook.



I did see that some third-party applications running on Facebook may have a problem with this, and may not support it, which may be why it's not turned on by default.  So if you turn it on, and things break or don't work, first of all, I'd love to know about it:  GRC.com/feedback.  But by all means, I immediately turned mine on, and it just means that when you're roaming around, especially in unsecured open WiFi hotspots, that you're not going to be subjected to abuses by Firesheep and its ilk.



TOM:  Yeah, go to Account, and then you want to get the Account Settings.  And on that main settings page, Account Security, you should have it say "Set up secure browsing (HTTPS) and log-in alerts."  And then you click Change for that, and then you're able to hit a checkbox that'll allow you to do it.  If you don't see that, you haven't got it yet.



STEVE:  And do make sure you click Save, which is right underneath that checkbox.



TOM:  Yes, absolutely.



STEVE:  Because just turning the checkbox on doesn't do it.  You've got to save that change.



TOM:  Very good point.  All right.



STEVE:  I have some feedback from a listener about SpinRite.  His email handle is LeeBing, but his name is Leland.  And he sent an email actually to my tech support guy, who forwarded it to me, saying "GRC Thanks."  He said:  "Please let Steve know that it may not have been a miraculous story, but still extremely thankful for SpinRite.  My wife runs her own business from home.  Internet Explorer had been acting odd, some crashes lately, so she didn't think much of it when it crashed the other morning.  She closed out and rebooted her computer like normal, except this time it wouldn't boot, not even into safe mode.  It would try to start, but just automatically reboot again on each attempt.



"Not wanting to have to reinstall all her software applications and settings if I didn't have to, I spent over three hours getting a new install of Windows XP into a different partition, hoping to then run a virus scan on the offending partition, assuming that that had caused the problem.  But I couldn't read the drive at all.



"After many other attempted workarounds, I knew I had one good option remaining.  I knew from all the stories shared on Security Now! that there would come a day that I wished I had a copy of SpinRite on hand.  I downloaded and purchased SpinRite from another computer.  Oh, I hate to think if I hadn't had a second computer working in the house.



"This was about 10:30 p.m. on a Wednesday night by this time.  Within five minutes of starting, SpinRite found a bad sector and started recovering the data from it.  Within 15 minutes it was done with that entire partition.  Upon rebooting, I waited while Windows corrected some cross-linked files and such.  But then it came right up into my wife's normal screen, and the machine has been running fine since then."



Then he has this in caps, he says, "PLEASE PASS ON TO OTHER LISTENERS!  Don't wait until the day comes that you wish you had SpinRite on hand.  The day you...."  And he's saying this, I'm not.  "The day you need it, you may not be able to simply walk over to another computer and download it."  Well, you probably have some friends who could help you out.  Anyway, he says, "And stop wasting hours avoiding using it or delay getting it.  Had I started with SpinRite when I got home, I would have been in bed early instead of up late.  Thanks again for the great software and great work on Security Now! and GRC.com.  Sincerely, Leland in Raytown, Missouri."



TOM:  It's a good point.  Have your tools downloaded and on a CD or USB drive.  It'll save you time.



STEVE:  Well, it does.  I don't realistically expect people to buy SpinRite when they don't need it.  But it certainly, I mean, what we do see is that having SpinRite on hand and, more importantly, running it preemptively, solves this kind of problem.  Leland never had a chance to buy it.  Had he owned it and run it, it would have fixed this problem prior to it getting to the point where that machine would no longer boot.  So really I think that's the great benefit.



TOM:  Steve, it's time for another listener feedback episode, Episode 110 of Listener Feedback.  We've got nine questions today.  First one comes from Ben in Atlanta, who doesn't quite understand whether XORing for encryption is good or bad.  He says:  I'm confused about your opinion on using XOR in encryption.  I believe you previously said that it is "bad," but in the episode on Bluetooth you spoke briefly about RC4, and you said that it was fine to XOR with the RC4 stream.  Could you please explain the issue?



STEVE:  Okay.  So this is confusing.  I guess the way to explain it from a thousand feet is to say that XORing itself is a useful and valuable technique for mixing a pseudorandom stream with plaintext in order to convert into ciphertext.  The idea being that, if you - and we did cover this at length in our crypto episodes.  So a listener who wants, like, more in-depth coverage of the topic can certainly go back and get a whole podcast on how this works.



The idea is that the XOR operation is essentially a conditional bit inversion.  If you XOR zero and zero, you get zero.  If you XOR zero and one, you get one.  If you XOR one and zero, you get one.  And if you XOR one and one, you get zero.  So if you were to, like, write that down on a napkin and look at it, you would see that, essentially, if you consider one of those bits of input to be the plaintext, and the other bit of input to be like a control bit, that control bit, whether the control bit is one or zero, determines whether the data bit is inverted or not.  So if the control bit is zero, and you XOR anything with a zero, you get the same thing.  If you XOR anything with a one, it inverts the data.



So what's so cool is, if you have a source of pseudorandom data, pseudorandom noise, then, almost counterintuitive though it is, if you take regular plaintext, and you XOR it with the pseudorandom noise, the pseudorandom noise being sort of that control bit, it determines whether the bits are flipped in the plaintext in a random, a pseudorandom fashion, which performs as good an encryption as exists.  That is, it's absolutely unbreakable, given some limitations.



And so I think this is where Ben is confused and where I have talked about XORing and the problems with XORing.  Given that you absolutely never reuse that pseudorandom data, and that's crucial, and, well, with that single caveat that you never reuse that pseudorandom data, so that it's always different each time you perform an encryption against plaintext, then you've got absolutely bulletproof encryption.  The beauty of it is that, when you take that encrypted data and so the same process again, XOR it again with the same pseudorandom data, since you'll be reinverting the same bits in the encrypted data, which you inverted to create the encrypted data, it reverts it to plaintext.



So it's of tremendous value, for example, in wireless communications.  We use it right now in WPA, which is an industrial-strength, bulletproof encryption technology which works great.  It does require that it be handled properly.  And it is the encryption that's used in Bluetooth.  Bluetooth uses a pseudorandom bitstream and XORs the plaintext to create the ciphertext.  The weakness comes from, if you know what some of the encrypted text actually is in plaintext, the so-called "known plaintext approach," if you know what that is, then you can XOR what you know with the ciphertext and recover the pseudorandom bitstream.



So that allows you - essentially we have three things.  We've got the bitstream, the plaintext, and the resulting ciphertext.  Any two of them will give you the third.  So if you know what the plaintext is for corresponding ciphertext, you can XOR those, and what falls out is the pseudorandom bitstream.



TOM:  And that's why you don't want to reuse it, right, because then it could be used to unlock anything else you've used with that stream.



STEVE:  Exactly.  Exactly.  So if you ever made the mistake of reusing that same stream, now that you've been able to recover it, knowing some of the data that was encrypted, you can recover other data which you don't know the value of.  And so the whole thing falls apart.  So while it works, and it's very useful, especially in any situation where you just don't have much computing power, you have to be very careful with the way it's applied.  So I like it.  But, again, people have continued, over time, people who have used XORing for encryption have made mistakes that ended up biting them.  And so essentially the world sort of moved away from it, over to, for example, AES encryption, which is far stronger and doesn't have these same sorts of weaknesses.  So, yes, I like it.  But you just have to be very careful with the way you use it.



TOM:  Right.  And you don't have to be as careful with AES.



STEVE:  You have different - you have to be careful in different ways with AES. 



TOM:  It's not as easy to mess up?



STEVE:  Correct.



TOM:  Yeah.  Question #2 comes from Chris Lincoln in Fremont, California, who thinks he's found another mass cookie OptOut solution.  I think you mentioned before about Firefox and Chrome having their own plans for opting out.  Chris says:  Steve, on the recent Security Now! podcast you mentioned the script on aboutads.info didn't get you many options to opt out from online ads.  For Firefox users, I recommend the "Beef Taco" add-on.  TACO stands for "Targeted Advertising Cookie Opt-out."  Cookies and tacos, and it's lunchtime.  I'm getting hungry.  It registers local cookies with the opt-out setting for over 100 online advertisers, and the cookies stay even when clearing the cookies within the browser.  This makes reading Spybot S&D scans tedious, but it eliminates the majority of what came up in my scans anyway.



A lightweight TACO, known as "Beef Taco," is available at GitHub and Mozilla Add-Ons and sets 132 opt-out cookies.  It is lightweight, completely non-intrusive, and you can see the full list of cookies at github.com/jmhobbs/beef-taco.  Note that it includes Google/DoubleClick.  I'll take a look.  Did you take a look at this?



STEVE:  I did, and I wasn't clear what I was seeing.  There were some complaints about v3 having become bloated and a real problem, and people saying just stick with v2.  Essentially, we talked last week about this aboutads.info page.  And what's there is a script which allows advertisers who are participating to sort of log themselves in, log in their participation with this website.  And then you run a script there, JavaScript, which causes your browser to go to each of those advertisers, asking to please receive an opt-out cookie from them.  So my complaint was that, while there were, like, I don't know, 60 or 70 apparently present advertisers, when I tried that aboutads.info page, I was only able to opt out of maybe nine or 10.  It said that it was unable to get the other ones to behave.  Maybe they've registered, but they don't yet have handlers for this aboutads.info page.  So it didn't seem very effective.



So I just wanted to bring Chris's mention of Beef TACO to our listeners' attention.  What this is, is different.  This of course is - it's something which is sort of pre-installing those opt-out cookies for you.  You don't have to visit those websites.  It just comes along with 132 sort of premade cookies, which it will just automatically put into Firefox's database when you run it.  So it's sort of like a built-in blacklist for opt-out advertisers.  And the reason he mentions that Google/DoubleClick is also listed there among those is that I did note that Chrome was promoting a solution also, which interestingly did not include their own advertiser, DoubleClick.  And so he was just bringing up the point this week that, well, this solution does include that.



So this is sort of another approach.  I wanted to let our listeners know about it.  I'm sort of annoyed at the idea of installing 132 cookies into my browser.  I'm using NoScript and AdBlocker and so forth to not go to these places.  But I could see that this could appeal to some people.



TOM:  Yeah, I think NoScript and AdBlocker are probably your best bet, if you're really concerned about this.  But the FTC has called for some sort of opt-out list, and we're going to see more of these kinds of solutions being put out there.



STEVE:  Right.



TOM:  Question #3 comes from Lucas J. in Maryland, wondering about delaying IPv4 depletion.  You had said we were going to get back to this topic earlier in the show.  Lucas asks:  Could ISPs, phone companies, et cetera, help delay IPv4 depletion through NAT (Network Address Translation)?  I know I've heard before of ISPs putting their whole customer base behind one large NAT, giving them all one Internet-facing IP address.  Couldn't we do this on a large scale?  All Comcast customers on the East Coast could have one of a handful of IP addresses; all Verizon phones have one of a handful of IP addresses.  Wouldn't this help, or are there more downsides than positive benefits? 



STEVE:  Well, yes.  First of all, it is NAT which has allowed the Internet to survive as long as it has.  I mean, I know that all of our listeners have NAT routers, and these days probably have many more than one IP operating in their own home networks.  So all of those IPs, all those machines behind their home NAT routers are seen publicly as a single IPv4 address.  Now, it is the case that some ISPs have for years been running their users on, for example, 10-dot addresses.  The 10-dot network has 16 million IPs behind it.  So it's all the IPs beginning with 10.  And then you've got three more bytes.  So that's 24 bits of space that is 16 million different combinations.



So an ISP that has up to 16 million customers could put the entire customer base on a nonroutable 10-dot network behind NAT.  You probably, well, you almost certainly cannot get by with one Internet-facing IP address because the way network address translation works is it essentially uses port numbers.  Technically it's called Network Port Address Translation, although people shortened it to NAT.  It actually uses port numbers to disambiguate the target IP for traffic coming back.  So it builds - there's a table in the NAT router which has outgoing traffic exits, egresses from the ISP.  It translates the port number and puts it in a table so that, when the traffic comes back, it's able to determine which IP behind the NAT router should receive the traffic.



Well, that works well if you have a handful of machines.  But remember the port numbers are only 16 bits.  And not all of them are available for translation.  Generally you use a subset of those.  So if you've only got less than 16, you have fewer than 16 bits of port number, there's no way to map that into as many as 24 bits of possible IP addresses behind the NAT router.  What that means is you simply need many more than one Internet-facing IP address.  But still this is not an intractable problem.  I don't know if ISPs are going to do this.  But, I mean, NAT has kept us going as long as we have.  Some ISPs do put their customers behind NAT already.  And it's certainly possible that more could in the future.



The problem with doing this, second part of Lucas's question was, you know, are there downsides?  The problem is that we use NAT, we home users use it because it gives us very good firewall, stateful firewall-like protection.  Unsolicited incoming traffic has nowhere to go because it's the outgoing traffic that creates the mapping for the traffic to return to the proper computer.  Which inherently gives us firewall-like capabilities.



But many customers deliberately create static mappings through their NAT router if they want to run some sort of server.  If they deliberately want to make services available, their own home network services available on the Internet, then they're able to do so.  In some cases they will use a feature of the NAT that does route unsolicited traffic over to a given IP address, over to a specific machine.  In another case they'll use static port mapping.  The problem is you lose that ability if you're behind an ISP NAT because the ISP controls the NAT router.  You have no control over the NAT router.  So you would be on a private IP address, and you'd have no way ever of reaching machines in your home network from out on the Internet because unsolicited incoming traffic would be dropped by your ISP.



So there really is a downside to this.  I've long wondered whether sort of low-end consumer Internet users might ultimately lose the ability to serve on the Internet.  That is, they would be clients of the Internet, but inherently not servers.  That would be a sad day, but we're going to have an interesting year here, and we'll have to see how it develops.



TOM:  That's another creative way for ISPs to charge you.  In other words, if you're the kind of person who just wants to passively surf and send email, you'd sign up for the NAT account.  But if you've got UPnP in your Xbox, or you want to do some remote computing, well, you've got sign up for the extra tier.



STEVE:  Right.



TOM:  And NAT was supposed to protect us from them charging us for these sorts of things.  Question #4, Steven in Baltimore has a question about home networking.  He says:  My question is about WPA passwords and how it salts the password with the SSID.  Right now I'm using one of your super long crazy passwords, and it's no fun to type with onscreen keyboards like on the Wii or Nintendo DS.  I know that pain, man.  I'm with you, Steven.  I'm wondering if I can use one of the passwords generated from your site as the SSID instead of the password, and a smaller password, say like 20 characters?  Would that offer any protection with the smaller password?



STEVE:  Well, that is a brilliant idea.



TOM:  That's clever, huh.



STEVE:  I thought that very clever.



TOM:  And then you don't broadcast the SSID?  Is that part of this?



STEVE:  Right, right.  So we talked about the way the WPA functions and the way it converts your password that you provide into the key which is used by the crypto.  What happens is these guys who did WPA knew their security very well, much more so than the people who did the original WEP WiFi encryption that was so badly broken.  They take your password and the SSID and merge them together and then hash them using SHA-1 4,096 times.  They do it 4,096 times, not because that makes it more secure, but because it makes it much more difficult to brute-force.  That is, you take the raw password, mix it with the SSID, and then there's a computational burden to hash that 4,096 times, rather than just, for example, hashing it once.  So anyone who was trying to do brute-force attack would be forced to do the same 4,096 repetitive hashes in order to get the key at the other end that they could then attempt to apply to your encrypted stream to see whether it decrypted.  So that's how the system works.



What Steve is asking is, hey, I've got a fancy password and a simple SSID, and those are being mixed together and then hashed.  Why don't I reverse it and use a simple password and a wacky SSID because they're being mixed together and then hashed.  Wouldn't that give me the same?  It's a cool and clever idea.  The problem is that just turning off the SSID broadcast does not remove the SSID from the packet stream.  Anyone sniffing your WiFi traffic will be able to capture your network's SSID.  Not every packet contains it, but various management packets do.  And so if they were doing a sniff, which they would be anyway in order to determine whether they were able to crack this, they would get the SSID.  So the fact that you've made it really long and gnarly won't help you enhance the security, and you'd still, the only real strength you have is unfortunately from your password strength.



On the other hand, 20 really bizarre random characters, it doesn't have to be 64.  64, I would argue, especially if you're using one of my crazy passwords from GRC.com/passwords, which is just absolutely high-entropy gibberish, 20 is still a lot to go through brute-forcing.  Most people are going to use a dictionary attack.  They are going to try something.  But the fact that the hash requires this 4,096 iterations in order to generate the key, that creates enough of a computational overhead that, you know, I'm not saying 20 characters is enough.  It depends up on how determined you are to have security.  Maybe make it 40.  But still, that's an awful lot of security.



TOM:  And those onscreen keyboards are really the problem.  It's not your password, it's the fact that those onscreen keyboards are so darn hard to use in the end there because, if you want to stay secure, it's - you only have to put it in once.  It's not like you're putting it every time you turn on the Wii or something like that.



STEVE:  Right.



TOM:  Question #5, Joel Oliver in Pittston, Pennsylvania says:  Hi, Steve.  Wanted to chime in to the fact that TRIM is also supported in Linux, as long as the distribution is running kernel 2.6.33 or later.  All that needs to be done is to add "discard" to the drives option in the etc/fstab file.  Also FreeBSD 8.2 and up supports TRIM in the UFS file systems.  Thanks for the great podcast.



STEVE:  Okay.  So I misspoke, everybody.  And, yes, we were discussing TRIM last week, and I said that the only operating system that supports it was Windows 7 [buzzer sound].



TOM:  Never say never, huh?  Never say only.



STEVE:  I know that Linux supports it.  I was only, in my mindset, I was thinking about, unfortunately, I apologize, Linux people, I was thinking about Microsoft and Apple, PCs and Macs.  And so of those operating systems, only Windows 7 supports TRIM.  It absolutely is the case that the Linux and some of the BSD OSes support it, as well.  So I wanted to - I chose Joel's note, but I received about 50 different pieces of email from people saying, "Steve, I'm using it on Linux."  And I thought, okay.  So I wanted to acknowledge everybody who wrote to me, to thank you and to say, yes, everyone is right.  TRIM support does exist outside of the small, well, not small, but the Windows 7 universe.



TOM:  I usually do this with Opera, so I feel your pain.  And then I get the 50 things, people saying you forgot Opera does this.  Question #6, Russell Spitler in San Mateo doubts the usefulness of software-based tokens.  He says:  In Listener Feedback #109 you discuss and encourage a software-based alternative to the common one-time use hardware authentication tokens.  This really rubbed me the wrong way.  Please correct me if I am wrong, but given my understanding of the authentication tokens, a software solution invalidates most of the security they provide. 

 

The one-time use tokens work on three inputs:  the current time, a crypto algorithm, and a shared secret between the token and the authenticating server in the backend.  While you can be reasonably assured that the shared secret found in a tamper-proof hardware token cannot be compromised without your knowledge, the same is far from true with a software-based solution.  By embedding the shared secret in a software solution you are compromising the basic premise of the token.  Having worked for a number of years in software security in particular, it is certainly a tractable problem to extract the secret from the software.  Use of software-based one-time use password generators is far from the same level of security as a hardware token.



STEVE:  Okay.  You did that in one breath, too.  That was very good, Tom.



TOM:  Thanks.  I was assuming Russell had also written in one breath.



STEVE:  I think he did.  He was upset with me.  Okay.  So he says, "Please correct me if I am wrong, but given my understanding of the authentication tokens, a software solution invalidates most of the security they provide."  Okay, Russell, I think you're wrong.  But I also think you have a point.  First of all, what I was referring to was that I had discovered that the VeriSign VIP service was now offering a BlackBerry applet, and there's also one for iPhone, and I'm not sure about Android.  There either is, or there will soon be.  But that would be in addition to either the one-time use credit card, the one-time password credit card, or the often-discussed football, which is a time-based system.



So I have a web page that wants me to log in, say I'm using PayPal or eBay.  And I have to use my BlackBerry in order to - which is running software, which knows what time it is and is generating a six-character token from that.  So if I was running software that was running on the PC, in the PC, where it's inherently on the same platform in the same world where malware might be crawling around, where some scripting on the page that I've gone on might have some way of getting loose and, like, figuring out what my software key is, I mean, I can theoretically understand what Russell means.



But I've got an entirely separate device, physically separate, different operating system, different architecture.  I don't see any way for software that I'm logging into a site with to somehow leap across space into my BlackBerry.  Now, okay.  I mean, playing devil's advocate, if my BlackBerry were infected, then I couldn't trust the integrity of this VIP system.  That is, the BlackBerry would have to be infected.  It would have to be communicating then with some site that knows I'm going to be logging in with my BlackBerry.



Anyway, I guess my point is that it seems a real stretch.  Is a software-based solution which is using a telephone, a smart phone as a hardware platform, is that fundamentally less secure than a hardware token?  Yes.  I would agree it is.  However, what we're accomplishing with using a time-based, always-changing token is dramatically greater security than if we don't have it.  So my feeling is, it might be theoretically somewhat less secure, but vastly more secure than not using it at all.  So, and it cost nothing.  It was free.  I added it as an app to my BlackBerry.  So, I mean, to me it's a huge win, one that I'm happy to encourage our listeners to use because the cost is negligible, and the benefits far outweigh essentially not using it, or even having it compromised, which would be the same as not having it at all.  So you don't lose anything, and all you have is a lot to gain.



TOM:  All right, I'm going to move this along so we can get our last three questions in here before we have to wrap.  Eric in San Jose says:  Hi, Steve.  Love the show.  Long-time listener.  So my broadband finally got upgraded at work.  It's fast.  But after speed tests I found that at home my D-Link DFL 200 firewall router could only support 15Mbps down and 3.5Mbps up while also running a site-to-site VPN.  So I decided to set up an Astaro Security Gateway at home - free license - to test the ASG's performance.  With a very old Dell box I got 95Mbps down with Comcast.  Only 3.5Mbps up, so uploads are throttled by my ISP.  Well, it took a little bit of thinking, and I decided to upgrade the NICs in the ASG to gigabit cards.  I am now getting 392.90Mbps down on my fastest run.  Still only 3.5Mbps up.

 

I thought other home users might be interested in upgrading to an ASG after hearing this.  Please, however, don't be a bandwidth hog in my neighborhood.



STEVE:  So I thought this was a great post for a couple reasons.  It is absolutely the case that these little plastic box, $49 SOHO consumer routers are built with the least expensive technology possible.  They get the job done, but it is very easy to overload them.  For whatever reason, many of the things that I've been doing in the last year, when I was working with the DNS Benchmark and the spoofability test, one of the things I had to deliberately do was throttle the spoofability test at GRC and the DNS Benchmark, specifically so as not to overload these little consumer routers.  So I've bumped up against their very significant performance and packet processing limitations myself a lot.



So the first part of this is what Eric did was, he said, hey, I think I should be getting better performance than I'm seeing with my - in this case, this was a D-Link DFL 200 firewall router.  So he switched to an old PC, a Dell PC on which he loaded the Astaro Security Gateway.  And lo and behold, his download performance went from 50Mb to 95, meaning that that little D-Link router was the choke point for him.  And when he switched to a PC, which is a much, I mean, vastly more capable computer than what goes in one of those little blue plastic boxes, he saw a huge jump in download performance.



Then, even though he was at 95Mb, okay, so 95Mb is very close to 100Mb, which was the limit of his networking cards.  So he did the next thing, which was to switch from 100Mb cards to a gigabit card.  And not surprisingly, it turned out that it was the Network Interface Card, that the 100Mb card was the thing that was blocking him at 95, which actually is pretty good performance to get on a 100Mb card.  So he went to a gigabit card.  Now he's at 392Mb.



So a couple of really good lessons, and one is to consider whether your little, cheap, cheesy, $40 blue router might be causing you to lose performance, which getting any random old machine and setting it up as a network gateway using Astaro Security Gateway, might give you much better performance.  It's definitely something to think about.



TOM:  Very clever.  Very brilliant.  And very frugal.



STEVE:  Yeah.



TOM:  Very green, re-using.  Question #8 comes from Nick Jackson in Austin, Texas, says:  As I was listening to the latest podcast about browser fuzzing - that's #285 - your discussion of IE, Firefox, and Chrome's different approaches to implementing a do-not-track system reminded me of one of my favorite episodes - and one of the most unnerving - #264, side-channel privacy leakage.  You endorsed Firefox's approach to do-not-track, namely adding an HTTP header, and that certainly makes sense as a forward-looking measure to ensure that web advertisers are technologically capable of honoring these requests in the hopeful event that legislation makes this mandatory. 



I am not particularly a fan of IE.  However, from your description it sounds like Microsoft's Tracking Protection List (TPL) approach works essentially like a blacklist for stopping the browser from visiting, running code, or accepting cookies from certain sites.  So my thought was, doesn't Microsoft's approach work better as a deterrent to side-channel privacy leakage?  In other words, under Firefox's approach, recalcitrant web advertisers may nominally support "do not track" headers by not using tracking cookies, but nevertheless continue to profile and uniquely identify you through a variety of other unique facets of your machine.



IE's TPL blacklist, it sounds like, would simply prevent connections from being made to these profiling companies at all, stopping the side-channel privacy leakage problem at its source by never allowing you to share potentially uniquely identifying information to third-party servers.  In fact, I would guess that the best combination would be both HTTP headers and a blacklist, which many people, including myself, get by using NoScript and AdBlock Plus.  Do you think Microsoft is onto something unique here that Mozilla and Google aren't trying?



STEVE:  Well, I thought that was a great question, and I included it here because I wanted to - we sort of covered this point in Episode 265, when we talked about this.  But I did want to draw our listeners' attention back to the fact that, as Nick says, Microsoft's TPL, the Tracking Protection List approach, from what little we've seen and read about it - this is going to be in IE9 - from what Microsoft has said is that any sites whose URLs match the pattern matching of a TPL list will be prevented from, exactly as Nick says, ever going.  So it's exactly as he says, the notion of essentially creating a blacklist.



Many users now, for example, use a hosts file, which they'll get from the Internet and maintain it.  The hosts file contains a huge list of typically advertiser domain names which they use to short-circuit DNS lookups, just for example turning it into 127.0.0.1, which is your own local IP, which prevents your browser from ever successfully going out to one of those advertisers.  This is very much the same in that it similarly would protect - it would allow IE to manage which sites it was allowed to go to and which it wasn't.  And essentially, I don't know that I would describe this really as side-channel leakage, but he is right that, depending upon the way the legislation is written, if the advertisers still got you, even though you had a header saying do not track me, then you're still making contact with a site that you may rather not have any contact with.



I'm hoping that this TPL approach does make it into IE.  If this becomes a standard, then I would imagine that Firefox and Chrome and the others would pick up on this approach because it is more aggressive than what they're doing; but if it's sort of managed for us by websites that we visit, saying, well, you have to be able to visit our advertisers in order for us to provide you with valid content, please click this list in order to add an exception to the TPL, if you agree to that, then that gives users a lot of control.  I can see it potentially gets confusing.  We're going to have to see how it all washes out.  But I did want to sort of reiterate that it's something hopeful from IE.  And because it's so good, if it ends up taking off, we may see other browsers doing it, too.



TOM:  And our final question comes from James Daldry in Raleigh, North Carolina.  And we're back to IPv6.  He says he uses a Linksys WRT54GL router - I used to have one of those routers - which is upgradeable to IPv6 by changing to Tomato firmware.  My problem is that every article I read extols the virtues of hanging your system's bare IP stack out on the public Internet, which of course you could do since there will be plenty of IPs available under v6. But no one mentions the security benefits of NAT.  So will my router stop NATing under v6, and will I have to become a sysadmin for real?  Or will the inside of my network remain the same, with 192.168 IPs?  I'd hate to have to toss my Grace radio because it won't work with v6.  I think this is a point of confusion for a lot of people with IPv6.  Because it has so many addresses, it doesn't need nor does it use NAT.  There's some other security considerations here.



STEVE:  Well, yes.  And, first of all, everything is a confusion for everyone with IPv6.  And he raises a really good point in his posting.  He says he's got an appliance, this Grace radio, that doesn't support IPv6.  Well, it probably never will.  And there's all kinds of stuff, like Internet streaming radios and Roku boxes.  Things that are state-of-the-art, you may be able to upgrade them and get newer firmware for them.  But we've got, for example, I've got TiVos.  All of my TiVos are IPv4, and they're using old hacked kernels.  They're never, ever going to get upgraded.  I know that.  So I want to continue to have them on the Internet to get their directory information.  And so what happens with v6?



Also, is it clear to us that ISPs are going to say, gee, how many IPv6 addresses would you like?  The idea of not using NAT means that you would have to say to your ISP, gee, I'd like 25 IPv6 addresses.  Well, is the ISP going to start charging you per IP?  We've been there with IPv4.  And the reason we're all hiding behind a NAT router is we want to look like we're just one computer.  And the ISP knows no one is one computer anymore.  But it works for them because they only have to give us one IP.  So it conserves their IP space.  That's not going to be a problem under IPv6.  But then the question is, do we get blocks, do individual end users get blocks of IPv6 addresses?  And if we do, what happens to our old IPv4 hardware?  So, great questions.  I don't have any answers yet.  But it's going to be a really interesting next couple of years.



TOM:  Can you make an IPv6 router that then does do NAT in IPv4 using tunneling?



STEVE:  Absolutely.



TOM:  So there you go, I mean, hopefully somebody comes up with a few products like that.  It sort of reminds me of the digital TV transition.  You're going to have to get boxes for your old IPv4 stuff to convert them.



STEVE:  Exactly.



TOM:  All right.  Steve, it was great to be back on Security Now! with you.  I really enjoy doing the show with you.  Leo is out, everybody, on a cruise for the next two weeks.  So I'll be sitting in on Security Now! for the next couple weeks.



STEVE:  Great.



TOM:  Don't forget to check out GRC.com.  You can find lots of excellent security, information, and products there.  You find the transcripts there, as well; right?



STEVE:  GRC.com/sn, for Security Now!, will take you to a page with all of the past podcasts, where you can get the lower bandwidth version of Security Now!.  I recompress it at 16KB and serve it myself for people who like the smaller, quarter-size file.  The TWiT website and the podcast download, 64KB.  And then we've got Elaine, who does a transcript in three different text formats for anybody who wants to read along.



TOM:  That compressed version's going to be handy for Canadians now with the new CRTC ruling.  They've got all those 25MB caps coming next month.



STEVE:  Oh, boy.



TOM:  So, good to know.  Thanks, Steve.  Thanks, everybody, for watching.  We'll see you next time on Security Now!.



STEVE:  Talk to you then, Tom.  Bye.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#287

DATE:		February 10, 2011

TITLE:		BitCoin CryptoCurrency

SPEAKERS:	Steve Gibson & Tom Merritt

SOURCE FILE:	http://media.GRC.com/sn/SN-287.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, after catching up with a busy "Patch Tuesday," Steve and Tom explore the fascinating crypto technology developed to create "BitCoin," the Internet's decentralized peer-to-peer completely private online currency exchange system.



TOM MERRITT:  This is Security Now!, with Steve Gibson, Episode 287, recorded February 9, 2011:  BitCoin CryptoCurrency.



It's time for Security Now!, the show you need to listen to if you want to be safe on the Internet.  And joining us to help us figure out all of the confusing things that could happen to you to threaten your security is the man who brought us ShieldsUP!, SpinRite, GRC.com:  Mr. Steve Gibson.  Good to be back with you again this week.



STEVE GIBSON:  Hey, Tom.  It's great to be with you for our second out of three weeks while Leo is roaming around the globe somewhere.  Is he in Asia?  Is that where he is?



TOM:  I believe he is with penguins.  He's on his way Antarctica.



STEVE:  On a cruise; right?



TOM:  Yeah, we actually got to use the words "out to sea," literally.  We were talking about whether we could contact Leo.  He's actually been very communicative.  He did a meet-up in Argentina when they stopped in Argentina.  And he's been Instagramming and Twittering.  So almost feels like I'm on the vacation with him, except having to work.



STEVE:  Fans everywhere.



TOM:  Yeah, I know.  All right, we've got a really good show today.  We're going to be talking a little bit about a virtual crypto currency?



STEVE:  Yeah.  It's something that a cryptographer, a Japanese cryptographer created about two years ago called BitCoin.  And I learned about it, I think someone sent me a tweet about it, saying, hey, Steve, check this out when you get a chance.  And so I dutifully noted it, jotted it down, and had a chance over the last week to dig into it more deeply.  And I'm really impressed by what they've done and by the fact that this thing really looks like it's the first solution to the concept of a distributed, non-central server, no central clearinghouse.  I mean, it's like it's currency, it's Internet currency, which can work and is working.  And there's just lots to talk about.  Lots of cool technology in there, which of course is our angle from the crypto side.  So we're going to talk about that this week.



TOM:  You know, I have always been fascinated with the idea of online currencies, even before Flooz came along and sort of turned it into a joke back in the dotcom days.  That is, like, the worst example.  I think that did more to set back online currency than anything else that's ever happened.  So I'm glad to see that a serious effort is underway, and I can't wait to learn more about it.  We've also got some security news about throttling and do-not-track and some good stuff like that coming up in our updates, as well.  Let's get up into the security updates.  We've got a busy Patch Tuesday today.  Well, this week.



STEVE:  Exactly, this week.  Of course, last Tuesday was February 1st.  So Patch Tuesday was the earliest it is able to occur in a month, that being February 8th.  And both Microsoft and Adobe showed up.  Microsoft had a large update.  They fixed 22 different flaws, five of which were rated critical, sort of across the board in their operating systems and IE and server platforms.  Seven had been publicly reported, and 15 were privately reported.  And the good news is the nasty one that we have been talking about the last couple weeks, that MHTML flaw...



TOM:  Oh, the MIME one, the one we were explaining last week, yeah.



STEVE:  Exactly, the MIME HTML, where, if you were to archive a web page which was malicious and then view it, it could get you.  But there was also a way that a website could supply an MHT format page.  There was a bug in the way this MHTML was parsed, and I'm really pleased that was fixed.  Now...



TOM:  We weren't sure it wasn't going to be fixed, were we.



STEVE:  No, because it was so, I mean, it was a short period of time, just before this Patch Tuesday.  So it's interesting because sometimes Microsoft really seems to, like, be asleep at the switch; and sometimes they just jump on it.  So I think they probably really wanted to avoid an out-of-cycle patch.  This thing was being exploited in the wild.  It was a zero-day exploit that was first discovered when it was being used to attack people.  So they had that little quick fix which we talked about last week.  And the effect of applying that, our listeners may remember, is only to disable the scripting in MHT archives.  Which I would argue you could very well just leave off.



TOM:  I was going to say, is that a good idea to have on anyway?



STEVE:  Exactly.  It's like many things which default on, and which if we knew better we would just always have them off.  And of course, if people had them, they would have never been potentially vulnerable to this problem.  So I would be inclined just to leave it the way it is, if you did disable it.  In any event, you'll have to do a reboot because this thing is actually part of Windows proper more than IE, although IE was the vector for exploitation.  So that got fixed.



Also there was a longstanding and kind of well-known flaw in Microsoft's Internet Server, IIS, that is, for the FTP service.  There was a way that a maliciously formed, deliberately malformed FTP command could gain bad guys access.  Microsoft's defense was, oh, well, FTP service is not installed by default.  But it's like, okay, fine.  For Vista and Windows 7 users, if you had IIS loaded and were using an FTP server, as people who have some reason to do so would, there was a vulnerability there.  That they fixed.



Now, the big news, though, is Microsoft did something that they almost never do.  There was a non-security behavior change that they also released this last Tuesday.  Two years ago we talked about - it was almost exactly two years ago.  It was February 24th of 2009.  On this podcast we talked about their bug fix for the broken disabling of autorun.  That is, it's very well known that all kinds of worms, I mean, Conficker, for example, is famous for this, will jump onto, for example, USB thumb drives and use the fact that, when you stick it into a computer, it looks for autorun.inf and then runs in order to spread.  So it used to be that you could, and very smart people would, disable that when they were setting up Windows the first time because it was...



TOM:  It was actually one of the first web articles I ever edited for The Screen Savers in 1999 was Kate Botello telling folks how to disable autorun in Windows 98.



STEVE:  Right.  And it's been a longstanding problem.  Now, what's really funny - well, funny in a strange way, ironic, I guess - is that just this recent ShmooCon 2011, Jon Larimer from IBM's X-Force Security Division gave a presentation - it was a very early presentation in the morning, he thanked people for getting up so early - on how unfortunately Linux's desktops have been evolving to be easier to use and becoming more like Windows, and that as a consequence Ubuntu is now exploitable due to its support for autorun, which has just recently been added to the Linux desktop; whereas Microsoft has been burned by it so much, they're moving away from it.  So...



TOM:  Now, that is an oddity.  I mean, it is the classic tension between ease of use and security, though, right there playing out in real life.



STEVE:  Well, and that's why Microsoft so infrequently takes away anything that they have previously had.  They are so reticent to remove functionality.  But this autorun problem with USB is a persistent problem.  So what happened was, in February two years ago they fixed a bug where it wasn't actually disabled the way we thought it was.  And then they came back in August, August 25th of '09, and for the first time they created an optional security update that would, for people who wanted to run it manually, would essentially do this for them.  It would stop autoplay functionality on USB, on external hard drives, and on network shares, all of which were being exploited for various purposes.



The big news for this Tuesday is that they rolled it out formally as part of their normal Windows update process.  Basically, it's installed non-optionally, and it turns off Autoplay for USB devices.  So that's huge.  What that'll mean is, I mean, the downside is, people who have been dependent on that will find that something that they're used to no longer works.  They'll have to manually run setup or install or autorun.inf, whatever it is, however they normally would be starting something that's on a removable device that they plug in, as opposed to it happening automatically.  Now, there are many USB devices which emulate a CD.  And those will continue functioning.



TOM:  Oh, okay.  So this is not turning off all autorun, which is what I've seen a lot of people interpreting this as.  It's turning off autorun for certain configurations, if you will.



STEVE:  Precisely.  CDs and DVDs will still autoplay as they did before.  But USB sticks - unless they emulate a CD, in which case Windows thinks it's a CD and will autoplay it - unless it emulates a CD, then Windows is just, from this point on, saying no, we just can't take the risk.  Users are going to have to run this stuff manually because...



TOM:  So there's no way to turn it back on.  It's just disabled.



STEVE:  You know, I didn't pursue that.  I'm sure you can.  I'll bet you could go back into the registry and manually reenable...



TOM:  Flip the switch, yeah, okay.



STEVE:  ...reenable autoplay.  I'm sure you could turn it back on.  But so what Microsoft is saying is, if you haven't manually disabled it yet, we'll disable it for you.  If you want to come back later and turn it on, fine.  Then we're assuming you know what you're doing, and you're going to ask for the behavior that you get.



TOM:  Dr. Mom in the chatroom has a good point.  Does that mean something like U3 still autoruns?



STEVE:  Precisely.  U3 was what I was thinking of when I talked about a device which does emulate a CD because it shows you a CD, and it looks like that to the OS.  So something like U3, you don't lose the functionality there.  Which is kind of a nice compromise.



TOM:  I guess it is, but how secure does this make us if somebody can just create their malware to emulate a CD?



STEVE:  Correct.  You're right.  That'll be the next thing is that we'll now move there.  Anyone who's running Linux, who's concerned about what IBM's X-Force guy showed at ShmooCon, if you just Google "ShmooCon 2011" and then "Autorun attacks against Linux" - probably you could just do "Autorun attacks against Linux."  But that will bring up - that's the title of this 51-minute YouTube presentation of this guy's talk.



And the point he's made is that in Linux, as in other operating systems, but specifically targeting Linux for his presentation, when you stick a USB device into a contemporary Linux desktop, all kinds of different levels of driver are engaged in order to connect with and recognize and mount the drive into the file system.  And many of those devices, he contends, have not nearly been examined for exploitability as much as we would like.  And he demonstrates taking over a Linux desktop that is normal default-configured, just by sticking in a maliciously formatted USB device.  So again, Linux desktop users may want to check out that presentation.  It was a good one.



TOM:  We also got a big, thick stack of security vulnerability fixes for Adobe Reader and Acrobat.



STEVE:  Yep, they're catching up with - they had 29, 29...



TOM:  Hey, they beat Microsoft.



STEVE:  They did, 29 critical security vulnerabilities which they addressed in the release version of Reader X, which you know they use an "X" for that, so Reader X, Reader 10.0.  And also many of the same things were in Reader 9.4.1.  So they're encouraging everyone to update to the latest version 10 of Reader and Acrobat, and that's 10.0.1.  And then in their release notes they note that it also includes updates to Flash Player, keeping it current.



And just I needed to mention this because I guess there must be some people somewhere who are still using RealPlayer...



TOM:  We could probably count them on one hand.



STEVE:  And that's the good news.  Real, as we've talked about in the past, just was a horrendous security and sort of over-marketing exploitation approach to media players back in the beginning, really before Microsoft got into the media player business and sort of pushed them aside.  There are still, I think mostly within corporate America, or in general, corporate Earth, companies that are standardized on RealPlayer.  If you're using the .rm, .rmi, the standard RealMedia formats, in this case you're okay because this is specifically an AVI vulnerability.  Quoting from one of the sites that was tracking this, they said:  "A buffer is allocated according to [a] user supplied length value.  User supplied data is then copied into the allocated buffer, without verifying [its] length, allowing the data to be written past the bounds of the previously allocated buffer."



I mean, this is classic buffer overflow attack.  You ask the media, oh, how large is the data you're going to give me?  And the media says, oh, let's call it 200 bytes.  And then it says, okay, fine.  Let me have it.  And of course the media loads 5K and blows the buffer of 200 bytes that was allocated, and then stomps over the stack, and has just loaded executable code, which the system then runs when it tries to come back from the subroutine that was loading this.



So anyway, this is a classic buffer overrun exploit.  It's in the current release of RealPlayer, only affecting AVI files.  So if you are a RealPlayer user, you probably know it.  Go over to Real and bring yourself up to date because the way this would be exploited would be just going to a web page that happened to invoke an AVI file in RealPlayer under the hope that you might have it installed.  If you did, you could get taken over.  So you don't want that to happen.



TOM:  I might also add, if you're a Real user, go to Videoland.org/vlc.



STEVE:  And stop being a RealPlayer user, yes.  Very good idea.



TOM:  All right.  Let's get into some security news.  Firefox yesterday added something to its latest beta of v4, the do-not-track option we were talking about last week.



STEVE:  Yep, we talked about their intention to do so.  I just wanted to let people know that it had appeared in the UI of Beta 11.  It is not enabled by default at this point.  Of course, it's not supported by default, by any advertisers that we know of in the world.  But it's one of those chicken-and-egg things.  The advertisers won't support it until the browsers ask for it.  So I'm glad to say that Firefox 4 is asking for it.  And I know that, as soon as I start using 4, I'll go there to the Advanced tab and say, yes, turn on do-not-track, and begin to get some experience with how that works.



TOM:  I like that the option says "Tell sites I do not wish to be tracked."  But it doesn't promise they won't because that's accurate to what it's doing.  It's putting up a flag, but sites don't necessarily have to honor that flag.



STEVE:  Yeah, and, I mean, I can vouch for the pervasiveness of Firefox use.  I mean, I know that GRC is going to tend to have a savvier user base come by.  But by far the bulk of visitors at GRC are using Firefox over IE, which of course in our case is in the No. 2 position.  But so that says that it's not as if we all have to sit around now waiting for Microsoft to do something before anyone's going to take this seriously.  I just hear people more and more talking about that they're using Firefox.  And of course Chrome is coming on very strong, too.  Google, as we also discussed last week, has made some motion in this direction, this whole do-not-track deal.  So the good news is, this has been a problem for years, and we're beginning to see some solutions.



TOM:  Hopefully we'll get to a standard.  It's good that the different browsers are trying different things.  Maybe we can see what works, what catches on.  What I always hate is, there's a point where you could agree that, okay, that's the thing that works best, let's all standardize on that.  Rarely does that happen.  Usually we go through a long march of everybody sticking to whatever it was the started with.  So...



STEVE:  Well, which we already have, for example, with NoScript that has its own format of do-not-track, different from what the Mozilla folks adopted, unfortunately.



TOM:  Right, exactly.  Within the same browser, even.



STEVE:  Within the same browser.  So, like, Giorgio, when Mozilla announced this, Giorgio, the author of NoScript, he posted immediately, said, uh, you know, I already put this in here.  Happy to have you guys use the same header.  But why not use the same header instead of use a different header?  So now the query that has - a query from Firefox of v4 Beta 11 that has the Mozilla do-not-track turned on, and is using NoScript with Giorgio's options turned on, will have multiple headers saying the same thing in different ways.



TOM:  And nobody listening.



STEVE:  Exactly.  And nobody listening at this point, exactly.



TOM:  All right.  Verizon is coming out with their own version of the iPhone this week.  And they have very quietly announced some new policies regarding throttling the top 5 percent of data users, as well as some, what they're calling "content optimization."



STEVE:  Yeah, which I thought - and I wanted to mention this just because I thought it was - the details of content optimization I thought was really interesting.  They said on a PDF that they made available on their site, quoting first this issue of bandwidth throttling - just I wanted to bring it to our listeners' attention for any of those who would be affected.



They said:  "Verizon Wireless strives to provide customers the best experience when using our network, a shared resource among tens of millions of customers.  To help achieve this, if you use an extraordinary amount of data and [thus] fall within the top 5 percent of Verizon Wireless data users, we may reduce your data throughput speeds periodically for the remainder of your then current and immediately following billing cycle to ensure high-quality network performance for other users at locations and times of peak demand.  Our proactive management of the Verizon Wireless network is designed to ensure that the remaining 95 percent of data customers aren't negatively affected by the inordinate data consumption of just a few users."



TOM:  I think, you know, this is a replacement for maintaining your network at proper capacity.  They're worried that they're going to get some bad press if their network gets clogged.  And so what's an easy way to do it?  Throttle down some people.  But if you want to do that, you've got to put a policy in place that explains who you're going to throttle down.  So this doesn't - a lot of people are saying, oh, if you're in the top 5 percent you'll be throttled for two months.  That's not exactly what they're saying here.  They're saying, we reserve the right to periodically throttle you, basically when we need to.



STEVE:  Right, I agree.  I think that, exactly as you said, they want to be preemptive.  They want to say, look, just to let you know, if you are, I mean, really hogging bandwidth.  Because I got my Verizon iPhone yesterday, and I've got unlimited bandwidth use on it.  That was the plan I chose.  I know, I have a BlackBerry; now I have the iPhone 4.  And I'm never going to be a heavy user.  But I know that there are people who, I mean, they're sitting there watching all of their video consumption through all of the various online services now, and over time using a huge amount of bandwidth.  So Verizon is saying, look, for people who are really at the top tier, as you said, we may need to throttle you.



Now, what's also interesting is, from a technology standpoint, I got a kick out of what they've acknowledged they're doing.  And anyone who's interested in the details, I'm going to run through them.  But you can see the whole document at VerizonWireless.com/vzwoptimization.  So VerizonWireless.com/vzwoptimization.  They said:



"We are implementing optimization and transcoding technologies in our network to transmit data files in a more efficient manner to allow available network capacity to benefit the greatest number of users.  These techniques include caching less data, using less capacity, and sizing the video more appropriately for the device.  The optimization process is agnostic to the content itself and to the website that provides it."  So they're making clear they're not wanting to go upset all the Net Neutrality people.  They say:



"While we invest much effort to avoid changing text, image, and video files in the compression process, and while any change to the file is likely to be indiscernible, the optimization process may minimally impact the appearance of the file as displayed on your device.  For a further, more detailed explanation of these techniques, please visit www.verizonwireless.com/vzwoptimization."



Now, I did go there and look.  And I saw a couple things that I wanted to bring to our listeners' attention.  First of all, this only applies over port 80, which is to say, HTTP.  They have, as we know, they have no visibility into HTTPS, into SSL connections.



TOM:  Well, that's a nice little workaround.



STEVE:  So, exactly, that is.



TOM:  If you're with a website that honors HTTPS, of course. 



STEVE:  Right.  And the reason this is interesting is that they really are - so what they're trying to do is they're trying to conserve the air bandwidth, that is, bandwidth in the air.  So if you were to go to a website, for example, that had a really large, low-compression JPEG - anyone who's actually ever made a JPEG probably knows that the compression that you set on a JPEG is variable.  You can choose lower compression, higher quality, where the image stays, like, ultra crisp sharp.  Or you can make a JPEG image, the file, physically much smaller at the cost of some fuzziness.  Basically, in terms of the type of compression JPEG uses, something called discrete cosine [transport] compression, DCT, it's expensive to transmit the data of a sharp edge.  It's much less expensive to transmit the data of a gradual change, the way this type of compression works.  So if you back off from requiring your images to have sharp edges, then you can get a much greater level of compression.



So what Verizon is doing is they're literally parsing the stream, looking at the objects which are being downloaded from web servers, and here they're saying they're reserving the option to change the data.  They will take a low-compression JPEG and recompress it to a higher level in order to minimize its size.  They will even transcode video, on the fly, across formats.  They'll go from, for example, they might take an AVI that's low compression, or RealMedia or something.  If they know what your device is capable of, they will transcode it, and this document talks about this, to H.264, which as we know is a much higher quality compression for bitrate.  And so what they're saying is, at their discretion, they're going to preserve the bandwidth of their over-the-air service and compress things.



Now, what's really amazing is that they're not doing it based on URL or even filename.  They look at the first 8K, which is typically multiple frames of a video, to determine if they've seen it again.  So they're watching the start of your video and using that to key their own caching technology to see whether they have already seen this video before and compressed it for somebody else.  And, if so, they switch you to that stream, and that's what they send.



TOM:  So you're sharing streams.



STEVE:  It's aggressive.  I mean, this is aggressive optimization.  Maybe they weren't carrying the iPhone until now because they weren't ready for it.



TOM:  That very well may be true with all of this work.  And couldn't they have - this is a cheap shot, but I'm going to say it anyway.  Couldn't they have spent that time and money on capacity?



STEVE:  Well, this is a long-term investment.  I salute them for doing this.  And this is some serious technology.  I mean, this is state-of-the-art caching and WiFi bandwidth optimization.  It'll be interesting to see if users notice any effect.  I mean, you could imagine, that, like, you could have two videos that start the same because they were edited from the same source material, but then are different.  And their cache could be fooled by that.



TOM:  I was going to ask about that.  I wonder when we get the first people on purpose spoofing videos that are popular to deliver some maybe images that people weren't expecting.



STEVE:  Yeah.  The other thing that they're doing along the same lines is that they're deliberately sending only enough video ahead to keep your player running.  That is...



TOM:  Yeah, I was thinking this would be a nifty way to take advantage of their transcoding, if you wanted to change videos to H.264.  But you don't actually get the whole file.



STEVE:  Yeah.  And again, they're being smart about this.  They're recognizing that many people don't watch the whole video that they download, yet they downloaded it all.  So Verizon is saying, we're going to be buffering in your player, but we're only going to stay enough ahead that, if you stop watching something after a few minutes of a 51-minute presentation, for example that YouTube I just talked about, then we won't have wasted our over-air bandwidth delivering video that was never seen.  So potentially this is all good, as long as it doesn't cause problems.  I would say it's tricky technology.  I salute them for being this aggressive.  I hope it doesn't have any downside.  I imagine there will be people who'll be playing with it.



TOM:  I think you're absolutely right about that.  The other thing I've been seeing in the news lately are a lot of reports about how mobile is now the new battlefield for  malware because we just had a report yesterday saying that smartphones outsold PCs in the last quarter of 2010.  So there's some news from McAfee about this?



STEVE:  Yeah, Symantec had issued a report.  We're beginning to see reports from the major security guys, and McAfee just, I think it was yesterday, issued their report where - and paraphrasing them, they didn't use the phrase "new low-hanging fruit," but that's how I would describe it.  What's happening is that PC technology, and Windows specifically because it's been such a target for attack - I mean, what, this podcast is in its sixth year.  Leo and I have been talking about Windows security, Internet security, security, security, security, every single week for six years.  Meanwhile, smartphones come along and are being adopted, as you just said, at a fantastic rate, and often, frankly, being used by people who are even less tech savvy than Windows users, who have figured out what it is they have to do in order to be safe.



TOM:  Less of a barrier to entry, so to speak.



STEVE:  Yes.  And maybe there's even more temptation.  Maybe it's just that people aren't yet as afraid as they need to be about phones.  But arguably, a smartphone, I mean, we know that it's running a full operating system now, given all that they're able to do.  But the thing that malware wants more than anything else is connectivity.  And while it's true that PCs are connected, I would argue smartphones are even more connected.  I mean, there's more channels.  You've got text, you've got all the social networking things, you've got email, you've got web browsing, and you've got applications, which, I mean, and this is of course a problem and a concern over on the Android platform, where people you don't necessarily know real well have created these things that look like, oh, wow, I really need that, and bang, now it's loaded in my smartphone.  Well, what is it doing?  It has all access to potentially this massive communication resource on the little computer that you're holding in your hand.



So I just wanted to say, once again, that we are seeing sort of the people who are watching security trends, they're saying that malware exploits are trending rapidly in the direction of smartphones.  So for our listeners, just stay on your toes.



TOM:  All right.  We're going to get into our main topic, BitCoin, a digital currency.  But I know you have a testimonial for SpinRite to read first.



STEVE:  Just, yeah, a nice letter that someone, a listener of ours named Mark Folkart, sent, with the subject "Yet another SpinRite story."  He said, "Steve, been listening to your podcasts and following you for a while.  I wanted to say thank you and relay yet another success story of SpinRite.  I've been a computer consultant for over 10 years and had a client come to me," he says, "(CIO/Director of IS for medium-size foundation) with her husband's dead laptop.  Her husband is not a client, but you know how that goes.  He works for a large brokerage company I won't name.  It had all his client/contact information on the laptop with no backup.  He had gone to his IT department, and they were unable to assist him.  At our urging, they unencrypted the drive and returned it to him still broken.  And his sales database was still inaccessible and trapped locally.  Couldn't even slave the drive.  I used a copy," and he says, "(they had purchased a licensed copy) of SpinRite and went to work.  Less than two hours later we were back in business.  He had his contacts back and a working machine.  Although I received no direct compensation, it certainly increased my credibility to a good customer, and how do you put a price on that?  I will continue to use and recommend your product and just wanted to say thanks.  Sincerely, Mark Folkart."  So Mark, thank you for the great note.



TOM:  It's amazing to me that an IT department wouldn't - and I've had it happen.  I won't name the workplace, but I have been in a place where my drive crashed, and I was like, hey, can you recover the data off this?  "Nah, can't be done," is what I was told.  I was like, well, no, it can.  There are ways.



So our big topic today is BitCoin.  You called this a "crypto currency."



STEVE:  Well, it's really, really clever.  The reason that I sort of fell in love with this for the moment is, as I plowed in, I just got a big kick out of the way that the many problems associated with a sort of a floating currency, meaning a currency that isn't anchored by any central bank, there's no state sponsorship for it, I mean, and it's a real thing.  Anyone who's interested, and I would encourage our listeners, if this podcast and what they hear about it makes them curious, go check it out.  Just put "bitcoin" into Google, and you'll start seeing pages of stuff.  And about two years ago the project was registered, a little over two years ago, by a Japanese cryptographer, Satoshi Nakamoto.  And it's an open source project on SourceForge, so none of this is black art stuff.



The goal is to really solve, I mean, to offer an honest-to-god, non-hobby-level, but industrial-strength, Internet-based, peer-to-peer currency where real value can be exchanged between two parties without any intermediary being involved.  And that's one of the trickiest things because you've got all kinds of problems.  First of all, where does the currency come from?  What creates the currency?  How much currency is flowing through the system?  How do you monitor that and regulate it?  How do you prevent it from being inflated?  How do you keep people from fraudulently creating currency?  How do you keep someone from, if they have some, from reusing the same currency?  All of that has been solved with this system in some very clever and very new ways.  Which is really what captivated my attention on this.  So there was...



TOM:  So wait a minute.  So we have currencies.  We have euros and yen and dollars.  How can you invent a currency?  What makes that work?



STEVE:  Well, okay.  So, think about it, a currency is nothing really but an agreement among the parties that this synthetic thing has value.  Once upon a time, when the dollar was anchored to a gold standard, the idea was that there was gold backing up dollars.  And so when you had a so-called "promissory note," it was equivalent to X amount of gold.  And we were of course famously taken off of the gold standard.  The problem was we needed more money than we had gold; so we had to disconnect, in the case of U.S. dollars, we had to disconnect U.S. dollars from gold because we literally needed to create more money than we had gold to back it up.



TOM:  It's kind of that incredible innovation in human society, when you think about it, that this works at all.  Because it started out you would carry around your chickens because you just wanted to trade what you had of value for what the blacksmith had.  That got inconvenient, so gold became a good standard because everybody valued gold, and everybody kind of had the same value of gold.  But we've gone from that to this sort of agreement that, well, I'm going to agree that a dollar's worth of work is worth a dollar's worth of merchandise, and it doesn't have to be backed by anything.  We'll all agree that that's the way to pay stuff.  So I guess that's all they have to do is get enough people to agree that this currency is valuable?



STEVE:  Correct.  Well, and notice also that we chose gold because it was scarce.  We didn't use water, for example, because you'd just go over to a stream and dip your bucket in.  And the problem is, of course, anybody could go do that.  So water...



TOM:  There's a famous scene in one of the Douglas Adams novels where they decide leaves will be their currency.  And it has the same problem.



STEVE:  Well, of course money grows on trees, so, yeah.



TOM:  Right, exactly.



STEVE:  And so we chose gold because it was scarce.  And famously in the days of individual gold miners, they'd go out and try to find it because they would - basically they were creating more currency to put into the system at a controlled rate.  And initially, when there was lots of gold around, we were digging it up and turning it into bars and coins and so forth.  And over time, it became increasingly difficult for us to find more gold, so it became increasingly scarce, and its value has increased.  So...



TOM:  And in some ways we have a virtual currency with the dollar and the euro and all of these.  And in some ways that is a little more fair because someone can't just go out and find a bunch of money, unless they're robbing a bank, I guess.  But, you know, you can't just go digging in the hills and luck into a bunch of money.  It has to be earned in some manner.



STEVE:  Right.  So what has been created with BitCoin has all of these attributes.  There is this concept of bitcoins, the currency - in the same way that the abbreviation for U.S. dollars is USD, and euros is EUR, BitCoin's abbreviation is BTC, bitcoin, BTC.  And so this network of computers exists now on the Internet, peer to peer.  You can go to BitCoin.org and download a program for Windows, Mac, and Linux, which is open source, and install it on your computer, and tell it to start generating bitcoins.  That is, literally start making money.



TOM:  So you are making money out of nothing, just by being a member?  I mean, how does this - this just sounds like some sort of BitTorrent situation.



STEVE:  I know.  It sounds wacky, but...



TOM:  Yeah, yeah.



STEVE:  So you are making money.  The way you make money is by processing transactions within the bitcoin system.  So, and this is complicated, but unfortunately it needs to be complicated in order to be robustly secure, which it really is.  In the FAQ at BitCoin.org, in the FAQ there's a link to the original PDF that Satoshi wrote that describes in greater detail how this works.  But the idea is that you want a transaction trail of every single transaction between two parties that has ever occurred.  And they're occurring all the time.



Now, this is not just - this currency is virtual, but it has been anchored now to real currencies.  There are websites that will trade real currencies for bitcoins.  At this point in time, about two years after it was launched, the current currency trade of U.S. dollars for bitcoins is about 1:1.  I think it's, like, 93 cents for a bitcoin.  And there are organizations which accept bitcoin payments.  The EFF, the Electronic Frontier Foundation, accepts donations in bitcoin currency.  There are programmers who will work and accept payment in bitcoins.  There's a, I think it's called Trade, a trade link at BitCoin.org that shows a page of lists of all the currency exchanges that exist now, and then a growing number of organizations and companies that will accept bitcoin currency as real.  So I know I...



TOM:  Okay, let's back up a little bit here.  If I can just create, by running the program, money, aren't we running into the leaves and water problem, where we just get runaway inflation and the currency is valueless?



STEVE:  Yes, except that it's all controlled.  The way it functions is that new coins, new bitcoins, are generated on the network when a node - and, for example, if you're running the program, you are one node - when a node finds the solution to a hard problem.  Now, this is really very clever the way this works because it prevents people from being able to create currency at will.



Back in '97, I think it was, 1997, someone named Adam Back came up with a concept for antispam, which he called "proof of work."  The idea was that spammers function because they're able to just spew out email at virtually zero cost.  It doesn't cost them anything to send out email.  So as a consequence we're all being deluged with email, which it's expensive for us to receive, not expensive for them to send.  So Adam said, what if we come up with a way of making it expensive for someone to send email?



And the way we do that is, we create a computational burden which we don't have the technology to short-circuit, where they have to do a substantial amount of work in order to sort of validate an email.  And on this show we've talked about hashing a lot.  Hashing of course is a valuable technique that takes an arbitrary length input and turns it into, hashes it down into a so-called "digest" of a fixed length.  So imagine, like, take SHA-256, which is the secure hashing algorithm which produces a 256-bit result.  Imagine if, in order to qualify for sending email, you have to hash the email header such that some number of the first bits out of the 256 bits are all zero.  So if you just hash an email header at random, the most significant bit has a 50 percent change of being a one or a zero.  So you increment a sort of a fudge factor and then hash it again until you get that first bit that's a zero.



But say that to qualify the header has to have a hash where the first 20 bits, for example, are all zero.  Well, it's going to take 2^20 operations to guarantee that.  So an average, half that number of hashes have to be tried.  So the idea is this forces someone to do a huge amount of work fudging the header in order to get all, like the first X number of bits of the hash to be zero.  So in practice you could set the difficulty so that it might take somebody two seconds to do the work on a 1GHz PC.  But that would mean that it takes a spammer two seconds per email, which is vastly more computation time than it takes them now.



TOM:  And so on an individual basis you don't notice that that much.



STEVE:  Exactly.



TOM:  But if you are trying to send vast amounts of email, which I guess could negatively impact legitimate bulk email like newsletters and things like that, too.



STEVE:  And actually that's exactly why the idea did not take off was that it was still - while, yes, it would be burdensome for spammers, exactly as you said, there are legitimate mass mailers.  And if we did anything to allow them through, then the spammers would come through, too.  So it had to be all or nothing.  And it was too much work for legitimate mass mailers.  But it was a really interesting concept.  And Satoshi borrowed that concept that Adam Back proposed back in '97 for this.



So here's the way it works.  So imagine that there are, among all these peers, there are people exchanging value.  They're exchanging bitcoins.  A bitcoin exchange is somebody wants to send somebody else some bitcoinage.  So  the whole system works with an asymmetric key system, a public key system where they have both a public key and a private key.  They take some amount of bitcoinage and put their public key, sort of associate or include their public key in the transaction, also the public key of the person it is being sent to.  And then they sign it with their private key.



So what that creates is, that creates a transaction that only they could have originated because they're the only ones who have their private key, which they keep secret.  That transaction is broadcast into this peer-to-peer network, to all the nodes in the network, and everyone's transactions are broadcast.  Now, it's easy for anyone to verify that transaction because they know the public key of the signer, and that allows them to verify the signature.  They can't sign it themselves, but they can verify the signature.  So that allows them to verify the transaction.  Now what we have to do is we need to prevent that person, who's just depleted their bitcoinage by giving some away, from giving the same bitcoins away again.  And so that's clearly one of the hard things to solve about this.



So the way we do this is, every so often, all of the transactions which have occurred since, okay, there's sort of a problem of chicken and egg here because I have to explain multiple things at once for this thing to hang together.  There is this notion of blocks.  A block is a collection of transactions which have been sort of adopted by the network.  And the block, which is this collection of transactions, is the thing which work is done to create.  In the same way that I was talking about work being done to create this special hash for email headers, the work being done to create this block is what all the nodes on the network are busy doing.



So all the nodes receive transactions.  And a block is chained to all the previous blocks by taking the hash of the previous block as part of the next block.  Which means that essentially you have a forward-moving chain of blocks which are linked by the hash of the previous block.  There is a genesis, what's called the "genesis block," which was created on January 3rd of 2009.  So just a little over two years ago, when the system began, there was an anchor block which is embedded into all of these nodes, into the code in the nodes.  When someone downloads the program and turns it on, they go to an IRC chatroom, that is, the code autonomously goes to an IRC chatroom, joins the room, and that's how it learns about all the other nodes or many of the other nodes on the network.  It then interconnects to them and receives the entire history of all previous blocks, that is, this block chain, anchored by the genesis block, all the way to the most recent block that anyone has created.  So, and...



TOM:  That sounds like it could become computationally extensive over time, though; right?



STEVE:  Yes, except that there's another clever thing.  It turns out there's a way to compress these so that, once the blocks are old enough, and no one cares about the individual transaction details, then you no longer really need to care about them.  The idea is you need the transaction details long enough to make sure that nobody - so that the transactions details are available in the network so that no one is able to reissue the same bitcoins again.  But at some point then it becomes impossible for them to because the blocks become old enough.  And you do not need to - it turns out you're able to compress these blocks and make them a lot smaller.  So, and I think the growth rate is estimated at something like 4.2MB per year would be the maximum amount of storage that this architecture requires.  So it ends up really not being very much over time.



So what happens is there is this sort of chain of blocks.  Now, all the nodes in the network are competing with each other to create the next block.  And it's the node which wins, the node which first does the amount of work required to essentially create the next block that earns 50 bitcoins.  And this all sort of scales in the right way.  I'll explain in a second.



So all of the nodes are cranking away.  They are taking all the transactions which have not yet been encased in a block, and they hash all of that along with the hash of the previous block, which that anchors them together and means that you're not able to create a block that isn't linked to the prior one, hash it all together, and then there's a certain amount of difficulty which is of finding a block that functions by exactly, as we were talking, having a hash with some number of zeroes from the left end going down.  And at the moment, I think that number is 12 at this point in time.  So all the nodes are tweaking a little fudge factor in the hash, trying to build a block which has 12 zeroes at the leading part of this 256-bit SHA-256 hash.  As soon as the node finds it, it declares success, broadcasts that to the network.



Remember that, while it's extremely difficult to find the pattern that makes the hash, it's incredibly easy to verify it.  Verifying the hash just requires doing the hash of the block and seeing that, oh, look, somebody did create a block that's got all those zeroes.  And the first transaction in any block is paying yourself 50 bitcoins.  But it's only if you can make that block valid that then that transaction in the block of paying yourself 50 bitcoins is validated by the network.  So...



TOM:  We've actually had two blocks created since we started explaining what blocks are, by the way.  Their little estimate of how there are people out there using this.



STEVE:  Yes.  In fact there's a site called, I think it's blocktrack...



TOM:  BlockExplorer is the one that I'm at.



STEVE:  That's the one.



TOM:  And that's how I'm keeping track of this.



STEVE:  Yep, BlockExplorer allows you, it's a website that is participating in this peer-to-peer network which allows you to go look at the history of all the blocks that have been created so far.



TOM:  Now, is this a worry. that all of your finances are now going to be in public?  Can people look at this and figure how much money you're spending and who you're giving it to?



STEVE:  Well, that's one of the other beauties is that the only thing which is known - this is a completely anonymous currency system.  I mean, like more anonymous than anything else.  The only thing that is known is your public key.  So when you download this software and fire it up on your machine and start it running, the first thing it does is to create a key pair.  And so you will see, for example, if you find the EFF bitcoin donation, they show their public key.  And there are various other organizations that accept bitcoin.  They show their public key.



So when you look at the history of transactions, all you're seeing is this random ASCII gibberish, which is the public key converted into ASCII.  And people keep their private key private.  But there's no way of knowing who is behind any public key.  And the bitcoin client will happily produce key pairs till the cows come home.  You can make more key pairs anytime you want. So you're not even - there's not even any way to track somebody by, like, oh, look, there's the same guy who did a transaction here.  He did it here.  Only if you did not create another public key would that be the case.  But you are free to create new - essentially the public key is a temporary, pure binary representation of you, which you're free to retire and create a new one anytime you want.



TOM:  I just downloaded it and started it.  It's not creating - it says I'm not connected.  It's not creating anything.  Is that because I'm not in idle time?  It has to be idle to start generating those coins automatically?



STEVE:  Well, yes.  And, okay.  So many things have happened in the last two years.  First of all, this began to get traction, and people began having fun with this.  The way the system works is - and I need to get this right - is the coin creation rate is 300 coins per hour within the entire system.  And your CPU speed, the ratio of your CPU speed over the total CPU speed within the entire bitcoin network, determines the probability that you will be able to solve the puzzle of creating one of these blocks.  So it's estimated, for example, that at this point, I think it was December 2010, so about two months ago there were enough nodes actively cranking away that it would take you about a year to generate 50 bitcoins.  That is, so you're not going to see it happen quickly.



Now, what happened is, as these things started getting valuable, started becoming worth something, I mean, you can actually trade, if you happen to get lucky, and your node solved the most recent block that everybody was working on before anybody else, you'd get 50 bitcoins.  Today there's an exchange that will transfer that, in U.S. dollars, for example, into your PayPal account.  So you actually can make money.



Now, you can imagine, then, that people said, wait a minute.  This seems like a good idea.  Well, there's something that's much more powerful than even multicore CPUs.  And that's GPUs, graphics processing units.  Now Google "bitcoin miner," as in a gold miner.  What's happened is that there are people on the 'Net that have built bitcoin-creating boxes with as many graphics processing units as they can get, with fans cooling them, they're overclocked, they're pouring Freon over them.  These things are running 24/7.



TOM:  Like oil derricks.  They're drilling for bitcoin.



STEVE:  They really are.  They're literally creating bitcoinage.  Now, the cool thing is, all of this was anticipated in the original system because the immediate response to the bitcoin network of the presence of massive bitcoin computation power, which essentially allowed the people who had these machines to be printing money, minting bitcoins with a much greater probability than somebody who just had a CPU running along, the system automatically changes and changed the problem difficulty in order to stabilize the rate at which coins are coming into the system.



And here's the deal.  There will never, ever, ever be more than 21 million bitcoins created.  The way this works is that the difficulty of this problem that is being solved, that is, this hashing problem where you're trying to find leading zeroes in the hash, it's adjusted continuously by the network.  So that in the first four years of the bitcoin network, and we're two years in now, in the first four years half of that total number of bitcoins will be created, that is, 10,500,000 bitcoins will be created in the first four years.  In the second four years, half again, that is, only 5,250,000 in years four through eight.  In years eight through 12, that is the next four years, again that amount is halved.  And so the rate of coinage creation will be decreasing exponentially, leveling off so that, in the far future, only 21 million will ever be created.



So we have a controlled and known rate of inflation within the system.  And it makes sense because, initially, as the system is coming online, as goods and services are being made available and are trading within the system, you want to have more currency being pumped into the network so that you have bitcoins to trade.  But you don't want it to go forever.



Now, the problem would be, of course, if we absolutely cap the total number of coinage at 21 million, and there comes a much greater demand for this, the tendency is to want more.  Well, the solution is that you're not forced to trade in integer amounts of bitcoins.  That is, the UI right now gives you two decimal digits of coinage.  So you're able to create, for example, you could exchange 0.01 of a bitcoin, but the technology supports eight decimal digits, although right now we're only using two.  So that allows for deflation over time because we're absolutely capping the total number of coinage at this 21 million mark.  And we know that it's going to be declining over time, and it doesn't matter how much GPU power is put into the system.  The system adapts so that the problems being solved scale - the difficulty scales up to balance the amount of processing power in the entire network.



And some people have commented that the question then becomes, are you spending more money on electricity and cooling for these crazy bitcoin-generating engines than the money you produce?  And over time it looks like that will be the limiting factor.  It's like, yay, I've created this insane work machine to create bitcoins.  But, gee, you know, my electric bill went up more than the money that I'm making.



TOM:  And PG&E isn't talking bitcoins yet for my rates.



STEVE:  Exactly.  So there's also a cool site that I got a kick out of called the BitCoin Faucet.  The BitCoin Faucet...



TOM:  I was just trying to use that.  Their rate limit has been exceeded.  I think everybody's going to get their - explain what it is.



STEVE:  It's just a fun way that somebody can get some free bitcoins.  People who have them can donate them to the site, and the guy thanks you very much.  And as long as he's got enough supply, he'll give you some bitcoins.  At the moment, when I looked before the podcast, he was giving 0.05 bitcoins per visitor.  When his balance of available bitcoins that he's able to distribute for free is high enough, he increases that.  But if he falls below a certain mark, he decreases it in order to conserve his supply.



There's an online buyer and seller escrow service, so that two people are able to agree that they're each happy with the exchange of whatever it is they exchanged.  For example, in the real world, in order to allow a bitcoin transaction to occur, there are a number of online exchanges where you're able to buy and sell bitcoins.  There's online charts where you can look at the rate at which bitcoins are being bought and sold, and their relative currencies.  This is available in a huge number of currencies and a whole bunch of languages.



And essentially it is extremely cool crypto which, I mean, this has been pounded on and looked at.  And it looks to me like the guy has solved the problems and has created a virtual currency that floats all by itself, that is completely private, that, I mean, obviously you need somebody who's going to agree with you that you want to exchange this coinage.  But this thing exists, and it's taking off, and I wanted our listeners to know about it.  It's just very cool.



TOM:  Really fascinating stuff.  I've been playing with it while we've been talking, too.  I have no balance, though.  And the faucet is off right now.  But at least I'm connected, finally.  So I...



STEVE:  Oh, so you did find your network.



TOM:  Yeah, it finally found the network.  I have no connections yet, though.  But it is connected.



STEVE:  One of the things they recommend, if our listeners want to play with this, is you will get much better connectivity if you do port forwarding of port 8333 through your router, which typically most people have, or your firewall, to the application.  In that way, other nodes that are informed about you are able to make incoming connections to you, and it's not just you making outgoing connections to them.  And that'll allow you to participate in the network.  But I would encourage our listeners to poke around, as you have been, Tom.  There are pictures of these people's GPU boxes that they've made, with all these fans all over them, and discussions about the giga hashes per second (GH/sec) in the network.  I'm trying to think, I made some notes about it somewhere about the...



TOM:  Oh, the average rate of block creation?



STEVE:  Oh, yeah, 186 GH/sec is the total network hashing strength.  That is, there are 186 billion hash operations being performed within the entire network, trying to solve the problem of the next block creation.  The one who does gets 50 bitcoins.  Oh, and that number also decreases over time.  So that it's, for the first 210,000 blocks, the value is 50 bitcoins per block, if your computer solves the puzzle before somebody else's.  Then for the next 210 blocks, that's cut in half to 25 bitcoins.  Then for the next 210,000 blocks to 12.5 bitcoins, and to 6.25 bitcoins, and so forth on down.



So this whole system is designed to scale correctly and basically create a secure, stable currency with real-world value, which it has now.  I mean, you can buy and sell bitcoins.  If you wanted to, you could take a hundred dollars and go buy some bitcoins.  And they're electronic currency.  You could then send those anonymously to someone else, and they could cash them in to their own currency or back into dollars or whatever they wanted.  I mean, this exists now, and it looks like it's, like, bulletproof.  And the PDF explains they've really thought through what bad guys can do.  The only attack which is known on the system would involve somebody with massive computational power spoofing the chain because it's this chain of blocks which provides the integrity for the system.  But the longer the chain gets and the more good nodes there are, the more impossible it becomes for anyone with massive computational power to spoof the chain.



So the other thing that has happened is there's this notion of pooling.  Individuals have become a little disenchanted with the fact that they've got their quad-core i7 cranking away 24/7, and they haven't made any money yet.  They like the idea of printing money.  The fact is, over time this is not going to be feasible.  That is, the way to get rich is not to print money.  It's like gold miners, like during the gold rush.  You ran out, and you hoped to go strike it rich and find a vein of gold and make money.  Over time, that just became less and less feasible because the ground had been picked over, and there just wasn't gold to be found.  Similarly, ultimately, this will be - it's when the coinage enters the currency and begins to flow, people will be using it as a store of value.



But anyway, what I was saying was that people who have been a little disenchanted, they're joining pools of users where they'll all be working together and pooling their CPU resources and then sharing the proceeds appropriately.  So you may not get 50 bitcoins, but you may get 2.5 because you are one 2.5 out of 50th of the CPU resource in a pool that collectively solved a block.  So it's a way for people to have some of the fun of creating coinage out of thin air by doing the work that makes the whole network go.  And anyway, it is the work that has to be done, the difficulty of doing the work, that keeps bad guys from being able to spoof the system because there just isn't any way to shortcut this hashing of the blocks.  It's just brute-force work.



And as more good, like GPU-based systems come online, that hugely raises the bar that bad guys would have to scale in order to spoof because now, as a consequence of sort of this phenomenon of using GPUs to create bitcoins, the network has scaled so the rate of coin creation is still tracking exactly what it should.  But the amount of processing time being required to make that happen has just gone through the roof.



TOM:  There's bitcoins in them thar Internets.  Or something.



STEVE:  Anyway, just really, really fascinating.  And, I mean, it works.  We have a state-free, crypto-secure, anonymous real currency now that exists.



TOM:  Check it out at BitCoin.org.  It's really fun to play around.  Dot org, not dot arg.



STEVE:  Argh, matie.



TOM:  Yeah.  There's no piracy in the bitcoin world.  Thank you, Steve, so much for explaining that.  That was really fascinating.  I can't wait to poke around with this a little more.  I think I'm going to have to do the port forwarding that you were talking about to get it.  Well, no, I've got one connection now.  So it seems to be slowly - I guess that's what I'd say to new people, if you're looking at this.  Be patient.  Give it some time to connect.  You might try the port-forwarding trick.  What port was it, again?



STEVE:  8333.



TOM:  8333.



STEVE:  All this is documented in the FAQ at BitCoin.org.  And the other thing that happens is, when you connect, the first thing that happens is your node needs to download the history of prior blocks.  So that'll take a while.  But you'll see progress things and so forth.  And there is, on the UI, there's an option to say "Start making bitcoins."



TOM:  Yeah, start making money.  All right, folks.  Don't forget to visit GRC.com.  Steve's got some excellent products up there.  Of course we talked about SpinRite.  I've used ShieldsUP! over and over throughout my years since you created it to make sure that there's not any ports open that I don't want opened and all that stuff.  Also, it makes you feel really good when you are locked down because you have this great - I don't remember exactly how you phrase it.  But you have this, like, "That's impressive.  I couldn't see a single port."  So check it out, GRC.com.  Anything else you want to talk about before we head out of here, Steve?



STEVE:  Think we've got it covered.  We'll do a Q&A next week.  So I encourage, as always, our listeners to swing by GRC.com/feedback.  And if you play with BitCoin, you have questions, I'd love to hear them, and maybe we'll answer them next week.



TOM:  For free.  We won't charge you any bitcoins to answer them.



STEVE:  No charge.



TOM:  All right, thanks, Steve.  Thanks, everybody, for watching.  I'll be back one more week next week.  Leo will be back in two weeks from his vacation.  Thanks for watching Security Now!.  We'll see you next time.



STEVE:  Thanks, Tom.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#288

DATE:		February 17, 2011

TITLE:		Listener Feedback #111

SPEAKERS:	Steve Gibson & Tom Merritt

SOURCE FILE:	http://media.GRC.com/sn/SN-288.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Tom discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



TOM MERRITT:  This is Security Now! with Steve Gibson, Episode 288, recorded February 16, 2011:  Your questions, Steve's answers, #111.



It's time for Security Now!, the show you need to watch or listen to if you want to stay as safe as you can on the Internet.  Joining us, the man behind GRC.com, ShieldsUP!, and SpinRite, Mr. Steve Gibson.  Hey, Steve.



STEVE GIBSON:  Hey, Tom.  Great to be with you again for our third and final show together.



TOM:  Our triptych of Security Now! episodes together.  Leo, of course, as we've mentioned, is on vacation.  He will be back next week, though.  And I can't say I haven't enjoyed doing the show with you.  But it will good to have him back.



STEVE:  Has been a pleasure, absolutely.



TOM:  Absolutely.  Well, let's get into - we've got some security updates, some new stuff around Windows, some clarifications.  We've got some password stuff coming from Google.  And of course questions and answers today.



STEVE:  This is our Q&A episode.



TOM:  Yeah, a lot of Q&A about Bitcoin coming up.



STEVE:  Yeah, in fact, we could have done all of the questions about it, it's generated so much interest and curiosity from people.  And actually I got some nice comments from people saying, hey, it was sort of a nice change of pace to talk about something crypto related, but not - some guy said "not just another Adobe security flaw" sort of thing.



TOM:  Right.  And something positive, too.  Something that hopefully is working to better the world, rather than you just trying to defend yourself against somebody who's trying to take you down.



STEVE:  Right.  Well, so I noted sort of in just the overall running news that Chrome, Google's browser, had crept up to major version 9 and then quickly had a couple things fixed.  Google was mum, as they always are, about the details.  Just that's their way.  And so they fixed multiple, as always, unspecified vulnerabilities, which they rated as high.  They repaired a flaw in an unspecified race condition in audio handling, an unspecified crash when printing PDFs, and an unspecified use-after-free condition related to image loading.  So we don't really know what those are.  But we're glad that they keep fixing these problems for us and moving Chrome along.  And it's funny, when I noted that it was at v9.something, it's like, wait a minute, when did that happen?



TOM:  How'd it get there?



STEVE:  When did that happen?



TOM:  Yeah, I know.  I do like that Chrome updates itself in the background.  It's less disruptive and all of that.  But I also miss being able to keep up on what's actually being done to my browser.



STEVE:  Yeah, it's a different model.  My sense is they probably got it right.  They came into the game later, so they were able to look at what Microsoft was already doing and had been doing, what Adobe had been doing.  And they probably made a decision, it's like, well, okay, there's a certain class of person who wants knowledge-base index numbers and wants to go in.  And certainly with the huge corporate load that Microsoft is dragging along with all of this, you can imagine that IT personnel historically are the reason we're doing Patch Tuesday.  That is, Microsoft has consolidated these changes to Tuesday.  Once upon a time these things were just being released all over the place, whenever it happened.  And it caused IT people a huge amount of trouble because they were constantly getting patches from Microsoft.  And in some cases those things broke specific IT infrastructure configurations that Microsoft had not been able to test for.  So by relegating it only to second Tuesday of the month, IT sort of is able to calendar that and arrange time.  They also really need details about what's happening.



So maybe one of the benefits Google has is that it is only a browser and not an OS that they are changing.  You might imagine that if it had the decades of history that Microsoft's OSes are still legacy-wise dragging forward, that they probably couldn't get away with this.  But as a browser it's like, yeah, yeah.  And I agree with you.  It's interesting to sort of see this approach as compared to the other approaches which are, it's like, okay, so we have all this detail.  Do we really care?  We just want it to be fixed.  So that's what Chrome does, it just fixes itself constantly.



TOM:  And anecdotally, I can say Flash has been performing better for me since this dropped.  I don't know if that's just luck.  But I haven't had as many of those Chrome crashes.  So that's good news.



STEVE:  Well, and I did a reboot of my system yesterday.  I don't do it often.  But all my icons went away.  So it's like, okay, well, I guess it's time to reboot Windows.  And I got a new Adobe, I got a new Flash, and a couple things.  But this version of Chrome did also include an updated version of Flash.  Remember that they're now taking more responsibility for their plug-ins and going to be updating those, as well, moving forward, something we talked about some time ago.  So we have seen that.



I wanted to give a shout-out and thanks to a frequent tweeter to me, who goes by the handle @Captn_Caveman on Twitter.  He sends news often of things, like he's the first person to bring things to my attention.  He did so just this morning.  I got an early heads-up on a new zero-day exploit that's been found in the Windows SMB system.  That's the Server Message Blocks, is what SMB stands for.  We commonly refer to it as file and printer sharing.  SMB is the protocol that it uses for file and printer sharing.



Now, it's caused some ruffles on the Internet because it's a remote code execution vulnerability.  Secunia confirmed this.  It had been posted by some guy calling himself Cupidon-3005, who posted this on the Full Disclosure mailing list, talking about - and that was why it was a zero-day exploit was the first anyone knew about it was when this, you might argue, irresponsible disclosure was made publicly.  Secunia confirmed that this problem exists.  It's a buffer overflow that can be triggered by sending a too-long server name string in a malformed browser election request packet.



Now, it's not browser in terms of web browser.  This is the - unfortunately we have a name collision in Windows.  The browser is also the name given to, like, the file browser that we sort of see in the form of Windows Explorer on our desktops.  So you have, in any version of Windows, you've got a file server and a file browser which are individual services that actually you are able to start and stop, although all kinds of horrible things break if you do that.  Now, this is not such a big deal, though, because this is, fundamentally, file and printer sharing ports.  Which, of course, it's the reason I created ShieldsUP! a decade ago was to alert everyone to the problems of that.  That's one of the main drivers for personal firewalls being created almost a decade ago.  And many ISPs have taken it upon themselves to block those ports, that's ports 137, 138, and 139, and also 445, which are the ports that SMB services are running on.  And now with Windows Firewall installed in Windows machines and enabled and running by default, you really are not very vulnerable to this.



The only place I could see a problem would be local vulnerabilities.  For example, we have seen instances where malware will use fileshares in order to propagate within a corporate network or within a home network, once it gets into one machine through some other means.  So it would be, I think, almost impossible for this to be a big problem out on the Internet because there's no way that malformed packets can reach your computers' ports 137, 138, 139, and 445 behind multiple layers of protection.  And NAT routers, of course, NAT routers are providing us with a good hardware firewall, essentially.



TOM:  If you're doing anything to protect yourself, you're probably going to be okay, it sounds like.



STEVE:  Exactly.  The first thing you would do, anything you did would solve this problem.  So it has been confirmed.  I wouldn't be surprised if we see malware maybe adding this to its bag of tricks for spreading itself around within an organization or home network, once it gets a foothold inside.  But it doesn't look like it's going to be - it's not going to be some major worm that's going to spread across the Internet like we used to have in the old Code Red and Nimda days and so forth.



TOM:  Well, that's at least a good side of the news from them.  But there is another critical vulnerability, though, being reported from Microsoft.



STEVE:  Well, yeah.  Microsoft has a DLL that does all of the HTML and CSS parsing.  We seem to be talking about CSS parsing problems now weekly.  It's almost like some new module of Windows gets focus of the bad guys, who then start pounding on it.  And it's like, oh, look, apparently Microsoft hasn't given much security attention to this.  And so we see a stream of problems coming from one particular avenue.  The only real explanation for that is that people are all looking in that direction at the moment and finding problems wherever they look.



So this is another MSHTML.dll problem.  Reportedly, there's a dangling pointer than can be exploited.  That would mean a pointer which is created and is not destroyed, still pointing to some memory that it's somehow possible to exploit through causing someone to visit a maliciously formed web page.  IE6, 7, and 8 have been confirmed as affected.  And I would be surprised if 9 wasn't because this is going to be - this MSHTML.dll would be a core component of what Microsoft is doing for rendering web pages.  So this is a critical vulnerability.  It just happened on Tuesday so Microsoft has had no chance to deal with it.  Just wanted to sort of alert people that it exists.  So with any luck they'll be fixing it and we'll be talking about it for a Patch Tuesday in March.



TOM:  All right, we'll keep an ear out for that.  Let's move on to some security news.  Google added some increased security for logging into Gmail and Apps.  They were calling it two-factor authentication when I read about it.  But it's not - is it exactly that?



STEVE:  Well, okay.  So we've talked a lot about multifactor authentication, the idea being that you don't want to rely just on something you know because it's possible for someone else to find out something you know.  You could disclose your password.  That's something you'd know.  You know what your password is.  You can write it down.  A keystroke logger could be in your machine watching you enter it, so suddenly whoever is dumping the output from the keystroke logger, now they know what you know.  So knowledge itself is a bit hard to keep hold of often.  So the notion of multifactor authentication is that you - and again, we've done podcasts ad infinitum about this, the idea being that you need something else, for example, something you have in addition to something you know.  Well, if it's a something in the physical world, then much as a bad guy in some other country may wish they had what you have, they don't have it, and they can't get it because it's something physical which has a physical property which can be tested.



TOM:  Yeah, a lot of times people have little key chains that just run on an algorithm, that tells them what number to type in.  Kind of works on the same principle as your car key does.  You just don't see it in a car key.



STEVE:  Right.  Famously, the eBay or PayPal football that we talk about is a little LCD dongle.  You press the button, then you get a six-digit code, which is running a well-known public algorithm, but with an unknown secret key.  So the serial number of that device associates it with its key by some agency like VeriSign, their VIP program for identity protection, which now Symantec owns.  They're the service that you register your token with.  And they know at any given time what will be displayed on that LCD.



So I wish - the one thing that Google has done, well, the one thing that they failed to do was they did not support VeriSign's VIP system.  As we'll see, it's really gaining traction in the world.  And it would be nice if they just said, okay, in addition to our own stuff you could also use your existing PayPal/eBay football.  Or there's also an eInk version, same six digits, but it works on sequence rather than on time in order to minimize its power consumption.  Yet Google is going their own way, which is fine.



They have offered, or now announced and created, a rather feature-complete, multifactor authentication system.  So you're able to, under the User Settings tab, for example, in Gmail, you're able to - and I believe this is probably fully rolled out by now.  This was a few days ago, and they said they would be rolling it out across Gmail users over the coming couple days.  So if it's not there now, I imagine it will be there soon.  So you're able to enable this and, for example, give them a phone number where, when you log into your Gmail account, after authenticating yourself with your username and password, a Gmail robot will phone the number you've registered.  So, like, your cell phone right next to you will ring.  When you answer it, this bot speaks the six-digit code, which you then enter into another field in addition to username and password to confirm to Google that you're in possession of your phone. So something you have is this second factor of authentication.



TOM:  And that was the part that was a little hard for me to wrap my head around because it's actually being sent to you.  So it's not really something you have.  But I guess there's really no other way someone else could get it, so it acts like something you have.  Because it can come as an app; it can come as an SMS; it can come as a voice speaking to you; right?



STEVE:  Well, yeah.  So the good news is they've done a comprehensive job.  So one thing it'll do is you can give it a phone number.  You can also have it send you an SMS text message of the same content, if you would prefer that.  Or you are able to download, and I did for my iPhone, you can download an app, either for Android, Blackberry, or iPhone, which essentially contains an algorithm that will generate the code for you in order to authenticate yourself with Google.  So again, I'm a little annoyed because we already have all of this with, as I was saying, the VeriSign-Symantec VIP system.  All they had to do was make that an option.  And then now, for example, I have the Symantec VIP system on my Blackberry.  Well, now if I want to use Google authentication the same way, I need to add another app.  So we've talked often about the notion of not having a keychain full of separate dongles.



TOM:  Right.  I got my Blizzard, and my PayPal, and my Google, and, yeah.



STEVE:  Exactly.  So I'm annoyed on that front.  Maybe they'll add that.  It would be great if they did.  I don't think there's any cost associated with authentication from the person who's requesting authentication.  Maybe I'm wrong, so maybe that was the problem is that there was some cost associated with it, and so Google said, well, we're not paying Symantec for the privilege of authenticating...



TOM:  Especially if they want to put it out in this many different forms, if VeriSign was charging for each different delivery method or something.  That could run it up, too.  There's also an interesting thing about being able to carry some backup codes for when you're offline.



STEVE:  Yes.  They did something that's very nice, which is you can print a number, I think up to 10, static one-time codes, which you carry in your wallet, or wherever.  But the idea being if you, for whatever reason, you loaned your phone to a friend, I guess they're going to wonder why some robot is calling and spitting out numbers.  But so you do have backup, one-time-use codes.  The other thing that they did to lessen the burden of this somewhat is you can choose to remember the verification on a given machine for a month, for 30 days.  Which is nice.  So that means that, if you were to authenticate on a new machine, that is, you were at a friend's house, and you said, oh, I want to check my Gmail, well, there you'd need to have either your phone or your app running or your wallet with the 10 static passcodes in it, definitely, to authenticate on that new machine.  But for the laptop you're always using, your machine at home, it might be annoying if you were constantly having to receive phone calls from Google in order to login to Gmail in the privacy of your own home.  So here this allows you to back off a little bit and say, look, only every month I will reauthenticate myself on a given machine.



TOM:  Does that work with something like Eudora, Thunderbird, MailApp?  Does that allow you to use those for 30 days without having to constantly enter in that second bit?



STEVE:  Well, okay.  So the other thing that they did, this is the final piece of this, is that they recognized that there are non-web browser-based third-party apps which, because they have existed for some time, will prompt you for a username and a password.  But they don't know yet about this new authentication system, so they don't have a third field where you enter this code.  So the one additional thing Google did to really make this system complete is you're able to use one-time passwords instead of the password you've associated with your username.  They're able to give you one-time passwords that allow you to still log in through non-web browser-based apps.  So they've really covered the bases.  Again, I wish they had followed through and supported existing authentication technology rather than inventing their own.  But from what I could see, you could argue it's everything that the Symantec/VeriSign approach offers, plus more because you're getting SMS, and you're getting an audio loop through the phone, and then these extra features.  So I think it's very cool.



TOM:  They do have a challenge question if you lose your second factor, if you lose the thing you have.  Let's say you only had it set up on an app.  You didn't set up a backup phone.  That's one thing that's different from these other systems is, well, usually they say, hey, you lose that football, you're going to have to call us, and you're pretty much out of luck.  Does that make it less secure, that they have that challenge system at the end?  Or is that challenge system set up pretty good?



STEVE:  Certainly I think it makes it less secure.  I know that, for example, even when I'm using my football and authenticating myself with PayPal, underneath the little field where they're at, they're prompting me for the six-digit code, they say "Click here if you don't have your football with you."  And it's like, okay.  And then you answer a couple questions which are, unfortunately, what city were you born in and what's your nickname or something, I mean, the kind of thing...



TOM:  Really?  PayPal does that.



STEVE:  Oh, yeah.



TOM:  Oh, wow.  Because Blizzard doesn't.  Blizzard for World of Warcraft, you lose your dongle, you've got to call them and plead because your account is toast.



STEVE:  Frankly, I wish there were a way to even, like, disable that in PayPal, where you could say, look, I'm really very careful about what I do with my football.  I'm not going to lose it.  Please, for me, I don't want my security softened by falling back so easily to these security questions.  Make me jump through some bigger hoops.  But no.  So, yes, it's certainly the case.  And again, it's a tradeoff.  In some of the articles that I was reading about the announcement of this, the author said, well, you can imagine that there will be some Gmail users who are going to get themselves tied up in knots.  They'll somehow type in the wrong phone number.  Or they'll one way or another cause themselves some grief as a consequence of this additional security.  But that's always the, hey, that's the nature of additional security.  That's going to happen.



TOM:  We also have some additional security being added to the Sandy Bridge chipsets; right?



STEVE:  It's so cool.  Actually it was a listener of ours, a Steve Fintel of Intel, has been working on this, he says, for the past year.  I caught a note, he went to GRC.com/feedback and left a note for me that I saw, to bring to my attention the fact that the soon-to-be-released, like next month, the next generation of chips from Intel, as you said, the Sandy Bridge chipset - get this - will be incorporating exactly this Symantec/VeriSign-compatible, one-time password technology in the hardware.



TOM:  At the chip level, wow.



STEVE:  Yes, at the chip level.  So what it means is that your desktop machine, your laptop, will incorporate this technology to mean that you don't have to carry the football.  You register yourself with whatever authentication provider that they're supporting, and they currently support both the Symantec/VeriSign VIP system and Vasco, which is a major supplier.  In fact, I think Vasco was the actual hardware producer for the original PayPal football.  That actually was one of their tokens.  I remember at the RSA Conference a couple years ago seeing all these very familiar-looking tokens in the Vasco site, or at the Vasco booth at the RSA Conference.



So this is that familiar six-digit code that changes every 30 seconds, which we're used to seeing on the PayPal football.  The Intel chipset will build that in, I mean, it's a trivial algorithm, so it's cool that they've done it.  And not a big hardship for them, but very nice because it does provide - while it doesn't mean that you have the portability of the football, meaning the football allows you, or any of these portable tokens, or even for that matter Google's approach using a cell phone, to authenticate on any random machine.  What this does is it authenticates that machine.  So that's very nice because from a standpoint of bad guys logging in from overseas, where they don't have access to your machine, they have no way of knowing what six-digit code your particular machine would be generating at this point in time.



So what it does, of course, is it lowers the cost of this level of authentication.  One can imagine that a couple years from now all the Intel chipsets - and this is a public protocol, by the way, which is why Intel has been able to incorporate it, why there are several different authentication back ends, and that means that AMD will be able to do it.  And essentially, not long from now, it will just be built in.  All of our machines will have this multifactor authentication.  Our software will know how to query it, and we'll be able to surface that and use it to authenticate ourselves online.  So this is - I think it represents a major step.  I mean, Intel's move to putting this in the hardware is a very nice major step forward for authentication.



TOM:  The thing you have is your computer.



STEVE:  Yeah, exactly.



TOM:  Now, is there a danger that malware could get on your machine and be able to exploit that somehow by reading it out of your chip and sending it out?



STEVE:  I'm assuming Intel did this correctly, which means the vulnerability would exist if this weren't in hardware.  If this were anywhere in the software running on your machine, then malware has pretty much equal access to anything else running in your machine.  So, for example, underlying this sequence of six-digit numbers is a secret key, is a cryptographic key which, based on time of day, drives a cipher which produces the six-digit code.



So the beauty of Intel doing this in hardware is exactly like having the football, which is a freestanding separate piece of hardware.  Which is to say that I'm sure Intel will have done this correctly, so that the key itself, which is the only means for knowing what this six-digit code sequence is, is absolutely unreadable by any software, period.  That is, it's unique.  It's burned into the chip.  It's got to be printed somewhere, like maybe on the outside of the chip.  There has to be some way for you to register your laptop, your desktop, with the authentication provider so that they're able to determine what this is.  So somehow that has to have been handled.  But the idea would be that there's absolutely no software interface that allows that key to be read, period.  Which means that there just isn't a way for malware on your machine to get it and then leak that out.  It has to be the case that they've done that right, or they haven't accomplished anything.



TOM:  I hope they've done it right.



STEVE:  They certainly have the ability to do it right.  Oh, and I did want to mention, for anyone who's interested, a short URL, blissfully short, Intel calls this Identity Protection Technology, IPT.  So you can go to IPT.Intel.com, and they've got there two lists, one of hardware that is available, as it becomes available, and of websites that are currently using the Symantec VIP technology, and that list is growing.  So, and interestingly, the hardware available list has no entries in it at the moment because I think it's, like, March 11 is when they will begin rolling this out.  So the Sandy Bridge chipset, as it becomes available, will incorporate this.  So IPT.Intel.com, as this happens, you could use that to help select your next computer because I think this is great.  I mean, I don't see a downside to this at all, the idea of your hardware building in a universal, easily authenticated, six-digit code that's changing constantly.  It's just another factor of authentication that all of our systems will have before long.



TOM:  All right.  Well, I hope you're right.  I hope it works that well.  And it is exciting to think about not having to carry around another thing on your keychain, for sure.  Federal Trade Commission is finally catching up with Security Now! and making some good recommendations.



STEVE:  And what I like about this, I caught it, I think maybe a couple people tweeted it to me.  So I was clued into it there.  The headline was "FTC Warns About Public Wi-Fi Hotspot Dangers."  Well, of course that's no news to any of us.  The good news is that, if any of our listeners have ever wished there was a friendly, easy-to-use, really well put together website that they could point their less savvy friends and relatives to, I've got to say now there is.  The FTC site is called OnguardOnline.gov, just all run together, OnguardOnline.gov.  And it's very nicely designed.  In fact, I was impressed by it.  Of course, when I went there the first time, NoScript on Firefox did not allow JavaScript to run.  And in black against a dark blue background, so actually it wasn't very legible, but it still said, "To view this site's flashiest features" - pun intended, I guess - "please ensure that JavaScript is enabled and use the latest Flash Player.  If you don't enable JavaScript or install Flash, you will still find the site useful.



TOM:  Oh, nice.



STEVE:  It was because then what I got was a large sort of scrolling window of topics.  And the site was still usable.  Now, when I saw that I thought, well, that's okay, good job.  And nice that they really went to some effort to make it still function even without scripting.  So when I did tell NoScript to trust the site temporarily, and I generally say temporarily for sites that I don't intend to go back to all the time, just because I don't want that list of sites I trust to grow forever, it seems unnecessary.  So per session, I just said, yes, trust it.  The page refreshed.  Of course that little notice disappeared.  And what I got was a very nice Flash and script-enabled experience, which is unfortunately what most people will get right off the bat because they'll be flying in there with script and Flash flying.  So it works both ways.  I was very impressed.



And under the WiFi Hotspots topic, which is highlighted there, they say "Wi-Fi hotspots are convenient, but they're often not secure.  Learn how encryption protects your personal information, and get other tips for using public wireless networks."  And if you click that, or anyone you tell clicks it, what you're taken to is a page I couldn't have written any better.  I mean, it's really nice.  It's got a few points up at the top which, I mean, are all correct and all perfectly phrased.  And then nice explanations.  Even as far as at the bottom, going as far as to suggest and recommend and mentioning Force-TLS and HTTPS-Everywhere, those Firefox add-ons which tend to encourage sites that are able to to be over SSL all the time.



So anyway, again, nothing there is anything that our listeners don't already know.  But, oh, and there was another link to another even nicer sort of touchy-feely site that I had not been aware before by an outfit called the Internet Education Foundation, called Getnetwise.org, which is even friendlier, and very nice.  So I wanted to bring it to our listeners' attention as something that they could refer friends and relatives to, to give them a nice hand-holding, if you want to learn more about security, this is a great place to start sort of site, Getnetwise.org.  So I really recommend them both.  I was very impressed.



TOM:  Good stuff, yeah, good information.  Coming from the government, too, so...



STEVE:  Better late than never.



TOM:  Exactly, exactly.  It's nice to have a couple of easy URLs that you can tell people, like, hey, if you're worried about this.  And I do get people asking me, yeah, those public WiFi hotspots.  I'm like, well, the ones that say "Free Public WiFi," you can very safely ignore those.  Don't even go to them.  But if you're worried about the other ones, the ones that seem legitimate, like a Starbucks Coffee, go to OnguardOnline.gov.  That's great.  It's good to have something like that.



STEVE:  And I should also mention, I mean, I hope our listeners will check those sites out because the WiFi hotspot was just one category of about 20.  So, I mean, they talk about phishing, they talk about dangers of gaming online, they talk about email security.  So, I mean, it's very comprehensive.  The WiFi was just one of maybe 20 different topics.  So I'm really, really impressed that that exists now and wanted our listeners to know.



TOM:  Right, let's finish up the news section with Symantec releasing a little bit of new information about the Stuxnet virus.



STEVE:  Well, it's a little bit of new information on top of an amazingly comprehensive report.  In fact, I think we'll do an entire Security Now! podcast about Stuxnet finally.  We've been talking about it of course since it first reared its head.  But there was, for the longest time, not much known.  Symantec has updated, I think it's at v1.4 at the time of this podcast, what they call their "Stuxnet Dossier."  And in fact, if you want to find it, you can just Google, that's probably the easiest way to find it is to Google "Stuxnet Dossier."  I did tweet about it yesterday when it came to my attention.  So you could also just check my tweet feed.  I'm @SGgrc.  And you'll find a link there that I tweeted the link to the PDF.



It's a 69-page report.  That's why I don't intend at all to cover it in detail now.  But there's enough meat in it, really, really interesting stuff in terms of, like, I mean, they've been able to backtrack this thing to the original 10 machines which were first infected and what happened after that, all the way out at the other end to the five specific sites that it was targeted to and did ultimately infiltrate.  So it's going to make a great podcast.  I'm going to read all 69 pages, and I'll share what I learn with my listeners.



TOM:  Yeah, this is really detailed, down to compile time and infection times of different attack waves and clusters of infection graphs, little cluster graphs.  This is incredible what they've done here.  You do need to have Symantec.com approved for scripting because it's a PDF.



STEVE:  Ah, right.



TOM:  Thing I found just now.  It's like, why am I getting a black page?  Oh, right.



STEVE:  And I did want to correct something that I said last week when we were talking about the Windows Update for the USB thumb drive autoplay.  It turns out Microsoft put that in the optional category.



TOM:  Oh, they did, okay.



STEVE:  So what was different was it will not install itself without your knowledge, but it will be visible for the first time in Windows Update.  So instead of having - so what the difference was, instead of people having to go to some knowledge base article and track it down, as was necessary before, now it's in optional updates.  And presumably it's just going to sit there in optional updates until users either say I don't want to see this anymore, as you're able to do with Windows Update, or ignore it, or install it.  So it won't do it to you.  But it is available much more easily now through Windows Update.



TOM:  All right.  We've got 10 good questions to get to in our Q&A session today.  But I know we've got another SpinRite testimonial to talk about first.



STEVE:  Just a little quickie.  I got a kick out of this because our listener referred to it as a recursive, the first recursive testimonial.  His name is Mike Woods, and he wrote saying, "SpinRite helps me watch Security Now!.  And he's in England.  And he said, "Hi, Steve.  I'm a regular Security Now! watcher.  A few days ago" - hi, Mike.  He says, "A few days ago I switched on my media PC to watch the latest episode, and I got the dreaded Windows Recovery screen.  Two or three unsuccessful boot/repair/fail cycles later, I gave up.  After hearing many testimonials for SpinRite on Security Now!, I decided to give it a try.  One purchase and 10 hours of disk activity later, I was able to reboot the media PC and am currently watching the latest version of Security Now! on it.  I thought you might find this story pleasantly recursive.  Thanks for a great product.  Mike."



TOM:  That's great.



STEVE:  So thanks very much, Mike.



TOM:  I'm glad you're able to keep watching, Mike.  All right, let's move into Listener Feedback #111, start it off with Spencer in Fayetteville, Arkansas.  And like we mentioned at the top of the show, a lot of Bitcoin questions in here because people are excited about this.  But when you start using it, you immediately start having questions.  When I was launching it during the show last week I had questions about, well, wait a minute, it doesn't seem to be connecting, how long does it take to connect, all that kind of thing.  So here's Spencer's question.



He says:  I'm a longtime fan of Security Now!, great stuff, and was very intrigued by last week's topic, Bitcoin.  I perused the trade page that lists eCommerce sites that accept bitcoins as payment.  As one of the most visible crypto geeks on the web, would you, Steve, ever consider supporting Bitcoin payments in exchange for GRC products?  And then he says:  Errata:  A very large number of bitcoin transactions occurred on February 9th.  Just a coincidence that Security Now! aired that day?  Take care.



STEVE:  Well, I had a number of listeners write in with that question.  And the answer is yes.  I think - I like the idea.  I think it's cool.  I did write my own eCommerce system.  So my feeling is, I mean, why not?  What the heck?  I'm not sure what it would mean to do that, but I think it would be fun.  So next time I'm in my eCommerce system making some changes - I probably will be at some point in the future.  I haven't touched it, knock on wood, actually since I wrote it.  It never had any bugs.  So it's been a while since I've been in there.  But I know that our legislature in Washington keeps looking at all of the tax revenue which is being lost because Internet transactions are nontaxable under most circumstances, and I don't know how long that moratorium is going to continue.  So I keep watching that nervously, thinking, okay, well, I'm probably going to have to go back in and deal with tax at some point.  So when I'm in there, I think I probably will.  I think that would be cool.  Basically what it would mean is that I would be publishing that long alphanumeric string token, which would be our Bitcoin account.  And people who had bitcoinage could move money over to us that way, which it would be authenticable, and it would be irreversible and, I think, fun.  So I plan to do that.



TOM:  How much would it be in bitcoins?  Would you just keep it at parity?  We drove up the value of bitcoins, I think, talking about it last week.



STEVE:  Actually, I think that also happened, yes.  We drove it above a dollar per bitcoin.  I know that it generated a lot of traffic.  There was a comment on the Bitcoin.org page saying that - no, it was the Bitcoin status account on Twitter said that, due to unusual level of activity, they were having problems with their server.  So I think we did tax them.  Our listeners taxed them.



TOM:  We did some stress testing.



STEVE:  Yeah.  So I guess I would somehow use the current currency trading rate versus the U.S. dollar for bitcoinage, which you could probably determine online, to determine at any given time what fraction of bitcoins was equal to the price of the software.  So, interesting problems.



TOM:  Makes sense.  Question No. 2 from Anthony Headley in Mississauga, Ontario says:  So isn't this just a great way for funds to be laundered?  And a lot of people in the chatroom had this question last week when we were talking about this.  Since you can create multiple personae, couldn't the following be attempted?  Badguy1 wants to send 10,000 BTC to Badguy2 without regulatory scrutiny.  So Badguy1.1 sends 5,000 BTC to Badguy2.1.  And then Badguy1.1 sends 5,000 BTC to Badguy2.2.  Badguy2.1 and 2.2 are the same physical person, but there would be no way of knowing this.  Worse yet, huge amounts of funds could be transferred via sneakernet, TrueCrypted databases, between borders without being able to be traced. It is interesting being able to see BTC transactions in real time, though.



STEVE:  Okay.  So, first of all, yes.  What I got a kick out of was of course it seems to me that what Anthony is referring to here when he talks about 10,000 BTC is the fact that, at least in the U.S., and I guess in Canada, where he is, transactions of up to, I think including, $10,000 do not have to be reported to the government.  But transactions with your bank greater than $10,000, even $10,001, require a bunch of paperwork on your bank's part and end up needing to be reported.  So he was talking about breaking up a $10,000 transaction into two $5,000 transactions and noting that you could easily create, as you can, multiple Bitcoin accounts, essentially, and transfer these numbers to different ones, although they end up all going to the same guy.  And in fact presumably what one of those accounts would do, then, would be to transfer $5,000 of bitcoins, 5,000 bitcoins to the other account, which can be done for no cost, so there's no reason not to do so.



Okay.  So the point is, these are all anonymous.  So you could transfer a million dollars, I mean a million bitcoins, between two different Bitcoin accounts, and no one would be the wiser.  The system is anonymous.  It's distributed across the Internet.  It's based on account numbers which have no identities associated with them.  The only way you own the coinage that you do is that you have the private key that matches the public key.  And the only thing ever visible out on the network are the public keys.



So this is like God's gift to money laundering.  Which is, I mean, it's true.  But this is always the dilemma.  I mean, this, for example, is the crypto dilemma.  It's like crypto is also God's gift to people who want to hide things.  And unfortunately, it can be good people who just want privacy, to which they're legally entitled; it can also be bad people who are using cryptography to communicate bad deeds which they don't want to communicate under the public scrutiny because they could be caught.



So we have the same dilemma here.  What we have is we have a fabulously powerful technology, enabled by crypto, which is absolutely bulletproof, just like crypto is.  And just like crypto, this application of crypto creates a dilemma.  And that is, yes, if this currency takes hold, as it is acquiring traction rapidly, so that you can move real world currency into bitcoins, and then you can transact bitcoins anonymously, and you can move bitcoins back into even some other different real world currency, then yeah, I mean, this has all the potential for being used both for all kinds of, you can imagine, like, humanitarian purposes where there are good reasons that you want, for example, an oppressive government not to be able to monitor these transactions, but also for, unfortunately, bad guys to move money around.  I mean, that's what happens when you end up with a technology like this which is that powerful.  It's just it's part of the bargain.



TOM:  Glowdime (sp) in the chatroom points out that the $10,000 reporting rule in the U.S. was changed effective January 1, 2003 to a "suspicious activity rule," along with the enaction of the Patriot Act.  So now I guess just putting money into Bitcoin could flag you because it's suspicious activity.



STEVE:  Well, and it's funny because, as I was talking about this, when I was just now talking about moving real world money into Bitcoin and back, it occurred to me that the way you would do that was through some of these trading companies, and they would probably have these reporting criteria.  So maybe what Anthony was talking about was doing it 5,000 bitcoins, or actually probably $5,000 in this case, at a time, in order to avoid those reporting criteria.  That is, yeah, you don't want to look suspicious, so you do 10 $1,000 transactions rather than one $10,000 transaction.  And that's why he was talking about Badguy2.1 and 2.2.  You could also be sending them, those $10,000 pieces, to 10 different account numbers which are in fact all owned by the same person.



So I get a better sense now for what he was saying.  And absolutely, this system without limit allows you to create these accounts.  And as he says, when he talked about moving data across borders, the idea is that your Bitcoin wallet is just your private key collection.  And it's up to you to protect that, to back it up, to preserve it, to keep it private.  So if you were to bundle that up into an encrypted container of some sort, then, yeah, I mean, no one knows what's in there.  You can carry it wherever you want.  And you are carrying your Bitcoin bank account with you.



TOM:  Put your Bitcoin in your hidden TrueCrypt volume.



STEVE:  Right.



TOM:  Question #3, John O. in Argyle, Texas follows up on the Windows Autorun episode, says:  You said you were pretty sure it would be possible to reenable the autoplay function in the registry after the patch was applied.  You were right, and Microsoft has a Knowledge Base article on how to do this and has a Fixit solution also.



STEVE:  Yeah, I just wanted to post this for people who might have gotten themselves in trouble, who might in the future get themselves in trouble if, for example, they disable this autorun by installing it on a system where it turns out that they wish they still had it.  It's support.microsoft.com/kb/967715.  So again, it's support.microsoft.com/kb/967715.  And that deals exactly with that problem, that is, you've installed this optional Windows Update on whatever systems, but on a given system you want it back on again.  So Microsoft, their little Fixit solution is the one-button click in order to reenable.  So that does exist.



TOM:  All right.  Thank you, John O.  Question No. 4 of 10, Danial Bulloch in Concord, North Carolina, USA, North America, Sol3, Milky Way, Universe - wow, he's really covering all the bases here - wonders about lost change in Bitcoin.  He says:  Listening to Episode 287 left me with many questions as to how it could functionally be considered.  But the one issue that stood out to me 

most is the thought of "lost change."  Since the coins appear to be stored locally, would it not be entirely possible to "drop" a coin if it wasn't properly backed up during hardware failure or another problem?



If it is possible, would that not result in a slow decline in the currency in circulation, with a slow increase in the value per coin?  Sure, today this wouldn't be an issue; but if the currency was being used for potentially hundreds of years, at some point the only remaining currency in the system would be fractions of coins, adding up to a very little total.  I guess, given enough decimal accuracy, a house costing one bitcoin wouldn't be so bad.  But people wouldn't like the concept of a week's worth pay being worth 0.0003 of a bitcoin.  This is an interesting question, which is...



STEVE:  It's brilliant.



TOM:  ...like you said just now, we have to back it up.  What happens if we don't?



STEVE:  Well, exactly.  And he's completely right.  The idea is that your sole proof of ownership of coinage is what you have in your wallet.  Now, it occurred to me that there is a transaction trail from the beginning of time, that is, literally - which in this case is 2009, when that first block was created, the genesis block in the Bitcoin system.  And that chain of blocks is a transaction log of every single transaction that occurs.  So that would allow you to see where the original 50-coin owners were.  But those inherently only contain their public keys, not their private keys.  And we know that the whole point of the public key/private key pair is that you can't get one from the other.



So it is the case that, if you lose your wallet, if your hard drive crashes and your wallet's not backed up, I mean, essentially the instructions that are part of using Bitcoin talk about making a backup immediately after transactions.  And you can understand why.  I mean, this doesn't have any of the benefits of real world physical currency that just can't spontaneously evaporate.  This stuff really can.  And exactly as Danial suggests, once it's gone, once you lose your private key, which is your only claim of ownership to coinage, there's no way to get it back.  You can't get it back from your public key.  You can never prove that a given public key was yours unless you have the matching private key.  So he is exactly right that, to the degree that people lost coins, once lost, they're gone forever.  And there's no way to prove that they're gone forever to the system.  So it would always enforce that 21 million coin absolute limit that it will be approaching, and ultimately there will be fewer than that number of coins in the system.



TOM:  Maybe there could be an unclaimed bitcoins office, so to speak.  Yeah, because you'd have to put in some kind of time limit to say, if you don't refresh and verify your ownership of the bitcoins, we'll put them back in circulation. But that's not the way it's set up right now.  Right now they're yours forever.  You don't have to prove that you own them.  But at some point they might have to deal with that.  That's a really interesting question.



STEVE:  Yeah.  I don't see that there's a solution to this.  I mean, one of the things that is cool about a system with this level of integrity is there are problems without solutions.  And this is a problem without a solution.  I mean, you can't have, oh, I'm sorry, I lost my coins, can you replace them, and anonymity both.  Because if you're going to have absolute anonymity, then it has to be the case that you are unable to prove that you have lost your coins.  Those two things go hand in hand.  And I would argue that one of the cool things that this system offers is, by virtue of being a peer-to-peer network, it's absolutely anonymous.



TOM:  John J. Jobst in Columbia, Illinois, wonders about faking out Bitcoin.  All right, let's see if he's found another weakness built into the system.  He says:  Your Bitcoin broadcast was very interesting and a welcome diversion from hearing about the latest Adobe exploit.  I was wondering what would prevent me from running Bitcoin on my 486 processor so that I wouldn't significantly increase the difficulty factor for everyone else, then offloading the problem to my GPU farm, then returning the answer to my 486 to upload?  You said it was open source, so it should be possible to reprogram.  Could he fool it that way?



STEVE:  Okay.  This is another one of the things that is so cool about the system.  I think that this bitcoin concept and the way it's been implemented is academically interesting just because the designer of it, in a sense, thought of everything.  I mean, the system holds together, and it works.  And it is unspoofable.  So here's why what John suggests can't work.  It is the network as a whole, operating in this vast peer-to-peer interconnected mesh, it determines the rate at which the puzzles are being solved by counting the rate, by looking at the rate at which these puzzles are being solved.  By "puzzle," of course, I mean finding the tweak that is added to a block in order to get its hash to have the required number of leading zeroes.



So all the machines that are in the network which you have told, please mint coins for me, they're taking blocks and trying to solve the puzzle.  If they're the first one to do so, which they announce on the network, they get the 50 bitcoins in the block.  So all the machines have the incentive to announce their solution to a block as fast as possible.  Which means all machines are going to be announcing the solution to the block as soon as they can because it's by doing so that they win 50 bitcoins at this point.  So the network as a whole can see the rate of those announcements, which will always be made as quickly as possible.  And it's the network as a whole which is balancing the difficulty to keep that rate at six announcements per hour, six blocks created per hour, which brings 300 coins at this point, new currency, into the network per hour.



So as more machines join the network, or as more powerful machines join the network, statistically, because of the overall increased processing power, there will be an increase in the rate at which the puzzles get solved.  And so the network scales, by agreement, scales up the difficulty to slow down the rate at which the puzzles are being solved.  So John's example of having sort of a slow processor front end and a screaming GPU farm back end doesn't get him anything because, if he's got the screaming GPU farm on the back end, it'll be providing solutions to his pokey 486 front end much more quickly than somebody else's, and so the network will recognize that, wow, this guy's minting coins over there somehow.  But what happens is, if that continues, then that minting rate, the puzzle solving rate goes up.  And so the entire network will agree, whoops, we've got to add another zero to the puzzle, make everybody work harder in order to bring the rate of block puzzle solution solving back down.  It's just conceptually such a fantastic system.



TOM:  Now, this begs another question, which is actually our next email from Efrain in Miami, Florida, who's, like, wait a minute, how can I compete, then?  I'm a little confused about how this works.  Does my old recycled machine have a chance of generating bitcoins against the massive bitcoin miner machines?  And since I have multiple old machines, could I have them all run as one account?  I guess my old machines combined cannot compete with a bitcoin miner machine.  There's a sense, he says, that only the rich get richer.



STEVE:  Well, okay.  That's the other cool thing about the nature of this.  I also have had three machines running full-time for a week now.  My little Mac Mini that we're doing the podcast on, actually I stopped Bitcoin just so that it wouldn't interfere with our podcast.



TOM:  It does really use up a lot of cycles, I've noticed.



STEVE:  Oh, boy.



TOM:  My fan runs constantly when I've got it on.



STEVE:  Yes.  And in fact I've got one machine that's got - in fact, it's the one I built for the video experimenting, which is an i7875.  And it's putting out heat at a much higher pace, because I've got Bitcoin running on it, than it did before.  And it's generating 5,418 hashes per second.  So that's the rate at which it's able to attempt to solve these problems.  My little Mac Mini was doing 1,400 hashes per second.  But here's the idea.  The idea is that it's chance.  It's statistics.  All the machines in the Bitcoin network are guessing, essentially.  They're guessing a 256-bit number which, when hashed along with the block, will produce a result that solves the problem, meaning some number of leading zero bits in the resulting hash.  There is no way, I mean, the beauty of a cryptographic hash, the reason we use hashes, the thing that they provide for us, is it is statistically - I've lost my vocabulary.



TOM:  Statistically unlikely, maybe?



STEVE:  Maybe the word "statistic."  It's computationally - "impossible" is too strong.



TOM:  Improbable?



STEVE:  Improbable.  There is no way to brute force the hash.  You cannot put something in and deliberately design what comes out.  So you have to guess.  You have to hash your guess along with the block and see what happens.  Now, the only advantage that the faster machines or the GPU-based machines have is they can do many more guesses per second.  So statistically on average they are more likely to stumble upon the solution before somebody with a slower machine.  But that's not to say that somebody with a slower machine might not get lucky.



TOM:  Right.  It really is like a lottery; right?  The rich people can buy more lottery tickets, but that doesn't mean they'll win.



STEVE:  Precisely.  That's exactly it.  If you bought more lottery tickets, you would be increasing your likelihood of winning the lottery.  But how many examples do we see of some guy who only ever bought one in his life, and now he's a multimillionaire.  So if you've got old machines, and you're curious, until you get tired of it, or until you get tired of the house warming up too quickly, they could be running Bitcoin.  I've got several that are doing it, I mean, just sort of to see.



Now, it is the case that a typical PC today, running for about a year, would solve one puzzle before everybody else.  So that would earn you at this point 50 bitcoins.  I don't think I'm probably going to do this for a year.  But I'll do it for a couple months before it's like, okay, fine.  And there's a chance, I mean, a chance that I will look one day, and my bitcoin balance will be 50 rather than zero.  And that would just be fun if that happened.  I think that would be cool.



And to answer Efrain's question, each of the instances of Bitcoin that you install would have a different private key and a different public key.  That is, they each have their own account.  But remember that there is zero cost, zero transaction cost in this system.  So if multiple machines each scored some money, you just transfer the money from one to the other.  Each Bitcoin instance running, you're able to see and enumerate all of the keys that you've generated, all of the little accounts.  And so all you would do is just send the coinage from one machine to the other.  And in fact, the act of doing that is what generates transactions out on the peer-to-peer network, which creates the puzzles everyone is trying to solve, to validate and lock up those transactions.  And then the funds go and are confirmed.  That's just such a - it's an incredibly cool technology.



TOM:  Yeah, it is.  I'm really excited about it.  I've got to put it on my gaming machine and let that thing crunch at it for a while if I'm going to have my best chance.  Although you can't pay your electric bill in bitcoins yet.  That's the only negative to it.



STEVE:  You're using up more power, yes, than the coinage you're generating.



TOM:  All right.  We'll finish up with some non-Bitcoin questions.  Seven out of 10 is Eric Stearns in Denver, Colorado, who wonders about transparent open source versus opaque closed source.  He says:  You, Steve, and lots of other people, make a critical distinction between closed and open source software.  The source code is available for the open source software, making it fairly easy for a knowledgeable person to evaluate how the software operates.  I presume that the key benefit is that you can look at the instructions in the program before they are compiled into something useful for the computer to process.



But I've never understood the technical differences between the two, and what makes a closed source program so much more difficult to understand than an open source program.  It must be possible to deconstruct how a closed source program operates by looking at the compiled code.  Is the principle benefit of open source software the programmer's comments that are omitted by the compiler?  Is there some reason that compiled code couldn't be deconstructed?  Is it just that closed source programs can't be evaluated in a reasonable period of time?  If so, how much longer would it take to understand the operation of a closed source program?  Again, that's Eric, SpinRite owner for several years, he says.



STEVE:  Well, this is, I thought, a great question.  And we happen to have a perfect model in something happening right now, which is Stuxnet.  Stuxnet, the code, has been available on the Internet.  It's been passed around freely for many, many months.  And only now are the people who have been spending full-time trying to understand it reaching real definitive conclusions.  If instead they had the source code for the Stuxnet package, they could have answered any questions in an afternoon.  So that really is the difference.



I'm a little bit of a dinosaur, as we know, because I write all of my stuff in assembly language.  That is, I write in the code that C compilers and C++ compilers and JavaScript and so forth, that are compiling and not interpreting, compile down to.  So people through the years, with all the free stuff that I've put out, some people sometimes come into the newsgroup and grumble that why don't we have the source code for the DNS Benchmark?  And normally somebody else will type in and say, wait a minute, Steve writes his code in assembly language.  So all you have to do is disassemble it, and you do have the source code.  Whereas compiling does create - okay.  So the point there is that what I write is exactly what the computer executes, and you are able to disassemble that back to essentially the code that I wrote.



However, as Eric suggests, the act of assembling and compiling, you lose a whole lot of context.  You lose normally the long and friendly names of variables, so you can't see, like, what's being added to something else.  You see a couple of memory addresses being added to each other.  But it takes a long time then, by looking at the code, to track the entire history of references to those memory addresses, to then begin to say, oh, you know, I think this area of code is doing this.  And that area of code, which is doing, like, there's some I/O operations over there, it's doing that.  And so, if you don't have the source - even if it's just disassembled assembly language, but even more so if it's disassembled compiled language, because there's a much greater distance between what the author wrote and what the machine executed due to this compilation.  That's what makes writing in a higher level language easier - higher level because there's more of an abstraction between what you write and what the machine does - than lower level languages.



But the point is that there is a huge amount of valuable information lost.  The names of subroutines, you can see that code jumps to somewhere, but you don't know what that somewhere is supposed to do until you analyze in detail what it appears to be doing.  But the source code gives a name to the subroutine that, in well-written code, tells you all you ever want to know about it, so much so that you can sort of ignore what's in the subroutine.  The subroutine says "print the string I've been passed."  And so it's like, okay, if you jump there, that's what it's going to do.



So none of that information survives the compilation and assembly process down into machine language.  All you're left with is sort of just this dense nugget of things jumping around and memory instructions and memory locations being added and subtracted and moved around.  And it takes a huge amount of effort to sit there and basically, like, reverse engineer the intent and the purpose and the actual function from what all that does.  It's so detailed that you want to step back further from it.



But the only way to do so is to literally understand it at that level first and then sort of work your way back to a higher level understanding, assigning these locations names and assigning subroutines names as you begin to figure out what they mean.  So it really is a whole different ballgame to have just the result of something like the Stuxnet worm, which only now, months after sitting there, I mean, there have been guys at Symantec whose lives are Stuxnet for the last six months.  And they're now beginning to understand it because all that was left was this little dense nest of instructions.



TOM:  Those guys are salivating at the idea of having had an open source Stuxnet or an assembly-written Stuxnet, aren't they.



STEVE:  Yeah, somewhere is the source code.  And it would have just, I mean, it's all laid out in the source code.  They have recreated the source code, essentially; but, boy, that was a lot of work.



TOM:  Three more questions.  John Webb is next, from Mechanicsville, Virginia.  And he's got a challenge.  He says:  Hey, Steve Gibson, I've been a fan of GRC, Security Now!, and a user of SpinRite 6 for some years now.  I greatly appreciate Security Now! and regularly check the GRC website for the latest transcripts.  However, in the recent Episode #286 with Tom Merritt, I was surprised that Intel's plan to implement an improvement to chip architecture to block zero-day malicious attacks was described as a "looney tunes announcement of the week." 

 

As most zero-day attacks typically involve a buffer overrun in the stack to hijack the transfer of execution control, I have to say that I do not so lightly dismiss a chance to improve system security by implementing improvements in the processor design.  Rather than dismissing this claim, I'm inclined to wonder how it might be possible for the processor to block attempts to overrun the buffer.  I do not work for Intel, nor do I have any inside information; but that need not prevent us from using what we know and what we can imagine.



STEVE:  Okay.  So I think John misunderstood, and there were a couple of other people who asked a similar question.  So I wanted to address it.  What you and I were chuckling about was Intel's claim that this solved zero-day exploits.



TOM:  Right.  It's not that it isn't more secure, it's that it eliminates the possibility.  And you just should never speak in those absolutes.



STEVE:  Yes.  So what Intel explicitly said, or this CTO, I think it was, of Intel, he was quoted as saying that this would eliminate zero-day exploits, which is exactly equivalent to saying this will eliminate all security vulnerabilities.  I mean, that's what that means.  The difference between a zero-day exploit and one that's not is that some researcher found it and told Microsoft about the problem, and they fixed it before the world found out about it.  Zero-day exploits are ones where somebody found a vulnerability and didn't tell the producer of the software.  We just saw it happening in the wild.  So what the Intel CTO was quoted as saying, essentially, is there will never be another security vulnerability.  Which is patently ridiculous.



TOM:  And, yeah, what John is saying here is that, well, what about buffer overrun?  And that's a great point; right?  But what the guy said was not "we've solved buffer overrun problems."  He said "we've solved all problems."  And I bet that's not exactly what he meant to say.  Or maybe he did, I don't know.



STEVE:  Well, yes.  And so, for example, buffer overrun is one way that we've talked about of a bad guy getting code that they provide to run in your system.  But there's also the return-based programming that we've talked about, where instead you jump to the end of existing code to get it to do a little bit of your work, and then it comes back.  And then you jump to the tail of a different subroutine, like sort of into the middle of a subroutine, so that the last few things it does before it returns are what you want.



And so, for example, if the claim was once made that data execution protection, DEP, would allow you to prevent data buffers that were marked as non-executable from executing any code.  So a buffer that was in one of these non-executable regions couldn't be executed.  Well, somebody might have said, oh, well, that's going to prevent all security problems.  It's like, whoops.  It doesn't prevent jumping to the end, the tail end of existing subroutines, which by definition are executable, and having them do the work for you.



So unfortunately there is no pot of gold here in this arms race with security.  No doubt Intel has some new hardware that will allow, when implemented, software to leverage it somehow to make some problems or some exploits harder to do.  That's a good thing.  That raises the bar.  I didn't mean in any way to presume that Intel was not going to give us anything.  But I was just saying the statement that was quoted was looney tunes because it can't be true.



TOM:  Yeah, and I still agree with you.  All right, let's finish up with a couple of Brits.  Amos Kittelson in Bristol, U.K., has an interesting idea.  He says:  In Episode 286, Question 4, you and Tom discussed the difficulties inputting long WiFi passwords into portable devices.  I started wondering if QR codes could help.  QR codes are two-dimensional barcodes that can hold up to 4,296 alphanumeric characters in a variety of different formats.  Most camera smartphones have apps available that allow you to scan the contents of the QR code into the phone's memory.  "Barcode Scanner" in the Android market, for example, scans the contents directly into the clipboard, allowing you to paste it into your WiFi settings.  May I suggest using the link below for creating a QR code, printing it out, and storing it in a safe place for use when necessary.  Of course, this wouldn't help with a Kindle, but it's a start.  Thanks for the great podcast and SpinRite, which has saved me from disaster more than once.  So you'd have to get the different devices to play along with this, but what do you think?  Is there any downside to having your password printed out on a QR code?



STEVE:  I think it's a clever means of getting it in.  And he provided a link to a site that I think is really nifty that I wanted to share with our listeners.  The site is Zxing.appspot.com/generator.  So again, that's http://zxing.appspot.com/generator.  And it is a very clean, nicely designed, QR code-generating web page.  I'm sure you have to turn scripting on in order to use it.  But it provides a lot of different formats of types of QR codes, and prompts you to input fields, and even has one for WiFi, where you're able to put in the SSID number of a hotspot and specify what type of encryption you use and put in your password, and it'll convert it into a QR code.  So that's going a little further.  But you can also just handle random ASCII, and it'll convert it.  So I thought that was cool.



Apparently there's a good QR code scanner for Android, and there's one that I found for iPhone on the iTunes store.  A bunch of them are there that are free that didn't seem worth the time downloading them.  But, yeah, I thought it was cool.  And it was a way to get something into your system.  And they do transfer the data to your clipboard.  So from there you could paste it into the password field of your WiFi.  And so you can sort of carry that little gizmo around in your wallet, and no one would know what it was. 



TOM:  I like this.  I'm trying it out.  You only need, because it uses the Google API, you only need Google's scripts turned on for it to work.  So if you've already done that, it'll work for you immediately.  And it really works fast and clean.  We just need to get Microsoft and Nintendo and Sony and Amazon to support this so we could just hold it up to our game consoles and say, there you go, there's my WiFi password.



STEVE:  Exactly.



TOM:  Now we're in.  All right, we've got one last question.  And then we're done.  And I have to say that I'm sad to see it go because Leo's coming back this week, and I've really enjoyed this.  But let's get to the question first.  This comes from Jerry in Swindon, England, about all of our talk of Firefox add-ons and track attackers and all of these different ways of stopping yourself being tracked by ad agencies.  He says:  Thanks for the continuing informative podcasts.  Over the last few weeks I've been following your updates on site tracking.  I recently was putting the Firefox add-on, Better Privacy, onto a new PC when I stumbled upon an add-on called Ghostery.  I have to say it appears great.  You do have to ensure you go into Options and select "All" to activate the 340 blocked sites.  If any site is not blocked, the small icon in the Firefox status bar can be clicked to add the site trying to track you.  You can opt for a small window to pop-up to tell you what sites are currently being blocked.  And I have to say I had no idea how much "track-attack" was going on.  It can also delete Flash and Silverlight cookies on exit.  It probably sounds like I am the developer, given the amount of fluffing I have given this add-on, but I promise you I'm not.  I have just found it to be a great tool for my PCs and those of my relatives.  Just wondered if you had heard of it.  Jerry.



STEVE:  Well, I really wanted to thank Jerry and also to share it with our listeners.  I had not heard of it, and I'm really glad to know of it.  I've had no chance to play with it yet.  But it's on my list of things to do.  So if it ends up being something that I end up using, I'll let our listeners know.  I do have something I added which is blocking or deleting Flash cookies on exit.  And if this does that, too, then I will probably remove that other one and add this and see how it goes.  But I just wanted to give our listeners a heads up.  It's Ghostery, and Jerry thinks it's great.



TOM:  Yeah, if you go to Ghostery.com, they have add-ons for Firefox, Safari, Google, Chrome, and IE.  So it's not just a Firefox add-on.  That's great.



STEVE:  Very nice.



TOM:  I think I now am going to steal Jerry's idea and use it as my tool on This Week in Google because it's a Chrome plug-in, and I definitely want to try this out.



STEVE:  Cool.



TOM:  All right.  Well, that is the end of this episode of Security Now!.  Thanks, everybody, for watching.  And Steve, thank you so much for letting me fill in for Leo while he was gone.  This has been a blast.  I've really enjoyed it.



STEVE:  Tom, you've been a great host.  And Leo, we know, likes to travel around.  So I'm sure this is not the last that our listeners will be hearing from you on this podcast.  I look forward to your return.



TOM:  I'll bet you a bitcoin you're right.



STEVE:  Thanks, Tom.



TOM:  All right, thanks, Steve.  We'll see you all next time on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#289

DATE:		February 24, 2011

TITLE:		Proxied Surfing

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-289.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's security updates and other security-related news, Steve and Leo discuss the many modes of operation of "Proxied Web Surfing" which are used to bypass firewalls and Internet filters, aid free speech, and alter the contents of web pages retrieved from the Internet.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 289, recorded February 23rd, 2011:  Proxied Surfing.



It's time for Security Now!, the show that protects you, your loved ones, and everyone else on the Internet from predators and viruses and bad guys, and at least explains how all this stuff works.  Here he is, the man who does that, the man of the hour, Mr. Steve Gibson of GRC.com.



STEVE GIBSON:  And in this case, Leo, maybe even foreign governments, or your own government that doesn't want you to know what's going on or talk to other people or your corporations or your schools or whatever.  We're going to talk about something this week that, oddly enough, in our sixth year, we've never directly discussed, which is proxied surfing, the idea of connecting to the web through proxy servers for a number of different reasons.



It sort of came onto my radar when I was reading about what was going on, of course, in Egypt in the last couple weeks, with them disconnecting the Internet, and then reconnecting it, and how strong and important the whole Facebook and social networking had become for organizing groups.  And I ran across a couple references to some proxy sites that offer their services, for example, in China, that allowed people to use them in order to bypass the Chinese restrictions that were being imposed.  And I thought, that's obviously a great topic for the podcast.  We've never really addressed all the different reasons you would use proxies, and exactly how the technology works.  So that's our topic for this week, in addition, of course, to other stuff.



LEO:  Very interesting.  And what's been interesting in both Libya, and it happened in Egypt, and it happened in Tunisia, and I expect it will happen everywhere else where they try to restrict the Internet, is companies coming along, saying, well, you can always use dial-up.  And while we don't, in the West, think of dial-up as a decent solution, it's plenty for tweeting and emailing and setting up Facebook pages.  And obviously I think the time has - I'm very bullish.  I think the time has come.  I think the Internet is really a disruptive force in a lot of ways, and it's very exciting.



STEVE:  Well, it's clear that it is because for a nation to take itself off the 'Net, I mean, that does not come at zero cost to the nation.  And so...



LEO:  And it doesn't come with success, I mean, at least in the case of Egypt.



STEVE:  Right, right.  And so given the fact that it would be so disruptive to a country's operation to disconnect it from the rest of the world, you'd have to imagine that the government that decides to do that is weighing the pros and cons and looking at the benefit they'll get from being repressive in that fashion, meaning that it is so powerful for their citizenry, in this case, that they want to disconnect from the rest of the world, to have access to it.  So, yeah.



LEO:  Well, let's - we're going to get to that subject in just a moment, of course.  But before we do, how about some security updates?



STEVE:  Absolutely.  It's been quiet because we had the second Tuesday of February was a biggie for Microsoft.  Things have been busy.  And welcome back, by the way.  Tom did a great job for us.



LEO:  Thank you for reminding me.  Thank you, Tom, for filling in.  I'm so sorry.  Tom, I owe you an apology.  Yes, three shows he did.



STEVE:  Yeah, he did a great job for us.



LEO:  Good, thank you.



STEVE:  I remember being very nervous at the idea of not having you.  Of course Tom stood in once before and did a great job.  And this time it was like, oh, hi, Tom, welcome back.  So in fact I had to send my email to someone else.  I almost sent it to Tom this morning with all the show notes.  I said, wait, wait a minute, Leo's back.



LEO:  I'm back.  I'm back, please.  I had a great time.  It was a wonderful trip.  I'm wearing an alpaca sweater even, right now, that I got.  And I showed yesterday, I showed everybody my Uruguayan hat.  But I haven't showed you yet.  This is, now, that's the ensemble.



STEVE:  [Laughing]



LEO:  Anyway, security updates.



STEVE:  Okay.  So the only real big news is that anyone who is still using or needs to use Java on their system needs to update it.  It was just moved by Oracle/Sun, a major update from them, to Java 6 Update 24.  It fixed a large collection of vulnerabilities, in total 21, 19 of which can be used to remotely install malicious software.  So it's important.  And I did get a kick out of seeing now sort of the wisdom out there, I was reading other people saying, you know, since Java seems to be having so many problems now, and it's surpassed Adobe in vulnerabilities and exploits, removing it, unless it's needed, would probably be a good idea.  And I'm thinking, hmm, where have we heard that before?



So, of course, that's something that I have said a number of times, is that sometimes Java gets installed, you remove what it was that brought it in, and it stays behind.  The fact that it's in your system allows your browser to engage it.  And that's what the bad guys are using in order to now perpetrate browser-based exploits against your system based on Java, which very much like something else like RealMedia, for example, that you'd like to not need, or not have installed unless you're really using it, can be used.



LEO:  There are some people, a lot of people installing Java these days for something called Minecraft, which is a really popular game with tens of millions of players.  So there are some reasons to install Java.  But I'm surprised because wasn't that the promise of Java, that it would be sandboxed?



STEVE:  Well, yeah.  And if the code was perfect, then that's what you'd get.  And of course that's why, when Adobe announced sandboxing in Adobe Reader X, it was like, okay, good.  But it's like, that's not going to solve all the problems.  I mean, the problem is it's little mistakes that are made.  And one thing is really interesting about these particular exploits, and that is that in some cases the exploits are machine independent, meaning that traditionally, when we've had a buffer overflow, it's been Intel code, which the processor would execute in the buffer.  All of the things we're talking about traditionally have been extremely machine dependent.



But what Java brings you is a machine-independent interpreter that, I mean, that's one of the whole points of it, is it's an interpreter that is able to execute the same Java code in a platform-agnostic fashion.  Well, what's a little funny is that some of these exploits are machine-independent exploits, meaning that they could do their bad stuff even on non-Intel-based machines.  So it's like, yikes.  So, but yes, clearly, if you need Java, you need it.  But there's certainly a window, a subset of people who have it just sort of around, like oh, well, you know, maybe I'll need that some day.



And the fact is, if you've got it, you really need to keep it updated, as is the same case with all of our browsers and add-ons and so forth for browsers, because that's the new vector for exploitation these days.  So anyway, it's update 24.  Probably your Java installation will check for you.  You'll get a little square icon down in your tray telling you that it wants to update.  But if it's something you know you have, you might want to make sure that you've got Update 24 running.



And hot off the press this morning was news of a new BIND vulnerability, BIND being the preeminent DNS server.  Now, this is not a vulnerability like we've talked about before where web spoofing can occur.  But it is a problem for existing versions of BIND.  It affects versions 9.7.1 through 9.7.2-P3.  And there is an updated version 9.7.3.



What happens is, in any high-performance server, and a DNS server is a server just like a web server, for example, where requests are coming in on a continuing basis at various rates, but more or less like the servers being flooded with requests, which is the case with typical fast DNS servers.  You have a queue of requests which are in a buffer.  And that queue is filling and emptying, depending upon the instantaneous number of requests coming in.  Then serving that queue in a state-of-the-art execution model, you'll have what's known as worker threads.  You'll have multiple workers which are conceptually each coming back to the queue, getting the next item that needs to be served or serviced and then going about doing their job.  And they're all sort of peers.  They're peers of each other.



Well, one of the things that can happen, unless the design of the system is exactly right, is known as a deadlock.  A deadlock can occur when there are resources in the server which only one thing at a time, by virtue of the nature of the resource, only one thing at a time can access.  For example, say that you had something that just wanted to increment a variable.  If it reads the contents of memory into a register, and then increments the register and writes it back, it will increment that content in memory.



But imagine that in a really busy system you had multiple threads, multiple paths of execution; and two happened to be trying to increment that at the same time.  The first one reads the value from memory into a register.  And at that instant what's called a "context switch" occurs.  That is, that thread has used up its time.  And as we talked about before, the processors aren't constantly doing things or aren't actually doing multiple things at once.  They're just jumping around, switching between multiple tasks or multiple threads very quickly.  So conceptually we see them as all happening in parallel.  In fact, they're time sharing.  They're swapping between them.



So this first thread has read the contents of memory into a register and just run out of time.  At that instant it's suspended, and another thread is then allowed to run.  Well, say that it wants to increment that value.  It reads that value out of memory and increments it and writes it back and goes about its business.  Well, when the thread that was first doing it is reawakened, it continues.  It's got the value that it read already, except now that value is obsolete because another thread, while it was sleeping, came along and incremented it.  But it doesn't know that.  It's got the value that was current when it was suspended.  So it increments that and puts it back, essentially overwriting the value that the other thread wrote.



So what happens is, in modern operating systems, there's a way to handle that.  You're able to - a thread is able to declare that it needs exclusive access to something.  And while it has exclusive access to an object, it could be memory, it could be a structure, it could be anything, nothing else is able to acquire exclusive access.  So that two threads might both say I need exclusive access to this region of memory.  And only one of them would have that granted because they both can't have it at the same time.  Which suspends that other thread while it's waiting to get its exclusive access.  So the first thread does its work, returns the value, and then releases its exclusive access that allows somebody else that might have been waiting for it to run.



But you have to be very careful in the design of these systems because imagine that there were multiple things that a process or a thread needed to have all at once.  And imagine that one thread might get a couple of them and then need to wait while it gets a couple others; whereas a different thread might have gotten some of those other ones, and it's waiting till it gets a different set.  The point is it's possible for two threads to each have something that another threads needs, and neither of them to be able to move forward until they get them all.  And that's a classic deadlock in computer science.  And...



LEO:  Is it what they call a race condition?



STEVE:  A race condition is sort of what you would have if you didn't have this protection, where you still get, like, an inter-thread competition, but it's sort of in a different fashion.  So what has happened is that the guys at Neustar found a deadlock condition in BIND such that there's a process called an "incremental transfer," where one DNS server is able to ask another DNS server for a bunch of data about a zone that it's managing, a zone being the technical term for, like, a domain, essentially.



And it turns out that there is a short window of time where, if you asked for an incremental transfer, and made a query of the DNS server virtually simultaneously, you can get that BIND server, the entire DNS server to lock.  That is, it's exactly this problem.  It causes a deadlock.  There's just a tiny little mistake that they made somewhere in their code such that, if those two types of requests come in virtually, are being handled virtually at the same time, the entire server locks.  It just, if you have - it stops servicing any DNS requests.



And so it is a classic golden goose for the bad guys, I mean, because BIND is the server everyone is using.  This is the latest version.  The latest version, I mean, like, except for this very, very latest one, because this announcement just came out this morning.  So the previous release, that was current, can be locked up solid.  I mean, you've got to stop the server and restart the server in order to get DNS services going again.  And so it's regarded as a high-severity advisory for BIND.



And one thing, there is a fun little workaround.  If you can't upgrade immediately to 9.7.3, but you can restart your server, you can restart it with a "-n 1" option on the command line.  And that says run a single worker thread.  So it literally, the -n command tells the server how many worker threads to run.  And if you tell it only run one, then there can't be another one, there can't be two threads that are trying to access the same resource, so you can't have a resource contention problem, and it won't lock up.  But it's only if you have more than one thread that, in this version, in this prior to 9.7.3, you can get a condition where there's a deadlock, and two threads are both trying to get something while they own some resources the other one needs, and nobody can move forward.  So, interesting little bit of computer science that has sort of come back to bite the developers.



LEO:  Yeah, I love that.  Well, but, now, this is temporary.  You're not going to want to do "-n 1" forever.



STEVE:  No, and, see, that's the problem is this notion of a worker thread pool is state-of-the-art maximum performance because what can happen is a thread can be doing some work, or making a request of a back-end database, or there are many things that can happen that causes a thread to stall, like it needs to wait for something.  So you'd like to have, in a busy server, many other things that could be done.  While one thread is waiting for some piece of work to complete, other threads get control, and they're able to move their own little bits of work forward.



So literally it's like having a team of workers who each go back to a queue, get their next job, and then wander off and start pursuing it.  And someone might take a lunch break, well, other workers are still going.  So it's a nice asynchronous model which is very effective for getting maximum work out of a server.  So a busy DNS server probably relies on having a pool of active workers.  And if you just said, sorry, everybody's fired except Joe, then Joe might not be able to do nearly as much work as the whole group.



LEO:  I had no idea that my programs were having lunch breaks.  But that's good to know.  Get back to work.



STEVE:  So we did have some congressional testimony this last week from our friend Valerie Caproni at the FBI.  This is on this whole going - what they call their "going dark" problem, which is what the FBI has named their increasing concern that their practical ability to wiretap the Internet is slipping from them because more and more of what's on the 'Net is encrypted.  And of course we've been promoting it, for example, in the wake of the release of Firesheep.  We've been saying, wow, you really want to be using SSL and HTTPS communications so that the bad guys can't be sniffing your traffic in wireless hotspots.  And we celebrated when Facebook recently added that option to their configuration, finally allowing, as they had said they were going to, a user to say "Force HTTPS secure connections wherever possible," which is a great move forward.



Well, what's good for us and our privacy, of course, is bad for the FBI and our other security and intelligence agencies that really feel that they need the ability to be able to see into the traffic on the Internet in order to protect us.  So the problem is that the FBI is still being very circumspect and cagey.  I mean, I was impressed with the testimony.  I was impressed that the people who were in this panel seemed to have enough of a grip on what's going on to make this useful.



CNET - actually this was widely covered, The New York Times, The Wall Street Journal, CNET and others because people are wondering what's going to happen with this legislation.  Of course I have been wondering because I'd like to do a VPN technology which is explicitly for the sake of protecting us from bad guys.  And I'm uncomfortable with the idea that there might be some legislation coming downstream here that says, no, sorry, we need backdoors in anything that uses crypto.



And of course the problem is that the FBI has still not articulated what it is that they want.  They've mentioned Skype, which concerns me because Skype is point-to-point encryption.  As we know, right now, Leo, you and I have a direct connection between us, between my machine and your machine.  It was mediated by Skype.  Skype did the presence management to show us each other and allow us to find each other.  But our connection is point to point and powerfully encrypted.  Skype has a very good crypto technology.  And so there isn't any way for our dialogue to be eavesdropped on, whether it's text chatting, or audio...



LEO:  Not that anybody would really want to, since we broadcast it live.  But all right.



STEVE:  But of course the bad guys are saying, hey, now we know how we can talk to each other without worrying about being overheard.  So in CNET's article they said, "FBI general counsel Valerie Caproni will outline what the bureau is calling the 'Going Dark' problem, meaning that police can be thwarted when conducting court-authorized eavesdropping because Internet companies aren't required to build backdoors in advance, or because technology doesn't permit it.  Any solution, according to a copy of Caproni's prepared comments obtained by CNET, should include a way for police armed with wiretap orders to conduct surveillance of web-based email, social networking sites, and peer-to-peer communications technology."



So I've listened to the testimony.  I've listened to the news reports afterwards.  And it's still not clear what it is they want.  We really didn't get much from it.  The EFF weighed in.  They've got some documents that were just released that they got under the Freedom of Information Act, which is still sort of murky.  What I'm hoping is that - and from some of the things that have come out, it sort of sounds like this is reasonable - that the problem the FBI is addressing, for example, is that they'd like to be able to go to Facebook and Google, with whom they have held talks already, and be able to serve them with a court order, a wiretap surveillance order, and then be able to receive a stream of some sort from the service providers on the use of certain individuals of their services.



And so what Facebook and Google are saying at the moment is we don't have that built in to our system.  Yes, we could do it because we're the database.  We're one end of this connection.  And so, yeah, that information is here.  But we don't have the technology to, like, tap ourselves.  We haven't ever needed to, and frankly we haven't wanted to.  And so what it sounds like, again, sort of reading between the lines, there have been comments made that, like, well, we realize that when individuals encrypt their own communications for their own sake, that's something we can't get to.  But when services like Facebook and Google are doing so, well, we need that, and it's reasonable for us to have it.  So it sounds like what they're trying to get is some legislation which would require anyone who is like a receiver, I don't even know how they would describe it legislatively, but a public entity like...



LEO:  A carrier.



STEVE:  A carrier, well, but sort of an endpoint.  See, the problem is...



LEO:  No, that's true, yes, they're not just a carrier, are they.



STEVE:  Yeah.  So an ISP can't decrypt VPN traffic.  They just don't have the key.  And but someone at either end does.



LEO:  Right, the endpoint does, yeah.



STEVE:  The endpoint does.  And so there was a comment made that in some cases our law enforcement would simply have to find other means, meaning that they are recognizing there are some things they just can't get.  And from conversations with Google and Facebook and, I mean, just we understand the way the technology works, there are things they could get, except that there isn't the facility for it now.  And so it sounds like what the FBI would like to have is some legislation to force entities like Facebook and Google to be able to respond to a court-ordered wiretap when it's provided.  At the moment they can say, sorry, we'd like to help you, but our system doesn't do that.  And so there would be legislation that would force their systems to have that added to it.  And I think that's where we're going to end up.  Which is - I hope it doesn't get abused, I guess, is all I'm saying.



LEO:  I was reading an article, I guess we talked about this before I left, about these pen register warrants, which do not need to be disclosed, and they're not as strongly regulated because it's presumed, well, there's no content being revealed, it's just the fact of communication, the subject of the email, your GPS location.  And these are being heavily used.  I got some emails after talking about it on the radio show from law enforcement people, said, oh, yeah, we use those all the time.



In the U.S., phone companies are allowed to profit from these requests.  They charge the police a few bucks.  In fact, Sprint has a web portal for law enforcement.  You want to know where somebody is?  No problem, you don't need a warrant.  Just say you're law enforcement, give us the person's phone number, and we'll tell you right now.  In fact, we'll tell you forever where they are.  It just costs you a couple of bucks.  In Canada it's illegal to do that.  So they have to give it to you free.  They still do it, but they just can't charge for it.  So it really does feel like our privacy is being eroded very rapidly.



STEVE:  Well, speaking of which, we have a couple more little bits that I wanted to share with our listeners.  And you're exactly right.  The COICA is the acronym for Combating Online Infringements and Counterfeits Act.



LEO:  Oh, I hate this.



STEVE:  I know, and it's back.



LEO:  It's back.  Great.



STEVE:  Or it will be shortly.  It was introduced last year, but the Senate did not take it up.  And it's being reintroduced with somewhat better controls to limit what the DoJ can do with it.  And one significant restriction which is being added to the legislation which is trying to be reborn here would be that domain seizures could only be used when less restrictive methods have failed.  And so basically, this is what we've talked about a couple times, Leo, where...



LEO:  That preemptive thing.



STEVE:  Yes, well, and where basically the MPAA, the RIAA, the large, powerful, lobbying content owners are saying, we need ways of getting counterfeiting websites shut down.  We just want them gone.



LEO:  And we don't need that due process thing.  That's so old-fashioned.



STEVE:  Well, and due process, exactly, you're right, Leo, due process is the problem.  Senator Sheldon Whitehouse, who's a Democrat in Rhode Island, he was quoted saying, "I contend that America is on the losing end of the largest transfer of wealth through theft and piracy in the history of mankind.  We're doing virtually nothing about it."



LEO:  I love it how these guys are so hyperbolic.  Oh, my god, the record and movie and TV industry, how will they survive?



STEVE:  Yeah, yeah.  Since late November, the U.S. Department of Homeland Security's division, it's called ICE, the Immigration and Customs Enforcement, that's the group that does this, they've obtained court orders to shut down more than 100 websites for alleged copyright infringement, even without this new authority which the COICA would give them.  And then just Monday of this week they announced they had seized the domain names of 18 websites which were offering counterfeit jewelry, handbags, perfume, and other products.  And this is something, though, that seems to have some global sweep to it, also, because Spain also just passed a similar law.  They had tried to pass it also last year and failed.  It was voted down.  They then added a panel to oversee the shutdowns, basically an oversight committee, and with that addition Spain was able to get the law passed.



So on that note, another bit of news is that one of these ICE, Immigration and Customs Enforcement takedowns completely backfired.  They were attempting, this was also last week, they were attempting to seize 10 web domains suspected of storing, displaying, or peddling child pornography.  Unfortunately, in the process, they also seized a site called Mooo.com, which is the most popular domain at Afraid.org, which is run by the DNS provider FreeDNS.  There are 84,000 subdomain websites hung off of Mooo.com, and they were all taken down.



LEO:  And so presumably this is some sort of hosting company or web hosting.



STEVE:  Exactly.  Exactly.  It's a huge web hosting company.  More than 84,000 companies and individuals had websites hosted there.  And they were not only taken offline, but instead, visitors to any of those 84,000+ websites were taken to a page with a banner that said this domain - it shows the logos of the Department of Homeland Security and the Department of Justice.  The banner says, "This domain name has been seized by ICE - Homeland Security Investigations pursuant to a seizure warrant ... under the authority of Title 17 USC 2254.  Advertisement, distribution, transportation, receipt, and possession of child pornography constitute federal crimes...."



LEO:  Talk about killing a mosquito with a cannon.



STEVE:  So all of these sites were accused of trafficking in child pornography.  And it took 48 hours for this mistake to be corrected at the DNS level because essentially the registrar for Mooo.com was forced to change the root level registration to point to a server that presented this notice.  So all the subdomains that were hung off of Mooo.com received this notice.  And due to Internet DNS caching, it took a total of about three more days after that for this all to get itself sorted out.



And one blogger who had this happen to his site, who was obviously completely innocent of any of this - ICE is being overseen by a guy named John Morton.  And so he blogged:  "Mr. Morton, with all due respect," and then we'll blank out this expletive.  But it was a word...



LEO:  Eff you.



STEVE:  Uh-huh.



LEO:  In the words of Cee Lo.



STEVE:  Something off.  He said:  "Get out of my Internet.  You'd get no argument from me that there are truly distasteful and illegal things on the Internet.  That's true of any society.  But there are also proper ways to deal with these problems.  Pulling a total domain, sweeping up innocent people along the way, feeling that you don't have to comply with due process of law, and indicating that you don't give a damn is wrong.  It's not as wrong as child pornography or counterfeiting, but it's still wrong.  As a taxpayer, I feel you're wasting my money and denying my ability to use the Internet to host a server containing useful, legal, and hopefully interesting content over a readily known alias....  That's to say nothing of any damage done to my name or reputation by this idiotic law."  So, whoops.



LEO:  Well, yeah, no kidding, whoops.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  So apparently what happened was there was one of those 84,000 subdomains of Mooo.com was the actual bad guy target.  But again, here's the problem, is Internet technology is complicated.  And it's important for the people who are going to be given this kind of power to be technically competent, to understand that they want to remove a subdomain where the subdomains are all hosted off of a primary root domain.  So we understand this would have been, who knows what, fancypursesforyou.mooo.com.  That might have been a piracy site.  But that's a subdomain off of Mooo.com.  Unfortunately, the DoJ killed the root domain that 83,999 other good sites were pointed to, and aimed them at this disturbing page so that anyone going to any of those sites would have seen something accusing them of child pornography.  So, yeah.  Clearly this was a mistake.  I read some nonsense on the 'Net about this being deliberate.  It's like, well, there's no way this was deliberate.  That's crazy.  But it does say that those who are doing this...



LEO:  Don't know what the hell they're doing.



STEVE:  Yes.



LEO:  That's what it says.



STEVE:  They're going around stomping, at the registry level, stomping on root domains.  But in the case that, exactly like this, this is a hosting site where you've got a huge number of subdomains, each containing separate websites, you just can't go kill - it'd be like them killing off .com, you know, what would happen if they killed off .com?  Well, it's clear that we would all cease to exist.



LEO:  Not me.  Not me, I'm TWiT.tv.



STEVE:  You're .tv.  Leo would be the beacon.



LEO:  I'd be the last guy standing.  I have Leoville.com is the only .com I have.  Almost everything else is a dot something else.



STEVE:  I'd just be on the roof waving.



LEO:  Hey.  Hey, over here.  They cut off the Internet.



STEVE:  And then in the last little bit of sad news - I don't know if this is sad news.  I don't know how anchored you were to U.S. politics during your cruise, Leo.



LEO:  Actually, I missed - I was watching Egypt, but I missed what happened here.  What happened?



STEVE:  What happened here was that, early, early, at 4:30 a.m. this last Sunday morning, the House of Representatives passed their H.R. 1 bill, which is very controversial.  This is where they are taking $61 billion off of our current budget in order to get us to September.  And we have until March 4, which, unless this ends up getting through the Senate and not vetoed by our President, then the federal government shuts down I guess at the end of the day of business on Friday, March 4th.  One of the things that they stripped out...



LEO:  Snuck into it.



STEVE:  They stripped out a lot.  I mean, Planned Parenthood lost its funding, and the EPA lost its ability to enforce greenhouse gas emission controls and all kinds of things have been removed, regardless of how you feel about it politically.  One thing also that got removed was that the FCC lost their ability to spend any money on implementing their Net Neutrality rules which they had proposed last year.  Now, it's still not clear whether the FCC has the legal authority, and Verizon has challenged them, is challenging them in court, whether they have the legal authority to enforce Net Neutrality.  But in any event, they don't have the budget any longer, or they may not if this stays in what finally gets passed.



And there are lots of vulnerable programs that I think, even if there's some compromise that's reached, that backs off of the $61 billion that's being cut.  Things like this, I imagine, I won't miss it.  We need some, as we've talked often, we need some sort of legal precedent for how Internet carriers can regulate traffic and what the limits of them doing so are.  So we're just sort of stumbling forward, trying to figure out what we should do.



LEO:  You know, it's really, I mean, if you know how to manipulate the government and the legislative process, there's not much you can't do.  I mean, just tie it to a bill that will shut the country down if it's not signed into law, and what can anyone do?



STEVE:  Yeah.



LEO:  Amazing.



STEVE:  Yeah.  Now, you did miss a fantastic episode, unfortunately...



LEO:  Oh, shoot.



STEVE:  ...two weeks ago.  We discussed something called Bitcoin.



LEO:  Oh, I'm familiar with Bitcoin.



STEVE:  Oh, good.



LEO:  I actually run a little Bitcoin server.  Nobody ever gives me any Bitcoin, but at least I earn it myself with my little server.



STEVE:  We completely covered all of the technology of Bitcoin.



LEO:  Isn't it interesting?  I mean, I don't know if it's going to take off, but I think it's very interesting.



STEVE:  It's fantastic.  I'm a fan.  And we really had fun a week before last talking about it, and then last week was the Q&A that had about half of its questions follow-ups.  And what I wanted to tell our listeners was that - I made the comment last week that, when I'd had my little Bitcoin server running, that of course nothing had happened.  Well, I turned the screen on, and I found out I had won 50 Bitcoins.



LEO:  Right.  They do that to keep you going every once in a while.



STEVE:  Well, no.  Well, actually the chances are about that everybody doing it would, as a function of the amount of processing power in the network, it would take about a year.  And it was on Valentine's Day at 7:32 p.m. that my computer - in fact, Leo, it's that i7875.  And it's only because I built that little powerhouse in order for us to play...



LEO:  You've got a lot of threads there, baby.



STEVE:  ...that I got, exactly, I'm able to do 4,800 hashes per second.  And so just - it's just pure luck, basically.  But I was out there pitching my hashes out onto the peer-to-peer network, along with all the other Bitcoin servers on the peer-to-peer network that were trying to solve this puzzle, and I got one first.



LEO:  And we should point out that this is completely automated, that it's not somebody rewarding you for covering Bitcoin.  Nobody pushed a button at Bitcoin headquarters or anything.



STEVE:  Oh, and no one's...



LEO:  There is no Bitcoin headquarters.



STEVE:  Well, yeah, and it's anonymous, too.  There's no way that...



LEO:  Right, they wouldn't even know.



STEVE:  It's not like they thanked me for covering the podcast, I mean, on the podcast for covering the technology.  They have no idea it was me.  It was just pure blind luck that on Valentine's Day my machine happened to be first in solving this hash puzzle, and I got 50 Bitcoins.



LEO:  The real issue is what the hell can you do with them.



STEVE:  Well, yes.  It's just fun.  I mean...



LEO:  You can give them to me.  I'll take them.



STEVE:  There are now - the current trading rate is about one bitcoin per dollar.  So I can cash those in.



LEO:  There are people who are actually - there is a market.



STEVE:  Yes, yes.  You can buy services and goods.  The EFF accepts donations in bitcoins.



LEO:  In Bitcoin?  Oh, that's great.



STEVE:  In Bitcoin.



LEO:  Because I've been giving them American dollars.  I'd better start giving them Bitcoin instead.



STEVE:  Oh, Leo, that's so old-fashioned.



LEO:  Old-fashioned.



STEVE:  Dollars, no.  We want virtual money.  We want crypto currency.



LEO:  I just love the idea.  It's just a great idea.



STEVE:  It's pure anarchy.  And in fact, some of the questions that we talked about last week were people were worried about, well, can't you use this for money laundering?  It's like, absolutely.  And you can also use it for privacy, if you would like it.  It's double-edged, unfortunately.  All technologies are.



LEO:  How would you money launder with it?



STEVE:  Well, you could easily take currency in any denomination and convert it to bitcoins, send it to somebody else...



LEO:  Oh, that's why there's a market.



STEVE:  ...and have them convert it back out.



LEO:  I couldn't figure out why somebody would give you actual money for bitcoins, and now I understand why.  I set it up as an experiment.  And I thought about using it for - somebody wanted to donate bitcoins, so I set up the server and all that.  And maybe we'll take bitcoin donations.  I just - I don't know what you do with it.  It's just kind of interesting.



STEVE:  It's just sort of a trophy.  I got 50 from having my machine on the 'Net.  That's kind of cool.  And people have asked, would you be willing to sell your software, Steve, in return for bitcoins?  And I said, well, I'm not set up to do that, but next time I go in to my eCommerce system, I'll think about maybe...



LEO:  Maybe eat bitcoins, I might.  Pay the rent with bitcoins, I might.  I have to say I'm glad to hear, though, that you vetted it and went through the process that they're doing, and it's...



STEVE:  Oh, Leo, it's so cool.



LEO:  Yeah.  I'll have to listen to that episode.



STEVE:  Oh, they just nailed it.  I am so impressed with the way the system works, the fact that everything anyone's been able to come up with was incorporated into the solution.  I mean, it's one of those things where it really works.  And it's self-sustaining.  And it's taking off.  And the value of bitcoins has been going up.  And in fact we apparently created a small denial of service, that is, the podcast discussing Bitcoin.org took it off the 'Net for a while.  There was a notice up saying that, due to overuse of the server, it was like a redirection somewhere else.  So we may have just used up their bandwidth.



Also, last week or the week before, we had talked, I think, about how Symantec had purchased VeriSign's ID system, the VIP.  And I discussed, I think it was also last week, that the news that the forthcoming chipset from Intel, the Sandy Bridge chipset, would incorporate VIP technology in it, which is very cool.  So that the little football that we've talked about and the eInk credit card and all that, that used the six-digit code, Intel has built that technology into the hardware.  So basically your laptop or your desktop, whatever it is that uses one of the Sandy Bridge chipsets that contains this, will itself be an authentication token.  It has the crypto stuff in it.  And once you register that, in this case with VeriSign or Vasco or one of the providers, then you'll be able to use it for authentication, just like you do the football or the credit card.



The reason I bring this up again is that I was assuming that - I was, like, wondering, well, okay, we were also discussing Google's move to multifactor authentication.  And I was lamenting the fact that Google had not, among their many things they do support, like a cell phone can call you and read you a code that you then type in, or you can get it via text and so forth, Google has basically unveiled multifactor authentication for their stuff now.  I was wishing that they - I said, yes, but they don't support, darn it, VeriSign's VIP system.  And then I thought, well, maybe it's because it's not free.  Maybe people who use it, we end users don't, but maybe the sites that are using it for authentication do have to pay for it.  Like, for example, PayPal and eBay are paying Symantec something for the use.  And I did get email from someone at Symantec who kept himself anonymous but said, Steve, you were right.  It is a service which is paid for by the websites that use it for their authentication.



LEO:  Oh, interesting.



STEVE:  So, yeah.



LEO:  That explains that.



STEVE:  Explains it, and also makes the economic model make sense, too, because, as I had mentioned before, I now have the VeriSign Symantec VIP applet on my BlackBerry.  I know that it's available both for Android and for the iPhone, as well.  So it's no longer necessary for you to have a physical football, or even a credit card.  If you've got your phone with you...



LEO:  I know, I love that, I love that.



STEVE:  Yes, you can now authenticate in there.



LEO:  That's so much better, really.  Because everybody always has their phone.



STEVE:  Exactly.  It's the perfect solution.  And I do have a neat note from a listener of ours, Philip Garrett, who wrote, in my quest to always find new SpinRite stories, "SpinRite Saves a PS3."  Of course the PS3's been in the news a lot lately because of the backdoor stuff that's been happening, all of the hacking of the PS3.  He said, "Sir or Madam:  My PS3 Slim started acting flaky during a game add-on download on Sunday, February 20, 2011.  The interface was sluggish and would momentarily freeze up.  On Monday evening, when I arrived home from work, I attempted to turn the PS3 on, and it would only perform an incomplete boot before hanging up and freezing solid.



"I have two years' worth of game-saved files and other moderately important information on that hard drive, so it was important to me to repair it.  I had a hunch that the problem was with the PS3's hard drive.  I removed the hard drive from the unit and slaved it to my main machine.  I inserted my SpinRite disk and rebooted the machine.  SpinRite booted right up, and I was able to select the slaved drive and run SpinRite at Level 2.  After 30 minutes, SpinRite completed its work and showed one unrecoverable sector.  I crossed my fingers, hoping the drive had been repaired enough to properly boot.  I placed the drive back into the PS3.  The PS3 boots right up.  I was able to immediately perform a backup of the data onto an external drive."



LEO:  Good man.



STEVE:  "No longer having any faith in the original drive, I jumped into my truck and left for Fry's.  I was able to purchase and install a new drive.  After formatting and reinstalling the OS, I was able to restore my backed up data.  My PS3 is back to running like a dream.  Thank you for reminding us on Security Now! that SpinRite is not just for computer hard drives.  I can now say from experience that it works on a PS3 drive.  Thank you again for a great product.  Philip Garrett in Fishers, Indiana."  And thank you, Philip, for sharing that.



LEO:  That's great news.  All right.  Time to talk proxies, Steve Gibson.



STEVE:  So normally when we use our web browser, we put the URL we want of a site we want to visit into the address bar.  And as we know, the browser looks up the IP address of that website, that domain, and then attempts to initiate a TCP connection to that IP on, by default, port 80 if we're just using HTTPS, or port 443 if we're using - if we're just using HTTP, not HTTPS, or 443 if we are using HTTPS.  So the browser connects directly to there, to its remote IP, and that standard web surfing port 80.  And then, if it's able to get a connection, exchanges its request with the remote server and obtains whatever resource, web page or whatever, it's asking for.



Now, there are some cases where it's useful to add a layer of complexity to that.  A famous instance which most users are not aware of is when an ISP is proxying connections on behalf of their own customers.  In that case, the web browser thinks that it is connecting to a remote server, but in fact that connection is intercepted by the ISP's caching proxy, which looks at the request to see whether it might have what the browser is asking for in its own cache.



In the case of very popular sites like Amazon, for example, that are covered with menuing, images, and just all kinds of stuff all over the page, it's very likely that that same stuff is being delivered to all of the customers of the same ISP.  And so if this intercepting proxy saves those when it retrieves them for one customer, it can save having to retrieve them for someone else.  So that saves the ISP bandwidth going out to the Internet, and it arguably improves the customer's experience because they're going to get their own page loaded much faster because their browser is not actually having to go out onto the Internet to get, like, all of the extra stuff on a page.



So this notion of a local caching proxy, which is transparent, is one which users don't normally see.  There are other instances, though, where the proxy is either automatically configured or manually configured to serve a nontransparent, some specific purpose.  For example, you might have a corporation which wants to control the exterior or external use of the Internet by its employees.  So in such an organization, the organization's firewall would block outgoing connections to port 80 and port 443, so that all of the web services that exist outside of that corporate network are inaccessible.  Those servers are serving their content on port 80.  But if your web browser is unable to send Internet traffic out destined towards port 80, it can't get on those websites.  Another instance might be schools or universities or corporations that don't want to do a wholesale blanketing, but for example they want to keep their employees from spending all day on Facebook or logged into Twitter.  So there they're blocking specific websites at specific locations.



And of course the much larger instance is a country where there's a government like China that sort of officially intends to censor those websites that its citizens are able to access, in which case they've got industry-strength firewall technology running at their national borders which are preventing anyone from, when Google turns up search results for links they click, if those are on sites which are proscribed, they're not able to connect to those servers.



So a proxy provides a means for providing sort of a middleman, which is exactly what it is, in the connection between a user's browser and the server they're trying to access.  In the corporate access case, you might have to log onto the proxy server in order to gain access outwards.  So you have to authenticate yourself, essentially declare your interest in going to the outside world.  And that gives the corporation a means for controlling your access.  It might be monitored; it might be logged.  They still might be filtering where you can go, even when you log into the proxy server in order to get out.



But the concept of proxying, from a technology standpoint, is one where, if the proxy is configured in your browser, that is, your browser has been explicitly told that it will not be able to get directly out onto the Internet, it has to use a proxy, then no matter what address you put into the address bar, the browser connects somewhere else.  It doesn't look up the IP address of the domain you put in the address bar and attempt a connection.  Instead, those settings which are in its configuration dialogs, those take precedent.  And so, for example, there will be an IP address or maybe a domain name and even a port number that essentially completely overrides the connection level part of this dialogue.



So the browser always goes to a specific IP and port number.  That's what it connects to.  And if it is authenticated, if authentication is required, then what happens is it makes its query, just as it normally would, as if it had normally connected to the actual destination IP.  However, it's connected instead to this proxy server.  And the reason the name "proxy" is that this server then acts on behalf of the web browser outwards toward the Internet, that is, it proxies its request and makes it on behalf of the web browser.  So what this allows is, it allows control to be applied, both outgoing and incoming.



Another example, when I was poking around looking for some good examples, I ran across UCSD, UC San Diego.  They have instructions on their website for students of the university who are outside of their university network.  And they talk about being on AOL or being on Cox or being on some other carrier, but who want access to, for example, the university library system, which is on their internal network.  UCSD has many servers running inside its network which are not available to the general public out on the Internet externally.  So if their students are working, for example, off campus, on Cox, that's not within the university network, yet the students may need access to those resources.



So students can configure their browser, putting in webproxy.ucsd.edu as the domain where the proxy is; and then the web proxy port in the case of UCSD, and this is just arbitrary, is 3128.  So a web browser running outside of UCSD, when attempting to connect to resources inside UCSD, is able to essentially redirect all of its traffic to the IP of that domain name, webproxy.ucsd.edu, and not connect to port 80, connect instead to 3128, and then they have to authenticate.  They've got to be a student with UCSD login credentials.  When they try to make any connection there, sort of like when you use a hotspot that isn't completely open, where you've got to jump through some hoops first in order to log into it in order to get access, the same thing happens here where, instead of trying to get out, you're essentially trying to get in to an internal network that's protected that way.  So the idea is that, if you're authenticated, then the server that is answering and fielding those requests from the outside is able to turn around and send that request into the interior network.



Now, the problem with this sort of a static proxying is that your browser sends all traffic there, not just traffic bound for servers and services that are inside UCSD.  So there's another fancier way this can be done, and that's with a proxying script.  If you look in your web browser, whether it's IE or Firefox or any of the others, there are normally a number of options for configuring your browser proxy.  And in fact one of my favorite tips for people using IE, whenever I go to someone's house and they've got some problem and say, hey, can you take a look at my computer, if I fire up Internet Explorer, and it takes a long time, I go, "ough," and immediately go into their Internet options and turn off, under LAN settings, automatically detect settings.  This is a really annoying thing that Microsoft has always done with Internet Explorer that delays its startup every time you launch it.



LEO:  I go "ough," too.



STEVE:  Ough.  So the Security Now! get-on-the-'Net-faster tip of the week, if you're using Internet Explorer, is under Internet options, connections, LAN settings, you'll find that, unless you turn it off, it'll say "automatically detect settings."  Now, Firefox has the same default, but for whatever reason I've never felt the same delay.  When I went to look at my Firefox configuration, I found it, too, had it turned on, and I immediately turned it off.  Maybe Firefox is a little less slow in handling it, or maybe it does a better job or does these things in parallel.  Because what this automatic detection does, it's a sort of a kludge protocol which allows your browser, knowing nothing at all about a network, to determine whether it needs to use a proxy in order to get out on to the Internet.  So this was one of those things where Microsoft decided, okay, even though this is probably only useful for 0.2 percent of the users of Internet Explorer, we don't want to get phone calls or customer service problems from those 0.2.



LEO:  We don't want to turn it off because, yeah.



STEVE:  Right.  So we're turning it on for everyone, even though now 98.8 percent of the Internet users in the galaxy are all going to go, "ough."



LEO:  You're right, because actually that's what I do, too.  Because you know it's checking to see if there's a proxy.



STEVE:  Oh, and it's a slow process.



LEO:  It is.



STEVE:  The first thing it does is it does a DHCP broadcast.  We talked about DHCP, Dynamic Host Configuration Protocol, which is the way our computers find their IP address and subnet and so forth.  Our routers are DHCP servers.  So it's a neat technology for allowing systems to configure themselves.  And I have mentioned also that DHCP can supply many other kinds of information.  You could get time of day from it, if it was configured to offer it, and all kinds of other information.



Well, one of the kinds of information you can also get from DHCP, in addition to give me an IP address and my gateway IP and my subnet mask, is, is there a proxy here, a web proxy that I should use?  So you make a DHCP request of option type 252.  And if that is supported on your DHCP server, it'll respond.  Now, when the browser makes the request, it sends it off and waits for a reply.  And if it doesn't get one, it sends it again a couple times because it might have lost the first response or the reply.  If that doesn't work, then it falls back to something called SLP, which is Service Location Protocol, that almost no one has, but somewhere someone had it once.  So Microsoft says, well, maybe they still do, and so we wait for that, too.



LEO:  This is the curse of Microsoft is this backward legacy for anything anybody ever did.



STEVE:  Yes.  And then, even though almost no one has this, they say, well, let's check DNS.  So have you noticed, Leo, and I've always wondered why my Windows wants to know what, like, the computer's own domain name is.



LEO:  Right.



STEVE:  And it's like, my computer doesn't have a domain name.



LEO:  It may not just be DNS.  It might be there's WINS and there's other systems incorporation.  It's a business thing; right?



STEVE:  True.  So what happens is, if your computer has a domain name associated with it, and there are corporations where, for example, when you get online, your machine will have a name, and so it'll be your machine name dot Jimmy's Hotcakes Corporation dot com.



LEO:  They definitely use Windows.



STEVE:  I'm sure they do.  And so what happens is, if nothing else has responded yet, then IE puts the prefix "wpad" - which stands for Web Proxy Auto Discovery - it puts that in front of your machine name.  So it would be wpad.mymachine.jimmyshotcakes, or whatever I said, dot com.  And it does an address record lookup for that.  And of course, if it doesn't respond, it tries it a few more times until it's sure that it's not there.  Then it does an SRV record lookup and waits for that to give up.  Then it tries a TXT record lookup and waits for that to give up.  And if that doesn't work, then it shortens the path by removing your machine name and just tries wpad.jimmyshotcakes.com and does all of that again.  So this is why people are going "ough" all over the place, is waiting for IE to get going, this is what's happening.  So by all means, if you've ever noticed this, or even if not, and you're using Internet Explorer, which seems to me the slowest of doing this for some reason, Internet options, connections, LAN settings, automatically detect settings, turn it off.  I mean, unless you need that.  Some people probably do.



LEO:  Oh, if you're in a corporation you probably should not do this.



STEVE:  Well, and in a corporation it won't slow you down because...



LEO:  Right, because it's going to find something.



STEVE:  Exactly, your machine will make a broadcast, say hey, here I am, do I need a proxy?  Somebody somewhere will say, you sure do.



LEO:  Oh, yeah, here it is.



STEVE:  And here it is.  



LEO:  Yeah.  We used to, I remember ZDTV was set up that way, TechTV.  And that made sense in a corporate environment.  But at home it makes no sense at all.



STEVE:  No sense at all, and all of us have it on, and we're all going "ough" and waiting for IE to get going.  And a little less so for Firefox.  Mine's turned off now for the first time with Firefox.  And I can't wait to, like, restart it and see if it's faster.



LEO:  I wonder if Chrome is doing - I guess everybody has to do it; right?



STEVE:  If they don't want to risk compatibility.  I sort of thought Firefox might have it off by default.  But I guess maybe everybody has to have it on.  And so we're all losing some time in this because some people somewhere have to have it on.  All the rest of us, unless we've gone in and turned it off, are waiting for that to expire.



So as I was saying, for a user who, for example, needs to get to proxied services - for example we'll take the UCSD student example.  If they configure, manually configure their browser to use a web proxy, then everything it does, it sends there, which is a problem.  So what that would force the user to do is to be going in and turning this on and off all the time.  That is, if they want to go out and surf the 'Net, just go to Facebook and Twitter and Google and everything else, they have to turn off the proxying, which is a few dialogues down to get to, in order for their web browser just to make direct connections out to the sites they want to visit.  Then they've got to turn it back on again when they want to go back into the UCSD network.



Not surprisingly, there are some utilities which have been created, one called GProxy, which makes switching the proxying on and off much easier.  It gives you a nice user interface for doing this.  And there are a bunch of those.  But there's one slightly cleverer solution, and that is, if you look at this proxying dialogue in your web browser, you'll see there's the solicitation for a script that you can give it.  Now, the bad news is it's got the word "script" in it, and we know how I feel about scripting.  It actually is JavaScript.  And so in the case, again, of UCSD, there's a file there, webproxy.ucsd.edu/proxy.pl.  And I don't know why they use "pl."  Unfortunately, that's a common extension for Perl scripts, and this is not a Perl script.  It's JavaScript. But if anyone's curious, you can put webproxy.ucsd.edu/proxy.pl into your browser's address bar.  It will probably pop up and say, would you like to save the file?  You could save it and then look at it.



And what you'll see is a very sophisticated JavaScript program which analyzes - which your web browser can now pick up from, if you are a UCSD student, pick up from UCSD.  And it, with very fine-grain detail, tells it which URLs and servers and services and domains and all kinds of stuff, IP addresses, I mean, you have all the power of JavaScript essentially in this filter so that every URL your browser is given is passed through this function.  That JavaScript file defines a function called "Find proxy for URL," and has given the arguments of the URL and the host machine name.  And it returns essentially a proxy string that tells the browser how to connect.



And so the beauty of using that is that you can still go to Facebook and Twitter and  Google and anywhere you may want to because that script will say, nope, we don't handle those domains, go direct.  And so your web browser will make a direct IP connection there.  And if it is a domain inside UCSD, that script, when it's given that, will say, oh, yeah, here's the settings you want to use.  Make your connection to this machine at this port number.  And so it makes that process of sort of being in and out of a proxy very nice.  And potentially you could alter the script yourself, if there were different proxy servers you wanted to use for different remote sites.



So it's a powerful capability.  Unfortunately, it's also JavaScript.  And there have been, as one would imagine, exploits where the web proxy auto-configuring script has been hacked by people because think of the power it gives you.  Basically, if that were maliciously altered, then your browser is going to blindly follow that script and connect to whatever machine and IP and port this script has told it to, and that's completely transparent to the user.  You put in the URL.  You don't see where you've really gone.  Your browser connected off to Russia, unfortunately, instead of to Palo Alto and Google.  But because it got a malicious - it's called a PAC, a Proxy Auto-Configuration JavaScript file.  That has happened in the past.  So it's just something to be aware of.  But still very cool capability, which has always been in our browsers, which most of us are just sort of unaware of.



Now, the final type of proxying - oh, there's two more.  The other type of proxying that many security-conscious users have used in the past is a local proxy, where instead of this being a remote server that you connect to, you actually run a server in your computer.  Famously, Proxomitron has been used for years.  And more recently there's something called Privoxy, which used to be called the Internet Junkbuster, but they ended up folding up shop, and this thing went open source, and it's Privoxy.org is the home of the Privoxy proxy.  This is multiplatform, open source.  It's something you run in your computer which essentially sets up a server which provides local services.  You then configure your browser using the same proxy dialogue which you may have now found, if you've been listening to the podcast so far, because you wanted to not, "ough," wait for IE to start up so slowly every time.



So you configure your browser to use this server running in your own computer.  And the reason you do this, the power of it is that it makes a very powerful filter.  This is what Proxomitron had been used for for years.  Proxomitron is still around, and as far as I know is being supported, and is well used by people who've gotten into the nuts and bolts of taking responsibility for their own security and privacy.  One of the things, for example, that people like to do is not declare publicly what their user agent is.  The user agent is the header which a browser sends out to talk about what make and model and version.  And increasingly, it also has a long string of stuff, of, like, if you've got .NET installed in Windows, which is becoming more and more unavoidable these days, there's all kinds of version information.  When we talked about the service that the EFF runs for fingerprinting browsers, Panopticlick, one of the things that Panopticlick uses to lock onto users that make us look so unique is that user agent string because it's got all this version information.  It's getting longer and longer.  It's just a rich, harvestable source of info.



So imagine that you don't want your browser, your system to be sending out information.  Something like a local proxy can fix that because essentially it's in the connection between you and the - between your browser and the Internet, your browser being told to not connect directly out to, for example, Google.com, but to route all connections through the local host, as it's called.  You know 127.0.0.1 is always an IP for your own machine.  So the server, the proxy server running in your computer sets itself up on your own machine.  And your browser makes all of its connections there.  It receives this request with all the browser headings; and, for example, cookies, as well, are all available to it.



And local proxies like Proxomitron and Privoxy are able to go in and snip out things.  They can blank them out.  They can remove headers.  They can add headers.  Essentially they're very powerful, typically script-driven editors, sort of on-the-fly editors of anything going out and coming in.  Remember that you make your request to it.  It can edit the request and then send it out on your behalf.  When it receives the reply, it comes back to it rather than to you, it's able to do any kind of filtering that you might want done.  And this is why this Privoxy was originally called the Internet Junkbuster, was it would do all kinds of stripping of ads and other junk from incoming pages.



So now we have add-ons in our browsers that do that. But when you think about it, if we have different browsers, like many of us have IE and Firefox, some may be experimenting with Chrome, and some people use Opera, well, the features available on any given browser are going to be a function of its own capabilities and what plug-ins are available.  Not all of the same plug-ins are available for all of these different browsers.  This sort of centralizes that job in one location.  And in fact, you can also have these things running on one computer in a household network and have all the browsers in the household network told to use that one computer as their gateway to the web, as their proxy, in which case you can centralize the kind of filtering and configuration, basically web page editing that you do on the fly.  So that's another very powerful capability that proxies bring.



And, finally, there's a really interesting type of proxy which requires no configuration at all.  And this, for example, is what many people in China are using, and in other organizations, and even, for example, in schools that are blocking Facebook access and Twitter access and so forth.  All you have to do is go to a different website, where the website will proxy on your behalf.  And there are, by all measures, apparently tens, if not hundreds of thousands of proxies, open proxies that are available in the ways I've talked about, where you configure your web browser to access them directly.  But also increasingly popular because they require no configuration are so-called "anonymous web proxies."



So you go to one of these sites.  And what you see when you go there is just field, a form field, prompting you for a URL.  And so this is a website which you're visiting that is asking you where you really want to go, where you really want to visit.  You enter your URL there.  And that web server, acting as a proxy that requires no configuration on your part, it goes and pulls the page on your behalf.  It goes and gets the page and returns it to you.  What it does in the process is very clever, though.  They encode the domain that you have gone to in the returning page.



So what your browser URL shows is the domain that is doing the proxying for you, followed by a long tail of gobbledygook, just cryptographic-looking noise.  And any of the page assets, like scripts and CSS files and images, all of those things, those are modified by this proxy, which through your going through it has interposed itself, this proxy website modifies all the URLs, all the links on that page that comes back and all of the objects, so that your web browser then asks for those objects to finish populating the page, sort of as aliases of what they really are.  Your web browser asks for those of this intermediate website, which turns around, looks up what they are, or decrypts them, and then makes the request out on the Internet.  That asset comes back.  And you end up seeing a web page.  Also all the links, if you hover your mouse over the links, you'll see that none of them are links that used to be.  They're all obscured.  They're all encrypted.



What this means is that, simply by routing your traffic through this website, which is essentially rewriting your web pages, you have hidden your actual IP from the site you're actually visiting because all of the requests come from this intermediate site.  And your own records, your own cache has no privacy-busting records in it.  All it has are URLs of this intermediate server.  All the images it caches, anything it downloads, all the links it visits, any trail, any logs that are being kept are all obscured, and they only have URLs of the intermediate server.  And the way these servers have been designed, all of those links expire.  They're only good briefly.  So nobody coming along afterwards, looking at your browser cache, can look up those URLs and find out what they were for when you were pulling them.  They're dead now.  They go nowhere.



LEO:  Isn't that great.



STEVE:  So it's really cool.  And I got a big...



LEO:  Why do these guys do this?  Is it just, do they make money at it?  Do they charge for the service?



STEVE:  They're free.  Some of them offer, like, upsells for additional services.  I got a kick out of, when I Googled just the phrase "web proxy," the first link that came up was a site called HideMyAss.com.



LEO:  And it does a lot.  It does anonymous email, it does port proxies, web proxies.  It has a VPN.  This is kind of interesting.  The VPN is what they're selling.



STEVE:  Yes.  But you can go, if you go to HideMyAss.com/proxy, or just select that on the home page, it'll take you to a page that's very lean, that simply has a place for you to fill in a URL.  And if you put something in there, then hit Enter, it will take you to that site.  But notice it's edited the page.  There's a banner at the very top where you have some controls.  You can say I want to remove cookies, I want to filter scripting, I want to do different things.  So you can configure what it's bringing back to you.  And there are, like, directproxyserver.com, onionproxy.com, onlineproxyservers.com.  Leo, if you put in onlineproxyservers.com, and many of these are, that's a list of hundreds of these open anonymous proxy sites.  And so they bill themselves as a means for allowing people who, for whatever reason, want to - they don't want to leave records of where they visit.



Now, if you control your own computer, that's probably not a problem.  But maybe you're visiting someone.  Or you're in a library or something.  There might be an instance where you don't have the ability to, like, clean up after yourself or scrub your own trails if you need to.  These services are always available.  So you just route yourself through one of these places, and all of the logs, all of the content that comes back is obfuscated by these crypto tokens that have a short life.  And it's certainly the case that organizations could get wise to this.  For example, it's not like there's no way for your corporation to block HideMyAss.com.  They could block that.



LEO:  Of course they could.



STEVE:  In addition to LastPass, I mean, in addition to Facebook and Twitter and other things.  But I think that's why there are the numbers that there are.  I mean, there's hundreds of these things.  And you can go to directproxyserver or onionproxy or onlineproxyservers.com and just try them until you find some that your organization or your school district or whatever organization hasn't blocked, and that allows you to get out and get to Facebook and do whatever you want to.  And I'm sure that's the same approach that is being used for busting through national boundary firewalls.  There's just too much available for people who are trying to police this to track down every last one of these.  And they're coming and going very rapidly, so it's also a constant moving target.



It is worth remembering, though, that you need - there's some implicit trust you're placing in these anonymous proxying services because, while your computer isn't retaining a record of all of the URLs, the actual resolved locations that you've gone and you've clicked on, they're all being anonymized, essentially, that site that you go through, it knows your IP because you've connected into it.  And it knows everything you actually did because you went to, well, because it was forwarding your actual requests out, after decrypting the links that you were sending it.  It knows where you went.



Now, what I don't know, I haven't tried it, is if you can chain these.  I don't know why you wouldn't be able to, within one, go to another.  And if that works, then, let's see, the one you connect to would have your IP, but it would have obfuscated URLs from the outer one.  The outer one would know where you were really going, but it would not have your IP.  It would only have the IP of the first one you connected to.  So, yes.  If they allow you to chain - and I can imagine they might be able to detect each other.  But if they allow you to chain, then it would take comparing records from both of them in order to backtrack and basically do what a single organization would have at a single point of contact, if you did chain through them.



LEO:  That's what TOR does; right?  That's the idea of TOR.



STEVE:  But TOR does it with...



LEO:  More sophisticatedly.



STEVE:  Oh, yeah, industrial strength.  As we've talked, when we discussed and delved into the detailed operation of TOR.  But we've never talked about any of this before, and I thought that our listeners would find it interesting and maybe helpful and useful, if nothing else to avoid waiting for their browsers to start up.



LEO:  JimmyMac3 asks an interesting question in the chatroom.  How does this affect SSL pages?



STEVE:  Good question.  Now, some of the better sites, like HideMyAss, you'll notice that on HideMyAss.com, because it is also a commercial provider, so they've got a little more technology, you can click there that you want SSL, and it will create an SSL connection between you and it.  So that's a perfect example of one way to surf safely in an open WiFi.  There are, in these big lists of proxy servers, they often show whether the proxy server supports SSL.  And that means SSL between you and them.  And that's what you want when you're in an open WiFi hotspot.



So if you used a service that looked reputable, that you felt you could trust, like HideMyAss.com, which is the first thing that comes up if you Google "web proxy," then they do offer an SSL option.  What that does is it connects your connection to them to SSL, meaning that your traffic, then, as you surf through them out to the Internet to do Facebook or Google or whatever, or a service, as a better example, that does not offer the SSL protection that you want, then you're at least protected from your traffic out to them.  And then it would go non-SSL from them out to the final destination.



LEO:  Good to remember that.



STEVE:  Yeah.  So that would be nice, if you were in an open WiFi situation, if these are available there.



LEO:  Yeah.  Steve, great subject.  Very interesting.  Of course, this is why these are so effective, and that's why regimes like Egypt just turn off the Internet.  Because they know they can't really stop you in the long run.  China's the same situation.  And of course, as you said, it's a huge consequence when you turn off the Internet, and China's never going to be able to do that.



STEVE:  Well, and I think the logic must be, they're probably going to stop 95 percent of the people, people who don't listen to this podcast, people who aren't up on the technology, who just try to go somewhere with their computer and, oh, it doesn't work; oh, we can't get there.  Well, there are always ways around that.  And proxying is the oldest and longest-standing way, which is still standing today.



LEO:  Steve Gibson is the man at GRC.com.  That's the place to go for Steve's great program, the world's finest hard drive maintenance and recovery utility, SpinRite.



STEVE:  Yay.



LEO:  You can buy it there, and that's Steve's bread and butter, so we encourage you to do that as a form of support, if nothing else.



STEVE:  And it's good for you.



LEO:  It's good for you.  It's healthy.  He also has lots of free stuff there, including, of course, this podcast, in both 64K full quality audio and 16KB somewhat less full quality for those of you who are bandwidth impaired.  He has the show notes there, and transcriptions, too, which is of course the smallest way to participate in this show.  And you can read it, absolutely.  GRC.com.  Next week a Q&A.  So if you want to ask a question about this or anything else Steve talks about, or anything that's on your mind, go to GRC.com/feedback.  There's a form there you can fill out for a question.



STEVE:  Can we tell our listeners about the stream you've got of the TWiT studio being built?



LEO:  Yeah, sure.  You can watch it being built at Dropcam.com.



STEVE:  Slash demo, I think, isn't it?



LEO:  Slash demo, yeah.  I'm not sure why it's demo because it's no longer the demolition, it's actually the building.  But I guess we're stuck with the URL now.



STEVE:  Oh, I thought it was as in demonstration.



LEO:  Oh, demo Dropcam, you're right.  And we're one - okay, you're right.  And we're one of the ones on the left-hand side there, new TWiT studios.  And thank you, Dropcam, because they're providing the bandwidth for this.  We couldn't do it.  And you can see what people are doing at this very moment.



STEVE:  So this is the new TWiT studios.  It's a camera stuck up in a corner that is basically looking out over the construction of where you guys are going to be in a couple months.



LEO:  Yeah, yeah.  We're very excited about that.  In fact, tonight I'm going over there with our designer, Roger, for his final plans and the final approval.  So you're going to see a lot more action in that cam in the next few days as they start to actually construct the set.



STEVE:  Good, because I think it's lunchtime right now, Leo.  Not much going on.



LEO:  There's nothing much going on.  They're just kind of quietly wandering.  Hey, a program note about next week, and I haven't talked to you about this yet.



STEVE:  Oh, yeah, the Mac, the big March 2nd announcement.



LEO:  Thank you for paying attention, yeah.  It is now confirmed that March 2nd Apple has an announcement.  We don't know what it is, but we presume it's iPads.  It may even be new MacBooks.  So that will happen during, nominally, the time that we'd record this show.  So what I'd like to do with you, if you don't mind, is swap this show with MacBreak Weekly.



STEVE:  Perfect.  So we do me on Tuesday.



LEO:  Yeah.  We'll do you on Tuesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern at live.twit.tv.  And this Wednesday slot, which is normally your slot, 11:00 a.m. Pacific, 2:00 p.m. Eastern on Wednesdays, next Wednesday will be a special edition of MacBreak Weekly, as once again I try to incur the wrath of Apple.



STEVE:  Successfully, no doubt.



LEO:  Well, I haven't gotten an invitation ever since that January iPad announcement.  It's now the one-year anniversary of that.  So I have a feeling I'm persona non grata there.  But you know what, we have ways.  And we will cover it live.  We've got lots of great people here.  And so that's exciting.  So thank you.  I was going to ask you.  So that's okay with you.



STEVE:  Yup, absolutely, no problem, I'm glad we covered it.



LEO:  Okay, Steve.  We'll see you next Tuesday...



STEVE:  Thanks, Leo.



LEO:  ...on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#290

DATE:		March 3, 2011

TITLE:		Listener Feedback #112

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-290.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 290, recorded March 1, 2011:  Your questions, Steve's answers, #112.



It's time for Security Now!, the show that covers your security online; your privacy, too.  Here he is, the man of the moment, the man of the hour, Steve Gibson.  Actually the man of the hour and a half.



STEVE GIBSON:  I actually got email from someone who was rather irate because I think maybe we broke a record.  No, we couldn't have broken a record.  It was, I think, like 101 minutes last week.



LEO:  Oh, not even close to a record.



STEVE:  And he said, "Come on, Steve.  I only have so much time."  And he said, you know, "Cut out the fluff and condense the podcast."  It's like, okay, well, I heard you.  So I actually responded to his email.  And I said, "Okay, I just want to let you know you've been heard."  But we have fun with the podcast.  We don't rehearse this.  So it's not possible for us to exactly plan everything.  We do have some fun diverging from time to time.



LEO:  I'll give him his money back.



STEVE:  There you go.



LEO:  Actually, this is the least fluffy of all the shows.  So if he thinks this show is fluffy...



STEVE:  That's a very good point.



LEO:  ...I got bad news for you.  Most of the other stuff is longer and fluffier.  But, no, one point he does have is that the shows have been getting longer and longer.  And I don't know what to say about that.  We could make them shorter, I guess.  I don't know.  I don't know.  I'll tell you what.  If I heard from a huge number of people, I might.  But most of the time all I hear is, we don't mind, we like it long.  We want more.



STEVE:  And I think in our case, from the feedback I get, certainly people are loving the fact that they're getting a lot of factual stuff; that they, even people who've been around for a long time, are running across tidbits that they hadn't encountered before.  But also they do appreciate it from an entertainment value standpoint.  So they're listening to have some fun with us.



LEO:  I think that's the best way to approach this is just figure we're in the background.  You're listening.  You're learning as you've got some company in the room.  It's this, or you could be listening to Dr. Laura.  So you take - she's off the air.  But you take your pick.  It's just like radio.  It's just keeping you company.  And in this case you learn a little bit of something.  So those of you who are tuning in live, we will do MacBreak Weekly tomorrow, along with the iPad announcement.  And Steve's very kindly moved us over.  Normally we do this show on Wednesdays at 11:00 a.m. Pacific, 2:00 p.m. Eastern on live.twit.tv.  I'll tweet out to let Security Now! fans know that we're going to begin early.  This is a Q&A episode.



STEVE:  Yeah.  The big news from the week, which I finally had to tweet to everyone that I knew about this because all of our listeners were sending me tweets, saying hey, Steve, have you heard about the LastPass cross-site scripting vulnerability which was uncovered?  And so in order to, like, stem the tide of everyone making sure I knew, I sent out a tweet saying, yes, I know about it, and we're going to deal with it in detail in this week's podcast, which we will do here in a few minutes.



LEO:  Oh, okay.  So that's coming up in just a little bit.  That's good.  All right.  It's nice, yeah, to give them - because people want you to cover the latest, but of course we don't want to cover it until we have something to say about it.  But we will talk about it.  Okay, Steven.  Let's see here.  What do you want to start with?  The security news?



STEVE:  I'm going to tell Greg, my tech support guy, about that.  I let him do, like, computer PC fixing stuff sort of on the side.  And this would be fantastic, I would think, for him invoicing customers.  And I was thinking also for collecting payment.



LEO:  I used it for years until I had Lisa and a staff to do this for me, and it got more complicated.  But it's just great.  I love it.  FreshBooks is so cool.



STEVE:  So we do have Service Pack 1 for Windows 7 - and also I think that also covers Server 2008, if I recall - has been released.  And not without some problems.  There have been instances where some security software, third-party security software has caused SP1 problems.  And, I mean, there's been enough of a buzz that I found it interesting.  Brian Krebs, our illustrious security blogger and researcher, came to the conclusion, based on everything that he had seen, that if you've been keeping up with security patches all along, as I'm sure all of our listeners have, his feeling is, since all SP1 is, is everything that's happened so far, don't bother.  And, for example, maybe only use SP1 if you're doing a fresh install.  You'd certainly want to do that because you'd install the original Windows 7, then immediately SP1, which probably saves about three hours' worth of ridiculous, endless, individual security patch updates, and then updates to those updates, and updates to those updates and so on.



My feeling is, based on our experience, Microsoft won't let us not install SP1 in the long term.  Ultimately they seem to get a little antsy about service packs that haven't been installed and start bugging us more and more.  Even if you told them, don't bother me about this anymore, it sort of comes back.  And then it's like, okay, why am I being bothered about this?  Well, you really need to install the service pack.  So I would say there's no hurry about installing it.  You get no substantial new features.  Nothing about it is necessary, especially, well, given the fact that you've been keeping yourself up to date.



LEO:  That's exactly what Paul Thurrott said, too.  We covered it a little bit last week.  He's in agreement.  But if you haven't been keeping it up to date, here's a chance to get them all at once.



STEVE:  Oh, yes, and save yourself a substantial amount of time.



LEO:  A lot of IT guys do this.  If you go to Windows Update, and you look at the catalog, you could download this service pack as a standalone file.  So if you've got a bunch of machines that you haven't been updating, or you're an IT guy, and you want to update the whole office, that's the way to do it.  You put it on a CD and then go around and update all the machines.  You can get the full update.



STEVE:  Yeah, it's big.  I think it's, like, half a gig, 500-something megs, as I recall, for the full monty.



LEO:  It is better to use Windows Update, Paul said, because Windows Update will check for dependencies.  So that if that machine needs something before Windows 7 SP1 is installed, it'll get that first so you don't have some oddball situation going on.  So that's the best way to do it.



STEVE:  Yeah, I will be installing another instance of Win7 in a machine shortly.  And so I was really delighted.  In fact, what I got, because I am a MSDN member, I just got Windows 7 with SP1 already prebundled.  So saves a lot of time.



LEO:  You bet.



STEVE:  In the news, something just sort of joggled my security filter.  In Cheshire, in the U.K., keystroke loggers were found on library computers.  They don't know how long they've been there.  They don't know who installed them.  They don't know who's been back to dump them.  But these were hardware blobs that we've talked about years ago, inline in the keyboard.  And so what they've done as a policy is they've changed their physical structure so that the keyboards are plugged into the front of the machines, so they must be USB keyboards.  They're probably plugged into a front USB port rather than in the back, just so that it's more obvious if there's a blob that's been plugged in between the keyboard and the computer.



But the point of my raising this is I just wanted to sort of remind, just as a little general sort of signpost reminder, that, as a general rule, you cannot find less security anywhere than in a publicly accessible PC.  A library computer - and we have talked about this before, but I just wanted to reiterate because I think it's so important.  A computer that you don't have pretty much constant oversight over, you just have no way of knowing what its short- and long-term history has been.  And there's no safe way to use it.  Even - and this is a perfect example - even if you were using SSL, you had HTTPS Everywhere, you turned Facebook's HTTPS enforcement on - although we're going to talk about why that doesn't really work, either.  I mean, even with all that, if you were to log on or purchase something and enter your name and your address and your credit card information, and there was a physical keystroke logger between your keyboard and your computer, it would capture all of the things you're typing in.  And anyone looking at a log could easily parse out your name, your address, your billing address for the credit card, and the credit card number.  Or your login credentials.  And somewhere you're typically typing in a URL, and so they could see you doing that, so they would know what site those credentials applied to.



So just by looking at the log of keystrokes, you pretty much, I mean, that's very powerful, which of course is why some bad people took the trouble to put keystroke loggers on those library computers.  So I just wanted to sort of, as just a little signpost reminder, if you have some use for a library or a kiosk or some public access PC, just have your guard up past the red level.  There's just really nothing safe you could do except completely passive browsing, where you're just putting things into Google and clicking on links and being passive and not getting sucked into providing any information on an inward direction.



LEO:  One thing I like, though, more and more on browsers you'll see, or I guess websites do it, too, "Don't check this if you're on a public machine."  They are at least kind of warning you, don't save that password, things like that.



STEVE:  Yes, and that's really, really good to see, that we're beginning to get this kind of pervasive understanding of what the dangers are.  Basically it's once upon a time, a company would have been reluctant to do that because they would have felt they were discouraging people from something that they wanted to do.



LEO:  Or scaring them.



STEVE:  Precisely.  Now it's like, oh, they're being responsible to remind us that this is a danger because everyone really understands that's the case.  Speaking of which, there was an interesting blurb from our old friend Robert Graham.  Robert Graham was one of the founders of Network ICE, that did the BlackICE firewall that was very popular years ago.  And he poked his head up in public, commenting about the new Intel Thunderbolt 10Gbps I/O bus, which the latest Apple laptop computers are famously going to be having installed in them for the first time.  And what Robert mentioned, I just wanted to note here, because that's what we do; and that is, in exactly the same fashion as the FireWire bus is a security concern, so is Thunderbolt.  Essentially, Thunderbolt is the PCIe bus, which is now the bus that links all of our components together in our PCs.  It is that bus serialized.



LEO:  I didn't know that.  That's interesting.



STEVE:  Yeah.  And what that means is that a device that is on Thunderbolt has DMA, Direct Memory Access, to your machine's RAM.  So we did talk about this years ago with FireWire.  There were some exploits.  In fact, HBGary, the company, the government contracting security firm that's been in the news a lot lately, they provided the government with a device, a FireWire-based device, which you could just plug into any FireWire-based machine, and it would instantly clone the current state of its memory that allowed people who had this device, for example, to steal cryptographic keys that were in use at the time, directly out of the machine's memory.  We've talked about, for example, in the past, lowering the temperature of RAM immediately after turning a machine off, like spraying it with Freon in order to...



LEO:  To hold it, yes.



STEVE:  In order to hold it, yeah.  And it's surprisingly effective.  And we talked also about how, due to the fact, the way cryptographic algorithms work, you take the key, and you do something called a "key expansion" where, for example, in the case of AES, which we covered on an entire podcast before, you take a 128-bit or 256-bit AES key, you run it through a key expansion, which takes that relatively modest number of bits and algorithmically expands it into a block of information.  It does that because the symmetric cipher is iterative, and it has to do what it does, for example, either 11 cycles in the case of a 128-bit AES key or 14 cycles in the case of a 256-bit AES key.  So in order to feed the cryptographic algorithm 14 times, you need much more data than just 256 bits, which is the source key.  So you sort of - you expand it, and that's called building a key schedule.



Well, the problem with that is that, in doing that, in scheduling the key out to full size, which is what has to be done in RAM in order to use the cipher in real time, if anything is using the cipher, like if you've got TrueCrypt running or anything else, then there's this block of memory which has to be there accessible to the computer in order to perform the encryption and decryption on the fly back and forth.  Well, the act of creating that dramatically increases the redundancy - reduces the entropy, increases the redundancy of information.



So what the researchers found was, if they Freon-sprayed RAM, even if there was some deterioration of the data, because they knew where the data came from, they could find it in memory.  They could sort of lock onto it, and they could figure out what the original key was, even from a corroded expansion of that key.  So I guess the point is that giving anyone access to the running contents of your computer's RAM is really a bad thing to do.



LEO:  It's all in there.



STEVE:  It's everything.  It's your logons. 



LEO:  Decrypted keys, things like that?



STEVE:  Decrypted keys, everything.  It's the running state of your machine.  It's the mother lode for a bad guy.  And FireWire, due to its nature, allows that.  Well, so does Thunderbolt.  And so on his blog, Robert Graham painted a picture of some presenter is in a conference and goes up to the podium of the future and plugs his MacBook into a Thunderbolt port...



LEO:  For the video.



STEVE:  For the video.



LEO:  But somebody's tapped into that.



STEVE:  Exactly.  Well, and because you have read/write access, a sufficiently clever hack would be to download some code that dumps the hard drive.  And at 10Gb, it's not going to take that long to suck the hard drive out through the port.



LEO:  Wow.



STEVE:  So anyway, I just - I wanted to put this on people's radar.  Now, it's important not to get too concerned about it because not only does Thunderbolt do this, but pretty much all the Apple ports do.  FireWire does.  ExpressCard does.  And even the SDIO slot allows this.  So these are all connections into the system's memory.  Now, in the case of Thunderbolt, there is chipset support for imposing limits on the range of memory that is accessible over the bus.  But as far as we know, the Mac OS isn't yet exercising those features of the chipset.



LEO:  They do have - Lion is in development right now.  It's close to coming out.



STEVE:  And I was just going to say, since Apple's giving so much security focus on this next iteration of the Mac OS, maybe, especially after listening to this, they'll do something about it.



LEO:  Yes.  That would be a good thing to put in Lion.  So you could constrain the amount of memory that Thunderbolt could see.  Is that how it works? 



STEVE:  Yeah.  You would constrain the range.  Like you set an upper and a lower limit to where, for example, to the display buffer, so that you're only able to access the display memory which you're wanting to export to a remote monitor and not export the entire contents, 4GB address space of the machine, which it's no one else's business.



Speaking of Facebook, someone tweeted me, and I remembered that I had seen this now a number of times, and so I pursued it because I wanted to get the whole story.  And I have verified.  We were excited that Facebook offered recently the ability to force HTTPS full SSL connection security as a user-configurable option for individual users' accounts.  The bad news is that it was known that some Facebook apps themselves may not support HTTPS.  You may be trying to connect to a server that just doesn't have an SSL certificate.



LEO:  The apps are served by the creator, not by Facebook.  And I would bet you a lot of app creators haven't bothered with an SSL certificate.



STEVE:  Correct.  And so what happens is, if you try to, from in Facebook, go to a Facebook app that doesn't support HTTPS, you get a dialogue box that comes up.  And the title on the dialogue box says "Switch to regular connection (HTTP)?"  And then in the text in the dialogue, it says, "Sorry, we can't display this content while you're viewing Facebook over a secure connection."



LEO:  So at least you'll know.



STEVE:  Oh, yeah.  "To use this app," it says, "you'll need to switch to a regular connection."  Now, here's the bad news.  If you do that, it turns off the option in your configuration permanently.



LEO:  Oh.  Not just for that session, but forever.



STEVE:  Yes.  It just puts you back to the Stone Age.  Back the way we were last year.  So that's unfortunate.



LEO:  But people, if you really are concerned about security on Facebook, you shouldn't be using those third-party apps anyway.  I know it's tempting and fun.  But those things leak your information like a sieve.



STEVE:  That's a very, very good point, Leo.



LEO:  Stay away from them.



STEVE:  And I would say, given that Facebook now supports this, something like Force HTTP or HTTPS Everywhere, using those add-ons for Firefox, which will keep Facebook back in a secure mode, even if it's not enforcing it itself, you can enforce it at your client end.  That's certainly the way you'd want to go.  But I wanted to make sure that people knew, since we were celebrating the addition of this feature to Facebook, that they hadn't quite done it the way we wished they had.



LEO:  I don't think they have any choice because they'd have to compel all the app developers to go SSL.



STEVE:  I don't understand, though, why they don't allow an exception for, like, non-Facebook domains, when necessary...



LEO:  Right, but keep it on.



STEVE:  ...but keep the settings set for themselves.  To me it sounds like it was a quick hack; that like they, oh, shoot, we need to turn off HTTPS for our app, so we'll turn them off for everybody.



LEO:  It's also that convenience versus security thing.  They don't want to bother grandma.



STEVE:  Ah, good point.  Because what this would prevent is it would prevent you from being prompted with that dialogue every single time you use a noncompatible app.



LEO:  Grandma's saying, I don't care, so they turn it off.  That wouldn't be, yeah, I can see why they did it that way, but still.



STEVE:  So you mentioned earlier the Gmail email lossage.  It's not really a security concern, but it just sort of came on my radar.  Google is estimating about 150,000 of their Gmail users, which they're saying is 0.02 percent of Gmail users lost all their email.  Just gone.  Whoops.  Don't you hate when that happens?



LEO:  Bye bye.



STEVE:  They're saying that it was a storage software update which was buggy, which they pushed out across their network.  And people had said, wait a minute, I thought you were replicating our email in multiple sites all over the place, specifically so that an outage couldn't happen.  And they said, well, yes, that's if there's no bugs.  But if there's bugs, then the bug replicated the deletion of all of the email in all those accounts.  And from their blog - well, the good news was nothing was permanently lost.  It was taking them a lot of time to recover, though, because - get this.  They were restoring from tape.  So...



LEO:  Well, hey, at least they had the tape.



STEVE:  Exactly.  I was going to say, the good news is they had that, and so they were able to get - they will eventually have restored everybody's lost and deleted email.  And their blog I thought gave us a sense for the size of the window.  They said, "It's important to note that emails sent to you between 6:00 PM PST on February 27 and 2:00 PM PST on February 28 was likely not delivered to your mailbox, and the senders would have received a notification that their messages weren't delivered."  So 6:00 PM on the 27th to 2:00 PM on the 28th is 20 hours.  So there was a big window during which things were not happy for those 150,000 Gmail users.  Again, not a security problem, but just something that is in the process of getting put back together.  I don't know if any of our listeners might have been affected.  I wanted to let them know what had happened and that, if they weren't yet mended fully, they probably would be once the tape was finished spinning.



LEO:  I don't see anybody in our chatroom who says it happened to them.  I don't think it happened to me.  I guess you would only know - it would be hard to know.  I guess if you got a lot of email, and you went 20 hours without email, I guess you'd know.



STEVE:  Yeah, and you might know later if...



LEO:  Right, some appears.



STEVE:  Yes, if some tireless SMTP server is retrying a few times and finally gets the mail to be accepted.  Okay.  So, LastPass.  The good news is I don't regret my recommendation or the analysis that I provided our listeners months ago, nor all of the feedback I have received from people whose lives have been dramatically improved thanks to LastPass.  What was discovered by a very clever security researcher, Mike Caldwell, who's in the U.K., was that there was a way that a user's logon session could be hijacked by a malicious site.  So what the user would experience would be what we always talk about here, is you go to a site which is malicious.  And if you are currently logged into LastPass, as most of us are statically so we have access to all of our other sites' usernames and passwords, if you were logged in, it was possible for a malicious site to execute script, JavaScript, in the context of the LastPass domain.



So this is what's called cross-site scripting, and it's the way that malicious sites are able to get around all of the preventions, all of the barriers deliberately erected in order to keep domains from leaking information to other domains.  So what was posted was that it was possible to determine that LastPass user's email address, their password reminder, and their site usage history.  Which is a big information disclosure problem.  The LastPass folks fixed it within three hours.  Mike responsibly disclosed it, let them know.  This was fixed in three hours.



It was a very clever hack.  I take my hat off to him because many of the things he tried, and he's got a lot of experience doing this, didn't work because LastPass had thought through all of these possible vulnerabilities.  Yet he came up with a way, and this is the problem with web-based stuff in general, he came up with a way that he could close a script that was going to be broken with a closed-script tag, and then reopen a new script, and then inject some script himself.



Now, here's the good news behind all this.  At no point was any of the encrypted data, which is what we have LastPass for, vulnerable.  And it wasn't because of the architecture of LastPass, which is why I endorsed it.  So in his blog posting he went a little too far, and he said that he was certain it would be possible to obtain encrypted and protected site logon username and password data.  But it's not.  He was wrong on that count.  I've responded over on his blog, after analyzing it and talking to the LastPass guys to make sure I had my facts straight.  And here's why.



What's so cool about LastPass is that they don't ever get our cryptographic key.  That's why I felt so comfortable using it.  What Mike found and was able to demonstrate was the fact that, by using cross-site scripting vulnerability to impersonate essentially us, he was able to get the LastPass site to reveal some information, the nonencrypted information that it had about us because LastPass back then, it's been fixed since then, but they didn't realize, there was no way for them to determine it wasn't us making the query, so they were willing to provide to us what they had.  But they can't possible provide what they don't have.  And what they never have is our cryptographic key.  It never leaves us.



When we log into LastPass, our master password, as our users will remember from the podcast we did covering this, script running in our browser takes our username and our password and cryptographically turns that into the symmetric cipher key which we then use, that is, our browser uses to encrypt our login data.  And so all that LastPass is doing is saving opaque blobs which they are unable to decrypt.  So even with cross-site scripting, another session is being created that has no access to the cipher key that is in our browser, running either in the plug-in or in the regular web UI.  So thanks to this architecture that LastPass established, at no point was anything more than the information that Mike showed available.  And Mike is a LastPass user then and still.  This hasn't put him off of it.  He's still using it now.



LEO:  Me, too.



STEVE:  As am I.



LEO:  Me, too, yeah.  So don't be afraid.  Should we consider not putting everything, all our eggs in one basket, as you said?



STEVE:  Well, the advantage of LastPass...



LEO:  That's the whole point.



STEVE:  ...is that it's one big secure happy basket.  I mean, the guys were very embarrassed.  They immediately fixed the problem.  Mike also suggested that they enforce strict transport security, which we've talked about, STS, with browsers which understand it, like Firefox does, which they immediately implemented.  And basically I think it was a good wakeup call because they have been spending their time broadening their reach and making LastPass more pervasive on more devices.  And this sort of refocused them on the web side of things, rather than the third-party device side.  And as a consequence, in about six hours, Joe has reimplemented, or rather implemented a very strong technology to much better control this sort of just prophylactically, to preemptively keep other things like this from happening.



And I'll also mention that anyone using NoScript would have always been prevented from this because NoScript has built-in cross-site scripting blockage, and it was effective.  Mike, in some follow-up comments in his blog, commented that users of NoScript, naturally we're trusting LastPass.  We would not be trusting some other random site.  But even if we were, NoScript itself would have blocked this particular exploit against us.  So one more reason to use NoScript, as if anyone needed another reason to use it.



LEO:  Well, that's a little scary, but I guess a happy ending makes it all okay.



STEVE:  Well, yes, we would like there never to be a problem.  The good news is the architecture that the guys implemented prevented this exploit from going any further.  What we really need to have protected was protected because they didn't have it to disclose.  And they don't want it to disclose, as I talked about when we talked about it originally.  The reason I liked it was that our stuff never left our local control in a nonencrypted form.  And the convenience of LastPass is that it is integrated into our browser so that it's able to participate.  Well, I mean, it's a difficult thing to do that securely.  I mean, it's really difficult because, as we know, browsers are the main focus of today's malware.  That's where all this is happening.



LEO:  If you didn't use the LastPass plug-in, would this have affected you?



STEVE:  Yes.  The only thing that would have prevented this is if you were completely logged out, meaning not logged into LastPass at all, such that it would have had to ask you for your credentials, your username and password, in order to log into it.  So because it was a session hijack, this cross-site scripting vulnerability was essentially hijacking our logged-in status.  The fact that our browser was logged into LastPass is what it was taking advantage of.



LEO:  And for those of you who are interested, Steve did a thorough analysis of LastPass on Episode 256, 2^8 if it's easier for you to remember.  And so you can go back and listen to that, and then add this to the mix because this is a new flaw.



STEVE:  Well, fixed immediately.  I mean...



LEO:  Yeah, that's what I like.



STEVE:  Mike let them know about it.  It was instantly fixed.  None of this Microsoft wait for next Tuesday or a month and a half or so forth.  I mean, this thing was addressed instantly.  And I think it ends up further increasing the security because these guys realize they have a huge stake in maintaining everyone's confidence in their service.  And I continue to feel, as even does Mike, who's still using it himself, that they got this right.



LEO:  Bravo, LastPass.



STEVE:  I did pick up a little note from a listener who wondered if I was ever going to review the Kindle 3.  And I don't want to take much time on that, but I'll just say that I love it for what it is.  But recently I've been reading some textbooks, more O'Reilly stuff, programming stuff, and I switched to the DX because code was wrapping in the little screen of the Kindle 3.  And then, sort of out of curiosity, I tried reading it over on my iPad.  And the iPad just blows it away.  The ease of use, the higher contrast that you're always going to get from an active backlit screen, means that things are just sharper.  And the various fonts show up better.



I love the Kindle 3 for fiction book reading, for textual book reading, for stuff that isn't graphics, that isn't diagrams, really for paperback sort of books.  Nothing beats it because it's great for that.  You can hold it in one hand.  The iPad really is too heavy to hold in one hand.  You really need to prop it somehow.  But if you're sitting down somewhere, and you have a lap, you can sort of prop it up in your lap and just flick the screen forward with your finger.  So I'm excited about tomorrow's iPad 2 announcement.  And really...



LEO:  Well, that's why the speculation is it'll be lighter and thinner, exactly for that reason.



STEVE:  Yes, and I'm really excited about iPad 3, which is supposed to give us that same quad resolution retina display in a pad form factor that we now have in the new iPhone 4.



LEO:  iPad 3, that's not till next year; right?  I mean...



STEVE:  Maybe later this year.  The news was that they're kind of - the problem is they can't get production levels up.  But it means they're trying to produce them.



LEO:  That sure would be great.  I mean, that's a beautiful screen.



STEVE:  That's all I want.  If I could get that retina screen on a pad-size device, wow.  We heard from a listener, a Security Now! listener, Anthony Pitcher, who wrote:  SpinRite Saves My Raid Zero.  He said, "Hi, Steve.  Long-time listener of Security Now!.  Enjoy the podcast immensely and appreciate the work yourself and Leo do for the community to inform us all about being more secure.  I purchased SpinRite two years ago to support the podcast."  Wow, thank you, Anthony.  "I never needed to use SpinRite to fix a drive until today.  On my Windows 7 x64 Raid Zero installation, Windows began to have some weird behavior, random freezes and the like.  I also noted that the Intel matrix storage manager began saying a drive was being disconnected from port 1 and reconnected, disconnected and reconnected.  However, Windows was still limping along.  Thanks to Leo and his continuous mention of backing up, I have a local and offsite backup at my office."



LEO:  Good man.



STEVE:  "So I wasn't concerned if Windows just fell over.  However, I was more interested to know if there was something wrong.  I ran SpinRite on Level 2, booted from a USB floppy drive."  A USB floppy drive, that's what it says.



LEO:  A USB floppy drive.  Well, yeah, that's probably the only kind there is these days.



STEVE:  Yeah, "...booted from a USB floppy drive, and it began chugging along.  I have two 500GB Seagate drives, so the scan took one hour and 30 minutes on the first drive, which reported no problems.  The second drive was about 80 percent done, and I was thinking by this time SpinRite would probably find no problems there, either.  Then the DynaStat monitor kicked in.  It ran for about two hours, and then completed the rest of the drive without hesitation.  Windows booted normally and no longer had the lagged experience I was having before.  And of course the Intel Matrix Storage Manager software no longer complained about a drive being disconnected and reconnected.



"Thank you, Steve, for such a superior product with so many boot options available.  Your software saved me from having to reinstall Windows and set all the settings I've gotten used to again from scratch.  I know this story isn't saving lives or someone's job, just a fellow fan who really enjoys your programs and hopes to be one of the first customers of CryptoLink.  Take care.  Anthony Pitcher."  Thank you, Anthony.



LEO:  What is the status with CryptoLink?  I don't mean to beat you up on this.



STEVE:  Put me on the spot?



LEO:  Yeah.  Just an update.



STEVE:  I'm very nervous still about...



LEO:  Oh, because of COICA or whatever it's called.



STEVE:  Yeah, about what the FBI is going to try to do.  As I mentioned last week, it seems like what they're going to ask for is - and they seem to be backing down a little bit from some of their earlier statements, which I think is good - they seem to be wanting sites and services that could comply with a wiretap order to be forced to.  So, for example, Google and Facebook, they're endpoint services that have decrypted information because they're at the other end of their customers' SSL connections.  So when the federal government goes to Facebook and says, we need all of the communications of this person, Facebook says, well, our technology isn't set up to do that.  It's not that they couldn't.  It's that they haven't had a reason to before, so they don't have the code in there to do that.



LEO:  And I bet you they intentionally don't add that.  I mean, they don't want that responsibility.



STEVE:  Right.  And so what the government would like would be legislation which makes it mandatory for something like Facebook or Google to implement the technology that would allow them to respond to a wiretap order like that.  That's what I'm thinking.  Now, the problem is, in the past they've mentioned Skype by name.  Skype is non-U.S. based, probably makes the U.S. government a little nervous.  And as we know, it's point-to-point crypto, just like a VPN, just like CryptoLink would be.  So what's unclear is what they're going to ask for along those lines.



I'm going to keep myself busy.  I actually have a project I haven't talked about yet.  I've got a couple of things I have to wrap up first, some very cool technology that's been running on the server for years, we've talked about it before, third-party cookie stuff, that I need to make - that I just need to finish documenting.  All the technology is in place.  But I have a plan for something that I'm going to do relatively quickly that I think a lot of listeners will find extremely interesting.  So I'll have more to talk about soon.



LEO:  Okay.  Fair enough.  All right, Steve.  I've got questions.  I presume, since you gave me the questions, you've got answers.



STEVE:  And we got some good dialogue from our customers - from our customers.  From our listeners, too.



LEO:  Good.  Hey, they're our customers.  This is Question #1 from Charles G., Pittsburgh.  I'm presuming Pittsburgh, Pennsylvania.  He wonders about a two-factor authentication, Intel style.  He says:  Am I missing something?  This is something that you must have talked about when I was gone.  Am I missing something?  So you'll have to fill me in on what this Intel thing is.  But if the six-digit number can be generated on demand for authentication - I guess I have one of those VeriSign cards that does that - what's to prevent malware from being able to do the same thing?  Yes, it stops crooks from using other machines.  But if your machine is compromised, isn't it worse than having a separate dongle?  Oh, I get it.  Intel's building this into the machine.



STEVE:  Yes.  It's in the Sandy Bridge chipset.



LEO:  Interesting.



STEVE:  They built in exactly the same technology, this one-time password authentication.  And I have to say I love our listeners because this was one of the two most popular topics when I dumped the mailbag for this week's podcast.  The other one was still Bitcoin.  Everyone just wants to keep talking about Bitcoin.  That just really catalyzed everyone's imagination.  But so many of our listeners said, whoa, whoa, whoa, whoa, wait a minute.  If this second-factor hardware is built into the computer, then what's to prevent malware from accessing it?



LEO:  That's a good point.



STEVE:  Oh, it's a great point.  And it is absolutely the point.  So what we know we can say is that what this is doing is authenticating the machine.  It does not have the advantage of a freestanding credit card or football, but neither does it have the cost.  That is, it's just going to be there.  So I'm also very interested in how Intel will use this, that is, how it will surface, how it will be protected, what measures there will be to prevent malware from accessing it.  But the point is that that isn't the threat model.



What Intel has hoped to do - and this is inexpensive, it's not like this is some big huge project or anything.  I mean, this is a trivial little algorithm.  It probably took a minuscule portion of one of their chips to do this.  So it was sort of one of these things that, well, we'll just throw it in because we can and because it's simple and another bullet point on our checklist of features that we've got for our chipset.  So I didn't mean to make it a big deal.  What it does allow, though, is for that hardware to be uniquely identified.  So while it's true that malware running in the machine - I would be the last person to say there's no way malware could get access to it.  But the point is there's no way that someone outside of the machine could know what's happening inside the machine.



So I'm sure it was intended to prevent, for example, keystroke logging, as an example, from being able to be captured.  Or somebody doing a man in the middle, sniffing your traffic in an open WiFi, who sees you logging in and then tries to log in again, that's a perfect example of what this would defeat.  So, yes, it wouldn't defeat malware running in your machine, but it provides authentication for the machine itself to entities that don't have access to the machine.  And there's a lot of those.



So I completely agree that it doesn't have the same strength as something that software can't access because by definition some software has to be able to access it.  But that isn't what it's trying to prevent.  And I'll also mention that there have been exploits, even against one-time passwords because, if malware is in our machine, it can intercept us entering our one-time password and ride on that session.  So it's still important that we keep our machines clean.  And really the one-time password concept is much more meant for external protection than it is for protection against things that have already crawled into our machine and set up housekeeping there.



LEO:  It's just the same story as with the Thunderbolt issue.  If somebody has physical access to your machine, you're in bad shape.  I mean, there's all sorts of things they can do.  But presuming they don't have physical access, this is a great solution.



STEVE:  Yeah, and it's free.  It'll just be there.  It'll be, like, hey, why not use it?  It's part of it.



LEO:  It's like TPM; right?  I mean, it's just another kind of thing in the chip.  Mike Norris - not Chuck Norris, Mike Norris, his brother in Louisville, Kentucky, I don't know if it's his brother - wants to poke a hole.  It's good Chuck's not doing that because he'd just kick it right in there.  Steve, I've installed Bitcoin, and it's cranking away.  I have a question about the comment to set the TCP port forwarding to 8333 so that you can create more connections.  I'm having trouble doing this.  What is the procedure to set this up safely?  I'm running Windows 7.  Mike.  He wants to know the port forward; right?



STEVE:  Yes, exactly.  Now, one thing scary about Windows is where we think we've got a firewall which is protecting us, when you look at all the exceptions that have been made through the firewall for incoming traffic, it's just Swiss cheese.  It's why it's still really necessary to be behind a NAT router if you want anything like protection.  In fact, I know that Mike is behind a NAT router, otherwise he wouldn't be having a problem.  You can, in all versions of Windows that have had the personal firewall, and I did it in Windows 7 just to look at what the process was, you can bring up the advanced firewall configuration screen, and then you will be terrified as you scroll down through all the applications that have said to Windows, oh, I'd like to receive incoming traffic, please.



LEO:  No problem, no problem.



STEVE:  Yeah.  And there are, sure enough, two entries in that list for Bitcoin.  I think they're alphabetically sorted.  And so they were at the top, as a matter of fact.  And one is to allow any TCP connection from any IP on the outside to any IP on the inside, from any port on the outside to any port on the inside.  And the second is to allow any UDP traffic, similarly, from anywhere to anywhere, on any port to any port.  So it's just wide open.  Basically Bitcoin negotiated with Windows 7 and said, I need to listen to everybody.  And Windows 7 said, oh, not a problem.



LEO:  Is that UPnP that's doing that?



STEVE:  No.  That would be used if your computer were talking to your NAT router.



LEO:  Oh, okay.



STEVE:  So this is just done locally in the machine.



LEO:  It's done in Windows software.  I get it, I get it.



STEVE:  Right.  So what it means is that we really, yes, kind of there's a firewall, like maybe there's some traffic that it would block.  I'm not really sure.



LEO:  Well, isn't there a way to turn this behavior off?  Can we just say don't do that automatically?



STEVE:  Oh, yeah.  You can override it.  There's buttons and switches and settings and everything.  But that's really not the problem.  The good news is, we're behind a NAT router, so that's Mike's problem, is that Bitcoin has taken responsibility, negotiating with the Windows firewall, to open everything up so it can hear anything happening.  The problem is it's still deaf because the NAT router is not allowing stuff through.  So the amazing site for helping people with port forwarding is just called portforward.com.  And it is - I didn't even know there were this many routers in the world.  You go to portforward.com and start scrolling.  I don't think it's possible not to find your model, make and model of router on their list.  And they will show you how to do this.



Essentially, you need to change some configuration settings in your router so that port 8333, which is the port Bitcoin uses to run its whole peer-to-peer network, all of the traffic is running over port 8333.  You want to allow that to be sent into the IP address of the Windows 7 machine where you're running Bitcoin, and then that will allow it to participate in the network.  Although I should also say I'm running Bitcoin successfully behind NAT without port forwarding.  The connection count is dramatically limited.  I think I have eight connections which my Bitcoin machine has been able to make.  Out of curiosity I ran it on a different machine and did allow incoming traffic, and it had set up 60, six zero, connections.



LEO:  Oh, that's a big difference, yeah.



STEVE:  So a huge improvement.



LEO:  And more is better; right?



STEVE:  Well, I don't know.  Because it's the eight-connection machine that won the Bitcoin prize, and I got 50 bitcoins.



LEO:  Well, that's just luck.  That's not...



STEVE:  Yeah, so I'm not really clear on why more connectivity is necessary.  They seem to be promoting it, so I would say do it.  I don't see any reason not to.



LEO:  Do you get more data sets if you have more connections?  Not clear.  Unclear.



STEVE:  It's not clear.  I got eight connections, and that allowed me to win coinage.  So I'm on the network, I think I've got something like 3,000 confirmations now have come in that my computer did solve the puzzle correctly.  So we're in good shape.  But portforward.com for anyone's port-forwarding needs.  They really - they've got it well covered.



LEO:  Bravo.  I have that Bitcoin server, I've just got to turn it back on.  I turned it off because I thought, well, what the heck.  What am I doing to do with it?  Maybe Bryan L. Gay in Atlanta, Georgia has a comment.  He says:  Bitcoin Fail.  Well, I installed the Bitcoin client on the only Windows machine I have, one built for gaming.  So, yeah, that should be fast; right?  And the rest of my machines are either servers or work machines and laptops.  Unfortunately, Bitcoin chose the wrong port to try to operate on.  8333?  Really?  This is VMware's port.  Ooh, I didn't know that.  I run a VMware server on all my machines.  So Bitcoin won't even attempt to run on any of them, citing its inability to bind to the port, assuming it must already be running.  Now I'm looking for a way to change the port and get off 8333.  You know, there are only 65,000 total ports, and there's going to be some collisions from time to time.



STEVE:  Yeah, I was disappointed to see that there isn't an option for changing the port from Bitcoin.  But on the other hand, it probably can't be done.  That is, it's probably not possible, or just maybe their software's not flexible enough, for one machine in their big peer-to-peer network of clients that are all running on port 8333, for some random guy to be on 62942 or whatever.  So there is a collision with VMware server.  The good news is that Bitcoin fully supports running over a socks proxy.  And of course proxying was the topic of last week's podcast.



LEO:  Bitcoin, by the way, I should mention, the topic of two weeks hence.  So if you go back in time...



STEVE:  Yes.



LEO:  Or three weeks hence, you can get all the information we're talking about.



STEVE:  On Bitcoin, yes.  And Bitcoin does explicitly support TOR.  In their FAQ they talk about someone who wants additional anonymity, for example, of the IP that they're connecting from, can use TOR.  So you could run TOR, the TOR system in that machine, have Bitcoin connect to TOR, which it does by not using port 8333, and then TOR would tunnel out to the TOR network in order to get out.  Or you could set up a local socks proxy, set the local proxy to run - if you use a socks proxy, then you're not going to be running over port 8333 locally.  You'd be tunneling that out through the socks proxy and thereby avoid the collision.  And there are lots of FAQ pages over on Bitcoin.org to explain how all that's done.



LEO:  Okay.  People really got - their imaginations were captured by Bitcoin.



STEVE:  Oh, I'm telling you, this last week it hasn't died down any.  Half of the questions people submitted were interesting things about Bitcoin.  It just captured people's imaginations.



LEO:  Yeah, it did.  Our banker is sitting here.  Ron's from Exchange Bank, and he's going, what?  What's wrong with the old American greenback, I ask you?  Andrew in Northern Ireland wonders whether the server will protect us.  Steve, I recently started working for a small company with a single server and around 15 client machines.  Having listened to Security Now! for several years, I was a bit startled to see that most of the client machines run XP SP2 with few or no updates applied.  I think this is actually pretty common.



When it comes to my home machines, I have a mild case of OCD regarding keeping everything up to date with the latest patches and fixes, so seeing this got me asking my employer some questions about their security practices.  They have been told that because they are behind a server, a Windows-based server, I don't know what version, they don't need to update the client machines at all.  Maybe they don't get email.  Maybe they just don't give them email.  That could be.  Maybe they're not allowed to surf.



Now, this doesn't seem right to me, and I'm sure there must be some example of how this could provide a security hole, but I can't think of any good ones.  If all traffic to and from the Internet goes through the server, does that automatically protect the client machines?  If a virus or a trojan were to be installed locally, maybe via say a USB pen brought from home or a downloaded malicious PDF file, what damage could it do if it can't get through the server to the Internet?  Of course, this assumes the server is constantly up to date with Microsoft patches, virus definitions, et cetera.  Of course I doubt this also takes place.  Am I wrong?  Will the almighty server protect us all?  Or am I right to advise updating some machines?  Love the show.  Regards, Andrew.



I guess you could extend this to say, what if they're running, say, an Astaro Security Gateway or some sort of security gateway.  Do they have to update the machines?



STEVE:  Yeah, they really do.  First of all, it's not clear from what Andrew said what this Windows server is.  I mean, Microsoft does have an ISA server, which is a firewall border protection server that can do filtering and things.  But we assume that these client machines have access to the Internet.  It's hard to imagine that they wouldn't.  Maybe they're running some client server application software to do whatever their business does?  I mean, when he talked about they're behind a Windows server, it's like, okay, well, I'm not really sure what that means.



But if these machines have access to the Internet, they are absolutely vulnerable.  I mean, all of the exploits that we've talked about for the last several years that have involved browser client vulnerabilities, I can't see how any of these things that Microsoft has been fixing constantly, that we're sitting here waiting for Microsoft to fix these things.  If these machines haven't been updated since SP2, then they've got years of missing updates for exploits that are going on, known problems with, for example, PDF files, which someone could email to them and open.  And these are - sometimes antivirus software catches the stuff.  Other times it never catches up before Microsoft patches it, or there aren't any fixes for these problems through various AV tools.



So I'd have to say, I mean, I don't want to get Andrew in trouble with his boss or challenging whoever their security nonprovider is, but this seems crazy to me.  So, yeah, I just can't see a safe way of running machines that are out of date, that have contact with the Internet, because that's where the problem comes from.



LEO:  Well, I mean, yeah, they're going to get infected.  Period.  Right?  So it's just a question of - and they don't have to communicate to the outside world to be dangerous.



STEVE:  I was just going to say.  And, as he points out, if something did come in on a USB stick, the most recent viruses, malware, and trojans are using local LAN connectivity to spread throughout an organization.



LEO:  So you can assume everything behind your server is now infected.  I think this is an example of what CNN - remember CNN got bit by one of those worms, Conficker or something.  And it's exactly what happened.  Somebody brought it in from the outside.  It infected that computer and then spread through the network to get all the computers.  And I'm sure CNN had a server between it and the outside world, and they probably had routers, too.  Doesn't matter.  Still get infected.



Let's talk about proxies.  We talked about that last week.  Steven Meyer in Switzerland has a great comment about proxy dangers:  I'm new to your podcast, really like it.  Welcome, Steve Meyer, good to have you.  Thanks for the high quality of content and sound.  Sound's important to us.  We want to sound good.  When you were talking about proxies you forgot to mention about the sniffing risk of a proxy.  Any password sent through the proxy can be listened to; and, if the proxy is malicious, it could impersonate you even when using SSL.  Thanks for the nice podcast.  Steven.  Now, we've talked about this many, many times, maybe not on that particular episode, but certainly we have talked about this.



STEVE:  We have, and he is so right that I really, I got so carried away with the technology of proxies, which is really what I was trying to cover last week, that I don't think I did justice to the huge risk of using them.  And many people wrote to say, uh, Steve, you forgot to mention that that's really unsafe.  And it's like, oh, you're right, I did forget to mention that.  And it really is unsafe because he's right, and many of our other listeners who wrote in to remind me are right, and I should have spent more time on that because, think about it.



I mean, it absolutely is the case that, when you are surfing through a proxy, even if you're using an SSL session between you and the proxy, you're then decrypting that at the proxy end.  The proxy sees everything going on.  So I guess what I should have and I didn't say is treat it the same way you would surfing in a library, on a library computer, which I was covering earlier.  I mean, it is just - it is that bad.  It is something you would use sort of in the context that I was painting it, for if you can't get out any other way - although I did use Facebook as an example, and that's a bad one because you have to log into your Facebook site.  So any proxy could see you do that, and game over at that point.



So I'm glad Steven brought it up, and I really should have spent more time on it last week.  So I wanted to do so, to absolutely make it clear that you have to - the proxy has to be trustworthy, and probably none of them are.  So what that means is you have to treat it as an absolutely untrusted channel and only use it as a means for having access you wouldn't otherwise be able to have, but put nothing through it that is important to you because it's absolutely, I mean, we don't know that they're sniffing things.  I think that there are trustworthy, I know that there are trustworthy proxies.  I forgot to mention famous Anonymizer.com last week, a really good - they're not free, they're commercial, but I would trust them.  And there are other commercial ones.  So they're not all shady.  But you just don't know who they are when you're using HideMyAss.com.



LEO:  Yeah, who are they?  That's a good point.  Question 6, Jesse in Minneapolis wonders about C language character arrays.  What other show, ladies and gentlemen, what other show would you hear the broad range of topics that you hear on this show?  I'm in my second semester of the CSCI program at the University of Minnesota.  We are currently covering the String class in Java.  My professor mentioned that, in C, all strings are handled as a character array ending in zero, a null terminator.  That's how you know the string ends.  Java probably is like Pascal where it begins with a character count, a string length.  Is that right?  I don't know.  My question is, if that's the case, doesn't that make any application in C vulnerable to buffer overflow attacks?



STEVE:  Bingo.



LEO:  I can answer that one.  Yes.



STEVE:  You were laughing by the time you got to the end of it.



LEO:  As a matter of fact.  Well, we've talked about using, for instance, there are a couple library routines in C for string copying.  One is strcpy, and one is strncpy.  And all good programmers now know you use string ncpy.



STEVE:  Exactly.  The way to phrase this, Jesse, is because C uses null terminator strings, the way you copy a string is you copy the characters from one place to the other until you hit the null terminator.  So it's hitting the end of the string, that zero, the null character, is what stops the copy operation.  But that is the malware author's absolute dream because this means that they can get code on the stack or in your system to copy whatever data they want, anywhere they want it to go, and it will just keep copying away until it hits a null character.



So it is absolutely the case that, unfortunately, it's very convenient to use null terminator strings, but they are incredibly dangerous.  And exactly as Leo says, a strcpy "n" variant allows you to specify the target buffer size so that the copy will terminate at either the end of the source string being copied or the end of the target buffer being reached, whichever one occurs first.  And that makes things way safer.  As we know, it doesn't solve all the problems.  But it certainly makes things harder to exploit.



LEO:  That's probably, at least it was for a long time, the single most common exploit was exploiting these string overflows.



STEVE:  Yeah, actually, cross-site scripting has surpassed...



LEO:  Buffer overflows, really?



STEVE:  Yeah.



LEO:  Welcome to the new world of the web.  I'm surprised, though, I would imagine, Jesse, that they're going to cover that in your class.  They sure ought to because nowadays when you're teaching computer science and programming, you've got to always teach about good security methodology.



STEVE:  I think that's what's so nice is that we're to the point now where security can no longer be an afterthought.  It's in the consciousness of everyone, both users and authors.  It's now a factor.  So we're maybe beginning to leave a little bit of the Wild West days.  I don't think we see evidence of it yet out on the frontier.  But I think we will in another decade.



LEO:  Yeah.  Kristofer Thurston, Plano, Texas, wants to tell us about another kind of proxy:  I've been a network administrator in public and private education (K-12) for over 10 years, and proxy use/abuse has been a nemesis for me most of the time.  Of course, if you think about it, especially in a high school, where you're using some sort of filtering, that kids are just going to use a proxy server to get around that, if they're at all sophisticated.  Just like in China and Tunisia.  Don't get me wrong, I'm a full believer in the right to privacy, the Internet, and speech.  But in my line of work, the distraction of the Internet can drastically reduce student performance while simultaneously increasing the level of aggravation in our teachers.



In order to make the Internet a resource instead of a distraction and also because of CIPA, which is the Children's Internet Protection Act, we're forced to filter traffic during school hours.  We're currently using a filter that leverages URL filtering in combination with deep packet inspection to prevent access to some of the less illustrious Internet content.  The DPI portion uses matching rules based on Snort packet signatures.  That's pretty sophisticated.  This solution does a fantastic job of eliminating proxy type traffic as well as instant messaging, and as a result is a great supplement to the URL filter. 

 

However, as a result, our students have had to use even more devious means - I have an opinion on this, which I'll share later.  But what they've found are two products called UltraSurf and Freegate.  These proxy services work by creating a local proxy server in the student's machine, and pointing their browser to this local proxy server.  The proxy server then negotiates an SSL connection to the network of servers on the public Internet which then proxy the web requests.  Of course, as soon as it's SSL, you're dead because you can't inspect it.



The distributed network, like BitTorrent, prevents blocking of specific IP addresses.  This is effective because SSL encryption completely masks the packet payload, so that deep packet inspection is no longer useful.  Also, because more and more sites are "going dark" and switching to SSL, like Facebook and Gmail, DPI is further more ineffective.  As a result, we are in the process of using a filter similar to those you have discussed previously, that require the installation of a CA certificate on all clients so that SSL traffic can be decrypted inside the box, authorized man-in-the-middle.  When we do this, we will, of course, do so with full disclosure and warn against using the school network for truly secure purposes like banking.  In other words, the school is now saying you're going to go through our SSL, and we're going to look at everything you're doing.



Sorry for the length, but I thought you'd like to know about these two products specifically.  By the way, from what I understand, UltraSurf was created by the CIA to subvert government Internet filters in China, and Freegate's a derivative of that.



STEVE:  So I actually mentioned UltraSurf and Freegate last week.  They were the impetus, as I said, for me thinking we had never talked about proxies.  And I didn't focus on them because I did poke at one, and I got a response back that my IP was not in China, and their service was only limited to - for people in China.  However, they both allow - they go further and do something I didn't do because it really wasn't germane to the podcast.  But clearly Kristofer's kids, high school kids are doing this.  And that is they have the option of installing Firefox plug-ins.  And that's where they establish their local proxy server that uses SSL out to an agile IP network out on the public Internet in order to create the connection.



So I just wanted absolutely to bring this to people's attention.  Again, I don't intend to be promoting the bypassing of established proxies and filters and things.  But our listeners are savvy and responsible and may have a need.  And both UltraSurf and Freegate, with the caution that the CIA seems to be involved somehow, do look like ways of bypassing the use of what would otherwise be frighteningly unsafe proxies by switching to something that was deliberately designed for free speech and communication.  And what were you going to say about...



LEO:  Well, I'm on the board of trustees at my kid's school.  I'm kind of their tech advisor in high school.  And we go back and forth on whether to filter or not filter.  And I also talk to educators a lot.  And of course there may be legal requirements for them to filter; and, if that's the case, of course you have to do it.  But barring those, philosophically, my point of view is, look, every kid's got a cell phone now, and their own 3G network.  You can't stop it.



STEVE:  And they go home after school, where they've got...



LEO:  You can't stop it.



STEVE:  Exactly.



LEO:  So better to use this as a teaching moment and not block, but teach the kids the right way to use the Internet, teach the kids how not to be distracted.  They're going to face this at some point anyway.  Might as well use - that's what you're doing now, isn't it, in school?  You're teaching them ways to cope with life.  And so I think it's an artificial constraint to say, well, no Internet for you.  First of all, it's not going to work.  Second of all, then they're not learning key skills about how to deal with the Internet, how to deal with distraction, how to appropriately use the Internet.



STEVE:  They're still distracted trying to get around the filters.



LEO:  They're spending more time doing that.  And every kid who has an iPhone or any smart phone can surf and go anywhere they want anyway on their 3G network, and you can't stop them, neener neener neener.



STEVE:  Very good point, Leo.  They've got their own connection out to the cellular network.



LEO:  It's hopeless.  So your teachers have to learn how to deal with it.  They say, "Shh, put your phone away and shut your laptop."  Your teachers also have to teach kids how to deal with the Internet.  I mean, this is a very - what more important thing can a kid learn nowadays, frankly?  Anyway.  I'm sorry.  I'll get off my soapbox.  Question 8 from Jack Daniel.  He's the man at Astaro, another one of our great sponsors.  He's got a little opinion on proxies.  He says:



As always, thanks to you, Leo, and occasionally Tom for the great shows.  Tom did a great job filling in.  The web re-writing, browser-as-client kind of proxies you mentioned in last week's episode have a few problems.  Jack is all about security, so this is his thing.  First is the inherent domain obfuscation.  This breaks what little cross-domain protection we have left as all content looks like it's coming to the browser from the same domain.



STEVE:  True.



LEO:  So it can't discriminate.



STEVE:  True.



LEO:  Second, and a bigger issue for many, these sites are free.  And some, perhaps most, are supported by unsavory practices like serving spyware and malware.  You don't know.  How could you know?



STEVE:  Right.



LEO:  This type of proxy is a big problem for schools, both as they try to keep the students focused on school work instead of Facebook or worse, and because of the malware issues they bring.  Astaro systems have tools to address  these issues, but I don't want to do an advertisement, he says.  But good security practices are of course part of this.  I haven't looked lately, but I would also worry about those that support HTTPS sites.  Are they proxying that traffic by performing man-in-the-middle proxies?  I would look closely at the certificates.  Finally, if they're just SSL/TLS wrapping the HTTPS, the tunnel is prone to the infamous TCP over TCP tunnel collapse once retransmissions begin.  But complaining about poor performance on a free proxy is probably pointless.



Also you've talked a lot about two-factor authentication over the years.  Have you ever looked at WiKID Systems?  They have two two-factor authentication systems, one open source and one commercial, and they do some pretty cool things and support a myriad of devices.  I don't know this one, wikidsystems.com.



STEVE:  I looked and only saw the commercial side, so I want to find out what the open source thing is because they look like they've got a broad range of support, and I would love to find a free source for good two-factor authentication.



LEO:  You bet.  Finally, updates on free events:  HacKid has a few more events on the horizon, no dates yet, but hackid.org/wiki lists several in the planning stages, including one in the Bay area near us.  Well, we'll check that out.  I'd love to cover that.  He says:  Another event I've been involved in and sponsored by Astaro is Security BSides.  These are a series of free InfoSec events held around the world, sometimes adjacent to large events, sometimes standalone.  The focus is high-quality content in a relaxed and conversational format.  Great for our audience.  I think Leo will be dropping by to see us in Austin next week.  I will.  Registration is full for that one, for South by Southwest.  We'll be down there covering it.  Unfortunately that one's full.  We may have space for a few walk-ins, but there are many more coming up all around the world.  And you could find out more about that at securitybsides.org.  That's the wiki. 

 

No need to mention my name, says Jack.  I'm sure folks are sick of hearing from me.  I just wanted to drop you a line with a few things I thought would be interesting.  Well, of course we love hearing from you, Jack.  Thank you.



STEVE:  So, great points from somebody who has been over on the front lines of this proxying stuff.  Certainly the points he makes about the fact that domains are collapsed into one is very good because it is only by keeping the domains separate that our scripts are able to be controlled.  So losing that really does dramatically weaken script security as another negative to that kind of proxying.  And that was the last one of the multiple type of proxies I talked about where you go to a site, and you enter the URL you want to visit into that site, and what you'll see then is all the URLs and all the links of the page that come back refer to the proxy server, not to yours.  What that means is that scripts are confused and believing that they are hosted by the proxy server, not by their actual origin server.  And that can be a problem.



The SSL thing is not such a problem.  I think that Jack was probably assuming there was more SSL going on than there is.  For example, in the case of, we talked about it last week, HideMyAss.com, you create an SSL connection between you and them only, and then they take that apart, and then you have a non-SSL connection out to the remote site.  So you probably aren't trying to tunnel SSL within SSL.  And so I don't think that's a problem.  And then the other information I just wanted to share with our listeners.



LEO:  Cool.  Want a YubiKey story?  Brett Moffett in Adelaide, South Australia uses his YubiKey to log onto PayPal:  Long-time listener, first time emailer.  Ever since hearing about YubiKey on Security Now! I've been a convert.  The power of a one-time password and the ability to store a very long random password all in a very small device is fantastic.  I just wish more sites would support it.  I do, too.  Well, it looks like instead of waiting for sites to accept YubiKey, Yubico has brought YubiKey to them.  I noticed in a recent Yubico newsletter there is now an option of buying a YubiKey with Symantec's VIP installed in the first memory slot of the key.  This can then be associated, because Symantec is supported by sites like PayPal, and you can use your YubiKey to access these sites. The second slot can be programmed to use Yubico's OTP, OATH, or even a static password.  Unfortunately, it can't be retro fitted to existing YubiKeys, but buying it with it built in costs no more than a regular key. 



Keep up the great work with Security Now!.  I can't wait for your VPN solution if it ever gets off the ground.  Isn't VIP VeriSign?  Is it Symantec?



STEVE:  Symantec bought it.



LEO:  Oh, I didn't know that.



STEVE:  Yeah, they bought the VIP division from VeriSign.  So it's now Symantec.  And I had coffee last Thursday morning with Stina Ehrensvrd, our founder and actually inventor of the YubiKey concept.  And she mentioned this to me, which I wasn't aware of, so I was glad to see Brett bringing it up and reminding me to let everyone know that among all of the other types of tokens which the Symantec VIP service offers, YubiKey is now one of them, if you get one of their Symantec VIP YubiKeys.  So exactly like the credit card that we've talked about with eInk, or the little LCD-based football, or the app in our phone - which frankly, that really solves the problem for me...



LEO:  That's the way I want it.



STEVE:  Exactly.  So essentially this is the same incremental algorithm that the static credit card approach uses where it just sequentially generates the next key.  The YubiKey has that built in.  And so that's one of the authentication options that it offers.  So you stick it into a USB slot, and when prompted to, just tap the button.  And I guess, if you had some application where you needed to authenticate often, then that could be pretty handy.  You'd just sort of leave it in the USB slot.  And every time you're being asked to reauthenticate, you just tap the little dot on the YubiKey ,and it would send in the next code to say, yep, it's still me, I'm still here.



LEO:  I'm still here.



STEVE:  And that would be easier than getting your phone out again and bringing up the app and keying in what the code is now being displayed.  So I can see a positive application for that.



LEO:  You bet.  I didn't realize the YubiKey was so sophisticated.  I mean, it's really a little computer there.



STEVE:  They're taking it in a lot of directions.  And in fact, I'm under embargo on a very cool, completely new thing that they've done, probably till the end of March.  Stina said they wouldn't be able to talk about it yet.  It doesn't have huge end-user significance.  It's more something for the enterprise.  But a very cool piece of technology that I'll be able to talk about in about a month.



LEO:  Great.  Our final question comes from an Eagle Scout.  Actually, I don't know if it's a question.  It's more like information.  Lance writes:  Steve, you've talked the last couple of weeks about Bitcoin.  After your podcast I decided to check it out.  After running two computers with Bitcoin for a day I saw nothing.  Well, it takes time.  Be patient.  So I decided to look into what others were doing to compete with these GPU Bitcoin farms.  I found that pooled mining is a great way to combat this.  I joined the mining effort at mining.bitcoin.cz, which is I think the Czech Republic.  And after two days I had generated [fanfare] one bitcoin.



However, my computer had, just as yours, cranked out the hot air, and I could hear the liquid constantly being pushed through.  In other words, it was working.  So I decided it wasn't worth wearing out my two computers for 50 cents a day.  Now both computers that I was using were quad cores, one at 3.4GHz and one at 2.8GHz.  So I was on the higher end of CPUs.  I can't imagine how long it would take an older PC, even in pooled mining, to generate one bitcoin.  I still wanted to get in on these bitcoins, but it was pretty apparent that I was either going to wear out my PCs doing it, or I had to invest money into a GPU or just buying coins.  But after searching around I found actually most people using bitcoins do not farm for them.  They use sites that accept bitcoins to sell items and make bitcoins from those sales.  In other words, it's really become an economy.  So they have sites...



STEVE:  Yes, there is really an economy.



LEO:  There's sites like eBay and Amazon that you can bid or pay in bitcoins.  For those looking to get into the Bitcoin game I would highly suggest trying to sell items on these trading sites that accept bitcoins instead of using eBay - then you can build up, accumulate some bitcoin - as I personally found it a lot easier than farming bitcoins.  And this way you will still make bitcoins, but you won't have to wear out your computer, waste bandwidth, and run up your electric bill doing it.  You know, I've got to set up Bitcoin donations.  Thanks, Steve, Leo and Tom.  I just, I feel like I like American money better.  For now.  Thanks, Leo, Steve, and Tom for the excellent podcasts.  You guys are my secret weapon at work to keeping my job and getting raises.  Lance, Eagle Scout.



STEVE:  So I just wanted to, again, there's been so much interest in Bitcoin that I think people liked it because it was a little wacky and off topic from what we normally do, yet it still has serious crypto side because of the architecture that was developed, and the fact that...



LEO:  It's kind of hacker-y, too.  It's kind of out of the mainstream kind of anarchy.



STEVE:  Anarchists, yes.  And so this farming, I did mention farming in the podcast, but I wanted, thanks to Lance, to bring it up again because the idea is that it sort of flips the model around.  Rather than one machine cranking away in isolation all by itself in the corner, pumping out heat, and not very often pumping out bitcoins, like they're estimating you would win one puzzle once a year and get 50, I just lucked into it and won one after less than a week.  But I haven't done anything since.  I've still got those machines running, and nothing.  The alternative is to change the model around and join a mining pool where any machines that you can allocate to it, you're all working together.  And if any one of those machines in the pool solves the puzzle, then you all share equally in the bitcoinage.



LEO:  Doesn't seem like that would give you any bigger advantage, though, because you have to split it.



STEVE:  Yeah, but he got one bitcoin in two days.  So it's like instead of getting 50 at once, you get one at a time, but at least...



LEO:  It's like creating a pool for the lottery, though.  I mean, I...



STEVE:  It's very much the same, yes.  But at least you're not looking at 0.00.



LEO:  Right.  I guess that's frustrating for people.  It's kind of a weird system that way.  You just, you know.



STEVE:  The whole thing's wacky.  But...



LEO:  So there's no expectation that you can generate any particular amount of bitcoin over any particular amount of time.  It's just random.



STEVE:  Right, it's purely statistics.  And so because I solved the puzzle, someone else who'd been working for a year, who came in second, didn't solve it.



LEO:  Poor guy.



STEVE:  But I was working for less than a week and got 50 coins.  It's like, uh, sorry about that.  I'm not unplugging mine, though.



LEO:  Well, and what have you got?  I think people would do better just buying a copy of SpinRite from Steve.



STEVE:  It's just pure curiosity.  It's just...



LEO:  I had the same reaction when I first heard about it, ran the server for a while, same thing.  It's very interesting.



STEVE:  On these cold days you could use a little extra heat.



LEO:  Yeah, why not.  God knows I've got enough computers running, idling, sitting there.  Steve is at GRC.com.  That's his website.  He actually tweets, too, if you want to follow him on Twitter.  It's @SGgrc.  And his corporate account is @GibsonResearch.  GRC.com is the place to go for 16KB versions of the show, transcripts, show notes.  And there are 290 shows on there, so you can go back in time and look at them all.  He's got them all there, GRC.com.  While you're there, pick up a copy of SpinRite.  Every hard drive needs SpinRite.  And a lot of free stuff there, too, some great free security apps and more, GRC.com.



And Steve, we'll be back at our regular time next week.  Thank you for allowing us to shift you with MacBreak Weekly because tomorrow of course the iPad announcement.  But normally we do record Wednesdays at 2:00 p.m. Eastern, 11:00 a.m. Pacific at live.twit.tv.



STEVE:  And so your trip next week doesn't interfere with our podcast?



LEO:  I don't leave for Austin till Friday afternoon.



STEVE:  Cool.



LEO:  Yup.



STEVE:  Okay, my friend.



LEO:  See you next week.



STEVE:  Talk to you then.  Thanks. 



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#291

DATE:		March 10, 2011

TITLE:		Stuxnet

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-291.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a very busy week of software updates and wide-ranging security news, Steve and Leo discuss the revelations documented in Symantec's comprehensive "Stuxnet Dossier."



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 291, recorded March 9, 2011:  Stuxnet.



It's time for Security Now!, the show that covers your security online, your privacy.  And here he is, the man of the hour, our guru from the Gibson Research Corporation, the creator of SpinRite - the world's best hard drive utility - and many great free security programs, Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again, as always.



LEO:  What's our topic of the day today?



STEVE:  We've got a great one.  I referred to it a couple weeks ago, probably when you were off and Tom was holding down the fort here, that Symantec had released a very comprehensive report on their detailed analysis of Stuxnet, which they really took apart.  And I thought, well, this would make an interesting topic.  And now I'm convinced that, by the end of this podcast, no one listening will be able to doubt that the term "cyberweapon" applies.  I mean, that clearly - I don't think there's any way this could have been produced without national-level state sponsorship.  And this thing is so sophisticated and was so targeted, the statistics that have been gathered demonstrate it.



And one of the coolest things that Stuxnet did is, as it infected machines, it appended to a log of its - basically of its travels.  And by capturing samples, the log was - Symantec was able to obtain more than 3,000 instances of Stuxnet.  And by going back through the log that it itself carried, they were able to, basically, follow this thing back in time and determine that there were three specific attack waves, and which five companies were targeted.  So it's not just like it's, oh, look, it's everywhere, as though all over the Internet everyone has it.  No.  I mean, we know exactly how this happened.  And it's really fascinating.



LEO:  Well, I can't wait to find out more about it.  We also have other security news, quite a bit of security news as we approach...



STEVE:  Oh, we do, yes.



LEO:  ...the Pwn2Own Conference, which I think is coming up today or tomorrow.  All right, Steve, I have in front of me a list, starting with Patch Tuesday.



STEVE:  Well, yes, we are just past our standard second Tuesday of the month.  So Microsoft has actually a rather lean response this month.  They fixed four different vulnerabilities, one which was critical in their media playback which affected all the recent OSes - XP, Vista, and Windows 7 - such that, if you went to a site that had a specially crafted malicious video, it could execute code on your machine.  That they fixed.



The bad news is the zero-day exploit, which we have talked about recently, the so-called MHTML exploit - MHTML is sort of a pseudo protocol.  In the same way that we have HTTP:, Microsoft defines MHTML: as a way to invoke MIME-encoded HTML.  We talked about how that's used for archiving whole web pages, in the same way that MIME stands for Multipart, what is it, Multipart Internet Message Extension or something?



LEO:  Yeah, something like that.



STEVE:  For allowing email to contain nontextual things, like photos and so forth, MIME is how you do that.  Similarly, this is how Microsoft has their own proprietary format for storing an entire web page including all of its assets, its other photos and so forth.  There's a problem with it such that, if you go to a website that invokes this protocol, similarly they're able to get their own code to run on your machine.  Well, that didn't get fixed this Tuesday, and I was hoping it was because it is being actively exploited in the wild.



So I wanted to remind our listeners that there is a one-click easy Fixit button that Microsoft offers.  If you go to go.microsoft.com, then ?linkid=9760419, that will take you to this page with the quick fix dealie that just disables that protocol.  And probably everyone, I mean, it's one of those things that's on by default.  It's got a problem in it that, if you don't know you need it, you probably don't.  So, I mean, I immediately went there and just said, I don't need this, I'm turning it off.  And had Microsoft fixed it a couple days ago, we'd probably be okay.  But like these things, now that it's seen that Microsoft hasn't fixed it, we can expect more exploits to happen.  So...



LEO:  It's a "sit up and take notice" to hackers.



STEVE:  It's a problem, yes, exactly.  They're saying, hey, we've got another month, probably.  So let's jump on this.  So more important to do that.  So I don't know what you could Google to get there.  It's MHTML exploit, but you can go to go.microsoft.com/?linkid=9760419.



LEO:  And I get a download, immediate download when I go there.  So you're getting a .msi file, an installer.



STEVE:  Yes, in fact, that is the link that you get when you click the button.  And so it'll instantly say, here's your goodie, run this, and we'll - and all it's doing is it's just making some registry tweaks.  It's changing, it's basically removing the protocol from the registry where it's defined.  So it's not even - it's not installing anything.  It's not making any deep changes in your system, just changing some values.  And there is, on the related pages about this, you can see do-it-yourself registry stuff, if you don't want to use Microsoft's little quick fixer.



LEO:  Yeah, maybe just go to the security advisory 2501696 if you want to read about it.  And there's I'm sure a link there to the download, so.



STEVE:  Yes, that's great advice.  Now, everybody else has, in somewhat of a panic, they have pushed out fixes for their browser because of something you referred to that is happening in Vancouver as we record this today.  Wednesday the 9th, the 10th, and the 11th of March is the CanSecWest.  It's the 12th Annual CanSecWest Security Conference, Canadian Security West Security Conference, happening in Vancouver.  One of the, well, first of all, there are a bunch of fun things going on there.  In the agenda, one of the talks is "SMS-O-Death," which I get a kick out of.  Also "iPhone and iPad Hacking" and "Stale Pointers Are the New Black" are some of the topics for the conference.



Anyway, one of the things that they host there, and we've talked about this for the last several years because fun things come out of it, is the so-called Pwn2Own, basically competition, where the security researchers and white and gray hat hackers who attend attempt to exploit not-before-known, that is to say, zero-day vulnerabilities which they've discovered or know of in the popular browsers.  So in the ramp-up to this, Apple recently immediately updated their Safari, both on the Mac OS platform and on the Windows platform.  In the case of Windows they moved iTunes, which uses the WebKit engine which is what's common in Safari, they moved iTunes up to 10.2, in the process fixing more than 50 known security vulnerabilities over on the Windows side.  iTunes over on the Mac OS was moved to 10.2.1, also just recently.  So anyone using Macs, or especially iTunes over on Windows - I don't know, if you're not going into iTunes very often, it's worth to get 50 security vulnerabilities fixed, you want to bring yourself up to 10.2.



LEO:  Even if you don't use it often.



STEVE:  Exactly.  Over on...



LEO:  It's a little deceptive because it's an iTunes update, and people assume, oh, well.  It's like if you were on the Mac, and you didn't use iTunes, you'd go, I could ignore it.  But, no, really it's not.



STEVE:  Yes, because it's WebKit that is being brought along.  And that's the rendering engine, the layout engine in Safari.  And there's all these problems that they know of in font rendering and HTML layout.



LEO:  So even if you don't use iTunes on Windows, if you use Safari on Windows, you have to do this.



STEVE:  Yes.  Yes.



LEO:  Yeah.  And I presume there'll be WebKit updates for WebKit itself and other WebKit-based apps.  Chrome is WebKit based, so that's probably where the Chrome updates come from.



STEVE:  Yes.  Over on the Mozilla side, similarly, Firefox, they brought themselves completely up, completely current.  Anything that they knew of that they hadn't sort of gotten around to pushing out yet, before this conference it's like, oh, we've got to get this out.  So in fact I noticed that I'm still at 3.6.13 on my main system, although a laptop that I started up yesterday did bring itself current.  Firefox is now on the 3.6 chain, is up to .14.  If you're still back at 3.5, that's at 3.5.17.  But also Thunderbird needs to be brought up to 3.1.8, and SeaMonkey up to 2.0.12.  And this fixes a bunch of stuff:  problems in the JavaScript engine, code-handling under HTML, style sheets, scalable vector graphics, objects, and JPEG images.  So just across the board.  And as is typical now, these are exploitable by enticing a user to visit a malicious website that then gets your browser to do something it was not designed to do.



And lastly, Chrome, always sneaking along as it is, when I fired my Chrome up, it was behind times, and so it quickly updated itself to what is now current, 9.0.597.107, in the process fixing 19 known security issues.  And Google never talks much about what these are, but we know for example that several are stale pointer vulnerabilities.  In fact, that was the topic of one of the talks was, remember, "Stale Pointers Are the New Black."  And also they had an integer overflow problem.  And one of the things we are now seeing more of is memory use-after-free vulnerabilities, where memory is released, but then there's still a pointer to it that allows it to be accessed in a way that the designers did not intend.  So that's cleaned up in Chrome.



So across the board, our browsers have sort of straightened themselves up in the hopes that they're able to survive the next three days.  This Pwn2Own conference, on their website they say, "If you can execute arbitrary code (PWN)" - which of course is the hackronym for maliciously taking ownership of something that was not yours, and really it's interesting because there isn't really a clear history of how that came to be.  People are assuming maybe it was a typo.  Since "P" on our English keyboard is right next to "O," maybe somebody was typing, meant to type "OWN," O-W-N, but they typed "PWN," they thought, hey, that's kind of cool.  Who knows where it came from.  But so if hackers are able to execute arbitrary code through a previously undisclosed browser - either Firefox, IE, Safari, or Chrome - exploit, then the site says "you can go home with one (OWN)."  So Pwn2Own.



The browser prizes for exploits were increased this year to $15,000.  And there are also state-of-the-art phones, laptops, and cash.  And then Google went a little further, decided to stoke the fires under Chrome, and tossed in an additional $20K for Chrome-specific exploits which are found.  So if anyone's curious, the site is cansecwest.com.  And the /agenda.html shows the three days.  And I'm sure that we will be talking about, next week, the outcome of these three days.  The Pwn2Own competition always produces some fun results.



LEO:  It's a great, it's an amazing event.  And I think this is the measure of it's a real success is that people are now, I mean, they didn't do this in the past.  And credit to Charlie [Miller] for breaking Safari every single time, winning 15 grand and a Macintosh laptop.  I think this finally forced Apple, which has been traditionally pretty slow to acknowledge these problems, to do something about it.  It's embarrassing for them.  So good job.



STEVE:  Well, and I'll say again that it's worth noting that Microsoft didn't do anything other than just roll out their regular old Patch Tuesday.



LEO:  But that patch, that HTML flaw, could well have been the one that people wanted to use; right?



STEVE:  Yes.  And so, and it was disqualified because that's publicly known.  So it has to be...



LEO:  Oh.



STEVE:  Yeah.  So...



LEO:  They can't use something that is known.



STEVE:  Correct.  It's got to be a surprise.  So it's going to be something new.



LEO:  Charlie Miller.  I'm sorry, I said the wrong - so Charlie says, by the way, "I got something."  He says, "It's okay."  We'll see.  It's amazing, I mean, Apple gets Pwned almost immediately, in the last three years that I can remember, almost immediately Safari is broken.



STEVE:  Yeah, well, I've been studying, for the last several weeks, JavaScript in greater detail than I ever have before because I have something that I want to do that has to be done in real-time, interactively, on the client.  And I've gone through all kinds of hoops historically to absolutely not require any scripting on GRC.  I have famously the script-free dropdown menuing system, which I created out of pure CSS, nothing but cascading style sheets.  The eCommerce system that I wrote for SpinRite commerce does not even need cookies to be enabled.  And still the whole shopping card system works, and your state is preserved as you go through that experience, with no state whatsoever being kept in the browser.  And but there are times when you need something browser-based interactive, you know, like Gmail, and pretty much Google anything, where you absolutely have to have scripting.



So anyway, so I've been bringing myself up to state of the art where I can actually write a substantial chunk of code in JavaScript, I just shake my head.  I mean, I'm just, it's like, oh, my god, I mean, the language begs to have people use it wrong and create bugs.  The problem is it tries to be simple, but a language isn't simple.  A language is inherently complex.  And so by saying, oh, look how simple this is, it does seduce nonprogrammers to try to start using it, and they can get results.  But inevitably they start wanting to do more complex things.  And the way JavaScript was designed, it just begs you to have problems because it sort of tells nonprogrammers, oh, look, this is just sort of scripting.  Anybody can do this.  And anyway, so anyway, when I look at these stories of competitions finding problems, and also I look at the complexity in modern browsers, I'm just not surprised that they can be owned.  They've gotten incredibly complex.



LEO:  Postel's Law is, and this applies to browsers:  Be liberal in what you accept and stingy in what you put out.



STEVE:  Exactly.



LEO:  And being liberal in what you accept for a browser means having to support, as you say, many, many, many, many different protocols and ways of interaction.



STEVE:  And styles, yeah.



LEO:  And styles.  And it's hard to prevent attacks when you're that open.



STEVE:  So here's something really interesting, and I don't yet know what it means.  But BBC News has reported that, as of May 25, 2011, that European laws dictate that "explicit consent" must be gathered from web users who are being tracked via cookies.  The beginning of their report says:  "The way websites track visitors and tailor ads to their behavior is about to undergo a big shakeup."  The story says that the changes are "demanded by the European e-Privacy directive which comes into force in the U.K. in late May," on May 25.  And it says the section of the directive dealing with cookies "was drawn up in an attempt to protect privacy and, in particular, limit how much use could be made of behavioral advertising."



The directive demands that "users be fully informed about the information being stored in cookies and told why they see particular adverts."  And then, quoting again, it says, "Specifically excluded by the directive are cookies that log what people have put in online shopping baskets," meaning excluded are first-party cookies, which is what you typically need in order to maintain your local state with a remote server, but it's the third party tracking mechanisms that we've talked about which apparently become, not really outlawed, but again, it's not quite sure what this means.



Now, in looking into this further, I determined that the U.K. isn't quite sure themselves yet what it means.  They've said, with some embarrassment, that their formal written policy about what exactly this means won't be ready by May 25.  And then of course we have the other problem of jurisdiction.  I mean, they don't have any jurisdiction on me.  I mean, I'm not using any tracking for anything, but the 'Net is global.  And so I guess they could, within the - I don't know if this applies.  It says "European law."  So is this maybe within the EU?  I mean, there's a lot more we need to find out about what this means.  But it means something.  And presumably companies operating within whatever environment this pertains to will have an obligation to disclose their use of tracking.



So again, this is the beginning of what feels like some serious change.  We've got the browsers adding do-not-track-me headers.  We've got the U.S. grumbling around, trying to figure out what direction it wants to go in.  And here we've got now the U.K. saying, okay, there's a date.  It doesn't quite mean anything yet, or we're not sure what it means, but there is one.  So I just wanted to put that on our listener's radar.  That's going to be interesting to see what happens.



LEO:  Very, very interesting.



STEVE:  Meanwhile, Google has famously been having problems, more, with their Android Marketplace apps.  50, or I should say about 50 apps were found recently to all be infected with the same piece of malware known as Droid Dream.  It uses a previously known vulnerability in earlier versions of Android, that is, before 2.2.2, which is the version where this hole was closed.  But Google became aware that a bunch of apps, on the order of 50, had made it onto the Marketplace, had been downloaded, and were in use by Android users.  So they pulled the apps immediately from the Marketplace.  They've suspended the accounts of the developers who were believed to be responsible for the infected applications, and they've said they've notified law enforcement.



One thing I guess, and I haven't looked closely at the contracts with Android Marketplace, but you don't put apps up there anonymously.  You have to sign an agreement about what your conduct will be.  And I did read some editorializing on the 'Net that was saying, well, this is interesting because big companies like Google who have big bunches of attorneys can afford to pursue the people who do this, who are presumably known.  So one of the things that Google did was then they took advantage of their so-called "Remote Application Removal Feature" to remotely go into the phones of people who had these applications installed and removed the app, and then installed something called "Android Market Security Tool March 2011," which proactively closed the hole on their versions of Android earlier than 2.2.2.  So Google's doing, I would say, everything they can to respond to the fundamental problems that they have with being more open than, for example, Apple is with iTunes and the iPhone and iPad app model.



LEO:  And that's the price you pay.



STEVE:  Yeah.  Yeah, so it'll be interesting to see whether, if the Marketplace developed a reputation of we're really going to know who you are in order for you to submit applications, and we're going to stomp on you hard if you maliciously exploit your privilege of putting applications in the Android Marketplace, well, that might really cool things off there.



LEO:  Exactly.



STEVE:  From a malware standpoint.



LEO:  I'm interested to see that they have and use the kill switch.



STEVE:  Yes.  Now, they had before, back last summer.  There were two instances, I think, where they did it.  But this was sweeping.  This was much bigger.  And it raised eyebrows.  There are people who don't like the idea that, without user involvement or agreement, Google is able to go in and change people's phone configuration, go in and remove applications which are bad.  I think it's entirely appropriate, frankly, given the level of user, the fact that - and it's very much like Chrome, just sort of always fixing itself and not making a big deal about it.  Google is saying, look, there's problems.  Stuff's going to happen.  We're just going to fix it as best we can when we know about it and move on.  So I would, I think - if polled, you're going to have some curmudgeon-y people who dislike it sort of on a conceptual basis.  But I would imagine 99.99 percent of the people who have Android are saying, hey, fine, if there was something bad on my phone, I'm glad Google came and took it away.



LEO:  Yeah.  I think the kill switch is just, I mean, look, this is not your personal computer.  It's a computer, but it is a computer on a larger network.  And there is a certain, I think, a certain responsibility.  I'd hate to see that on PCs, but I think on phones, I think it's understandable.  Especially if they use it appropriately.



STEVE:  Yes, you're inherently connected.



LEO:  Yeah.



STEVE:  So here's a weird thing.



LEO:  Okay.



STEVE:  And I don't quite get this.  But Microsoft is actively working to discourage the use of IE6.  Now...



LEO:  That's good, actually.



STEVE:  Oh, it's very good.  But it's like, okay.  First of all, I'm not sure how they're doing, going about that.  But they've created a site called TheIE6Countdown.com.  And you should go there, Leo, while we're talking about this.



LEO:  Okay.



STEVE:  So it's www.theie6countdown.com.  Got to have scripting enabled, otherwise it won't count down for you.  It shows at 100 percent in the upper right-hand corner.



LEO:  Oh, look at this.  Oh, my.



STEVE:  But so that's - what you're looking at, and what our listeners will look at when they go to the TheIE6Countdown.com, is a map of the world showing the continuing use, against all odds, I mean, we have 7, we have 8, and we almost have 9.



LEO:  But look at this, China, it's like...



STEVE:  Yes.



LEO:  Huge.  What is that, 59 percent?  Or 5.9 percent?  I can't understand...



STEVE:  34.5 percent of IE use in China is still IE6.



LEO:  Wow.



STEVE:  Which does make you wonder why they're not getting their security updates.  Of course we know that...



LEO:  It's pirated software is what it is.



STEVE:  Pirated software doesn't get updated, right.  So it's IE6.  It's now 10 years old.  It's been a decade.  And its use is enduring.  And it's interesting because in the text down there in the lower left, Leo, that you can see, they're talking about if only people would stop using IE6...



LEO:  Hey, you know, good for Microsoft.  I think that's great.



STEVE:  Except it's their fault that it's not standards compliant.  I mean, what they're saying is, if you'd stop, if only people, I mean, I agree, it's nice that they're doing it now that they have a much more standards-compliant browser.  I've been reading, because I've been studying JavaScript, about the history of Microsoft IE's, for example, their event model still isn't the W3C standard.  They've just done it their own way, and they're just thumbing their nose at everybody so that anyone who's programming JavaScript has to special case just for IE because IE's still the dominant browser on the planet.



But so here's Microsoft saying, down there in the lower left, please, if everyone would stop using IE, then web developers would have an easier time because of course IE6 is, like, much worse than 7, 8, or 9, which have been progressively getting better.  Not just better in security, and that certainly is the case.  I mean, like in the middle there it says "Friends don't let friends use IE6."  And so Microsoft is really - and I didn't even know this was their site initially.  But I do take my hat off to them.



So in China 34.5 percent are still using IE6.  In India the number is 12.3; Saudi Arabia, next lower at 10.7; and Japan, next lower after that at 10.3 percent.  So I looked at my own stats because I track browser version, sort of out of curiosity.  Interestingly, IE5 still is not completely zero for us.  In the last week, out of about 70,000 unique visitors, 0.07 percent of them are using - they came to GRC with IE5.  2.87 percent came with IE6.  And I'm proud to say Firefox users by far outnumber all other users.  Firefox 3 is the most used browser at GRC, above even any version of IE.  So people who come to GRC know what they're doing.



LEO:  Yeah.  And I've seen that on my own pages, too.  I mean, it's not our audience we have to worry about.



STEVE:  Right.  So Adobe released something odd.  Adobe Labs released something called "Wallaby" which converts simple Flash games and animations into JavaScript, using HTML5 and scaled vector graphics, so that they can run on, quote, "devices that do not support the Flash runtimes."  And of course we know what those are.  There aren't many of them.  And then on their release notes page they further said that "Complex animations crash the browser, and zooming in and out can cause odd artifacts in the browser."  They said:  "Wallaby is delivered as a 32-bit application for Windows and Macintosh."



So what this thing is, is you give it your Flash project, written in ActionScript, which is the Flash scripting language, and the various Flash resources, and this thing converts it into a WebKit-compatible HTML5 and script.  They said:  "Wallaby is designed to emit HTML5 files compatible with WebKit" - and they made that in bold on their release notes - "based browsers.  The only" - again in their bold - "supported WebKit browsers at this time are Chrome and Safari on OS X, Windows, and iOS (iPad, iPhone, iPod).  Because Wallaby uses WebKit-specific animation primitives, animation will not work and has not been tested on other browsers."  So it's a WebKit-specific converter of Flash.



And I've seen a lot of criticism about it out on the 'Net because it has lots of problems.  You just can't give it your current Flash project and have it work because - and on their release notes page, if you scroll down, it's labs.adobe.com/wiki/index.php/Wallaby#Release_Notes.  But that'll just be the release notes section of that Wallaby page, which is where this can be found.  So clearly what this is is a response to Apple and Jobs saying we don't want Flash running on our devices.  In fact, we're going to prohibit it from running on our devices.  But what's odd is that Apple has also made it very clear that translators cannot be used, that you have to write things natively for their platform in order to use them.  And so this is a translator.  On the other hand...



LEO:  But it runs in the browser, ultimately.



STEVE:  Exactly.



LEO:  Okay.  So you can do anything you want on a web page.  Apple can't stop you from putting a web page up.



STEVE:  Exactly.  So I guess this is just, you know, I just sort of - this crossed my radar.  I thought our listeners would find it interesting.



LEO:  I'd like to see what kind of translation, how good the translation is.



STEVE:  Yeah.



LEO:  It uses SVG for graphics.



STEVE:  Scalable Vector Graphics.



LEO:  Yeah.  Does it have a video layer?  I'm looking through here.  Hmm, doesn't seem to have a - yeah, video is unsupported.  So the thing that most people use Flash for doesn't work.



STEVE:  Yeah.  And they said games and animations.  So it's going to be, I don't know, line drawing stuff and...



LEO:  There's a lot of games in Flash that are just animations, I guess.



STEVE:  And so, if they work, it does allow people a way to make that happen.  I guess there's no economic model for it because you can't sell something like this through the iTunes store.  All you could do is say, oh, here, click this link and run this game.  And we'll hope there aren't any bad security vulnerabilities with what Wallaby does.  I don't know.  Now...



LEO:  Yeah, that's another issue.  But that's up to the browser; right?  I mean, if it's HTML5...



STEVE:  Yeah.



LEO:  Yeah, the browser is ultimately the security model here.



STEVE:  Yup, exactly.  So two conflicting reports have come out in the last week which, based on the number of people who sent me links and tweeted to me about it, generated a lot of interest.  A UCSD study came out which stated that erasing data on solid state disks is difficult to do.  They performed some experiments where they took a bunch of various manufacturers' SSDs and USB drives and wrote patterned data on them so that they could sort of track the data by sector, and then erased the data, like tried to do a secure erasure, like an overwrite erasure, and then went into the flash ROM chips themselves and found, as I remember, on the order of 10 percent of the data still survived.



Now, at the same time another report from Australia, from the Murdoch University in Perth, some researchers are complaining that solid-state drives are making forensics, traditional forensics, difficult because the logic in the drives sort of - the firmware in the drives is altering the contents without any external intervention, causing these drives to lose data that forensics people would like to be able to recover.  So I've decided, since there was so much interest that has been expressed by our listeners, that I ought to dig into this stuff and what these researchers have done and cover it in detail in a podcast.  So I wanted to let our listeners know that I'm going to, the issue of the secure erasure from SSDs.



And many people also tweeted in response to my comment last week, Leo, you'll remember, about one listener who was annoyed that the podcast was so long.  Well, we got...



LEO:  We got a response back.



STEVE:  Oh, not "a."  I mean, many people took the time to say, Steve, I love it the way it is.  Love you and Leo bantering when you do.  Listen for information and entertainment.  Go for it, and please don't feel like the guillotine is going to drop if you talk a little longer.  So I wanted to acknowledge and thank everyone who thinks we're doing just the right thing here.



LEO:  Yeah.  I mean, this is the show with the least fluff of any show on the network.  You could rightly complain that other shows are padded with BS.  But not this show.  This show is dense with material.



STEVE:  Well, I have a little BS.



LEO:  Okay.



STEVE:  Here's just...



LEO:  Once in a while is fine.



STEVE:  I'll ask our listeners to indulge me because this was really neat.  A listener of ours named Kent Nelson referred us, meaning GRC, to a posting he found on MediaSmartServer.net.  This was posted February 24, 2011, at 3:12 a.m., so somebody who was up in the wee hours of the night.  And this is on a board under Windows Home Server troubleshooting and support.  And so this person whose name I don't know, but I thank him, said, "I came to this board because I have a particular problem with my Windows Home Server.  People were helpful, and I wanted to pay back by contributing a little.  Surfing through the topics, I see the same themes recurring over and over again, themes that I recognize from my day job.  It would be a game of Whack-a-Mole to answer each of these individually.  So here is a piece of advice to all.



"Firstly, what is my day job?  I run an IT help desk company focused on the home market.  Our workshop processes a vast number of PCs from every manufacturer and with every conceivable configuration.  When you deal with thousands upon thousands of machines, patterns start to emerge.  The pattern that I am recognizing from your posts is disks with health problems.  Not the blindingly obvious, disk-has-stopped-working-altogether type of health problems - the system itself will tell you about those - the much more subtle problems created when a drive starts to have low-level problems.



"Modern disks are miracles of engineering.  It is a true wonder that they work at all.  In fact" - this guy sounds like me, but it's not me.  "In fact, when you look under the covers, you can see just how close to the edge they're actually operating.  These things are throwing millions of errors as they try to read data, fail, and have to go back and try again.  None of this is surfaced to the operating system.  You have to use special software that talks to the SMART subsystem on the drive to get at such data.  If a drive has a problem with just a tiny part of its surface, the performance of your computer can fall dramatically as the drive keeps trying to get the data.



"A good number of those posts with folks seeing machines behaving in flaky ways, or working one time and not the next, sound like disk problems to me.  This should hardly be a surprise.  With your Home Servers, you guys are dealing with many more drives than people with a single drive in a single PC.  You are bound to run into more drive problems.  The problem is, the operating system gives you no visibility of such problems.  It simply waits for the drive to do its thing.  The only fault you're ever going to know about with the operating system is complete failure.  All the subtleties up to that point, and you can be sure there were many, will be lost.



"There are tools for monitoring the SMART subsystems on your drive, but we have found them to be of very limited use in the workshop.  I only know of one tool that really goes to the depth of the drive and corrects these faults.  It's called SpinRite."  And he says (www.grc.com).  "I should say this post is not an advertisement for the product.  I have no connection with the vendor.  If I knew of alternatives, I would list them here, but I do not.  To the best of my knowledge, this is the only tool that does this, and it is extensively used by professional workshops throughout the world.  Certainly, it gets run on every spinning drive that comes through our workshop.  He says: (It is not suitable for SSDs.)"



He says:  "I have personally seen it bring back to life nonbooting PCs, recover data that was thought to be beyond recovery, and speed up systems to no end.  And I have seen this numerous times.  There are techies who say that such a thing is impossible and could never work.  But they are also the people who have never tried it.  Do not take my word for it.  Ask around.  The only downside is it is not free ($89).  However, to folks like you, with terabytes of data to protect and manage, it is a reasonable investment.  On my own personal kit I run SpinRite on any new drive before deploying it, then again after each six months of use.  I get longer life and much lower failure rates.



"I suggest you consider running this product on any PC or server that displays any odd behavior.  You need to extract the drives from your Home Server and connect them directly to the motherboard of a spare PC because you need to boot from a CD to run it, which is not an option on a headless server.  It will work via a USB adapter, but this is very much second-best, so plug the drive into the motherboard.  It takes an age to run on large drives, but there is no way around that when you read the documentation on what it is doing.  Do not be put off by their website, which is very amateurish."



LEO:  No, it is not.



STEVE:  Well, that's what he wrote.



LEO:  Okay.



STEVE:  "This is a geeky product for geeky people that's been around for more than 20 years now.  I apologize that this post is unbalanced in that it is focused on a single product, which makes it feel commercial.  If foreign members know of anything else which can perform these tasks and has a good reputation, then please comment, and we can add some more balance.  I suggest the moderators consider making this a sticky post, as with an audience like this, managing lots and lots of big drives, disk health will be a crucial topic.  You will also save yourself a lot of time trying to whack each of those moles."



LEO:  Yeah.  Boy, that's - you must be thrilled about that.  I mean, that is great.  And by the way, I don't know what they responded in the forum, but I don't know of anything that's anything like SpinRite.  I mean, it's...



STEVE:  No, there was nothing.  There were some people who said, yeah, we agree.  And they were some Security Now! listeners, too, so that was neat.



LEO:  It's the one and only.  I mean, I suppose, as SSDs become more prevalent, it may be the last of its kind; right?  I mean...



STEVE:  Yeah.  Yeah.



LEO:  I can't imagine at this point, I mean, I don't know how much longer spinning drives will last.  I guess we've got another decade or so.  But...



STEVE:  Oh, Western Digital just bought Hitachi.  Did you see that in the news?



LEO:  No, I didn't see that.  Interesting.  Hitachi bought those IBM drives.



STEVE:  Yup.  Hitachi bought the technology from IBM.  Now WD has acquired from Hitachi.  So it's WD and Seagate, pretty much.



LEO:  Wow.  Wow.  That's too bad.  I liked those Hitachi drives.



STEVE:  Oh, that was absolutely my favorite.  When I could choose, that's what I - yeah, I'm with you, Leo.  They were great drives.



LEO:  And now, let's talk about Stuxnet.



STEVE:  So what we have is, without argument, a true cyberweapon which was, over the course of about nine months from the time it was first seen to the last version that was seen, was under development.  Symantec called it the most complex threat they had ever analyzed because of the number of different functions that it contained and also the fact that it was very cross-platform.  It was, or is, because it's still out there a little bit, but it is a Windows-based worm, but it's designed to infect non-Windows-based systems.  Many things are absolutely no longer in doubt.  It cannot be doubted that this was directly targeted at the Iranian nuclear enrichment project.  And I'll explain exactly why we know and how we know what we know.  But it contained multiple zero-day exploits bundled in a Windows rootkit to hide itself from anyone.  The first ever PLC, or Programmable Logic Controller rootkit, that had never been done before.  It incorporated antivirus invasion techniques that I'll detail in a minute, where it literally looked to see what AV tools were in the system and knew how to get around them by version number.



LEO:  Wow.  Oh, wow.  Talk about targeted.



STEVE:  Oh.  It had, well, and what that means is, think about it, it means the people who developed it ran it in these different AV environments and watched the AV tools capture it.  See, because one of the things it needed to do was it was trying to remain hidden.  So, for example, after it replicates itself three times from a USB stick, it removes itself from the USB stick.



LEO:  Oh, wow.  Oh.



STEVE:  To minimize the chance of discovery, it figures, okay, I have spread onto three new systems, me, the USB stick.  So I'm going to now - Stuxnet sees that because it's logging and recording what it's doing, and then it deletes it from the USB stick so that someone later wouldn't see it and wonder, whoa, wait a minute, what's this?  So, I mean, it's all of this stuff.  It's got process injection and hooking code that allows itself to insert itself in other processes in the machine; an array of network infection techniques, including a peer-to-peer technology that allows it to spread within local area networks; and a command-and-control interface.  It connects to a couple of domains that I'll describe in detail in a minute, in order to report on its existence and to give those domains the opportunity to update the code.  So essentially a binary package comes back which is actually encrypted.  It's decrypted and then executed in order for Stuxnet to evolve over time.



So it's, functionally, it's able to self-replicate through removable drives, as I was saying.  And that exploits a vulnerability which Microsoft knew about.  And we've talked about it, it was that .LNK vulnerability that where just - then you'd have to open the link, a shortcut.  Just viewing the shortcut in Windows Explorer could cause that file to execute by malforming the way the link file was made.  And the rootkit which is hiding this knows exactly how many bytes long the file is; and when Windows Explorer attempts to retrieve that from the directory, the rootkit says there's no file here.  So you just don't see it, even though it's sitting there on the drive.



So it's also able to spread through the LAN using a vulnerability that was also known for some time in the Windows print spooler in order to - so everyone has this service running in Windows by default.  The LAN is a trusted environment.  So unless those Windows machines were patched current, they would have this problem.  Oh, which is a perfect example for one of the questions we were asked last week.  Remember the guy whose company had 15 machines behind a "Windows Server," and they were back on SP2, and no one was patching them.  And he said, you know, is this a problem?  Well, here's a perfect example of where machines on a LAN have visibility to each other, and the Windows firewall protects you from WAN-based things, but because Microsoft wants to make things easy, like filesharing, does not protect you from LAN-based threats to the same degree.  So if you're not patched, if you've got this Windows print spooler service listening, then Stuxnet would have been able to infect all the machines on that network.



And there's an SMB exploit, another well-known problem in the server messages block, the so-called file and printer sharing service, which Stuxnet also knows.  So machines that were kept really current would have been safe because these were known and patched vulnerabilities in several cases.  But there were, and still are, even today, Stuxnet is using some privilege escalation exploits which have never been made public, which it uses in order to get around these AV devices.  So it copies and executes itself on remote computers through network shares.



And Siemens has a version of Windows called WinCC, which runs something called Step 7, which is their - it's all Windows hosted.  And this is sort of the programming and code-writing and debugging tool to which you connect Siemens-based programmable logic controller devices in order to sort of download the code that you write.  PLCs are programmed in sort of a - they have, like, an assembly language and also sort of a simple, step-based, basic language in order to tell them what they want to do.  They're pretty simple-minded.  But so you do all your authoring of this stuff on a Windows-based machine, then hook up the device and download it into the PLC.  Stuxnet is able to update itself through this peer-to-peer mechanism.



So through using remote procedure calls, RPCs, Stuxnet sets up a server when it installs itself in a - when it infects a machine, and then sends out a broadcast for any other machines to see if they are of a later version.  And, if so, they share their updates with older versions of Stuxnet.  So it's constantly keeping itself up to speed.  And it exploits a total of four unpatched Microsoft vulnerabilities, two of which have never been disclosed publicly, as I mentioned before.



Okay.  So what's significant about this, when you look at how comprehensive it is, is that it could never have been designed blind.  That is, this is just - this is not something that script kiddies, no matter how much they want to, could create.  In order to pull this off, you need, first of all, essentially schematics of the target.  Somehow, someone got, through information leakage, very detailed description of what it was that was going on in Iran's nuclear enrichment program.  And of course that's not information they were letting go of.  We know that because the targeting side of Stuxnet only fires when it sees a specific configuration of frequency converters tied onto this programmable logic controller which matches the fingerprint of what was going on in Iran.



The problem with Stuxnet is that it's a little bit blunt in that it is a propagating virus.  A hundred thousand copies of it are, like, infected Windows machines all over the place.  So although it was dispersed in a targeted fashion that I'll talk about in a second, because of these abilities it has to propagate, it got loose from the targeted companies, the five companies with connections to Iran that were infected with this.  And it got out into the wild.



Well, we wouldn't want this thing infecting our own nuclear power plants or opening the floodgates on the Hoover Dam or anything else.  I mean, programmable logic controllers are used for all of these things.  This is like the way process control systems are run.  And so you don't want to let something loose that is this powerful that is going to misfire.



LEO:  That's like weaponized anthrax.  You've got to have some sort of protocol.



STEVE:  Yes.  And so what that meant was that the designers of this thing had to know exactly what it was going to find if it could get into the enrichment plant.  They had to know exactly what was there because, I mean, there were versions of it all over.  I mean, it was found in thousands of other Siemens systems.  So this thing, I mean, this was - this upset a lot of people who...



LEO:  Oh, yeah.



STEVE:  Because, I mean, this got into many of these Siemens PLC systems.  But because the equipment that it found connected to the programmable logic controller didn't exactly match what it was designed to find, they didn't do anything malicious in those cases, thank goodness.  But so you have to know exactly what your target is.  And then, as I had mentioned in a prior podcast as information began to come out, I remember saying to you, Leo, a few months ago, somebody had to actually have this equipment.  I mean...



LEO:  You called it.  You called it totally.



STEVE:  You had to set it up.  You had to, I mean, you don't just write code and say, well, hope this works.  I mean, all of this had to be prototyped.  So you had to have frequency converters and basically mock up what is in Iran in a lab somewhere in order to write the code to make this go.  So basically, as Symantec put it, a mirrored environment had to be created in the lab.  Also remember that this thing, in order to work, it needed to get into the kernel in order to set up a rootkit to protect itself.  It needed to have digitally signed drivers.  And we know where they came from, remember?  They came from Realtek and JMicron, two companies in the same industrial park, same physical location.  So it is believed that some agent broke into and physically compromised those facilities to steal their private keys for their credentials.



LEO:  Wow.  There's a novel here.



STEVE:  Oh, I know.



LEO:  I mean, what a book.



STEVE:  It really is.  I mean, this is real.  You couldn't, I mean, this is - it's incredible.  So some agent, you know, covert, undercover, in the middle of the night, went into RealTek Semiconductor and JMicron and did whatever they had to do to get their private digital signing keys and made off with them so that the drivers could be signed for this to all work.  So, I mean, there are so many facets to this.



Now, the problem with these PLC-based machines, these programmable logic controller authoring machines, is it is understood that security is a concern.  So they are never directly connected to the Internet.  So the designers of Stuxnet understood that they were not going to infect the machine.  But think about it.  As a consequence of not being connected to the Internet, you have to get data in and out of them.  So it's thumb drives.  Which is the infection vector.  If you're going to have a standalone machine because you're worried about security, well, you're going to use thumb drives.



And so a lot of attention in Stuxnet is paid to infecting removable drives, protecting their contents, keeping the contents invisible.  And it is believed that essentially that strategy is what worked, that machines that were connected to the Internet got infected with Stuxnet and then, in the normal course of transferring data, updating files, here you've got this machine running your nuclear enrichment facility, and you're all proud of yourself that it's not on the Internet, so nothing can get to it.  Yet there's a new version of the PLC software.  So you download it over on this machine...



LEO:  Oh, boy.  Oh, boy.



STEVE:  ...load it onto your thumb drive, and then bring it over to the not-on-the-Internet Iranian enrichment plant controlling computer, and bang.  That gets it infected.  So when Stuxnet arrives in a new machine - and I have it written down here somewhere the domains that it queried.



LEO:  I should look.  I have your notes.



STEVE:  Here it is.  It's mypremierfutbol.com, so www.mypremierfutbol.com and www.todaysfutbol.com are two servers which originally pointed into Malaysia and Denmark.  When the worm was able to get itself installed, it would look up the IPs of those DNS domains and send a package of sort of status, including its log of its entire history of infection.  It had a timestamp, information about the OS version, and additional information, and that log.  So over the time that Stuxnet was known about, Symantec was able to collect over 3,280 unique samples, individual instances of Stuxnet, each with a different log because each log tracked basically the lineage, all the ancestral versions.  As it had infected one machine after another, it kept appending to this log.



What they know as a consequence of being able to mine these logs, this 3,280 different instances of Stuxnet, is that there were three events targeting exactly five organizations, each having a presence within Iran.  From those three events, targeting five organizations, 12,000 infections can be traced back to exactly those five organizations.  So basically - and we don't know how Stuxnet was planted in those organizations.  Could have been a conspirator.  Could have been emailed in.  Somehow they got within those organizations.



The first organization, and they remained anonymous in this report, was targeted twice, in June 2009 and then again in April 2010.  The second organization was targeted three times, in that June '09 attack, the second one in March of 2010, and then in May of 2010.  The third one was targeted once, the third organization targeted once in July of 2009, as was the fourth organization.  And the fifth one was targeted once in May of 2009, but had three initial infections because the same initially infected USB drive was inserted into three different PCs.  Oh, yeah.  So they were like, it was targeted once, but it was, like, salted in three different locations within that organization.  And so Symantec was able to track back all the way back to those very original three instances within that fifth organization.



The shortest span of time between the compilation of Stuxnet, where it was, literally, its source code was compiled, which inherently binds some date information into the code, to an initial infection was 12 hours.  So this thing was built and, in at least one case, within 12 hours an infection was planted.  The longest span between compilation time and infection was 28 days, and the average was 19.  So this whole thing took place in the latter half of 2009 and the beginning of 2010.  And so they know from, again, looking at these logs, that there were three attack waves:  essentially June 22 in 2009, March 1 in 2010, and April 14 in 2010.  And Stuxnet was getting better.  The March 1st attack was a much more capable worm than the June one.



So if you can sort of put yourself in the mindset of the people who were doing this, who designed this, they had a goal.  And they had a system which was providing them feedback.  And so that was a mixed blessing because obviously Symantec is able to determine everything they have because of the feedback which the worm provided to its command and control servers every time it propagated.  But you could see also that, while it was unknown, before it became known, this was vital information for the designers because it allowed them to profile the performance of this weapon they had written in the wild, and these were spear attacks.  I mean, they were somehow sending agents into Iran or into affiliated companies and planting Stuxnet there.  We know that because of the dispersion of the virus.  Of all infections of Stuxnet globally, 58.31 were in Iran.  58.31 percent, sorry.  58.31 percent.



LEO:  That's pretty effective.



STEVE:  So, yeah.  Like...



LEO:  Good job.



STEVE:  Nearly 60 percent were in Iran.  But that's just machines infected.  So that means it wasn't released in Santa Clara and all went there because all the machines between here and Santa Clara would be infected.  I mean, so the point is that it started there somehow.  Somehow it was planted in that location, like near to its goal, and then spread locally.  And of course due to the fact that it was a worm, and used unpatched but known vulnerabilities of Windows, it did get loose.  Yet as I said, the weaponized end, thank goodness, was so tightly targeted that it didn't do damage to all the other Siemens Systems that it sought out and did infect, 18 percent in Indonesia and 10 percent in India.  And then it fell off.



And also the Siemens Step 7 system that I mentioned, of the infections, 67.6 percent of the Iranian infections had Step 7 software installed.  So it was, again, it was seeking out and looking for these process control-based systems.  8.1 percent in South Korea of the infections had Step 7 installed, 5 percent in the USA, and 2.18 in the U.K.  So it did, for example, in the U.S., 5 percent of the infections of Stuxnet were Siemens-based systems.  So it was infecting U.S.-based process control systems.  And the good news is the flood gates of Hoover Dam didn't get opened as a consequence.  So...



LEO:  Well, I think it's really clear that, well, we know - in fact, I think we know who did this now because there have been some revelations.  But I think it's pretty clear that they were heavily targeting.



STEVE:  Yeah, well, and this evidence, I mean...



LEO:  And effectively.



STEVE:  I guess what I find so interesting is that, if you really take advantage of the information coming back to you, you can, as you said, Leo, this is a plot.  I mean, we can work out what had to happen in order for this result.  In order for the drivers to be signed with good driver certificates from two innocent companies, somebody had to go and break into them and get their private keys in order to sign the drivers.  Stuxnet the virus is aware of Kaspersky KAV versions 6 through 9, the current McAfee products, AntiVir, BitDefender, eTrust, F-Secure, Symantec and Symantec Common Client, ESET's NOD32, and Trend's PC-cillin.  It has code in it to specifically see that those products are in the system.



And remember, one of its priorities is stealth.  It very much wanted to get its work done before it was being found.  So what it did was it would look in the system to see if these things were present.  And, if so, it would look at the EXEs to determine the versions, and had version-specific behavior, so it was designed to go underneath the detection.  And in several cases it did that by using either one of two because it ran on all versions of Windows, XP through Win7, not earlier than XP.  It used vulnerabilities that had never been published for getting admin privileges, if it was not running with admin privilege, and it used those in order to place some kernel-level hook games in order to install itself into processes in a way that specifically would not be detected by these intrusion detection systems that were designed to detect exactly this behavior.



The rootkit that it installed, even with these tools, with these AV systems in place, it was able to install a rootkit, robustly and reliably, and filter the API calls that Windows was making to the kernel such that, if a file with a .LNK extension was going to be enumerated in a directory search, and the file was 4,171 bytes long, the rootkit would just remove that from the listing because the malicious link files that Stuxnet used were obviously 4,171 bytes long.  And if a file was named "~WTR[FOUR DIGITS].TMP," whose file was between 4Kb and 8Mb, but the sum of those four digits, modulo 10 was zero, then that file would also not appear.



LEO:  And why would that - I don't understand what the point of that is.



STEVE:  And so, well, so this was - Stuxnet needed some flexibility in its payload.  So the link files wouldn't be seen, but it needed other files from time to time that it might need to hide.  And so what it would do is it would design - it designed the rootkit filter such that - sort of with a pattern match.  So that if the pattern was "~WTR[FOUR DIGITS].TMP, and if the sum of those digits added up to zero modulus 10, then, that is, added up to 10, 20, 30, 40, for example, or zero, I guess, then that triggered the rootkit not to show that file.



LEO:  So they could hide in plain sight.



STEVE:  Yes.



LEO:  It would be an obvious rootkit file.



STEVE:  Precisely.  And it had to coexist.  So this was on the thumb drive or on the system where Stuxnet was installed.  It had to coexist with other things.  And it would look, when it was going to jump onto the thumb drive, it would verify that the drive had not just been infected by comparing the files with the current time.  It would verify that the infection source was less than 21 days old.  Meaning that after three weeks...



LEO:  Wow, it expires.



STEVE:  Yes.  It would stop trying.  It would just...



LEO:  So cool.



STEVE:  It was.  It was just brilliantly designed.  So the point is, again, it was trying to not get discovered.  So it gave itself three weeks, on a given system, it gave itself three weeks to infect all the drives it could.  And after that point it would go silent and just not do it anymore because, again, it figured, hey, if I haven't done it within three weeks, then - and who knows what the developers knew about the protocol being used in Iran's nuclear enrichment facility.  They might have known, for example, that something happened every two weeks or every week or something.  So if they were able to get onto the machine that was one step away from the machine doing the development and controlling the programmable logic controller process control stuff, if they could get to that machine, and they knew that, like, there would be some thumb drive-based communication between those two within three weeks, and if not, then they're just not on a machine where that's going to happen.



LEO:  Sounds like they really knew what they - not only what they were doing, but where they were going to be.  I mean, this was so clearly targeted.



STEVE:  Yes.  And the drive, the thumb drive, had to have had at least three files and five meg of free space because you wouldn't want to run into, I'm sorry, you don't have enough room on your drive to hold our rootkit and our Stuxnet virus.  So one of the files, WTR4141.tmp, and if you think about it, 4141, that adds up to 10, which is zero modulus 10, that would - it was sort of like the advance guard that was a small bit of code that hid its companion file, ~WTR4132.  And again, 4132, that sums to 10.  So that's zero modulus 10.  And that contained the entire Stuxnet payload that jumped over onto the thumb drive.



When they finally got there, one file, which was a DLL on this Step 7 PLC programming computer, the DLL was s70tbxdx.dll, that got renamed to, instead of the last characters being xdx.dll, it got renamed to sxs.dll.  And a replacement s70tbxdx.dll, which was the PLC rootkit, it was installed.  So essentially this DLL that was - it's very comprehensive.  It has, like, 140 different, what Microsoft calls "exports."  Those are, like, functions that the DLL can offer.  The replacement file didn't duplicate all of those.  For almost all of them, it simply forwarded those calls to the fake DLL to the real one because it knew what it had renamed the real one.



So when 135 of those different functions were called, it handed them off to the original DLL to work correctly.  But the few that it needed to alter allowed it to intercept those functions on their way to the Siemens programmable logic controller and essentially add its own code to the code that was being downloaded and arrange for that code never to be visible, never to be seen.  And so everything we talked about was for just the sake of getting a bit of code, custom-written code, appended to the front of the code controlling the PLC.  And it also had to be that code that looked around at what it was connected to and knew whether to do anything or to stay inert.  And so that's the history of the world's first, I mean, truly weaponized Internet worm.



LEO:  Do you think the people who wrote this were security researchers?  Virus authors?  Do you think they took existing code and modified it?  I mean, it sounds fairly sophisticated.  



STEVE:  Anyone who...



LEO:  Maybe, like, they contracted out, I mean, look.  Israel did this; right?  We know that.



STEVE:  Yes.



LEO:  We've heard that in fact they had exactly the same setup intentionally.  It was pretty clear.



STEVE:  Yes.



LEO:  And they had, of course, they had means.  They had the motive because they didn't want Iran to have a nuclear bomb.



STEVE:  Yeah, I would say they probably did it with help.  I mean, I believe that there are resources in the U.S.  And, I mean, we certainly would not be hostile to the intention of keeping Iran from getting a nuclear bomb.  And the argument was that that's what they were using this nuclear enrichment for, despite their denials, saying that they just want it for electric power generation.  So you have to think that, within the NSA, within our own government, and sort of shady organizations, I mean, we were talking about, what is it, HSGary is the company?  Or HSB?  I can't remember the name of the company [HBGary].  But it's a major sort of hacking contractor that...



LEO:  Right.  This is what they do.



STEVE:  ...organizations in Washington use for their own purposes.  And it was those guys who created a device, a Firewire device that allowed the guts to be sucked out of a computer just plugging it into the Firewire port to DMA and copy the contents out.  And that came from that company.  So there are even commercial organizations - it's where our tax dollars are going - that have this kind of competence and are able to participate in projects like this.  And you know, Leo, how many times in the early days of this podcast, like Episode 2 and 3 and 4, when we were looking at sort of interesting Windows viruses and worms and things and commenting, isn't it nice, I mean, and aren't we really lucky that they're not malicious?



LEO:  Right, right.



STEVE:  So many of these things - and I scratch my head.  It's like, why - okay.  I'm glad that they're not doing bad things, but...



LEO:  Why not?



STEVE:  ...who's going to all the trouble of creating them, just to sort of have them float around out there?



LEO:  They're practicing.



STEVE:  That's what they did.  They just floated around out there.



LEO:  I think I remember the very first virus was written by that guy Morris...



STEVE:  The Morris Worm.



LEO:  ...the Morris Worm, just to see what would happen.  He wasn't malicious.



STEVE:  No.



LEO:  It escaped.



STEVE:  And it really hurt his reputation a lot.



LEO:  Yeah, his father was a very famous security guy.



STEVE:  Exactly.



LEO:  And so I think that some of this in the early days was just people, you know, hackers are curious.  And I could see how tempting it would be to say, you know, I could create something that would spread itself.  Wonder what would happen?  And just do it.  I can understand that.



STEVE:  And within the white hat community we still hear echoes of, well, boy, you know, why can't we write a disinfector worm?



LEO:  Yeah.  Yeah.  Remember that?  Yeah.



STEVE:  It's like, I know you want, yeah, I know you want to.  But sorry, even if you're altering someone's machine, and you think that's a good thing, you're doing it without their permission.



LEO:  Well, and I think ultimately, while it sounds like Stuxnet was pretty carefully crafted not to do harm and was very specifically targeted...



STEVE:  Oh, danger.



LEO:  ...it's still a bad, bad, bad, bad, bad idea.



STEVE:  Yeah, and Leo, imagine if it had misfired.



LEO:  Right.



STEVE:  Imagine if there had been, literally, collateral damage from the thousands of Siemens computer systems.  I mean, it went in, and it replaced a DLL.  I mean, we depend upon these process control systems to run big plants.  And it was in there replacing a DLL in order to get access to the programmable logic controller, to then go add code to it, and hope that it didn't do the wrong thing.  I mean, it was gutsy.



LEO:  Look, we know there is no such thing as perfect code.  And we also know that programmers have a little bit of hubris.  And there's probably not a programmer alive who thinks he can't write perfect code.



STEVE:  Yeah, and not one alive that ever has.



LEO:  Yeah.  If it were that easy, everybody, anybody would do it.  What a great subject.  Show notes, as always, are on Steve's site, GRC.com.  And I put the show notes in our TWiT wiki every week.  It's the one show I actually do that because you have such good notes.  I always make sure they're in the wiki at wiki.twit.tv.  You can get 16KB versions of the show at GRC.com.  Steve has transcripts, too, which is really great.  And this is the kind of show that I could imagine a college class or somebody who's teaching security might very well want to get people to listen to or read because it's so interesting.  John is asking, was there an Easter egg in Stuxnet?



STEVE:  You know, actually I skipped over that, but...



LEO:  There was?



STEVE:  Yeah, well, there were some odd things.  Like there were some codes which, if you took it to represent a date, was the birthday of somebody famous in Iran.  I mean, it was those sorts of things, really subtle.  And in Symantec's report they made a point of saying, look, this is what Wikipedia says about this, I mean, about this particular collection of characters.  But remember, the people doing this would have strong reasons to be pointing fingers to someone else.  So we absolutely couldn't take that as ego out of control, but rather just additional subterfuge.



LEO:  Red herring.  It could be a red herring.



STEVE:  Precisely.



LEO:  Wow.  Oh, I want somebody to do the - some intrepid journalist to do the research on this and write a book.  What a fascinating story that must have been.  I don't think we'll ever know because...



STEVE:  No.  Because, I mean, it really, oh, thank goodness it didn't misfire, Leo.  As I really came to understand what this thing was, I was thinking, oh, goodness.  I mean, this was really - this was potent.



LEO:  Well, I can guarantee you in future Security Nows we'll be talking about worse.  Absolutely.  Sad to say.



STEVE:  Well, we'll be here.



LEO:  Yeah.  291 episodes in, and no sign of stopping.  Steve Gibson, he's a machine.  Visit GRC.com for your copy of SpinRite.  You've got to have it.  If you've got a hard drive, you've got to have SpinRite.  And of course if you've got questions, we do a feedback episode every other episode.  And now is the time to go to GRC.com/feedback, ask those questions.  Maybe you'll get included in next week's episode.  And tune in every Wednesday at 11:00 a.m. Pacific, Apple permitting.  Thank you for moving last week.  11:00 a.m. Pacific, 2:00 p.m. Eastern time at live.twit.tv to watch.  Steve, thanks so much.



STEVE:  Thanks, Leo.



LEO:  We'll see you next time on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#292

DATE:		March 17, 2011

TITLE:		Listener Feedback #113

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-292.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 292 for March 16th, 2011:  Your questions, Steve's answers, #113.



It's time for Security Now!, the show that covers your security and privacy online with the man of the hour, Mr. GRC, Steve Gibson, of Gibson Research Corporation.



STEVE GIBSON:  Or hour and a half, as the case may be.



LEO:  Or two, you know, whatever.  The man of the next 90 minutes or so.  Hey, Steve.



STEVE:  And we spared our listeners about 40 minutes of you and me yammering about Japan and iPad 2, so...



LEO:  And diets.  And diets.  Which is the thing they least wanted to hear...



STEVE:  And what is it that makes you fat.



LEO:  Yeah.  But I think that the earthquake stuff is very interesting.  And maybe just a little footnote, you found a very good explanation of how these boiling water reactors, the kind that are in Japan, work.  Almost looks like...



STEVE:  With diagrams.



LEO:  Yeah, like how things work.  It's on the Nuclear Regulatory Commission website, NRC.gov.  They have, I guess, a lot of teaching material, student material.



STEVE:  I did tweet all this, also.  So if anyone wants to get links for all this, you can just put in - go to Twitter.com/SGgrc, which will be my Twitter feed, and you can scroll back a little ways because I tweeted all these links to the stuff that I was finding.  The MIT article that you found, that really great blog posting, Leo, and also this diagram.



LEO:  Yeah, this is just one last point, which is that those of us who are technically inclined, which I presume is anybody listening to Security Now! for sure, just want to know facts.



STEVE:  Yes.



LEO:  And the problem is there's so much polemic and rhetoric associated with your position, whether pro or anti nuke, and I just want to know the facts.



STEVE:  And the blondes are nice to watch on the news, but...



LEO:  But they're nitwits.



STEVE:  They're not nuclear scientists.



LEO:  Even CNN, nobody has really done a very good job.  I saw an explanation of how a nuclear reactor works yesterday that was just wrong.  And, look, we were talking, Steve and I were talking, I remember when I first got an Atari there was a great nuclear simulator called SCRAM.  And it was very simplified, of course, but you had to be - you were a nuclear operator, nuclear generator operator, and you had to run the rods and scram the rods and so forth.  It was so much fun.  And I learned a lot on the basics of how a nuclear generator works.  I wish that game were still around.  I'm going to see if I can find it.  Maybe an emulator would have it.



STEVE:  I was reminded that I tweeted this morning, I found a link to a really neat professor, nuclear professor guy, who's got hair like Einstein. 



LEO:  Well, that's his credential right there.



STEVE:  And I tweeted, I said, for your less techie friends, because people who follow me probably are on the techie side, for your less techie friends, you might want to send this link to a kindly nuclear professor explaining...



LEO:  A little German accent?



STEVE:  ...very simply how reactors work.  He did a great job talking about the boiling water reactors in Japan, so...



LEO:  This was the game.  These are screen shots.  Chris Crawford did it, who is a very famous simulator designer.  And you learn a lot from stuff like this.  I wish these kinds of games were still around.



STEVE:  Simulations actually are very, very powerful for teaching these kinds of concepts.  I mean, simulations of anything, physics simulations, for example.



LEO:  Yup.  I'll see if I can find a - it would be really fun to find an emulator.  I know there's good emulators, Atari emulators out there.  So I'm sure I can find - if I can find the ROM, I can probably get it working.  That'd be kind of fun.  Somebody should make an Atari emulator for the iPad.  Wouldn't that be fun?  Apple would never approve it.



STEVE:  Yeah, it could run all the classic stuff.



LEO:  Yeah.  Apple would never approve it unless Atari did it.  So let's get to the news.  This is a Q&A session; right?



STEVE:  Yup, #113.  But Security Now! #292, so don't let that 113 throw you off.



LEO:  Very confusing.  We've got two numbers.  But we know you can handle numbers.  That's why we do it.  Steve, what's the latest security news?  Speaking of perfect.



STEVE:  I think you should settle for amazing, Leo.  You are amazing.



LEO:  Amazing, if not perfect.  Imperfectly amazing.



STEVE:  We'll be happy with amazing.  So the good news is nothing happened.



LEO:  Yay.



STEVE:  In terms of updates since the pre-Pwn2Own flurry of updates last week.  We're going to cover in detail the consequences of the Pwn2Own competition shortly.  But no updates to talk of, to speak of.  Although we need some because exactly as I predicted, and shortly after we recorded last week's podcast, I got a little advisory update from Microsoft.  They send email when they revise their existing updates.  And I thought, hmm, what is that?  So I went to the advisory update.  And under "Why was this advisory revised on March 11, 2011?" it says, "Microsoft revised this advisory to announce that Microsoft is aware of public proof-of-concept code being used in limited, targeted attacks."



LEO:  Pwn2Own.



STEVE:  Users that, well, no, not - this is before that.  This was the MHTML vulnerability which we commented on them on Tuesday not patching.  They fixed other stuff.  And...



LEO:  Is it in IE9?  Because IE9 is now official.  Maybe they figured, well, we'll just update IE.



STEVE:  It's actually not.  It's in a library in Windows.  So...



LEO:  So it's everywhere.



STEVE:  Exactly.  It's accessible through the browser.  But it's a Windows DLL that you get to through the browser and you exploit through the browser, so it's very likely that you can get to it through IE9, as well.



LEO:  Great.



STEVE:  Now, again, the moment this happened I tweeted about it.  So that's one way you can find the link.  There is a Fixit.  And so I will say again, as I said last week, when I said last week we're probably going to shortly see exploits of this.  Well, now we are.  And the Fixit simply disables scripting in the MHTML pseudo protocol.  And the MHTML is MIME HTML, which is Microsoft's own format for storing a whole page in a single archive.



LEO:  Just like their web archive format.



STEVE:  It is their web archive format, which is .mht or something.



LEO:  Right, right.



STEVE:  And so that's the file format.  So you could argue that we never needed scripting in that anyway.  You want to snapshot a page, you wonder why you need to run JavaScript in that.  It's a vulnerability there that is the problem. So turn it off.  I mean, and leave it off.  Even after they fix it you could leave it off because lord knows whether they're actually going to fix it, or let alone when.  So we'll probably wait a month for this to get fixed.  So there is a Fixit that you can access to just simply disable the scripting for this particular file format, and everyone should do it because it just - no one needs it on.



LEO:  Even if you have IE9, even if you've updated, you should do this because it's not...



STEVE:  Yes.  Yes.  It's going to be - it's browser agnostic, across all their OSes and all their browsers.  Meanwhile, at the beginning of this week, Monday, Adobe confessed to knowing of a new Flash zero-day exploit.  Our old friend the authplay.dll is back for more.  We keep talking about authplay.dll and various ways that you can access it.  In this case, it can be accessed through Flash, and there are exploits in the wild.  It's exploited with a Shockwave Flash embedded in a Microsoft Excel file, delivered as an email attachment.  So when Windows views this Microsoft Excel file, it allows the Shockwave Flash to run because you've got Flash installed.  And that accesses this authplay.dll vulnerability.  And it's across everything - Windows, Mac, Linux, Solaris, and even Chrome and Android platforms.  So nothing to do about it at this point, unfortunately.  Hopefully Adobe will get us a fix shortly.  I think they'll do it out of band.  Their quarterly update concept isn't really working very well.



LEO:  It only works if you only have bugs every three months, you see.



STEVE:  On their page they said, well, because our 10.x, I think it was, was it Flash 10?  I don't - no, it wasn't Flash, it was Reader 10.  The Reader 10 sandbox does contain this.  We won't be updating that until July.  And that's like, okay, wait, March, April, May, June.  Okay, well, that's fine.  Now they're saying there's containment there, so they're really trying to not update when they don't have to.  But they're going to have to update Flash here any day now.  So they are working on a fix, so maybe next week we'll be talking about a fix for this.  In happy news, Twitter has added always-on HTTPS to their site.



LEO:  Yay.



STEVE:  Much as Facebook has, kind of, as we talked about last week, that they turn it off, Facebook, that is, turns it off if necessary.



LEO:  At the drop of a hat.



STEVE:  Yes.  But Twitter has it on.  So what that does is it enforces an HTTPS connection at Twitter.com.  You normally, if you were to go to Twitter with http://twitter.com, you would be moved to HTTPS for the login, to protect your login credentials; but then, as used to be the case with Gmail, you'd be taken back to nonsecure.  Now, on the settings page, the main settings page of Twitter, at the very bottom of the page is a checkbox that just says "Always use HTTPS," which everybody should go and check.  Now, the bad news is they haven't extended that over to mobile.twitter.com.  So even if you have it checked on your login at Twitter.com, you can log in at mobile.twitter.com, and it won't be secure.  But you can manually use HTTPS at mobile.twitter.com, and it will be secure.  So you're still responsible for doing that over on the mobile side.  And they have said that they're going to work on integrating those two so that the setting, your main settings page at Twitter.com will also have an effect over on mobile.



LEO:  Is that because mobile phones tend not to be fast enough for HTTPS, or don't support it, or is there an issue with HTTPS on mobile?



STEVE:  I can't imagine.  Remember that it's only when you initially connect that there's any...



LEO:  Overhead.



STEVE:  Yes, overhead.  I just think that they must have server farms that are not integrated.  And there isn't, like, separate account settings over at mobile.  So they just sort of haven't gotten there yet.  I imagine that they'll cross-enforce it as soon as they're able to get around to it.  And I did want to note, actually this is thanks to someone tweeting me, Simon Zerafa, who I think is in Wales, made a comment that, while in your settings of Twitter, go over to the connections option page and just scan through all the apps that you have permitted to have access to your Twitter and remove the ones that you're no longer using.  I removed five.



LEO:  Really good idea.



STEVE:  Yeah.  Because remember that we're authenticating Twitter apps.  And then so often we're, like, using different ones, and then we end up stopped using those.  I've switched over to TweetDeck.  I gave up on Seesmic because it was hosted on that horrible...



LEO:  Twitter's down right now, of course, so you can't do that.  But when it comes back up.



STEVE:  For those who are not listening live.



LEO:  And Twitter has deprecated these third-party apps because you're not seeing the ads.  So they're discourage- they say, don't write any new ones.  They're saying, well, if you already have one, okay.  But they'd prefer you didn't use those.  So I have a feeling in time those old apps will not - you'll be using Twitter.



STEVE:  I gave up, I was using Seesmic for a while.



LEO:  I like Seesmic.



STEVE:  And they moved it over to Silverlight, which is just a monster.  I mean, it makes Flash look good.



LEO:  Really.



STEVE:  It's just horrible.



LEO:  Oh, that's interesting.



STEVE:  It really is.  It's big, and it doesn't terminate when you shut things down, and oh, it's just awful.  So anyway, it would stop working reliably.  And I see everyone's using TweetDeck, so I thought I'd give that a shot, and I'm liking it a lot.



LEO:  Now, that's Air, though; right?



STEVE:  That is on Adobe Air, yes.



LEO:  You can't win.



STEVE:  I know.  So the Pwn2Own results from Vancouver...



LEO:  Oh, this was exactly as predicted.



STEVE:  Yes.  CanSecWest Security Conference.  Safari collapsed in five seconds.



LEO:  [Cackling] I'm sorry.  That was a cackle.  I apologize for cackling.



STEVE:  And remember that Apple plugged 62 security holes that morning.  They should have plugged 63.



LEO:  Apparently.  Charlie Miller wasn't worried.  Actually he didn't do it.



STEVE:  No, he didn't.  He did join up with another guy, Dion Blazakis, I think, Blazakis, and the two of them did an iPhone exploit the night before, working, like, a lot to make that happen.  So basically Safari, IE, iPhone, BlackBerry, all collapsed.  Significantly, neither Firefox nor Chrome did, although one researcher was a little annoyed because shortly before this he had given Google a heads-up on a cross-site scripting vulnerability which was not previously known, which he could have used to score himself a Chrome exploit for Pwn2Own, and 15 grand.  As it is, he only got, what is it, $1,337.



LEO:  Well, how dare they fix that exploit before Pwn2Own?  How dare they?



STEVE:  And in fact I think it was Charlie who did make a comment that this was sort of a downside of Pwn2Own because it was tending to cause researchers to hold back their disclosures because it was worth 15 grand, which is nothing to sneeze at.



LEO:  Well, and Google added 20 grand on top for Chrome.



STEVE:  Yes.



LEO:  So clearly that was cockiness on Google's part.



STEVE:  Yeah, but they and Firefox survived Pwn2Own.  So it took Safari five seconds to fall, although in fairness this was an exploit that was worked out well in advance so that, essentially, the guy who did it just walked up, plugged his code into Safari, and it collapsed.



LEO:  That's how it works.  It's not like you sit - I think people think, oh, you sit down at the machine and you try stuff.  No.  They know exactly what they're going to do.  They have a USB key, they plug it in, they go boom.



STEVE:  Right.  Ha ha.



LEO:  Ha ha.  Give me the money.



STEVE:  IE8 fell to Stephen Fewer, who's got a small, I think it's a one-man security company, Harmony Security he calls his company.  And his exploit was interesting because in order to do it he had to chain three previously unknown, unpatched vulnerabilities, together  The first two of then were to allow him to get past IE and Windows ASLR, the Address Space Layout Randomization protection, and DEP, the Data Execution Protection, which we've covered in depth in past episodes.  And then the third one, which he said was extremely difficult to exploit, got him out of the sandbox, which protects IE8.  He got out of IE8, he busted out of IE8's sandbox and wrote a file to the system, which demonstrates that IE8 sandbox was no longer in control.  And Microsoft immediately responded, we're already on the case.  And I thought, well, I feel so much better knowing.  Oh, joy.



LEO:  We'll fix that.  Next week.  Maybe the week after.



STEVE:  We're on it.



LEO:  Sometime.  It'll be fixed.



STEVE:  Exactly.  And then BlackBerry was brought down, the BlackBerry browser, by a multinational team who attacked the Torch and in seconds had it taken down.  So, and RIM said, oh, yeah, we're going to fix that, too.  So it's like, okay, fine.



LEO:  It's really interesting.  Wow.



STEVE:  I did want to note, as you've mentioned before, that IE9 was released a few days ago, Monday of this week.  It's final for download.  It's got so much in it that I'm going to give it a deep security review podcast, which we will do maybe next week.



LEO:  Oh, great.



STEVE:  I think it needs that.  And I did notice that, at the last minute, a do-not-track header was added, after the RC apparently, which is really good news.  I mean, I like that solution.  That's of course the one that we've talked about that Firefox has, where every query just says "Please don't track me," essentially.  Now, IE9 is already coming under attack for their tracking blocker lists, which I will go - we talked about it before, but as part of my full IE9 security review I'll talk about it in detail.  The problem is that users can load multiple lists, which both block and permit sites.  And the problem is that the logic that's used is such that, if you load a list which allows, that overrides any other list which blocks, which sort of seems like the wrong thing to do.  So I'm going to look into it in more depth, and we will cover it thoroughly.  But I did want to acknowledge IE9.  I mean, it is a big step forward.  I mean, this is a worthwhile browser.  You might argue that it's about 10 years too late, but Microsoft has really moved the bar and has created a very nice browser which I think is state of the art now, along with Chrome and Firefox, which I think are the - now we have three state-of-the-art good browsers.  I don't know if IE9, I don't think it's going to win me back because it took a lot to pry me away from it.



LEO:  Right, right.



STEVE:  I'm over on Firefox now and very happy.  I know that you're over on Chrome and very happy.



LEO:  Yeah, I love Chrome.  And I guess the results of Pwn2Own kind of justify our support of either of those.



STEVE:  Yes, yes, good point.  Our two browsers did not collapse.



LEO:  You have NoScript, which is a really good reason to use Firefox.  I don't know if there's a...



STEVE:  I do, although there is a script manager now for Chrome.



LEO:  Oh, there is?



STEVE:  Yes.



LEO:  Oh, good, I'll get it, okay.



STEVE:  Yes.  It's...



LEO:  What's it called?  Do you know?



STEVE:  I don't remember the name.  It's similar to NoScript in name, but there is one for Chrome.



LEO:  I will check it out.  I'm sure the chatroom will tell me in just a second.



STEVE:  And our friends, yes, our friends at...



LEO:  It's called NotScript.



STEVE:  That's it exactly.  I knew, I remembered the name was very much like NoScript.



LEO:  Chatroom says, "NotScript."



STEVE:  Yup.  NotScript for Chrome.



LEO:  Yeah.



STEVE:  And again, I do recommend, I know you don't like this selective scripting.  I'm using the temporarily allow scripting so often that I'm wishing now that NoScript - are you listening to this, Giorgio? - that NoScript could give me the option of a toolbar button.



LEO:  Oh, yeah, that's a good idea.



STEVE:  Instead of doing the right-click and then temporarily, just give me a button that says "temporarily trust this site."  Because I don't want to be adding sites all the time to my trusted list that I'm probably never going to go back to again.  There are sites like Amazon and eBay and Twitter and lots of sites that I'm using frequently, I would like to have on my permanent trust list.  But most of the time I'm just somewhere that I'm probably never going to go, I'm browsing around.  And that's where you want script blocked by default.  And I look, and I go, okay, looks like it's not come up.  So then I - it'd be easy, it'd be nice if it were easier to temporarily add a site to the trust list.



LEO:  Sometime we will talk about hashbang, because this is something that Twitter uses, a lot of sites are starting to use this as a way of making an AJAX-y page.  And when you go to Twitter.com, I don't know if you've noticed this because you have to allow scripting or you can't even load Twitter because instead of getting any HTML at all, you get a big lump of JavaScript, which then renders the page after the hashbang.  And this is being used more and more widely.  Gawker's using it on their sites.  And it really breaks the Internet in some very interesting ways and absolutely requires JavaScript.  You don't get anything.  There's no graceful degradation.  You get nothing.



STEVE:  And that's so dumb because all you have to do is put, I mean, put something in NoScript tags, and then you see that...



LEO:  Well, the reason they don't is they want these dynamic pages that, you know, if you go to Twitter it's rolling and scrolling and things are updating and all of these chunks are all loaded as AJAX chunks instead of HTML rendered.  So it would remove considerable amount of functionality.  But I think they have - I don't, well, this is a big debate going on in the...



STEVE:  So I guess what you're saying is that they have gotten themselves so committed to scripting that the site isn't at all usable with JavaScript disabled.



LEO:  And I think probably that's going to happen, Facebook and everybody else, because they want these - it's web apps.  They want their page to be not a page as we understand a web page, but to be an app.



STEVE:  I'm a JavaScript programmer now.



LEO:  You have to be.



STEVE:  No, I mean, in the last few weeks I started, pretty much from cold, and I have a JavaScript page running on GRC, a capabilities and compatibility test page which I'll be making public...



LEO:  Well, you can see how powerful it is.  I mean, it's incredible.



STEVE:  It's a very useful system.  And you're right, when you add this HTTP query facility, which we've had since IE5, that allows JavaScript to query back to the server and get other things, you're right that instead of this notion of going from, like, clicking links to go from page to page, the state-of-the-art approach now is that you go to a site which is an application, very much like Flash-enabled sites used to be, where you sort of stay on the same page and just browse around within that one page using Flash to take you to different things and do different things.  Now that same capability with JavaScript and the Document Object Model and DHTML and all that, has come so far that it's possible now to do that without using Flash, just using scripting.  So, yes, unfortunately, I think scripting is clearly the way sites in the future are going to be written and built.



LEO:  You should look at jQuery, which is of course a client-side library; and then Node.js, which is a server-side library.  That's what these sites are using.  Mostly Node.js.  It's very popular, gives you great functionality, really cool web pages that totally suck.  By the way, just an update.  Tim O'Reilly just tweeted - Twitter's back, but it just got back - has tweeted that the Mark 1 nuclear reactor design used at the Fukushima plant caused GE scientists to quit in protest at the time.  This is from ABC News, so, fascinating.  Story still coming out.  And I don't know, again, but there's a lot of information, and we've got to sift through it.  We're going to try to get some intelligent people on to discuss this at some point.



STEVE:  So our friends from San Diego and the University of Washington, whom we discussed last year hacking a car by hooking their laptop into the car's network, are back.



LEO:  Oh, boy.



STEVE:  They gave a presentation recently where they demonstrated three new means of hacking into existing cars.  They used an undisclosed model of a 2009 auto which they sort of deliberately used because it was an older car that was presumably less vulnerable than newer cars.  They were able to take the car over by playing music.  Now, this shouldn't surprise anyone...



LEO:  Oh, boy.



STEVE:  ...because all this means is there was a vulnerability in the...



LEO:  Player, yeah.



STEVE:  ...CD player software, a buffer vulnerability that we're used to dealing with all the time on our PCs.  And so a specially crafted MP3 file was able to load a trojan into the car's operating system, rewriting the firmware, in order to give them control.  They were also able to get into the car by Bluetooth and by cell phone.



LEO:  Whoa, boy.  That's not good.



STEVE:  So this is not good.  I mean, again, it ought to surprise nobody.  No one who's listening to this podcast ought to be surprised.  I mean, these are rolling computers.  And unfortunately it's important, just like nuclear reactors, to have safety systems that function correctly.  It's important that our rolling high-speed multi-ton computers on wheels be secure.  And it's incredibly difficult, if not well-nigh impossible, to achieve that.  And these guys have shown that it's possible.



Now, I did want to back off from this a little bit and say that they had made a specific comment which I thought was important to understand, that these attacks are extremely car specific.  That is, no attack that they designed would work on any other car.  So it's not like Windows, where we're all using IE8 or we're using Windows 7, and we have a massive code base which is almost universal.  In this case, it would only work on a given make, model, and year of car with a specific version of firmware.  So they specifically found vulnerabilities in an instance of a car, rather than something much more weaponized.



But the other thing we know is that, over time, these things get easier.  I mean, these attacks mature.  If you want an example of maturity, just look at Stuxnet, which we covered last week.  So this is something that we'll certainly be keeping an eye on.  Many people wrote to me and tweeted about this music taking over a car.  It's like, uh-huh, well, who would be surprised by that?



LEO:  Amazing.



STEVE:  They're computers, and they're going to have buffer overruns, and that allows code to get injected, and that's what happens.



LEO:  Well, the only surprise is you'd think that the car computer would be isolated completely from the music player.



STEVE:  It's more expensive to do that.



LEO:  Well, they will in the future, I hope.



STEVE:  Yeah, I mean, you're right.  You would hope that.  And in fact, in the photo, they showed the instrumentation, "pwned" was the word showing in the instrumentation of the car.  And remember that they were able to stop and brake and literally really control the car.



LEO:  That's so horrible.



STEVE:  Control its functioning.  So I think we really are going to need, well, there's a commercial on TV now where Dad's talking to his teenage daughter, and he says, hold on a second, you can borrow the car, let me start it for you.  And he presses a button, and the car starts.  I just think, oh ho ho ho ho ho, help us.



LEO:  Why not just use Bluetooth.  You know Bluetooth's secure.  There is no problem there.



STEVE:  Oh, god.  Well, finally, in the news, the U.S. Pacific Command - I thought this was interesting, a little unrelated story but interesting - requested 13 high-profile sites be blocked across the Department of Defense's .MIL network in Japan to conserve bandwidth.



LEO:  YouTube?



STEVE:  YouTube, Google Video, Amazon, ESPN, eBay, DoubleClick, EyeWonder, Pandora, StreamTheWorld, MTV, iFilm, MySpace, and Metacafe.



LEO:  I love it.



STEVE:  It's like, okay, now, wait a minute.



LEO:  That's all the fun stuff.



STEVE:  Exactly.



LEO:  But really, it is a military network.



STEVE:  This is a .MIL network, and they're streaming Pandora?  It's like...



LEO:  They're having fun.  Well, hey, look, they're at an office.  They want some music.



STEVE:  They need some tunes.



LEO:  I'm glad they didn't block TWiT, you can keep listening to TWiT until they discover us.



STEVE:  And Facebook.  They didn't block Facebook.  It's not on the list.



LEO:  Well, it's probably, you know, most of those are rich media sites.  They're video and/or music sites.  So those are the ones that use a lot of bandwidth.  Facebook probably isn't as bad.



STEVE:  Yeah, well, yeah, YouTube, Google Video.



LEO:  Pandora.



STEVE:  Amazon now has video streaming that they're offering.  Wow.  So anyway, sorry, guys, you're going to have to work over there in Japan.



LEO:  I think the generals use Facebook, so they didn't want to block it.  That's how the generals stay in touch.



STEVE:  And one little bit of errata that I wanted to mention.  When I logged into Google Docs this morning in order to prepare the document that you and I are looking at right now, Leo, and which you'll post...



LEO:  Yeah, already have.



STEVE:  ...I got a little reminder screen that said, imagine how it would feel if you weren't just able to log on.



LEO:  Oh, yeah, good.  Good for them.



STEVE:  That wouldn't be good, would it.  And I said to myself, no.



LEO:  It wouldn't.



STEVE:  And they said, here's the information that we have for you, which is used for access recovery.  Is it still correct?



LEO:  Good.  Brilliant.



STEVE:  And I thought, wow.



LEO:  Brilliant.  Love them.



STEVE:  Very, very cool that they were proactive in, like, saying every so often, is this information still correct?



LEO:  That's just good sysadmining.  I mean, that's what, in a business, your sysadmin will go around and say every three months, change your password, we're going to lock you out unless you do.  Google has some really - the problem with recovering your password with Google if you don't set up things like an SMS number is it's really tough.  So they're proactively saying, make sure you have a phone number that we can SMS, and make sure it's up to date.  And this is advice to everybody, if you don't have that secondary means of notification, besides your email.  Because if somebody hacks your account, unless they get your phone, that SMS - I guess they could change the SMS.  But that's why you want to check it regularly.



STEVE:  Yeah.  I was very impressed that Google proactively reminded me.



LEO:  That's great.



STEVE:  We'd like to see more of that.



LEO:  I think they can't change the SMS unless they send you a text message saying, do you have this phone, is this a new phone.  I think they - I hope they would do that.  Very important.



STEVE:  And speaking of support, I got a nice note, a different twist on SpinRite from a listener, Anthony Ungerman.  He said, "Hi, Steve.  I purchased your software about two years ago in support of Security Now!.  I had no immediate need for SpinRite, so I soon forgot about it."



LEO:  That's fine.



STEVE:  "Well, this Friday I had a few drives that needed some SpinRiting, but I could not find my download codes anywhere.  I sent your support alias a 'Help!!!'" - with three exclamation points - "email at 7:15 p.m. on a Friday night.  By 7:26 I had received a reply containing the codes I needed.  The download took a second, and the system created a bootable CD a few minutes later.  I had SpinRite up and grinding away by 7:45 p.m., and I made the 8:00 p.m. date with my family for a Friday night movie.  Do me a favor and call Dell, Linksys, et cetera..."



LEO:  And let them know.



STEVE:  "...and teach them how to do support.  It would more than likely have taken three phone calls and a lot of waiting to get the same level of service."



LEO:  Absolutely.



STEVE:  "Thank you very much.  Anthony."



LEO:  Isn't that great.



STEVE:  Thanks for sharing that, Anthony.



LEO:  Now, is that automated, or do you have a tech guy sitting there?



STEVE:  No, that's Greg, who checked his email.



LEO:  Awesome.



STEVE:  And probably sent it over to Sue, and she checked hers, and she looked him up in our database and said, oh, yeah, here he is.  And then we sent him email containing his download information.



LEO:  Isn't it great when you have a great team that is just there and works hard.



STEVE:  They're the best.



LEO:  Love it.  Steve Gibson, I have got questions, if you have answers.



STEVE:  You have to look at this professor.  Can you real quickly go to...



LEO:  Yeah, what is his URL?



STEVE:  Go to Twitter.com/SGgrc.



LEO:  Okay, that's your Twitter handle, all right.



STEVE:  To get my feed.  And it's the most recent link.



LEO:  All right.  You have to, I think you have to type https: now to get - oh, it's down again.  Thank you, Twitter.



STEVE:  <Groaning>.



LEO:  You see, by the way, that hashbang in there?  So if you type SGgrc, it adds that hashbang to render the page.  And so that's what we were talking about.  It basically is a lump of JavaScript you'll see that comes in, and then the page is rendered.  So you enter SGgrc, but it - so apparently the servers are enough up to give me the hashbang, but not the data.



STEVE:  I just put in twitter.com/sggrc.



LEO:  Yeah.  Maybe it's just me.  That's what I put in.



STEVE:  Oh, and it comes right up.



LEO:  Is it coming up for you?  No.  Maybe it's just our network.  Twitter doesn't like me.  I'll get it before the end of the show, I'll get...



STEVE:  It's a little - and I would give you the link, but it's a YouTube shortcut, and I couldn't even begin to...



LEO:  I will get that for you.  I will put it in the show notes, too.



STEVE:  Oh, the guy is just wonderful.



LEO:  I hope they have the good German accent.



STEVE:  He's got the best hair.  In fact, somebody said, he said, somebody sent back to me, said, well, that guy explains things as clearly as you do, but he sure has a lot more hair than you do.  Like, yeah.



LEO:  Maybe you should grow your hair out there.  You should grow it out.  And maybe have a German accent.  That would be very...



STEVE:  I don't think he's ever cut his hair, that crazy Einstein guy.  Anyways, well, it's a really nice presentation.



LEO:  I love it.  I love it.  It's not Cliff Stoll, is it?  We used to have him on Call For Help.  He wrote a book called "The Cuckoo's Egg," where he talked about tracking down the...



STEVE:  Okay, if you go to YouTube and put in...



LEO:  I got the link from our chatroom.



STEVE:  Oh, good.



LEO:  The chatroom is - chatroom, you rock.



STEVE:  He's just wonderful.



LEO:  Chatroom rocks.  Nuclear reactors in Japan.  Oh, my god, look at his hair.  That's great.  Oh, my god.  That's fantastic. 



STEVE:  He does a great - and in fact his desktop, you can see it toward the beginning, the screen blanker kicks on after a while, but his desktop looks a bit like mine, you know, basically covered with icons.



LEO:  This is great.  And you liked his description of how reactors work and all that stuff.



STEVE:  Oh, he does a beautiful job and really covers the whole thing in about eight minutes.



LEO:  Fantastic.



[Clip] I have quite a personal interest in this because I went to Sendai six years ago...



LEO:  This is great.  All right.  We'll put the link to that in our show notes.  And you could just search for it.  Let me just see what you would search for.  You go to YouTube.com and search for "nuclear reactors in Japan."



STEVE:  That would probably bring it up.



LEO:  It's from Periodic Videos is the YouTube channel, Periodic Videos.  This is actually kind of neat.  The periodic table of videos from the University of Nottingham.



STEVE:  And he's got a - his tie, at one point we're looking down at the table because he's got some balls, and he's showing how neutrons split atoms.  And you can see his tie is the periodic table.  I mean...



LEO:  Oh, this is - that's my kind of guy.  Look at these guys.  So, yeah, in fact, if you go to PeriodicVideos.com, all the videos are here.  And the very first one is Nuclear Japan.  So this is the University of Nottingham in England, which is a great engineering school, very well-known engineering school.  So, good.  PeriodicVideos.com.  Fantastic.  I can't wait to watch that.  Maybe, you know what we'll do, for those of you watching the live stream, right after this show, in between this show and This Week in Google, we'll run that video because it's only eight minutes long.  Are you ready for questions, Steve?



STEVE:  Let's go.



LEO:  Question #1 from Chicago, Illinois, Jeff says:  I wonder about reverse DNS.  Steve and all, I recently found the podcasts of Security Now!, am enjoying them, learning a lot.  Thank you, we appreciate that, Jeff.  I did have one question about the reverse DNS message under the ShieldsUP! proceed page.  It was "The text below might uniquely identify you on the Internet."  One time it showed me no listing, and it was rated as a good thing.  Then, after an hour or so, my DSL or ISP listing was on that page.  His own IP address, I presume.  Which I guess is bad?  Someone could track your descriptors?  What would keep this IP/DSL listing from showing up to begin with?  And why would it later show up when I did a ShieldsUP! scan?  I did switch to a dual boot with Linux/WinXP, maybe that has something to do with it.  Keep up the good work, and thanks.  Jeff in Illinois.  I've seen this before.  So you do a reverse DNS lookup on his IP address.



STEVE:  Yeah, sort of as part of what ShieldsUP! does, sort of as a privacy heads-up, I check the reverse DNS of everyone connecting and just show them what theirs is.  In some cases, it's nothing but their IP address, like with the digits reversed and then a suffix of their ISP or something else.  But in some cases it looks more like an account name, which is, even though their IP address might be changing, their reverse DNS doesn't change.  That is, it does actually uniquely identify them.  And so...



LEO:  So it's a machine name, in effect.



STEVE:  Well, really it's whatever the ISP wants it to be because the DNS provider determines when a reverse query is made, what they'll say, what they'll send back.  So some ISPs actually do send back your account name, I mean, something that's like a serial number, not your IP address, with the octets reversed.  So because of that, I show that on ShieldsUP!.  Well, this question came up because something happened to GRC's DNS server.  We got a bad update, like a week ago, from the root servers, and reverse DNS failed at GRC.



LEO:  Oh, that's interesting.



STEVE:  And so I just wanted to bring it up in case anyone else had seen this.  It was a problem at our end which I tracked down and fixed quickly, which is why it was coming and going and may or may not have worked for him or seemed to change.  It wasn't anything he did.  It was just...



LEO:  It was a coincidence that he hit you when you were...



STEVE:  Exactly, down and then not down, and we're no longer down.  I've locked that so that it can't happen again.  So it was just a - it was a one-off thing at our end.  But I wanted to also...



LEO:  It is, in my case, it's my IP address preceded by netblock and ended by dslextreme.com.  So...



STEVE:  Yes.



LEO:  And that's probably fairly typical.



STEVE:  That's more common.  Although in some cases I do have people who sometimes send me what theirs is, and it's definitely, like, it's not their last name or anything, but it's something that, if they go and change their IP address, it stayed the same.



LEO:  Yeah, interesting.



STEVE:  Which means that anybody could lock onto that as something more persistent than an IP address.  You know, we're talking about tracking and identity and stuff, and this is just a sort of an obscure but still present means that in some cases some ISPs are not changing the way they should.



LEO:  We should point out, and I think this is a common area of concern that doesn't need to be, we should point out that every website you go to knows your public IP address.  That's just automatic.



STEVE:  At that moment.



LEO:  Yeah, at that moment.  And all websites could do what you do, which is a reverse DNS, a query saying, well, who is this?  So the issue is really your Internet service provider because all sites can do what you've done.



STEVE:  Although actually...



LEO:  And many do.  Our chatroom, we do that all the time.  If we want to block somebody, we can immediately right-click on somebody's name and see what their reverse DNS is.



STEVE:  Except if they're running through a proxy, a transparent proxy from an ISP.



LEO:  Don't tell them how to do that.



STEVE:  Oh, no, I mean, only if you're secure, only if you're secure with an SSL connection are you sure to bypass a transparent proxy that your ISP may have.  I always think of Cox for some reason in our neighborhood because when I was developing ShieldsUP!, I had my employees testing it.  And it's before we were using HTTPS, in the very, I mean, the early days before this thing went public.  And I realized, oops, I'm not testing them, I'm testing Cox Network's transparent proxy.  So of course ever since this was released we were smart enough to get around that.  But it does mean that you may be seeing a proxy's IP rather than the user's IP, unless they're establishing a secure connection.



LEO:  We won't tell our trolls that.



STEVE:  And for what it's worth, anybody listening who wants to check their reverse IP, just go to ShieldsUP!, and the first page you get will show you a page, because I do reverse DNS on the actual...



LEO:  I just showed that page for people watching on the video.



STEVE:  Ah, cool.



LEO:  And by the way, our IRC server, we are so locked down on our IRC.  We have such a great team of IRC people, including some really good programmers.  And apparently, I'm being told now by our mods that our IRC server checks for proxies and does in fact block them.



STEVE:  Nice.



LEO:  Yeah.  For that reason.  It's not that we - it's just that sometimes we get attacked.  And so we need to make sure that we can protect ourselves.  Chris B. in Northern California wonders about Aegis Padlock hardware encryption and SpinRite.  Well, well, well.  He says:  Good afternoon, Mr. Steve Gibson.  I've been a fan and devoted follower of Security Now! since the very beginning.  I've used ShieldsUP! more times than I can shake a stick at.  Well, I'm curious about the security of hardware-based encryption, primarily related to Apricorn, that's the Aegis Padlock software.  Actually hardware.  They have USB and eSATA drives.



STEVE:  Right.



LEO:  Also being a SpinRite owner I'm curious if hardware encryption will have any impact on SpinRite's operation.  A short shout-out to SpinRite's awesomeness.  I've used SpinRite to fix an Archos-605, that's the little tablet PC, prior to vacation.  I used it to store pics from my vacation in Central America.  And I can tell you the drive was so handy and convenient, it's worked flawlessly.  Oh, I guess the Archos is  - maybe it's one of those photo wallet things.  And the value of SpinRite has just become priceless, in my honest opinion.  Thanks so much, and keep up the excellent work.  So hardware-encrypted - and there's lots of different kinds of hardware encryption.  In fact, even ATA drives have a built-in encryption mechanism.  Does that impact SpinRite?



STEVE:  Well, some ATA drives have built-in encryption.  And I would, I guess, maybe more recent ATA drives do.  But that's - we need to make sure we separate that from just a password.  So...



LEO:  Right.  All ATI supports passwording.



STEVE:  Yes.  Passwords have been available on IDE/ATA drives for many years.  And what that is, is a low-level lock on access to the rest of the drive, which has to be provided.  That, however, can be bypassed by the manufacturer, and even by the end-user.  If you forgot your drive password, and you had locked the password, or for example sometimes if you had a password-protected hard drive in a laptop and moved it to a different laptop or even to a desktop machine, that drive would still be locked, and you would be unable to unlock it.  So if you format the drive and wipe out the contents, that will clear the password from one of those drives, allowing you to access it again - although, of course, you've lost access to the data that you had there before.



But manufacturers and, presumably, the three-letter agencies are able to remove a simple password protection and get at all of the data on the drive behind it.  So what you really want is encryption of the drive, which is driven by a password and, you know, by a key that the drive has, which you're able to eradicate if you needed to, and that would make all of the drive's contents incomprehensible.  So, I mean, that's the way to do it right is to, before you ever put any important data on the drive, you get a drive which has encryption at its interface, assign it a password, and at that point you're good to go because all the data that's written on the drive passes through this cipher on the way in.  Well, this is what this Apricorn.com, this Aegis Padlock for USB and eSATA drives does.  It's an external case which adds that in hardware to a drive that doesn't already have it.



LEO:  Oh, I get it.  I get it.



STEVE:  So, yeah.  So you're able to take any drive, a USB or I guess a USB or eSATA interface, and I'm not sure what kind of drive it takes internally.  It might be IDE or eSATA, for example, internally.  And it performs hardware encryption on the fly in both directions.  Apparently there's some overhead in doing so because they have a pro version which is way faster than their non-pro version.  So it looks like theirs is not quite as transparent as you'd like.  You'd like to have this happening on the fly, at full speed, so that you're not suffering any performance overhead in doing this.  But the benefit of that is that, when you remove that drive, it never had plaintext stored on it, so you don't have to worry about all the scrubbing and recovery and emergency procedures and all that that people are worrying about more and more, about leaving unencrypted data on the drive.



LEO:  Okay.



STEVE:  Oh, and as for SpinRite, SpinRite runs right through it.



LEO:  It doesn't operate at that level.



STEVE:  It doesn't operate at that level.  It sees the sectors.  It will recover them.  That's why, for example, SpinRite is usable on a TrueCrypted drive, too, one that has been encrypted.  SpinRite doesn't care about the fact that it can or cannot see the data.  So you could run SpinRite either on the outside of it or even on the encrypted inside, which actually might be better because there you really do care about performance, and it'll take much longer, if there's this hardware overhead that there seems to be on this particular brand, SpinRite would run a lot slower through that drive's encryption than if you just plugged the drive temporarily onto a motherboard and let SpinRite have at it.



LEO:  Right.  That's important.  I think people don't know sometimes the different drive recovery or data recovery levels.  I mean, you operate at the sector level, at the hardware level.  So encryption doesn't matter to you.



STEVE:  Correct.



LEO:  Then you can operate at the file system level or the actual data level.  Encryption would affect those, of course, because...



STEVE:  And that's why, for example, we're able to fix TiVos and iPods and things.



LEO:  Right.  You don't care.



STEVE:  Don't care what it is.



LEO:  It could be HFS, yeah.



STEVE:  If it spins, we'll fix it.



LEO:  If there's a sector, we can examine it.  Question #3, Dick Nelson in Melbourne, Florida wonders about uncovering spoken phrases in encrypted voice-over-IP conversations.



STEVE:  Oh, so cool.



LEO:  I haven't seen this, but he points to an article at the Association for Computing Machinery, ACM.org.



[http://portal.acm.org/citation.cfm?doid=1880022.1880029]



STEVE:  Okay.  So...



LEO:  On VoIP-encrypted calls.  What is going on there?



STEVE:  Okay.  So a number of people sent me tweets.  I'm going to read the abstract of the article.  This was published in the ACM, the Association for Computer...



LEO:  Computing Machinery.



STEVE:  Machinery, that's right.  Okay, their abstract says:  "Although Voice over IP (VoIP) is rapidly being adopted, its security implications are not yet fully understood.  Since VoIP calls may traverse untrusted networks, packets should be encrypted to ensure confidentiality."  Okay, so we're talking about encrypted VoIP.  No biggie so far.  "However, we show that it is possible to identify the phrases spoken within encrypted VoIP calls when the audio is encoded using variable bit rate codecs."



LEO:  Oh, interesting.



STEVE:  Think about that.  That's all - when I read that, it's like oooh, yes.  Because the rate, the amount of compression you get...



LEO:  Varies.



STEVE:  ...is a function of the audio.



LEO:  Right.  Oooh, clever.



STEVE:  So, oh, my god...



LEO:  So you could basically - you'll get a frequency.



STEVE:  Well, you'll get a - the amount of compression is a function of the audio.  So that means that the density of the VoIP varies with what is spoken.  So they go on to say:  "To do so, we train a hidden Markov model using only knowledge of the phonetic pronunciations of words...."



LEO:  So they're going to get something that maybe would sound like [garbled speech].



STEVE:  Well, so we...



LEO:  To get a waveform; right?



STEVE:  "We train a hidden Markov model using only knowledge of the phonetic pronunciations of words, such as those provided by a dictionary, and search packet sequences for instances of specified phrases.  Our approach does not require examples of the speaker's voice, or even example recordings of the words that make up the target phrase.  We evaluate our techniques on a standard speech recognition corpus containing over 2,000 phonetically rich phrases spoken by 630 distinct speakers from across the continental United States.  Our results indicate that we can identify phrases within encrypted calls with an average accuracy of 50 percent, and with accuracy greater than 90 percent for some phrases.  Clearly, such an attack calls into question the efficacy of current VoIP encryption standards.  In addition, we examine the impact of various features of the underlying audio on our performance and discuss methods for mitigation."



Okay.  So what this means is that, I mean, this is just a brilliant side channel attack on crypto because - so what this says is that, if you're using a variable bit rate codec, the compression ratio is a function of what you say.  That would be obvious.  So what they did was they were able, they took a spoken language corpus and basically trained a pattern recognizer to map from what was spoken to the equivalent compression of what was spoken.  And since encryption does not compress, the fact that it was encrypted didn't change its compression.  So they took the encrypted data and looked at the compression that it had experienced, and they were able to map it back to what must have been spoken if it had that much encryption.  It's brilliant, and just incredibly clever.



So we know that the amount of compression you're going to get is going to change with what you say.  So it's possible to build a pattern recognizer, which is what this so-called "hidden Markov model" - a Markov model is one means for doing probabilistic state analysis of something like speech, for example.  It's been applied to speech recognition.  So basically they're doing compression recognition.  They're looking at the amount, like the way compression varies with time, and which encryption doesn't change because you compress, then you encrypt.  So they're able to look at the rate at which compression occurred and develop - and their pattern recognizer is encryption blind.  It doesn't care about that.  It just sees how much compression you got.  And so with 50 percent accuracy and up to in some cases as much as 90 percent, it is able to figure out what you're saying.  It's like, it's just brilliant.  It's fantastic.



LEO:  Yeah.  And actually, in hindsight, kind of obvious.



STEVE:  Exactly.  Again, it's like one of those things that's like, oh, yes, that's just perfect.



LEO:  Now, presumably you could have VBR encryption that would pad it or something, make it somehow not - but the key would be to turn off VBR.  I guess, though, that that's not typically built into, you know, any of the control panels.



STEVE:  You want VBR because it's what you...



LEO:  It's more effective.



STEVE:  Yeah, you get so much better bandwidth use.  Unfortunately, that gives away what you're saying.



LEO:  I presume - we're using Skype.  I would bet you it's using VBR.  I don't know...



STEVE:  Oh, it is a variable bit rate encoder, absolutely.



LEO:  So there.  I bet you the NSA's known about that for a while.  In fact, they're probably a little peeved that this information got out.



STEVE:  Somebody else figured it out, yup.



LEO:  Dagnab it.



STEVE:  And imagine, if you then had this, you'd feed encrypted VoIP into this.  And even if it only got 50 percent right, you could be reading, and like most of it's wrong, but you'd get lots of snippets that would get you a lot of information.  Half of the conversation contains a huge amount of data because most of what we're saying, especially on this podcast, is nonsense.



LEO:  Right.



STEVE:  So - no, not really.



LEO:  I'm sure it would sound like the teacher in Peanuts [muffled speech].



STEVE:  There's a huge amount of redundancy in normal, natural language.



LEO:  Of course there is.



STEVE:  And so you could get away with missing a lot of it and still pick up the content.  Wow.



LEO:  Unbelievable.  Just fascinating.



STEVE:  Very cool.



LEO:  Yeah.  This is, you know, understand why Steve's excited about this.  It's kind of a cool insight.  It's not that he thinks it's a great thing that it can happen.  It's a very cool insight.  And once you understand it, you go, oh, of course you could do that.



STEVE:  A brilliant hack.



LEO:  It's a brilliant hack.  Question #4 from Hendrik in Utrecht, The Netherlands.  He's been playing with something called PLCs.



STEVE:  Our PLCs that Stuxnet programs, yeah.



LEO:  Oh.  Greetings from Holland, Steve and Leo.  As an intern I have been doing research into security-related applications of PLCs.  I can't tell you much more than that, I'm afraid.  I was therefore greatly interested in your Security Now! episode on Stuxnet.  As usual, I learned a lot.  Steve, you're amazing.  I mean, even somebody who this is their field.  One thing I noticed was you mentioned that PLCs have their own network.  What does PLC stand for, just to remind me?



STEVE:  Programmable Object Controllers.



LEO:  Okay.  Those are the things in the Siemens controllers, for instance.



STEVE:  Yes, those are the things that run all the plants everywhere.



LEO:  Right.



STEVE:  And the nuclear plants.



LEO:  Right.  Because PLCs have their own network, a Windows machine is needed to infect them.  In my research I've come across various PLC models, most of which supported many connection types to create a network.  One of these connection types is Ethernet.  In other words, a standard network cable.  In my security research report I mentioned there's a reasonable risk of someone misconfiguring a network by accident, not intentionally, or accidentally plugging PLC into another network, say, one connected to the Internet?  This is one of the reasons the company I was doing research for chose only to use models using different connections in Ethernet, he says, RS-485 in this case.  I can imagine other companies finding the ease of Ethernet too attractive not to use.  Does seem like that opens up a big hole.



Another thought was that some system administrators might find it useful to connect the entire system to the Internet anyway so they could fix things without getting out of bed.  Now, I don't like being a pessimist, though it seems second nature in the security field.  But I'm sure there are plenty of PLCs, SCADA systems and other such networks that are in some way connected to the public Internet.  This combined with the frightening malware advances you've told us about in last week's show does not make me feel so great about the whole thing.



Anyway, just wanted to share my thoughts on the subject and thank you, Steve and Leo and all the other folks that make Security Now! happen, and there's a big bunch of people, for a great podcast.  Regards, Hendrik.  He is Malachy on the TWiT IRC, by the way, if you want to say hi to him.  None of the PLCs I've worked with have any form of encryption while communicating over Ethernet.  So usernames, passwords, et cetera are sent in the clear over that network.



STEVE:  And they're typically all default, too, because...



LEO:  Right, because why change it?



STEVE:  ...the presumption is, well, no one can get to our network, so we don't want to have to bother with figuring out what our username and password is.



LEO:  We're here inside the uranium enriching plant.  Who could get in here?



STEVE:  What could go wrong?



LEO:  What could possibly go wrong.  Wow.  Question #5, Steven Gibson, from Robert Osthelder in Fond du Lac, Wisconsin.  He wonders how to switch from Windows to Mac without losing all his security tools.  Oh, that's an interesting question.  Never heard that one before, actually.  I've been a longtime Windows user, go-to guy for IT support for my family's Windows machines.  I've been considering purchasing a new laptop since mine is getting very old and clunky.  Doing some shopping around online, I'm very interested in the new MacBook Air.  Which I give two thumbs up for.  I know you don't have...



STEVE:  Me, too.  It's beautiful.



LEO:  Oh, you have one.



STEVE:  I do, and it's a beautiful machine.



LEO:  Elegant machine.  Which runs Windows, by the way.  You don't have to - you could put Windows on it.  I know people have been thrilled with it.  The big reasons for being so interested in the Air are the size, weight, build quality.  Yeah, the build quality in the Air is pretty spectacular.  Right now, though, my concern about switching to Mac is figuring out where to get started when it comes to securing and protecting a device running the Mac OS.  For example, on my Windows machine I'm running Malwarebytes, Spybot, Comodo Firewall, and AVG antivirus.  The problem is I don't have a clue if those types of programs exist or whether or not they're needed on a Mac or in what combination.  Would you mind giving me a quick rundown of how to get started keeping a Mac OS squeaky clean?  Thank you for all the time and work you and Leo do on the Security Now! podcast.  I've been a regular listener for the past couple of years and a proud owner of SpinRite since shortly after I started listening, which I have used to recover several drives.  Best regards, Robert.  Steve?



STEVE:  So this is a combined answer from you and me, Leo.



LEO:  Okay.



STEVE:  Not being a big Mac person, I don't have an answer on the details of third-party software for the Mac.  I would say, however, immediately switch to Firefox or Chrome as...



LEO:  I think we know that now.



STEVE:  ...opposed to Safari.  And that the Mac's got a nice firewall built in that prevents external stuff from getting in.  So beyond that, what do you think?



LEO:  Yeah, I mean, the advice for all operating systems, of course, is keep it up to date.  And Apple, right under the Apple, has a software update which will check.  It will do it automatically, as well, to make sure you've got all the patches.  Immediately after Pwn2Own, another bunch of patches came in, obviously to patch Charlie Miller - no, it wasn't Charlie, the attack on Safari.  Nevertheless, we know that there are holes in Apple's OS.  I agree with you, use Firefox or Chrome.  I like Chrome on the Apple.  I think it does a great job.



There is, in the system preference pane, that's the Apple equivalent of the control panel, a security button which gives you some useful security things.  For instance, I always make sure that I require a password after sleep or screensaver.  I disable automatic login.  I use secure virtual memory.  A lot of people don't realize that the virtual memory on your system, the pagefiles, will contain unencrypted data.  So this is built in.  Apple also has built-in secure deletion in its trash can.  You might want to use that, as well.



FileVault secures the entire drive.  It's whole-drive encryption.  You may or may not want to use that.  I don't use it.  You might want to prefer to use TrueCrypt or something like that.  And you're right, turn the firewall on.  You see it's not on here.  But turn the firewall on.  And when you do turn on the firewall - let me just log in.  This I like, by the way.  Apple, kind of like user access control on Windows, requires administrator login to do anything of importance, including - and you can set it this way, and I do - including the system preference panes, require a password to unlock each system preference pane.  That keeps kids and others with access to your computer from doing stuff.  But you're right, I think the firewall is quite good.



And you see immediately, by the way, as soon as I turn on the firewall, do you want the application Axia DVD to accept incoming network connections?  It's immediately notified me that there is a request for network access.  I do know what that is.  That's our audio software, so I'm going to allow it.  But you'll get those periodically.  I think that's great.  I always keep the firewall on.  And you can even have it block all incoming connections except those required for basic Internet services - DHCP, Bonjour, and IPSec.  At that point your browser works, other stuff works, but all incoming connections are blocked.  That's super secure.  I don't know if you need to turn that on.  You see, I've allowed two connections.  It will list these connections.  You can add more manually, or it'll do it automatically.



This is another checkbox you may or may not want to have checked:  Automatically allow signed software to receive incoming connections.  Probably want to uncheck that so that you have explicit approval.  And this you would like, Steve:  Enable stealth mode.  Which means don't respond or acknowledge attempts to access this computer, including ICMP packets, that's ping.



STEVE:  Yup.  I'm responsible for them using that word, too.



LEO:  That's right.  Stealth mode is a Steve Gibson trademark.  Well, I don't know about that.



STEVE:  I invented that for ShieldsUP!.



LEO:  So I always turn that on when I'm in public.  We're on a protected network in here, so I don't have it on in here.  But actually I'm going to turn it on.  There's no - it doesn't seem to have any performance hit.



STEVE:  No.



LEO:  It really is a good firewall.  It's based on the BSD firewall, so it's - I don't know if it's ipchains or which firewall, but it's a very strong firewall.  That's probably the most important thing you can do.  There is security software for the Mac.  ESET makes a program called Cybersecurity for the Mac.  It's an antivirus, antispyware.  And there are other commercial programs like that.  But there are also some free Mac antiviruses, as well, that you could take a look at.  I personally don't run one.  I don't feel it's needed.  The Pwn2Own, I don't know what to say about that except that I use Chrome.  But no guarantee that that's secure, either.  Most important thing to do on any OS is just update it as often as needed.



STEVE:  And in this day and age the entry vector for problems is going to questionable, sketchy sites with a browser that is either not updated or has zero-day vulnerabilities that no one knows about.  That's how they get you.  And in every instance it involves JavaScript.  So I just - if you have JavaScript disabled normally, and you enable it selectively, you're really very safe these days.



LEO:  Yeah.  So that's a big addition, NotScript, I guess.  I'm going to have to find that for Chrome and put that on there.  I hate doing that because it really slows me down in my surfing.  But on the other hand...



STEVE:  I know.  



LEO:  ...it is the single most important thing you can do to protect yourself.



STEVE:  It really is.



LEO:  Chrome extension gallery, NotScripts, that's cool.  I didn't know about this.  I'm so glad to have found this.  That's great.  And they liken it to NoScript.  So that's fantastic.  I'm installing it now.  Thank you.  Question #6 from Greg in Brisbane, Australia.  He wonders about IPv6 and ShieldsUP!:  I'm currently trialing IPv6 on my home connection with my ISP in Australia, Internode.  That's neat, that Internode offers that.  Curiously, there appear to be no testing sites such as ShieldsUP! that support testing an IPv6 firewall.  Do you plan to do that?



STEVE:  I do.  I've got a call in to Level 3, the guys who provide bandwidth to GRC, to say, hey, guys, I'm liking all my IPv4s; I'm going to need some provisioning of IPv6.  And I have not heard yet back from them.  But I'm sure they must have this, I mean, they probably have to just push a button somewhere, and I get a bunch of IPv6 IPs.  And when I do, I think it's definitely a priority for me to make ShieldsUP! run over IPv6.



LEO:  Yay.



STEVE:  So no - I don't have a date yet, but it's definitely going to happen.



LEO:  And you can of course go to Hurricane Electric in the U.S., and they're offering IPv6 tunneling.  If you want to play with IPv6, they have free tunnels.  Randal Schwartz was telling me he's got, like, five IPv6 addresses for free.  Actually, no, wait a minute he has, like, a Class B block because there's so many IPv6 addresses, I think he has 65,000 of them.  I can't remember.  Some huge number.



STEVE:  Yup, that would be a B class.



LEO:  Yeah.  Because there's so many, you can have as many as you want.



STEVE:  How many do you like?  How many do you want?



LEO:  Take 20,000, they're free.



STEVE:  Yeah.



LEO:  Question #7 - is it a lot of work, by the way, for you to make IPv6 compatibility in ShieldsUP!?  Or is that something not too...



STEVE:  Oh, no, it's just sort of, like, I just have to refocus myself.  It'll be fun.



LEO:  Steve, you have way too many things on your punch list now.



STEVE:  I've got a big one that I haven't talked about yet, but maybe next...



LEO:  Oh, dear.  Okay, good.  Look forward to it.  Question #7, Anthony Woodall in Santa Rosa, California, just up the road apiece, comments about the IE6 Countdown.  We talked about that web page where Microsoft's urging people to dump IE6.  I just thought I'd mention that some businesses are using IE6 internally, Internet Explorer v6, and are probably not included in the IE6 Countdown website.  This is true within the company that I work for.  Yeah, I suppose if you have an Intranet that is written to IE6, which is not uncommon.  He says:  We're using a heavily customized-with-code IE6 for all of the web-style internal network resources.  There you go.  Also I remember you mentioned that a specific government in Europe has refused to move from IE6 because they have so much custom code.



STEVE:  Yeah, we did talk about that a while ago.  And this is the - I guess it's a conundrum that Microsoft is in because 6 happened and was, in its day, very good and very dominant.  And Firefox, or I guess back then Mozilla probably, or Netscape, they were still struggling.  There really wasn't any strong competition.  But Microsoft also was not following standards.  They were just adamantly saying we're going to go do these things our way.  I've been fighting that for the last two weeks because I'm now writing JavaScript code that needs to be platform agnostic.  And half of my code is dealing with the fact that Microsoft handles events that happen on the web page completely differently from everyone else.  I believe that they finally got with the plan with IE9.



But, look, here we're trying to kill off IE6, which is a decade old, not to mention 7 and 8 since then.  So no code is going to be able to not take Internet Explorer into account until, not only 6, but then 7 and 8 also stop being used.  And that's never going to happen.  So, yeah.  So it certainly is the case, I mean, Microsoft is guilty of really defying standards, even after they existed.  Well, because at the time they thought maybe they would win.  I mean...



LEO:  Thought they'd be the standard, yeah.



STEVE:  Yeah.  I mean, they were using Visual Basic for scripting, VBScript.



LEO:  Oooh.



STEVE:  Yeah.  You're not going to see that anymore.  That one lost big-time.  But it certainly is the case that people can't give up IE6 without investing a huge amount in reengineering.  And the question is, why would they?  Their system's working now.  Of course what's going to happen is that IE6 support will disappear, and they'll end with a browser with lots of vulnerabilities.



LEO:  Well, but is that a problem if it's only on the Intranet?



STEVE:  If they kept it, as long as they didn't use it to go outside, then you're right, that could just be a separate application.  Although the problem is IE has never lived along other instances of IE very happily.  Whenever you install - and that's the whole Microsoft, oh, no, it's part of the operating system nonsense from the trust, the antitrust suits, where they were saying, oh, no, you can't - notice I have no problem with Opera and Netscape and Firefox and everything else, and Safari and Chrome, all loaded in my OS at the same time.  Except, oh, no, I can't have two versions of IE.  So it's like, okay, fine.



LEO:  Curious.  I'm thinking, if it would be possible to make network policies that said you could use IE internally only.  Yeah, they could lock it down and then give you Chrome or something, or Firefox.



STEVE:  Yeah, or maybe...



LEO:  People are going to want to use one browser, though.  I know I look at my office staff, and they've got - they're all using IE.  They just, well, it's the browser, it's on Windows.



STEVE:  The one that's there.



LEO:  It's what I got.



STEVE:  Yeah.



LEO:  So it kind of would be very difficult, very challenging for IT to say, okay, IE6 for our Intranet, but the minute you want to go outside the Intranet you've got to launch Chrome.



STEVE:  Ah, good point.  You wouldn't switch to IE9 because it would conflict with IE.  You would switch to...



LEO:  Firefox or something.



STEVE:  Yes, exactly.



LEO:  But you'd have to somehow enforce the policy and...



STEVE:  Yeah, you might be able to get IE to refuse to go out.



LEO:  Yeah.  Oh, you'd lock it down.  You'd just lock it down with the security and say you could only use Intranets.  That's easy.  But then what happens is your user calls you and says, my browser doesn't work.  I'm trying to go to Amazon.  And you say, remember I told you you have to use Firefox to go to - what's Firefox?  I just, I don't, what's Internet Explorer?  I just, my, the Internet is broken.  That's the problem.  And I love users, by the way, and that's not you.  I'm not talking about you.  It's that other person next to you.



STEVE:  Any of our listeners.



LEO:  Nobody who listens to this show.  The Internet is broken.  Help me.  See, they don't want that call.  Final question from Kevin York who's in our IRC.  He is wickedproxy.  That sounds dangerous.  He's in Harrisburg, Illinois in the real world.  He says malware hides in strange places.  He was looking at an article on Al Jazeera with a disturbing sentence that, if true, could be a game changer in computer security.  By the way, I just want to point out, Al Jazeera is a highly respected and excellent news source.  Even during this earthquake they've been great.  So it's not just Middle East coverage.  And they are not owned or run by terrorists, as some seem to think.



STEVE:  Right.



LEO:  They're great.  And so this is an article on Al Jazeera English about - it's an opinion article about, well, it says:  "Even next-generation rootkits were explored - to remain active despite the removal of a hard drive, to persist on a machine in the video card memory."  It's been the case to the best of my knowledge that if you wipe or replace the hard drive and put in a fresh install of the OS, you should have a clean machine.  That's the advice I always give our listeners on the radio show.



STEVE:  Rational.



LEO:  Yeah.  I mean, what are you going to do if it's sitting in the CMOS or on memory in a video card or some other firmware?  He says:  If things can live on your video card, what are you going to do?  This is at the least troublesome and scary to think what would happen if this were to get in the wrong hands.  It's in the wrong hands, I'm sure.  But who is to say whose hands are the right ones, he points out.



STEVE:  Yeah, a number of people picked up on this and said, hey, Steve, can malware live in video cards?  And the answer is, unfortunately, yes.  Think about how powerful our video cards have become.  I mean...



LEO:  They're computers in themselves.



STEVE:  Yes.  They are more, there is more processing power now in the video chips in the video cards than there is on the motherboard.  I mean, no matter how many cores you've got on your Intel processor, notice when we were talking about Bitcoin, it's the guys who were minting the bitcoins are using the GPUs, the graphics processing units on their video cards, that are getting 140,000 hashes per second, where I'm getting 5,000 hashes per second, and I've got the state-of-the-art i7 quad core.  So the video card technology has gone crazy.  And they've all got Flash-updatable firmware now.  Well, that's how the viruses are living.  There is malware that is able to live in a video card.  And that's just another area that the bad guys have explored.



LEO:  Unbelievable.  Wow.



STEVE:  So it's not good.  It's a side effect of the complexity.  We always get this when we get complexity.



LEO:  So format your video card.  You can't just unplug it; right?  The video card, it's static RAM or whatever it is.  It's firmware.



STEVE:  Yeah.  So you would need to reflash the firmware BIOS, the BIOS of the video card, from the manufacturer's clean copy, in order to make sure that nothing was living in there, if you thought and were suspicious of something having crawled into your video card.  Unfortunately, it's now possible.



LEO:  Wow.  I just - sometimes I despair.



STEVE:  Leo, we're getting old.



LEO:  I just despair.



STEVE:  If we can hang in here for another couple decades, we can just say, okay, we're done with all this stuff, turn it over to the young whippersnappers.



LEO:  Next week - that was our Q&A session.



STEVE:  Yup.



LEO:  Have you decided what you're going to cover next week?



STEVE:  If I can, I'd like to give a thorough look at IE9, really cover it from stem to stern, what's new, what they've done, what the security is, what the implications are.  And also the privacy factors, which I think are a big addition to IE9.



LEO:  Can't wait.  IE9, time permitting.  If you have questions for our next Q&A episode, which will be a couple of episodes hence, you can go to GRC.com/feedback, leave those questions there.  While you're at GRC, get SpinRite, the world's best hard drive maintenance and recovery utility.  You'll find 16KB versions of these shows as well as the full audio fidelity versions.  Those are for people who don't want to spend the bandwidth, or they've got bandwidth caps.  And they sound pretty good.  They're not, you know, they're a little crunchy, but they sound pretty good.



You can read the transcripts.  That's the smallest version, thanks to Steve, who pays Elaine to make those transcripts available.  I really appreciate that.  That's at GRC.com.  And a lot of freebies, including ShieldsUP!.  It's all there, Gibson Research Corporation.  You should follow Steve on Twitter if you're not.  I think we're going to see some more interesting tweets from him about this nuclear situation.  SGgrc is his official Twitter handle, SGgrc.  And we record this show live every Wednesday around 11:00 a.m. Pacific, 2:00 p.m. Eastern time at live.twit.tv, so do tune in for that.  Steve, I thank you for a great show.  Fascinating show.



STEVE:  Thanks, Leo.  Great, as always.



LEO:  See you next time on Security Now!. 



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#293

DATE:		March 24, 2011

TITLE:		IE9

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-293.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a great deal of security news and interesting computer industry miscellanea, Steve shares everything he has recently learned from his extensive study into the new security and privacy features of IE9.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 293, recorded March 23rd, 2011:  IE9.



It's time for Security Now!, the show that covers your security, your privacy, everything you need to know about protecting yourself online and, in the process, I think does a pretty darn good job of teaching all of us the fundamentals of computing technology.  And that's thanks to this guy, Mr. Steve Gibson, who's been doing it for an awful long time now, starting with the light pen he wrote for the Apple II computer; his many columns, loved those columns in InfoWorld magazine.  What was the name of that column?



STEVE GIBSON:  It was Tech Talk, was the name of that, yeah.  I originally called it Behind the Screens, but CompuServe had a trademark on that name, and so we were told we had to change it.  So I just said, well, Tech Talk.



LEO:  How long did you do that?



STEVE:  That was eight years.



LEO:  Wow.



STEVE:  Or maybe nine years.



LEO:  I learned so much from that.



STEVE:  It was a great column.  It ended up, I mean, Dvorak was there with me at InfoWorld, and Robert X. Cringely, and...



LEO:  Oh, yeah, the original, not the current one.



STEVE:  Right.



LEO:  There have been many of them.  I don't think the current Cringely is actually the same Cringely as was there in the early days.



STEVE:  I don't know one way or the other.



LEO:  It's a character.  It's like Betty Crocker.



STEVE:  Right.



LEO:  Well, I have to say, and I'll give you full credit, there were a few people that early - because I started getting into computers late '70s.  Did start early on writing, I wrote for Byte a little, wrote for InfoWorld, did reviews.  But I was learning in the early '80s.  And the way I learned was you, Dvorak, Jerry Pournelle in Byte magazine...



STEVE:  Yeah, Byte magazine.



LEO:  Steve Ciarcia's "Circuit Cellar" in Byte magazine.  It was just a handful of columns, and I read them religiously.  InfoWorld was weekly, which was great, so I read it every week.  And that's how I learned.  That's how I, you know, it was great.  So I owe you.  I don't think I've ever thanked you.  But I owe you a debt of gratitude.



STEVE:  Well, as you said, it's all about fundamentals.  And I guess I view everything from that standpoint, from that foundation.  And so it gives me a perspective that other people don't have who haven't been doing it since they were four years old.



LEO:  I do wonder how kids today - because we were all, you know, personal computing was a new industry.  So we were all kind of learning together.  And there was this great exciting time.



STEVE:  It would just be overwhelming today, Leo.  I mean, it's so big, you'd have to be looking at it, thinking, where do I start?  Like, what do I do?  How do I make a difference?  It would be daunting, I think.



LEO:  And there are no, I mean, those magazines are long gone.  There are no magazines anymore really to speak of.  They're all very small.



STEVE:  Dr. Dobb's Journal, that was another one of the good ones.



LEO:  Yes.  "Running Light Without Overbyte."  I read that religiously, cover to cover.  That was a great magazine.



STEVE:  Yeah.



LEO:  And nowadays, I mean, there's a lot of stuff, there's a lot of content on the web.  But I don't know, it's mostly fan content, content about content, and less so about the inner workings.  Even AnandTech and the other kind of geek sites are more about benchmarking and building a computer than about the fundamentals.  So I'm glad we do this because I think this is one of the last few places where you could say - we've got 293 episodes, and you could go back, and you could start at the beginning and learn as much as I learned from Steve's columns over the years.  Take you a little less than eight years to read it.



STEVE:  I think probably it sneaks up on people because we didn't start out by saying we're going to tell you about the fundamentals because some people might have started to snore, thinking, well, why does that matter?  But by sort of folding that stuff in, it's like, oh, I'm glad to know where this came from because it gives it some richness and some background.



LEO:  Well, you've done it as needed.  So we can't talk about crypto unless you understand the fundamentals of crypto.  So it's always been - yeah.  Well, today what are we talking about?



STEVE:  I think we need to cover IE9.  I have spent all my time, well, a lot of my time, when not playing with iPad 2 - which finally did come a couple days ago, and I like it, Leo.  It's just, to me, I would agree with you.  I can't see a reason, a compelling reason for someone with the first iPad to upgrade to the second, especially when there are strong rumors about a third, which is probably no more than another year away.  And it's really going to be the one we want.



But to me the second iPad just feels like a second-generation device.  It feels substantially more polished and refined.  I mean, physically holding it, it just - and of course holding it is what you do a lot with a tablet, much more than a computer.  And it does seem to have a faster frame rate when you're dragging pages and doing the little animations that are sort of just part of making it a nice experience.  So I like it a lot.  But I spent a lot of time with IE9, which was not easy for me because you can't install it on XP, which is, as we know, the operating system I'm still proudly sitting in front of.



LEO:  Microsoft is thinking of you specifically, Steve.  They're trying to force you to move forward.



STEVE:  Well, it's funny, too, because there have been a lot - there was a lot of press noise about IE9, and of course about Firefox 4, with actually recently the Firefox 4 people saying that they were outstripping the download rate for IE9.  And IE9 was pretty, I mean, it was significant, too.  It was several million copies of IE9 downloaded since its release.  On the other hand, no one...



LEO:  Well, Microsoft has hundreds of millions of users, you know.



STEVE:  Yes.  And nobody with XP.  I mean, remember, there's still a huge XP base.  It's not like I'm the only one left still using XP...



LEO:  I think it's still the majority in many countries.  I don't know about the U.S., but...



STEVE:  Yes.  And so none of those people are downloading IE9 because it won't.  It just says, I'm not compatible with your operating system.



LEO:  Do you think that that's a technical limitation or a marketing issue?



STEVE:  I would say both.  They could have certainly made it compatible, as is IE8.  Although IE9, as I'm sure Paul will have told you, is in fact deeply integrated with Windows Explorer, with the tray and the taskbar and the pin-ons and - or pin-ins or ons or ups or, I mean, I didn't bother spending much time with some of the frosting of IE9 because I know that you and Paul and a lot of other people in the industry are going to do that.  I'm looking more at privacy and security aspects.



LEO:  That's what we want from you, absolutely, yeah.



STEVE:  Right.  So but I do think that the decision they made was to take advantage of some of the new UI features that were added in Vista and then carried further in Win7.  And so, you know, they could have probably made it work, but it wouldn't have had those things.  And they probably just said, hey, it's time to give up on backward compatibility.  Which is surprising for them.



LEO:  I love this.  In the chatroom somebody said, "Why is Steve using XP?"  And he's getting a little schooling from one of our chatters, Popojijo.  He says, "Because new is inherently the nemesis of security."  We have trained them well.



STEVE:  That's great.  Yes.  In fact, someone asked me had I moved yet to Firefox 4, and I said, unh-unh.  No, that was, like a couple days ago.  Let's let it settle down a little bit.



LEO:  It's just too young.



STEVE:  Yeah.  I installed it on my MacBook Air so that I could sort of diddle with it over there on a little island all by itself.  And the other thing, too, is that it immediately, I don't have nearly the number of add-ons for Firefox 4 that I do have for Firefox 3.  But it immediately said, oops, this is not compatible, and that's not compatible.  In fact, NoScript doesn't even display the little options down in the taskbar in...



LEO:  Oh, that's disappointing.



STEVE:  Yeah.  Although many people tweeted me and emailed me.  I don't even want to look at the mailbag next week for the Q&A about, duh, Steve, NoScript does have button add-ons.  You just go to customize your toolbar, toolbar buttons.  Remember I was talking about how...



LEO:  Oh, yeah, you wanted an on/off switch, yeah.



STEVE:  Oh, they're coming out my ears now.  So, yeah.



LEO:  Well, I apologize for not knowing that myself.  So you can write to me.  Don't berate Steve.



STEVE:  It's very nice.  Very nice.  So thank you, everybody who tweeted and who wrote.  And I was immediately schooled, as was our poor chatroom person who said, why doesn't Steve always run the latest and greatest?  It's like, well, I'll get there eventually.



LEO:  IE9 our subject.  We also have some security updates, some security news, of course.  Wouldn't be a show if we didn't keep you up to date on the latest.  I like that.  That's something we added, I think, around show 100.  For the first few hundred shows we didn't talk about security news so much because we wanted to be a timeless show.  But then we realized that it's important.  So let's start with the security updates, I guess, because, well, it's funny, you didn't put this in your notes, but I just was doing an update.  Apple did a big update.



STEVE:  Right, huge, 300-and-some-odd-meg update of OS X.  Just, you know, catching up security stuff, standard next version of OS X.  And it took, oh, about an hour for me to get downloaded.  And then it sits and rebuilds itself in a sort of a non-applications-running mode, and then restarts, and you've got the next version.



LEO:  It doesn't seem like anything's changed, but I know there are a lot of security patches and all sorts of stuff.



STEVE:  Right.  Yeah, no big feature changes.  We talked last week about the recently discovered, at the time recently, zero and bad, zero-day exploit for Flash, which was being exploited by people who had a malicious Shockwave Flash file embedded in an Excel file.  Then there was, like, a third layer.  I can't quite remember what it was.  But anyway, it was being used for targeted attacks that Google said were politically motivated somehow, based on their observation.  And Google Security also recommended - oh, I'm getting myself confused.  That was the MHTML mistake that was politically motivated, that Google said use the Fixit to disable yourself.  And we still have no fix for that over on the Microsoft side.  But we did get a fix for the auth DLL problem, which was actually part of Reader and Acrobat, but exploited through Flash.



And so two days ago from when we're recording this, on March 21st, Adobe did release updates for their various versions of 9, Adobe Reader and Acrobat 9.  They are holding to not releasing one for X, or 10, because they're saying that their built-in protections are holding over on that side.  And so they're going to wait until summertime to update on their schedule, in their normal cycle, their quarterly cycle.  But they were unable to do that for people who were still using 8 and 9.



So I did want to let everyone know, you can just go adobe.com/support/security, and there's separate updates for Flash and for Reader or Acrobat, depending on which one you have installed on your system.  And I've got to say, I'm liking what Chrome is doing, under Google's management.  They auto-patched Flash for themselves the prior Wednesday the 16th, just...



LEO:  That's interesting.  So they are taking responsibility for the version of Flash that comes with Chrome.



STEVE:  Yes, they are.  Which I find is interesting.  I don't know what their arrangement is with Adobe that allows them to do that.  But they responded instantly with this.  And it just - people who were using Chrome just had it fixed.



LEO:  The more I use it, the more I love it, I've got to tell you.



STEVE:  Yeah, and boy, is it speedy.  I've looked at some benchmarks relative to IE9 that we'll be talking about here in a minute.  And Chrome is really out there.  I mean, it is really, really speedy.  We don't have any updates from Microsoft.  I did want to remind everyone, though, that IE8 was pwned during Pwn2Own at the Vancouver security conference a couple weeks ago, using three undisclosed but still unpatched vulnerabilities.  The person who came up with that has I'm sure communicated them to Microsoft, and Microsoft is fixing them.  And as long as they stay secret, and no one else discovers them independently, then that's a good thing.  But of course knowing that they're there does encourage people to go after them.  So the clock is ticking on that.



The week's biggest security news was that RSA announced they got broken into.



LEO:  Yeah.  I was so hoping you'd talk about this because I'd love to know what this means.



STEVE:  Not only am I talking about it, I did my first blog posting in a long while because I was so annoyed with what little they said.  Their senior VP guy put out an announcement on their site, and they even made an SEC filing, a filing with the Securities and Exchange Commission...



LEO:  Really, wow.



STEVE:  ...like, because they felt they had to because...



LEO:  It had material impact on their business.



STEVE:  Well, materially affect their stock evaluation.  So excerpting from, like, the most annoying chunk from what they wrote - and anyone who's interested can go to steve.grc.com, and it's my most recent blog posting there that has had a lot of really great feedback added to it since I put it up earlier this week.  RSA wrote, and get a load of this bureaucratic say-nothing speak.  Oh, it's unbelievable.



"Our investigation also revealed that the attack resulted in certain information being extracted from RSA's systems.  Some of that information is specifically related to RSA's SecurID two-factor authentication products.  While at this time we are confident that the information extracted does not enable a successful direct attack on any of our RSA SecurID customers, this information could potentially be used to reduce the effectiveness of a current two-factor authentication implementation as part of a broader attack.  We are very actively communicating this situation to RSA customers and providing immediate steps for them to take to strengthen their SecurID implementations."



Well, okay.  If you have a multifactor authentication system, and one factor relies on a piece of hardware whose numbers are changing - the SecurID is basically what we've talked about, like with the PayPal dongle, the VIP technology, that's what it is.  It's a time-based, changing every 30 seconds, six- or eight-digit, typically six, LCD screen thing.



LEO:  So is it - I have this VeriSign identity protection.



STEVE:  Same thing.



LEO:  But is this the one, or is this using RSA?



STEVE:  No, no, no.  This is...



LEO:  This would be one from RSA.



STEVE:  Well, no.  The VeriSign is from VeriSign.  VeriSign uses Vasco, I think, as their provider.  And, but, I mean, it's the same technology.  It's cryptographically driven, time based, six characters, you know, six digits.  And the point is that it's driven by a unique key that nobody knows.  Well, somebody knows it now.  And that's the point.



LEO:  So you mean all of the cards on the RSA technology are compromised.



STEVE:  We don't know that.



LEO:  Okay.



STEVE:  So what RSA is claiming is they said - okay.  So reading from my own blog posting, I said, "On March 17th, 2011, Art Coviello, RSA Security's Executive Chairman, posted a disturbingly murky statement on their website" - and I have a link to that on my blog posting - "disclosing their discovery of [what they called] an 'APT' (Advanced Persistent Threat).  In other words, they discovered that bad guys had been rummaging around within their internal network for some time" - hence "persistent" - "and had managed to penetrate one of their most sensitive and secret databases," the SecurID system.



LEO:  Unbelievable.



STEVE:  I know.  And so what has upset many people, not just myself, but, I mean, many people, is that RSA, that's essentially all they've said.  But then they also said other things, like make sure not to let people see the serial number on your RSA dongle.



LEO:  Oh.  I just did.  Mine's VeriSign.  Hope they haven't been compromised.



STEVE:  Oh, no, VeriSign's completely different, so I don't want to confuse anybody.



LEO:  I understand, yeah.



STEVE:  Completely different.  RSA has something called SecurID that is their take on adding a hardware token or a software token.  You can also do software.  But a lot...



LEO:  By the way, I want to just point out that this is widely used in government.



STEVE:  Oh, yes, yes, yes.



LEO:  And by spooks.



STEVE:  40 million.  When SANS, the SANS Security Institute was reporting this, they mentioned that 40 million SecurID tokens had been deployed, which are often used to conduct financial transactions and by government and major corporations.



LEO:  Dr. Mom says the hospital healthcare system she works for uses those keys for record access.



STEVE:  Yeah, I mean, this is big.  So in my blog posting, essentially I took the position of, okay, they're not saying anything.  But what they did say was that their SecurID two-factor authentication system had been compromised.  Well, okay.  There's only one thing that is a secret, and that is the mapping between the serial number that's printed publicly, for the public to see on the outside of the SecurID tokens, and the matching cryptographic key which determines uniquely the sequence of numbers from one 30-second interval to the next.  So if anything has been compromised, that's what's been compromised because there's nothing else to be compromised.



LEO:  In fact, that's their entire business.



STEVE:  And that's the worst thing that could possibly be compromised.



LEO:  Geez.  Oh, my god.



STEVE:  So it's really bad.  So, and there is, down, way down toward the end of the comments, I link to another person's blog posting that I liked a lot because he essentially took them even further to task than I did.  And there have been people privy now who have seen the letters that RSA has sent to their corporate customers.  Basically they're CYA letters which are essentially telling the customers to be much more careful with their own networks and with their own disclosure of things relating to SecurID, like don't let people know what the serial numbers are.



See, it used to be fine because no one knew what the secret key was that the serial number mapped to.  But if that database has escaped RSA, if that's been exfiltrated - and, I mean, to be sympathetic to RSA, and I was at one point, I said, you know, bad things happen.  And if people are using toy operating systems, which is what we're all sitting in front of, I mean, Windows is a toy.  Look at what a catastrophe it is from a malware and virus standpoint.  So here's a corporation like RSA that you really want to have bulletproof, industry-strength security.  But they've got to be using Windows or Macs.  And these machines are not secure.  That's why we have a podcast.  And so unfortunately - and they talked about it being, oh, a very sophisticated cyber attack.  And I'm hoping that it wasn't that somebody didn't just open a bad PDF file and get themselves...



LEO:  Yeah, oh, boy.



STEVE:  Because that's how this stuff happens all the time.  So I really, I am sympathetic to the fact that somebody got into their network.  But it's very, very difficult not to have people getting into the networks of large corporations when people really want to get into the networks of large corporations.  And now here's the problem, is that, after the fact, they discover this so-called APT, persistent threat.  Well, how do you answer the question, what did they get?  How do you know what they got?



LEO:  You don't know.



STEVE:  You really don't know.  It's exactly analogous to what we've talked about.  If you've got malware in your system, if your system has got a rootkit on it or malware that you've discovered, you can never again be sure of the security of that machine.  You have to go back to an image made from a time before that thing got in and then work forward.  Or format the hard drive and hope that it didn't infect the firmware of your display adapter.



LEO:  Oy.  We talked about that last week, for folks who just said, what?



STEVE:  Exactly.  So I really, I'm seriously sympathetic to RSA's condition.  And they're a big corporation.  They're owned by EMC, an even bigger corporation.  They've got obligations to their shareholders.  They've got obligations to all of the 40 million users of their SecurID tokens who are now wondering, is this secure or not?  So, I mean, I have suggested, drawn the conclusion, that since something got away from them that relates to SecurID, and the only thing that they have that relates to SecurID is that mapping database between the publicly known serial numbers and the secret cryptographic keys on all those devices, they may not know how much of it got out.  We hope it didn't all get out.  But we're talking about replacing all of those.  I mean, they're not secure now.  So what RSA seems to be telling their customers is, well, try to keep all the other factors as secure as possible because the one you bought from us...



LEO:  You're screwed.



STEVE:  Yeah.



LEO:  Oh, boy.



STEVE:  It's not good.  So, meanwhile, RIM - Research In Motion, our BlackBerry creators...



LEO:  I just ordered the new PlayBook.  I'm excited.



STEVE:  I was going to ask you, Leo.  If I were to get a Android tablet, what do you think?  Because the PlayBook is supposed to support Android.



LEO:  No, the PlayBook is not.  It's QNX.



STEVE:  No, I know, but it apparently supports Android apps.



LEO:  What?



STEVE:  You haven't heard that?  Yeah.



LEO:  Oh, that's exciting.  That's good news.  That opens up, of course, a giant app store.



STEVE:  Yeah.  Well, we'll talk about that in a minute because in my errata I'm talking about Amazon.



LEO:  Yeah, there are a lot of third-party - third-party.  There are a lot of companies making Android tablets, including the new Samsung Galaxy tab.  There's a seven-inch, but there's a 10.1 coming.  There's the Xoom we've talked about with Motorola.  Lot of kind of off brands.  Archos makes them.  But I think that these - it's still a little rugged, a little rough.  I was very impressed with the seven-inch PlayBook when I played with it briefly.



STEVE:  Ah, so you have had your hands on it.



LEO:  Oh, yeah.  I had it for the Regis and Kelly show.  And very impressed with its multitasking.  QNX is a really robust real-time operating system.



STEVE:  Oh, it's been around forever and ever, yeah.



LEO:  So I think that was an interesting and good choice.  Now, of course, it's not known as a touch operating system, but the touch seemed to work quite well.



STEVE:  Oh, good.



LEO:  So we'll see.  I ordered it.  It comes April 19th.



STEVE:  Oh, yay.  Cool.  So anyway, what I was saying about RIM and BlackBerry is that they were unnerved by the fact that they got pwned also during CanSecWest a couple weeks ago.  And they're now advising all their customers - wait for it, wait for it...



LEO:  Buy an iPhone.



STEVE:  Disable JavaScript.



LEO:  Oh, well, there you go.



STEVE:  Where have we heard that before?



LEO:  But right as rain.



STEVE:  Exactly.  So it's a flaw in their WebKit-based browser in the BlackBerry.  And you need to disable JavaScript.  Now, JavaScript is not the problem.  But you need JavaScript - wait for it, wait for it - to exploit the flaw.  Yes.



LEO:  Of course you do.



STEVE:  So just turn JavaScript off on your BlackBerry.  I don't ever use my BlackBerry browser because it's the crappiest browser on the planet.



LEO:  It's a terrible browser, yeah.



STEVE:  Oh, my god, it's just like - it's just horrible.



LEO:  I'm surprised to hear it's WebKit based because it doesn't seem like it's got anything going for it.



STEVE:  Yeah, it sort of hurts the reputation of WebKit.  I don't know what it's doing most of the time, but it's just - I don't have my BlackBerry to browse.  I have it for messaging.  And I think it's the best messaging platform there is, so that's what I have it for.



India, speaking of BlackBerry, India and BlackBerry are in the news again with Robert Crow, who's the BlackBerry VP of Industry and Government Relations, quoted as saying, "Holy smokes" because India's Home Ministry, which is responsible for domestic security, has informed BlackBerry that it will require the ability to intercept communication data sent via email capabilities of the BlackBerry handset.  And Crow was quoted, it said according to Crow, "These demands could potentially open up the doors to further problems, such as whether the government tracking of ambassadorial conversations or even transfer of financial files would be off limits."



BlackBerry's concern is that, first of all, they really care about the security that they're offering to the users of their handsets.  They have repeatedly told the Indian authorities that it's impossible to do what they want.  And they've reiterated that, that they don't have the keys; that their fundamental architecture is an end-to-end encryption, and there's nothing they can do.



Now, and the point they're making here is that apparently they're not very confident of the infrastructure in India to responsibly manage opening these doors.  Which, sure, they could update their firmware, and they could rejigger things and fundamentally dramatically weaken their platform.  But if they did so, what kind of abuse would this open themselves to if suddenly it became known that people without much authorization were able to get access to email messaging.  It would substantially hurt the platform.  So they're at an impasse.  India has not given any deadlines.  And, significantly, they have not singled out BlackBerry.  There are other VPN and peer-to-peer technology providers, like Skype, that have been given the same ultimatum.



LEO:  Really.  Oh, interesting.



STEVE:  Yeah.  So I don't see how this is anything more than huffing and puffing on India's part, but we keep talking about this.  It doesn't go away.  And this has just happened again.  So, he said, "You connect the dots and you're saying, 'Holy smokes.'"



I wanted to let our U.K. listeners know, and I know we have many people who follow the podcast from the U.K., that the major ISPs there have all signed on to a voluntary policy where they're going to specifically delineate what they're doing with bandwidth shaping.  BT, Virgin Media, Sky and others have signed a voluntary code of practice, saying that they'll provide consumers with clear traffic management policy information explaining when Internet connection speeds are throttled, why they are, and what effect that throttling will likely have on consumers' broadband service.



LEO:  That's all we want to know.



STEVE:  Yes.  And the disclosures will also state whether the provider has arrangements with specific content providers to prioritize their traffic.  So basically coming clean.



LEO:  Great.



STEVE:  Which is really, really good news.



LEO:  If you're going to do it, at least let us know so we can choose.  That's great.



STEVE:  So, yeah, I was really glad to see that.  So Friday morning I got a call from Good Morning America.



LEO:  Really.



STEVE:  They wanted someone who could talk on the issue of celebrities' cell phones and email accounts and things being hacked.  And I said, well, I can do that.  And they said, oh, we'd like to talk to you.  And so we talked for about 45 minutes.  And then the producer of this pending segment said, "Steve, come on up and let's put you on camera and just say everything that you said again."  Well, I brought my MacBook Air up with a copy of Firesheep.



LEO:  That must have been fun.



STEVE:  Let's put it this way.  The aim of the segment changed when they saw what was going on.  And I don't yet know when it's going to air, but I will certainly tweet.  I won't be able to, unless there's a coincidence of timing, and I can do it on the podcast, I will.  But I'll tweet when I know.



LEO:  Can you tell us how many people was on that list on the left there?



STEVE:  Well, it got populated and blew their mind.  And I think one of the things they're going to do is set it up themselves and reproduce it, just to show how easy it is.  But one of the things that I thought was significant was I hadn't looked at the download count for a while, and I haven't for two days.  But on Monday we were at 1,334,000 downloads.  And by the following day it had gone up by another 3,500.  So it is still being downloaded.  It still works.



And, now, the good news is, it's having an effect.  Ars Technica just yesterday put out a large column, and about halfway down they said something like, and I'm just paraphrasing from memory, but it was like, "Firesheep:  How a good UI can change the Internet."  And of course you'll remember this is why I was celebrating, with a caveat, why I was celebrating the release of Firesheep.  That's why Twitter now has always HTTPS.  That's why Facebook has it.  It forced Google to go sitewide, more than just using it in Gmail.  So, I mean, and I'm really happy that Good Morning America, a widely watched, nationwide network, morning news show is going to aim some more light on this because this will - raising the awareness of the danger.  First of all, it's really good to do, to let people know what the dangers are; but to get the word out is so important, too.



LEO:  I'm actually surprised they're going to do it because their issue is going to be, this is going to scare the pants off people.  And unfortunately the fix is kind of technical.  But I'm glad they're doing it.  Now, for those who...



STEVE:  Go ahead.



LEO:  For those who don't know what Firesheep is, we did a show on it, and a good description.  But the short answer is, turn on WPA2 on an open access point, and don't use open access points that don't have security.



STEVE:  Right.  And for those services that do allow you to use HTTPS, try to do so.  Turn those settings on in Facebook and Twitter and on Google accounts.  Yeah.  So if you put into Google "How do I install and use Firesheep?" you get 886,000 links.



LEO:  It's pretty easy.  Lots of people want to know that one.



STEVE:  Yeah.  So, wow, 1.3 million downloads since we were talking about this, Leo.



LEO:  Isn't that amazing.  Jiminy Christmas.



STEVE:  I got a tweet that I wanted to share from someone, his handle on Twitter is BioTurboNick, who said, "Just found a bunch of trojans via an MSSE full scan that weren't found by the quick scan."



LEO:  Oh, that's good to know.



STEVE:  Yes.  He said, "The shocker?  They were all Java related."  So we had been talking recently about Java and about removing it unless you needed it because it's becoming a problem.  I mean, it's like we fix one thing, and then the bad guys move to the next soft target.  After we harden that target, they find something else soft.  But so this is the built-in, anyone with Windows has it now, the Microsoft tool.  And I think you can just, in the Run dialogue, you can put "mrt" or...



LEO:  It's "mrt," and it'll open it up.



STEVE:  Yes.



LEO:  And then you can click "Thorough scan."  So I tell people on the radio show to do this, and I'm glad that you're - well, not glad, but it does reaffirm my inclination to do a thorough scan if you think you have a problem.



STEVE:  Right.



LEO:  Because it's better.



STEVE:  Right.  I also discovered, to my surprise, just yesterday - and we're in Errata section now, so I get to be a little weird here.



LEO:  This is - I don't know if "errata" is the right word.  Miscellanea.  Tidbits.



STEVE:  Miscellanea.  Oh, you're right, you're right.  But William Shatner turned 80 yesterday.



LEO:  I heard that, and it stunned me.



STEVE:  80.



LEO:  I can't believe he's 80.



STEVE:  He looks fantastic.



LEO:  Yes.



STEVE:  And in my tweet, because I tweeted this, I said, you know, gee, last time we saw him on "Boston Legal" he looked great.  Maybe a little heavy, but great.  And I got a ton of people tweeting back, saying, uh, Steve, that's not the last time we saw him.  Aren't you watching "$#*! My Dad Says"?



LEO:  Oh, that's right, he's the star of that show.



STEVE:  Yeah, and apparently very funny.  So I've never seen a single episode of it, but I added it into TiVo, so it'll - I think it's on Thursdays.  So tomorrow I'll...



LEO:  Well, you know, it's based on Twitter.



STEVE:  Yes, exactly.  And I think you and I talked about it back when it was just going to be happening.  And so we're in the first season of it.  And many people say it's very, very funny, and Shatner is fantastic.  And I can imagine him being real - but, Leo, 80.  I've got friends who are in their early '70s who can barely walk.



LEO:  I know.  I know.  Denny Crane.  He's looking good.



STEVE:  He really is.



LEO:  Happy birthday.



STEVE:  I think it's all that time travel he did.



LEO:  Yes.  Maybe that's it.



STEVE:  I think that explains it.



LEO:  He's actually 400.  He's so much older than he looks.



STEVE:  And there was also something interesting that I ran into on the Techdirt site.



LEO:  By the way, before we go on, there's another fellow celebrating a birthday on Saturday.



STEVE:  Uh-oh.



LEO:  And he doesn't look a day over 80, either.



STEVE:  Thank goodness. 



LEO:  As long as we're talking birthdays, I've just been informed your birthday is Saturday.  Happy birthday, Steve.



STEVE:  Oh, boy, that chatroom, I tell you.



LEO:  They are sharp.



STEVE:  Can't pull anything over them.



LEO:  They are sharp.  I know, I don't celebrate either.  After 50 it's like, eh, let's not.  Let's not talk about this.



STEVE:  Oh, I don't care.  I talked to Mom because I wanted to let her know about the Good Morning America spot that might be happening.  And she said...



LEO:  "Well, it's about time."  What did she say?  She said happy birthday.



STEVE:  She said happy birthday.  And she said, "I'll be calling you on Saturday."  I said, well, that's our routine.  I called her on the 5th, which was her birthday, so...



LEO:  Oh, that's so sweet.  Well, yeah, happy birthday to you, Steve.



STEVE:  Thank you.  So Techdirt had an interesting posting, someone wondering if using NoScript to bypass The New York Times' newly erected pay wall would be violating the DMCA.  And I thought, that's interesting.  Now, apparently - so a little bit of back story.  The New York Times has generated a huge amount of kerfuffle since announcing that, it's either this week or next week, that they're no longer going to be free.



LEO:  Yeah.  And it's expensive if you're not a subscriber.



STEVE:  Oh, Leo, it's like prohibitively expensive.  Really expensive.  And so it's like, okay, I can find my news elsewhere.  I mean, I like The New York Times.  I love The New York Times.  But, wow, they want a lot of money.  So as I understand it, you can see 20 - you can directly look at 20 articles, and then they block you.  But if you click on links elsewhere, like on search engines that take you to stories, then they don't block you.  And, I mean, I remember thinking the whole thing sounded kind of flaky.



LEO:  Wall Street Journal does that for some reason.  You cannot see full articles in The Wall Street Journal unless you either are a subscriber or pay for it.  But if you find a Wall Street Journal article link on Google News, you get the full article.  So all I do, when we share Wall Street Journal articles with our hosts because we're going to talk about them, I just go to Google News, get the article, and send them that link because they can read the whole thing.



STEVE:  Crazy.



LEO:  So I think these companies know and understand that there are loopholes.  But they figure most users are not going to know about them or take advantage of them, so that's fine.



STEVE:  So people who have looked have determined that there's four lines of JavaScript that are, like, blocking people.



LEO:  Well, at least they're efficient.



STEVE:  And that, if you have NoScript on, then this ridiculous "pay wall," as it's called, doesn't get erected.  And you can simply use The New York Times without being blocked.  And so the question then would be, are you altering the content and violating The New York Times copyright through, like, their terms of service probably change to reflect the paywall.  So anyway, it's sort of an interesting question.  There's a bookmarklet called NYTClean which is just, being a bookmarklet, it's a little bit of JavaScript in a bookmark, essentially.  And if you ever - you can probably Google "NYTClean" to find it.  And you just click that, and then it resets your paywall blocking.  So I don't know, it seems crazy for them to have done something so weak.



LEO:  Well, again, I think that they realize that there are, I mean, how many people use NoScript, compared to their subscriber base?



STEVE:  Good point.  Lots of people will go, oh, shoot.  Okay, here's my money because I want...



LEO:  I think anything like this relies on goodwill.  You can always get around - we don't charge for anything we do.  And one of the reasons is I watched what happened when Revision3 started to charge for Diggnation.  They said you can get early access if you pay for it.  And of course, when you have a technically sophisticated audience, as they do and we do, it didn't take more than a day or two before people paid for it and then put the early release version out on the Internet so nobody really had to pay for it.  They quickly abandoned the plan.  I would never do a subscribe version of this because I know that you guys are way too smart and would immediately get around it.  But I'm sure that The Wall Street Journal and The New York Times just figure, well, we're going to rely on the goodwill of our readers for the money.



STEVE:  And they're wanting to get some revenue.  It's been free forever.  And so they're saying, okay, it's time for us to start making money.  And it will be very interesting to see how this turns out for them.



LEO:  The Times says they don't need more than a few percent of the people who read it to pay to make it worthwhile.



STEVE:  Oh, cool.



LEO:  It's quite annoying.  I subscribe.  I am actually - I get the dead tree version.  So I get it for free.



STEVE:  So you have free online access.



LEO:  Yeah.  It's really expensive, though.  I don't think I'd pay for it if I didn't get...



STEVE:  It is.  I mean, there's just too many other good places you can go.



LEO:  Well, and we're conditioned to getting it for free.  So...



STEVE:  Yes, exactly.



LEO:  It breaks the Internet, frankly.  It's not - so we'll see.  I think it's foolish.  But it's their business.



STEVE:  So the news is really nothing but good at Fukushima.  We've talked about the reactor problems since the earthquake and the tsunami.  And I've been tweeting about it constantly as I've been just sort of like following their progress in getting electrical power restored.  They're filling the reactors from afar by shooting water into the spent fuel rod pools.  And the reactors 5 and 6 now have cooling, electrically powered cooling for their spent fuel pools.  The reactors did reach cool shutdown, that is, 1 through 4, the ones that were running at the time.  And they've got electric power now being brought to them, and they're bringing them back.  So basically I think this is going to end up being really an amazing case of phenomenal luck that...



LEO:  Oh, that's not good.  If you're relying on luck for this stuff, that's not good.



STEVE:  Yeah.  I did have a real - I found a great URL that I wanted to share with people.  It's jaif.or.jp/english.  And it's a lean site that, several times a day, publishes an updated PDF chart of the status of all six reactors with a tremendous amount of detail, really interesting.  So, again, it's jaif.or.jp/english.  And so I just wanted to pass that on.



LEO:  The Japanese Nuclear Foundation?  What is it?  It's Japanese Atomic Industrial Forum, that's it.



STEVE:  Yeah, exactly.  And if you look at, if you just click one of the, like, the most recent link at the top there of their PDFs, it's just a spectacular chart.  And several pages of it, too, I think six or seven pages of information.  So for anyone who is interested in and having their fingers crossed, as I have, as this - I mean, the last thing we wanted was a really bad problem there.  So I think they averted it.  And just my final little bit of wackiness is the news that Apple has sued Amazon over Amazon's use of the term "App Store."  It's like, oh, come on.  App Store?  Really?  Apple, you think you own that term?



LEO:  They do have a trademark.  I mean...



STEVE:  Well, and so I wrote to my own trademark guy, my intellectual property guy, this morning.  And he wrote back, and he said - I wanted to share what he said because it's a little bit of insider, inside-industry info.



He said, "It is an interesting case.  Apple based its U.S. application for the mark APP STORE on a foreign registration from Trinidad, likely hoping to go under the radar as opposed to filing directly like normal."  Now, and understand, the reason they did that is that normally "App Store" would never qualify.  I mean, it'd be like...



LEO:  No, it's too generic.



STEVE:  Exactly.  Well, it's descriptive.  And something that's descriptive is immediately disqualified for trademark registration.



LEO:  Aha, interesting.



STEVE:  That's why something like Kleenex, the word "Kleenex" tells you nothing about what the product is.  And someone mentioned in the GRC newsgroups that, well, after all, Microsoft got a trademark on "Windows."  It's like, yes, but that, the word "windows," even though it actually is a word, it doesn't describe at all what Microsoft's software was.  They created that connection.  But Apple trying to get "App Store" is really pushing the limit.



So continuing what my attorney said, he said they filed in Trinidad, "likely hoping to go under the radar as opposed to filing directly like normal.  It had the opposite effect.  Apple's application was refused registration [in the U.S.] based on descriptiveness...."



LEO:  Oh, interesting.



STEVE:  But then they "overcame the refusal [on appeal] by arguing acquired distinctiveness (basically that it was descriptive, but now due to Apple's marketing and notoriety consumers know the App Store emanates from Apple)."



LEO:  That's a good point.



STEVE:  "USPTO [U.S. Patent and Trademark Office] bought the argument, but Microsoft is now opposing the registration of the application.  I believe Amazon saw Microsoft's argument and thought, let's ride Microsoft's coattail."  And he finally said, "This is one of the really interesting cases between folks with plenty of resources.  This will be played out on many levels and a lot of fun for us with no interest in the case."



LEO:  Yeah, because Amazon has an app store now, and it's an Android app store.  I use it, and it's pretty good.



STEVE:  And you've seen all the rumors about Amazon doing an Android tablet?  I mean, they'd be perfect for it.



LEO:  Turning the Kindle into a - well, you know, the Nook, the color Nook is a pretty capable Android tablet, if you hack it, the Barnes & Noble Nook.



STEVE:  Oh, no kidding.



LEO:  Oh, yeah.  And in fact Microsoft, just to complete the circle, is suing Barnes & Noble over Android, preparatory, I think, to claiming that...



STEVE:  Microsoft?



LEO:  Microsoft claims that Android violates its patents.  And this is the first of what I expect will be...



STEVE:  Oh, my god.  Then they're going to establish that, and then go after Google.



LEO:  Yeah.  Well, I think they wait till they have a pretty good war chest before they go after Google.



STEVE:  Wow.



LEO:  So it's just a fascinating, I mean, oh, my god.  I always say, you know, compete, don't litigate.  And often companies that can't compete end up litigating, and that's just a mess.



STEVE:  Wow.



LEO:  Just a mess.



STEVE:  Well, I did have a short note from a listener, David W. Roscoe, who wrote to say that SpinRite saved a music studio.  He said, "Hello, Steve.  I'm a longtime user of and advocate of SpinRite.  I've also been a listener of Security Now! from the beginning and have heard you tell a few stories about using SpinRite to recover hard drives from devices that are not computers.  I have such a story which you might not have heard yet.



"My brother's a professional musician.  He uses a Boss BR-1180CD digital recording studio.  It's a tabletop device that he uses to record and mix his songs.  One day he told me that it had stopped working after going through a period of increasingly frequent freezing.  He said his repair service could fix it by replacing the hard drive, but he would lose the several dozen songs he has stored inside.  He did not have any backups and asked me, the family computer geek, whether there was another way.  I told him about SpinRite, that I was willing to give it a try on his hard drive.  He had nothing to lose, so he let me.



"I opened the device and discovered that it contained a 20GB IDE hard drive.  I moved it to one of my computers and ran SpinRite on it, which found a bunch of bad sectors, including some nonrecoverable ones.  But the device did not work again when I reinstalled the drive.  Apparently one of those nonrecoverable sectors had contained something needed for startup.  I will skip the details and say simply that I was able to find the song folders after SpinRite fixed it on the mostly recovered drive, copy them to an initialized replacement drive, and trick the device into thinking that those songs were its own."  He is a computer wizard.  "My brother got all his songs back and was very pleased.  This would not have been possible without SpinRite.  Thanks for all the great stuff you've produced and continue to produce.  Sincerely, David W. Roscoe."



LEO:  Excellent.



STEVE:  So he solved the problem in a roundabout way on a wacky digital recording studio thing from Boss that happened to have a hard drive in it.



LEO:  I wish I could easily get the hard drive out of my iMac, it's a real pain, because my son's hard drive crashed.  And I'm sure I could put it in a PC, SpinRite it, and it would all be fine.  But the iMac, the big negative, you have to actually take suction cups and remove the glass.  It's very - it's ridiculous.  Colleen did it, she's got more nerve than I did, some time ago when the hard drive on my iMac here died.  And I remember watching her do it.  And I thought, oh, geez.  Oh, geez.  I ain't doing that.  No user-serviceable parts inside there.



STEVE:  She can weld, so she can pretty much do anything.



LEO:  Yeah.  Well, she had nerve.  That was the thing.  I mean, that just takes nerve.  It was like, I mean, suction cups to remove the glass, it was crazy.  I think I might have to try it, though, just to see.  Or a hammer.



IE9 just came out, what, about last week that Microsoft pushed it out.  People have been using the release candidate, but now the official version is out.  Doesn't automatically update in Windows.  You have to, when you open IE8, you get a little button that says, would you like to try IE9?  But I think they said something like 25 million people have, so it's out there.



STEVE:  So it's really good news.  I don't think it matters.  But it's really good news.  It is, in many ways, a state-of-the-art web browser for Windows.  And that's just a good thing.  As we know, Internet Explorer has been losing market share.  The more really good browsers come in, the more people get pried away from IE.  I famously got pried away over to Firefox.  I'm not going back because I love the Firefox ecosystem.  You were on Firefox for a while, having left Safari on the Mac, and now you're a Chrome user.



LEO:  Big-time Chrome fan, yeah.



STEVE:  Yeah.  But one of the problems the whole industry has had is that IE has really been a boat anchor from a standards standpoint.  Famously, there were some things that, version after version after version, from IE5 on, and these are multiyear gaps between, Microsoft just stubbornly refused to fix or to do the event model - now that I'm a JavaScript programmer, I'm having to work around IE-specific stuff all the time.  And, finally, in 9, they have - they've actually gone overboard, if that's possible, with support for standards.  And so it represents a massive investment on Microsoft's part to create a browser which is as standards-compliant as they are.  And in fact they're now more standards-compliant than anybody else.



LEO:  Oh, interesting.  Good for them.



STEVE:  They really are.  I've got some numbers here that I'll cover.  But so this was two years in the making.  They announced their work on 9 shortly after the release of 8.  And this was, like, at the developers conference in '09 that they said, okay, we're going to start working on IE9, and they began bringing pieces of it out.  It's got strong support for CSS3, Cascading Style Sheets 3, and Scalable Vector Graphics, SVG technology.  Their score on the Acid3 test is a 95 out of 100.  Whereas IE8, which was two weeks ago, was 20 out of 100.



LEO:  Boy, that's a big improvement.



STEVE:  So it's a huge improvement.  And Firefox 3 is a 94.  So they - oh, and IE8 just collapses completely and fails, doesn't even - it just is a disaster.  So they've really done well there.  It's got a new JavaScript engine, code name was Chakra, which compiles to native Intel machine language using its own thread in the background to leverage multicore processors.  So your page comes up, and it starts to go.  And then, if you've got a multicore processor, the background Just In Time, the JIT compiler, will take off and basically turn your JavaScript into native code.



Now, what's interesting is that, while it is much faster than any IE before it has ever been, it's still not very fast.  Well, I mean, it's a contemporary browser, meaning that it has joined the ranks, finally, of Firefox, Opera, and Chrome.  And I guess really Safari is lagging behind now in terms of their technology.  But it does support HTML5 audio and video natively.  So this is what we're beginning to see is, if all you really need, for example, Flash for is displaying movies, is displaying movie clips or video, you no longer need Flash when you've got HTML5 video support.  And HTML5 wants H.264 video, which is our standard MPEG-4 container.  So we're moving away from the dependence on Flash for video that we've traditionally had.



Lifehacker, just like a couple days ago, did a set of benchmarks on Firefox, Chrome, Opera, and IE.  IE9, meaning.  IE9 was - oh, so Firefox 4; Chrome I think 10 and 11, 11 is the dev release of Chrome at this point; Opera 10, or the latest version, I think it's Opera 10; and IE9.  IE was the slowest one of those to start up.  It was the slowest on JavaScript, but it was able to finish, which IE8 hadn't been able to do.  And interestingly, the 64-bit version of IE9, which is not the default even on 64-bit platforms, was four times slower.  So probably not optimized.  Maybe the Just In Time engine isn't working yet on a 64-bit platform.  But again, you'd have to really try to use it because it's not the default, even on 64-bit Windows.  The 32-bit is.



It also has the slowest Document Object Model and CSS system.  But again, it was able to finish, whereas IE8 couldn't.  And it has the highest memory usage.  So it's just out a few days ago.  And it's pretty much across the board worse than all the others, but vastly better than IE8.  However, one place it blows everyone away is in its standards handling.  It is extremely standards following.  There's a JavaScript test called test262.ecmascript.org.  People may want to play with it.  It's super easy to use, that's why I want to give everyone the URL:  test262.ecmascript.org.  That'll come up.  Now, IE8 doesn't even display the page, just can't even get there.  It runs a huge battery of tests, 10,456 different tests.  My current latest version of Firefox 3, out of 10,456 tests, fails 3,661 of them.



Okay.  We'll call Firefox 3 prior generation.  Now we move to current generation.  The latest Chrome, latest version of Chrome, out of, again, 10,456 tests, Chrome failed 497 of those.  So it passed a huge percentage, but it failed 497.  Firefox 4, just out, was better.  It only failed 301.  IE9 only failed 17.  Which is stunning, 17 out of 10,456.  So IE9 really is incredibly standards compliant.  And they have a state-of-the-art JavaScript engine.  And, I mean, again, when I started off by saying I'm not sure that any of this matters, what I mean of course is that we have really good alternatives to IE9 anyway.



The reason it's worth covering on this podcast is that it has a chance to stay strong.  And even though people listening to the podcast may have already switched to Firefox and/or Chrome, all of the people that they support who are still using IE can move to IE9.  Next version of Windows will I'm sure have IE9.  We've seen that the adoption rate of IE9 among Windows users who are conscious of this is strong.  So it matters.  Okay.



It also matters in terms of what Microsoft has done from security and privacy, which I'm impressed by.  We've talked briefly about Tracking Protection Lists, so-called TPLs.  This is - something makes me nervous, and I'm going to explain why.  But it's potentially very nice.  IE8 had sort of a - what was called InPrivate Filtering, which was part of InPrivate Browsing.  And the way InPrivate Filtering worked was, if you went to a bunch of different websites, and IE noticed that there were common third-party sites that kept being invoked by the first-party sites you went to, IE8 would adaptively - and this is impressive - it would adaptively add them to a filter, saying these are trackers because you're going to all these different first-party sites and, like, you know, DoubleClick.net keeps popping up as being polled by these first-party sites.  And so it was a way that IE8 would adaptively recognize tracking behavior.  So that was impressive.



The problem is that InPrivate Browsing wasn't something you could turn on and have stay on.  You had to deliberately go there every time you started up IE.  So it's like, okay, I don't know if Microsoft was afraid to do this full-time, or they wanted to offer it, but they felt that if they allowed you to turn it on and have it be sticky, it would be too aggressive.  Who knows.  But the good news is that's changed with IE9.  We now have these things called Tracking Protection Lists that are files you can get from third parties who maintain them for you.  The syntax of the file is very simple.  No nightmare of even XML nesting stuff.  It's just a simple flat text file.



The first line, in order to qualify, has to have the word "FilterList" in it somewhere, which qualifies it as a tracking protection list.  You can then put comments in by starting them with a pound sign.  If the first character is a pound sign, the rest of the line is ignored as just being a comment that's human readable.  If the first line starts with a colon, then that's a setting line.  And at the moment there's only one setting that's supported, and that's Expires= and then a value which must be between 1 and 30, which is the number of days that IE can wait before checking for an update.



So this is very nice.  It means that you're able to add one or more of these TPLs, and IE will maintain them for you.  It will go back to the source URL, which it keeps, and refresh them as this changes for you.  Now, there's additional syntax for specifying what is and is not allowed.  If a line begins with a +d, then it's followed with a domain name string specifying what domain this applies to, and then an optional string where the URL must contain that string to qualify.  And the "+" means that this is an allowed domain, that is, we're going to allow IE to fetch content from there when this is being fetched in a third-party context.



So when your web browser is going to some site, if the page you load then makes references to other domains, they're checked against this list.  So if that domain name occurs on a line that has a +d on it, it's allowed.  If it's a -d, then it's not allowed.  And after the domain, also for the -d, can be a string which, if there, must be present for that line to qualify.  And then you can also just have a minus sign by itself, without a "d," in which case the string that follows the minus sign, if that appears anywhere in the URL, then it matches, and the minus means disallow.  And an asterisk can be a wild character that can match any number of characters which occurs in the string at that point.



So this is a very simple and a very powerful syntax for qualifying and disqualifying fetches to third-party sites.  In the case of having - oh, and you can have many lines, which can be mixed with pluses and minuses.  The semantics of that is that all of the allow lines are looked at first.  And anything that matches any of the allow lines qualifies for allow.  Then the disallow lines are looked at, and anything that matches them, any of those queries are thrown out.  They're just dropped.  And then queries that don't match anything are allowed.  So it's explicit allow, then explicit disallow, and then implicit allow is the sequence of processing.



Now, in the UI in IE9 they provide already a bunch of sites that are producing mature tracking protection lists.  And they're familiar names.  There's the Adblock Plus people who have, I think, is it EverList?  It's a name I know because I've got on my adblocker on Firefox.  I subscribe to that list, and so it automatically provides updates for me.  But here's the problem.  I mean, so all that's good news.  I looked at some of these TPLs that are available, and some of them are horrifying because I see a real problem with false positives.  The domain-based blocking is fine because, if you block DoubleClick.net, it's DoubleClick.net.  And the domain has to match in order for that rule, that block rule, to apply.



But that free-wheeling string blocking scares me.  For example, in the EasyList from Adblock Plus, they have a block on the string ".com/ad-."  Now, that means, because it's not a domain name block, it's just .com, that means that any resource on any domain, any .com domain that happens to begin with /ad-, even if it's not a domain, I mean, even if it's not an ad, gets blocked.  I mean, your browser won't see it.  Or ad. or ad/ or ad_.  And this goes on.  So it's a little worrisome that this thing could false positive.



I'm assuming, and I don't believe that I read carefully or saw this specifically, that it absolutely only applies for third parties.  It has to be that this only applies for third parties, or sites would be in danger of blocking themselves.  So that's some benefit.  But I'm a little concerned about this being a false positive.  And then the second problem is that this opens us up to the traditional cat-and-mouse game.  If the advertisers know that starting their ads with ad- is going to make them not show up...



LEO:  They're not going to do it.



STEVE:  They'll just change it to "bd" or "ax" or whatever.  So basically these...



LEO:  Kind of a goofy system, to be honest.



STEVE:  It is.  It is.  Unfortunately, again, it puts us immediately in this cat-and-mouse problem where now here's these lists that Microsoft makes available through the UI, which you can add.  And, I mean, they're initially useful except that they're also a template for the advertisers to use for how not to name their ads, in order for them to get around it.



LEO:  Yeah.  Here's how - by the way, in case you're interested in getting around this, here's how.



STEVE:  Yeah.  If you name your ads any of these things, then we're not going to display them.  So let's not name them that.



LEO:  Do they think that advertisers will opt in as a goodwill gesture? 



STEVE:  I don't know what they're thinking.  I mean, this is what Microsoft has come up with as their solution.  And it's another one of those, well, okay.  It's better than nothing, but it seems to me that it's easy to get around because here's the template for how you do it.  Now, the good news is they are also supporting the do-not-track header, which, if we can just please get some legislation, then this is the perfect solution for our problem.  They've submitted this to the W3C.  Mozilla has submitted this.  And amazingly, they're compatible.



LEO:  Oh, that's good.  That's good.



STEVE:  Yes.  We do not have yet another format for a do-not-track header.  It is DNT: 1.  And the way IE9 works, if you enable any tracking protection list, if you have any tracking protection, then this header is included with every query it makes.  That's just what we would want.  And that's the same as under Firefox 4.  In the Firefox 4 UI you're able to say, tell sites I do not want to be tracked.  And you can turn that on, and then Firefox will add the DNT: 1 header to all its queries.



LEO:  Now we just have to get Chrome to do that, and we're set.



STEVE:  Yes.  I wish Google hadn't gone off in this other weird direction with their persistent lists or whatever that was we talked about a couple weeks ago.  And so the good news is I think Google will probably do it because, with Firefox and IE9 both doing it, I mean, again, everyone says, oh, yeah, well, people can simply ignore it if they want to.  It's like, well, yes, they can.  And that's a problem.  But if we get legislation that backs it up, then we're starting to move forward correctly.  And I'll mention that there is a user - there's, like, a personal TPL, Tracking Protection List, that you can enable and leave blank if you don't actually want any tracking protection lists, but you do want the do-not-track header to be added in IE9.  So we have that, and that's a good thing.



In terms of malware protection, IE9 hasn't really advanced that any further.  They've added something called - they still support DEP, the Data Execution Protection or Prevention, with a don't-execute bit for processors that support it, and now pretty much all contemporary processors do.  And we had that in 8, and we have that also in IE9.  They do support Address Space Layout Randomization (ASLR), as IE8 had, that's also there in 9, and Safe Structured Exception Handling [SafeSEH] to handle structured exceptions.  There were some exploits of that.  That is, the bad guys figured out how to actually use structured exception handling, which is - essentially it's a way for 

a programmer to say, if in the following block of code anything bad happens, come here so I can handle it rather than just die.



The problem is, the bad guys figured out, hey, we can subvert structured exception handling so that, when we do have a buffer overflow, it'll come to us rather than killing the application.  So naturally they figured out how to commandeer that technology.  The good news is that IE9 has enhanced that.  They now have something called SEHOP - getting a little carried away with our acronyms.  This is Safe Exception Handling Overwrite Protection, which validates the validity of the structured exception handling chain before dispatching exceptions to it.  So it makes sure that the bad guys haven't overwritten the structured exception handling before it's being used.



And, significantly, that's being implemented on a per-process basis, not just on a per DLL.  These other things, like DEP and ASLR, remember that DLLs had to be recompiled specifically to enable that.  And so some - and we've even seen some exploits which took advantage of the fact that a couple DLLs in earlier versions of IE still hadn't been recompiled, and so they were loading into known locations. They were not using ASLR for themselves, and that's all it took for the bad guys to take advantage of that.



And then, finally, IE9 has been compiled under Microsoft's latest state-of-the-art C++ compiler, which - and IE8 was not.  IE9 was, and it adds support for something called Stack Buffer Overrun detection, which is something built in at the compiler level which should make IE9 more robust against those kinds of exploits.



Now, the thing that impresses me the most is, for the common user, is something new in IE9 called SmartScreen Application Reputation.  What we're all...



LEO:  That's SSAP.



STEVE:  Or SSAR, SmartScreen Application Reputation.



LEO:  SSAPR.  We'll call it SSAPR.



STEVE:  Okay.  We will.



LEO:  Yes, we will.



STEVE:  We're all used to seeing the warnings whenever we download anything these days, saying this has been downloaded from the Internet; therefore it's potentially hazardous.  Are you sure you want to proceed?  Well, what do we do?  We all say yes.  We know we just downloaded something from the Internet, and we want it, or we wouldn't have downloaded it.  So, yes.



LEO:  Of course we want that.



STEVE:  IE9 doesn't do that.  And...



LEO:  What does it do?



STEVE:  Which is fantastic, actually.  IE9, I'm going to quote from their explanation:  "Based on real-world data we estimate that this new warning" which they have, this SmartScreen Application Reputation warning, "will be seen only 2-3 times a year for most...."



LEO:  Wow.  But if you see it, then pay attention.



STEVE:  Exactly.  That's the point, exactly.  This is training people.  Instead of training people to ignore it, this is - I mean, and this is sort of what we saw with the evolution of Vista - I'm sorry.



LEO:  Of UAC.



STEVE:  Yeah, of Vista into Windows 7, exactly, with UAC.  It's in your face much less often, so it's like, oh, okay, maybe I ought to read this.  So they're saying, "...for most  consumers compared to today where there is a warning for every software download.  The key" - I'm still reading - "the key challenge with malware on the Internet is that attacks are fast moving and quick to change.  The importance of application reputation is as an early warning system.  There is latency between the outbreak of an attack and when it is detected and [proactively] blocked.  Consumers today are unprotected during that time.  Think of this new warning as 'stranger danger.'  It's an early warning system for undetected malware.  No antivirus or protection technology is perfect.  It takes time to identify and block malicious sites and applications.  Blocking after detection is still an important strategy, but there remains a gap between the start of an attack and when it is detected and blocked.  IE9 SmartScreen Application Reputation fills that gap."



And it does it as follows:  "When you download a program in IE9, a file identifier and the publisher of the application (if digitally signed) are sent [in real time] to a new application reputation service in the cloud."



LEO:  Oh, interesting.  Wow.



STEVE:  Yes.  "If the program has an established reputation, there is no warning.  If the file is downloaded from a reported malicious site, IE9 blocks the download, just like IE8 does.  However, if the file does NOT have an established reputation, IE lets you know in the notification bar and download manager, enabling you to make an informed trust decision."  And they give an example of a file called "06-FHU-ICB.exe," and it says, "is not commonly downloaded and could harm your computer."  So they affirmatively acknowledge files to be downloaded that have a good reputation, a known reputation.  They affirmatively block known dangerous files.  And then until a file has established a reputation, only then will you get a notification saying we don't know about this, it's not commonly downloaded, so it could harm your computer.  I think this is a huge win for the common casual user.  And this is the kind of thing that Microsoft can do, invest in this kind of a large infrastructure and, like, ecosystem for a major feature, that it's really hard to compete with.  I salute them.  I think this is a tremendous feature.  I think it's going to benefit a lot of users.



LEO:  Of course we've got to hope they keep this database up to date.  But I'm sure they will.  Google does something similar.  I mean, they'll let you know if it's a known site with some problems when you search.



STEVE:  Well, and I would imagine it's happening on the fly and automatically.  No doubt it ties into the MSRT technology, to their own virus stuff, things you download, I mean, every time you download, it sends notification to the cloud.  So we also need to be - once upon a time we would immediately twitch about this from a privacy standpoint.  It does mean that your downloads are trackable, which needs to be remembered.  I would imagine Microsoft has addressed it by obscuring this.  But it does mean that files with a reputation are being checked.  So your...



LEO:  It doesn't need to be necessarily your download.  It could be that, in the process of indexing pages - and I think that's what Google does.  If they see malware, they add it to a database.



STEVE:  Well, but...



LEO:  That means Microsoft would have to download everything; right?



STEVE:  This is you clicking on a link does send that act identifying the file you're trying to download into the cloud.



LEO:  Yeah, that's right, yeah.



STEVE:  So it does mean that you can be tracked.  The flipside is, for the common user, you're not having to be warned for files that have a good reputation.



LEO:  Right.  That sounds sensible.  As long as they don't miss, well, I mean, it can give you a false sense of confidence, as well; right?



STEVE:  If there's no reputation established, then you get the warning.  So it's only when...



LEO:  Aha.



STEVE:  Yes.  So it's only when a file's been downloaded a lot and then, like, no alarm bells have gone off, no antivirus has been fired, nothing bad has happened, then the cloud says, eh, looks like we're going to trust this.  Oh, and it also knows where it's coming from.  For example, I sign, I Authenticode-sign my Windows apps, and they're being downloaded from GRC.  So I've already established a reputation for myself.  So when I come out with a new piece of freeware, Microsoft already knows, oh, GRC, yeah, he's a good guy.



LEO:  So the default is to no reputation, for a brand new file no reputation.



STEVE:  Correct.  And then you're just - and that's the thing that Microsoft believes people will only see a couple times a year because...



LEO:  I don't know about that.  Aren't there a lot of, I mean, I don't know about that.  I guess it depends on...



STEVE:  Well, but consider all the people who download Firefox in Windows.  Every single time...



LEO:  They're not going to see that, of course.



STEVE:  Right, right.



LEO:  But, I mean, there are some sites that offer new files all the time.  I guess if the site is - so you're saying, if the site has a reputation, it'll be okay.



STEVE:  Correct.



LEO:  Yeah.  That's interesting.  Well, we'll see how it works.



STEVE:  Yeah.  And then the last thing I had in my notes is the User-Agent header has been in IE9 dramatically cleaned up.  Remember how bloated...



LEO:  It used to be a lot of stuff.



STEVE:  Oh, my god, Leo.  Remember every version of .NET that you'd ever run across in your lifetime, and then other things.  I've got this Flash, I've got that, I mean, it had become increasingly long.  And it was becoming a tracking problem because your browser, it was one of the things that the Panopticlick site glommed onto and said, oh, look at how unique this is.  Who else has exactly this combination of versions of things?  Because all that version crap in there, that's all gone.  It now says Mozilla/5.0.  They bumped it up from 4 to 5 because they are so standards compliant that they figured it was time, and they deserved it, and I agree.  Then, open parens, it says "compatible" as it always has; and then MSIE 9.0, because they are; and Windows NT 6.1, meaning 7 because it really is Vista with some different candy coating, so Windows NT 6.1; and then Trident/5.0.  Trident is their layout engine.  And it used to be 4, and they've bumped that up to 5 for their latest standards compliant.  Close parens, and that's it.  There's nothing else.  [Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)]



LEO:  That just shows you how bad it was if that's cleaned up.  But all of that information necessary for a web page to know because it's telling the web page how they're going to be rendering.



STEVE:  Oh, and I forgot to mention also that the do-not-track header does have an appearance in the Document Object Model, meaning that script running on the page can detect whether the do-not-track header is being used.  So that allows scripts to be aware of whether the user is requesting no tracking so that sites could be preemptive if they said, hey, you're blocking resources that help pay our bills.  We need you to please allow that for us.



LEO:  Hmm, interesting.



STEVE:  So that exists there, too.  So, overall, I'm impressed with it.  It has caught up from a - largely caught up from a performance standpoint.  It is, frankly, it's the standards leader at this point.  And these standards are not easy to pass.  I mean, if you've got something like Firefox 4, that is typically state of the art with following standards, still failing 300 tests of ECMAScript 5, although it's 300 out of 10,456, and I looked through them, and they're not horrible game-changer things; and Chrome failing 497 of them, almost 500; but still IE9 only fails 17.  Very impressive.  So very standards compliant.  We'll see how the tracking protection lists fare.  A little bit of improvement in their security model, their layered security model.  And some nice user-side improvements with the so-called SmartScreen Application Reputation for things that you download.  Overall, I'm impressed.  I mean, I'm staying with Firefox.



LEO:  I was going to say, you're going to switch?



STEVE:  I love all the goodies.  No, I'm not going back.  And I can't use IE9 because I'm on XP still.



LEO:  Oh, that's right, yeah.  You know, I just love Chrome so much, I probably won't.  But it's nice to know that you can, and it's safe.  And remember, if you're using Windows, you're using IE9 whether you like it or not because Windows uses IE so often to render things, and many applications do, as well.  So you don't get the choice in a number of situations.



STEVE:  Yeah.



LEO:  Steve Gibson is at GRC.com, the Gibson Research Corporation.  That's where SpinRite lives, the world's finest hard drive recovery and maintenance utility.  You've got to have a copy if you've got hard drives.  Go there to buy it.  You can also get lots of free things at GRC.com, including free copies of this podcast in 16 or 64KB form, complete show notes, and he even gets transcriptions done so you can read along as you listen.  GRC.com.



We've got the video on our site, TWiT.tv/sn.  In fact, if you want to watch live, we do this show live every Wednesday at 11:00 a.m. Pacific, that's 2:00 p.m. Eastern time at live.twit.tv.  And you're invited to stop by, say hi.  Coming up in just a little bit, This Week in Google.  And then we're going to interview Bob Heil, the microphone guy, who makes the mics you and I use...



STEVE:  Oh, cool.



LEO:  ...on Triangulation.  Yeah, Bob's in town, so we thought that would be fun.  He's got some great rock-and-roll stories.  That's coming up at 4:00 p.m. Pacific, 7:00 Eastern.  Thank you, Steve.  We'll see you next week.



STEVE:  Thanks, Leo.



LEO:  On Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#294

DATE:		March 31, 2011

TITLE:		Listener Feedback #114

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-294.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 294, recorded March 30, 2011:  Your questions, Steve's answers, #114.



It's time for Security Now!, the show that helps you stay safe online with the man, the myth, the legend, Mr. GRC.com, Steve Gibson.  Good morning, Steve.



STEVE GIBSON:  And that never gets old.



LEO:  Yeah, well, it's true, I mean, I have to say, if you're going to do a security show, there are lots of security experts, but there are very few with the breadth and depth that you have.  So this show is more than just how to lock your browser.  This is how stuff works, how crypto works.  And so I like somebody like you who really has a broad-brush understanding of this.



STEVE:  Well, and it comes from my passion.  I just, I really, really am interested in this stuff.



LEO:  Yes.  Well, we share your interest, so that's why we're glad you're here.  Today is a Q&A day; yes?



STEVE:  Yes, Q&A.  We've got 10 questions and a couple, some of them are sort of short things; so as I was running through things, there were some little tasty tidbits that I just couldn't resist throwing in.  We've got a couple of bonuses at the end.  And not an overabundance of security news this week.  No updates have happened.  There was, I just - I don't know why I feel compelled to mention when RealPlayer has problems.  We last did about a month ago, they had a security fix in early February.  Now there's another one, a heap buffer overflow.  I don't have any real sense, either, for how many people are still using RealPlayer.  But I think there is some penetration, for example, in the corporate world.  And somewhere I tried to go, like C-SPAN or something, they still make you use Real...



LEO:  Oh, I hate that, when you go to a site, and you have to use RealPlayer to play back the video or audio?



STEVE:  Exactly.  So anyway, on the Security Focus website I kind of got a kick out of this.  Apparently the person who found the problem described it, saying:  "RealPlayer is an ugly media player...."  I don't know if he didn't like the UI, or if he just meant ugly from a hacker standpoint or from, like, an internal workings standpoint.  But he says : "...an ugly media player..."



LEO:  It's both, both.



STEVE:  Yeah, probably, "...developed by RealNetwork and used mainly for its browsers' plug-in supporting the proprietary file formats of its developer."  And then under the "Bug" category on the Security Focus posting, he wrote:  "Classical heap buffer overflow during the handling of the IVR files caused by the allocation of a certain amount of data (frame size) decided by the attacker."  And you never want to have your allocations decided by the attacker.



LEO:  By the attacker, that sounds bad.  I don't know what it is...



STEVE:  Really not a good idea.



LEO:  ...but it doesn't sound good, yeah.



STEVE:  We're only going to allocate a little bit, but we're going to write a lot and just see what we stomp over.  And that of course is the way you overflow the heap.  And he says:  "...and the copying of another arbitrary amount on the same buffer."  So, yes, that's about as bad as it could get.  That's in the rvrender.dll.  I checked.  They have no updates as of the recording of this podcast.  Hopefully they will get onto it.  The nice thing about Real is that they're not trying to make any claims as to, well, we're only going to update quarterly, so hold onto your seats in the meantime.  So they'll fix it when they can, although I think I also just, it flew by my eye on the news a couple days ago, that they've just lost their CEO.



LEO:  Yeah, their CEO quit after a year.  Rob Glaser, the founder of RealNetworks, quit a year and a half ago.  Replaced him, that guy just quit.



STEVE:  Yeah.



LEO:  Doesn't feel like a vital, growing...



STEVE:  Ongoing enterprise.



LEO:  You know, they tried, last year they announced kind of a complete pivot on their business model.  I don't even remember what it was.  It just was - it was odd.  And I think it's obviously not going so well.



STEVE:  And when I went to their site to see what they had to say about this, there's, like, all this other stuff going on.  It's like, okay.  There's, like, nine different things they're trying.  Essentially, they were first, to their credit.  Rob left Microsoft and founded Real.  And they were out there early.  Unfortunately, they really upset people who cared by over-commercializing their player.  I mean, it's like spyware before spyware existed.  It was really nasty.  And so they got a bad reputation and really created an opportunity for other alternatives.  So I just think their day is probably past.



LEO:  Yeah, I think that's true.



STEVE:  Now, the big news this week I'm not going to address in today's podcast because it's going to be the entire topic for next week, because there's so much interesting detail about it.  And that of course is the rogue SSL certificates that were issued by a reseller of Comodo.  Comodo is one of the trusted certificate authorities in all of our browsers.  And a collection of alarming sites, I had the list earlier this week, and I've got it in my notes.  We'll go over it in detail next week.  But, I mean, like, Yahoo! and Google and a few other very high-profile domains had SSL certificates issued maliciously.



Now, some rumors are, for example, that it was hackers in Iran, or even maybe acting on behalf of the state because, as our listeners know, essentially what a rogue SSL certificate allows you to do is impersonate that site.  But other people have said, wait a minute, that's only part of the game because you've got to get the person to go there, like to the wrong server, in order for that server, the rogue server, to serve the rogue certificate.  But if you're a country, and you control the borders of your traffic, then you don't need to spoof IPs; you don't need, like, a DNS attack or something.  You can essentially put up a proxy, and no one within your confines would know that they weren't actually going to that correct site.  And SSL would not function in terms of keeping privacy.



So, anyway, really interesting topic.  I didn't want to ignore it, but I wanted to give everybody a heads up.  We're going to plow into that.  And we've never talked about revocation because the SSL certificates were quickly revoked.  To their credit, Chrome immediately revved their browser, blacklisting the bad certificates.



LEO:  Good.



STEVE:  Microsoft, yes, Microsoft immediately produced a Windows update.



LEO:  That's where the automatic updates of Chrome have a huge advantage.



STEVE:  Really do.



LEO:  Because it happens instantly, automatically, without your involvement.  Who knows who updates Windows, and how often, you know?



STEVE:  Yeah.  And in fact I immediately tweeted to my followers the link to Microsoft's page, where there was just a menu of OS versions.  Each OS version had its own little DLL or EXE that you could download.  And so Microsoft immediately pushed out a bunch of updates also to deal with this.  And I did see something interesting saying Mozilla sort of ignored the whole thing, and after the fact now is unhappy that they weren't more forthcoming about it.



So anyway, we're going to go into this in detail because we've talked about this before.  Remember my shock when I looked at the number of certificate authorities that our browsers now trust.  Famously, we used to joke about the Hong Kong Post Office being among them.  And so this is what happens when you have this kind of problem.  So that's our topic for next week.  We're going to cover it in detail.



And then just a little bit more on the RSA SecurID breach.  Pretty much everyone's upset.  And one quote that I really liked from the SANS Institute.  Alan Paller, who's a friend and very well-connected director of research of SANS, wrote in their most recent newsletter, he said:  "One of the largest defense contractors has stopped the use of RSA tokens by its senior staff."



LEO: Oh, that's how serious that one is.



STEVE:  Yes.  "They replaced the tokens with another manufacturer's solution.  I asked," says Alan, "I asked whether the move had been planned for a long time.  The 

answer was, 'No.  We did it because of the breach.'"  So, I mean, as I said, and as I blogged when this immediately happened, it could only be one thing.  The secrets that they were being entrusted with were the secret key to public serial number mapping database.  And there's only one way the SecurID system could be weakened, and that's if that's what got out.



LEO:  Well, that proves it.



STEVE:  And it sure looks like that's what got out, yeah.  Also in the news, we've talked about of course Stuxnet, that - I mean, we did a whole podcast on it - famously was used to deliver the first rootkit to the SCADA system, which is an acronym standing for Supervisory Control and Data Acquisition, which are the process control technology which in this particular case of Stuxnet was running Iran's nuclear enrichment process.  We talked about how it was some vulnerabilities in that software that allowed Stuxnet to do its work.



Well, what I found interesting was the news that 34 new exploitable vulnerabilities had been found in these SCADA systems, produced by a handful of different manufacturers.  And this is a classic case of there are vulnerabilities everywhere.  And all you have to do is look for them, and you find them.  So these SCADA systems hadn't, until Stuxnet, focused people's attention on them, hadn't been really looked at closely.  Now security researchers are going, oh, you know, Stuxnet found some problems.  What other problem might there be?  And, oh, what do you know, here's 34 in two weeks.



LEO:  I bet that, you know, people don't treat this kind of stuff as as insecure as, say, a PC is.  They just don't think of it that way.



STEVE:  Correct.  Correct.  And there is some awareness, for example, we're seeing that there's sort of an awareness that you can't have, you cannot have a Windows machine on the network.  So these SCADA machines that use Windows as their front ends, like the way the workstation that you use to program the lower level process control hardware is Windows hosted, but everyone knows that's not safe.  So those machines are kept off of the network.  But as we learned with Stuxnet, it cleverly used USB drives because you still have to get files to and from those machines.  So they just used a USB drive rather than a network and, bang, same effect.



So anyway, I got a lot of email from people saying, oh, no, no, what does this mean, 34 more problems.  It's like, well, this is significant because these SCADA systems are what run our nuclear reactors and our dams and factories.  Leo, when you were famously touring Ford's production lines, building cars, all of those robot arms are controlled by these things.



LEO:  Ooh, imagine that getting - ooh.



STEVE:  Ooh, not good.



LEO:  Yeah.



STEVE:  Yeah, I remember when I was at the - this was back in the '70s at the AI lab at Stanford.  They had a robot arm behind Plexiglas shields, and there was like a rope around it with limit switches.  And I remember the first time I saw this, it's like, what's that about?  And they said, well, do you know what happens when there's a bug in our software?  I mean, this thing was hydraulically powered, and apparent- and I heard stories about it just literally pounding its own table into the ground when there was a bug in the software.



LEO:  Oh, boy.



STEVE:  So anyway, so it will end up having been a good thing, in the same sense that Firesheep has been a really good thing for HTTPS and for vendors getting themselves, taking SSL security more significantly.  Stuxnet, which was tightly targeted at the Iranian nuclear enrichment, we now know without a doubt, it had the beneficial effect of turning attention to the security of these SCADA systems, which you can imagine attackers, maybe they're getting a little bored these days.  It's like, well, let's open the floodgates on the Hoover Dam because they're there.



LEO:  Be kind of cool, yeah.



STEVE:  Yeah, well, you know, what a hack that would be.  Oh, anyway, so.



LEO:  You'd get a lot of attention for that.  I mean, never mind, bad idea.



STEVE:  Bad idea.  But anyway, we are - the problem is, these systems have not had the kind of security scrutiny that Windows has because no one's been looking at them.  And when you do, what do you know, 34 exploitable vulnerabilities.  And then in perhaps my favorite little "whoops" of the week, Oracle's MySQL.com site, MySQL site, was breached through a SQL attack.



LEO:  Oh, please.



STEVE:  There was a great little posting that I'll read on the H Security site.  It says:  "MySQL allegedly hacked - via SQL injection.  On a security mailing list over the weekend, an unknown party published details about the structure and content of databases on the website of database vendor MySQL."  Which, you know, is not public.  None of that information is meant to be public.



"The information was apparently accessible via a security hole on the MySQL.com website.  The hacker says the vulnerability is a blind SQL injection problem.  This is a worst-case scenario for a web server because the flaw allows access to the entire database behind a public-facing website.  SQL injections are possible when SQL commands can be embedded in user input so that Web servers pass them on to the backend database.  Blind SQL injection means that the result of the database operation is not displayed; in other words, the attacker has to work blindly.



"In such cases, hackers therefore often ask the database yes/no questions and link one of the answers to a time-consuming operation.  Depending upon how long it takes the resulting page to appear, they can then tell what the response to the query was."  So, I mean, it's classic, beautiful hacking.



"Among other things, the data made public includes password hashes for database access, and some of the plain text passwords behind them have already popped up on the Internet.  Oracle, the database vendor that acquired MySQL when it bought Sun Microsystems in 2010, has yet to comment on the matter."  So anyway, even the database vendors are vulnerable to database injection.



LEO:  Well, if there's a MySQL problem, of course who's going to be running MySQL?  I'd say the MySQL website.  First place I'd go.



STEVE:  Exactly.  Now, I did want to mention in miscellanea that I got a number of, I don't know what to call it, feedback for lack - I won't characterize it anything other than that, to my reference to "toy operating systems" last week when I talked about...



LEO:  How dare you call my operating system, whatever it might be, a toy?



STEVE:  Exactly.  And people said, like, well, and you're using XP.  And it's like, well, yes.  That's true.  Because that's what everybody else is using.  I would love to be using UNIX, but then I'd be all...



LEO:  When Steve retires, he'll be OpenBSD all the way.



STEVE:  Precisely.



LEO:  Or whatever.  Is it NetBSD?  I can never remember which one is the one you...



STEVE:  It's Free is the one I'm...



LEO:  FreeBSD.



STEVE:  FreeBSD.  We're being subjected to emergency, out-of-cycle updates pushed on us constantly.  We update monthly from blindly accepting what Microsoft gives us.  If we visit a bad website, we could be taken over.  Mysterious things happen all the time on our systems, and we just sort of shrug and reboot them.  I mean, my icons all turn into something different, and I go, okay, fine, it's time to reboot because I haven't for a week or two.  And just ask anybody who does PC support.  They never see the same thing twice.  Users bring computers, well, I can't get on the Internet.  Well, I can't print anymore.  Well, Notepad doesn't work anymore.  Well, IE won't open.  I mean, it's one thing or another.



LEO:  Oh, believe me, this is what I hear on the radio show nonstop.



STEVE:  These are toys.  I mean, it's just - this is not, I mean, and the fact that we're used to it doesn't make it right.  This is, I mean, the systems that I have that are running GRC haven't been rebooted in four years.  I mean, it took a long time to get them that stable.  It was really hard to do.  But, I mean, they are rock-solid actual operating systems that are not like this, where it's like, oh, I downloaded some patches, may require reboot.  When has it not required a reboot?  May?  Ugh.  No, I mean, it's just, it is full employment guarantee for anybody involved with these things, anyone doing PC support.  As you mentioned, you on the radio show, Leo, I mean, it's just - it's endless.



LEO:  It actually makes me nuts because I feel like people, quite rightly, normal users have been sold this idea that they can use technology easily, safely, reliably, and change their lives.  And then unfortunately what the reality comes down that they have to become security experts, they have to become geeks, they have to become enthusiasts or rely upon somebody else.



STEVE:  And learn not to click links.  You know, Mom sent me some very well-meaning birthday cards...



LEO:  Oh, I hate that.



STEVE:  You know, it's like...



LEO:  She gave your address to everybody.



STEVE:  I know.  So my email address is out there.  And I didn't open them.  She said, "Honey, didn't you get those?"  I said, "Mom, we've had this talk before.  I will not open those."



LEO:  I know.  Well, and...



STEVE:  "I don't know what they are."  And she said, "Well, what do you mean?"  I said, "Well, Mom, their site could have been compromised.  People's sites are being compromised all the time."



LEO:  That's a good point.  It doesn't have to be a malicious vendor.  They could just be hacked.



STEVE:  Well, like Oracle was.  And who was it, oh, McAfee, it turns out their McAfee site is riddled with - it was just - this was in the news this week - riddled with security problems.



LEO:  Oh, that inspires confidence.  Geez.  But that's the thing that - and by the way, this is why Apple sells the iPad in droves and will sell more and more and more, is because people are really frustrated and puzzled and baffled, and they don't know what to do.  These complex operating systems are just too hackable.



STEVE:  Yeah, actually, Leo, I've got to tell you, I have opened some sketchy things on an iPad because it's a safe little contained environment.



LEO:  Well, we hope.  I mean, I'm sure there's exploits there, too.  But...



STEVE:  Well, I've done other good, other safe things, too.  But, yes.  But, I mean, it's...



LEO:  It's not nearly the complex system that a full operating system is.



STEVE:  No.  I mean, and so in Microsoft, in defense of the toymaker, I will say that these things do everything.  I mean, anything you could ask for.



LEO:  Right.  And that's part of the problem.  A full general purpose computer is inherently complex and requires a complex priesthood to maintain.



STEVE:  And the highest level expert there is has no idea what most of the files are on these systems.  Huge teams all submit their blobs.  And then the only way Microsoft can know that it kind of might work is when they put it out and have it tested extensively.  And when they ship it, it has tens of thousands of known problems at release time because, oh, well, we called Windows it 2000; and, shoot, it's November.



LEO:  Well, and they can't help it.  I mean, there is no perfect OS, so there's never a point where you have a bug-free OS to ship.  You'd never ship.



STEVE:  Well, and decisions have been made, like, oh, we need more performance, so we're going to move the graphics system, which used to be out in user space, down into the kernel.  Well, we know what happened with that, you know, bad idea.



LEO:  So the thing to do is make what the iPad essentially is, which is a system that keeps users from doing anything.  You can't put files on an iPad.  You can't, you know, the dumber the system...



STEVE:  And what do we hear?  We hear complaints from people that the iPad doesn't have a real file system.



LEO:  Well, that's why.



STEVE:  It's like, yeah, I mean, you can't have it all.  So did RSA learn a lesson?  Oh, my god.  Can you imagine they're going to change their architecture?  Absolutely.  Some people wrote saying how could RSA, I mean, we sort of hold them up as, like, this ideal of, well, they invented public key security.  How can they make a mistake like this?  It's like, they're using Windows.  It's a toy.  It's junk.  Yes, we're all using it.  I'm using it.  I don't like it.  But...



LEO:  There it is.



STEVE:  It's where everybody is.



LEO:  Right.



STEVE:  Yeah, I would love to be, oh, my god, do I pine for the days of a textual interface and commands.  Yes.  But I'm not useful to anybody if that's what I'm doing over in the corner somewhere.  So, okay.  That'll teach you, that'll teach you for asking me about toy operating systems.



LEO:  Well, no, this is - look.  I don't know why, but people treat this like team sports, like rah, rah, my team's the best.  Go team, go team.  And it isn't a team sport.  These are just tools.  And it's silly to say this hammer is so much better than any other hammer.  If the head comes flying off and pokes you in the eye, it's a toy.



STEVE:  It hurts, yeah.



LEO:  Period.  Doesn't matter if you love your hammer.  It doesn't love you.  It's just a tool.



STEVE:  Okay.  So I did want to mention something very cool, which is Amazon's announcement of a virtual machine-based Android test-drive system.



LEO:  I'm very interested in this, yeah.



STEVE:  Oh.  It actually, when you go to Amazon's site - Amazon of course released their AppStore.  I notice they're spelling it as one word.  Maybe the...



LEO:  Which Apple does, as well.  That's why there's a lawsuit.



STEVE:  Oh, okay.  I didn't realize Apple was - because I had seen it as two words for some reason.



LEO:  Oh, no, it is two words on the Apple site, you're right.  But I don't think that makes any difference.



STEVE:  Good luck with that, Amazon.  So anyway, this is very cool.  They have that EC2, the Elastic Cloud computing technology.



LEO:  So cool.



STEVE:  And so Amazon is, I mean, they're doing many neat things.  They also just announced a couple days ago a music in the cloud system.  It's limited to the U.S., whereas their cloud drive technology for storing stuff is global.  But the music-based system, at least for now, is only U.S. based.



LEO:  That's just because of licenses, you know.



STEVE:  Yes.



LEO:  You've got to get every record company in every country and, oh.



STEVE:  But, so, for example, users can upload 5GB of music, which actually is a pretty nice little collection.  And then it's available on Android players or PCs and Macs and Linux machines.  So you're able to just, like, stream music from Amazon's cloud.  Well, they've gone one step further.  They actually have created a virtual Android OS.  And, I mean, it must be that they're going to be producing a tablet.  It's just...



LEO:  There's no doubt about that.



STEVE:  There's just no doubt about it any longer.  And arguably they have the chance to be a real mover in the industry.



LEO:  I think we talked about this yesterday on MacBreak Weekly.  And I don't think Google minds.  I think Google says, go for it, we'll help you.  This is good.  They don't want to be the marketplace.  They want to be Google.



STEVE:  Right.  So one of the things that has annoyed me with the iPad is there is no trial software.  I've got all kinds of crap that I've purchased for a buck or two or three, and it's only the low cost...



LEO:  99 cents, yeah, okay, so if it's a piece of crap...



STEVE:  It's like, yeah, okay, fine.



LEO:  I guess I'm out a buck, yeah.



STEVE:  But there's so much junk.  It's like, oh, how do I get rid of this thing?  I mean, it's like, okay, well, there went a dollar, there went two, there went three.  So it is annoying that Apple doesn't do this.  Well, so what Amazon has done...



LEO:  And by the way, Android always has.  You've always been able to - they had a refund process.  They've shortened the length of time.  Used to have a day to try something.  If you didn't like it, and you deleted it, it would automatically give you your money back.  Now they've cut down to 15 hours, which is why I'm glad Amazon's doing what they're doing.  This is really a good idea.



STEVE:  So they literally launch an Android VM instance using their elastic cloud computing technology.  And their servers run the app for you and then download the display dynamically to your web browser.



LEO:  Brilliant.  I love this.



STEVE:  Oh, so you can click...



LEO:  It's probably just EC2; right?



STEVE:  Yeah, they're using EC2.  And so you can click things, you can play with the app on your web browser, not installing any software, I think it's like 30 minutes because I saw in their sample it said "29 minutes remaining" in the lower right-hand corner.



LEO:  That makes sense.  Yeah, that makes sense.



STEVE:  So you get, like, 30 minutes just to poke around and, I mean, actually use it virtually, not even download, not buy it, not commit, not trial.  Just there it is running.  But if you want it, then you click the little famous Amazon orange "yeah, I need this" button, and you can buy the Android app.  So this is very cool stuff they're doing.  I just wanted to bring it to our listeners' attention.



LEO:  Yeah.  This is, well...



STEVE:  What?



LEO:  I sit on MacBreak Weekly, and people get mad at me because I say, look, it's finally - like Andy Ihnatko's finally saying, you know, this Android's not so bad.  And it's like, I've been trying to tell you this for [frustrated sounds].  There are so many great features in Android phones.  And I think people, you know, just because Apple was first with iOS there's a little bit of a prejudice towards iOS.



STEVE:  A blindness, yeah.



LEO:  Now, I admit tablets we've got a way to go, but - "we."  I don't want to say "we."  Again, that's that team mentality, isn't it.  My team has a way to - they've got a way to go.  But I think for phones this is a pretty amazing system.  And I'm very interested to see how Amazon enters this.  They could change everything.



STEVE:  Yeah, yeah.  They're big.



LEO:  They know how to market.  They know how to do this stuff.  They're smart.  EC2 is amazing.  S3 is amazing.  These guys do more than just sell books.



STEVE:  Yes, they really, really have broadened their reach.  Speaking of which, American Express has launched Serve.



LEO:  This I'm also really interested in.



STEVE:  Yes, a very interesting-looking PayPal competitor.  We've often talked about there's no company more in desperate need of competition than PayPal.  And American Express has come along and done that.  So I just wanted to put that on our listeners' radar that there is something from American Express.  I read a comprehensive review, and it sort of seemed like six of one, half a dozen of the other.  Some things PayPal charges for, some things American Express doesn't.  Some things American Express does that PayPal doesn't.  And different things, they work a little bit differently.  But essentially it looks like American Express is very interested in getting into this game in a serious way.  So...



LEO:  It's about time PayPal had some competition.  They're just so, really so bad.  And I use it because there isn't a lot of choice.  If there were something better - Google payments is pretty good.  But Amazon has a system.  But I think American Express is a great financial services company.



STEVE:  And many people have said, hey, Steve, I trust you and all, and so I gave you my credit card information when I had to buy a copy of SpinRite.  But why couldn't I use PayPal?  And it's like, well, I use PayPal as an eBay customer, buying old computers and things, and I've had no problems with them.  But we had a perfect case in point, those little PDP-8 models that you see running behind me while we're doing this podcast.  The guy that produced the kits - remember when we were organizing a big group purchase to prepurchase a bunch of kits.



Well, a whole bunch of people sent him their money.  And after a whole bunch of it accumulated, PayPal shut it down and then demanded all kinds of ridiculous paperwork, saying, well, you can't take money for a product you haven't delivered.  You have to deliver the product.  And he tried to explain to them that everyone knew that this was prepayment to get enough to see if we had enough orders to proceed, and if not all their money would be refunded, blah blah blah.  I mean, it was a huge nightmare.  And the industry has horror stories about vendors that have had massive problems with PayPal.  And so there's just no way I'm going to subject myself to a third party where you can't get actually anybody responsible on the phone.



LEO:  Well, we use, you know, that's how we take donations just because it's the simplest, the easiest, Drupal, the web...



STEVE:  And for that it makes so much sense.



LEO:  And the web, everybody uses it, you can use a credit card.  Drupal supports it with a plug-in that makes it very easy.  I do this all by myself, that's how, you know, in the earliest days I had to figure out how to do this.  But I think it's time, in the next generation, for us to look at alternatives.  And I just knock on wood that we haven't had a frozen account or, you know, we've had no problems so far.



STEVE:  Yes.  And American Express is a name everyone has heard of.



LEO:  Oh, yeah, everybody would trust that.



STEVE:  Yeah.  So I think that's - it really makes a nice step forward.  I hope they just don't screw things up or have any real bad breaches and so forth.



I did get a nice note I wanted to share briefly with our listeners.  Christian Alexandrov, who's in Sofia City, Bulgaria.



LEO:  Yeah, baby.



STEVE:  As you can tell from what I'm about to read, English is not his first language.  But I salute him because his is much better than my Bulgarian.  So he says, "Hello, Steve.  SpinRite saved my St. Valentine Day."  He says, "A friend of mine is a restaurant owner who uses very old Compaq Presario M2000 laptop, Intel Centrino mobile CPU, a 1600, 1GB of RAM, so forth.  The owner called me to go there on emergency call because his laptop just died in his hands while browsing for some recipes for the restaurant's chef for the St. Valentine Day menu.  I went there as fast as possible to see the corpse."  Meaning the laptop, of course.



LEO:  Yes, yes.



STEVE:  "He assumed motherboard died, but quick tour around BIOS settings showed that this assumption was wrong.  I suspected the hard drive on such old computer.  I took the laptop home and started to mess around with files settings.  My phone rang, and he said, 'Look, I have important files on that drive.'  'Do you have backup?' was my first question.  He said [LEO:  No.] no."



LEO:  It's universal.  Nyet.



STEVE:  Nyet.  "Then he says he needs these files at all cost.  So I told him I will do best to help him.  He promised me that if I pull this stunt through, I will have the entire St. Valentine evening free, unlimited amount food and drinks for the whole evening for free, and music of my choice for me and my girlfriend."



LEO:  Good way to make friends.



STEVE:  "So I booted this messed-up laptop from my SpinRite boot" - with three o's, that threw me for a minute - "booot CD, and I chose to run at Level 4.  Once I saw that SpinRite took matters in its own hands, I went to the restaurant to set up a nice surprise, a gift and flowers for my beloved girl, and a nice Valentine cake.  It took SpinRite 17 hours and 30 minutes to process the whole drive.  At the end SpinRite says this drive has long years of faithful service ahead."



LEO:  Really?  Is that a message in SpinRite?



STEVE:  No, but it does, the SMART system does show you how the drive's doing.



LEO:  You have long life, my friend.



STEVE:  He said, "And now the computer booted, and all of the drive's files were saved."



LEO:  I love this.



STEVE:  "I was surprised as much as I could be because of the old model and age and obvious abuse of the laptop.  So I updated everything, ran various tools, I backed up the files, I fixed the partitions and so on, updated Windows system protection such as antivirus, and set up" - oh, so he really spiffed the thing up - "XP SP3, firewall, and I connected the laptop to my router so I could update the OS.  While I am waiting all updates to come and install, I decided to share this story with Security Now! listeners."



LEO:  That's great.



STEVE:  "I brought the laptop to its owner, and he tested it.  He was happy to see all his files intact and the laptop working fine.  Thank you, Steve, for this great piece of software; and thank you Steve and Leo for this upstanding podcast.  Best wishes to both TWiT.tv and GRC.com from a happy SpinRite user."



LEO:  I love that.



STEVE:  So thank you, Christian, for that great, great story.



LEO:  That is just great.  And I'm glad you didn't fix the, I mean, his English is excellent.  But we could hear his voice coming through, which I love, yeah.  I love that.  Christian, thank you for listening to the show, too.  That's wonderful.



STEVE:  Yes.



LEO:  All right.  We've got questions, 10 good ones, plus a couple of freebies we're going to throw in at no cost to you.  Now it's time on Security Now! to answer questions to Steverino.  By the way, people ask me, how do I ask a question?  You go to GRC.com/feedback, fill out a form, Steve will look at it.  You don't answer them individually, I know, but you couldn't.



STEVE:  Yeah, we got - I checked the mailbag, and there were more than 300 from last...



LEO:  You'd spend the rest of your life.



STEVE:  ...from two weeks ago.  So...



LEO:  But you take representative samples.



STEVE:  Yup, I do.  I sort of see, I sense the wind.  In one case, I think #8 here, we've actually got two questions in one because they were two different people asking almost the same question, but with a little bit of a twist.  So I sort of try to combine them and find something representative and try to do what I can.



LEO:  Well, here you go.  This is Question 1 from Patrick Pater, London, England.  He says drive encryption is killing him:  I'm a long-time listener of Security Now!, Steve.  I enjoy it as a good source of information and amusement.  I hope he's not laughing at us.  Being a software developer for many years, I put an effort into keeping my data secure.  The machine is a T9400 running SuSE Linux, using until recently his 200GB 7200 rpm full-disk encryption hard drive.



A couple of weeks ago I switched to an SSD drive.  Wanting to keep my data still secure, I performed full partition encryption on the drive using openSUSE's encrypted root file system how-to.  However, the amount of CPU power needed to decrypt and encrypt data on the fly was through the roof.  Don't get me wrong, thanks to you and Leo know a thing or two about how encryption works and of course that it comes with a price.  But can you advise a reasonably usable crypto that won't cost an arm and a leg?  I got this SSD for speed, and I'm not getting it.



The drive stats for non-cached read timings, full disk encryption, the old style, around 50 MB/s.  That was on the standard drive.  On an SSD unencrypted, 220MB/s.  But now with encryption 70MB/s, so that's a lot slower.  Thanks for a great show and SpinRite.  B.S. - P.S., not B.S., P.S.:  Thanks to you, my private project SpaceBench.com now accepts Bitcoin.  That's great.  So that's interesting.  And, well, what do you think?



STEVE:  Well, okay.  When I was playing with TrueCrypt I was unable to measure a decrease in speed.  And I did, I mean, I remember talking about it extensively on the podcast we did about TrueCrypt, and I was very impressed.  It seemed to me that on the machine that I was using, which wasn't particularly muscular, that the overhead of encrypting and decrypting was fitting underneath the speed of the drive so that, while the drive was reading data, the AES-based encryption was as fast as the drive was, so that we weren't seeing a substantial overhead from that process.



Now, he went from unencrypted 220MB/s to an encrypted partition at 70, so it's about a three-to-one difference, like it's running a third as fast.  His SSD is still going faster than his old mechanical drive was; but if he weren't encrypting, the SSD would be going more than four times faster than the mechanical drive that was running at 50MB/s as opposed to 220.  So my feeling is that it may just be that the encryption technology that he's using is, for whatever reason, not as tightly optimized as what TrueCrypt has done.



I know, because I looked at TrueCrypt very closely, that they've got a ton of code that is in assembler.  All of the speed-critical stuff, all the crypto has been hand-coded and hand-tuned in assembler so that specifically to reduce the overhead as far as possible.  If, for example, the encrypted root file system technology he's using had stayed in C, it would be secure, but easily a fourth the speed of it being written by hand in assembler.  So it might just be that it has not been optimized.  The thing that I wanted to...



LEO:  I think it's TrueCrypt.  I'm looking at the how-to.



STEVE:  Really.



LEO:  Well, this is an interesting question.  I guess you can choose from different systems.  Maybe he's not using TrueCrypt.  Yeah.  TrueCrypt, though, is one of the choices that they talk about in this article that he's mentioning.



STEVE:  Oh, okay.  Because he says SBD.  Don't know what that says, SBD encrypted root file system.



LEO:  Yeah, I don't know what that is.



STEVE:  Well, and does TrueCrypt do whole-drive encryption?  Maybe that's not available over on that platform.



LEO:  I think it does, yeah.



STEVE:  Okay.  In that case, one thing you could do, Patrick, if it's feasible for you, and you're not using TrueCrypt, is try switching to TrueCrypt, where at least on a PC platform it's really fast.  And more generally what I wanted to suggest is, I don't think we're there quite yet, but...



LEO:  Oh, yeah, wait a minute, yes, he's using cryptsetup instead of TrueCrypt.  The how-to describes cryptsetup.  So he's using a simpler, less sophisticated system.



STEVE:  Okay.



LEO:  There's three choices:  cryptsetup, loop-AES, and TrueCrypt.  So he should just change to TrueCrypt.



STEVE:  Great, yes, perfect.  And I did want to say that we're not quite there yet, but I don't think we're far away from all hard drives having on-the-fly AES encryption in their hardware.  So it would not be something that is enabled by default.  It's not something you would be able to add after the fact.  You'd have to set it up and establish it before you loaded an OS or anything.  But the idea is, and we've talked about this at various points along the way, the idea is that everything written would pass through the encryption; everything read would pass through it to be decrypted; and, at boot time, the drive would be given the key which it would have internally that allows it to do the encryption/decryption.



The beauty of that, whether it's on a physical hard drive or on an SSD, is it solves everyone's concern about these drives being difficult to erase, that sectors have been spared out that are no longer accessible that might have a piece of important data on it, or the SSD's drive leveling might move some data somewhere else that it hasn't erased, that forensic analysis could get.  But if everything is encrypted from the beginning, then when you remove that key from the drive, the entire thing is filled with noise that is no good to anyone.



So, again, we see this in some laptops and in some drives.  It's not universally available.  It's something that really has to happen.  And the other problem is, since it's not something you can add incrementally, the drive, if you're getting it from a manufacturer, it has to have been set up that way at the time that it was manufactured.  And then you've got the problem of the manufacturer's technically having the password for the drive.  So, I mean, there are some logistical problems with implementing it.  But for people who are really concerned, once the hardware is there, we'll at least have the ability not to leave data behind when we decommission hard drives or solid state drives.



LEO:  Kill that slack space.



STEVE:  Yup.



LEO:  Moving right along to - actually now I've opened - I blew it.  I opened up that Linux article, and now I don't see the questions anymore.  Let me go back, back out, back to our wiki.  Here we go, Question 2, an anonymous listener wonders, old Internet Explorers, will IPv6 kill them?  Listening to 292, you're talking about Microsoft's attempts to kill IE6.  I saw a job description today that included website testing with - ready, wait for it - IE5.  But are these old versions of Internet Explorer IPv6-ready?  Were they designed to be protocol agnostic enough?  What about old Netscape browsers or old game consoles like the Xbox and PS2?  What happens with them and IPv6?



STEVE:  Really good question because in many systems, for example, like an Xbox, you'll see configuration data that has the dotted quad IP address.  It's 192.168.0.1, or it's DHCP that knows nothing about IPv6.  It knows how to get a dotted quad IPv4 IP.  So the question is, when IPv6 is being delivered from our curbs, curbside, what happens to all of this equipment that we've got that predates it?  And that's just one more example of why this is a challenge and why people are going to be going kicking and screaming to IPv6.  I believe what we're going to see is this will be something that befalls our NAT routers.



LEO:  Yeah.  There's something called "tunneling."



STEVE:  Exactly.  There are all, I mean, it's a confused mess.  And when we finally get to our How the 'Net Works, we'll certainly be spending a lot of time about the whole IPv6 to IPv4 transition.  And I'm sure we'll be talking about it a lot this summer and in the fall as this becomes more and more important.



But what's really funny is that this is exactly what all the IPv6 proponents didn't want.  The original concept of the Internet was every device has its own IP address.  And we were supposed to have plenty because, after all, we had four billion, 4.3 billion in a 32-bit address space.  But chunks of that space got allocated for other things.  And turns out we need more than that many, so we have to go to a larger bit size for the address.  So we're going from 32 to 128 bits, giving us really a lot.  I mean, 340 with an amazing number of zeroes after it is 2^128 power different IP addresses.



So the problem is that we still are carrying the legacy of IPv4 which I would argue in our lifetimes will never go away.  There will be all kinds of systems that stay on IPv4.  So what does our NAT then do?  Well, what it's been doing for us up until now is converting a single public IP address into a personal network of IP addresses.  What it will next-generation do is convert IPv6 down to IPv4.  And there's no reason it can't.  It's simple to have hardware translation that works in the same nature as port translation and IP address translation works, that right now NAT routers are not translating the format of the packets, they're translating the content.  But they can certainly translate the format so that you would have a NAT router with an IPv6 public IP that would behind it still be running, and I'll bet they do, an IPv4 192.168, and nothing within our home networks would know the difference.



LEO:  A lot of the, if you get, you know, Hurricane Electric right now will give you an IPv6 setup.  In fact, Randal Schwartz is boasting he's got like a Class C IPv6 network, or Class B, because it's - why not?  There's so many addresses, go ahead.



STEVE:  I don't think they allocate on smaller than a certain, I mean, a large chunk.  You get, like, 65,000 IPs.  Like, okay, that ought to hold me for a while.



LEO:  So if you go to TunnelBroker.net, you can go - this is free.  Hurricane Electric is one of the big, they're like Level 3, they're one of the big backbone companies, big Internet service providers for Internet service providers.  And what you can do is, for free, get your own IPv6 by tunneling over existing IPv4.  And it's, you know, actually Randal did it because he just wants to kind of test it and play with it and learn about it.  And so it's kind of interesting.  So TunnelBroker.net, and you get your free IPv6 tunnel.  And everything will continue to work.  Your hardware doesn't stop working.  It's just it's seeing IPv4 over a tunnel.  And actually the IPv6 is going over an IPv4 tunnel.  So it's crazy.



STEVE:  And I've asked my Level 3 guys about IPv6, and they're ready to give me a block any time I need it.  I've asked my T1 providers, Cogent, and the hardware that terminates my T1s is not currently provisioned for handling IPv6.  But the neat thing is one of the engineers is one of my old friends from the Verio days, and he is going to be lobbying for the importance of switching over because I'd like to have IPv6 natively flowing in here so I can do a bunch of experiments and prototype technology that I'll need ultimately to move over to GRC.



LEO:  Yup.  I'm sure that's what Randal's doing.  It's also got great bragging rights.  "Oh, yeah, I'm running IPv6.  All through the house."  Good question.  I think that in fact there are a lot of people, I've talked to a number of people, including Dane Jasper, who is our local Internet service provider here, Sonic.net.  They provide the big pipe that we use to stream and everything.  And he says, you know, he's not convinced it'll happen at all, that they'll just - there'll be these hybrid solutions.  There'll be ISP tunneling and so forth. 



STEVE:  Yes.



LEO:  ISP NAT, they call it, so that you get IPv4, but they do IPv6, things like that.



STEVE:  Well, for example, there are, when I was talking - I did a conference call with the Level 3 guys.  And I had a technical sales guy on the phone who said, oh, yeah, large corporations are switching to IPv6.  They're using it internally.



LEO:  Internally; right.



STEVE:  Exactly.  But externally they're still running over the IPv4 backbone, and they're contacting IPv4 websites.  And like I'm sure GRC will always be on 4.79.142.203, which is my www.GRC.com's IP address.  They're not going to take those away from me.  I want additional ones because it would be very cool to be able to do native IPv6 and check people's ports.



LEO:  Oh, yeah, for ShieldsUP! and things like that you need to do that, yeah.



STEVE:  Exactly.



LEO:  Michael Noone in Circleville, Ohio has an update on Facebook and HTTPS.  Remember, Facebook went HTTPS.



STEVE:  Kinda.



LEO:  But then it turns itself off at the drop of a hat.  A long-time listener, first-time commenter.  I'm not sure if you covered this.  I was on Facebook today, received the following message when I attempted to access an app:  "Switch to regular connection (http)?  Sorry!  We can't display this content while you're viewing Facebook over a secure connection (https).  Would you like to temporarily switch to a regular connection (http) to use this app?  You will have a secure connection" - oh, this is a change.



STEVE:  Uh-huh.



LEO:  "You will have a secure connection upon your next login."  Looks like they are trying to fix - so we mentioned a few weeks ago that once you turned it off, it just stayed off.  Like you turn it off for an app so you can use an app because a lot, most apps don't do it.  And so you're using Farmville or whatever, it turns off, and then just stays off.  So this apparently will turn it back on.



STEVE:  Yes.



LEO:  Looks like they're trying to fix the issue about having to shut off the secure connection completely.  I did need to log out of Facebook, which people don't typically do.  But when I logged back in, it was back to HTTPS.  Thanks for a great podcast.



STEVE:  So that's great news.  I wanted to update our listeners that that was fixed because a number of people wrote to me and said, eh, not so much, Steve, and then verified that http setting was disabled if you acknowledged that little dialogue box.  It unset it, essentially, in your configuration and left it that way.  Now, as you say, it's a little bit of a problem that you have to log off in order to have it back.  On the other hand, what they're protecting people against is logging on in an insecure WiFi hotspot.



So the good news is that this really does look like, if you were to log on freshly, it will preserve your security.  Of course, you still have the danger of applications forcing your whole session into HTTP.  That they need to fix because you ought to be able to use Farmville over HTTP but maintain the security of HTTPS everywhere else.



LEO:  So you're saying it's a weakness in their implementation.



STEVE:  Yeah.  And it may be, I mean, Facebook has so much money, they're hiring people right and left, and I imagine they can get this fixed.  The good news is it really does, this really seems to be on their radar.  And I'm glad they're moving forward.  So that's just good news.



LEO:  Yeah.  Question 4, Rommel in San Diego wonders about the LastPass virtual keyboard.  Hi, Steve.  I'm wondering how secure it is to use the LastPass virtual keyboard when I login to LastPass?  Let's say I have to use a computer that I'm not familiar with.  I don't have my onetime passwords.  My phone is dead.  Is using the virtual keyboard safe?  LastPass says keyloggers can't detect what is entered using that keyboard.  That's the whole reason they have it.  What do you think?



STEVE:  Well, okay.  So basically he's painted himself into a corner where he's using a computer that he doesn't control, and he doesn't have one-time passwords which LastPass provides as sort of an escape hatch for this purpose, and his phone is dead so he can't use telephone authentication.  So he's backed up against the wall with their virtual keyboard.  Well, so one thing I have to say is, well, what choice do you have?  It's the only other way at this point to log in.



LEO:  Well, you could not log in, I guess.



STEVE:  Yeah.  And it is the case that they did not implement this virtual onscreen keyboard through the keyboard interface specifically so that keystroke loggers could not detect it.  So all that's happening is that there's JavaScript there which is capturing mousedown events in coordinates and translating that into keystrokes.  So that's about as secure as you can be given the situation you're in.  The problem, of course, is that LastPass is still logging you into websites.  And if the browser remembered your username and password that's being logged in, then those are sticky.  So you definitely want to make sure you use a browser that offers private browsing so that you can create a session that will not leave breadcrumbs behind.



And then, yes, I think you can use LastPass's virtual keyboard with as much confidence as possible.  I mean, again, if something malicious were in the computer designed specifically to intercept the virtual keyboard, it could because all software is software.  But the chances of that are vanishingly remote.  So I would say, as long as you, you know, you definitely want to use, always use a browser that offers a sandboxed private browsing option when you're logging into sites on machines you don't control so that it's not going to leave traces behind.  And then LastPass is the way to log in.



LEO:  Question 5, Joseph in Los Angeles has a VoIP hacking follow-up question:  Steve, I'm addicted to your podcast.  That's good.  It's like free continuing education, but this is one class I really look forward to attending.  Anyway, on to my question:  I listened with great interest to your most recent Q&A #113, our last one.  One of the questions had to do with being able to decrypt about half of a VoIP call.  If you didn't hear this hack, it was a very clever hack using VBR compression.



My business has a PBX switch that allows us to connect a traditional office phone, multiple phone lines and the ability to intercom other employees and so forth, over the Internet.  Instead of a traditional phone cable, we plug in an Ethernet cable.  Actually that's the kind of system we're going to put into the new studios, using Asterisk, hosted Asterisk.  We've had this since 2004 when I literally begged my phone vendor to sell me the equipment so I could have employees work at home and answer our phones.  We were the first customer in Southern California to install this equipment.



The system has been incredibly reliable for seven years.  I couldn't be happier - until I listened to the podcast today.  At the time, the vendor thought I was crazy for worrying about people hacking our phone switch.  I was really worried about a bad guy somehow connecting to our PBX over the Internet to make phone calls.  I was insistent that the PBX only be accessible over a local 192.168 IP.  Here's my question.  Are the VoIP calls through a VPN tunnel able to be monitored using this technique?  I've always assumed that our calls are private when on the VPN, but fully hackable over copper.  Do I have anything to worry about or change?  I'm very curious whether you and Leo gave me an A or an F for the way I set up access to the PBX.  P.S.:  I'd like to vote to make the podcasts even longer.  You never waste our time trying to educate us.  Interesting question.



STEVE:  Okay.  Really interesting question.  First of all, I salute, I definitely give him an A.



LEO:  Yes.



STEVE:  For Joseph in Los Angeles for going to the extent that you have.  I've also, when I did build this building that we were talking about earlier, had a phone system installed, and I remember, and I'm sure you do, too, Leo, there were a bunch of scams going on with people breaking into PBX systems and getting outside lines that then they would make transatlantic phone calls from.  I mean, like, and this is in the day, back in the day when, you know, long distance was really expensive, so that you thought twice before you even dialed out of your own area code.  And many corporate systems ended up clamping down by, like, disabling the ability to use an area code in order to prevent this kind of problem.



So just to refresh, the hack which he's talking about which has concerned him is that what was discovered was that variable bitrate encoding changes the size of the samples of digitized voice as a function of what's being digitized because some things can be compressed more than others.  And an analysis showed that just by looking at the size of the data packets, about half of a variable bitrate conversation could be determined blindly, just, I mean, which is just really cool, speaker independent, I mean, just amazing cool hack.



Now, the good news is he's over a VPN.  It's not clear, though, whether the packets will be varying in size after they're VPN encapsulated or not.  And all other network traffic is sharing that same VPN connection, which would tend to mask the VoIP packets within the VPN tunnel.  So, and if this system is, what, seven years old, it might not be using a variable bitrate codec.  The older Asterisk systems were using fixed bitrate codecs, not variable.  So if it's a fixed bitrate codec there's nothing to worry about because that's leaking no information in this really clever hack.  Or, if there's other network traffic happening at the same time, web browsing or anything else, it sounds like he's got everything tunneled through a VPN, that would mix in with the VoIP traffic, and there's no way then that anyone on the outside - because the VoIP is going to be encrypted.  So it's just going to look like completely opaque blobs of data that no one would have any way of dissecting further.  So in general I think he's probably safe, partly because of the age of the system he's using that's probably using a fixed bitrate voice and not variable.



LEO:  Well, also because it's a VPN, I mean, anything outside of his building is safe because it's inside an encrypted tunnel.



STEVE:  Except that, if the VPN, for example, if he's using UDP, the VPN might be just encapsulating the UDP packet.



LEO:  Oh.  I should mention that, because I always assume VPN's encrypted, it doesn't have to be an encrypted tunnel; right?



STEVE:  Doesn't have to be, but I think it probably is encrypted.  But remember, that was the cool thing.  That's why the hack that we talked about two weeks ago you could read, you could determine 50 percent of the conversation from encrypted VoIP.



LEO:  Oh, right.  But it sends tunnel.  So that wouldn't affect the tunnel, or would it?



STEVE:  The idea would be that the packet length would be varying.



LEO:  Oh, it would.  So it would affect the tunnel.



STEVE:  Yeah, yeah. 



LEO:  The VPN doesn't pad?



STEVE:  The VPN pads, but it still varies.



LEO:  Interesting.



STEVE:  So the VPN would have a fixed amount of padding, but the individual packets would still change in size depending upon their payload, which is encapsulated inside the VPN packet.



LEO:  Wow.



STEVE:  Yeah.  I mean, so it's possible that with a variable bitrate codec on a VoIP which is encrypted and then encapsulated in a VPN tunnel, that you could still figure out what was going on inside.



LEO:  We should probably say that, although this method's published, it is nontrivial.



STEVE:  Oh, you're right.  Good point.



LEO:  It's not something some hacker has a...



STEVE:  You can't download it anywhere right now.



LEO:  Because you need, I think you'd need a massive database of sound samples and things to compare it to.  I'm sure it's just not a simple thing to do.



STEVE:  Yes.  I mean, this was a very cool research project at a university that showed a proof of concept.  Now, we know that proof of concepts do tend to mature over time.  So...



LEO:  Yeah, somebody could do a rainbow table sort of a thing with voice samples, I guess.  But it's not - I don't think it's widespread.



STEVE:  It's not something you have to worry about.



LEO:  And what are you really saying over the phone call anyway, c'mon.  Question 6, JT in Wintergreen, Virginia - mmm, that's fresh - wonders about MSSE versus MRT:  Long-time Security Now! listener, Steve, licensed SpinRite user.  I switched my home office and home computers to Microsoft Security Essentials - that's the MSSE - which I keep current.  And I run an automatic full scan with Security Essentials every night.  It only flags malware once every couple of months or so.



STEVE:  Okay.



LEO:  He says that so offhandedly.  No big deal.  Also, immediately after Patch Tuesday I run the latest MRT in full mode, thorough, that's what you want to say, thorough scan, which it doesn't do automatically.  Once I do that, do I have any further use for that month's MRT?  Isn't the once or twice daily update to MSSE definitions making Security Essentials more current, therefore more complete?  That's a good question.  Microsoft does not explain this at all.



STEVE:  They really don't.  And in poking around, I see a huge amount of confusion about this, so I wanted to try to provide a little bit of clarification.  Remember that we heard last week someone who told us that he ran the MRT, which is the Malicious Software Removal Tool, in full mode, and it found an installed rootkit which nothing else had found.  That is why Microsoft created the MRT.  And maybe it's the consequence of the history of the way Microsoft got into this that explains why it's unclear.  So I wanted to share what Microsoft says about their MRT, the Malicious Software Removal Tool.



They said:  The tool removes malicious software from an already infected computer.  Antivirus products block malicious software from running on a computer.  It is significantly more desirable to block malicious software from running on a computer than to remove it after infection.  The MRT removes only specific prevalent malicious software.  Specific prevalent malicious software is a small subset of all the malicious software that exists today.  And, finally, the MRT focuses on the detection and removal of active malicious software.  Active malicious software is malicious software that is currently running on the computer.  The tool cannot remove malicious software that is not running.  However, an antivirus product can perform this task."



So the two, MRT and MSSE, the Microsoft Security Essentials, are very different.  And MRT came about because Microsoft was having problems updating Windows with their monthly Second Tuesday of the Month patch on systems that had rootkits installed.  Remember that was causing problems, causing all kinds of crashes and things because Microsoft would change some core components whose internal offset addresses changed.  And when the system rebooted, the rootkit would try to reinstall itself, hooking those physical locations which in the new update had moved, and it would destabilize the system, I mean, it would crash.  And so people were blaming the update for wrecking their system, and that's what was so screwy because we reported this, like a few people are having problems.  Well, yeah.  Those few people had rootkits that they were unaware of.



So Microsoft stepped up and said, okay, the only solution for this is for us to do a pre-update check for anything that has its hooks currently into the system.  So that's the difference.  The Malicious Software Removal Tool, which only looks at things in RAM actively hooked in, versus Security Essentials, which is much more like a traditional AV.  Bottom line is, directly answering JT's question, is there a benefit to running MRT more than doing a full scan immediately after it has been updated, I would say, well, given that MSSE is finding malware every couple of months on his system, I would say yeah.



LEO:  That's not good.



STEVE:  It is absolutely the case that MRT can find things that Security Essentials may not, although MRT predates Security Essentials.  It came first, as we remember, Security Essentials came later.  So my sense is there's probably some overlap.  But believing in maybe using both a belt and suspenders, run MRT.  It won't schedule itself automatically the way Security Essentials will.  But you could set up, using Task Scheduler, a task probably to run it.  I would bet there's some command line switches.  This is something I haven't looked at because normally you have to click a few buttons to get it to do a full scan.  Knowing Microsoft, you can probably use Task Scheduler to run a full scan.  And it takes a while.  So it's the kind of thing you'd want to automate and do at night.  So I would say, yeah, probably worth doing.  Not fanatically; but, you know, why not.  You're running MSSE every night, so MRT and MSSE are not doing the same thing.  Probably worthwhile to use both.



LEO:  You can, I presume, use Microsoft Scheduler to run this automatically, I would guess.



STEVE:  Right.



LEO:  I don't know what the command line would be to do a thorough scan, because otherwise you have to click a button.



STEVE:  Oh, I just did it.  I typed in - I opened up a DOS box and just typed MRT /?, and it popped up a little usage with /q for quiet, /n for detect only, /f for forced full scan, and /f:y for same as above but automatically clear infected files.  So you can definitely run it from the command line, meaning that you can give it a command line through Task Scheduler and have it automatically run at night, doing a full scan.



LEO:  Perfect.  Moving right along to Question 7, Jonathon Bly in Sioux Falls, South Dakota.  He's peeved with his bank:  Steve, I've been listening to Security Now! since around 2006 - that's pretty good because I think we started in 2006, maybe a little earlier, 2005 - but I've recently been working through each and every episode to bring myself up to date.  I also recently purchased your excellent SpinRite software.  Haven't needed it yet, but I feel very comfortable knowing that, not only can it save my bacon - mmm, bacon, oh, sorry - when one of my disks start to fail, but also provides preventative maintenance.



With the standard introductory material out of the way - just boilerplate - I would now like to comment on my bank's ability, or inability, to allow the use of secure passwords for online access.  The following is a letter I sent off to the bank through its contact link:



Dear Sirs, I have been trying to change my password to something more secure than the easily guessable combination of a dictionary word followed by some numbers to a secure password from GRC.com.  I was completely dismayed at your ridiculous restriction of a password a maximum of 16 characters.  Quite honestly, that should probably be the minimum.  Fine.  I'll obey the restriction.  I dutifully cut down the secure password from 64 characters to 16.  I copy-pasted the new password into the appropriate fields, I hit the submit button, I got an error.  Maybe you don't allow copy-pasting of passwords, so I tried typing in the password.  No go.



I tried typing in a new password that I made up off the top of my head, being a slight modification of my current password.  That just went fine.  I tried switching to Internet Explorer (ugh) and Firefox.  Neither allowed me to use the password I'd like to use.  Fix this.  Good day, sir.  As you can tell...



STEVE:  I'm sure glad the bank was glad to get that note.  We'll get right on that.



LEO:  Good day to you, sir.  As you can tell, I was little miffed with the bank.  I feel like duct-taping the software engineers to a chair in front of a computer and playing every episode of Security Now! for them.  Maybe you'd prop their eyeballs open, as well.  Now, if I did so, I would think they'd come up with a system a little more security friendly.  I understand that having a small password would be preferable to the people who have no sense of security and just want to log in quickly.  I, however, live on a shoestring budget, and I need my finances to be completely secure.  Anyway, love the netcast and everything you and Leo do.  Just wanted to know that your guys' hard work is very appreciated.  All the best, Jonathon Bly, Sioux Falls, South Dakota.



STEVE:  So any time you see a limit on a password length, that's a bad sign because what it implies is that they have allocated 16 characters to store your password in their database.  The one good thing we heard about the hack of the Oracle MySQL database was that hashes were obtained as opposed to the password plaintext.  Remember that a hash converts any amount of data into a fixed-size token.  And so, if a site were hashing passwords, as everyone should in this day and age, then there would be no length on the password because they could take as long a password as you gave it, and they would hash it to the same token, which that's what they would store.  And when they asked you for your password again, they would perform the same function and see if the two tokens matched, the one stored and the one they just made from what you gave them.  So it's distressing that a bank is not doing so.



What this means is that, if at some point someone compromises their database, they'll get everyone's username and password and be able to log in as them.  The beauty of using a hash is that, if a database is compromised, they get their usernames and the hash.  But the whole point of a hash is you can't unhash it.  You can't unscramble the egg.  The hash is an information lossy process that loses information as it moves through the hash, but it creates something unique.  And from that you cannot guess what the input was.



The only thing you can do is to use, as you mentioned earlier in the podcast, Leo, a rainbow table, is a table of known input and known hashes.  So if it weren't a salted hash, which is the other thing that good security requires that you do, where you add something different to it, like you salt the hash by adding something to what the user provides so that the result is still different from what a rainbow table would provide, then you've got security.  So all I can say to Jonathon is that I hope that over time we stop seeing this kind of limitation from websites where security really does matter.



Now, mitigating all of that, 16 characters, if you really choose a random chunk - I'm confused as to why he took 16 characters from what he got from the Perfect Passwords page at GRC and the bank wouldn't accept it, unless they also don't allow some special symbols.



LEO:  I bet that's what it is.  I'm sure that's what it is.



STEVE:  It might just be, like, A through Z, 0 through 9, and dash and underscore or something, which is further annoying because then it's really preventing you from creating a unique password.  And then I'm wondering if it's case sensitive or not because the only thing you could really do then is play with the case, given that the password is case sensitive, come up with a non-alternating but odd changing case if you're not able to use special symbols.  Do anything you can to make it something that is different from what someone would try brute-forcing.  So anyway, it doesn't bode well for the security of that bank.



LEO:  It's a little weird.



STEVE:  Yeah.



LEO:  You know, this is good.  If everybody wrote letters like this, maybe people would start to - look, these companies are going to respond to what their customers want.  And all they're hearing is, it's too hard.  It's too much typing.



STEVE:  Right.  I lost my password.  What was my password?



LEO:  Yeah.  So if they start hearing from people who say, you know, I want you to be more secure, maybe they will.  So Question 8, as you said, two listeners with similar questions.  Jason Stratman in St. Charles, Missouri, he wants to know about Smartphones and Firesheep:  Just started listening to Security Now! when Firesheep first sprang up, and I heard you talk about it again last week.  I started wondering, if I'm using Facebook or let's say Twitter, the apps on my Smartphone on an open access point at a local bar, can Firesheep still acquire my login information?  Do Smartphone apps use cookies like web browsers?  It's funny because I had this same question that day, the Firesheep day, and I immediately tested it.



Jim Guistwite in New Jersey has some thoughts and concerns raised by Firesheep and mobile apps:  I tried Firesheep a few months ago when you first mentioned it.  I was startled, as many other listeners were.  Many websites are switching to secure communications for browser-based HTML traffic, but are their APIs used by mobile applications also using HTTPS?  Couldn't there be a similar session cookie issue as with the browser clients on the desktop?  Makes me wonder how safe it is to use mobile applications on an open WiFi connection.  Perhaps other listeners are similarly concerned - yes - and you should address this on an upcoming show.  Thanks for the podcast.



P.S.:  My 11-year-old son calls Steve "the bot guy."  His iPod died on a car trip, maybe about a year ago, and he was forced to listen to what I was listening to.  His first introduction to Security Now! was during a discussion of botnets.  So, Steve, you're "the bot guy."



STEVE:  Okay.  So here's what we know.  We know that cell phone radio is encrypted.  It may not be the best encryption in the world, but it is encrypted.  So if your Smartphone is using its cellular connection, then you're relatively safe.  You're at least safe, but in the local air between you and the cell tower or the terminus where it then goes over the Internet, at which point the cellular encryption is removed, and then the actual data in the connection would be moving over the Internet.  If you're using a - and this must be what both of these guys, Jason and Jim, are talking about.  You've got a Smartphone which also has WiFi capability and preferentially uses WiFi when it's available, much like, for an example, an iPhone or an iPad does.  If it has WiFi, it would prefer to use that than cellular.



Then this is a great question.  The question is, are these apps encrypting themselves for, not browser-based apps, but Smartphone apps that are bringing their own little world with them.  And I don't know.  The way to find out, if you are curious, and our listeners could, those who are curious and savvy, would be to use the app with your Smartphone and your WiFi at home...



LEO:  I did.



STEVE:  ...while looking at the traffic.



LEO:  And it was fine.



STEVE:  Neat.  So all you see is just gibberish.



LEO:  Yeah.  They don't - they're not using the same techniques browsers use.  They're using the...



STEVE:  Makes sense.



LEO:  And if you think about it, they're using the API.  They're not using browser cookies or that kind of thing, tokens.



STEVE:  Right.  Or they might just be setting up, they might use an SSL connection, like within the app, just to have security from end to end, or some kind of encryption.  So, or as you say, Leo, it might just be a completely dense binary protocol, which is their own API.



LEO:  Yeah.  Both Facebook and Twitter have an API for this kind of thing, and that's what they use.



STEVE:  Right.



LEO:  So I think there's nothing to fear.  I certainly played with it and wasn't able to get any Firesheep love.  That was the first thing I did when I installed Firesheep.  I said, let me see.  What else?



Matt Vanderville, Woodstock, Illinois, wonders whether, after uninstalling Internet Explorer 9, his Windows 7 is less secure.  Hmm.  Love the show.  Get to the point, I've previously chosen to remove IE8 through the Add/Remove Windows Component section.  After investigating and trying out IE9, I chose to uninstall it, as well.  Is my OS now less secure?  In other words, will I be left with the old IE8 components that integrate with the OS, or am I left with the newer IE9 components?  Oh, I get his question.  That's a good question.



STEVE:  It is a great question.  And I have no idea.



LEO:  Microsoft doesn't say.



STEVE:  It was a great question.  So, Matt, here's the problem.  You really can't uninstall Internet Explorer.  You can remove the icons for launching it, and you can remove the EXE.  But it is the case that modules of IE are part of Windows.  Now, when you install IE9, those are being updated.  And that's probably a good thing.  So I would imagine, when you uninstall it, it probably puts back the things that it removed.  And so you're probably back to IE8.



LEO:  But he uninstalled IE8.  So what does he really have?



STEVE:  Exactly.  And that's my point is you can't really uninstall IE8.  You can remove the UI of Internet Explorer, but you're still, for example, going to have the browser, the browser helper, the browser DLL, the HTML rendering.  For example, Outlook uses IE's browser renderer to display your email and for its preview window.  And we know that when you - just previewing email can cause your machine, your toy Windows operating system, to be taken over.



So IE is still there.  If you're using Windows, you've got Internet Explorer.  It is deeply integrated into your Windows system.  I don't know whether having IE9 and then removing it put back what was there before.  I would guess it does, in which case you probably have IE8.  That is, whatever IE came with Windows 7, which would be Internet Explorer 8.  So, and also I'm surprised that you just uninstalled IE8.  I mean, I don't use Internet Explorer any longer, except, for example, using Windows Update.  I like to go to use Windows Update or Microsoft Update to sort of more carefully pick and choose what's going on with my updating of my software.  And you can't do that with Firefox.  It only runs in Internet Explorer.  And also there are times when I'm downloading things from Microsoft that it wants to run me through all kinds of weird validation hoops if I use Firefox.  I go, oh, that's right, I've got to do this from Internet Explorer.



So for me it's handy to have it around.  I just don't use it every day.  And I've never been an Outlook user, so I'm not risking being bitten there.  So anyway, my sense is don't use Internet Explorer daily.  Use anything else - Firefox, Chrome, Opera.  But also know that Internet Explorer is still lurking in Windows.  You just really can't get away from it.  It's part of the OS.



LEO:  So the only real question is, what does Microsoft do when you uninstall components?  I mean, at some point IE9 will become the default, and it will be using IE9 components whether you install it or uninstall it.



STEVE:  Yeah.  And so, for example, I'd rather have IE9 installed and not use it than have removed IE9 and maybe be falling back to IE8 because then you're getting the benefit of the security updates in the components you can't get rid of anyway.



LEO:  So that's the real answer, is just install IE9 and keep it.  Just don't use it.  You don't have to use it.



STEVE:  Right.



LEO:  And you're not really getting rid of it.  So it's kind of a false sense of security anyway.



STEVE:  Exactly.



LEO:  Question 10 from Jerod Lycett in Duncannon, Pennsylvania.  Actually, I should be more specific:  Duncannon, Pennsylvania, U.S., North America, Earth, Sol, Milky Way.  He wanted to really narrow it down.



STEVE:  Yeah, he didn't name a universe.  I think someone else said universe number, you know, 39274, yeah.



LEO:  We don't know what universe we're in.  That's the problem.  We do know we're in the Milky Way, though.  He has the Chrome Security  Tip of the Week.  First of all, I want to give a small tip of not saying bad things about Java, as one of your sponsors, Citrix, uses Java.  Hey, wait a minute.  We don't say bad - first of all, if there's a security issue, we say it.  What Steve says is, if you don't have a need for Java, don't install it because there's no reason to install something that you don't use, given that it might have potential security issues.



STEVE:  Precisely.



LEO:  That's just good policy.  You don't install a bunch of crap you don't use.  Nobody should do that.  However, you're right, Citrix does use Java.  And I think, as I have looked, there has never been a security issue with Citrix.



STEVE:  And by bringing it along, they'll be keeping it current, also, instead of it just...



LEO:  That's right.  Yes, it actually does that, yeah.  It's interesting, it installs fresh each time and makes sure you have the latest Java.  That's probably why they do that.  Here's a quick Chrome security tip:  In about:flags - so you're in Chrome.  You type in the URL bar about:flags.  I'm doing it right now, just to see...



STEVE:  Which is just a cornucopia of things you should, like, think about before you click on them.  All kinds of goodies.



LEO:  There's a lot of flags.  Boy, there's a ton of flags.  So he says, in about:flags, one of the most important flags there is Click to Play.  This adds a third option to the menu Content Settings, which you click the Wrench, then Options > Under the Hood > Content Settings > Plug-ins, and that menu item is Click to Play.  Now, that means, when you go to a website, you can choose not only whether or not to use the plug-ins at all, but also which ones specifically you want to allow.  So you can only play the YouTube clip, but not the ads or other possibly malicious content.  Also, you need to expand the Location box, as I couldn't fit Alpha Quadrant into it.  I guess Alpha Quadrant's a game.



STEVE:  So this is a great tip, and I did it because he's right.  Your normal options under managing your plug-in content is an all-or-nothing.  And if you go to about:flags, and then enable that Click to Play, and then restart the browser, when you go back into the Options > Under the Hood > Content Settings > Plug-ins, sure enough, what used to only have two options, now has three.  And the one in the middle, I think it is, is Click to Play.  So you'll bring up a page whose plug-ins are disabled, and then you can selectively click on them in order to allow that plug-in to run, which is a very nice little upgrade to Chrome.



LEO:  I'm doing it right now.  Tools and then - Tools...



STEVE:  And options.



LEO:  Options, hmm.



STEVE:  Under the Hood is like the last thing down on the left.



LEO:  I don't see it.  I must have some strange setup.



STEVE:  Uh-oh.  I'm in Windows, and we know that there are differences.



LEO:  Oh, it's not in the Mac.  Okay.



STEVE:  Okay.  We know that there are differences between Windows...



LEO:  Oh, rats.  I can set the flag, but apparently I can't get to the menu item.



STEVE:  Yeah, the other thing I liked is that remember that Windows had the tabs on the side option, and I don't think that the Mac version does.  Which is really weird.  Why are there two different versions of Chrome?



LEO:  Yeah, I mean, I'm sure the engine is the same, the WebKit engine is the same.  It must be a - huh, interesting.  Well, it's okay [sobbing].  I didn't need that.  Let's see here.  Going on...



STEVE:  Stay where you are, Leo.  You're safer over there on the Mac anyway.  I'm holding on for dear life over here on this toy operating...



LEO:  There are plug-ins, and there were plug-ins for Firefox that would do that Click to Play thing for Flash and stuff like that.  And that was - that is a very handy feature.



STEVE:  Well, and NoScript does.



LEO:  Oh, right, of course.  Are you ready for Bonus Question - wait a minute.  Yeah, that was 10.  So here's a couple of bonus questions, first from Matt Peterson.  We were talking a couple weeks ago about your old InfoWorld column, the Tech Talk column.  Although they are mostly of historical or nostalgic interest now, writes Matt, I thought that the other Security Now! listeners might be interested to know that all or most of the back issues of InfoWorld containing your column are archived on Google Books.  I didn't know that.  So all of your insights, from "Borland's Turbo Basic Language Encourages Fast, Easy, and Casual Use" column, December 1986, to "The Only Drawback to the SCSI Interface Is Its Pronunciation" from January 1989, all the up to your farewell column in 1993, are there to peruse.  Ready for the short URL, kids:  snipurl.com/sgtechtalk.  Oh, dude.  This is great.  Look at this.  Did you know that, Steve?



STEVE:  Yeah, yeah.



LEO:  You knew it.  You already knew that.



STEVE:  Yeah, all the columns are there.



LEO:  Oh, that is really a wonderful thing to have.  I think that's fantastic.  So thank you for that tip.  It's worth a trip, he says, down memory lane if you were a computer nut back in those days, as I was, or if you just want to see what Steve's mustache looked like back then.



STEVE:  It was a lot darker.



LEO:  And Bonus Question 2, just had to mention this.  Kevin in Ocala, Florida found Khan Academy.  Steve and Leo, though you might want to check out this website:  KhanAcademy.org.  Many students use this to get help in math.  It's a terrific training site and free of charge.  I love the podcast and listen to many, but yours is my favorite.  I'm going to have to point Henry.



STEVE:  Okay.  Now, Leo, go to this page:  KhanAcademy.org.  And then scroll.  Look at the scroll thumb, how small it got, and just look at the topics.



LEO:  Holy moly.



STEVE:  It's just, it's unbelievable.



LEO:  This is, okay, so Algebra I, Algebra, Algebra II, which Henry is in, Arithmetic, Banking and Money, Biology, Brain Teasers, Calculus, and these are all worked examples from various textbooks.  So you can really learn.  California Standards Test Algebra II, I can sit down with Henry and play with that.  Chemistry, oh, he's in Chemistry right now, too.  First year high school or college course, roughly.  Cosmology, astronomy, credit crisis - I'm just in the C's.  Developmental math, differential equations, finance.  This is amazing.



STEVE:  It's just an incredible site.



LEO:  So who are these Khan Academy peoples?



STEVE:  I have no idea.  But it looks big and legitimate, and it's free, and just an incredible amount of content.  So I wanted to point our listeners to it.  I'm sure some people will find it very useful.



LEO:  This is "A free world-class education for anyone anywhere.  The Khan Academy is an organization on a mission ... a not-for-profit with the goal of changing education for the better by providing a free world-class education to anyone anywhere."  Wow.  Free of charge completely, in every area.  This is so cool.  It's just one guy?  They're telling me it's a person, it's an individual who does this.  2100 videos, exercises, a knowledge map.  I'm going to school.  I'm going to school.



STEVE:  Yeah, I had a hard time pulling myself away from it.  It's like, okay, wait, I've got to get this podcast produced here.



LEO:  You know what I really love?



STEVE:  What?



LEO:  Creative commons licensed.  I think, whoever you are, Mr. Khan, I salute you.  That's awesome.  Hey, great tip.  What a good way to end.  I'm glad you...



STEVE:  Had a bonus.



LEO:  ...threw that one in because that is fascinating.  Wow.  I never heard of this.



STEVE:  Hey, and we've got to thank Kevin in Ocala.



LEO:  Thank you, Kevin.



STEVE:  Thank you, our listener.  Our listeners bring it to us.



LEO:  Thank you all for being here.  We do this show every Wednesday about 11:00 a.m. Pacific, 2:00 p.m. Eastern time at live.twit.tv.  You can tune in and watch, or just download the show.  It's available at all sorts of places, of course on iTunes, the Zune Marketplace, anywhere podcasts are.  Or you go to our website, TWiT.tv, that's where all the shows are.  And each show has its own page.  Usually it's an abbreviation of the initials, in this case TWiT.tv/sn for Security Now!  And let's not forget - and by the way, there's a TED talk.  This Khan guy, Salman Khan has a TED talk.  So if you want to know more about this guy who does Khan Academy, that's awesome.  I'm going to watch that TED talk.  He says, "Let's use video to reinvent education."  Yeah.



STEVE:  Makes so much sense.



LEO:  Brilliant.  Wow.  I'm so glad there are people like this in the world.  Steve has copies of the shows.  I'm glad there are people like Steve in the world who also gives away a lot of free education.  If you go to GRC.com, you'll find all of the audio of all 294 episodes, including 16KB versions for the bandwidth impaired or people with bandwidth caps.  You'll also find the smallest version, which is a text transcription of it, which makes it really easy.  All the show notes, too.  That's GRC.com.  That's where you'll find SpinRite - Steve's bread and butter, his program to maintain hard drives - and all his freebies that he gives away, including the Perfect Paper Passwords and more.  GRC.com.  Steve's on Twitter, too, let's not forget.  He is @SGgrc.



STEVE:  And I think I'm either approaching or right around 18,000 followers.  So I've been tweeting a lot about Fukushima and various things that happen.  So I'm trying to create a useful stream for people who follow me.  And so, thank you, thank you for...



LEO:  Thank you for doing that.  I really appreciate it.  And, Steve, we'll see you next week.



STEVE:  We're going to talk about the Comodo theft of the SSL certificates, how it apparently happened, what people have, about certificate revocation, how that system works, which is something we've never covered before, and have lots of information about that.



LEO:  Should be great.



STEVE:  Thanks, Leo.



LEO:  Thank you, Steve.  Thank you all for joining us on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#295

DATE:		April 7, 2011

TITLE:		The Comodo SSL Breach

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-295.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the past week's very busy security news, Steve and Leo closely examine the circumstances and repercussions surrounding the mid-March breach of the Comodo SSL certificate authority certificate signing system.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 295, recorded April 6, 2011:  SSL and Epsilon Breaches.



It's time for Security Now!.  We're starting a little late today because of a scheduling change earlier in the morning.  We had a great triangulation with Cory Doctorow, who is a fan of this show.  Hello, Cory.  He was talking about listening to this show.  Steve Gibson is...



STEVE GIBSON:  Oh, cool.



LEO:  Yeah, isn't that cool?  Steve Gibson is here.  He's our security guru.



STEVE:  What a surprise.  I'm here for Security Now!.



LEO:  Wow.  That would be the 295th time you've done that.



STEVE:  Who would have guessed.  Yes, indeed.



LEO:  Episode 295.  We are going to talk about two big stories in the news today, the SSL breach...



STEVE:  At Comodo.



LEO:  ...at Comodo, and the Epsilon hack, which is just breaking this week.



STEVE:  Well, and there's, I mean, there's even, like, you probably heard about this massive SQL injection which has affected millions of links that Google turns up.  Just it's a huge automated SSL injection attack which is routing people to sort of mid-tier companies' websites to a malicious, your computer has been infected, download this to fix your problem kind of.  So we've got lots of news.



LEO:  I'll tell you how I always find out about stuff like that.  Now, I had read about that last week.  But of course I got a million phone calls on the radio show.  Well, not a million, but three or four from people who had gotten bit by it.  If I get three or four on the radio show, you know it's very widespread.  So I'm glad we can cover that, as well.



Steve Gibson, the man at GRC.com, creator of SpinRite, security guru, author of a great many free security utilities at GRC.com.  Let's get to the security news because there was another big story we didn't mention.



STEVE:  Oh, well, there's a bunch of stuff.  We've got to go back a little bit and just sort of mop up the debris from the RSA big SecurID break-in that we talked about, I guess it was just last week.  Some new information has come out from RSA.  They're trying to paint it as a very sophisticated attack.  Now, remember, this again, this is my most recent, my own personal blog posting, because what they initially announced and said was so annoyingly little that no one knew what to make of it.  Yet they're, like, the major multifactor hardware token provider for the industry.  As you mentioned, lots of government and Fortune 500 companies use RSA because, I mean, RSA are the inventors of crypto.  State-of-the-art asymmetric crypto came from the founders of RSA.



So the fact that they were being so circumspect led us to believe, okay, well, sure, they're embarrassed, they may have some fiduciary obligations to their stockholders not to say too much, they maybe need to get word out to other people who can deal with the problem.  Anyway, it turns out it was not a big league, sophisticated attack.  It was something we've talked about, and in fact I've been talking about for the last couple weeks before this.  Somebody opened an Excel file...



LEO:  Oh, no.



STEVE:  ...containing a Flash movie.



LEO:  Oh, no.



STEVE:  That's all it was.  It was a so-called spear-phishing attack, meaning that - what RSA did reveal is that two small groups within RSA received some email that was targeted at them.  So it was written to encourage them to open it.  Well, it went, it was automatically routed into their junk email folders.  So it wasn't even on their map.  But one of the employees in one of these small groups looked in her junk mail folder, and the email was titled "2011 Recruitment Plan."  And she opened the email, and there was an attachment, 2011 Recruitment Plan.XLS, making it a Microsoft Excel spreadsheet.  That she opened, and that allowed a Flash movie, an Adobe Flash file that was embedded in the spreadsheet with an at-that-time unknown exploit, a zero-day flaw which Adobe has since patched, that allowed it to run.  And that installed a well-known trojan which is freely available on the Internet called "Poison Ivy."  It's a so-called RAT, an R-A-T, a Remote Administration/Access Tool/Toolkit trojan, which then phoned home, that is, it called outwards from her machine to a remote server that gave bad guys essentially the ability to do anything that she could do from her machine, they could do.  And that's all it took.  That was their foothold in RSA.  And the rest, as they say, is history.



LEO:  Geez.



STEVE:  So it was from, I mean, and I had been talking about Flash in embedded Excel spreadsheets for quite a while prior to this because this was a well-known problem that had been successfully used in spear-phishing attacks.  It had been going on for several months.  And unfortunately RSA was one of the victims of that.  And that's all it took for someone to get enough access to their network that they were able to get credentials, elevate their access as necessary, and then exfiltrate what is now known to be essentially the keys to the kingdom, these master RSA files containing the mappings between the publicly available serial number of tokens and the secret key, the cryptographic key embedded in these hardware devices.



And as we know, at least one major agency has dropped RSA.  I mean, they can't trust their two-factor authentication any longer.  And RSA's advice was, well, don't let anybody see your token, and make sure all your other security is good.



LEO:  Don't use us.



STEVE:  Yes, basically don't rely on that second factor.  Oopsie.



LEO:  Oy gevalt.



STEVE:  Yeah.  Now, what's weird is that I had spoken to Stina Ehrensvrd, our founder of Yubico and great friend of the podcast about a month before at the, unfortunately or coincidentally, the RSA Security Conference.  She was out here for that.



LEO:  Is that put on by RSA?



STEVE:  Yeah.



LEO:  Oh, wow. 



STEVE:  Yeah.  And, but, I mean, I'm sure funded and financed by lots of other people.  But, I mean, RSA is like the main...



LEO:  They have to be so embarrassed by this.



STEVE:  Yeah.  It was not good.



LEO:  They're supposed to be the security wizards.



STEVE:  Well, so there's a technology known as HSM, Hardware Security Modules.  And these things are typically $15,000 just to get in the door.  The idea is, if you've got your servers spread around, like in data centers, and they have really, really, really important stuff in them, how do you keep them physically safe and protected and network-level safe?  That is, you know, as we've often heard, the main breaches are from internal employee subterfuge and sabotage of systems even to a greater degree than is external.  We don't normally hear about it because they're not network-wide, sweeping, automated attacks.  But much of the problem comes from employees.  So how do you protect something from, essentially from yourself, but also from just, I mean, like if something is vitally important.



So this was the problem that Yubico faced as their own YubiKeys gained in popularity.  They suffered an outage at one point earlier on, I mean, like not recently, but earlier on in their startup history that we're largely responsible for causing because we helped Stina get some traction in the industry.  And that was a real problem for them, I mean, for their users because, in order to authenticate a one-time password device, you need some authentication server somewhere that's able to say, yup, that's the next password in sequence that we would expect.



So they realized they needed to, I mean, and they're still at this point a very small company, I mean, just a handful of people.  So they're thinking, okay, we need to replicate this database of, basically of private keys, around the globe.  We need - we can't just be in one location the way we are.  It's time to get serious about this.  But then they faced the question, how do we protect these?  How do we have a server in Silicon Valley and one on the East Coast and a couple others in Europe?  And the point being that all of these systems have to contain duplicate copies of everything so that local users are able to authenticate against them.  But the flipside is, you have to keep them secure.



So they looked into the whole Hardware Security Module solution.  And it turns out, I mean, again, it's $15,000 just to open the door.  But you have to have, typically, you'd be repeating this everywhere.  And you end up with, like, physical security and data level security.  Well, what they decided was, Jakob, their lead techie person, said, why don't we put this in a USB stick?  Like, put everything that we have to protect in a USB dongle?  And let's build a cryptographic processor and a true random number generator, not just a pseudorandom number generator, but since we'll have hardware we can do weird things like measure the noise threshold in a diode which is actually generating quantum level noise and capture that and use that to generate cryptographic material.



And our listeners can't see it, but I am holding one up in front of the camera, which is - this is marked Beta 0.9.6. - is the YubiHSM, as they're calling it.  It's the Yubico Hardware Security Module.  They have essentially solved the problem and reduced the cost of protecting, literally, the keys to the kingdom, all the stuff that companies absolutely cannot lose control of, down from $15,000 to $500.  So, and I imagine, I guess it does have - it's got their name on it, so they did some plastic molding.  I mean, it looks, for the people who are not seeing the video stream, it looks like a regular USB thumb drive.



LEO:  Yeah, same size, yeah.



STEVE:  That's all it is.  It's got the USB interface.  And so what they've built in here, there is a processor and nonvolatile memory and some fancy electronics that uses quantum level noise to generate true randomness, better than you can generate algorithmically.  If our listeners are interested, just Yubico.com.  If you look at, like, What's New, I think is the first link on their site, it'll take you to Yubico.com/yubihsm, where there's a lot of information.  They're still at beta at this point.  The final device will retail for $500.



And from their site they explain that it contains a cryptographically secure, true random number generator; a store for cryptographic keys, that is, a secure place to store cryptographic keys.  It also incorporates a complete YubiKey authenticator that has enough storage for a thousand YubiKeys.  So, for example, if you were a company that wanted to deploy YubiKeys yourself but not rely on Yubico for authentication, this little gizmo here can store your YubiKeys' secrets...



LEO:  But you wouldn't - you'd need a server.



STEVE:  Well, yeah, exactly.  So you plug this into a server, and so the server passes to this what the YubiKey has just said.  And it says, yup, that's good; or, nope, that's not good.  But the point is you are...



LEO:  It's a black box.  It's a sealed black box that can't be modified.



STEVE:  Precisely.  It is a sealed black box that cannot be modified.  And they list some use cases for this, saying you run an authentication service, secrets are stored on a computer that has to be accessible from the Internet and are concerned that one day it might be hacked.  You want to prevent system administrators and staff who have physical access to the server from copying the database and getting access to sensitive data.



LEO:  Yes, good point.



STEVE:  Yeah.  You need an architecture that prevents a hacker from compromising your secrets, but allows you to run your service full speed.  Or you've got a smaller fleet of YubiKeys and want to do the authentication yourself.  So just today, on April 6, 2011, they have announced their YubiHSM.  And they are making available betas if these to interested developers who want - because they're soliciting people to flesh out the full specification, to make sure they haven't forgotten something that might be useful to add.



LEO:  That's the right way to do this, absolutely, get the security community to look at this.



STEVE:  Yes.  So on their site it says, "Yubico is inviting its developer community to refine the YubiHSM and define the functionality set of the final product.  Developers who would like to contribute with applications and further development of the open source client software can today apply to get a free beta YubiHSM from Yubico."



LEO:  They anticipate, what, about $500 to buy this.



STEVE:  Yes, they're saying that it will be $500, which is way below the entry price, by orders of magnitude, what, 30 times cheaper than a $15,000 similar device which is the only other thing available now.



LEO:  Now, somebody's saying that - a couple of people in the chatroom said, yeah, but look how easy that would be to lose.  I don't imagine you'd keep that on your key ring.  You'd keep it plugged into the server.



STEVE:  Oh, yeah, I mean, it's in a data center in a locked environment.  But remember, if RSA had had these files similarly protected, they could not have been exfiltrated.  And...



LEO:  Now, even if somebody stole it, it's useless to them; right?



STEVE:  Correct, exactly, because it itself is protected cryptographically, and it cannot be induced through the API, there's nothing someone can do that can get the secrets out of it.



LEO:  So even physical access to the server isn't going to compromise it.



STEVE:  Precisely.



LEO:  But don't lose it.



STEVE:  No, well, no.  I mean, you would have a couple of them.  Or you would have this data backed up offline.



LEO:  Oh, you could do that, okay.



STEVE:  The point is you don't want it online.  It's like, I've never gone into the architecture of my own ecommerce system, but the data that we have is not available at that server.  I did it from scratch the right way.



LEO:  It's the equivalent of the cabbies' "Cash is not kept on premises."



STEVE:  Exactly.  Exactly.  And unfortunately, clearly, RSA's data was accessible for exfiltration.  And this should be a lesson to all companies.  And what I like about what Yubico has done is solving this problem no longer is necessarily super expensive.  You could imagine smaller companies, developers listening to this podcast who are thinking, wow, right now we're just hoping we're not hacked.  But if you move your stuff behind this kind of protection, then you don't have to hope any longer.  You can know that you're safe against being hacked.



LEO:  Awesome.



STEVE:  And they've got a PDF you can download that's got the entire specification of how this thing works, what it does, and how to talk to it.  So I wanted to give everyone the heads-up that this thing now exists.



LEO:  What a smart company.



STEVE:  Last week I deliberately didn't talk about something because it just seemed unlikely to me.  I got a ton of email and tweets from people asking about Samsung's laptops coming pre-installed with keystroke loggers.



LEO:  Little pat on the back for us.  Because I saw that story, and I did not leap on it.  And I know you didn't either.  Something was fishy about that story.



STEVE:  Well, okay.  The good news is our friend Alex Eckelberry - who used to be at Sunbelt but now is technically GFI's chief technology officer because GFI, I guess, bought Sunbelt - he stepped up with a blog posting that I really appreciated.  The industry appreciated it because they explained what happened.  This whole rumor of Samsung laptops coming with keystroke loggers preinstalled was the consequence of a false positive from one AV product, and it was Sunbelt's.  It's their VIPRE, V-I-P-R-E.  The Slovenian language directory...



LEO:  Slovenian.



STEVE:  Slovenian, right, language directory for Windows Live was C:\Windows\SL.  Which was the same directory created by the StarLogger, thus SL, StarLogger keystroke logger.  And unfortunately somehow all that VIPRE was doing was looking for the presence of that subdirectory off of Windows to make its declaration.  Now, Alex in his blog posted:  "The detection was based off of a rarely used and aggressive VIPRE detection method, using folder paths as a heuristic.  I want to emphasize 'rarely' as these types of detections are seldom used, and when they are, they're subject to an extensive peer review and QA process."  So they recognized that, in retrospect, just looking for the presence of a subdirectory "SL" was really not specific enough, and it did...



LEO:  No kidding.



STEVE:  Yeah.  It would tend to produce false positives.  In this case it did.  And that sole thing was entirely responsible for the industry briefly going insane and calling and accusing Samsung of installing keystroke loggers when in fact that wasn't the case at all.  So for all the people who were concerned, that's essentially what happened.



LEO:  Yay.



STEVE:  Yeah.  Okay.  Malicious code injection.  Another event that's happened in the last week is the most successful SQL injection attack ever seen.  Initially it looked like it was being reported as at least hundreds of thousands of websites.  But later a Google search for domain names known to be used by the attackers uncovered more than three million pages, web links, which were displaying URLs to those domains.  It was, not WebMon, shoot, I can't remember the name of the company that first uncovered, they named this LizaMoon because that was the first domain they saw - Websense, it was Websense...



LEO:  Websense, that's right, yeah.



STEVE:  ...that ran across LizaMoon.  And so they dubbed this the LizaMoon attack.  But since then, 21 other domains were found.  So what happened was someone created an automated SQL injector which rummaged through all kinds of websites looking for an SQL injection vulnerability.



LEO:  And, by the way, somebody's saying in the chatroom this is not a new vulnerability they were taking advantage of.



STEVE:  Right, right.



LEO:  It was an old one.



STEVE:  It was automated.  And that's what made the difference.  So all that had to happen was that, in your typical Web 2.0-style attack, a web server does not adequately sanitize user submissions.



LEO:  It's supposed to, but that's just a mistake.  It's a bug.



STEVE:  It's a bug.  So basically a spider, a web spider posted these SQL commands such that, when the server went to display the page containing the content that the spider had put up there, instead it created links to these 21 separate domains which presented a dialogue box saying - a popup, basically, calling itself Windows Stability Center, looking like it was from Microsoft, though Microsoft doesn't have anything called Windows Stability Center.  And so these were small businesses, community groups, sports teams, sort of mid-tier organizations who were hosted on any number of providers.



LEO:  Everybody uses MySQL.  Everybody.  I mean, we use it.



STEVE:  I don't, but, yeah, I know...



LEO:  You're smart.



STEVE:  ...everybody else does.



LEO:  I wish we didn't, but...



STEVE:  Yeah, it's just you have to be extremely careful when this is the kind of technology that you use, that you've got filters.



LEO:  To illustrate that this is a longstanding problem, there's a great comic I'm going to show here from XKCD, our chatroom reminded us, XKCD.com/327.  "Hi, this is your son's school.  We're having some computer trouble."  "Oh, dear - did he break something?"  "In a way.  Did you really name your son Robert'); DROP TABLE Students;--?"  "Oh, yes.  Little Bobby Tables, we call him."  "Well, we've lost this year's student records.  I hope you're happy."  "And I hope you've learned to sanitize your database inputs."  That is a very geeky comic, but boy, it says it right there.  That says it all.



STEVE:  Yup, exactly.



LEO:  That's obviously an SQL command that says delete a table, the entire students table.  And if you didn't check your inputs, if you allowed somebody to type that into a URL, well, shame on you.



STEVE:  Right, because then, when the server tried to display it, it would execute it as if it were a valid command.



LEO:  Oh, lord.



STEVE:  And your SQL database would drop that table.



LEO:  Say, yeah, whatever you want.  The problem with computers, they're very compliant.  Okay.  Let's talk Epsilon.



STEVE:  Okay.  So Epsilon is the world's largest permission-based email marketing services company.



LEO:  Who knew?



STEVE:  I know, never heard of them before.



LEO:  Who knew, yeah.



STEVE:  2,500 clients, including seven of the Fortune 10.  So seven of the largest 10 corporations in the United States use Epsilon to do their customer emailings.  So when we get email from, well, from 1-800-Flowers, AbeBooks, Air Miles, Ameriprise Financial, Barclays Bank, Beachbody, bebe stores, Best Buy, Brookstone, Capitol One, City Market, Citi, Dillons, Disney...



LEO:  And he's just in the C's.



STEVE:  ...Destinations, Eileen Fisher, Ethan Allen, Food 4 Less, Fred Meyer, Fry's, Hilton Honors Program, Home Shopping Network, Jay C, JPMorgan Chase, King Soopers, Kroger, Lacoste, LL Bean Visa Card, Marriott Rewards, McKinsey & Company, MoneyGram, New York & Company, QFC, Ralphs, Red Roof Inn, Ritz-Carlton Rewards, Robert Half, Target, The College Board, TD Ameritrade, TiVo, US Bank, and Walgreens.  They were all breached.  That is, Epsilon is saying that 2 percent of its email clients, which 2 percent of 2,500 would be, what, 50, were affected.  Well, I just read the list of known clients who are now vulnerable to a much heightened level of spear-phishing.  The problem is that what was lost was the email databases for those companies.



LEO:  So people didn't get - they didn't get the credit card numbers or personal information.  They just got email addresses.



STEVE:  Well, and names.



LEO:  And names.



STEVE:  And that's the problem is that there's now - there's a much greater chance that you will click on a Hilton Honors Program email that knows your name.



LEO:  Hi, Leo.  Your Hilton Honors program is about to expire.  Want to renew, make sure those miles are still good?  Click this link.



STEVE:  Right.



LEO:  And then you log in.



STEVE:  Right.



LEO:  But it's not them.



STEVE:  Right.  So, I mean, because of the breadth of this, I mean, this was a huge breach of their database.  And once again one wonders, if they had protected this in a Hardware Security Module of some kind, making it not available for theft, then they wouldn't have egg on their face.  So other security blogs and security-aware people are really, are warning people to be especially alert for spear-phishing attacks.  That is, from the list that I read, which is the most complete list I've managed - I pulled it from...



LEO:  Is that from the Times or...



STEVE:  ...a bunch of different places.



LEO:  Oh, different places, okay.



STEVE:  Yeah.  And that's why I had to alphabetize it in order to, like, make sure I hadn't lost any and to remove duplicates because there were so many companies there.  But, you know, their email addresses are - their email lists are out, along with the people's names.  That is, whatever it is that you are - what you normally see when you receive email from these companies is it comes from the database that was lost.  So the point is, that's what you'll see when you get fraudulent email and may be much more inclined to click on a link.  And so it's dangerous.



LEO:  And the funny thing is that Epsilon gave boilerplate language to send out.  All these companies sent out essentially the same email.  And unfortunately, now, Chase's was pretty good.  Somebody sent me the Chase email, and it says, "We want to remind you, Chase will never ask for your personal information or login credentials in an email.  As always, be cautious if you receive emails asking for personal information," et cetera.  Many of these - actually the Chase email was pretty good.  It was pretty good.  It actually said don't click links and stuff.  Most of these, the one that Epsilon seems to have sent out to everybody, said don't click links on email from people you don't know.  But that's the problem.  It's going to come from these companies.



STEVE:  Right.



LEO:  It's not going to be from people you don't know, it's going to be from Citibank and Chase. 



STEVE:  Exactly.  Essentially, the data that was lost, that they lost control of, that was exfiltrated from them, is what they use, is exactly what they use to generate the legitimate email because they're the people that send the email out on behalf of their clients.



LEO:  Right.  So what is the advice?  I mean, I know our audience knows it.  But just to reiterate.



STEVE:  Well, I would say, if you receive email, because email itself, email displaying in a web page where the URL behind the link that you click can be masked...



LEO:  The link can say Citibank.com, click here, and go to Hacker.com/Citibank.



STEVE:  Or C-i-t-y-b-a-n-k, I mean, a tiny change in the domain name takes you to somewhere else.  So, I mean, unfortunately it's really - I mean, again, this is what our listeners know.  It is just not safe to click on a link in email, that you receive in email.  If you really have to, for some reason, you could look at the email headers, maybe.  But unfortunately you've got to be a real expert because you and I have talked long ago on TechTV shows, Leo, about spoofing email headers and how easily that could be done.



LEO:  It's trivial.



STEVE:  So, I mean, the real news is read the email, then manually go to the website, entering the URL yourself, logging in, not through email, but using LastPass or whatever you use for logging in, and arrange to achieve the same end, but not clicking something that you receive in email.  Treat the email as just the information that something is important that they're bringing to your attention, like, oh, look, your miles are about to expire unless they hear from you immediately.



Generally the phishing emails use an emergency of some sort to get people to act.  They're not saying, hi, we just wanted to make sure you're happy with the service we're providing you because people go, yeah, yeah, yeah, fine, delete.  No, it's that there's a call to action in spear-phishing emails that is presenting you with some dire event unless you take action.  And people go, ooh.  And in the moment of worry, they hit that, they click on that link without - even if they know better, it's like, oh, I'd better do this right now.  It's like...



LEO:  I've come so close because they scare you.  You click the link, and it all looks legitimate.  And then fortunately in my case I've always gone, whoa, whoa, whoa, as soon as it asks you for anything, and you look at the URL.  But you're right, hand-type the - that's what I told everybody on the radio show.  So thank you for reiterating that.  That's all you have to do.  Hand-type it.



STEVE:  Yes.



LEO:  Now, there is one - and the chatroom came up with this.  There's one side benefit to the fact that Epsilon services so many of these big companies.  You can go to their website and opt out of all emails with one click.  So if you go to Epsilon.com or search for Epsilon consumer opt-out information, there is a page where you can say don't send me anymore crap.



STEVE:  Well, and are those only promotional emails, or are those, like, true account maintenance sort of emails?



LEO:  Well, it's marketing emails.



STEVE:  Oh, okay.



LEO:  So it says "Many consumers value and seek out targeted advertising [bullshit] and look forward to receiving offers of interest at their homes via email."  So you can choose...



STEVE:  That's amazing if you can opt out of 2,500...



LEO:  You can choose not to receive most - it doesn't say all, but most targeted advertising by following the links below.  Consider your choices carefully.  Opting out of Epsilon Services will stop the delivery of some targeted advertising.



STEVE:  Some spam is good.  Uh, right.



LEO:  It will not eliminate all targeted offers, it says.  So much for that.  But at least some.  I've been, lately, I've been unsubscribing.  I've been on an unsubscribe tear.  Anytime I get something, any bacon, I just unsubscribe, unsubscribe.  And I'm hoping that that will take hold.



STEVE:  So the do-not-track movement is gaining some traction.  For people who use Twitter, there is now an account, it's just @donottrack.  And I am following it and would recommend it for anyone who's interested.  Mozilla blogged at the end of March, since we've last spoken to our listeners through this podcast, that advertisers and publishers are beginning to adopt and implement do-not-track.  Specifically, in their blog posting, they said that the AP news registry service run by the Associated Press implemented the DNT header across 800 news sites, servicing 175 million unique visitors each month.



And the Digital Advertising Alliance, which actually I care about much more, the DAA, which includes the five major media and advertising agencies, is initiating a process to explore incorporating the DNT header, as proposed by Mozilla, into its self-regulatory program for online behavior advertising.  The DAA represents more than 5,000 leading media and technology companies that span the entire marketing media ecosystem.  So the good news is, this is the same header that IE9 offers.



LEO:  Oh, good.



STEVE:  That DNT: 1.  And I immediately contacted Giorgio, the famous author of NoScript, whose headers were not compatible; and I said, "Hey, looks like this has pretty much been decided.  How about switching NoScript over?"  And he said, "Steve, I did that a couple months ago."



LEO:  What a surprise.



STEVE:  Ah, oh.  Okay, good.  So the good news is, if you - and of course Giorgio reminded me also that using NoScript to produce the header allows you to allow some and disallow others.  So it gives you granular control.  Whereas the other guys are just a blanket, stick this DNT: 1 header into every request made by the browser.  Which I think is just fine.



So if you haven't yet gone up to v4 of Firefox - and I have not because I don't do anything immediately when this sort of thing happens, I wait a while - but you are using NoScript, NoScript is now adding this DNT header, as is IE9.  You have to turn it on in every case.  Nowhere is it enabled by default.  So you do need to opt into opting out.  But at least it's there.  And everyone, all the critics say, yes, well, but it's all - honoring it is optional.  It's like, yes, it is at the moment.  But, you know, these advertising agencies recognize that they risk having Uncle Sam in the U.S. case drop a heavy foot on them unless they behave well.



LEO:  Yes, exactly, yeah.



STEVE:  And so this is - ultimately we're going to get a law that says, if your browser says DNT: 1, it is illegal to track you across the Internet.  And we're not there yet, but that's the right answer.  And it'll end up happening.



LEO:  And even if we don't get a law, the real problem is bad guys will always circumvent, no matter what.  But the good guys are going to try, look, they want to stay in - people like Epsilon want to stay in business.  They're not going to flout, flaunt our requests.



STEVE:  Right, right.



LEO:  I hope.



STEVE:  Right.  A clear and explicit request not to be tracked behaviorally.



LEO:  The problem is I just was following the rabbit hole of this Epsilon opt-out.  



STEVE:  Uh-huh.



LEO:  They don't make it easy.  They ask for - and it's not optional, required - the header from the spam, from the message that you - not who it's from, not - they want the entire header.  Most people will not know how to do that and will not do it.



STEVE:  Right.



LEO:  Terrible.  Just awful.



STEVE:  So I've got a little bit of miscellaneous stuff before we get into talking about Comodo.  This just crossed my radar, and I thought this was really interesting:  Microsoft offered to purchase 666,624 IPv4 addresses...



LEO:  We're running out.



STEVE:  ...out from the bankruptcy proceedings of Nortel, the bankrupt Canadian telecom equipment maker.  So Nortel's going bankrupt.  They're a corporation that had a huge block of IP addresses.  And Microsoft has offered and apparently - I just saw something else that looked like it had been accepted - $7.5 million for their block.  And that's, like, wait a minute.  Since when are IPv4 addresses for sale?  I mean, you know, you get them for free when you have an ISP.  So I'm interested in how that can be regarded as a corporate asset, why they wouldn't immediately return to the provider of Nortel's - wherever Nortel got them from, from some registry.  It's like, wait, they're not property, they're sort of - I don't know what they are.  But I don't know how you can buy them.



But Microsoft's paying $11.25 each for these.  And as you said, Leo, it's like, oh, no.  We're running out of them.  And I have seen other notes talking about the emergence of a black market, or a gray market, at least, or dark gray, in IPv4 addresses.  I guess they're going to become worth something.  Wow.  I don't know how you can sell them.  I don't know you...



LEO:  You could auction them off.



STEVE:  ...can call them property.



LEO:  But you know, it does change bankruptcy proceedings.  You now actually have some assets that might be of some value.



STEVE:  Yeah.



LEO:  Ignore that person looking over my shoulder, it's my son.  Go ahead, Steve.



STEVE:  Someone tweeted something that I really appreciated to me, that I wanted to share.  Just noting, he said, "Steve, you don't need to be quite so embarrassed.  Skype's SSL certificate expired on March 31st."



LEO:  Well, it's about time.



STEVE:  And of course caught them with their pants down.



LEO:  Isn't that funny?



STEVE:  It's happened to me; it's happened a couple other times to notable large organizations.  And so you go, oh, crap, and you immediately go with your registrar and renew your SSL certificate and get it up on your servers.  So it does happen, even to the big guys.



LEO:  Amazing.



STEVE:  I also wanted to - just a note that there is a forthcoming virtual machine solution to allow Android to run on Windows, called BlueStacks.com.  BlueStacks...



LEO:  That's cool.



STEVE:  Yes.  It's not out yet.  They ask you to follow them on Twitter @bluestacksinc, so it's just @bluestacksinc.  If you go to BlueStacks.com you get a little Flash video that plays and sort of shows you something, some pretty graphics talking about the idea of being able to have Android apps running in a VM on Windows.  So we talked about how Android was hosting a VM last week and would allow you to use that in order to preview Android apps.  Now you'll be able to do it locally, running them under Windows.  There is also something called Android-x86.org, which apparently has made this happen also.  But I'm told that it's much more difficult to get it up and configured and with the video drivers and all kinds of weird stuff.  So with any luck, a VM would be a great little solution for basically giving you a little Android machine running under Windows that you could run Android apps in.



LEO:  I can't wait to do this.  I wish it were there now, actually.



STEVE:  Yeah, we'll keep an eye on it.  And I am following bluestacksinc in one of my following Twitter accounts, so I'll...



LEO:  Yes, I see them.  I just followed them myself because I...



STEVE:  Yeah, but you follow a thousand...



LEO:  I know.



STEVE:  I mean, 17,000 or something.  So you'll never know if it happens.  But I'll let you know.  I'm sure you'll know before I know, Leo.



LEO:  I'll let you know.



STEVE:  That'd be very nice.  And I wanted to mention I got a nice little note from a Neil Warwick with a subject that caught my eye, saying that "SpinRite Saves the Sky."  And I thought, okay, what?  Okay, so and he's at Reading, England.  He's a Security Now! listener.  He sent it through the Security Now! feedback form at GRC, which is GRC.com/feedback.  He said, "Hi, Steve.  Just thought you'd like to hear a short story about how SpinRite saved my Sky TV/DVR from losing all my partner's saved shows, and probably saved me from a lot of nagging, too.



"In the U.K. we have a satellite TV service called Sky TV that broadcasts many, many channels.  And for most people it's accessed using a hard disk-based DVR similar to your TiVo boxes.  A few weeks ago our box started freezing and stuttering when viewing live or recorded content.  We have an insurance package with Sky to cover breakdown, so I called them.  Their only solution was to offer to send an engineer out who would reset, in other words, reformat the hard disk; then, if that didn't work, would replace the DVR in its entirety.  Having been a listener of Security Now! since July 2010, when I saw it mentioned in a magazine" - I don't know if he saw SpinRite or Security Now! mentioned - he says, "I started at the beginning."  I think he saw Security Now! mentioned in a magazine.  So in July 2010 he saw Security Now! mentioned in a magazine.



 He says, "I started at the beginning; so as I write this, I'm up to about Episode 155.  I've been looking for an excuse to buy a copy of SpinRite and thought, why not give it a go?  15 minutes later SpinRite was downloaded and burned to a CD.  I removed the hard drive from the DVR, installed it into a slave PC chassis I had lying around, and booted the CD.  I set SpinRite to work immediately and went to bed.



"Upon getting up the next morning, SpinRite had finished and reportedly had fixed some errors.  So I reinstalled the drive into the DVR and powered up.  As you will probably have guessed by now, everything worked perfectly.  When the engineer showed up to have a look, he couldn't find anything wrong with the system so left without doing anything.  I didn't tell him about SpinRite, as I'm not sure if I'm allowed to open the box under my insurance agreement.  Thanks again for a great product and great podcast.  Neil Warwick."



LEO:  Awesome, awesome, awesome.



STEVE:  It says, "P.S.:  I run a very small computer repair company and would like to offer a SpinRite optimization-slash-check as a service for clients' PCs, et cetera."



LEO:  That's a good idea.



STEVE:  "Can you tell me what kind of license I would require to do this, and how much it would cost?"  Well, the way we've solved that problem is to ask people who want to run SpinRite on machines they don't themselves own, or a corporation that just wants to run it across their whole organization, we call it a site license.  And so we ask people to keep four licenses current.  So, for example, Neil already has one.  So if he bought three more copies, then he would qualify to use SpinRite on any drive that he wants to.  That's essentially a site license.



LEO:  That's a great deal.  That's a great deal.  I think that's very fair.



STEVE:  Yeah, well, it allows people to try it and then not - then they don't have to ask for a refund when they want to upgrade to a different license.  So I thought, okay, let's just have them maintain four current licenses.  So when we have an upgrade, if they upgrade all four, then that's like upgrading their whole license.  So but the plan works very nicely.



LEO:  So let's talk about this Comodo breach.



STEVE:  Okay.  So here's - there's a really interesting back story here because it wasn't initially acknowledged by anyone.  What happened was a researcher at the University of Washington's Security and Privacy Research Lab, Jacob Appelbaum, he was just sort of, as he does, monitoring the Chromium, that is, Google's Chrome browser open source project, just sort of - he's like part of the change log, seeing things go by.  And in late March he noticed sort of an odd thing had been added.  A bunch of SSL certificate security serial numbers had been put into the source code and blacklisted.  So there was a function that had been added that said, essentially, see if certificate is blacklisted.



And then there was an array of serial numbers.  The first one was commented as this is just to be used for testing.  But then there was, like, nine or 10 others after it.  And he thought, huh.  That's weird.  Why would Chromium be, like, putting a block of SSL certificate serial numbers into the source?  Seems like a strange thing.  And this sort of just, like, raised his curiosity.



And then, at around the same time, he noted that Mozilla pushed out a security update.  And he looked into it, and it was doing the same thing.  It had some - he was a little bit thrown off at first because Mozilla's format has a zero byte prepended to the serial numbers.  So a simple match didn't line up.  But when he removed that leading zero, then he realized that Mozilla was also blacklisting, in a patch, a block of SSL certificates.



Well, he hangs out at EFF, and EFF has something they call the SSL Observatory, where they monitor the Internet, looking sort of at traffic, sort of just trying to watch the way SSL is being used and seeing what's going on.  The SSL Observatory had built up over time a big database of certificates.  So he was able to essentially process this list and see that it appeared that all of these certificates had been issued by one certificate authority, something called UserTrust.com.  The URL in the certificate was http://www.usertrust.com.  And that seemed to be a subsidiary of some sort of Comodo.



And so he sort of thought, okay.  It sure seems to me like the only reason Chrome and Mozilla would suddenly be blacklisting a block of certificates is that they're important, and they're bogus, they're invalid.  So he sent a note to Mozilla, who said, uh, hmm, yeah.  Something's happened that we don't want to talk about.  Now, in fairness to Mozilla, they have since regretted their response, that they weren't immediately forthcoming.



But what happened was there was some dialogue behind the scenes.  What essentially happened, we now know, is that a subsidiary of Comodo - and Comodo has never even said whom.  But we now know, from this forensic analysis, one of Comodo's - Comodo is a so-called CA, a Certificate Authority.  They have a subsidiary that they call RAs, Registration Authorities.  And one of their RAs was hacked in some fashion, and we think we know how now, and a bunch of very high-profile websites got loose, well, high-profile certificates for websites were made illegitimately:  mail.google.com, so an SSL, a valid SSL certificate for mail.google.com, for www.google.com, for login.yahoo.com, for login.skype.com, for addons.mozilla.com, for login.live.come, which of course is a Microsoft domain, and something called "global trustee."  Valid certificates for those high-profile domains were issued by this registration authority that has received its authority from Comodo.



Now, the SSL Observatory, this project that the EFF runs, was able to state that, knowing that these certs were signed by this user trust organization, as of August 2010, so late last summer, 85,440 publicly transacted, that is, they've seen them on the Internet, HTTPS certificates were signed directly by this UserTrust organization.  That's significant because, if we were to blacklist UserTrust, then 85,440 websites would suddenly have their certificates that they had gotten from this UserTrust organization declared invalid, and they'd have to scramble around to obtain SSL certificates from someone else.



So after this became public - oh, the other thing that happened was that I first became aware of it when Microsoft issued an emergency update through their Windows Update system.  And looking at it closely, it was very clear that Microsoft was immediately adding a block of certificates to their untrusted list in Windows.  I tweeted immediately to the followers of SGgrc that this had just happened, and gave them the link to Microsoft's security page, where you could choose which operating system you were using, and yourself immediately update your version of Windows so that it would no longer trust these certificates.  And the next day it surfaced, or shortly thereafter surfaced on the standard Windows Update as an important update that users should install immediately.  So Microsoft, Google's Chrome, and Mozilla were all immediately updated.



Now, one of the questions this raises is, well, okay, don't we have a facility in place for revoking bad certificates?  And the answer is, uh, kinda.  It doesn't really work.  And that's why all of these major browsers, well, these three major browsers were immediately updated.  But what about less significant browsers?  What about browsers that are not mainstream?  There's lots of little offshoots that didn't get changed, didn't get updated, that aren't part of the central core browsers.  To what degree are they vulnerable, and to what degree are their users vulnerable?



So the other thing that happened when news of this surfaced is that someone began posting on Pastebin.  We've talked about Pastebin once before because there was - it's a way of anonymously posting stuff up to the Internet that anyone who knows the URL - then you share the URL, and people can go there and grab what you posted.  A hacker was claiming that he's the person who did this and put a bunch of code and certificates and things up in order to prove it.  Several people have in fact verified, because he posted the private key which he used, and that allowed people to verify that he was in fact the person who created these certificates.  What apparently happened was that this registration authority, who is a subsidiary of Comodo, had a DLL which itself was empowered to log onto their servers and issue certificates.  So this guy, who is believed to be an Iranian hacker...



LEO:  Oh, great.



STEVE:  There was some news, there was some speculation that this was state sponsored, that this was based in, like, Iran was hacking SSL in order to get certificates that could be used to spy on people.  It's possible; but it's, again, we generally like the most feasible explanation.  And it looked like it was one guy because, if this was state sponsored, no one in Iran would have gone bragging about this and posting this stuff on Pastebin...



LEO:  Well, that's true, yeah.



STEVE:  ...and so forth.  So he reverse-engineered this DLL which contained the username, the login username and password for the server that this subsidiary of Comodo, apparently UserTrust, was using, and accessed their server and was able to induce it to issue these certificates.  Now, Comodo found out about it, immediately revoked these certificates.  We'll talk about that quickly.  But then they also did find one server in Iran where one of the login.yahoo.com certificates was in use, meaning that, like in the same way that when Google has, Google gets a certificate for themselves, they install it on their servers so that when you connect to them over SSL, that server is declaring, I am Google.com.  And that's the whole point of a certificate is that it is providing authentication in addition to encryption.  So it was briefly the case that a legitimate server in Iran, at an IP located in Iran, was saying it had one of these fraudulently issued certificates installed on it so that, when you connected to it in Iran, it said, I am the login.yahoo.com server.  And it quickly stopped answering queries after this revocation happened.



So, briefly, to talk about revocation.  The idea is that certificates have a certain life.  I like them, you know, I complain about having to do this every couple years.  But there's an upside to it because, by keeping certificates relatively short-lived, they will expire no matter what.  And so the burden is on the certificate licensee, the owner, to go and renew the certificate with the certificate authority and get another one that's good for one, two, or three years.  I think three is the most I can purchase from VeriSign, which is where I get mine.  But what happens if, while during that window of time that a certificate is valid, if something happens, for example, if the certificate got away from its owner?



So, for example, if Google lost control of the private key that is what makes its certificate valid, which has been signed by VeriSign, if they lost their certificate, then, that is, if anyone else could get it and install it on some random server, that would be bad.  So if that happened, Google could say to whoever signed their certificate, please revoke this certificate.  We need a new one, and we need the one that we lost control of to be canceled.



So there's a facility - there's actually two.  One's called a CRL, a Certificate Revocation List; and the other is a protocol, an Online Certificate Status Protocol, OCSP.  The certificate revocation list is a list which a browser client can download from the Internet containing a long list of all the certificates which are revoked, but otherwise valid, meaning that, thank goodness for the expiration of certificates, so this list doesn't have to contain certificates which are expired.  It only needs to contain them, the certificate serial numbers of certificates which would otherwise still be valid except that they have been revoked by their issuing agency.  And the point is it's only by somehow proactively declaring a certificate invalid that it can be found to be invalid.  That is, if bad guys get it, then they're going to want to use it.



So somehow we need to tell our browsers, no longer trust this certificate; however, still trust other certificates issued by the same certificate authority.  Now, and of course we've talked about the controversy, the fact that there's more than 1,500 certificate authorities wandering around the globe now, all equally trusted by our browsers.  Okay, the second mechanism, this online certificate status protocol, that's a different approach where, before trusting a connection, the browser will reach out and, in real-time, check to see that a certificate is valid.  So that's something that some browsers support that you can turn on to check it on the fly.



The problem is, both of these approaches fail open, meaning, if your browser is unable to obtain information that the certificate is bad, it assumes it's good.  So part of a spoofed attack, a spoofing attack would be, for example, a man-in-the-middle attack, where somebody would intercept your communication - we've talked about this in WiFi scenarios or hotel scenarios or state-level scenarios.  They would intercept your connection, and they would proxy your access to the Internet.  They would, when they saw you trying to go to login.yahoo.com, they would accept the connection, respond using their fraudulent and revoked certificate, which your browser doesn't know is revoked.  When your browser tries to authenticate on the fly that revocation, all they have to do is drop the connection.  All they have to do is return a 404 or a 500 server error, or bad URL, something that blocks your browser from getting an affirmation or denial, and all browsers currently accept the certificate.  Even though technically it's been revoked.



This is regarded as a known and serious problem with the whole revocation process, is that the same mechanism that would have a bad guy able to pull off a useful exploit with the certificate, unless they were able to spoof DNS, which is the other way you'd do that, is to get someone to go to a bad IP address by spoofing DNS.  But any kind of a man-in-the-middle approach would still have your browser believing that the certificate was valid because it wouldn't know otherwise.



And when we step back from all this, here's the fundamental problem.  When you think about the way our whole SSL browser security web authentication system functions, the fundamental technical design is fragile because any certificate authority can certify to any user that any server owns any domain name.  Therefore, the consequences of a misplaced trust decision are about as bad as they could be.  And stated another way, the problem is a structural one.  There are 1,500 certificate authority certificates, controlled by about 650 organizations.  And every time we connect to an HTTPS web server or exchange email encrypted by TLS, we implicitly trust every one of those certificate authorities because, think about it, we've got these, as we've talked on this podcast, a huge block of certificate authorities we trust.  When we receive a certificate claiming the identity of a server we want to connect to, it is signed by one, any one, of those.  Meaning that any one of those can sign a certificate, and we will trust it.  So we are trusting all of them.



LEO:  Okay.



STEVE:  Yeah.



LEO:  Wrong way to do it, obviously.



STEVE:  I read, during the research for this, one interesting concept that I just - I haven't even had a chance to think through enough.  But the concept is a different way of structuring the system where the people having the certificates are - it turns things around.  Instead of having a multiyear expiration, you have a multiday expiration.  All of your web server certificates expire every three days.  And then you - so it's necessary for you - and this obviously would be automated in some hopefully good fashion - it's necessary for you to go out and renew, you know, you have your web server establish a trust relationship with a certificate authority and dynamically renew your certificate every other day so that you're sure you're going to get it renewed before the one you have expires.  Or renew it every day or something.



So but it's sort of a - again, I haven't had a chance to think that all the way through.  So, but it's sort of, again, I haven't had a chance to think that all the way through.  That's an interesting, completely different approach to building this trust.  Fundamentally the problem is we trust too many people.  I mean, trust is too widespread.  And there was a blog posting asking, well, do I really need to trust a certificate authority in China?



LEO:  No.



STEVE:  And I really don't think I do.  I mean, I'm not going to Chinese websites because I can't read them anyway.  So why do I have that certificate authority in my browser which is subjecting me to the danger of going to a spoofed website using a domain, a super popular domain?  Oh, and that brings up one other issue.  There was a bunch of back flak aimed at Comodo, as you can imagine.  And one of the real good criticisms was, wait a minute, you know, not all web domains are created equal.  Arguably, Live.com, Google.com, Yahoo.com, Microsoft.com, I mean, there are, in any statistical distribution, there's a relatively small set of super high-value domains, I mean, major focuses of the Internet.  And you would really think that all certificate authorities should be, like, have a database of, absolutely, bells and whistles should go off, sirens should sound, if anyone tries to register any of this set of really high-profile domains.  Why was it that some second-tier certificate authority even had the ability to issue certificates for www.google.com?  And, I mean, it really does say that this infrastructure could be hugely strengthened.



LEO:  Well, I'm glad you talked about it.  I can see why they haven't changed things.  You change something like that, it breaks a lot of things.



STEVE:  Oh, my goodness, yes.



LEO:  And who do you call for support?  So I can see why there's a lot of pressure not to change things.  But, boy, that's a mess.



STEVE:  Actually, though, it is the case that just changing that certificate expiration model, nothing else breaks if you change that.  I have to think about that some more.



LEO:  Yeah, let's - yeah.  Well, I'll tell you what, next week, feedback episode.



STEVE:  Yes.



LEO:  Guess what?  We're going to probably hear from some people who have some thoughts about that.  Maybe you get to vet Steve's idea, and maybe we'll get an A+.  GRC.com/feedback is the place to go if you have a question for Steve.  We'll answer as many as we can on the next show.  Every other show we do that.  While you're there, get that copy of SpinRite you've been holding out on.  It's well worth it.  If you have hard drives, you need SpinRite, just the best hard drive maintenance utility.  Nothing better.  GRC, Gibson Research Corporation, GRC.com.  You'll also find a lot of free stuff there, including 16KB versions of this show, transcripts of this show, full show notes going back 295 episodes, it's all there at GRC.com.



Steve, as he mentioned, is on Twitter at SGgrc.  He's also got a corporate account, @GibsonResearch.  I don't know if you do anything more on the Pads, but he's got @SGpad, as well.  Follow them all.  Follow all three.  Why not?  And, Steve, I apologize for the interruption from my son.  And we will find the missing clock.



STEVE:  That was fun.  I will talk to you next week for a Q&A.



LEO:  Thank you, Steve Gibson.  We'll see you next time on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#296

DATE:		April 14, 2011

TITLE:		Listener Feedback #115

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-296.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 296, recorded April 14, 2011:  Your questions, Steve's answers, #115.



It's time for Security Now!.  Yes, I'm back in the studio.  Steve Gibson is back in his secure fortress, his secure undisclosed location.  And we are going to discuss the latest security news, privacy news, and answer your questions, too.  Good morning, Steve.



STEVE GIBSON:  It's been such a busy week.  We have lots of news to cover.  And actually a new section added to our - in my own mind.  Our listeners wouldn't know.  But I do have an outline that I produce every week, and it's got major section headings.  And normally we have Security Updates and Security News.  I've decided, as a consequence of this week, and actually get a clue from what's been going on recently, we now need an Attacks and Breaches section.



LEO:  Holy cow.



STEVE:  Because, I mean, there was a Texas-size screw-up in Texas by Texas.  Adobe's got news.  WordPress got hacked.  And there was a third one, or a fourth one.



LEO:  I love it.



STEVE:  Oh, and Barracuda Networks, a very large networking security company, got themselves hacked when they turned off their own firewall by mistake.  So lots of interesting news this week.  And of course it's a Q&A episode, so we've got some great feedback from our listeners to share.



LEO:  Not to mention, and we're going to talk about it in just a moment, a record number of fixes from Microsoft on Patch Tuesday.



STEVE:  It is 64.  I wonder if they tried to make it 2^6.



LEO:  As long as it's not 128 next month and 256 the month after.  That could really get out of hand.



STEVE:  Yeah, but they did fix some longstanding problems that we'll talk about.  So, yes, it was a record-breaking Patch Tuesday.



LEO:  Patch Tuesday, Steve.



STEVE:  Yes, yes, yes, yes.  So this was, this most recent Tuesday, a record 'nother - we have been setting records.  And in order to keep setting records, they have to keep getting worse and worse.  And this one did.



LEO:  It's not a good record to set.



STEVE:  No, it's really not what you want.  64 known security flaws were patched.  The good news is, that persistent MHTML flaw, which we've talked about a number of times, which was being actively exploited in the wild, and which Microsoft, they took their time fixing this.  I think we missed a prior Patch Tuesday, so it's been more - it's well over a month.  And remember that this was the one where you could, if you saved a page that had scripting in it, then in a web page archive, which is an IE-only format, then this is the - MHTML stands for Mime HTML, which allows a single file to contain multiple assets of a web page, and this was where the problem was.  So the idea was that...



LEO:  It's the web archive; right?



STEVE:  Yeah, the web archive, which allows - it's Microsoft's way of bundling everything, all the different images and...



LEO:  When you save a site, it says that.  Save a site, you get a web archive.



STEVE:  Right.  You're not just saving the text, though.  You're saving all of the parts of the page in this single file.  And so they had a mistake in that which they finally fixed.  They also fixed the way that they were owned in the Pwn2Own competition.  That got fixed.  And we also referred to an SMB flaw, the Server Messaging Blocks flaw.  SMB, most of us know it as file and printer sharing.  And everyone made a lot of worry about that when this was unveiled.



I told our listeners, well, okay, it's a concern on a local network.  But firstly, most ISPs are blocking those ports, the SMB port, which is 445, preemptively because of the longstanding history of problems before Windows had a firewall.  And Windows now, for three versions, XP after SP2 and Vista and Win7 have all had firewalls that are there and on by default.  XP's original firewall was there but not turned on, as Microsoft sort of creeps forward and adds security features to their OS.  So that would have protected people.  And being behind a router keeps you being safe from incoming, unsolicited attacks over that port.



So the real problem was local networking.  If something got into a corporate or a personal network, it could use that to spread among the machines within that network.  So that's also been fixed.  In addition to 60 other things that are just your typical Windows and Office sorts of problems.  We won't go into enumerating them all because people will fast-forward.



LEO:  In the interest of fairness, I might point out that I just came in, and I have a security update from Apple, too, on all my OS X machines.  Their second update of the year came out.  They don't do it on a schedule.  But this one fixes Safari, which I imagine has to do with that Pwn2Own contest, or maybe something more, and also a number of security fixes.  Apple is not as forthright about what's going on as Microsoft is.  But you should apply that update, as well.



STEVE:  Now, I almost have an update, if we had the hot tub time machine, Leo, I'd have an update which is expected tomorrow.



LEO:  That's what we need, to go forward, not back.



STEVE:  That's right.  We could prospectively warn listeners of coming problems.



LEO:  Wouldn't that be good.



STEVE:  That would be a hot podcast, in that case.  Not that this isn't.  But...



LEO:  Here's what's going to happen tomorrow.



STEVE:  The hot tub would heat us up further.  So anyway, there will be, it's expected that Adobe will be releasing a fix for a new zero-day exploit.  And I've got to take my hat off to Adobe.  They may not be holding to this ridiculous quarterly update cycle - well, in fact they haven't from the moment they announced it.  But they really do respond quickly.  This zero-day flaw first came to surface early this week.  And immediately there was a security notification.  And just this morning they said they're working to get it fixed tomorrow.



So in our Attacks and Breaches category, this is where I put this, it affects all versions of Flash, or all current versions of Flash, across all platforms.  And we are expecting a fix on tax day.  Although I guess we get a deferral, don't we, until Monday because tax day's on a Friday, so you don't really have to have things postmarked until, what, till the 18th, I think.  But otherwise, Adobe is supposed to be getting this thing fixed.



And Brian Krebs, a well-known security blogger and researcher and author whom we've spoken of often, wrote something that I thought was interesting in his own analysis.  He said it's not clear how long attackers have been exploiting this newest Flash flaw.  But its exploitation in such a similar manner as the last flaw suggests the attackers may have a ready supply of unknown - to everybody else - unpatched security holes in Flash at their disposal.  And his point is that, essentially, this one just was slipped right in, I mean, slipstreamed, just moved right in and replaced the prior exploit which Adobe patched.  And now there was another one.  Which, and frankly, given the fact that so much code was written to create Flash prior to any real focus on security, I mean, I'm letting Adobe off the hook a little bit.  Really they're big enough...



LEO:  That's very kind of you, actually.



STEVE:  They're big enough, they really ought to have their act together more than they do because this is really causing problems, well, we know it's causing people problems because RSA lost their keys thanks to the prior one.  So, yeah, not good.



Texas.  Get a load of this.  Get a load of this.  Texas.  The state of Texas itself revealed that the personal information of 3.5 million citizens, including their names, their addresses, and their Social Security numbers...



LEO:  No.



STEVE:  ...and more has been exposed to the public.  Ars Technica summarized some of the news.  And Ars Technica wrote:  "According to Texas State Comptroller Susan Combs, the data wasn't exposed by a hacker or a group of vigilante script kiddies.  It ended up on a state-controlled public server after having been passed around between various state agencies."



LEO:  Okay, that doesn't sound good, either.  That's not good.  There's a hard drive you might want to see.



STEVE:  Oh.  "The data came from the Teacher Retirement System of Texas, the Texas Workforce Commission, and the Employees Retirement System of Texas, all of whom transferred the unencrypted data, against state policy" - but, oh, well, data is data - "between January and May of 2010."



LEO:  But now here's the best part, kids.



STEVE:  "The information was only discovered on the public server on March 31, 2011, meaning it has been available for almost a year."



LEO:  Almost a year.  Ding ding ding ding ding.  You're a winner.  The world's longest security breach.



STEVE:  Oh.  Combs said that other data, like, get this, date of birth and driver's license numbers, had also been exposed to varying degrees.  And I did go back and look at the original source documents.  And she said, well, but they were all kind of run together in a big stream.  It's like they...



LEO:  Oh, yeah, computers can't figure out. 



STEVE:  Exactly.  That's not difficult to parse out...



LEO:  Nitwits.  Nitwits.



STEVE:  ...that information.  She said, finally, "I want to reassure people" - uh-huh, good, yeah - "that the information was sealed off from any public access immediately" - after a year, no - "after the mistake was discovered and was then moved to a secure location."  Well, big deal.  Combs said in a statement, "We take information security very seriously, and this type of exposure will not happen again."



LEO:  Well, okay, thanks.  That's reassuring.



STEVE:  Until it does.



LEO:  Until it does.  Geez.  So, I mean, if a bad guy has your Social, your address, they don't really need your DOB, but now they've got that, too.



STEVE:  Oh, they've got everything.  Your name, your Social Security number, your date of birth, your address...



LEO:  Well, here's the message.  If you were in those databases, the Teacher Retirement System, the Texas Workforce Commission, the Employee Retirement System of Texas, in other words, if you work for the state of Texas, you should be very - you should be on fraud alert right now for your identify theft.



STEVE:  Yes.  I would say that's exactly the right takeaway from this is this is all the information required to perpetrate identify theft.  So people impersonating you who are, like, for example, applying for credit cards, applying for various types of accounts, the good news is those applications are generally caught by the major credit screening bureaus.  And so it would be worth...



LEO:  Well...



STEVE:  Well, but, you know, it's one thing to check is to see whether there have been applications or queries against those that were not yours, or that were not people that you were applying for accounts and credit from.



LEO:  I mean, given the incredible breach from Texas, I wouldn't count on this, but here's what Texas should do is notify all their employees and help them to protect themselves by putting fraud alerts on all of their accounts on Experian and TransMed, all three of the...



STEVE:  TransUnion...



LEO:  TransUnion, Experian, I can't remember the third one.  But anyway, no, this happened, Tech TV, they weren't sure, but they thought maybe some data had been released from the payroll system.  And they, on our behalf, went to those three credit unions and said, this is what's happened.  You have to have an excuse because credit unions don't like to do this because then they can't issue credit cards randomly.  So you have to have an excuse.  But if you say, look, this has happened, if Texas goes to those three and says that this has happened, please put fraud alerts on these accounts, they will.



STEVE:  And the nice...



LEO:  It's the least they could do.



STEVE:  And the nice thing about this, Leo, is they have all the data.  They've got the database of all the people's names and addresses and so forth.  So they can just hand this over to the credit bureau agents and say, okay, we have 3.5 million people we'd like to put fraud alerts up for.



LEO:  Experian, TransUnion, and Equifax.



STEVE:  Ah, Equifax.



LEO:  Equifax.  That's something anybody, everybody should know about.  You can go to all three of them and say, I want a fraud alert placed on my account.  Makes it very hard for you to get a loan because the people who are trying to get the loan on your behalf can't just run a credit report on you.  But it also makes it very hard for a third party with that information to get a fraudulently issued credit card.  So, very important.



STEVE:  Yeah, and I think you're able to ask for a free report at least once a year.



LEO:  Once a year.



STEVE:  Once a year, yes.



LEO:  Reporting bureaus, not credit unions, credit reporting bureaus, thank you.



STEVE:  Right.



LEO:  TransUnion, Equifax, and Experian, I think.



STEVE:  Yeah, and I did - something happened to mine a while ago where someone - it wasn't identity theft.  I can't remember, it was a credit - I lost my credit card, it got loose on the Internet through someone I purchased from who consequently had my name and address and so forth.  And someone had something sent to a different address, like to them, and that's what raised the flag.  It ended up all getting resolved and everything.  But I remember then pulling reports from the credit reporting agencies at that time, just to make sure that there had been nothing else going on.  So as a wake-up call, you can do it once a year, and it's worth just going through and seeing if there's anything that looks strange, that isn't your own activity.



LEO:  There's a website called FightIdentityTheft.com that has an explanation of how to do fraud alerts.  I am a subscriber to a company called LifeLock, which used to do this.  And the problem is that Equifax, Experian, and TransUnion don't want to do this because what they really make their money on is selling your information to companies to issue you credit cards, which they no longer can do if you have a fraud alert.  So they actually blocked LifeLock from doing this, which is unfortunate because LifeLock was just turning it on every 90 days because it expires in 90 days.



STEVE:  Ah, nice.



LEO:  And it was a great feature.  And yes, it meant when I wanted to refinance I had to jump through some extra hoops so that the loan office could get my information.  I did not mind that.



STEVE:  Yeah, but so what, compared to the extra security.



LEO:  So what, yeah.  I wish I could have a permanent fraud alert because I don't want credit card offers in the mail anyway.



STEVE:  Yeah, that ought to be done.



LEO:  Terrible.  Yeah, it should be automatic.



STEVE:  So, WordPress, on our list of a very busy hack week.  The WordPress hosting company, which is - I think it's Automattic with two T's.  The first time I saw it, I thought that was a typo.



LEO:  Because it's Matt Mullenweg's company.  He's Matt, get it, Automattic.



STEVE:  Yup.  And in fact I have a quote from him, in Matt's own blog, the founder of WordPress.  He said:  "Tough note to communicate today:  Automattic" - with two T's - "had a low-level (root) break-in..."



LEO:  Whoops.  Whoa.



STEVE:  Yeah, "...to several of our servers, and potentially anything on those servers could have been revealed.  We have been diligently reviewing logs and records about the break-in to determine the extent of the information exposed, and re-securing avenues used to gain access.  We presume our source code was exposed and copied.  While much of our code is Open Source, there are sensitive bits of our and our partners' code.  Beyond that, however, it appears information disclosed was limited. 



"Based on what we've found, we don't have any specific suggestions for our users beyond reiterating these security fundamentals," which are coming from Matt, but they will be very familiar to our listeners.  "Use a strong password, meaning something random with numbers and punctuation.  Use different passwords for different sites.  If you have used the same password on different sites, switch it to something more secure.  Tools like 1Password, LastPass, and KeePass make it easy to keep track of different unique logins.



"Our investigation into this matter is ongoing and will take time to complete.  As I said [before], we've taken 

comprehensive steps to prevent an incident like this from occurring again.  If you have any questions or concerns, please leave a comment below or contact our support."  So it is, I mean, the refrain we always hear is, oh, well...



LEO:  Never happen again.



STEVE:  Yeah, we're really sorry, but we learned our lesson, and it's never going to happen again.  It's like, well, yeah, okay.  I hope that's true.



LEO:  Wouldn't it be nice if companies, states, government agencies would learn the lesson from the other guy instead of letting it have to happen to them.



STEVE:  To them, yes.  Yes.



LEO:  Geez.



STEVE:  And finally, Barracuda Networks, which may be a name not known to our listeners, it's not like Cisco or Netgear or D-Link, because it's a big iron company.  These are the guys, they produce - and sort of the focus of this is something called a WAF, a Web Application Firewall, which is used in datacenters and by companies, larger companies that are able to afford a very expensive, multiple thousands of dollars, like $15,000 are what these things typically cost, so-called "big iron" machine.  A blog posting from Michael Perone, whose title is EVP and CMO - well, now, EVP's got to be executive vice president.  What's a CMO?



LEO:  Probably, usually chief marketing officer, which always makes me nervous.



STEVE:  Okay.  I was hoping for something a little more technical than that.



LEO:  Chief marketing officer means the PR machine is in full force.



STEVE:  Yeah, okay.  So what happened was, what was compromised was names and email addresses, much as was the case with the hack last week.



LEO:  Oh, last week.



STEVE:  Yeah, that was...



LEO:  Who was that?



STEVE:  Somebody, I'm blanking on the name.



LEO:  Epsilon.



STEVE:  Epsilon, yes.  He wrote that their databases contained just one-way cryptographic hashes of salted passwords, which we'll be coming back to later in this podcast.  All active passwords for applications remain secure.  And so, quoting him, he said:  "So, the bad news is that we made a mistake.  The Barracuda Web Application Firewall" - I mean, and so what's a little bizarre is that the equipment they invented and produce and sell is supposed to stop what happened.  This was an SQL injection.  So "The Barracuda Web Application Firewall..."



LEO:  This is really embarrassing, then.



STEVE:  It is, "...in front of the Barracuda Networks website was unintentionally placed in passive monitoring mode..."



LEO:  Oh, somebody's in trouble.



STEVE:  "...and was offline through a maintenance window that started Friday night (April 8, 2011) after close of business Pacific time.  Starting Saturday night at approximately 5:00 p.m. Pacific time, an automated script began crawling our website [searching for] unvalidated parameters."



LEO:  That just shows you, it doesn't take long.



STEVE:  And this is what - he has some nice conclusions here.  "After approximately two hours of nonstop attempts, the script [crawling our site] discovered an SQL injection vulnerability in a simple PHP script that serves up customer reference case studies by vertical market."  So this was an obscure little script somewhere that wasn't, like, mainstream.  It wasn't the big deal.  It was just off on the sidelines.  But of course that gave it a foothold.



"As with many ancillary scripts common to websites, this customer case study database shared the SQL database used for marketing programs..."



LEO:  And there's the problem.



STEVE:  "...which contained names and email addresses of leads, channel partners, and some Barracuda Networks employees.  The attack utilized one IP address initially to do reconnaissance and was joined by another IP address about three hours later.  We have logs of all the attack activity, and we believe we now fully understand the scope of the attack.  This latest incident brings home some key reminders for us, including that:  One, you can't leave a Web site exposed nowadays for even a day (or less).  Two, code vulnerabilities can happen in places far away from the data you're trying to protect.  And, three, you can't be complacent about coding practices, operations, or even the lack of private data on your site, even when you have Web Application Firewall technology deployed."



LEO:  That's amazing.



STEVE:  Yeah.



LEO:  That is really - but, you know what, I think Barracuda responded quite well.  As they should, they're a security company.



STEVE:  And they got kudos within the security community.  Your point is exactly right, Leo.  They got - some analysis said congratulations on the way you came forward.  As opposed to, for example, RSA, who is also a high-profile security company, but they angered everyone for several weeks.



LEO:  Right.  They obfuscated it.  They kind of were so - they felt so bad that they didn't respond appropriately.



STEVE:  Right.



LEO:  And of course you feel bad.  It's very embarrassing.  But this also shows a couple of things that could be good lessons.  One is that PHP scripts are all over the place, and if it gets run at any time, it's enough leverage for a hacker to get in.  And I think, to their credit, it sounds like they had multiple databases, and their most secure databases - this was just the marketing database.



STEVE:  Right.



LEO:  You want to separate databases, obviously.  Because once you get access to a database, a MySQL database, you've got it.



STEVE:  Yes, you're able to tell it to enumerate its own tables, as we talked about back in our SQL injection episode.  But in security news, I have great news.



LEO:  Oh, thank you.



STEVE:  Apple is adding the do-not-track browser header to the OS, I can't remember, am I supposed to say 10 or X?



LEO:  10.



STEVE:  To OS X's Lion release.



LEO:  So that'll be, oh, that's good, that's 10.7.  Okay, good.



STEVE:  Yes.  It's in the next - it's currently in the developer release, the pre-release betas.  The do-not-track header option has been added, is being added to Safari.  So that means IE 9, Firefox 4, and the next Safari will all have it.



LEO:  Well, pressure's on Chrome, now, boy.



STEVE:  It really is.  And I'm glad.



LEO:  Well, they'll do it.  They'll do it.



STEVE:  Yes, yeah.  Okay.  And we're going to talk about France a little bit, Leo, because you and I did talk about this during Sunday's This Week in Tech podcast that I joined you and John Dvorak and...



LEO:  By the way, thank you for being on with Jerry and John, Jerry Pournelle.  It was our gray-hair, our periodic gray-hair episode.  You can't be on unless you have gray hair or no hair.



STEVE:  Or aging gray matter.



LEO:  Or aging gray matter.  And every time we do it, one or two people say, I don't want to hear old farts.  But almost invariably, people are grateful because of the depth of knowledge, the context, the history that everybody shares on that show.



STEVE:  Oh, we were talking about ham radio and, I mean, all kinds of wacky things that, you know.



LEO:  It's really fun to do that.  And we do it every few months.  And thank you for being a part of it because...



STEVE:  It was great.



LEO:  ...it was really great.  I really loved it.



STEVE:  So France has done something which I'm still holding back judgment.  What they've said is that part of their data retention laws, which they're in the process of getting ready to start enacting and enforcing - and we know that data retention is already controversial because it puts probably an impossible burden on ISPs, the idea being that people who provide end-users connectivity to the Internet need to keep everything that their customers do.  Well, that's easy for some legislator to drop the gavel and say, yeah, that's a good idea, that sounds good, let's do that.  But, I mean, look at the bandwidth we have now and the amount of data that would have to be aggregated across - at that bandwidth across some length of time.  I mean, it's just, I mean, there is just no technology for it today.



I mean, you can imagine at some point in the future this happens.  There will be data aggregating service providers that will create big RAID arrays that timestamp when things happen.  The problem ultimately could be solved, although at an expense that would never be low.  It just seems like a bad idea.  You could step back from it and say, okay, let's just then record the IP addresses, or the email headers but not the content, or there are things you could do to back away from it that make it substantially more feasible to do this.



But what France has said is they want the usernames and passwords and basically login information to be made available by people who provide services, like Google and eBay and so forth.  And those companies are fighting back.  And the issue that is interesting is that, as our listeners know, no responsible providers store passwords any longer.  That's old school.  If you see something that says, oh, your password is limited to 16 characters, as we've discussed, that's a warning flag that they've got a 16-character field in their SQL database, and there's spiders trying to crawl around their site, trying to get into it right now.



You don't want your password saved.  You want a hash, and technically, yes, a salted hash of the password.  That is to say, you want a one-way cryptographic function between what you enter and what get stored permanently so that, when you are asked to log in, you provide that again, and all your provider, Google or eBay or whomever, all they're doing is they're doing the same thing to the new password you put in that they did to the last password you put in, the valid one, and seeing if the result of the hashes matches up.  And if so, that's cryptographically sure that you entered the same thing.  In fact, because a hash is a lossy operation, there are other things that technically could hash to the same thing.  But the hash is so large, typically minimum of 128 bits and often now 256, that the chance of a collision is just vanishingly small.



So anyway, I'm hoping that the French legislation said usernames and passwords just because that's the way they think of it from the user end.  And once the legislators get some additional education about what all this means, they'll go, oh, well, I guess what we really just need is - and I'm not sure what it is they wanted.  I mean, getting usernames and passwords potentially allows people with that information to impersonate those users, which is nothing that you should allow data retention laws to facilitate.



LEO:  But that's what they wanted.  Remember, it's law enforcement that's asking for this.  What would they like?  Well, they'd like to be able to log in as Tony Soprano, into his email system, until he has the brains to change his password, i.e., forever.  I think that's what they wanted.  I wouldn't hold out hope for them.



STEVE:  My mind wasn't even believing that that's what they could want.



LEO:  Of course that's what they want.  They want as much as they can get.  Because remember, law enforcement's always thinking, well, it's bad guys we're going to do this to.  But as civil libertarians what we're thinking about is, well, who defines who the bad guys are?  And today it's crooks, tomorrow it's political dissidents, somebody who doesn't agree with the government.



STEVE:  So I have on my note here, or on my news, the question of Dropbox authentication and whether it's insecure by design.  There's a blog posting that was made by someone who was just doing his own little forensic analysis of what kind of debris is left behind by the use of these kinds of remote storage systems.  I had it here, and I wanted to mention that I know about the blog post.  I'm going to cover it in detail next week because it was one of the things that I was going to do if I had time, and I just ran out of time.  So I will cover this.  I want to let everyone who's been sending me email and tweets about it that I do know about this posting, and I will figure out what this guy did and what it means and tell all of our listeners next week.



LEO:  Thank you.



STEVE:  In my miscellaneous section, I wanted to note that Amazon has done something interesting.  They've dropped the price of the Kindle to $114, if you allow...



LEO:  With ads, yes.



STEVE:  Exactly.  But I saw - TechCrunch mentioned it, and then mentioned, well, that they didn't think that was cheap enough.  And I sort of agree.  If they could get...



LEO:  It's 25 bucks.  That's not a whole lot of savings.



STEVE:  Right.  If they could get down under a hundred, if they could get into the $99...



LEO:  $80.  And you see ads.  You don't see ads in the books.  You only see ads on the front page and when you're browsing.



STEVE:  Well, I was just going to say that it's less intrusive than I thought.  So I wanted to say that, as I understand it, there's some sort of a screensaver.  Their screensaver I guess is customizable.  And only on the home page are there ads.  But you're not being accosted by them, like when you flip the pages of your book and suddenly there's an ad there.



LEO:  That would be more not - that would be unacceptable.



STEVE:  Yeah, that would be.



LEO:  This seems to be not so bad.



STEVE:  I think it's not so bad.



LEO:  I wish it were more than 25.  But maybe that's because it's not so bad.  They can't really expect to make more than 25 bucks per user.  But isn't, after all, isn't the profit in the Kindle in the books, not in the Kindle itself?



STEVE:  I really think so, Leo.  When I was thinking about this, it occurred to me that, wow, when I look at all the money that they've sucked out of me because I have Kindles, it's like, wow, I mean, they're making much more money on me selling me bits than they are the pieces of plastic.



LEO:  Just imagine if they could manage to - I don't mind these ads - if they could manage to subsidize to the point where they give it away.  For instance, there's a lot of people with an iPad or an iPhone who say, well, I could read my books on my iPad and iPhone.  But now they can get a Kindle, they can add that because there's times you want a Kindle and bright light and so forth.  And they're going to buy that many more books.  I mean, I'm sure Amazon's doing these calculations.  They know their business.



STEVE:  Yup.  So I just wanted to let our listeners know that, with a little bit of...



LEO:  Tempting.



STEVE:  It is, $114.



LEO:  All right, I'm going to order one.  I'll tell you how bad it is.  But the thing is, you've got to think it's going to be $85 in about six months.



STEVE:  Yeah.  Also, I've mentioned to you, I think probably offline, Leo, that there is, in the current build of the iPad - oh, and by the way, there was just a new iOS, minutes ago, came out from Apple.



LEO:  You're kidding.



STEVE:  4.3.2 is now available for the Phone, the Pad, and the iPod Touch.



LEO:  Must be a bug fix.



STEVE:  Yes, it's just bugs and security.  It doesn't appear to have any new features.



LEO:  You know what's interesting, Steve, though, is they're releasing these updates - this is the second update in a couple of months.  They're releasing these updates much more quickly than they used to.  Clearly these portable platforms are now in exactly the same position that the desktops have been for a long time, which they need to be updated frequently to prevent security flaws. 



STEVE:  Yup.  I think that's very much the case.  I enabled something that I mentioned to you called, well, I wrote down "developer gestures."  I don't think that...



LEO:  Yes.  Yeah, because...



STEVE:  But I don't think that would be, I mean, it is at the moment for developers.  But what I wanted to mention was that I was experimenting with cloning one iPad to another, that is, making a backup of my main iPad after I got all the apps organized and arranged and set up in subfolders.  And then I didn't want to go through all that again because it's a pain in the butt to do that.  So I erased one iPad, the second one, and then told it it was the first one and restored the first one's image, essentially, to the second one, just to see that that all worked.  And it does.  So it's a very nice thing to do.  You lose some passwords, like your WiFi passwords and things you have to reenter again.



LEO:  That's appropriate.  You also lose...



STEVE:  Makes sense.



LEO:  I found the folders kind of disappear, so you have to kind of rearrange stuff.



STEVE:  Well, mine didn't.  I was able to...



LEO:  Oh, you were lucky, okay.



STEVE:  ...clone the entire folder tree, which is what - that was really my goal.  What I lost was, temporarily, I got it back, those gestures.  And so what -  and so my point was that you know something is wonderful and, like, the right thing, when, after you lose it...



LEO:  You miss it.



STEVE:  You can't live without it.  The gesture that I love most is just you just put all your fingers on the pad and squeeze.  You sort of - as if you're squeezing the current app, and that's a replacement for the home button.  And...



LEO:  It's so sweet.  It's so sweet, yeah.



STEVE:  Oh.  It is just - it's the right thing.  And it's also nice you're able to put your fingers on and lift up in order to do the equivalent of double-clicking the home button in order to get to the little strip of things you used recently and also the brightness setting and so forth.  But I just wanted to mention the presence of those gestures.  You need to use the Xcode.  And when I talked to you about it before, maybe it was during the podcast, I don't remember, I bought it, I bought Xcode 4.something or other, and it just got updated for $5.  But it turns out that the free Xcode 3 works, too; works also.



LEO:  Oh, that's good.  If you have the SDK on it.



STEVE:  Yes.



LEO:  You have to have the iOS SDK.  So it's not free because it's 99 bucks because you have to have the iOS SDK.  I think that's the case.



STEVE:  Okay.  What I did learn was that Xcode v3, which you can apparently get for free...



LEO:  Right, connect.apple.com.  You have to have a developer account.  But I think you have to also have an iOS - check me, chatroom, if I'm wrong on this.  I thought you had to have an iOS developer's license, a $99 developer's license, to get the SDK.  Oh, no, it does include the SDK.  Never mind.  You're right.  Sorry.  Forget I said anything.  Zipping it up.  Chatroom confirms.



STEVE:  So I don't have one, and it worked for me.  And let me just say, oh, it is the best thing.  Once you start just squeezing the apps to make them go away, when you want to do the equivalent of a home button, you can't live without it.



LEO:  So you have this on your - if you have a Mac, you have Xcode 3 on your disk, on your install disk.



STEVE:  Yes, it is.  You're right, it's an optional install when you install it, or you can add it later on.  So yes,  yes, yes.  I just wanted to bring it to our listeners' attention.  And while going through email today, this didn't quite rate a Q&A slot.  Jared in Western Australia says he wondered about Leo and his iPad.  Now, I didn't know what the context of this was.  But he says, "You guys on MacBreak are nutters.  Did Leo actually take his iPad 2 everywhere, even to the bathroom on a cruise ship?  I couldn't believe what I heard.  Next thing would be Leo taking his iPad to bed with him.  Sheesh."



LEO:  I do.  Don't you take it to bed with you?



STEVE:  That's where mine - I have got one in bed.



LEO:  What are you talking about?  Of course you take it to bed with you.



STEVE:  "Now, that's an Apple fanatic.  Maybe you never heard of something, it's called 'privacy.'"  It's like, okay, well.  So I wanted to just acknowledge that I sleep with my iPad.



LEO:  I got in bed last night, after getting back from Las Vegas, Jennifer was in bed, and I had to slide her iPad over to make room.  So even my wife goes to bed with her iPad.



STEVE:  And this morning, before I got out of bed I grabbed it and read some news for a while.



LEO:  That's the whole point is you take it with you every- in fact, Steve Jobs is very famous, when he was first approached about making tablets, he said, "I don't want to make a bathroom device."  But he did.  'Nuff said.  We won't belabor the point.



STEVE:  And I had promised a review of iPad 2.  And I will only say this.  I agree with your appraisal, Leo, that anyone with an iPad 1 need not get an iPad 2.  My takeaway is that the only thing they did, and it is brilliant, is they beveled the back side so that it comes to the flat front.  And bizarre as that is, I mean, that's all they did.  But when you hold it, you swear to god it is, like, a third of the thickness.



LEO:  I know.  It's tricksy.  I know.  They're very tricksy. 



STEVE:  It's bizarre.  And I, like, I've turned it over so that I'm holding it, looking at the back of it.  And sure enough, you don't get that same feeling.  Now it seems like it's the same thickness.  But when you hold it with that bevel, just the way your fingers work on the edges, it's fantastic.



LEO:  They did the same thing with their laptops, the MacBook Air, to give it the same apparent thinness.  It's very clever.  They are smart, aren't they.



STEVE:  Yeah.  I mean, it was simple to do; and, oh, what a difference in holding it.



LEO:  Well, it's funny because at NAB I saw a number of iPad 1s.  And they looked so thick.



STEVE:  They look boxy, they do, they look boxy.



LEO:  Now, my conspiracy theory is, because Apple did this with the MacBook Air years ago, like two or three years ago, so they knew about it.  They intentionally released the iPad 1 boxy so that they'd have something to do with iPad 2.  I'm sure of it.  They knew how to do this.  They could have done this.



STEVE:  Well, we had a listener, Evan Drosky, who said - this ties into backups - "SpinRite saves me from my backup wakeup call.  Steve, I've been listening to Security Now! for a few years and appreciate the job you and Leo are doing and can't wait for Wednesday afternoon" - or in this case Thursday - "to roll around for the next never-too-long episode."  We may be testing that today.  He says:  "Okay, truth time.  I haven't been backing up my system.  I usually transfer my stuff from one drive to a larger one every so often as I need space, and keep one step ahead of the inevitable disaster.  I'm sure you know where this is going.  This time I waited too long."



LEO:  Oh, boy.



STEVE:  "It started when I was ripping an unprotected DVD I have and was shocked to see that Windows Media Player was having problems playing back the file I had just created.  Luckily I already had SpinRite, so I rebooted into SpinRite, ran it at Level 2.  It found a few bad sectors right away and fixed them.  No other problems were detected with the rest of the drive.  I rebooted into Windows and Chkdsk came up to fix the file system.  Okay, fine.  Everything looked okay, and I went about my normal computing again.  A few days later I rebooted my system and Chkdsk came up again for the drive and fixed some problems again."



LEO:  Bad sign.



STEVE:  Uh-huh.  And he says:  "Hmm, not good.  I rebooted into SpinRite the next morning, set Level 2 on its way, and left for work.  When I came home, I was shocked at what I saw.  This time the first two lines of SpinRite's graphical status screen were completely filled with red U's.  This was bad.  The detailed log told me that every 50 to 100,000 sectors or so, there was a bad one that was only partially recovered.



"Four days later, and my 250GB drive was finished.  Looking at the results, everywhere there was data on the drive, there were bad sectors only partially recovered.  It looks like every file on there could have been affected.  I restarted into Windows and started copying my recovered data onto a newly purchased 1TB drive.  Post more use of SpinRite, there was only one file that Windows could not copy."  Oh, I see.  So he kept using SpinRite and working on getting his data back, sort of like bouncing back and forth between Windows and SpinRite.  He says, "And I can easily recreate that one ISO file myself.



"A preliminary look at my data shows that SpinRite has recovered everything off that old drive that was trying everything it could not to give up my stuff.  I want to thank you for such a well-written and tenacious program.  It's well worth the price to me for recovering 10-plus years' worth of my digital life.  My next project will be to build myself a file server, RAID and all, for image-based system backups - one step closer to the 3-2-1 process that Leo endorses.  I can now say I'm a backup convert.  Thank you again."  And not a moment too soon, either.



LEO:  No kidding.  He was very lucky, yeah.



STEVE:  Yeah.  And so I just, I did want to make a comment that hard drives should never show any bad sectors.  So he should have taken more warning when he ran SpinRite that first time and saw some red U's.  That says the drive is in trouble.  He got four more days of apparent bonus life out of it before it really began collapsing on him.  And then it's a good thing that he was able to get everything he could off.  But I would consider that really pushing one's luck.  So if you do see the red unrecoverable sectors, SpinRite is telling you, well, I've done what you told me to, but don't count on this drive for much longer.



LEO:  So "unrecoverable" means I can't read it, and I can't save it.  I can't save that sector.



STEVE:  Exactly.  And SpinRite doesn't make any conclusions.  It doesn't rewrite it.  It leaves it alone because there's - and this is a good thing because clearly there are tricks like getting the drive cooler, sticking it in your refrigerator for a while and then trying it, that do, often, surprisingly, allow data to get recovered that couldn't be otherwise.



LEO:  But you do that once, and then you get a new drive.



STEVE:  Yeah.  It's a lot of work.



LEO:  Yeah.  And it's not going to work twice.



STEVE:  Right.



LEO:  You should get the data and get out.



STEVE:  Exactly.



LEO:  Thank your lucky stars if you do get it.  All right, are you ready, Steve?



STEVE:  You betcha.



LEO:  Q&A time.  Of course did I close the questions?  I probably did.  You know what I do, as we're doing this show, I immediately get them into the wiki because I want to make sure that people can read the show notes and even read the questions as we go.  In fact, I don't know if I mention this enough, but we have a really great wiki, wiki.twit.tv.  Because it's a wiki, we use our community to keep it up to date, and people are always putting information in there.  Many of the shows have their own kind of people doing the show notes for them.



But since you send me - you're the only host that does this, Steve - complete show notes with all the detail and links, I just, because I have them, I do a little grep on it to clean it up and wikify it.  And then I put it into - let me turn this on.  I put it into the wiki, wiki.twit.tv slash, well, it's a long URL.  If you just go to wiki.twit.tv, click the Security Now! link, you'll see all the notes are in there as we go.



So Question #1, right from the wiki, it's Beau via Twitter, so it's a short question.  Steve, is there a do-not-track option in Chrome?



STEVE:  There is not at the moment.  And we mentioned this earlier in the show, that the good news is the notion of - okay, now, he says do-not-track option.  And what we're talking about is a do-not-track header, where right now...



LEO:  Chrome has an extension to do this.



STEVE:  Well, it has, and that's what I'll address in a second.



LEO:  From Google, yeah.



STEVE:  Yeah, but it's different.  So what Firefox does is, with v4, or if you're using 3, as I still am, waiting for 4 to kind of settle down a little bit, using NoScript, NoScript has converted its do-not-track header over to what has now become the standard, which is just DNT: 1, which is not the default at any of the browsers.  But in IE9 and in Firefox 4, or 3 if you use NoScript, and we believe now in the next release of Safari, the Safari that'll be part of the OS X Lion release, that will be available.  That adds this header which requests not to be tracked, which is different from other technology which is available, for example, turning off third-party cookies, blocking persistent objects, using IE's tracking protection lists.  There are other technologies.



What Chrome has is an add-on which saves your preferences.  So the idea is, you opt-out on a advertiser-by-advertiser basis, or there are sites that we've talked about where they'll use scripting in order to visit all the sites and set the opt-out cookies for you.  Then what Chrome allows, what this Chrome add-on allows you to do is to freeze those, essentially to not worry about those requests, those individual requests not to be tracked.  Don't have to worry about them being lose somehow or reset.  So I'm not nearly as excited about that as I am about just having our browsers say "do not track."



And everyone comes back, well, not everyone, but they say, wait a minute, that's optional.  I mean, people have to agree to abide by it.  And it's like, well, today it is.  The direct advertising groups, the societies are trying to decide whether - how they feel about this, whether they're going to adopt it or not.  They haven't said yet one way or another.  But there's a sense that, if they don't go along with this voluntarily, that it'll be imposed on them legislatively.  So I just think, given that the major browsers are supporting it, we now have a standard, thankfully.  It'd be crazy for Chrome not to add this.  So it doesn't do it yet, in the same way that the other ones do; but I think we'll have it before long.



LEO:  Yeah.  And just by virtue of the fact that everybody but Chrome is doing it in the browser, it's just going to not only have it happen, but it'll also mean that the federal government can then pass a law, if they need to.  I mean, there'll be a lot more support for the notion of do-not-track with the system working.  



STEVE:  Yes, exactly.



LEO:  So it's just a matter, I mean, I'm surprised - Google did introduce, may have been the first to introduce this plug-in and this concept.  It was either Google or Firefox.  Google followed very quickly on.  But it's a plug-in, it's not in the browser.



STEVE:  Right.



LEO:  Bruce Powers in New Jersey wonders about CAs, Certificate Authorities:  I see that Comodo has another bad CA event.  Do you remove authorities from your browser, Steve?  What disadvantage is there from removing one I don't know or use?



STEVE:  Actually Comodo did have two other problems, which they disclosed at around the same time as the bad one that we discussed before, although those were breaches of two additional subsidiaries of theirs.  The breach occurred, but certificates were not issued.  So it didn't create as big an issue.  So I just did want - I wanted to cover that.  I don't remove CA certificates, certificate authority root certificates from my browser.  But I kind of think that I should.  I mean, I think it's worth doing, depending upon who you are.  I would like to see better technology for managing our SSL connections.  And we've discussed this from time to time.



For example, it would be nice if our browsers cached the SSL connection details that we make, for example, when we're really connected to Google or to Microsoft or wherever.  That is to say, we've talked about how there's actually a certificate chain.  And every certificate has a unique serial number.  So even fraudulently obtained certificates will have a different serial number.  The only way to spoof a serial number would be to get access to the root CA's private key, and so far that hasn't happened in the case of certificate authorities.  We know that it happened, for example, it's one of the things that Stuxnet did in order to spoof its driver certificates.  They did get the private keys of two companies that were hardware manufacturers that was being used to sign their drivers.  So it's not impossible for private keys to get loose.  It hasn't happened yet in the case of an SSL provider.



But the idea is that a fraudulent certificate could be used to impersonate a website, for example, Yahoo! was one that was targeted immediately by whoever it was believed to be in Iran who used the compromised third party to issue themselves certificates for these high-profile websites.  But if your browser remembered the certificate path with serial numbers that it normally uses to go to Yahoo!, a change in that would really be a red flag.  It's not necessarily the case that that represents a problem because, for example, when I renew my certificate, when GRC's certificate expires, as it does every two or three years, I'm forced to get a new certificate, which I install on my server before, hopefully before the expiration of the prior one.  Well, that will have a different serial number.  So that would raise a red flag if such a system as I'm describing existed.



But people could then check to see, like, does this look like it's still GRC.com?  What IP am I connected to?  Is there any - or look at the certificate chain carefully.  Are there any unknown intermediate certificate authorities in there?  I mean, like, essentially do a sanity check to see whether something has changed because change would be an indication of there being a problem, and it's not something that is spoofable.  Alternatively, you remove certificate authorities that you just don't trust, like the unfortunately often maligned, unfairly maligned, I should say, Hong Kong Post Office.  I hope it's unfair.



LEO:  I'm sure it is.  We bring it up a lot.



STEVE:  We do.  They're my favorite whipping boy.  So have I ever visited a website that was over SSL, using a certificate signed by the Hong Kong Post Office?  I don't think I probably ever have in my life.  I mean, I don't speak Chinese.  If I go to a Chinese site, I can't read the page that comes up.  And the flipside of being spoofed by a certificate of an English-language site signed by the Hong Kong Post Office seems higher than what I would lose if I didn't have that certificate.  So I could see some advantage to removing certificates that just really seem like they're not bringing me more value than they are bringing me the possibility of them being used to exploit the trust that they imply.



LEO:  I guess the problem is you don't know - removing a root certificate doesn't just remove the Hong Kong Post Office.  It removes everything that uses that root CA to certify itself.



STEVE:  Precisely.



LEO:  And you can't - is there a way you could tell where the - no, because it's just as it comes in.



STEVE:  Exactly.  So that, yeah, there isn't any way.



LEO:  So if, for instance, Google used the Hong Kong Post Office as its certificate - the only thing you would get is this certificate isn't legit; right?



STEVE:  Right, right.  You would get the notice saying that this certificate is signed by a party whom you do not trust.  That is, you haven't said you trust it because that chain is not anchored by a certificate that you've implicitly trusted because you haven't explicitly deleted it.  So you get that notice.  And then the behavior from that point varies.  And it's been getting tighter, I've noticed.  It used to be that you could click through those warnings and say, yes, okay, fine, I trust them anyway.  That's one thing that's probably a good change we're seeing is browsers are really beginning to fight back more and saying, eh, we're not going to let you go there at all, if you don't trust these people.



LEO:  Oh, so that's interesting.  So you might not be able to get to a site.  But at least you'd know, you'd probably have some idea why.



STEVE:  Oh, yeah.  You could definitely look at the certificate and see that it was signed by the Hong Kong Post Office and go, oh, that's right, I deleted that.



LEO:  Yeah, yeah.  So go ahead.



STEVE:  I mean, that's what I think, too.  I think we could use some nice certificate authority management tools.  The tool that I mentioned, the EFF runs this thing, the EFF Observatory.  I've got it on my notes to spend some time and look into that, probably do a podcast on it because the sense I get is that they may have an answer to that question, Leo, who's signed by the Hong Kong Post Office, which they would have obtained by watching Internet traffic over a long period of time.  And I think what they're doing is building a record of certificate chains in use on the Internet. 



LEO:  Yeah, that's what it looks like, doesn't it.  That's great.  One more reason to love the EFF.



STEVE:  Yeah, they're doing a great job.



LEO:  If you use this, donate to them.  I donate, we make a regular monthly donation [indiscernible].



STEVE:  And they take bitcoin.  They take bitcoin, Leo.



LEO:  They take bitcoin, but I send them American greenbacks.



STEVE:  Oh, okay.



LEO:  I'll send them bitcoin, too.



STEVE:  My machine just generates bitcoin for me, so I send it off.



LEO:  Yeah, we know.  A lot of it, apparently.  You have friends at Bitcoin.  No, just teasing.



STEVE:  There are no friends.



LEO:  There are no friends because there is nobody home.



STEVE:  No one to love there.



LEO:  No one to love.  Moving along, Question #3, I think.  Let me just make sure.  Yes.  Lisa Matias in San Jose says, why do you like Java on Android?  I heard you, Steve, and Leo speaking favorably of Android, the Google operating system for handsets, and its openness.  But it seems to me, as a third-party developer, Android OS is the most closed system since it restricts me to only develop "glorified web apps" - Java, JavaScript, Flash apps.  Well, I'll speak to that in a second.



It also seems strange that whenever Google needs a new type of processor-intensive app, as the Android guardians, they create extensions to their Java VM to support it.  This is not an option that third-party developers have.  Android apps are restricted to the virtual machine.  In contrast, only iOS allows me to create native binary apps using the same API, libraries, and SDK that Apple uses for their own native apps that come bundled with it.  Apple apps are not restricted to any VM space since they run natively, but are restricted in the app store.  Note that, like Android, you could still develop and install your "glorified web apps" - they're not.  I'm sorry, I can't let her say that twice.  A web app is JavaScript, HTML, and CSS.  Java, I think people often confuse Java with JavaScript, is a full-blown programming language.  You have full access...



STEVE:  Beautiful language.



LEO:  It's a beautiful language.  It is not a "glorified web app" by any means.  It's run in native code, well, not native, but it's code running on your phone, just like a regular program, just like all of the other Google programs.



Steve could easily write his own iOS apps in assembler - which is true - and publish them in the - I don't - I guess it's true.  You could certainly write assembler code in Xcode for a desktop.  I don't know if they have an assembler for the ARM A5.



STEVE:  I doubt that I would pass their API tester, which only allows you to use special things.



LEO:  Yeah.  I do not think that you can, in fact, write A5 for assembler.



STEVE:  Right.



LEO:  So anyway, Steve could easily write his own iOS apps in assembler and publish them in the iTunes app store, an option Steve does not have with Android.  So could you guys please explain why you like Android OS when it seems to be nothing more than a glorified web browser, like Google's other Chrome OS.  Sincerely, Lisa.  Steve?  Do you want me to yell, or should I?  You're not going to yell.  You're going to be very nice.



STEVE:  Well, it sounds a little maybe that...



LEO:  I think she doesn't understand stuff.



STEVE:  Well, and maybe a little evangelical.  I mean, she seems to be very pro iOS and very anti Android.  And so I was thinking back, well, okay, I mean, I really don't have an opinion one way or the other that she sort of seems to think I have.  I mean, I'm really sort of an iOS fan boy, if anything.



LEO:  She's referring to me, really, more than you.



STEVE:  Well, and what I think it is, I think she got a little confused because what I was excited about was just the concept of Amazon's Android VM that allows you to test Android apps in the web browser.  And that is something that we talked about in the last week or two, which I think was very cool, the idea that you could do a 30-minute test drive of an app, play with it, see how you like it.  I mean, it's one of the things that really annoys me about iOS is there's no way to try out an app.  They're not very expensive.  But I've got a lot of them that I wish I hadn't bought.  But I don't know that until I buy it.



LEO:  Right.  So let me just address the technical issues, which is that Java, the way Java works, and it's a very respected language, works very well, is it does, it's write once, run many, because every platform that you run a Java program on does in fact have a virtual machine.  So Google...



STEVE:  Yes, Java compiles down to an intermediate language, which you then have an interpreter, essentially, to interpret Java bytecode into the native platform.  Which gives you this tremendous portability.



LEO:  Right.  And that's - many phone systems, BlackBerry uses this, as well, many phone systems use a Java virtual machine and Java for several reasons.  There is a security value to it because all the apps are running within the virtual machine, and they're protected from the hardware.  It's the same reason Apple, I guarantee you, does not let you run assembly language code on the iPhone.  You're always running, in a sense, you're always running within an environment...



STEVE:  Containment.



LEO:  Containment to protect you on the iPhone or on the Android phone.  So that is not the - when people say Android is not open, that is not where the discussion lies.  These are not web apps.  They're genuine first-class apps.  You have access to the same tools that Google has and uses.  And many developers do in fact like writing Java code for platforms.  So I don't think that is an issue.



STEVE:  Yeah, and when Java - I guess it was on Sunday we were talking about Gosling.



LEO:  He's now working for Google, the guy who wrote Java.



STEVE:  Yeah.  I mean, it is a state-of-the-art, very modern, tremendous little language.



LEO:  And if you feel like it, you can write Android code in other languages, including Python, C, or C++.  They just have little plugs, little bridges that make it run.  Still within the VM, which is the tool that Google promotes, is an amazing tool that does allow you to write in other languages and so forth.  So I think that any complaint that it is a web app is not accurate.  Nor does Apple have some sort of advantage by not using a Java VM.  I don't think so.



STEVE:  Well, and market forces and popularity is showing us that Android's OS is doing just fine on similar platforms, with similar processor power and similar battery life.



LEO:  Now, she says access to libraries.  I don't know if Google writes libraries that they don't release.  I don't believe that's the case, either.  Android is not fully Google's.  It is the Open Handset Alliance's.  Google does write code that they then later release into the open source.  But you can go to GitHub right now and get the full source code for the current version of Android, which is Gingerbread.  Full source code, and I presume full libraries, or it wouldn't run.  So I don't think they're secret libraries.  Can I tell you something?  Guarantee you Apple has secret libraries.  There's no doubt, because Apple can do things on the iPhone that no one else can.



STEVE:  Oh, yeah, it's a completely locked-down DRM'd platform.



LEO:  Yeah.  Now, [indiscernible] asks an important question:  Is performance on Java on Android comparable to native performance?  Yes.  Because it's hardware optimized for it.  So I don't think that you're seeing a performance hit at all.  Now, Lou, who works for Microsoft, says Android does have operating system APIs they don't publish, which is why some applications require root.  But, see, then I wouldn't - I don't think so, Lou, because then you would be able to download Gingerbread.  Well, maybe there are, so maybe Gmail and some of the proprietary apps have access to - no, because you have the source code.  I don't...



STEVE:  They'd be open, yeah, there's no way to hide that.



LEO:  If you have the code, there's no way to hide that.  There's no way to hide that.  Apple absolutely hides that.  They have many undocumented libraries.  So, sorry, Lisa, nice try.  Question #4, Dan - we could keep this conversation going.  It's so funny because I - here's the bottom line.  Why be religious about operating systems?



STEVE:  Right.



LEO:  Makes no sense.  There are pros and cons to everything.  They're just computer operating systems.  You may like or not like a company, but the company couldn't care less about you.  You can love the iPhone.  It doesn't love you back.  So why be dogmatic about it?  Everything has advantages or disadvantages.



STEVE:  I'm pretty sure my iPad loves me, Leo.



LEO:  See?  See?  Steve's smart.  It's that thin little beveled edge.  Dan Hummon - or Hummon - in Pennsylvania, on Question #4, offers a minor nitpick about our password discussion in 294:  Steve, I just wanted to drop a quick note about how passwords are stored in databases.  I totally agree with hashing and salting passwords - we just talked about that - but I think you left out an important final step.  When choosing a hash algorithm, make sure it is one that has some significant computational load 

associated with it.  Oh, this is an interesting point.



The one I personally use is bcrypt.  If there's a small, but real, computational cost to hashing one password, then if the database is compromised, brute force attacks against the entire stored database hashes are much more difficult to accomplish.  I only mention this because I know many up-and-coming web programmers are listening, and I want them to have the best possible tools available to them.  And he points us to a website, CodaHale.com, and the page there - Coda Hale is I guess a programmer, and his website has a page called "How to Safely Store a Password."  Yeah, you wouldn't use rot13.



STEVE:  Well, it's more than that.  And this is something I've been looking at sort of myself for different reasons.  The idea is that the hash algorithms that we commonly use -MD5, SHA-1 and so forth, even the more recent stronger ones, SHA-256 for example - one of their benefits, one of the things, one of the reasons we chose them is that they're fast.



LEO:  Wasn't SHA compromised?



STEVE:  Well, both MD5 and SHA-1 have had some sort of semi compromises, meaning that, as cryptanalysis has gone further with them, it's been possible to play some games with them.  For example, you wouldn't use SHA-1 today in a state-of-the-art product.  You would absolutely use SHA-256.  But they were - one of the original design criteria was that they're fast, that is, that it's very quick to hash something because you might be hashing, and typically are, large blobs.  So the algorithm itself needs to run very quickly.



Hashes are not, except for the purpose of obscuring a password, hashes are not used on something smaller than the hash itself.  Remember, the hash produces 256 bits.  You might be putting in a password actually smaller than that, and it expands it to 256 bits because anything that comes out of the hash is always the same size.  So typically hashes were designed and chosen for speed.  Well, what that means is the flipside is, from a brute-forcing standpoint, it is much easier to brute-force a cached password which is based on a fast hash because you can do many more of those brute-force tests per second when the hash, even though it's a cryptographic function, it just very quickly produces a result.  So you can try another one and try another one and try another one and try another one.



So what Dan is saying is, and he's exactly right, state-of-the-art protection deliberately slows this down.  Bcrypt is a solution which uses, I believe it's blowfish, it uses the blowfish key schedule, which is a time-consuming thing to set up.  It uses that in order to produce a deliberately computationally intensive process of going from password to hash.  So it's on purpose it's slow.  And actually, what's cool about bcrypt is it's scalable.  As processors get faster, you can turn the workload up to slow it down so that there's a relatively fixed amount of...



LEO:  That's funny.



STEVE:  ...of cost, yes, that deals with the increase of speed in processors over time.  Now, I'll take this one step further because I have been reading a lot about hashing lately, or passcode, or password, passcode protection.  The problem you still get, then, is with FPGAs, Field Programmable Gate Arrays, basically hardware.  The idea being that GPUs, Graphics Processing Units, in PCs are amazingly powerful.  But people who are serious about cracking passwords have field programmable gate arrays, literally turning that process into hardware so that it is very fast.  And interestingly, the way people on the leading edge of this have dealt with that problem is something called "memory hard" problems.  One thing that field programmable gate arrays don't have is vast amounts of memory.  And so what Dan was talking about is doing an algorithm which is computationally intensive.



But imagine an algorithm which is memory intensive, that is, where in order for it to function, and there's just there is no way around this, it has to be given a big, like a gig of memory, a big block of memory.  And it has to have it all to itself for some length of time in order to do its job.  And there just isn't - you can demonstrate cryptographically there is no way to do this without it having access to all of that memory.  And those are called "memory hard" problems.  And so the state of the art in protecting passwords involves, not just something that is computationally intensive, but is deliberately memory intensive.  And what that prevents is it prevents people like the NSA from just doing this in hardware.  You'd have to have vastly more memory than is practical currently.  Which I think is a very cool insight.



LEO:  That's a great idea.  CodaHale.com to read about using bcrypt to hash your passwords.  Yeah, that's kind of clever.  I like that.  Let me see here.  Did I close your window again?  As I surf around, I keep closing your window so I can't - let's see.  There it is, twit wiki.  I'm reading it out of the show notes these days.  Dalvik, by the way, we were talking about the Java Virtual Machine on Android phones, it's called Dalvik, which is, I think, a Finnish fishing village.  And it's open source, as well.  The virtual machine itself is open source.  I find that kind of intriguing.



STEVE:  That's really neat.



LEO:  Yeah.  Russ - oh, and LouMM, who works for Microsoft, says that there are secret, or let's not say secret, there are closed libraries used by some of Google's own closed apps on the Android phone that are dynamically loaded, they're downloaded, which is why they're not in the open source.



STEVE:  Ahhhh.



LEO:  But of course if you could only do - the closed source apps would be the only apps I think that could use those closed libraries.  So, yes, I guess to defend Lisa a little bit, it is true, it is the fact that Google, or it could be the fact that Google has proprietary libraries they don't disclose.  But I don't think that gives them magical powers over the Android operating system.



STEVE:  Not when they're running on top of an open source OS.



LEO:  Right, right.  Glenn Edward in Nottingham, Maryland - nope, sorry.  We'll go to Question #5, Russ in Austin, Texas, he's next, takes issue with your comments about Microsoft Windows being a toy operating system.



STEVE:  Boy, that really did generate some fur, some fur flying.



LEO:  Oh, I bet you got some.  But you knew it would.



STEVE:  Oh, yeah.



LEO:  Them's fighting words.  I think it's unfair to criticize Windows for having hundreds of files and modules, as well as distributed development teams.  Are you saying every other "real" OS such as Linux, BSD and others are made by a single team of programmers that handle all aspects of the OS?  I know this is not true, and I know there are tons of files as part of the distributions.  I also think it's fair to differentiate a consumer OS such as Windows - unfair, or fair, he says fair - to differentiate a consumer OS such as Windows 7 and Windows 2008 and their roles.  Oh, yeah, to be fair, these are consumer OSes, of course.  Lack of proper configuration and maintenance of an OS will leave everyone vulnerable.  IT professionals working at companies need to be responsible for their configuration regardless of OS.  It's unfair to imply that BSD, Linux or others would be secure with no additional configuration or maintenance out of the box.



STEVE:  So all of the people who took issue with my use of the word "toy" brought me to some pause.  It's like, okay, well, what did I mean by that?  When I made the comment, it was the idea that RSA, their most secret crown jewels could be exposed by somebody opening a Microsoft Excel spreadsheet that had an embedded Flash movie in it, and that that let the person get into their network.  So my frustration is that, and one can imagine this is no longer true at RSA, but it was true once, it was true the first time.  So my annoyance is that RSA's original network architecture was such that there was no division, I mean, no absolute unequivocal division that prevented someone pulling a rogue piece of email out of their trash and opening it and allowing a bad guy to get in.



And I do, I'll defend my lack of respect for today's operating systems.  These are consumer toys.  I mean, it is possible, computers obey strict rules, it is possible to have an absolutely bug-free, bullet-proof system.  It's very expensive.  And we don't have any.  And I didn't mean to imply that BSD and Linux were necessarily different.  We're surrounded by toy operating systems.  Unfortunately, that's all there is for us to use because it's just too expensive.  People say, oh, all software has bugs.  I cringe when I hear that.  It's, yes, it's true, and absolutely unnecessary, yet it's true.  Because it's too expensive to do a perfect job.  There's no money in doing a perfect job.



LEO:  Do you think it's even possible?



STEVE:  Yes, Leo.  I mean, c'mon.  It's math.  It's processors.  These things obey rules.  There's absolute, I mean, I guess I feel so passionate about it because I live down in assembly language where nothing is hidden.  I've been pulling my hair out for the last couple weeks in JavaScript land.  I will soon have a JavaScript machine to show everyone, all of our listeners.  But oh, my god, what a catastrophe JavaScript in the environment is.



LEO:  Oh, it's a nightmare, yeah.



STEVE:  Yeah.  So, I mean, everything I do I have to fight and struggle, and it's not compatible, and it runs over here but not over there.  I even ran across where my own development environment, something was not working there, but it does when I'm not in the development environment.  It's like, oh, my god.  And nothing is the same between browsers.  There was one place where every browser I tried interpreted something slightly differently.  So, oh, goodness, it's just a - and I'm so unused to that because I'm down in assembler.  And one thing that Intel has been good at - not perfect, but good at - is the Intel machine language is uniform across their chipset.



So of course, I mean, by definition it's possible for us to have an absolutely bug-free environment and not a bug in any apps.  It'll never happen.  But it's absolutely possible.  And it bugs me, it annoys me that we're sitting here, some guy turns his web firewall off and a spider marches into his website and crawls around it for a few hours and finds an unchecked SQL phrase and leverages it.  I mean, this sounds like science fiction.  It's not science fiction.  It's true.  It's happening all the time.  And does it seem it's happening more often, Leo?



LEO:  Oh, yeah.  You now have a section called Breaches and Vulnerabilities.  We're making a special feature on the podcast just for that.



STEVE:  Wow.



LEO:  Yeah, I mean, PHP is pretty notoriously bad for this, and so much of the web is written in PHP.  But it's programmer education.  It's things like validating your SQL queries.



STEVE:  To a huge, I mean, again, when I let Adobe off the hook, it's because I recognize that all of that code in Flash was written with no concern for security.  I mean, just like Windows was originally written with no concern for security.  That doesn't mean that lots of bad decisions or decisions made for expediency's sake haven't occurred since.  They certainly have.  But still we are dealing with a huge legacy that only very slowly gets moved forward.



LEO:  Sanitize your inputs, folks.  Silver lining from Glenn Edward in Nottingham, Maryland, an observation about this recent April 2011 Windows Patch Tuesday, the one we just talked about, with 64 fixes.  One thing you can say about this month's Patch Tuesday is the majority of the vulnerabilities that are being patched exist in Windows 7.  Okay, that's, wait a minute, I'm trying to figure out the logic here.  That means either, one, no more faults exist in Windows XP [laughing]; or, two, Microsoft isn't bothering to fix Windows XP faults now; or, three, hackers are abandoning XP for the more exploitable playground of Windows 7 and Vista.  A silver lining for those of us still using Windows XP, like you, Steve, is of course we may finally be slipping off the radar, hacker attack-wise.  Even if it's not true, it feels kind of nice to believe it.  Almost like running Linux and knowing no one's actively after your system.  What do you say to that?



STEVE:  I think there's something to it.  



LEO:  Really?



STEVE:  I mean, I've - oh, yeah.  I've talked before about how I've got some friends who are on Windows 98 because it does what they need, which is minimal, email and web surfing, and there is no - no one is attacking Windows 98 anymore.  And it is the case that the target is a moving target upstream, and that we also know that new code is inherently more vulnerable than old code.  And I think it's no coincidence that we will be and are beginning to clearly see a differentiation between attacks against XP and Windows 7 and Vista.  It's the newer stuff, the newer browsers.  IE9, for example, no, you can't have any IE9 problems in XP because IE9 won't run on XP.



LEO:  That's true.



STEVE:  So as we move forward, we really do - it's not that we're leaving behind perfect code.  We're leaving behind much more well-tested code, and no one is messing with it any longer.  It has a chance to just sit there and not be changed all the time because change is the enemy of security.



LEO:  I would just like to point out that Microsoft's end-of-life date for Windows XP was 2009.  You can get extended support, but you have to be a business.  The reason they're not pushing fixes is because they end-of-lifed that operating system.  There's no way in the world that it is secure, that they got all the stuff fixed.  And they're not pushing fixes because they said we're not going to push fixes anymore.  That's why.



STEVE:  Yup.



LEO:  I wonder, though, I mean, I have to say, if I were a hacker, I would look at what is the percentage distribution of the various versions of Windows.  You certainly do go after the one that's in the majority.



STEVE:  But they're still fixing SP3.  XP/SP3 is still being fixed.



LEO:  You do have to have SP3.  But I just think there - I think there are a ton of unpatched XPs running in closets in corporations all over the world.



STEVE:  Oh, god.  You take an original XP [laughing]...



LEO:  And no one's paying attention to those.  So you hack them, and it's yours forever.



STEVE:  True.



LEO:  I think, if I'm a hacker, I'd go after XP.  But if you have SP3 you're all right.



STEVE:  If you took an original XP and stuck it on the Internet, it's hysterical to see how quickly it succumbs.  I mean, there's still Code Red and Nimda are out there wandering around, making random pokes.



LEO:  So you're saying, if it's SP3, you feel comfortable with it.  That came out 2008.  Support ends two months after the next service pack release, or at the end of the product support lifecycle, whichever comes first.  24 months.  So I think that also ended, but I may be wrong.  It's hard to tell.  This Microsoft table is very obtuse. 



STEVE:  Yeah, it is.



LEO:  Review note, it says.  Review the note.  All right.  Well, I'll move on.  I hesitate to say, oh, we're safe now.  Nobody's paying any attention to us.  John O. in Argyle, Texas found debris in MRT:  Steve, I enjoyed your nice discussion of Windows Malicious Software Removal Tool, MRT in Episode 293.  You might add a note on the next show about where MRT logs are stored.  It's in C:\Windows\Debug\mrt.log.  Oh, that's good to know.



STEVE:  Actually it's very cool.  I don't think I ever noticed that MRT was leaving a log.  And I would commend our listeners to go look at it because one of the problems with MRT is that it's so quiet.  I mean, you don't know that it's running all the time, except this log details every single time it has launched, and what it found, and what it did.  It's just fantastic to have that.  So it's just in your Windows directory.  There's a debug subdirectory underneath Windows.  And there's a collection of little logs there that Microsoft builds very quietly in the background.  And there's an MRT, there's something else related to MRT.  There's two different MRT-related logs and some other things.  And I thought, wow, cool.  And mine is huge, 660K was one of the logs because, I mean, literally every time it's run, it's left a little note behind.  It's like, hey, I ran on this date, and everything was fine.  It's like, wow, very cool.



LEO:  Extremely useful.



STEVE:  Yeah.



LEO:  Logs, as every security guru knows, are your best friend.  And that's immediately what hackers modify.  Soon as they get in there they...



STEVE:  To remove trails.



LEO:  ...take the log, take down the log.  Question #8, Craig in Chicago wants you to help put pressure on Yahoo!.  Hi, Steve and Leo.  Steve, I've been with you on SpinRite since the mid-'80s.  Yeah.  And, yes, I've used it many, many times and have referred SpinRite to many over the years.



I need to ask you two a favor.  I've been a Yahoo! user for way too many years, and I have for the last five years been sending them requests to go SSL for the entire session, as Google and now Facebook does.  But apparently they just don't care.  If you could talk about this and ask all who have Yahoo! accounts to demand they get their act together, there's no reason for them at this point to keep their customers at such a high level of risk.  I do understand why they lost their lead.  And if I weren't so entrenched, I would just move.  But there's no easy way to move years of emails and other things.  I do pay them for a premium service.  What a joke that is.  I also pay for premium Yahoo! mail.  I guess I pay for no SSL.



So maybe if, with the quality and quantity of your listeners being what it is, they might finally get the message.  But of course after they've been deaf to the world for the past 10 years, it's probably wishful thinking.  You and Leo are the best.  I've been listening since the very first podcast and can't thank you enough for all you do.  Signed, Craig.



STEVE:  Well, so I never somehow got the Yahoo! fever.  I don't know.  I guess I was using my own email server and clients.  And then Google came along with Gmail, and that seemed to be interesting enough to pull me in to experiment with something else.  I have two observations.  First, anecdotally, any time I have played with Firesheep, as I had occasion to a few weeks ago, remember, when Good Morning America wanted to find out what was going on.  And I went over to the UCI-located Starbucks.  By far and away the most intercepts that Firesheep finds is Yahoo!.



LEO:  Oh, boy.



STEVE:  More than Facebook.  I would have expected Facebook.  But Yahoo! just pops up like crazy.  And obviously it's non-SSL.  That's the problem is that these credentials can be stolen because Yahoo! is not SSL.  And as a consequence of Craig's note, I thought, well, okay, maybe I could recommend that he use one of the force HTTPS solutions.  We know that our friends the EFF have HTTPS Everywhere, and there is something called Force HTTPS.  Turns out Yahoo! resists that.  It is specifically mentioned that, for example, HTTPS Everywhere from the EFF cannot do its magic on Yahoo!.  Yahoo! fights it.



So presumably, I'm sure, you are secure during your login.  But as we know, the whole deal with Firesheep is that it grabs your cookie, which is still being sent to keep you authenticated during a non-SSL post-login period, during which time it's possible to easily grab the session, because it's only represented by that cookie token, and impersonate the user.



LEO:  So even if you have an SSL login, it doesn't matter.



STEVE:  Correct.



LEO:  Because the person using Firesheep in the counter over there could just be you.



STEVE:  Right.  And I did see some people posting in Yahoo!, I mean, Craig is not alone in recognizing that Yahoo! not offering SSL is really a problem.  And so, as much voice as this podcast gives us, Leo, I'm glad to raise this because this needs to be fixed.  Yahoo! should either go away or fix it.



LEO:  Yahoo! is the - now I understand.  Yahoo! is the No. 1 place people report getting their email account hijacked.



STEVE:  Ahhhh.



LEO:  And that's the one where you get the email from somebody you thought was your friend with pertinent comments and information in the email that only your friend would know, saying, in my case, it was our gardener...



STEVE:  Oh, yeah, you told us about that.



LEO:  ...I got robbed in England, and I lost my passport, credit cards.  Please end me a thousand bucks so I can get home, and I'll pay you back the minute I get home.  And that was a Yahoo! account that had been hijacked.  And I've often wondered, well, is it a bad secret question?  Is it a bad password?  Now I'm starting to think it's Firesheep.



STEVE:  Yeah, or, well, I mean, Firesheep made this way more easy.  But it has always been possible, I mean, any time you did packet sniffing in an open WiFi, you would see all of this Yahoo! nonsense going by.



LEO:  But you wouldn't get the password because that is SSL.



STEVE:  True, but you do get the cookie that then allows you - if you just start using that cookie, it thinks you're the legitimate logged-in person.



LEO:  So you're sitting in a coffee shop next to somebody.  You use Firesheep.  You're able to look at their email, read enough of it to get some pertinent details, and send an email to everybody in their address book.  You don't need to be able to log in after that.



STEVE:  And you can send it as them.  When you send it, you're sending it from their account.



LEO:  Right.  So now when somebody calls me, and that has happened to them, I will say I know exactly what happened.  And I think it's almost certainly Firesheep.



STEVE:  Yeah.  And I haven't looked recently at the download count, but it was 1.3 million copies of Firesheep, 1.3 million copies.  And again, when I turned it on in an active location, I see more Yahoo! people than anything else.



LEO:  Right.  Somebody's saying there's phish, it could also be phish.  That's true, you could get a phishing email that says, this is Yahoo!, somebody's been accessing your account, please log in and change your password, which would be also another way to capture it.  Usually, my experience with Firesheep is you can impersonate the person.  But changing the password almost, I don't know about Yahoo!, but I would guess, almost everybody says give me your password before I change the password.  So Firesheep users I don't think, in most cases anyway, I mean, can change your password.  They just can see, they can just be you for a while.



STEVE:  Yeah, and that's bad enough.



LEO:  Bad enough.  Question #9.  You can see the whole article at cs.unc.edu/~fabian.  He's talking about this VoIP cracking thing, which we just loved it because it so clever.



STEVE:  Yes.



LEO:  So he's talking, he's referring to the original research paper.  What you're failing to note is that the system as-is has 50 percent accuracy for the words and phrases in its list.  You said that.  This is not the same as the ability to discern 50 percent of the conversation.  Ah, that's a distinction.



STEVE:  Yes, and a very important distinction.



LEO:  Right.  That's hype.  So he's referring to a figure in the article.  I'll put a link in the show notes if you want to see it, wiki.twit.tv; I'm sure you'll have a link in your show notes, Steve, at GRC.com.  Figure 11 is titled "Performance on selected phrases."  All this setup can do is look for select phrases and words.  Even the authors' "evil scenario" means the villain has to create a rainbow table of words.  One can't use a dictionary pronunciation to guide because people don't speak right.  I know we security folks are pushed to be paranoid in order to balance our society's lack of logic, but I think you've taken this to the hype level, which I'm defining as past what the data supports.  Love the show and my SpinRite license.  David in Seattle.  That's a very good point.



STEVE:  Absolutely.  And David, thank you.  You're right.  Remember that we referred to this again when somebody was concerned that it was possible then to eavesdrop on his VoIP system that he'd set up for his company a long time ago.  And so it's, I mean, and in retrospect it's like, duh, I mean, clearly this isn't, if all you've got is compression rates, and you're basing your discrimination on how much compression different audio phrases get, then what they said was they are able to determine with 50 percent accuracy of the phrases they know, what those phrases are after they've been compressed, based on how much they were compressed.  Which is entirely different from saying they  can transcribe an arbitrary conversation through VoIP.  So I did want everyone to relax a lot.  This was interesting technology, very clever, but it has a long way to go before it compromises anybody's encrypted privacy.



LEO:  Very good to know.  Our last question, Steve, and it's some really cool news.  There's an app for that.  In case you haven't seen it, says an anonymous listener, your show, Security Now!, has an app on the iTunes store - I didn't know this - called "Security Now Catalog."  It came out last Friday.  No, I have nothing to do with it.  I just figured you'd be amused and flattered to know this.  It's in the education section.  Actually, Tom Chisholm - I don't know if he wrote this or wrote the app.



STEVE:  Well, no.  He wrote the app.



LEO:  He wrote the app.



STEVE:  And it is, if you - I just Googled iTunes Security Now Catalog, and it brought me to the page.  So what it is, is...



LEO:  It's a buck ninety-nine, but I don't mind he's making a little money on that.  That's great.



STEVE:  Yep, it's two bucks, and it is every - it automatically updates itself so it'll be current, it'll stay current weekly.  And it is apparently direct access to all the podcasts, all 296 podcasts, and transcripts.  He's got - it links in transcripts.  I don't know if he searches transcripts.  That'd be very cool if it, like, had compressed transcripts that it could search.  Probably not. But he does have a search feature.  And it's both the iPhone and the iPad.  I'm constantly receiving requests from people, and I know you are, too, Leo, for, like, could I get the first hundred podcasts?  The iTunes feed or the RSS feed only gives me the last few.  I want to go back further.  Of course I have them all on my site.



LEO:  As we do, too.



STEVE:  As you do.



LEO:  You always have access to it.  But the RSS feed would get mighty big with 300-odd entries in it.



STEVE:  Yes.  And so this is - it looks, I mean, it's very simple, but it's very clean.  It's just it's a listing of all the podcasts, which you can search by name.  And presumably you click on it, and it downloads it.  So it's just a way to - it's the Security Now Catalog app for iOS.



LEO:  Wow.



STEVE:  So thank you, Tom.  And thank you, anonymous listener for letting me know because I don't know, I mean, we would have found out about it sooner or later.  But it was just last Friday, so it came right to our attention.  Which is cool.  And I hope that Tom sells some because that would be great.  And maybe he'll make it better.



LEO:  And Tom, email me.  Because if you want to write an app for every one of our shows, I'd love to help you do that.  Wouldn't that be great?  Every show should have its own app.



STEVE:  Yeah.



LEO:  Why not?



STEVE:  Yeah.



LEO:  And if you, I mean, of course you can subscribe to any podcast.  But I love this idea, that every one of the shows had its own app.  If you were a really big fan of that show, like Security Now!, you'd always - I think this is great.



STEVE:  It's got a nice little icon, which he obviously grabbed off of...



LEO:  It's our album art, but that's fine.  And it says "catalog" instead of audio or video on the right.  Tom, you've got my wholehearted thanks and support.  And I would love to talk to you.  So please - I presume he listens, or he wouldn't have done this.



STEVE:  Good point.



LEO:  Email leo@twit.tv.  And I want to commission you to write one of these for every one of our shows.  I imagine, once you've written the first one, it's all the same.  I mean, it's very similar naming and so forth.  Steve, I have one more question from Leo to you.  I've got to send you two emails I received - and I just can't figure out if it's a spoof or not - I received last week, and everybody said, well, you ought to ask Steve, I received an email from the president of one of the world's largest advertising companies, Publicis, last week, saying we would like you to come to the EG8 Summit in Paris - by the way, this is May 25th and 26th or something like that, it's coming - 26/27.  It's coming up, like, in a month.  



STEVE:  Wow, yeah.



LEO:  As the guest of President Sarkozy because we're putting together a panel of people who are Internet luminaries to guide the G8 summit, which is a summit of the top, the leaders of the top eight nations in the world, as to information and communications technologies, the Internet as a force in economic growth and so forth.  And I thought, yeah, right.  He said, you'll get an invitation from President Sarkozy soon.  Well, I've got the invitation.  But it was emailed.  And this makes me suspicious.  Wouldn't the president mail it to me?  I'm a little worried about that.  So I want to send you these messages.  Maybe you can look at the headers.



STEVE:  I'd love to look at the headers.  I'll tell you what I find, sure.



LEO:  It just doesn't feel right to me.



STEVE:  I mean, clearly this is not a come on that would work for pretty much anybody but you.  I mean, it's just not...



LEO:  No, and there is going to be this forum.  I just feel like maybe somebody's pulling my leg.  I don't know.



STEVE:  Wow.



LEO:  The G8...



STEVE:  Clearly you need to talk to somebody...



LEO:  I've got to call them before I buy a ticket.



STEVE:  ...before you go make your plane reservations, yeah.



LEO:  President Sarkozy is the president of the group of eight countries:  Canada, France, Germany, Italy, Japan, Russia, the U.K., and the U.S.  And they're convening an extraordinary, invitation-only meeting of the - I'm almost embarrassed to say this - the best and the brightest technology leaders from the G8 and the rest of the world.  It's an EG8 forum.  It'll be in Paris, preceding the G8 Summit in Deauville.



STEVE:  Wow.



LEO:  Actually I guess the G8 Summit's the 26th and 27th, so it's a few days - the 24th and 25th at the Tuilerie.  Invitation-only.  I think I should go, if it's real.



STEVE:  Oh, my god, of course you have to go.



LEO:  I wouldn't have any choice.



STEVE:  No.



LEO:  But I just - I can't believe it's real.  I'll send you the emails.  You could tell me if the headers make any sense.



STEVE:  I'd love to.  I'll track them down.  I'll see what they say.



LEO:  You know why I believe it?  As far as I could tell, the header that came from Maurice Levy, the president of Publicis Group, was sent from a Lotus Notes account.  And I don't think any hacker uses Lotus Notes.



STEVE:  Good point.  Good point.



LEO:  Doesn't seem right.  But maybe somebody got these and intercepted them and reformatted them and sent them - I don't know.  I guess I should call.  Maybe I'll call - I'll call Nic.  The President of France, I'll call him.  Hey, Nic baby, comment ca va?



STEVE:  Yeah, he'll probably be going off to a fancy wedding here before long.



LEO:  What's happenin'?  What's happenin'?  Did you really mean to invite to invite me to that party?  They don't want me.  Steve, so great to talk to you.  Thank you so much, as always.  If you want to find out more about this show, get the show notes, the transcriptions, the actual audio including 16KB for the bandwidth impaired.  We're getting very sensitive to that, I think we're going to have to start doing that for all shows as these new bandwidth caps are implemented.  Go to GRC.com.  That's a great place to ask your future questions.  We'll do this again in a couple of episodes.  GRC.com/feedback.  And by the way, when you're at GRC, might as well just plunk down, what is it, 80, 90 bucks for SpinRite?



STEVE:  Yup.



LEO:  Well worth it.  If you've got a hard drive, you need SpinRite, the world's finest hard drive maintenance and recovery utility, and of course Steve's bread and butter.  GRC.com, the Gibson Research Corporation.  Steve is on Twitter, @SGgrc.



STEVE:  Yup, I'm enjoying notifying people on short notice of things that happen.  And, boy, it's becoming a really fantastic resource for me.  Our listeners know that they can just drop me a short little blurb when something happens to make sure that I know.  And it's just great.  I accumulate things during the week and then deal with them during our podcast.



LEO:  Well, thank you so much, Steve.  This is, obviously, if you follow security at all, and you follow Twitter feeds from security experts, this is a must-follow:  SGgrc.  Steve, always a pleasure.  We'll see you next week, our usual time, by the way, Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern, at live.twit.tv.



STEVE:  Thanks, Leo.  Talk to you then.



LEO:  Take care.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#297

DATE:		April 21, 2011

TITLE:		Pass-Sentences??

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-297.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a number of extra-interesting security news of the week, Steve and Leo explore the recently raised suggestion that using a three-word "pass-sentence" such as "I like tomatoes" would be MORE secure (and far more memorable) than "J4f6<2".  Short sentences are certainly easier to remember ... but more secure?



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 297, recorded April 20, 2011:  Pass-Sentences.



It's time for Security Now!, the show that covers your security online, with the king of all of this, Mr. Steve Gibson of GRC.com.  Steve is the man who first discovered spyware, coined the term, wrote the first antispyware program.  But he's been doing security for a lot longer than that.  He's also the author of a great hard drive maintenance and recovery utility that's still number one:  SpinRite.  Hey, Steve.



STEVE GIBSON:  I'm glad that we've dropped the "the man, the myth, the legend"...



LEO:  Oh,  you're that, too.



STEVE:  ...intro.  I don't really miss it.



LEO:  He blushes every time.  I don't want to make you blush.  And I really should say, first and foremost, one of my dearest old friends.  And always a pleasure.  We had you on TWiT a week and a half ago with Pournelle and Dvorak, and it's just...



STEVE:  It's really fun.



LEO:  It's just so great that us oldsters, because we're the same age, can still participate in technology.



STEVE:  Yeah, we're still getting to our computers.



LEO:  Well, more than that.  We have a context.



STEVE:  We may be sitting on balls, but we are in front of our keyboards.



LEO:  You're not sitting on a ball, are you?



STEVE:  No, I'm not.  Although...



LEO:  I am.  No, I think what we bring to the table, though, is this memory and this history.  Aaron Newcomb was doing FLOSS Weekly, he was in here, as you know, a minute ago.  And we were talking about old computers and your first computer and stuff.  And I think that there's a whole generation that grew up with super powerful computers and iPads and stuff, and they don't really - they don't know the history of all of this.



STEVE:  Well, and I see things on the 'Net from people who are clearly newbies, which I know is great.  Everyone is at one point.



LEO:  Everybody's got to start somewhere, yup.



STEVE:  We were once.  But there certainly is something that you get from having seen a lot of things before where you say, okay, well, let's put this into context.  And in fact that sort of is a perfect segue into today's topic because somehow through Twitter, and maybe you were the genesis of this, I started getting a lot of people asking me about a blog posting which actually is not even new.  It was originally posted in I think it was September of '07 by a guy in Denmark who's not really a security guy.  He's sort of a new media guy.  Actually, I think he's, like, in charge of new media for some fashion designer company.



LEO:  Oh, you're kidding.



STEVE:  No.



LEO:  I should have dug deeper.  I mean, I think I saw it on Hacker News.



STEVE:  Anyway, the concept is he makes the assertion that three-word sentences make - are, like, vastly stronger than anything else you can do for a password.  And so...



LEO:  And memorable.



STEVE:  And the advantage being, yes, like "I like pudding" or something.  And so he makes the assertion that that's vastly stronger than, like, random gibberish passwords.  And so I started getting everyone in Twitter saying, is this true?  Does this work?  Does this make sense?  And what's compelling is that the graphical design of this page is very nice.  And unfortunately he's made a number of logical mistakes.



LEO:  Oh, shoot.  I thought it was too good to be true.



STEVE:  Yeah, it is too good.



LEO:  Oh, shoot.



STEVE:  But and then in his FAQ that he has, he also contradicts himself in a number of places.  So, I mean, I wanted to give this our type of Security Now! rigor.



LEO:  Good.



STEVE:  And also sort of move the bar a little further in our discussion of passwords, which we haven't covered for, like, five and a half years because it turns out that was the original series of topics when we began Security Now! with Episode 2 or something, I think it was.  So I think everyone's going to find it very interesting.  And we're going to talk a lot about bits and password technology and binary stuff.  Some interesting news.  Some broke just an hour ago.  I may have scooped you on one of these things, Leo.



LEO:  Oh, good.



STEVE:  So we'll see.



LEO:  I love this.  Well, we always have - I love this show.  There's always something to learn.  There's always something new.  And I meant to send you an email about this, and I'm so glad that our listeners did - they're very proactive - because I really want to hear what's wrong with this.



STEVE:  Well, and before I forget, I want to mention that there are, throughout this, a number of URLs.  And I was thinking, how am I going to share these with people?  Well, first of all, I should mention that I recently grabbed the domain GRC.sc, as in shortcut, so that I could do my own URL shortener and give it the kind of security features that we would like it to have.  I haven't yet implemented that.  But then I realized I had recently tweeted all of these things.  And so even for old-school people, I mean, I got excited when I saw that Jerry Pournelle had a Twitter account, and I forgot to give him some feedback about that when I was on TWiT with you guys a week and a half ago.  Then I realized it's not really an account that he's tweeting on.  Rather it's some bot that takes topics from his blog or something.  So it's some sort of an automated gizmo.



LEO:  We've been working on getting him on Twitter.



STEVE:  Yeah.  And anyway, so even for the people who are not on Twitter, if you just go to Twitter.com/SGgrc, what that gives you is my feed, and all of my recent tweets will be there.  So, for example, I informed people several days ago that this was going to be our topic this week because I  finally thought, okay, this needs to be what I talk about to satisfy all the people who are asking me.  So where we have strange URLs, I've already tweeted these things, so you can find them, you can just pick them up at Twitter.com/SGgrc.



LEO:  That's a great idea.  That's great.  Thank you, Steve.  So before we get to that, and of course we have security updates and a lot more to talk about, as well...



STEVE:  Some fun news, yes.



LEO:  Steve's been busy.  And people are saying in the chatroom, is Steve going to cover the iOS tracking issue?  Well, don't you know Steve by now?  Of course he is.



STEVE:  Top of the list.  You see it right in front of you there, Leo?



LEO:  I do.



STEVE:  iOS is and has been tracking us.



LEO:  So, yeah, this broke, this iOS thing just broke yesterday, I think.



STEVE:  Well, actually it was blogged by one of the discoverers earlier today, today being the 20th, which is Wednesday, of April.  There's an O'Reilly conference going on in Santa Clara from yesterday, today, and tomorrow, April 19th through the 21st, the so-called Where 2.0 Conference.  And two guys, Pete Warden and Alasdair Allan are planning to announce today their discovery that our iPhone and 3G iPads, that is, those devices with cellular connectivity, so not, for example, the iPod Touch nor the WiFi-only iPad, that those cellular connected devices from apparently starting with v4 of iOS, so not prior to that, but starting with v4, those devices are regularly recording the position of their location and synching it with iTunes to build a large and growing composite file called - it's titled "consolidated.db."



And what they discovered was this file contains a wealth of information about the location of that device or devices over time, including the longitude and latitude and a time/date stamp for that location.  And Alasdair also wrote, because he was the person who did this blog posting on O'Reilly's site that got picked up by the various news spools, he said, "For example, in my own case, I discovered a list of hundreds of thousands of wireless access points that my iPhone has been in range of during the last year."



LEO:  Wow.



STEVE:  So as far as they know - and this is significant, I want to make sure we don't overblow this - as far as they know, this is not being shared with Apple.  That is, they don't believe it's being transmitted to Apple.  But it really does beg the question, what is this for?  Why is this file being built?  What purpose does it have?  How is it accessible to the outside world?  They raise the point that, from a privacy standpoint, once it's known that it exists, and now everyone knows it exists, if anyone had access to it, then your location and whereabouts through time, when you're traveling around with your iPhone, as most people do, or their iPad, as I do, is all there.



For the Mac, they produce a free little bit of software which you can get to from the link from their blog posting.  And I imagine this will be much in the news in the next day or two.  And again, you can get the link, I have it as an O'Reilly shortened link.  But again, I linked to it from my Twitter feed, so Twitter.com/SGgrc, and you'll find my first note of this earlier this morning on April 20th.  Their blog posting, Alasdair's blog posting has a link to the software.



So I grabbed it and downloaded - it was tiny, I think 132K or something - ran it, and immediately I'm looking, sure enough, at a map of the U.S. with a little concentration showing in Southern California.  And I zoomed way in on that.  It also has - it has a timeline slider along the horizontal and a zoom scale on the vertical.  And I zoomed in, and sure enough, I mean, it knows where I've been spending all my time.  It was right there on the map.



So they have asked Apple what's going on, and there's as yet been no reply, though I don't know what length of time Apple had to reply in.  I'm sure we will, within a day or two, know much more about this.  And apparently there's even more stuff in this file that they will be talking about.  For example, I only mentioned the longitude, latitude, and timestamp.  But we also know that all WiFi contact, we know from what Alasdair wrote, all WiFi contact is being logged in this, too.  So I wonder why?  And we don't know.



LEO:  Could be diagnostic.



STEVE:  Eh, yeah, I mean, again, it's like, okay, don't know why that is.  I'm not hugely concerned.  He does make a point that, if you use encrypted backups through iTunes, then this file is encrypted.  So it's only if your...



LEO:  Well, it's on the phone unencrypted, but the backup is encrypted.



STEVE:  Correct, the backup on your Mac is kept encrypted.  So anyway, so if someone had access to it, and you were concerned with someone knowing where you had been and when, then that's all there.  So it does sound like something that we need the option of disabling or manually enabling or Apple telling us what their plan is for this thing.  So in any event, users should know that their phones are doing this.  And anyone listening to this podcast and my Twitter feed now knows.



LEO:  Amazing.



STEVE:  Microsoft has also released a third antispyware tool.  Now, as our listeners know, my theory of Microsoft's slow march forward is that this is just Microsoft's compromise with people who are selling things for Windows that Microsoft recognizes they actually really do have to incorporate into Windows, but they can't do it all at once because everyone would scream unfair competition and antitrust and so forth.



We first saw this with the firewall.  I remember Gregor Freund, who was one of the cofounders of ZoneAlarm, Zone Labs, one of the co-founders of Zone Labs, I remember when he was invited up to Redmond, along with all the other personal firewall vendors, for a meeting where Microsoft was disclosing that they were going to put a firewall for the first time ever in XP.  And I don't know who they were trying to pacify.  But they said, oh, don't worry, this is not going to compete with you commercial firewall guys because we're doing inbound only, not outbound, and it's off normally.  So most people will never turn it on.



And so I remember Gregor and I used to chat on the phone frequently back then.  And he sort of scratched his head, and he says, well, you know, we're not real happy about it.  But they're right that it's really you know, it's not really going to impact what ZoneAlarm's functionality or Symantec's Norton firewall and so forth, all of the various things.  We had, what BlackICE at the time and other firewalls of that era.  But as we know, Microsoft has slowly moved that forward.  In SP2 of XP, now it's on by default.  And then now, in Windows 7, and I think in Vista, it also does outbound blocking and application-level blocking.



So today, although it took many, many years and many versions and service packs, they're pretty much done with personal firewalls.  And one wonders why you would add a third-party firewall.  So I think we're seeing and have been seeing the same thing happening with antivirus.  They're very slowly creeping forward, adding features, adding capabilities.  And in some cases, I mean, the MSRT is the Microsoft - no, sorry, Security Essentials.  Microsoft Security Essentials was clearly a big step forward in stepping into this territory.  The MSRT was the scanner that we've talked about on a number of occasions which is updated with every second Tuesday of the month, which they introduced to defend themselves against the problem people were having of updating Windows and then having that crash their systems because they didn't know that they had a rootkit installed which was assuming fixed entry points for functions which would change when Microsoft revised the core Windows things.



So what we have now, like in the last couple days, is a third thing from Microsoft.  Microsoft calls it the "Safety Scanner," Microsoft Safety Scanner.  You can find it simply by putting "Microsoft safety" into Google, and it'll immediately jump to suggest that the third word should be scanner.  I do not suggest you use this as a three-word password, however.



LEO:  We'll talk about that.



STEVE:  We'll be discussing this later.  So what this is, is basically it's built on the MSRT, the Microsoft Software Removal Tool.  However, this brings a full and mature set of antiviral, antimalware signatures with it.  It's big.  It's 72MB.  And interestingly, it only survives for 10 days from the time you download it.  But also interestingly, you don't need to install it.  It doesn't install.  It's a standalone EXE called MSERT.  Maybe that's for expanded or extended or something, I don't know.  It's available in 32- and 64-bit versions and runs from, for example, a USB drive, a little USB stick, thumb drive, with no problem.



So if you want to use it, the idea being it's standalone and is a full mature scanner.  It's been tested versus the other current commercial scanners, and it has not found to be wanting.  That is, it's state of the art in terms of what it finds and sees.  And I've already had some feedback through Twitter from some people who have used it under safe mode, for example, to successfully scan and remove malware from their machine.  And Microsoft still...



LEO:  Now, it doesn't replace an antivirus.  It's kind of a different beast; right?



STEVE:  Correct.  It is a scan-on-demand scanner.  And they say on that page, quote, "The Microsoft Safety Scanner is not a replacement for using an antivirus software program that provides ongoing protection."  So this is the third asset in this arsenal.  So we have Security Essentials running all the time, MRT being updated automatically and running monthly, and you can of course do, as we know, if you type "MRT" in the Run dialogue of Windows, you can get it to come up, and then you can ask it to do a full scan.  And this looks, I mean, this is MRT but with a full complement of virus patterns.  I mean, it's the same MRT dialogue.  You can ask for a quick or a full scan in the same fashion.  And it looks the same from a UI standpoint.



So anyway, I wanted to let everyone know that that's there.  And, for example, if a friend said they think they have a problem with their computer, you could boot, from a CD, boot a safe version of Windows that you know doesn't have a rootkit installed, and then easily run this from a thumb drive to scan someone's system on an on-demand basis.  Which I think makes it pretty cool.



LEO:  Yeah, that's great.  Just got a note in our chatroom.  There's a company called, I think it's a German company called Ashampoo which makes an antimalware solution along with other things, office suites and so forth.  And they just sent a note to all their customers saying that their customer database had just been hacked.  And they discovered it, but apparently a lot of information was stolen, including addresses, billing information, credit card - well, wait a minute.  I'm sorry.  Credit card information definitely not affected.  Sorry.  So there you go.  So it's just email addresses.  But we have to add that to your - don't you have a new section on this show called...



STEVE:  Yeah, and it was empty.  And so now...



LEO:  Well, I just have something for you.



STEVE:  It's the A&B, Attacks and Breaches, section.



LEO:  There's one.  There's one every week, I'm sure, if you really look.



STEVE:  Oh, and actually a lot of them are, like, sort of off to the side or not big, you know, it doesn't quite make it onto the radar.  But, yes.  We're seeing problems.  And I'll tell you, it really does seem to be a growing rate and scale of these kinds of breaches now.



LEO:  Yup, yup.



STEVE:  Which is why I created a section for it.



LEO:  Now, I wanted to ask you about this next topic because I use, as you know, I use Dropbox.  And Miguel de Icaza, who is a great developer and a really important guy in the open source community, said, "What the hell?"  Because apparently Dropbox has been assuring everybody that they use strong encryption that they can't decrypt.



STEVE:  Well, yeah.  And there's two things.  There's two issues.  One is that Dropbox recently updated their terms of service to say explicitly what was always apparently implicit.  Quoting from their new terms of service, they say:  "As set forth in our privacy policy, and in compliance with United States law, Dropbox cooperates with United States law enforcement when it receives valid legal process, which may require Dropbox to provide the contents of your private Dropbox.  In these cases, Dropbox will remove Dropbox's encryption from the files before providing them to law enforcement."



Now, this sums up more perfectly than I ever could why I chose Jungle Disk for my own remote cloud-based backup.  And that is, I did a full security analysis of Jungle Disk and verified that all that is ever being put up to Amazon's S3 cloud stuff is pre-encrypted data.  That is, my Jungle Disk client has the key and everything it sends.  So all Amazon gets is opaque pseudorandom noise that they have no ability to decrypt.  I mean, it's full TNO, Trust No One, as my acronym for this, which is the only way I would ever store something in the cloud.  So here Dropbox has formally acknowledged that they have the ability to decrypt the contents of all of their users' data, and that they will do so when ordered to by a court order from the United States.



LEO:  So as Miguel points out, well, if they can do it by court order, then they've had that capability all along.  So they essentially misrepresented the encryption capabilities.



STEVE:  Well, and see..



LEO:  And he says this is a larger issue, not so much government, but that means employees could do it.  And even with a company that has very strong data policies like Google we see these things happen.



STEVE:  Very, very good point.  It means that keys could get compromised; keys could get lost.  Or, as you say, you could have a bad apple employee who realizes, hey, we're hosting a celebrity.  I wonder what he's storing in his Dropbox?



LEO:  So I make sure I don't put anything of a private nature in my Dropbox.  But I'm going to make sure I don't.  And you're right.  I think if you're going to do it, if you want to store something like financial records, use Jungle Disk.



STEVE:  Well, and here's another - well, or, and this works, too...



LEO:  Pre-encrypt.



STEVE:  Exactly.  Only store stuff that you have encrypted up there, where you're pre-encrypting that data.  And this is why, when I see someone saying "industry standard AES 256-bit encryption," it's like, that means nothing.  I mean, unfortunately it catches out people who don't listen to this podcast, who assume that, if you're using state-of-the-art encryption, then you must be safe.  No.  I mean, I would imagine that means that the link is encrypted.  And it does sound like they're storing it in an encrypted fashion.  But they're storing it with a key that they have.  So that doesn't really help.



LEO:  Yeah.  That's the question, who has the key?



STEVE:  Right.  And the best solution is for no one but you to have the key.  And the only way to do that is to pre-encrypt and only store encrypted stuff in the cloud.  Now, the other issue that came up was a question of their authentication.  Someone named Derek Newton, who is a security researcher, was poking around in Dropbox-like applications, and he just decided he would take a look and see what they left behind, what was left behind after they installed.  What he found was that, specifically in the case of Dropbox, there is a single file called config.db, which is an SQLite database file, which contains the email address, the dropbox_path, that is, where the Dropbox folder is on your system, which is being synchronized to the Dropbox in the cloud, and the host_id.  Any SQLite DB-compatible client is able to open this file and look at it.



And what he determined by experimentation is that the only thing that identifies you to Dropbox is the host_id.  There is no other lockage of that file to a given system.  And so what he posted - and again, I learned about this from people saying in Twitter, hey, Steve, what do you think about this?  And this has been a constant flow for the last couple weeks.  And I mentioned last week that I hadn't had a chance to dig into this, but I would, to look into it and verify it.  So I did want to follow up for everyone who's been wondering.



So what this means is that, if you weren't protecting this file, or if anything got onto your system which was able to grab this file through social engineering attack or spyware or malware, whatever, if you lost control of that file such that it was in any way exfiltrated from your control, then that file can be installed on any other system.  And that provides the sole authentication of you, the instance of you, to Dropbox such that, with no other information, no username, password, no logon, anything, that authenticates that new system.  And there is - it doesn't appear as a  new machine in the set of machines that you have authorized to use.  It's merely a clone of that first one, which then has full access, unencrypted access, to your Dropbox contents.  Which to me says these guys aren't really looking at security.



I mean, on one hand we know now that they can decrypt the contents of our Dropboxes.  And this could clearly have been done in a way that was more secure.  Even if you change, if the user changes his username and password, that doesn't invalidate the host_id.  It still functions.  And so if somebody had it, their connectivity survives across a user changing his username and password.  So it's just they really could have easily done a much better job of hashing username and password into this, tying it in some fashion, for example, to the serial numbers of the hard drives on the system.  I mean, just anything to make it more difficult than simply one file which you can put on any machine anywhere, and suddenly it's authenticated just as solidly as the system it came from.



LEO:  Yeah, that's not good.



STEVE:  So not good news over on the Dropbox side.



LEO:  You know, there are alternatives.  LaCie has a similar service to Dropbox that's Java based.  I don't know if it's more secure.  But I think maybe it's time to look and see what the other alter- I love Dropbox.  And I hope they respond to this by making it more secure.  That would make everybody happy.



STEVE:  I think they can.  I mean, one would imagine they will because it's so trivial.  I mean, all they have to do is listen to this podcast for a while.



LEO:  Right, and add some encryption features.  The other one to look at, I'll take a look at, is from LaCie, it's called Wuala.  Randal Schwartz told me about it.  It's Wuala.com.  Very similar to Dropbox.  I'll look and see if they say, when they say all files get encrypted - see, that's the thing, is "get encrypted."  Well, what does that mean?  Where, is the question.



STEVE:  Yeah, exactly.  And that's just it.  Unless there is a full security analysis available of how it works and what it does, you just can't trust it.



LEO:  Here's what Wuala says.  It says all files are directly encrypted on your desktop.  Your password never leaves your computer.  Not even we as a provider can access your files or your password.



STEVE:  Well, that's all good sounding.



LEO:  That's what you want - validated, of course.



STEVE:  Yeah.



LEO:  I'm going to take a look at them.  Randal Schwartz recommended them.  He likes them a lot, so I'm going to take a look at them as an alternative to Dropbox.



STEVE:  So under my miscellaneous category, I did note, and I just got a kick out of this, that Bitcoin's BTC, which is the three-letter acronym for the currency, the Bitcoin currency, Bitcoin's currency to U.S. dollar exchange rate has reached a new all-time high of $1.12 per bitcoin on one of the major bitcoin exchanges, which was mtgox, the @mtgox market.  So I just thought I would let our listeners who are following Bitcoin and interested in knowing that bitcoins keep getting more valuable, ephemeral as they are.



LEO:  More valuable.



STEVE:  More valuable.  Well, I mean, you can trade them in for dollars.  You can get actual dollars...



LEO:  But that worries me.  That worries me.  I feel like that's money laundering by somebody, somewhere.



STEVE:  But that's privacy.  Isn't that a good thing?



LEO:  No, but I - yeah.  But I've got to wonder, who's buying bitcoin for real greenbacks, and why?



STEVE:  Yeah, I don't know.  I just think it's cool technology.  And it works.  And we have a full security analysis of it, and I can vouch for the fact that...



LEO:  No, Bitcoin's good.  I'm not saying that.  The only thing that worries me at all is this notion of there being a market for greenbacks.



STEVE:  Yeah.  So I've been getting questions, mostly over in the GRC newsgroup, about when GRC would offer ShieldsUP!-style analysis scanning, port scanning, on IPv6.  And so I contacted Level 3, and I said, hey, what does it take to get some IPv6 block?  And they said, all you have to do is ask.  Are you ready?  And I said, uh, not quite yet.  So then I called my local T1 provider.  I have, as always, two T1s coming here into me.  And for the first time really in a long time I'm glad I've got T1s because I don't think Cox or Community Cablevision or whoever does my cable modem, I don't think they would know how to respond to this question at this point.  Ultimately they're probably going to have to.  But I don't even know if they'll make IPv6 service visible to their customers.  Who knows what they're going to do in order to actually roll this out.



But I have a direct connection with Cogent, who is my provider of connectivity on the other side of my pair of T1s.  And the engineer from Cogent has been with me since before Cogent bought the T1 business from Verio.  You'll remember all that, Leo.



LEO:  Oh, yeah.



STEVE:  And so I said to them, hey, I'd like to have IPv6 service, the idea being that I'd get it here at home, you know, slash office, where I hang out and work, and update my router to handle it because I've got an old Cisco router, but there's firmware available for Cisco's IOS.  And there was a name collision, of course, with Apple's iOS, but Cisco was there first.  Cisco's IOS has been able to handle IPv6 for many years, since I think '03.  So I had to update that and my various other stuff and then begin to perform some experiments and bring myself up to speed and write some code and be able to support IPv6 access of ShieldsUP!.



So they had never done that before, when I asked them.  Which gives you some sense, and this is just in the last couple weeks, gives you some sense for where IPv6 still is, is that Level 3 wasn't pushing it, but they did say that new deployments of large customers, when they were setting up new people, they were often using IPv6, though still with some IPv4.  But IPv6 was in the conversation.  Over the course of a week or two, because I know the engineer at Cogent, they were able to move things around and provide me with IPv6 service.  They gave me a choice of how many IPs I wanted.  Is everyone sitting down?  The normal allocation for a customer, the typical sort of, like, minimum that you get, if you've got a network, is a /64.  Now...



LEO:  How many addresses is that?



STEVE:  Okay.  IPv6 uses 128 bits of addressing.  So a /64, and this is the normal networking that is used, is 64 bits for the network number, and 64 bits for the machine in the network.  So we're used to this notion of there not being a fixed division between the network and the machine.  So, for example, we have, like, a /24 will be 24 bits for network.  And IPv4 we have a 32-bit address.  That leaves you with 8 bits for machine.  So, for example, the famous 192.168.something.something, well, technically that's a /16 because you have .something.something.  But it's normally used in a /64 mode where you'll have 192.168.0.something, meaning that only the last byte in that network is set to which machine you have so that you could have 253 machines on that network, which is more than anyone has at home, typically.



So but this changes when we move to IPv6.  Just because the reason we began to constrain the size of the number of machines in the network was that it gave us many more networks.  And we started to have to need, we needed that variable boundary between networks and machine numbers because we were running out of available networks.  So they sort of pushed that boundary downwards, making each network smaller so that we would have more networks.  Which is probably the best way to say it.  But with 128 bits of addressing under IPv6, we don't ever need more networks.  So typically they're going to just divide the 128 bits of IP space in half and not argue about it.  You get a 64-bit network often if you're like a regular customer with an ISP.  So that's 2^64 different IPs.  And I did the math earlier, I don't have it in front of me, but it's billions of billions of machines.  Wait, 2^64, I can do it.



LEO:  You got your programmer's calculator there?



STEVE:  You bet I do.  2^64 is...



LEO:  A lot.



STEVE:  ...1.8 times 10^19.



LEO:  Whoa.  That's pretty big.  That's how many IP addresses you get?



STEVE:  Yes.  No, well, actually no.  That's what most people get.  John said, well, you know, Steve, if you ever needed to, like, renumber yourself, then we would make you move to a different /64.  So we're going to give you a /48.



LEO:  Oh, well.



STEVE:  Okay.  So that...



LEO:  So lower is more.



STEVE:  Yes.  The 48 is the number of bits they have over on their network side.  So 128 minus 48 is the number of bits I have.



LEO:  I get it.



STEVE:  So I have 80 bits.  Which is 1.2 times 10^24.  Now, okay.  So 10^24, that's 24 zeroes.  Now, a million is six zeroes.  So this would be four sets of million.  So 1.2 million million million million IPs I'm going to have.  Now, I don't know what I need all those for.  But...



LEO:  It just shows you how much there is.



STEVE:  Yes.  That's why I wanted to illustrate this.  It's just it gives us a sense for, I mean, and you can imagine, in an environment where we're all running out, and everyone's oh, no, no, the sky is falling, IPv4, now the registries have run out, now, blah blah, we're hearing all this.  So you'd think maybe they'd learn the lesson and be a little more parsimonious with these IPs.  It's like, well, how many do you really have over there?  How many do you need?  But the point is, even in this climate of, well we ran out of IPv4 space, so we don't want that to happen again.  But with 128 bits, they're just saying, aw...



LEO:  Take all you want.



STEVE:  You can have, Gibson, you've got, what, five, six computers over there?  We're going to give you 1.2 million million million million IPs, where you can just get lost.  I mean, I can't even write that down.  It's more of a burden than it is a benefit.  But that's what - and so it's funny, too, because then I wrote back, I said, okay, John, how many do you have?  Because he just seemed to be peeling them off with such alacrity.  How many do you have?  And he said, well, we received a /32 from ARIN, that's the North America registrar, and another /32 from RIPE, which is the European one.



So /32 means 32 bits of network, and then so like they have a - so the 32 bits are fixed.  And their number is 2001:550, which is a way in IPv6 parlance, and we'll be discussing all of that in the future, that's their network.  They then have - they can do anything they want to with the balance of the bits out of 128.  And since 32 from 128 is 96, they've got 96 bits that they can allocate any way they want to.  So, for example, when they gave me a /48, they have 65,538 networks of that size.  So they have 65,000 /48s, of which they're giving me one.  Most people they'll give /64s.  So they've got vastly more of those networks.  Actually they have another - that gives them, if they use 64s, that gives them another 16 bits of allocation.  So that's another 65,000.  So they're just not worried.  Oh, and if they do actually run out, they just ask for another one.



LEO:  Because there's plenty.



STEVE:  Yes, well, there are 4.3 billion of those /32 networks because we know that /32 - think about that.  /32, that's the total number of IPs that we have now in IPv4.  That's the total number of networks of that size that the registrars can just peel off at will, 4.3 billion networks, each containing 65,000, 65,000 /48s.



LEO:  Wow.



STEVE:  So, yeah.  We're fine.



LEO:  In the words of Tamahome, you sound like Carl Sagan.  Billions and billions of IP addresses.



STEVE:  I did love this.  He said, in his note he wrote he said, so customers, really, they can have a 48, a 56, or a 64.  He says, to get a /47, which would be like, you know, one more bit above 48 because you're then squeezing the network down to get more machines.  He says, "To get a /47, a customer would have to prove a need (which no one has done yet)."



LEO:  Or will ever do.



STEVE:  Okay, because, yes...



LEO:  Try and prove a need for a 64.  That's more than the whole Internet now.



STEVE:  Oh, exactly.  That would be needing 1.4 times 10^14 individual IPs.  Which, as you said, is like many, many, many millions of Internets now.



LEO:  I have an unusual application.  I'm going to be...



STEVE:  And you know, I've got to say, as I was thinking about this in the context of ShieldsUP!, how many times have we run across situations where a problem was that it was possible to scan, that is, Nimda and Code Red and Blaster, they used to be scanning the Internet.  And even though we think of four billion IPs being a lot, if you've got a botnet, for example, you can scan a lot of IPs in a relatively short time.  And that's one thing that dramatically changes because it's no longer the case that a large percentage in a small region of allocation are going to be valid IPs.  You have 128 bits, they're going to be relatively sparsely allocated.  I mean, I'm going to use a handful of IPs out of - actually I'm behind some powerful NAT-y kind of stuff, so...



LEO:  Yeah, you don't really even need more than one, yeah.



STEVE:  Yet here's this massive block which is all given to me.  And God help something that tries to scan that.  So scanning really...



LEO:  Oh, that's a good point.



STEVE:  Yeah, scanning, the nature of scanning, really does change in an IPv6 world.  Now, you might argue that, well, you just scan the, like, zero, one, and two of each range.  Well, but I'm not going to put my IP, the one I use, down there.  It's going to be floating hidden somewhere in the mist.



LEO:  Up there in the billions.



STEVE:  Oh, yeah.



LEO:  Wow, that's so cool.  Well, I just hope this all happens, that's all.  I mean...



STEVE:  Yeah.  That'll be fun to talk about because...



LEO:  APNIC ran out of IP addresses, you know, IPv4 addresses.



STEVE:  Yup.  And there sure is some reluctance for it to happen.  Otherwise Microsoft wouldn't be offering millions of dollars for Nortel's block of IPs.  Clearly there's some reluctance to make this move.



So a customer of ours, of GRC's, David Ward, I guess he has a computer company called Wellmax Computer.  He just wrote a short note that I wanted to share.  He said, "I had a friend bring a laptop to me and tell me that the fan was failing.  The machine would freeze after about five minutes into the Windows XP boot process."  Wow, it was taking more than five minutes to boot?



Anyway, he says, "He had taken it to three other techs before me, who all said the same thing, that the fan was failing, so the machine was overheating and then stopping the boot.  I experienced the same problem, however, after booting into safe mode.  And having the machine stay on for an hour, I knew this was not a fan issue, but a hard drive issue.  Sure enough, after running SpinRite for over 180 hours," he said, parens, "(It's okay, at one point it said it had another 1,089 hours to go.)"  Because, remember, it estimates how long...



LEO:  It's guessing, yeah.



STEVE:  Yes, it estimates how long it's going to take based on how long it's taken so far.  But often bad spots are in the beginning, and so things pick up the pace dramatically after SpinRite deals with the early problems.  So he says, "It finally finished after finding and fixing many bad sectors.  Now the machine booted successfully and ran very well.  All the customer could do was shake his head and utter the phrase, 'Amazing,' several times.  Thanks so much.  David Ward, Wellmax Computer."



LEO:  Amazing.



STEVE:  Amazing.  So thank you, David, for your testimonial.



LEO:  So I tweeted this.  I think I saw it in Hacker News.  It's funny because I didn't realize it was a four-year-old article.  But a fellow named Thomas Baekdal, I think that's how you say it, in Denmark, published an article on his blog four years ago which has gotten a lot of attention lately, saying who needs those really hard-to-remember random punctuation passwords, when you could just use three common or uncommon English words and do better?  I believed it.  Looked good to me.  But we've got to give it the Steve test.  Steve Gibson is going to explain why three English-language passwords may not be the best solution.  All right.  Let's talk.  Three words.  "This is fun."  Is that a better password?



STEVE:  Oh, god, no.



LEO:  Than "asiw>"...



STEVE:  No.



LEO:  No?



STEVE:  No.  In fact, that was one of the conclusions in bold on Thomas's page.  He says "this is fun" is 10 times more secure to use than "J4fS<2."  Now, just look at what it took me to communicate the second one versus "this is fun," and that gives you a clue.  But let's start a little bit back further.



LEO:  Let's get the science.  Let's do the math, yeah.



STEVE:  Yeah.  So once upon a time we had the notion of a password.  And we understand that that became unusable, unsafe, because of dictionary attacks where, well, first of all, people, I mean, famously would use the word "password" as their password, or all nines, or 1234567, or something guessable by somebody who knew them.  There were all kinds of reasons.  So then we sort of, in my own thinking, evolved to passphrases where you had the notion of longer is better.  And that's sort of where my own thinking moved through with this notion of something that was memorable.  But then, in thinking about it more and also literally doing the math, I moved to passcodes.  And our listeners have heard me referring to passcodes now for some time.  And so the question is, what about short pass sentences?  Does that make sense?



So let's back up a little bit and look at the attack model, that is, the threat model for the use of passwords.  I think this whole thing, the whole notion of something the user knows as one factor of authentication remains important because, not only is it the original technology for online authentication, but, sadly, we're seeing such slow adoption of other things like the YubiKey or the smartphone-based one-time password technology, I mean, we have all the technology that we need to solve the problem.  But it's just adoption rate.  And what's interesting is much could be done to strengthen even the use of passwords, much more than has been done.  And what I'm hoping we're going to see is that happening over on the server side.  And we'll talk about what that is because that's a function of sort of this password technology.



So we start with something the user knows, which is the idea being that it's a secret.  And obviously you'd like it to be unguessable by somebody who knows you.  You'd like it to be not easily brute-forceable, like not "aaaaaaa" as a password.  So as we've talked, there are two technologies, essentially, for a user's interaction with logging in online.  At the server side, they either store the password, or they hash it, and then they store the hash.  The idea being that, unless you're in France, where there seems to be some legislation requiring that the user's password itself be made available, unless that's the case, there's really no need for an authentication system to store your password.



What you can store is something which you can uniquely derive from the password, and that provides some privacy protection for the user because we have the cool cryptographic technology now known as a one-way hash, a cryptographic hash that can take a password and turn it into essentially a pseudorandom token for which there is no way to reverse that process.  You can't go backwards because it's inherently an information lossy process.  So that allows an authentication provider to just store that hash.  And when asked to reauthenticate, the user provides the same thing, which gets hashed in the same fashion and produces an identical result, which can then be compared for identicalness.  That prevents someone from saying, well, you almost got it right, you know, you didn't get the punctuation correct, or you didn't get the capitalization correct.  There's no way they can do that.  All they can say is, nope, that's not what you gave us before, try again.



Now, cleverly, rainbow tables were developed as a means of getting around this one-way hash concept.  A rainbow table is essentially a dictionary of all the results of hashing everything.  So you sit there in what's called an "offline mode" - and we'll make that distinction very clear in a minute - an offline mode with your field programmable gate arrays, your graphics processing units, your GPUs cranking away, whatever it is.  Or you network this among a whole bunch of people, producing rainbow tables, the idea being that you just brute-force everything through the hashing function, and you store in a database, a huge database, like a terabyte database, the result of all of those hashing operations.  In that case, if you ever do get access to the result of the hash, you can look that up in this rainbow table, and it provides you the reverse direction, only because it did all of the forward directions, and it saved them all.  That allows you to essentially look up the result of the hash and figure out what you could input that would give you that result.



It turns out, the good news is, that's easily defeated, too.  All you have to do is add something which in cryptographic circles we call "salting."  You add some salt to the hash, meaning that you take anything, and it could just be some hopefully not easily guessable blob, and you always append it, or prepend it, whichever, doesn't really matter, or even mix it in with what you're going to hash.  Which essentially produces a custom hash function.  It's the way to think of it:  Salt gives you a custom hash function so that, with your particular salt, no one else's rainbow tables will work because you've mixed something in beforehand.



Now, if they did get access to your salt, somebody could generate rainbow tables for that.  But that's sort of a - that's a different problem.  It prevents a single, like an SHA-1 or an MD5 hash, which are well-known public uniform hashes, it prevents rainbow tables for being generated for those hashes.  And by the way, those exist.  They're big, but they're available on the Internet, rainbow tables for those hashes.  So you would never want to use those without adding some salt.  When you do, it makes those existing pre-created rainbow tables obsolete. 



Now, I talked about online versus offline.  The reason this is important is it's a function of how many opportunities an attacker has to test a password.  If something is offline, that is to say it's - for example, TrueCrypt.  We've talked about cracking TrueCrypt.  The idea would be you have a hard drive that you want to encrypt.  And it is unfortunately subject to an offline attack, meaning that an attacker could set himself up so that, at an extremely high speed, they are presenting to the TrueCrypt algorithm, which remember is open source, so there's no secrets there, which wouldn't make their job impossible if it weren't open source, but it's just easier that it is.  They would present to that algorithm every possible password they can come up with as fast as possible, run it through TrueCrypt's front end to create a key, and then see whether that key decrypts the beginning of the hard drive, like a hard drive sample that they have taken.  And the point is that nothing theoretically prevents them from doing that at an incredibly high speed.



LEO:  Well, but doesn't a good program - I would imagine TrueCrypt would slow them down.  I mean, I know SSH slows you down.  Doesn't TrueCrypt say, oh, you've made 10 guesses, let's wait a minute?



STEVE:  Well, actually TrueCrypt itself could.  But the algorithm - but the problem is the bad guys can simply, since it's open source, they have access to...



LEO:  Oh, they can read the file, yeah.



STEVE:  ...anything that does that, and they could just short-circuit it.



LEO:  Got it.



STEVE:  So the problem is, in an offline attack like that, where you have access to everything - and, you know, cracking DVDs is the same thing.  Anything offline, then the idea is that it scales linearly.  That is, the more processing power, the more GPUs that you bring to it, the more you can try.  But notice that online attacks are completely different.



LEO:  Oh, yeah.  And that's what he's talking about, we should say.



STEVE:  Yes.  Well, he discusses the issue.  But yes, he says...



LEO:  Baekdal is assuming in all of his calculations you could do a hundred tries per second.



STEVE:  Exactly.  Now, I think that that's probably very generous.



LEO:  Yeah, that's way fast.



STEVE:  Because, yes, because we know that when we're trying to log onto something, we put our username and password in, click Submit, and we kind of sit around and wait for typically a couple seconds, whether we're right or wrong, before the system comes back and says, oh, that's correct, or oop, nope, sorry, something's highlighted in red that your username and password don't match, try again.  So my point is, and this is really true...



LEO:  By the way, somebody claiming to be Baekdal is in our chatroom.  So I'll watch what he says, and I'll give you his feedback.



STEVE:  And I think it probably is because he did see that I was going to be talking about this, and he did send me a tweet yesterday because he knew that I was going to be talking about this.



LEO:  Yeah.  And as we mentioned, he's not a security expert, he's a new media guy.



STEVE:  Well, and he makes a number of very good points.  But I would only take issue with the notion that three simple short English words are more secure than something completely random.  And I can do the math...



LEO:  And we're going to talk, we're going to explain it, yes.



STEVE:  Exactly.



LEO:  But so far so good.  He's made a very conservative assumption, which is that you'd have a hundred shots a second at this.



STEVE:  Well, okay.  Now, maybe if you - and this would be a function of the way the website is designed.  You might be able to have, like, a hundred clients or a hundred agents all connecting to a web service at once, trying to get into the same account, in which case that would scale up your rate.  But no matter what, you've got Internet roundtrip delays.  You've got lost packets.  You've got TCP retransmissions.  There's, like, substantial overhead which scales back dramatically the number of attempts that any kind of brute-force guessing is able to make.  Which dramatically changes the math.  And this is, more than anything, that's the point that I would like to get across to our listeners is it is very different to choose a secure password for an online service where the attacker would be reduced to an online attack versus anything like TrueCrypt or an attacker that could do an offline attack.



Now, this isn't an absolute because, as we mentioned earlier, and we do talk about weekly, it is often the case that databases are being stolen.  And so an online service whose database was stolen could then be subjected to, could have its accounts subjected to an offline, that is to say, very high-speed attack.  So it's not necessarily - we can't guarantee that an attacker would be using the same online transaction delay that we are.  But I think it's a reasonable assumption.



LEO:  Okay.  So whatever he says is, we're talking about in the realm of attacking a web password.



STEVE:  Yeah.  Yeah.



LEO:  Without physical access to the server.



STEVE:  So what we really need, when I talked earlier about some changes that could be made, that we're in desperate need of having made, and that is that, in an online scenario, and you mentioned something a second ago...



LEO:  What?



STEVE:  ...that does, that introduces a delay.



LEO:  Oh, well, a lot of programs do.  I mean, on the Mac, SSH.  A lot of programs do.



STEVE:  Right, secure shell.



LEO:  Yeah.  Or if you're logging into your Macintosh, if you enter the password twice or three times wrong, it just pauses.  Doesn't pause very long.  It gets longer each time.  But it pauses.



STEVE:  And of course UNIX and Linuxes have done this for time immemorial, and specifically to prevent this kind of brute-force attack.  All you have to do, in fact, you could make the time delay exponential, where each time you guess wrong, it doubles the length of time you have to wait.  Well, we know how quickly powers of two pile up.  And you don't even have to set a fixed lockout.  When I was designing my ecommerce system, I was very conservative.  And if somebody messes around with the ecommerce system in a way that my system detects doesn't make sense, they're blacklisted.  I mean, it's like, I don't care, I'm sorry about that.  And we've had some complaints from people who seem unable to type their name correctly.



LEO:  No SpinRite for you.



STEVE:  Yeah.  And again, I have no problem then with handling that through a human interaction loop.  But we certainly don't want to allow an automated script of any kind to be able to pound away.  So that is lacking to an alarming degree in today's websites.  And that is something so simple to fix, if it was just universally applied that, like, a progressively longer delay was present.



Now, the flipside is they know that's going to cause some customer support problems.  And so that tends to work against them doing that.  But it's just, it's so simple to do, to introduce that delay of response on the server side, and radically scales up the security in the face of anyone trying to do an online attack.  So the question then becomes, what's more secure or less secure?  And again, I'm not meaning to be attacking Thomas at all.  That wasn't my intent.  But many people asked if short English words were more secure than a short bit of gibberish.  Now...



LEO:  And that's his assertion, so that's what we want to know.



STEVE:  Now, one of the things that I have referred to when we were talking about passwords in the past is something that is a point that Bruce Schneier made that I thought was really astute.  And Microsoft's own security people have said the same thing.  They've said the danger of using something that you can remember is that it's going to be too simple, because it's difficult to remember J4fS<2.  That's arguably difficult to remember, more so than the phrase "this is fun."  And so Bruce's point was that, use something difficult to remember which you write down and stick on a piece of paper in your wallet.  And he made the point that we already know how to secure and manage little bits of paper.  We do it.  We have a wallet.  We know how to handle that, more so than something which is easy and memorable, but as a consequence of that sacrifices security.



So in the tweets that I received from people asking me about this, they were using different little three-word sentences.  Thomas on his site uses the sentence "This is fun."  The problem is that the issue in terms of bits of vocabulary size and the strong tendency people would have to design a sentence which makes sense, that is, they're not - they would not tend to choose three truly random words from a really large vocabulary because "aardvark" has two A's, and who can remember how to spell that.  Or tapioca might be a problem and so forth.



So in the samples that people were sending me, they were using three words from maybe a thousand-word conversational vocabulary, for example.  Well, we know that, if you took three words chosen purely at random from a set of a thousand, well, that would be a thousand times a thousand times a thousand possible sentences.  So there we're at 10^9, or one billion possibilities, so a thousand million billion.



The problem is that, if you instead were to choose characters from the full ASCII set, that is to say, lowercase alpha, that gives you 26 characters, uppercase alpha gives you another 26, the digits 1 through 10 gives you 10.  And just the characters available on your keyboard give you another 35.  So that's 26 plus 26 plus 10 plus 35 is 97.  So that means that, if you randomly choose a random character from an alphabet of 97 characters, and you used, for example, a six-character token, which is what Thomas uses in his example, that would be 97^6 possible combinations.  Which compared to taking three words from a thousand-word vocabulary, which gave us one billion combinations, using just six characters is 833 billion combinations, so 833 times stronger, all other things being equal.



Now, you could argue that, okay, wait a minute, the weakness in the argument is this thousand-word vocabulary.  But it turns out, even if you used a 500,000-word vocabulary, which is the number of words in the English language, for example, it turns out that that doesn't scale much faster, either.  500,000 words in the English language is 18.93 binary bits, and then - if you use three of those.  But to do that you're using really obscure words.



So my feeling is that, while it's tempting to use memorable sentences, short, three-word sentences, the problem is that we want to have multiples of those.  We know that it's much safer to use - not to reuse the same password on different sites.  Which is why of course LastPass famously solves this problem by giving us a local database which is locally encrypted and is able to figure out what domain we're trying to log onto and fill in these forms for us.  So it solves the problem of a pass anything, whether it's a passcode or a passphrase or a pass-sentence, on a per-site basis.



If we're going to be using different sentences on different sites, then we still need to write them down to remember which sentence we used on which sites because many of us are logging into all kinds of different services throughout our day, and that number of services increasing.  So we still need to have something written down to disambiguate.  And that assumes we didn't have LastPass, which sort of solves the problem for us anyway.



So I guess my feeling is that, if we're going to use a single short sentence across the entire Internet, we know that's not safe.  And if we're choosing it from a small vocabulary, it doesn't give us as many possibilities as - and again, you can of course add words.  It doesn't give us as many possibilities as using a short token from a much larger character set or from a full-size character set - 97 characters, for example, are available on an English keyboard.  And there isn't anything wrong with this notion of writing it down because, if we're going to use different ones for different sites, then we need to write them down anyway in order to remember which one we used where.



So I wanted to respond to everybody who was saying, hey, Steve, what do you think about this?  Wouldn't it be great if this was really secure?  My feeling is, well, if you want to use short sentences, make the words really obscure.



Now, the other thing that I didn't touch on is notice that, in the case of "this is fun," well, that makes grammatical,  semantic sense.  And that's another huge weakness of the whole sentence problem.  And that is, we didn't use "barnacle itch robbery" as our three words.  We used "this is fun."  And in all the examples that I've seen people sending me, their takeaway from this was...



LEO:  Use "this is fun."



STEVE:  Well, or...



LEO:  Something grammatical.



STEVE:  "I like tapioca."  Now, sure, it could be I hate tapioca, I despise tapioca, I slurp tapioca, I mean, you could have different things.  But notice, if you impose the filter of this makes sense, this is a grammatically correct sentence, now you have hugely changed the odds in favor of the attacker because, for example, in the case of a thousand-word vocabulary, a conversational vocabulary, a thousand times a thousand times a thousand, that gives you a billion, well, only a small fraction of those billion possible arrangements of three randomly chosen words make sense, would actually be a sentence.  And although we don't know that it exists today, we can imagine if this became in vogue that the extension of the classic dictionary attack would be the sentence attack.  It would be an English sentence-generating algorithm that chose words, starting with small, short small ones, and then ramping up to larger ones, very much doing sort of a brute-force sentence attack, which is completely possible.



LEO:  But what if, for instance, instead of using spaces in "this is fun," I used an arbitrary punctuation of my choosing, and something easy for me to remember, let's say "%," and I wrote "this%is%fun," it strikes me that we're not saying - Baekdal says it's computationally more difficult.  We might dispute that, but it's certainly difficult enough, isn't it?



STEVE:  I really think so.  Yes.  Anything you do to obscure.  Now, the other thing you can do, and we didn't talk about this, is case sensitivity.  You would want to make sure that the system receiving the password was case sensitive.  There are some, for example, that are deliberately not.  For example, I remember when I was talking about LastPass...



LEO:  Banks.



STEVE:  Well, but LastPass, the password is definitely case sensitive, but they deliberately lowercase the email address, which is the other portion of what you use to identify yourself with because email addresses are not case sensitive themselves.  So they felt that they would have a problem with users who might formally use a capital for their first letter of their name, if that appears in their email address, but then either use it or not use it when they were logging on.  And that ambiguity, since email doesn't care, they didn't want their system to care.  But yes, Leo, as you made a point, we know that there exist systems which are deliberately case insensitive because they want to ease the logon burden of their users, and in the process mess up their security.  So case is less strong, for example, than the use of...



LEO:  Punctuation or numbers or...



STEVE:  ...punctuations and numbers instead.  And in fact, you could also go hackeresque and use numbers instead of letters that look sort of the same.  But again, I mean, I guess my feeling is the bottom line is, if it is too memorable, it is too easy because it is its memorability - memorability?



LEO:  Yes, memorability.



STEVE:  Memorability.  That didn't come out right somehow.



LEO:  It's a word.



STEVE:  It is its memorability which we like, but to me that says somebody else could guess it.  Somebody else would have some reason to include it in some big corpus of things that they were testing against.  Now, the one thing that completely changes everything I've just said is that we're assuming knowledge on the part of the attacker that they don't have.  That is, no attacker knows anything about the scheme the user could have used.  That is...



LEO:  And it would probably be foolish for them to make assumptions about that.



STEVE:  Yes.



LEO:  Because it would...



STEVE:  Because there are an infinite number of schemes available.  So, and that's one of the things that Thomas did on his page that was a little misleading, where he talked about the comparative strengths of different passwords.  He showed, like, all lowercase as opposed to random symbols and said that the all lowercase one was weaker.  Well, it's only weaker if the attacker knew that your password was from a limited character set of all lowercase.  If the attacker didn't, and they still were having to try all possible characters in all possible character positions, then all lowercase is no weaker than random symbols because the attacker doesn't know what you've chosen.  So anyway, so my feeling is, yes, Leo, you could use words if you do something to obfuscate them, and the attacker will not know what you did.



LEO:  But there are the two issues, one of which you raised, which is that, if you use words, you're going to be tempted to use that password all the time, on more than one site, so that's a bad weakness.



STEVE:  You're going to be tempted to use nonrandom words in a sentence.  And as soon as you do that, wham, the strength of what you have done just collapses.



LEO:  Right, right.  So that's the same problem, essentially, which is memorability is anti-security.



STEVE:  It implies a weakness.



LEO:  Yeah, it's a weakness.  And then there's a second issue which the chatroom raised which I thought was quite astute.  If you use something that is a phrase, and somebody sees you type part of it, they are a lot closer to guessing your password than if you use random letters and numbers. 



STEVE:  Very good.  Now, and Thomas did, on his side, he made a point which I did like.  And he said, if you use words, you can probably type it in easily and quickly.  And it's like, well, okay, that's a good point.  You would be less prone to typos than if you're trying to type J4fS<2.  On the other hand, I've pretty much got that memorized by now, and I think all of our listeners have.  Don't use that one.



LEO:  And of course systems like LastPass, KeePass, 1Password, RoboForm, all use a master password which does not change.  That might be a good candidate for a passphrase that is memorable to you.  I tend to use longer passphrases than three words.  And I also like to put punctuation in, commas, exclamation marks, and I capitalize.  So all of that makes it more difficult to guess, especially if an attacker doesn't know I've used a passphrase.



STEVE:  And the one other thing that we've talked about before, but I'll remind our users, is never write the actual password down.



LEO:  On a post-it note, and put it on your monitor.



STEVE:  Well, no.  What I meant was, do something to it, like in what's written down.  For example, always leave off the first or the second characters, which you know to put on, but no one who discovered that written down would know.



LEO:  I actually do that.



STEVE:  They would, if they got a hold of your wallet that had your little post-it note in it, they'd go, ah, I've got all his passwords.  But when they try one, it wouldn't work, and they would have no idea why.



LEO:  And there's a scheme I'm sure that you could come up with that you would somehow modify your consistent passphrase with something like the name of the site that would make it recoverable.  I use SuperGenPass for that, where I have a master pass which it hashes, in a one-way hash, the master pass and the name of the site to create a unique password for the site.  All I have to remember is the master pass.



STEVE:  And then you're always able to regenerate that from that.



LEO:  I can regenerate that.  But ultimately LastPass, or KeePass if you like open source, is such a good solution because it creates strong passwords and memorizes them.



STEVE:  And when Thomas did this post back in August of '07, LastPass didn't exist.  And frankly, LastPass has solved all of my online logon problems.  There are some situations which are not online, where you can't have access to LastPass, and that's where this conversation, I think, is worth applying.



LEO:  Right.  His math, though, is not wrong at any point here, is it?  Or are there errors?



STEVE:  No, I think his math is right.  He just makes some assumptions.  And the comparative strength issues I take issue with because he says, as I indicated, like all lowercase is less strong than uppercase, lowercase, numerals, and symbols, which really is not the case.



LEO:  Got it.  Very interesting stuff.  I'm sure Thomas Baekdal would not disagree.  He says the password he uses on his server is a 40+ character completely random password.  He does not, and we should underscore this, use three words for offline sites.  Always, if there is opportunity for an attacker to, at his leisure, attack, this isn't going to work.



STEVE:  And the one thing I forgot to mention that I keep meaning to mention is that, relative to brute-force attacks, we talked last week when this came up about this notion of memory hard functions.  I also wanted to mention that, when we discussed WPA, the WiFi technology, these guys, because they did it with really good crypto in mind, they take the phrase, your login passphrase, and they salt it with the access point's SSID, which hopefully changes from one access point to another, that is, you did change your access point's SSID and did not leave it left to Linksys or D-Link or Cisco or whatever.



But then they hash it 4,096 times, not because doing it once isn't secure enough, but deliberately because they want it to take a long time so that it thwarts rainbow tables, both because it mixes the SSID as salt into the hashing function, but they do it 4,096 times so that there's a computational overhead for the actual production of the cryptographic key out the other end.  And so that's one way of dealing with the offline attack problem, by just making it much, you know, 4,096 times longer to get a key, which you would then test against the crypto algorithm in a WiFi scenario.  So really this is something that's been given a lot of time and attention because it's the way we authenticate, even today.



LEO:  Slow the bad guys down.



STEVE:  Yup.



LEO:  Steve, always fascinating.  We have links to all of this information in the show notes.  You have 16KB versions of the show, as well as the 64K full quality, and transcriptions available at your site, GRC.com.  That's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility, and lots of free utilities that Steve offers everybody for your security and convenience.



STEVE:  And something coming shortly called The Passcode Designer.



LEO:  Oh.  I like that.



STEVE:  That ties into all of this.



LEO:  Yeah.  So you'll find it, GRC.com.  Steve is @SGgrc on Twitter.  And next week we'll answer questions.  So if you've got questions or comments or suggestions - and Thomas, if you want to respond - just go to GRC.com/feedback, and the feedback form there will go straight to Steve's inbox, where he will comb through it.



Steve, so nice to see you.  Thank you so much.  We do this show every Wednesday morning, 11:00 a.m. Pacific, 2:00 p.m. Eastern, at live.twit.tv.  I hope you'll join us for the live show.  If not, you can always download it from Steve's site, our site, or anywhere finer podcasts are carried.



STEVE:  Thanks, Leo.



LEO:  Thanks, Steve.  We'll see you next week on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#298

DATE:		April 28, 2011

TITLE:		Listener Feedback #116

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-298.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 298, recorded April 27, 2011:  Your questions, Steve's answers, #116.



It's time for Security Now!, the show that covers your security and privacy online.  Boy, there couldn't be a better time to do a show like that.  Of course we started this show more than five years ago.  Steve Gibson has been the host ever since, from GRC.com.  We thought five years ago he might run out of stuff to talk about.



STEVE GIBSON:  Well, when you first proposed it, I was thinking, uh, boy, I wonder, you know, what are we going to talk about?  Will we have enough?  And here we are, Episode 298.  And, yeah, we've got a ton of information this week, really interesting stuff.  There was a breach at the Oak Ridge National Lab.



LEO:  Oh, boy.



STEVE:  Another spear phishing attack there.  And of course big in the news was 77 million users of the Sony PlayStation Network had all of their personal information lost.  So, funny that I have a new Attacks & Breaches section in our podcast.  I think that's going to be a busy section.  And all kinds of other stuff.  So and of course we've got a great Q&A episode this week.



LEO:  That's the thing.  I think if you invest, if you buy futures in insecurity, you're going to be all right.  It ain't going away.



STEVE:  God.  And it just seems that we see over and over and over where it takes a catastrophe for these companies to get a clue.  I mean, clearly, based on what Sony has said, and we'll be describing this, they're cautioning people that, if you use the same email address and password anywhere else as you did or do at Sony, you need to change that, too.



LEO:  Oh, dear.



STEVE:  Yes.  Which, I mean, all follows the best practices that we've been talking about for password management.



LEO:  I've got a problem, because I signed up for PSN probably three or four years ago.  I have - I don't remember what my password is, and I can't log into it, obviously, to figure it out.



STEVE:  Oh, just ask the hackers what your password is, Leo.  They have it.



LEO:  And I don't know what credit cards are on file with them or anything.  I mean, I haven't used it in years.  And yet presumably I'm compromised.  Holy cow.



STEVE:  Well, they said everyone, their entire network.



LEO:  Well.  And you can tell it's bad because they said we're not going to put it back up till we fix it.



STEVE:  Well, and they didn't even explain what happened for six days.  It just went off.  It was shut down.  And people were saying, hey, what happened to PlayStation Network?



LEO:  Finally they admitted that it was a breach, and we can't fix it, and we're going to start from scratch, they say.  So I guess, I take it this means that the passwords weren't hashed.



STEVE:  Precisely what I was going to say, is that not only - the passwords were not hashed.  So the bad guys got away with basically unencrypted data.  Nor were credit card information, expiration date, billing address, I mean, everything you gave Sony to sign up, they have acknowledged probably got loose.



LEO:  Jiminy.  That's terrible.



STEVE:  It's as bad as it gets.



LEO:  That's terrible.



STEVE:  77 million.  So clearly they were running this huge network with really very minimal concern for security.  It's like, oh, well, nothing bad has happened so far, so nothing ever will.  Anyway, it'll be interesting if we do learn more.  Right now they're being very mum about, like, what it is that happened, how it happened, who got in.  They said that they've hired a well-known, highly respected security firm to come in and do a forensic analysis and  tell them what happened.  So I don't know.  You've got to wonder who built this network that they aren't monitoring and managing the security themselves.  But anyway...



LEO:  Unbelievable.



STEVE:  Yeah.



LEO:  All right.  Let's talk about Oak Ridge National Laboratories.  What do they do at Oak Ridge?



STEVE:  They're a department of the U.S. Department of Energy.  And...



LEO:  The DoE is, by the way, a very highly security-conscious enterprise.  They have a - their DoE web page has all these recommendations for security.  For end-users.



STEVE:  Well, and here's the problem, is a phishing attack, a spear phishing attack, is extremely effective.  I'm going to quote from what the SANS Institute wrote because they had a really nice summary of this.  They said, "The U.S. Department of Energy (DoE) Oak Ridge National Laboratory in Tennessee has shut down email systems and employee Internet access following the discovery of a cyber attack last week.  The attack, which some have called" - here we go again - "an Advanced Persistent Threat (APT)" - we saw that with RSA.  What that meant was somebody opened their email.  It's a little less impressive when you look at the man behind the curtain.  It says, "...appears to have targeted Oak Ridge and several other national laboratories in the U.S."



LEO:  Oh, man.



STEVE:  Yeah.



LEO:  Is this our version of Stuxnet?



STEVE:  "The protective measures were taken after an investigation indicated that the attackers were trying to steal technical data."  You know, like, what, plans for nuclear weapons or something.  That's the kind of stuff we have there.



LEO:  Yeah.  This would be the most secure place in the world.



STEVE:  "Investigators believe that they stole less than 1GB" - oh, good - "of data before the attack was thwarted.  The attack gained its initial foothold on the laboratory system through spear phishing messages that appeared to come from the HR department regarding employee benefit changes."  So somebody opened their email.  "When the recipients clicked on the provided link, malware was downloaded to their systems.  More than 10 percent of the employees who received the message said they clicked on the link."  At least we have honest employees at the DoE.



LEO:  Well, 10 percent honest.  It could have been 50 percent.



STEVE:  That's a very good point.  10 percent honest.  "Just two of those machines became infected with malware that lay dormant for a week..."



LEO:  That's all they need.



STEVE:  "...before it started harvesting and sending data to a remote server.  Lab deputy director Thomas Zacharia says that 'one of [the] core competencies at the lab is cyber security research.'"



LEO:  It is.  If you go to the DoE page, this is a big thing for them.



STEVE:  Yeah.  Yeah.  So Eugene Schultz, who's an editor for SANS Institute, he wrote something in reply to this that I really appreciated.  He said, "Spear phishing attacks such as the one against ORNL invariably succeed.  Users are getting training concerning how to resist such attacks, but the training is not sufficient - it goes in one ear and [out the other].  More radical (and possibly somewhat potentially traumatic) training, such as inoculation training in which users are sent simulated messages and malware in training labs and loud noises go off if they open one of these messages, is needed."  Now...



LEO:  Wait a minute.



STEVE:  I think that's a bit extreme.



LEO:  Loud noises?



STEVE:  Okay.  But think about it.  One of the problems is, I mean, in a way I think Gene makes an extremely good point, which is there isn't any daily encounter that people have in the workplace with their employers testing them to make sure they don't click the link.



LEO:  Right.  We should do that.



STEVE:  I mean, that's brilliant, really.  I mean, think about it.  Large companies ought to - the security departments of large companies ought to be proactive in deliberately sending email which is spear phishing, that is, they know the employees, they know what departments they're in, they know what they're interested in.  See if, I mean, send them baiting email tied to an EXE or a script or something which runs that notifies the employee and headquarters that, whoops, a link got clicked on.  And obviously it's not malicious.  But, I mean, it's a test.  And if you even - well, so first of all, that would spread through a company like wildfire, the news that that was being done, and put everyone on guard.  And people who did click the links would have that experience.  We don't need loud noises going off, but they'd be like, oh, my goodness, that's what they've been talking about.



LEO:  I do kind of like the loud noises, though.  Here's an info graphic - this is from a website called KindSight.net - on the process of infection.  And so what's interesting is that it lay dormant for two weeks.  It's also interesting that only two people got bit.  Was that because you think they had antivirus software?



STEVE:  Or it could have been various patch levels.  It's that sort of thing.



LEO:  Ah, yes, of course, yes.



STEVE:  People clicked on it, but some people had - their machines were current.  And other people were more like me, oh, I'll reboot soon.  And they hadn't yet.  So, yeah.  But, I mean, so here it is.  The problem is we've got - and again, how is it that technical data of a protected nature can be accessed by some computer that's receiving email from the Internet?  I mean, just saying that, I mean, it's like RSA's problem where somehow the most critical, crucial data they had was available to, I think we heard it was a secretary who clicked on this email.



LEO:  The rich irony of it, I mean, this is DoE's website, their national security page, cybersecurity protection, managing operations security, preventing the spread of weapons of mass - these guys specialize in teaching people how to secure their businesses.



STEVE:  Yeah.



LEO:  This is what they do.  I mean, this is as bad as RSA.



STEVE:  So, I mean, the only thing I could imagine, when you think, when you put yourself in the position of someone clicking the link, they received an email that bore - probably had Oak Ridge National Laboratory letterhead stationery logo on it, looked absolutely legitimate, from human resources.  And they clicked on a link.  So that says that the only way to prevent this is for no one to ever click on a link in email.



LEO:  Thank you.



STEVE:  You just can't.



LEO:  I've been saying this so many...



STEVE:  You can't trust it.  It can come from your mom, or it can come from yourself or something.  I mean, there's just no - there's no way to trust the contents of email because it's all able to come in from the outside.



LEO:  We've been saying this for so long.



STEVE:  I know.  Yeah.



LEO:  It's really scary, frankly.  Because this is not just trivial.  This isn't a trivial website here.



STEVE:  No, no.  So breach number two...



LEO:  Oh, there's more.



STEVE:  ...of our new Attacks & Breaches section...



LEO:  Soon to be the longest section in the show.



STEVE:  ...is Sony's screw-up, as we were talking at the top of the show.  Basically they are saying that they had a network, a server, a database, something somewhere in which the detailed personal information of 77 million users, that is, all the people who were present in the Sony PlayStation Network, had a compromise.  They posted an FAQ, a Frequently Asked Questions.  And I'm going to quote from two questions from that that are most salient here.



Question #6, they're asking themselves, "Does that mean all users' information was compromised?  Tell us more details of what personal information leaked."  And the response is:  "In terms of possibility, yes.  We believe that an unauthorized person" - this is Sony speaking - "an unauthorized person has obtained the following information that you provided:  name, address (city, state/province, zip or postal code), country, email address, birth date, PlayStation Network password, login, password security answers, and handle/PSN online ID.  It is also possible that your profile data may have been obtained, including purchase history and billing address (city, state/province, zip or postal code).  If you have authorized a sub-account for your dependent, the same data with respect to your dependent may have been obtained.  If you have provided your credit card data through PlayStation Network or" - what is this, Qriocity, I guess, is their audio.



LEO:  Qriocity.  Yeah, that's, yeah, it's like a podcast.



STEVE:  It's related.  "So it is possible" - continuing from Sony - "that your credit card number and expiration date may also have been obtained."  And then Question #9 is:  "I want to know if my account has been affected."



LEO:  Well, don't log in.



STEVE:  Yeah.  Sony says, "To protect against possible identity theft or other financial loss" - love that opening - "we encourage you to remain vigilant..."



LEO:  [Laughing] Unlike us, apparently.



STEVE:  Yeah, we haven't, but we want you to.



LEO:  So now you have to.



STEVE:  "...to review your account statements and to monitor your credit reports.  Additionally, if you use the same username or password for your PlayStation Network or Qriocity service account for other unrelated services or accounts" - elsewhere on the Internet, they mean - "we strongly recommend that you change them.  When the PlayStation Network and Qriocity services are back on line, we also strongly recommend that you log on to change your 

password" at that time.



LEO:  We certainly do.  Another fine mess you've got us into.



STEVE:  And at the bottom was "Get your free credit reports here."



LEO:  What?



STEVE:  They provided the links and phone numbers to the three credit reporting agencies.  They're not taking responsibility, they're not paying for them, but they did mention that, as a - and they cited some law which said that, you know, required that these agencies provide free credit reports at least once a year.  So Sony said, if you're concerned, or in order to manage any fallout from this, you can, and we advise you to, pull all your credit reports and see if anyone has been making inquiries, trying to open accounts using this personal information.  Because they're talking about identity theft, of course.  And this is the mother lode of identity theft.



LEO:  This is stunning.  I mean, I don't know how it could get any worse.



STEVE:  I know.  And nothing encrypted, just here it is, folks.  It's probably in a big SQL database, 77 million people.  So...



LEO:  Boy, I wish we had those one-time-use credit cards still.  That would have been a perfect solution for this.



STEVE:  Yes, yes.  I mean, the good news is this gets a lot of press.  I mean, these things are generating press.  We talked about the Apple tracking, and we're going to come back to that here in a second.  But letters were written from Congress to Steve Jobs asking what exactly it is that Apple is doing.  And Sony has not stated whether they were storing their data in compliance with the formal regulations that the credit card industry has set up for the way this data is stored, one of them being it needs to be encrypted.  So it's hard to imagine that it was.  And again, I'll keep an eye on this and share any other information we learn about how this was perpetrated, how long the people were rummaging around in there.  But, I mean, I think we're probably, today, at the worst point we're going to be. 



LEO:  I hope so.



STEVE:  My sense is, yes, it can't - because it can't get much worse.  And we're all becoming extremely dependent upon our connectivity.  Here you and I before we began recording, we're talking about cloud services and stuff in the cloud and all of that.  So my feeling is these high-profile breaches have to have other CEOs, COOs, CFOs saying to their security personnel, tell me how this cannot happen to us.  Is all of this data encrypted?  Those questions have clearly not been asked until now, certainly not within Sony.  How is it that a secretary can open email and have access to highly confidential secret technical information?



There's architectural problems which underlie breaches of this kind.  It shouldn't be possible for this to happen.  So I think in time the architecture will change so that it's not.  Or so that it's radically more difficult.  This is just shooting fish in a barrel, apparently, because, again, this is now a weekly topic, major breaches that are occurring with clearly increasing frequency.



LEO:  I just have to think that - boy.  I hope it gets better.  But it's something that is so well understood already that I just have to think that companies are kind of accepting it.  They - just like, well, this is part of the price of doing business.  Somebody in the chatroom said, and I thought this was good, I wonder what the ratio of the amount of money Sony spent on lawyers in the last week is to the amount of money Sony spent on security experts to fix the problem.  And he says, I suspect they spent a lot more on lawyers. 



STEVE:  A very good point.  And you can imagine lawsuits will be flying.



LEO:  And I think that Sony and companies like this, and we know this about the banks, they just batten down the hatches, and they just say, well, it's the price of doing business.  Rather than have a real security policy.



STEVE:  And point at everybody else.  Well, look, everybody else is having problems.



LEO:  I hope it doesn't - my real theory is that it has a chilling effect on people using the Internet and eCommerce and everything else.  I mean, people are really going to think, normal people, not us, but normal people are going to really - well, actually, we will, too, think twice about giving people credit cards, things like that.  Citibank apparently still does those one-time-use credit card numbers.



STEVE:  Yeah.  I mean, it's almost worth getting an account just to have that.



LEO:  Just to do that.



STEVE:  Yeah, it really is.



LEO:  I want the one where you use it once, but it can be reused, as long as it's always the same company.



STEVE:  Yes, exactly. 



LEO:  So it would be Sony's number, and only Sony could use it.



STEVE:  Yes.



LEO:  I mean, I don't want to have to give a new credit card number every time I want to buy something, that's okay.  All right.  Thank you.  So, cheered me up.



STEVE:  So Apple responds to this whole issue that we discussed that was breaking news the morning that we recorded last week's podcast.  And I got a kick out of some of their responses.  Number 6 in their own Q&A was the question they posed to themselves:  "People have identified up to a year's worth of location data..."



LEO:  More than that.  Not just up to a year.  Many years.



STEVE:  "...being stored on the iPhone.  Why does my iPhone need so much data in order to assist it in finding my location today?"  And Apple's answer to their own question:  "This data is not the iPhone's location data - it is a subset (cache) of the crowd-sourced Wi-Fi hotspot and cell tower database which is downloaded from Apple into the iPhone to assist the iPhone in rapidly and accurately calculating location."



LEO:  Oh, that's interesting.



STEVE:  I don't think it's true, unfortunately, Leo.



LEO:  No, because I'll tell you what...



STEVE:  I know, my own data was me.  It wasn't a bunch of other people.



LEO:  It wasn't crowd sourced.  I mean, it's downloading it I guess from where you are, based on where you are?  I don't know.



STEVE:  So they're saying, "The reason the iPhone stores so much data is a bug we uncovered."  It's like the bars; right?  Remember the whole nonsense with the bars showing a strong signal when you were barely getting any?  Oh, that was a bug, and we're going to fix that.  So "The reason the iPhone stores so much data is a bug we uncovered and plan to fix shortly (see Software Update section below).  We don't think the iPhone needs to store more than seven days of this data."



LEO:  That seems true, yeah.



STEVE:  Okay.  Now, that was Question #6.  Question #7:  "When I turn off Location Services, why does my iPhone sometimes continue updating its Wi-Fi and cell tower data from Apple's crowd-sourced database?"  Answer:  "It shouldn't.  This is a bug, which we plan to fix shortly (see Software Update section below)."  So they're now claiming that this was a bug.



LEO:  That I believe.  And I also believe that it was a Skyhook-like attempt to collect data about WiFi access spot locations.  You know how Skyhook works.



STEVE:  Yes, which really does make sense.  It makes sense that they would turn their users, thus the term "crowd-sourcing," into mobile probes, which would be associating WiFi hotspots to cell tower databases.



LEO:  Exactly.



STEVE:  I mean, cell tower locations.



LEO:  They use Skyhook currently, but it's expensive, and they want to just create their own.  Just as Google has been creating their own with the street view cars.



STEVE:  Driving around all over the place, exactly.



LEO:  That makes perfect sense.  I believe that it was a bug because I don't see a lot of advantage to them saving it.  And to be honest, I feel like this is not the biggest privacy issue ever.  They should have absolutely let people know.  But, I mean, if you carry around a cell phone with a GPS turned on, don't you think a lot of people know where you are at all times?



STEVE:  Oh, yeah.  In fact, there was someone in Congress...



LEO:  Ed Markey of Massachusetts asked Apple for clarification.



STEVE:  Right.  There was that.  But there was a gal who sued her cell provider for her own GPS data and then posted the results, to demonstrate what it was that cell companies had.  And we know, for example, I mean, even if you didn't have GPS, our phone is logged into the...



LEO:  They know.



STEVE:  ...nearest cell tower.



LEO:  They triangulate cell towers.  They know exactly where you are all the time.  And they sell that information to law enforcement.  They have portals.  You don't even need to sue.  This is apparent.



STEVE:  Right.



LEO:  So I think it's, I mean, it's good, I mean, certainly people now know this and are knowledgeable about this.  But it shouldn't be a surprise.  I don't think - I think this is no more nefarious than Google's acquisition, accidental acquisition of unencrypted WiFi access spot data, and I would treat it the same way.  I think it's - however, in future, please let us know that you're doing this.  I think Apple says, well, you do, you agree to this when you - by the way, this is another little disingenuous piece from Apple.  When you first connect your iPhone, iPad, or iPod Touch, you get a box that says would you be willing to give anonymous data, return anonymous data to Apple to help improve our services, yes or no?  They say, well, that's the box.  That's when you opted in.  And if you don't want that, well, just either don't check that box or turn off location services.  You've opted in.



STEVE:  And I guess there is a question of proactivity.  For example, if after a week or maybe a month, when you next synchronized your phone, iTunes popped up and showed you a map of where...



LEO:  That's what should happen.



STEVE:  Yeah.  Then they would say, hi, just wanted to make sure that you understood that you've given us permission to send all this data back to Apple.  People would go, what?  Because we click on Yes now.  We've been trained because no one can read the fine print in this stuff.  And also they really weren't very clear about what it was that they were sharing.  And they always say, oh, it's anonymous, and blah blah blah, which it is, but it's not anonymous apparently when it's on your own computer.  I mean, when I looked at my computer, I was seeing what was clearly where I had been.  That is, the data on my machine.  So some of this doesn't really track with my own personal experience, which I checked on when this first - the story first surfaced last week.



LEO:  It doesn't pass the smell test.  And they took so long to respond to this, also.



STEVE:  Yeah, they really did.  And so in their software update section they've said, sometime in the next few weeks Apple will release a free - oh, free, that's nice - free iOS software update that:  One, reduces the size of the crowd-sourced WiFi hotspot and cell tower database cached on the iPhone; two, ceases backing up this cache; and, three, deletes this cache entirely when Location Services is turned off.



LEO:  Good.



STEVE:  So that's great.  That means for people concerned, you don't need to go digging around in your Mac looking for the consolidated.db file.  You just turn Location Services off, dock your phone, synchronize, and iTunes, after this free iOS update, will dutifully delete the cache for you.  So that's good.



LEO:  Okay.  I try to keep this blood pressure down here.  You've not done much to help.  What else?



STEVE:  In an interesting story, an interview in Politico, Jon Leibowitz, who is the Federal Trade Commission, the FTC chairman, singled out Google for not adopting the do-not-track header.  Computerworld reported that "Federal Trade Commission Jon Leibowitz this week singled out Google for not adopting 'Do Not Track,' the privacy feature that lets consumers," as we know, "opt out of online tracking by websites and advertisers."  And in their story they said, "Noting that Do Not Track had gained momentum, Leibowitz said, 'Apple just announced they're going to put it in their Safari browser.  So that gives you Apple, Microsoft, and Mozilla.  Really the only holdout - the only company that hasn't evolved as much as we would like on this - is Google.'"  So I just see this as good news because it is so trivial, so simple to add this to any browser that Google just needs to.



LEO:  I think they will.  But of course remember that their business...



STEVE:  Uh-huh.  They bought DoubleClick.net.



LEO:  Yeah.  I mean, this is their business is tracking you, frankly.  They own one of the worst offenders here, DoubleClick.  So, I mean, but I think that, nevertheless, it's going to be pretty obvious that they have to do this.  There's no way around it.



STEVE:  Yeah.  No browser will have it defaulted on, so everyone will have to be - have to turn it on.  But it'll happen.  And by the way, I forgot to mention that I have had for years, there's a page on GRC somewhere, actually it's on the ShieldsUP! menu of things you can do, which lets you look at your browser headers.  And it's trivial to go look there and see if the DNT: 1 is actually being sent, because GRC will show you.  So that's something that I had meant to mention.  Actually I have some other tech that I haven't put online yet - actually it is online, but it's not enabled by default - where I will be showing you up in GRC's menu header on the top of every page some of these privacy settings and alerting people if they're not taking advantage of them.  So, I mean, I'm going to get proactive with that.



LEO:  Good.  That's great.



STEVE:  Yeah.  So there was another interesting story that I got, I learned about through people tweeting me.  And I'll say again, thank you for everyone.  And believe me, I got deluged with PlayStation Network tweets.



LEO:  Oh, I bet.



STEVE:  And this is really interesting.  This is something that popped up on Nmap.org, the famous makers of the TCP scanner.  And that is something called a "split handshake attack" for TCP.  What was discovered was that it was possible to bypass the operation of many intrusion detection systems by something called a "split handshake."  I'll just read from the abstract of the PDF which is posted:



"Many network engineers might presume that the TCP three-way handshake is the one, inviolate method of establishing TCP connections.  A smaller percentage of engineers are also familiar with the little-used 'simultaneous-open' connection method of establishing TCP connections."  I would be among them.  "Researchers have discovered a third means to initiate TCP sessions, dubbed the 'split-handshake' method, which blends features of both the three-way handshake and the simultaneous-open connection.  Popular TCP/IP networking stacks respect this novel handshaking method, including Microsoft, Apple, and Linux stacks, with no modification.



"Given the novelty of the split-handshake technique, session-aware devices have had very little formal testing to determine their effectiveness in relation to sessions established in this way.  The authors audit a number of intrusion detection devices, NAT gateways, port scanners, and firewalls, and unexpected behavior was observed within each class of device and application.  This inconsistent behavior leads to the conclusion that such network-aware devices and applications should undergo more rigorous testing by their respective manufacturers in an effort to reliably detect malicious traffic, handle network address translation more effectively, and detect the presence of servers offering this form of session establishment."



Okay, so what does this all mean?  We've talked in the past, back in the dim history of the podcast, and will again when we refresh our series on how the Internet works, about how TCP functions.  We all know that a client that wants to open a connection to a remote server sends a so-called TCP SYN packet to the server, which is short for "synchronize."  In that packet the client provides a not-quite-random but definitely unpredictable sequence number.  Now, contemporary systems have very good unpredictability of sequence numbers.  But historically that was something that was not done well, and early attacks which are no longer effective took advantage of the fact that sequence numbers could be predicted.



So the client sends a SYN packet, a TCP SYN to the server, saying I want to establish a two-way TCP connection with you.  The server typically sends a SYN ACK back, which is acknowledging the receipt of the client's SYN and also sending its own SYN, that is, its own synchronization, with a 32-bit initial sequence number in that packet.  So that's used to establish its numbering of its packets.  And then the client finally sends and acknowledges the receipt of the SYN portion of the SYN ACK by sending an ACK back to the server, thus the three-way handshake - the SYN, a SYN ACK, and an ACK.



Now, the geniuses, the original geniuses that invented all this stuff realized there was the possibility of two machines on the Internet wanting to simultaneously establish a conversation with each other.  That is, it was possible that SYN packets might cross paths on the Internet, two endpoints, each sending a SYN to the other at the same time.  So the original TCP specification handles that gracefully.  It's called a "simultaneous open," where two machines send a SYN to each other, and then the other machine receives each other's SYN, and then they send back acknowledgements of each other's SYN packet and have established a connection.  So actually that's four packets transiting rather than just three, but it's called a "simultaneous open."



And in fact it is a trick, it's one of the main tricks used for penetrating NAT because in order to connect two clients that are both behind NAT routers, as we know, NAT routers do not allow incoming unsolicited packets.  So the trick is, you get each end, each of the end points that you want to connect through where they're each protected by a NAT router, you get them each to send outbound packets at the same time.  And what that does is the packets going out through the NAT routers conditions the NAT routers to accept return traffic from the proper IP and port.  So the packets cross over through the Internet and enter the NAT routers and allow you to establish a TCP connection.  So it's something which is well understood by people who really do understand the way TCP works.



What these guys discovered is that there is a third way, not the normal three-way handshake and not the simultaneous open, but a third way that also works, which is, and this is kind of tricky, the client sends its SYN to the remote server.  The server essentially ignores the SYN data, that is the client's sequence data, and does not send a SYN ACK.  Instead, the remote server sends a SYN, just a SYN, as if it was opening a connection to the client.  Because the client has got a TCP connection in the process of coming up, it accepts the SYN, even though it wasn't accompanied with the ACK, which the normal three-way handshake would.  In response to that, it says, oh, hmm, well, I got a SYN, but I didn't get the SYN ACK.  So it treats that as a dropped packet, and it resends a SYN, but it's also acknowledging the receipt of the server's SYN.  So what it sends is a SYN ACK, exactly as if a three-way handshake was going on, but initiated by the server rather than by the client.  And when the server receives a client's SYN ACK, it then acknowledges the receipt of the client's SYN, and the connection is open.  But it in every way looks like the server initiated the connection, not the client.



And what was discovered was that there is, there was network protection equipment which doesn't handle this correctly.  The IDS systems that are doing intrusion detection, they're set up to monitor and handle outgoing TCP connections.  When one comes back in, it's treated differently, and it turns out it allows bad guys to get around some of the protections and networks.  So that was just - that ran across my radar, and I thought that was extremely cool.



LEO:  The split handshake.



STEVE:  The split handshake connection.  I've got a person who tweets from time to time, who's also a blogger and a listener of the podcast, whose name is Andrew.  He has a site called AndrewTechHelp.com, and he wrote a nice article after we covered and announced essentially the introduction to Microsoft's Security Scanner, the so-called MSS, last week and sent me a little note saying, hey, Steve, I put together a nice article sort of explaining it if you want to share it.  So I just thought I'd tell our listeners, if anyone is curious for more information, he did a nice little write-up about why it's not an antivirus, how it differs from that.  And I was impressed with what he wrote, so I wanted to share that at AndrewTechHelp.com.  If you go there you just find the article about Microsoft's Security Scanner.  Currently it's right on his home page there.



LEO:  Great.



STEVE:  And then in TWiC - This Week in Clever, Leo - we have a new form of steganography.  Steganography is something we've actually never covered before because it's never impressed me very much.  I mean, it's the trick of hiding information like, well, sort of in plain sight.  For example, there's a - Wikipedia has a nice article where they show you a picture of a forest or something which actually contains a hidden lower-resolution picture of a kitten with a ball of yarn or something.



And the idea is, for example, if you have a 24-bit color photo, then you've got eight bits for R, G, and B.  But the fact is, our eyes don't really need all eight bits.  We wouldn't notice if the least significant bit in the various color bytes was off or on.  We wouldn't detect the difference.  So, for example, you could hide a black-and-white photo or a lower-resolution photo or actually digital information, it doesn't have to be a photo you're storing in a photo.  You could hide a file inside a photograph by encoding the files bits in the least significant bits of the photograph.



LEO:  So it'd be completely invisible.



STEVE:  And it works.  I mean, it absolutely works great.  I guess it never impressed me that much because the bandwidth is inherently limited, that is, the photo is going to be a certain size, so it's X by Y.  You've got X times Y, number of pixels.  And, for example, you only use the least significant bits of a 24-bit photo, then you get three bits times that.  So it's not a lot of data you're able to hide.  But clearly, I mean, apparently it has been used by spies.  And, for example...



LEO:  It solves that problem of having to pass a secret key.  So you don't have to put a lot of data in it, could just be the secret key data.  And then you could then pass data back in another form; right?



STEVE:  Well, of course it also solves the plausible deniability issue.



LEO:  Ah, yes.  It's just a picture.



STEVE:  I mean, exactly.  And you just post it on a website.  Or you post it to a photo aggregating site.  Or you stick it on your Facebook page.  Or, I mean, so it's in plain sight.  Somebody else gets it, knows how to strip the noise bits, the least significant bits out, and they've got a message.  So anyway, get this.  And this is why I think it's - that's why I called it This Week in Clever:  Disk drive steganography using deliberate fragmentation...



LEO:  Oh, clever.



STEVE:  ...of files.



LEO:  Love it.



STEVE:  And so think about it.  I mean, there is information in file fragments which is completely different from the file contents.  So we defrag our drives, which makes the files contiguous and packs them down at the front of the disk for maximum speed.  But if you then deliberately fragmented the file system in some clever way, that could contain information itself, the way the files were fragmented, while not altering the contents of the file system at all.  So the inventors of this have said that their method would make it possible to encode a 20MB message on a 160GB portable hard drive.



LEO:  That's quite a bit.



STEVE:  So that's a lot of data on a hard drive that would not - it would not be obvious to anyone inspecting the drive.  You would have to know that it was there.  Of course it's fragile because anything that changed any of those files would immediately destroy the fragmentation.  So you could imagine, if you needed to store less than, like dramatically less than 20MB, you could put in, like, redundancy and error correction and things to, like, even be resilient in the face of probably not a full defrag, but some change to the file system, your message could survive that.  So the fact that it was 20MB that you could store in a 160GB drive, I thought, well, okay, that's worth talking about.  So it's very cool and clever.



And I ran across something, I don't remember now where, about a widget for Windows 7.  And I now have a Windows 7 up and running.  In fact, we're talking through it at the moment.  I built it on this fast machine that I built so that we would have something for both this Skype and also for Vidyo, when we switch to that.  Anyway, I got a kick out of it, there's a widget, it's the "End of Support" widget for Windows XP.



LEO:  Is that like a clock that counts down?



STEVE:  It is.



LEO:  Oh, my god.



STEVE:  And I got a kick out of the fact that of course it doesn't run on XP.  So I'm not really sure what you use it for because in order to run it you've got to have Windows 7 or probably Vista.



LEO:  It should say "This system will self-destruct in...."



STEVE:  And I have to tell you, Leo, I seriously considered playing hooky for a day and writing a GRC end-of-XP-service-life app.



LEO:  For XP.



STEVE:  For XP, so that it could actually be sitting on people's XP machines.  Anyway, the good news is today, when I fired up Windows 7, we have 1,076 days remaining.  So I'm not going to start worrying yet about...



LEO:  It's Service Pack 3.



STEVE:  Service Pack 3, yes.  Service Pack 2 is lost, stopped being supported.  But Service Pack 3, 1076 days remaining.  So everybody else who's with me still on XP, and I know you're out there, we don't have to worry yet.  We have some more time.



LEO:  I wonder if they can say the number the days till next exploit.



STEVE:  Oh.  Actually that'd go negative immediately.  And red.



LEO:  And very fast.



STEVE:  And finally, this is my favorite anti-bot thing I've ever seen.  I don't know if anyone else has seen this, or Leo, if you have.  But I was filling - I was joining - oh, I know what it was.  I wanted to post - there was an AES encryption tool whose documentation wasn't very clear.  And so I wanted to write the author to ask him something about the way he was handling logon information or, like, password management, and also where he was getting his entropy because that wasn't clear.  And that's of course very important.  So but I needed to post on this forum.  And so I had to join in order to do that.  But I thought this was worthwhile.  So I filled out a form providing information.  And then there was an anti-bot measure, something to prevent bots from joining.  And I looked at it, I thought, uh-oh.  And it was a question.  What year was the Battle of Hastings?



LEO:  Now, this must be a British guy because every British schoolchild knows that answer, 1066.  But I suspect he's British because I doubt American school kids know this.



STEVE:  And come to think of it, in 10 days that will also be how long Windows XP has left.



LEO:  Coincidence?  I think not.



STEVE:  1066.  I think not.



LEO:  Now, is it always the same?  It must change.



STEVE:  That's exactly the question.  I was just going to say, I've been tempted to go back and, like, pretend to sign up again to see if...



LEO:  But that's better than CAPTCHA, I think.



STEVE:  It's great.  Well, it forced me to go to Wikipedia for it.



LEO:  To Wikipedia, yeah, very quickly.



STEVE:  Yeah, I had to go in, look up the answer.  But bots don't know how to do that.  So I thought that was just very clever.



LEO:  I like it.



STEVE:  Bravo.



LEO:  Only a human.



STEVE:  Yes, exactly.



LEO:  Who's buried in Grant's Tomb, they could have asked.



STEVE:  Hmm.



LEO:  I don't think a computer would know that.



STEVE:  Yeah, maybe not.  We do, though.



LEO:  We do.



STEVE:  So very quickly, a listener, Marek, wrote to say that SpinRite fixed a problem without even running.  And I thought, well, I haven't shared that little tidbit with our listeners before.  He's in Sweden.  And he said, "Hi, Steve.  Last week I brought over my computer to a friend of mine because we were having a LAN party.  When I got home later that weekend and booted up my computer, it was extremely slow.  It was practically impossible to work with it.  It would start up in about 10 minutes, 10 times longer than before, and it would get stuck while performing tasks like opening an application.



"After rebooting the computer a few times, I decided to use my copy of SpinRite.  While booting into SpinRite, SpinRite immediately recognized that the drive's SMART subsystem for some reason had been turned off.  So SpinRite automatically turned it on.  That surprised me.  So before proceeding to run SpinRite, I tried booting normally.  Bang.  Everything was back to normal.  I didn't need to run SpinRite.  The computer booted up just fine and worked as before.  Thanks for a great product."



LEO:  Sometimes the threat is stronger than the execution.



STEVE:  Oh, that's a good point.  The drive saw SpinRite coming and said, "Aaaggghhh.  Okay, I give up.  I'll behave."  Actually, there's a bunch of stuff SpinRite does because drives can get themselves a little tangled up.  There are sticky bits in many drives.  And among them is the SMART enable or not-ness.  And there's caching bits and error correction bits and things.  So one of the things SpinRite does is sort of straighten things out as it's sort of getting ready to go.  And that's all that was wrong with his drive.  So it wasn't actually a surface problem, it was just something in the sticky bits which SpinRite fixed.



LEO:  Now, somebody in the chatroom has given me - Stride (sp) in the chatroom has given me another CAPTCHA that you might like.  You'll have to turn around and take a look at your screen.  Just to prove you are human, please answer the following math challenge.  Calculate...



STEVE:  Oh, my god [laughter].



LEO:  I don't even know what the hell that is.  I think I'd have to fire up Mathematica.



STEVE:  Actually that would be a pretty good joke, you know, to have somebody - the thing that always annoys me is when you fill out a huge long form, and then you get to a CAPTCHA that you cannot read.  I mean, I'm definitely human.  And there are some that are just so nasty-looking, it's like, oh.  And sometimes you can say give me another one, but not always.  It would really be funny, like, to have some sort of a deal where you, like, you fill out this really long form, and you get down, and you get, like, one of those things that looks like some graduate study in nuclear physics.  And it's like...



LEO:  What the heck?



STEVE:  What's the proper answer?  And not multiple choice, because that would be cheating.  You've got to fill in the...



LEO:  Ah, here's one I could do:  Minus 3 minus 2 minus 5.  So it says, if you don't know the answer, just refresh.  You'll probably get an easier question.  And then it's a variety of very, I think in most cases, tricky math questions.  Find the least real zero of the polynomial P of X equals X squared plus 6X plus 9.  Come on, you remember your algebra 2, come on.



STEVE:  Okay.  We would do a - we do a factorization, and...



LEO:  Oh, he's going to do it.  Not necessary.  What is this page?  This must be MIT; right?  I mean, who could this be that would expect you to know that?  It is the Rudjer Boskovic Institute Quantum Random Bit Generator Service.  So there you go.



STEVE:  Okay.



LEO:  If you need a quantum random bit generator.  Is that a joke?  I don't - somehow it doesn't feel like it is a joke.  It's the Center for Information in Computing in Zagreb.  I don't even know if it's - what the name for - Zagreb used to be in Yugoslavia.  I don't even - I guess it's the - I don't know what country it's in.  That's a question.  I don't even know what country it's in.



STEVE:  Yeah.



LEO:  Where is Zagreb these days?  Is it Croatia?  I don't know.  All right.  Let's take a break.  Hungary?  No, not Hungary.  Where is Zagreb?  Croatia, all right.  Used to be Yugoslavia.  Not Ruritania.  We're going to take a break, come back with more.  Steve has questions and - actually I have questions.  Steve has answers.  And none of them are...



STEVE:  Our listeners have questions.  And now it's finally their turn to ask.



LEO:  Finally.  You can ask some CAPTCHA questions of Steve.  Somebody said "Elbonia."  I don't think so.



STEVE:  And we have 12 today because some of them are pretty quick.



LEO:  Oh, good.  All right.  Well, that'll be fun.  It's a famous institute in Croatia.  Okay.  Well, then maybe it's not a joke.



STEVE:  And it's got random quantum bits, apparently.



LEO:  Apparently.  That would be a - I guess you'd use that for a seed?



STEVE:  Oh, you'd def- no, you'd use that for, yes, or actually as a source of random numbers.  That's really cool.  I've been looking into it, too.  In fact, I don't know if I mentioned that that's one of the features in the little YubiKey gizmo is it has a true hardware random number generator using electron tunneling noise, which is one of the good ways to get real, I mean, real quantum-level uncertainty stuff.  So, yeah, very cool.



LEO:  And they do get some easier ones.  Here's 7 minus negative 7 plus negative 6.  That's, whew.



STEVE:  So you just click, you just keep clicking till you get one.



LEO:  Keep clicking till you get something that's not algebra 2 or calculus.  Trigonometry.  I don't even know what it is.  Twelve questions good and true, starting with Chuong Pham, who wrote a question to your support email address asking:  Thanks for providing ShieldsUP!.  That's the port testing service that Steve offers on his website, GRC.com.  However, I have one question regarding the user specified custom port probe option.  That's the USCPP.  Your website shows my port number 58529 as being failed.  It's not true stealth.  It's open, due to the fact that I've opened this port for uploading data.  Well, duh.  Well, yeah.  So that means it's open.  This is the nature of peer-to-peer, and Vuze - he's using something called V-u-z-e - uses this port for both downloading and uploading.



Now, if I disable outgoing traffic in my router for this port, then I can't upload any data.  Would it be possible for you to reevaluate the rules regarding P2P ports?  Other P2P apps use different ports from Vuze, so I assume they'll also fail, according to your website scan.  Interested in feedback.  Kind regards, Chuong Pham.  Well, Steve.



STEVE:  Yeah.  Now, okay, now I'm wondering why...



LEO:  I guess the answer's pretty obvious.



STEVE:  Yeah.



LEO:  An open port is an open port.



STEVE:  I did reply to him because he was confused.  And I said, look, maybe you're expecting ShieldsUP! to be somehow aware of the fact that you deliberately open this port, but that's not something it can do.



LEO:  Or should do.



STEVE:  Exactly.  There's 65535 possible ports, and he's using 58529.  So which I guess is the standard port for that.  One thing that I explained to him, though, was that - because he was asking, like, what vulnerability does this represent.  So I said, well, ShieldsUP! is confirming that unsolicited packets, because I deliberately send, the ShieldsUP! system sends its probes from a different IP than the one the user is visiting at GRC so that they are unsolicited and just like they were coming from anywhere else on the Internet.



And so I said that what ShieldsUP! is doing is it's demonstrating that unsolicited packets are able to get into his inner sanctum, essentially, through his router.  And I said, it doesn't mean that this is unsafe.  But if your - and this is the reason I wanted to bring this up for our listeners is just to remind people about changing, if you can, the default ports.  Because the point I made in my reply to him was that, if this is Vuze's standard port, which they tell you to open for peer-to-peer file sharing, then if at some point a vulnerability was found in the Vuze peer-to-peer system, that is, you give it a certain packet or you connect to it and then you in some way do something nonstandard which causes a buffer overflow, I mean, given how hard it is to make these things right, it's almost - it strains credibility to imagine that there isn't somewhere lurking in there some sort of vulnerability.



And the point is that, once that became publicly known, bad guys would immediately scan for port 58529.  Just as ShieldsUP! is showing that it's open, they would be able to find all the people using Vuze and then exploit that newly discovered vulnerability in order to do malicious things.  So really the lesson here is, if there's any way, I mean, it's like not using the password "password," or changing the name from "administrator" to something else on your system.  These are small things, but easy to do, which end up being the reason that some people are compromised and other people aren't.



So if you are able to reconfigure your peer-to-peer client, anytime you've got to have a static port open that is like the common port for a given utility, and ShieldsUP! confirms that it is open, that it sees it open, that's a problem because it does mean that if something were found that was wrong with that, and it was running on a standard port, the bad guys would scan.  It does not take that long, as we've been saying, to scan the entire Internet in IPv4 space.  That's one of the nice things about v6 is it becomes impossible to scan the entire Internet.  But we're not there yet.



LEO:  You gave a very long answer.  I would have just said, "Dufus, that's the point of ShieldsUP!, to tell you what ports are open."



STEVE:  Right.



LEO:  Period.



STEVE:  And he had to put that number in, also.  Because I'm scanning normally.  It was the user-specified custom port probe.



LEO:  Yes, it's open.  You opened it.



STEVE:  Right.  And I did explain that to him.



LEO:  I mean, that's - you're very kind.  I mean, and he's not a dufus.  I mean, that's a reasonable - I don't know if it's a reasonable question.  But this is what port testing is, is is this port open?



STEVE:  I guess what he was saying was, could you tell ShieldsUP! about Vuze...



LEO:  No.



STEVE:  ...so that - I know.  Yeah.  No.



LEO:  No.  In fact, maybe you should think about do I want to open this port.



STEVE:  Right.



LEO:  That's the whole point.



STEVE:  Right.



LEO:  I'm sorry.  You're very nice.



STEVE:  And it's the reason that we brought it up, because our listeners...



LEO:  I shouldn't - you're a gentle soul.  I shouldn't get upset.  That's a reasonable question.  But now you understand what's going on.  Why would you test a port to see if it's open when, I mean, and you're surprised that it says it's open?



STEVE:  Then you're going to love this next question, Leo.



LEO:  Oh, it's getting better.  Fortunately, this one's Anonymous in San Diego wondering why are you still using Windows?  Hi, Steve.  Love the show.  I've been listening for a little over a year now.  During that time, until now, I've been able to bite my tongue.  But I can't hold back any longer.  For the love of all that is holy, why don't you use Linux?  I think I asked Steve this in day one.  In your last Q&A show you mentioned how you would love to use BSD, and I suppose that by using Mac OS you are using BSD.  But why are you still on Windows?  I understand if you want to be successful in developing software you must test it on the OS that has the greatest market share.  And this is the good question:  Why use it for personal use?  In the same show you mentioned something about not wanting to be on the command line all the time.  Well, as I'm sure you know, there are probably close to a hundred different window managers and desktop environments for Linux/Unix:  Gnome, KDE, XFCE, Fluxbox, Openbox, Blackbox, and now Unity.  Please try it out.  This is, I think, an evangelist.



STEVE:  Yeah, I think so.



LEO:  There are great advances - and I love Linux.  I use it all the time.  There are great - so don't - there are great advances being made every hour - every hour - in Linux and BSD technology, and it's free.  I've been using Linux as my main OS since 2004, and I haven't looked back.  I was forced to do something on Windows 7 recently and found it very confusing and frustrating to use.  I think it would be great if you started a small segment of the show discussing Linux and Unix desktop security vulnerabilities because of course I know there's no perfect OS.  Thanks for everything.  I think that's appropriate.  Why don't you just use Linux?



STEVE:  I like Windows.



LEO:  Oh.



STEVE:  I don't like Windows 7.  I like XP.  Maybe someday I'll like Windows 7.



LEO:  But Steve, it's a toy operating system.  You said it.



STEVE:  It is a toy.  And, I mean, it really is.  No, I mean, I wanted to add this question today because we do get this in our mailbag a lot.  And it is - I guess it's a number of things.  First of all, anything I want is available for Windows.  Not everything I want is available for Mac.  On the other hand, not everything that's - there are some things for the Mac that are not available on Windows.



You may remember that I switched to using the Mac for some period of time when I was writing all the code for those machines that are over my left shoulder behind me.  All of that was on a PDP-8 simulator that was only available for the Mac.  So I dusted off a MacBook Pro and used it happily for some length of time.  So, and I've got a BSD server where our newsgroups live, and it's the DNS server for GRC.  And every time I touch it, I feel good.  It just feels right somehow.  And so the idea that Mac's got a real good Unix underneath with a very nice UI on top, to me I think that's probably my sweet spot.



But I know Windows inside and out.  I'm a Windows developer.  Anything that I want, like my little wacky Wizmo, which a surprising number of people like and use for turning their monitors off and rebooting and doing little utility functions, it's easy for me to whip these things out for Windows, much as I said I was considering doing a countdown for days left in XP's life.  So I'm a Windows developer and a Windows user.  And I've never been, knock on wood, been bitten by any of these problems that do catch out so many people because I'm a very careful Windows user, and I do not click links in email.  So it works for me.



LEO:  Well, and that's another answer which you've given in the past, which is how am I to talk about Windows security, how am I to be an expert in Windows security, if I don't use Windows?



STEVE:  Right.



LEO:  So you kind of have to.  I mean, it's not merely because you want to sell more copies of SpinRite.



STEVE:  No.



LEO:  In fact, it's not that at all because, I mean, it runs in DOS.



STEVE:  SpinRite boots itself, yeah, exactly.



LEO:  So it has nothing to do with that.  It has to do really with the fact that, if you want to talk about security...



STEVE:  Well, and Leo, if I want to affect the most people.  Frankly, my DNS Benchmark is incredibly popular.  I looked at the DNS page, I think 1,500 people a day look at that.  And about 500 of them are downloaded every single day.  Well, sorry, I mean, Linux exists, yes.  But Windows is where everyone is.  Windows, I mean, and the Mac, the Mac to a growing degree.  And when I wrote the benchmark, I did make sure that it ran under Wine for Linux and the Mac in acknowledgement that those platforms are growing in strength.  But still, I mean, by default, Windows is - it's ubiquitous.  So I want the things that I write to be able to help the most people.



LEO:  That's an interesting point because you don't make money on those freebies.



STEVE:  No.



LEO:  And you know how to develop for Windows.  You're not a Mac developer or a Linux developer.  And that's just what you know how to do.



STEVE:  And frankly it would be a huge learning curve.  I mean, it's not small...



LEO:  No, it's not trivial.



STEVE:  ...to switch platforms.



LEO:  For instance, SpinRite, which uses INT 13, has to be on BIOS.  You're using a BIOS call.  You would have to duplicate all that functionality on EFI.  And I guess you could do it in Linux, wouldn't be so hard.  But it still doesn't run in Linux, it runs perfectly well on a Linux box in DOS.  You just put the - you create the boot disk, you stick it in, it's running on FreeDOS, and it just runs, so that's fine.



STEVE:  Well, yeah.  And you often see multiplatform things that just aren't very good.  I mean, for example, they make you install Java because they're written in Java.  And it's like, okay, they work.  But they're just - they don't feel like they're - it's like, because they want it to run anywhere, they don't really run anywhere very well.  And it's like, eh, that's not a tradeoff I want to make.  I want to make really, really good stuff for Windows.  And increasingly acknowledge that it's not the only solution in town, and put some time into supporting other platforms, as well, as I have.



LEO:  I begged him to write, I begged him to write, to rewrite SpinRite to work on the Mac.  But no.



STEVE:  Not quite yet.



LEO:  No.  But that's fine.  Because I just take the drive out, put it on a PC, and run it.  It works fine.



STEVE:  Yeah. 



LEO:  Friedrich H. Burkardsmaier, who lives in Thailand, just to throw you a curve, wonders about virtual keyboards and form grabbing:  Steve, one of your recent episodes you recommended the use of a virtual keyboard to enter passwords so they can't be intercepted by keystroke loggers.  My concern is that passwords could still be intercepted by something called a "form grabber," once the virtual keyboard has been used to fill in the form.  In other words, you are submitting it, frankly.



STEVE:  Correct.



LEO:  I would appreciate it if you could elaborate on this topic.  How are form grabbers implemented?  Are there effective countermeasures a user can take?  Thanks for the excellent software and for the great podcast.  I always look forward to listening to every episode.  Friedrich Burkardsmaier.



STEVE:  So, okay.  So what he's saying is that he recognizes that a virtual keyboard, like a keyboard on the screen which you click with the mouse, will avoid a hardware keystroke, and actually hardware and probably software keystroke logger; but that, once you've used that to fill out the form, when you submit the form, there's this possibility that the contents of the form could be grabbed by some malware running in your machine.  And he's absolutely right.



As we've said before, the web was originally a content delivery system.  So the concept of interacting with web servers interactively, that is, sending data back, posting things, this was all something that was sort of an afterthought.  And in fact the design sort of demonstrates that.  One of the ways that data is sent back, sort of the most ugly way is you make a request of the server, and you add the data to the end of the URL.  So it's whatever, blah blah blah blah, dot html, question mark.  The reserve symbol question mark specifies that this is the end of the URL and the beginning of additional data, that is to say, form data, which is then tacked on the end.  It has uses because it allows you to, for example, save search queries in shortcuts because a shortcut is just able to save the URL.  So there are some advantages to it.



But the problem is anything that sees what you're submitting is able to look at your forms.  And the alternative way of submitting data basically just has the data after a space line under the submission headers, you just list all of the data in all of the fields in cleartext, and off it goes.  It doesn't get encrypted, of course, until it goes into SSL.  So the form contents itself is in the clear.



In thinking about the answer to his question, the only thing I could imagine that would solve this would be scripting, which would run in the browser client, which would intercept the Submission button, and that's easy to do in JavaScript, preventing the normal browser behavior.  It would then take the data from the form, encrypt it well, and then submit that.  So it really needs to be - it needs to be a service provided by the page containing the form that you're submitting.



And so that would be, since it's a service provided by the page of the service you're submitting the form to, it would be, for example, LastPass, they do this.  For example, they've got script running in the client that encrypts the stuff at your end before it ever goes over the wire.  And so it's certainly possible that that could be done, although today the number of services that do that are - you could probably count them on one hand.  So we're a ways away from having security from that kind of exploit.



LEO:  Question 4, Andrew in Tucson, Arizona wonders about IPv6 support for your program, ShieldsUP!.  Can you add - I feel for you, Steve.  Can you add IPv6 support for ShieldsUP!?  Most operating systems lack an easy way to view if an IPv6 firewall is enabled or to easily check what rules are applied.  For instance, OS X lacks an accessible IPv6 firewall.  But ShieldsUP! is not a firewall, first of all.



STEVE:  No, but of course it does test yours.  And I'm getting an increasing flux of questions about IPv6.  I don't know if it's because we're talking about it so much on the podcast, or people are increasingly getting ready to use it, and they want something to verify what their ports are that are open.  The good news is I'm moving toward that pretty quickly.  I've got hardware on order.  I've got IP networks are being added.  And it looks to me like it's not going to be a really huge problem.



The architecture that I created - ShieldsUP! is, I think it's in its maybe third iteration.  And I really had figured out how to do it by the third try.  That was that NanoProbe edition that I came out with a few years back.  And it's just - its implementation is so clean that I can add the IPv6 layer to it without much trouble.  So I don't have an ETA.  I don't work with ETAs, as everyone knows.  But it's definitely on my radar.  And I like the idea of being out there early and maybe even exclusively with a good port tester for IPv6.



LEO:  Cool.  Joshua Gardner, San Antonio, Texas, wonders about Memtest86.  Oh, I remember Memtest86.  That's a blast from the past.



STEVE:  Yep.



LEO:  I was fumbling around on the web, found this nifty open source program, Memtest86.com, for testing RAM.  It appears to be quite extensive in what it tests and the patterns tested.  I was just curious if you've heard of it, and your thoughts.  Finding a way to actually test memory and give it a conclusive good or bad status has been a real challenge.



STEVE:  And you're right.  Memtest86 has been around since, not surprisingly, the 8086, which is where it got its name.  It turns out it's tricky to test memory.  And as you could imagine that, being a hardware-level guy and the author of SpinRite, at one point I sort of thought, hmm, maybe I ought to get into the memory testing business also.  The problem is that, if I found a problem in a bank of RAM, the user would want to know which was the bad SIMM.  And I mean, anyway, there's really no way to tell.  There's no way to accurately, especially these days where SIMMs are paired, and there are DIMMs, and there are quads, and it's, like, very complex.  There's no way to be able to say, oh, on your motherboard it's this one over here.  So I just decided not to do my own GRC-style memtest.  And there is a good one that already exists, and that is this Memtest86.  It's not as simple to test RAM as writing some data in and then reading it back out because - and you'll remember this from the old days, Leo - core memory used to have something called a "checkerboard test." 



LEO:  Right.



STEVE:  And it was because it turns out that not all data which you would write into core memory was equally easily read back.  And so it actually, that introduced the notion of ways you could read and write that induce the maximum amount of noise in the core memory system and best tested the one and zero discriminators.  Turns out that RAM bears a strong relationship to that.  That is to say that the way memory, the way dynamic memory tends to fail is that adjacent bits improperly influence each other.  So, for example, you want to write a one into a given bit, and then write zeroes into all of its neighbors and see if the writing of zero into its neighbors influences the one that you stored.  And then you want to write a zero there and write ones into all the neighbors and do that.  And you can imagine, it's extremely difficult and time consuming.



So bottom line is, Joshua and all of our listeners, Memtest86 is a terrific program.  It runs standalone.  It's bootable.  It's free, open source.  You can download an ISO you burn to a CD, boot a machine, and just let it crank away.  And when I've had some strange, hard-to-diagnose problems, that's what I've used in order to see whether all of my RAM is working.  And it's also a great exercise if you're working on, like, tweaking your system and wanting to get the maximum speed out of RAM, this is a good way to see whether, without all the other layers of OS and everything confusing things, if the RAM itself is being pushed too hard, based on the wait states and speed that you've told your fancy BIOS to run.



LEO:  There is an updated Memtest86.  It's called Memtest86+ at Memtest.org.  That's probably where I would go to get it, as opposed to the URL that Joshua mentioned.



STEVE:  Is it Memtest86.org?



LEO:  It's Memtest.org.  But it is...



STEVE:  Okay, good.



LEO:  It's basically what's happened is that the guy who wrote Memtest86, Chris Brady, stopped adding, developing it.  And so there was a team that took the open source and updated it.  Its open source, GPL, and so it's free.  And you can see everything that they've done.  And it just makes it more up to date.



STEVE:  Yes, good.  It's funny because he put Memtest86.org.  And I went there first, and I saw, like, an abandoned pseudo search site.



LEO:  He was confused, I think.



STEVE:  Yes.



LEO:  So there is Memtest86.com, but that hasn't been updated since 2002.  Memtest.org, no 86, just Memtest.org is the fresh version.  Same idea.  Same source, basically.  Just updated for modern OSes and so forth.  Actually  probably not OSes, modern hardware, I guess.



STEVE:  Yes.



LEO:  Kai Franke in Germany would love to use Seagate HDD hardware encryption.  It's built in, of course.  Steve and Leo, I'm a long-time listener of your show, very security concerned.  My question, is TrueCrypt's whole drive encryption as secure as Seagate's HDD hardware encryption?  Ever since your TrueCrypt episode, I've been using TrueCrypt all the time.  And right now I'm using whole drive encryption on my Netbook.  But encryption/decryption is of course CPU intensive, needs more energy, reduces my battery life.  I didn't even think of that, but I guess it would.  Because the Netbook includes a 250GB Seagate hard drive, I looked around on their web page to find a bigger, faster drive with lower energy consumption, and I found a drive that supported hardware encryption.  Wouldn't that mean I don't need a CPU-hungry TrueCrypt anymore?  Best regards, Kai Franke in Germany.



STEVE:  Well, the problem is, with just swapping an encrypted hard drive for one that isn't, is that you absolutely have to have BIOS support.  And it's in some laptops, but I don't know about a random Netbook.  You can check your BIOS.  If you can get into the BIOS of your Netbook, see whether it talks about a hard drive password.  And it's not clear, I mean, you'll need to see whether it's just a standard BIOS password or a hard drive password or hard drive encryption.  Normally they'll make it clear that it's hardware, there's hard drive encryption, because it requires BIOS support because the first thing that happens when the laptop powers up is it has to provide the encryption password to the hard drive that normally comes from the TPM, from the Trusted Platform Module.



So you normally enable the trusted platform module, and then it contains the password for the hard drive's hardware encryption.  But unfortunately it is not as simple as dropping a hardware-encrypted drive in anywhere and just having it work.  And it definitely needs to have a hard drive password in addition to probably the trusted platform module.  And, for example, on most mainstream motherboards, we still don't have a hard drive password.  But laptops typically do. 



LEO:  Oh, that's interesting.  By the way, now they're telling me, oh, no, Memtest86.com has been updated.  So try one or the other.  It's probably exactly the same.



STEVE:  Yeah, they're free.



LEO:  Yeah.  Brent in Central Illinois is confused about the RSA attack we talked about last week:  Steve, additional details have now been released.  CNET had a story.  They said that the RSA attack was due to a phishing email that exploited a Flash vulnerability?  Flash displayed in an email?  Crazy, huh?  Anyway, I'm not really clear exactly how they got infected because they said the email had also attached an infected Excel file.  So Flash loaded the infected Excel file, which infected the system?  Is that how it worked?  Please explain.



STEVE:  Well, I thought this was important enough just to quickly touch on this and explain that Brent is right in being confused, that it's sort of the other way around.  And we see this over and over and over in spear phishing sorts of attacks.  The vulnerability is in Flash.  That's the culprit.  But in order to get Flash to run, because typically email won't run it, it needs to get encapsulated in something else.  And typically users need to be coaxed into opening something.  So it's generally a, for example, a Microsoft Word document or an Excel spreadsheet.



And that was the case in the RSA attack.  It was an Excel spreadsheet which was opened by a link in the email.  And embedded in the Excel file was the Flash exploit.  So it's the document that contains the Flash exploit which is executed by either Word or Excel, they being the carriers.  So don't open those.



LEO:  Don't open attachments.



STEVE:  Don't do it.



LEO:  Don't click links in email.  Don't open attachments.  Knock it off.  Steve Holmes in Lake Forest, California found a terrific Bitcoin podcast episode.  Here's an FYI, we did a whole show on Bitcoin.  He said he listened to the April 4 EconTalk podcast interviewing Gavin Andresen, a principal of the Bitcoin Virtual Currency Project.  That podcast is at EconTalk.org.  And they talk about Bitcoin, the origins of it, how new currency gets created, how you can acquire bitcoins, prospects for Bitcoin's future, could it eventually replace government-sanctioned currency?  How can users trust it, what threatens it, and how it might thrive.  Thank you, Steve.



STEVE:  Yeah.  I wanted just to share that with our listeners.  There's been an enduring interest in Bitcoin...



LEO:  No kidding.



STEVE:  ...back ever since our podcast.  So it's EconTalk.org.  You'll have to scroll down.  They've got a number of podcasts.  It's very nice.  It's about an hour-long audio podcast.  The date is April 4.  And it's a not-so-technical interviewer interviewing Gavin, who is a coder, and technical, and really understands this stuff and does a really nice job.  So if anyone wants any additional dip into Bitcoin, I wanted to bring it to our listeners' attention.



LEO:  A dip into Bitcoin.  Michael Dombrowski in Washington, D.C. wonders about Do Not Track and Google Analytics:  You were talking on Episode 295 about DNT, the header that tells a browser - actually that a browser uses to tell a site not to track it.  You said the U.S. will most likely eventually make it illegal not to honor a do-not-track request.  I hope the tracking is clearly defined, however.  As someone who runs a few sites, I need to know how many people visit my site and what posts do the best.  I hope that tracking is defined as tracking a user as they surf from site to site, not as they browse a single site.  Products by Google Analytics are greatly helpful to me as a site administrator.  I use Google Analytics, too, actually, among others.  I also use Quantcast on our sites.



I can only hope that the bureaucrats - in fact, if you download this podcast, you go through a little track.  I can only hope that the bureaucrats do not make this all about political parties and also think about the implications any law they pass will have.  Thank you for all you do for the tech and security communities.  And he says, can I pimp my site:  UnblockedAlways.com.



Hey, let me ask you.  I didn't even think of that.  We track, in a sense.  The only way we can tell advertisers how many people have listened to this show is, if you look at the URL for the show, it filters you through a site real quickly, the Podtrac site, and that's how we count how many downloads we've had.  And they do a lot of stuff.  I mean, it's not just like, oh, one, two, three.  They compare the IP address that you're coming in from to a database of IP addresses.  They make sure it's unique, they make sure it's real.  We do a lot of stuff with that.  Would we be affected by this?



STEVE:  It's a really good question.  And Michael raises a good point.  I hope that we don't see overreach in what the Congress does.  I have to imagine there'll be hearings, there'll be people really arguing against this being too pervasive or too onerous.  And the clear distinction will be made certainly between first-party and third-party tracking.  I think we pretty much understand what it is that we don't want.  And so we just need to get legislation that does a good job of encoding that into legal jargon.



LEO:  It's kind of scary.



STEVE:  I know.  Let's hope we - yeah.  Because, I mean, I don't know whether...



LEO:  It is third-party tracking for us.  You go to our site, or you go to iTunes, and it goes through the Podtrac site briefly.



STEVE:  Yeah.  And they are getting people's IPs.  We know that they don't care, that they're not aggregating them and so forth.



LEO:  We do.  We don't collect them.  We don't even aggregate them.  We just compare it to a database and say, oh, this is a real IP address.  And I guess we'd have to collect them to see if it's unique.  So I guess for each show it does make, you're right, it makes a database of who's downloaded it, and we just compare it to - because otherwise, if you download it 20 times, advertisers don't want us to count that as 20 impressions.  It counts as one.



STEVE:  Well, okay.  So I think that one of the problems we're going to have is that just a single DNT header with a single on/off switch is going to be too coarse.  What could happen, for example, is that, if this legislation were enacted, and it were decided that, for example, Podtrac was - oh, gee, that's what second syllable in their name?



LEO:  T-r-a-c, yeah.



STEVE:  Yeah.  If Podtrac was tracking, then what would happen is, if they received a link, which they would normally redirect, which contained the DNT header, they'd have to instead give you a page and say, we're sorry, you've come to Podtrac.  Here is our privacy policy.  Here is why you've come.  This is what we do and why you have visited us.  Please make an exception for your DNT header for us so that we are able to forward you to the material you want.  Or that page could just show the direct link that you would be forwarded to, and you could click that instead, if you manually didn't want to be tracked in that given instance.  So there are workarounds.  But I really do think that there will be instances where people essentially need to or want to give permission for some clearly defined delineated reasonable tracking, essentially.



LEO:  You can see why this is a complex issue.  I mean...



STEVE:  Yes.



LEO:  It would put us out of business.  Guillaume in France wonders about the SSL OCSP protocol.  Steve, I'm an engineering student in computer science, a GNU/Linux user, and listener since December 2010.  I watched your last Security Now! podcast and was concerned by the SSL authority breach.  The OCSP protocol is used to check the status of certificates, and the default behavior is, if OCSP fails to get a certificate status, it is assumed to be valid.  So it's kind of upside down.  However, this default behavior can be changed, at least in Firefox 4.  Go to Option > Advanced > Encryption > Validation.  There you can check a box to assume that certificates are invalid if the OCSP status check fails.  Thanks for the show.  Guillaume.



STEVE:  So, yeah.  So I wanted just to bring this up to our listeners.  We didn't talk in detail.  OCSP came up briefly when we were talking about SSL revocation a couple weeks ago.  OCSP stands for Online Certificate Status Protocol.  And the spooky thing about it is that it potentially represents a privacy compromise because the way OCSP operates, it's not a revocation list, which is the alternative approach.  Instead, when enabled, your browser will manually, I mean, deliberately connect to a verification server every time you visit a site with a certificate.  So the certificate can contain a URL saying here's a URL of our OCSP server if you want to verify.  And so you can - and then there's another setting, for example, in Firefox, and this also is in prior to version 4.  It's in 4 and also in the 3 Firefox chain.  And that allows you to override the certificate's statement and always go to a specific OCSP server, which can sometimes be useful.



And the problem, though, is that essentially what that's doing is, everywhere you go that is secure, your browser is sending a beacon out to whatever OCSP server is specified that inherently contains your IP because it's establishing a connection in order to verify that the certificate is currently still valid.  So it's a nice technology inasmuch as it does allow for realtime verification of certificates.  The problem is that it also allows for this OCSP server to know that you're going to that site.



The reason it currently fails in the wrong direction, that is, if you, for example, if the OCSP server didn't respond, Firefox and all the other browsers that support this fail open.  That is, they just go, okay, well, we don't know that it's bad.  So since we haven't heard anything, we're going to assume it's good.  That's the behavior that can be inverted, and I think it probably makes sense to invert it.  One of the concerns with OCSP is that, if an OCSP server were under a denial of service attack, or had a network outage or whatever, then if browsers failed hard, then suddenly all the certificates that were referring to the OCSP server would refuse to connect.  And that would be really bad.  So again it's like, well, we want the security, but we don't want too much because that might get in our way and bite us.



LEO:  Last question for the Gibson, from Li in Houston.



STEVE:  Oh, and this is good.



LEO:  He mentions a Firefox plug-in called Certificate Patrol:  For expert users like us and your listeners, it's a great help.  It alerts when SSL certificates change by comparing and displaying the old and new certs side by side.  My employer probably won't be able to start proxying my communications without my noticing.  Ah.



STEVE:  So this is exactly what I said I wish we had.  And Firefox does have it.  I did some poking around looking for one and didn't use the right keywords, I guess.  But Certificate Patrol.  I have found it and downloaded it.  And I'm impressed with what I've seen.  For example, it will even - it's built some intelligence in.  So the first time you go to a site to which you have never been, that is to say, when it's going to be caching the certificate for the first time, it stops you and shows you the certificate and says, hi, here's a chance, we're about to put this in the cache, so make sure this looks good to you so you don't initially cache a bad one, and so you don't go to a site through, like, a bogus certificate chain the first time.



Then when I talked about it being a little intelligent, it will notice, for example, if a certificate has been reissued after the prior one expired.  So it's smart enough to say, oh, just by the way, the certificate for this site you're visiting has been updated because the prior one expired.  So it'll see that the one it had in its cache before had expired, see that it's being now given a new certificate with a different serial number, since every certificate has a different serial number, and lets you know what's going on.  I think this is a great solution.  And if you did go to a site that had a bogus certificate, or there was a man-in-the-middle attack going on, or your employer was setting up a proxy, or any of those things, this thing would warn you.  It's exactly what we want.



LEO:  So Google "Firefox Certificate Patrol," and you can find that add-on and install it.



STEVE:  Yeah.  And there was one comment from someone who posted, saying that it actually did work.  His employer was adding a web proxy, and because he had Certificate Patrol installed, it alerted him.  Hah hah.



LEO:  Hah hah.



STEVE:  All we want is control.  That's all we're asking for.  We just want to know what's going on.



LEO:  Please don't not track us.  Don't let us not - I don't want to go out of business.



STEVE:  It'll be okay, Leo.  I'm sure our listeners will make an exception.  But we're going to have to have - it's very much like NoScript, where scripting is disabled by default, but then you enable it for sites you trust.



LEO:  Yeah.  That'll basically kill us because most people won't enable it.  It'll just - it'll be dead.



STEVE:  Well, no, but, I mean, if it's dead, then - I don't know what.



LEO:  Well, and that's the whole issue about tracking.  And I'm sure it's one of the things Google is thinking, is...



STEVE:  Oh, I know what it is, Leo.  They'll come to TWiT, and you will see if their DNT header is on when they...



LEO:  I will say, "No podcast for you." 



STEVE:  Then you can explain, you say, hey, sorry about this, I hope this is not an inconvenience, but we need you to make an exception to DNT for the following URLs in order for the podcast to be available.  So it'll be possible to intelligently handle it.



LEO:  It'll put us out of business.  I guarantee.  Because people just, they don't do that.  They just go, oh, never mind.  Bye.  Oh, that's okay.  We'll worry, we'll cross that bridge when we come to it.  There may be other ways to measure without tracking, and I guess we'll have to find those ways.



STEVE:  Actually there are.  I mean, you could do it yourself.  It's a convenience for you that you're bouncing through a third party.  But...



LEO:  Well, advertisers demand it, of course, because advertisers don't want numbers from us because we could lie.



STEVE:  Yeah.  But you could put some script, you could do a Google Analytic-style thing where you put some script on the page that would - it would still be giving control to a third party, so.  There are probably ways to do it.  Maybe that would still be illegal, I don't know.



LEO:  That's the issue.  And I think that that's really something to think about.  Those are the unintended consequences of not tracking.  If you're an ad-supported network, and people use ad blockers, it ultimately puts you out of business.  And it's the same thing.  That's why it's a larger conversation.  But I'm not going to worry about it.  I'm a bullish optimist.  Or maybe I'm just...



STEVE:  I think too much of the Internet is running on, I mean, with benign tracking.  So it's benign tracking, nobody minds.  It's having personal information aggregated that is the biggest problem.



LEO:  Oh, I agree.  I agree.  But I don't think that these tools and laws make much distinction.



STEVE:  We'll see.



LEO:  Yeah, I'm not going to worry about it.  If we go out of business, we go out of business.  I can get that boat then.  Thank you, Steve.  A great show, as always.  Now, next week we don't - do you know what we're going to cover?



STEVE:  Believe me, too much happens in a week, Leo. 



LEO:  It's hard to say.



STEVE:  Who knows what's going to happen?  But I've got a whole list of things to talk about.  So if nothing else comes up to preempt, then I'll pull from my list and we'll have another great podcast.



LEO:  You bet.  And by the way, if you have questions for Steve, we'll be doing questions and answers again in a couple of shows.  Go to GRC.com/feedback.  While you're there, pick up a copy of SpinRite.  Everybody should have that.  If you've got a hard drive, you need SpinRite, the world's finest hard drive maintenance and recovery utility.  Also lots of other freebies, including, as we mentioned, ShieldsUP!.  But there's also Wizmo.  There's toys, there's security, there's everything.  It's a great site:  GRC.com.  You'll find show notes there, transcriptions of each and every show, all 298 episodes.  We're going to be Episode 300 in a couple of weeks.



STEVE:  Yeah, we are.



LEO:  And of course Steve does 16KB versions for the bandwidth impaired, as well:  GRC.com.  Steve, thanks, as always, and I'll see you next week.



STEVE:  Talk to you then, Leo.



LEO:  On Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#299

DATE:		May 5, 2011

TITLE:		Going Random, Part 1

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-299.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week's security news and events took up so much time that we didn't have time to cover the entire topic of "Randomness" in security and cryptography.  So we split the topic into two parts.  This week we open the topic and explain the background, problem and need.  Week after next we'll plow into the solutions.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 299 recorded May 4, 2011:  Going Random.



It's time for Security Now!, the show that covers your security and privacy online with this cat here, this man, Steve Gibson of GRC.com, the Gibson Research Corporation.  He is our hero, our knight in shining security.



STEVE GIBSON:  I'm a cat this week.



LEO:  A cat.  Yeah, I'm hep now.  I've turned hep.



STEVE:  Yeah.  Very cool.



LEO:  That was a little Sammy Davis, Jr. channeling there.  Hey, Steve, how are you today?



STEVE:  Hey, Leo, great to be with you again, as always.



LEO:  Thank you.  Today we're going to cover a subject that's kind of fundamental to, not only security, but computers in general.



STEVE:  It was something we have - we've touched on many times in the last five and a half years, but never really focused on it.  And I have been focused on it personally because I've had some problems to solve in this regard.  And I thought, you know, this would be something really great to talk about.  And that is the whole issue of randomness - what is randomness, why does crypto depend upon it, and where do we get it?  Now, it's a big enough topic, and we've got so much news this week, as we have been in the last few weeks, that I thought, you know, I'm not going to be able to do this all in a single podcast.  So this will be part one of what we're calling "Going Random."



LEO:  Going random, I love it.



STEVE:  Where we'll set up the problem and get into it, but stop short of going into the solutions which have been devised, which are really interesting.  I mean, I think - I'm sure I've spoken on the podcast, for example, that somewhere at Sun Computer there was at one time cameras looking at lava lamps.



LEO:  Yes.



STEVE:  Because lava, the flow of the wax in a lava lamp is a chaotic, unpredictable process.  And so they were literally digitizing lava lamp images as a source of chaos to feed into their need for random numbers.  So anyway, we've got a great podcast this week - lots of interesting updates and news, and the first half of the issue of random numbers in cryptography and the need for them and the problems of, like, that we have of generating them.



LEO:  It's actually a fascinating subject in computer science.  And as you say, germane.



STEVE:  Well, and it's a problem because computers aren't.



LEO:  They're not.  Random, they're not.



STEVE:  And that's the problem is, you know, every time you add two and two, you really want to get four.  But sometimes you really wish, you need something random.  And computers can't produce randomness.  They absolutely can't.



LEO:  So first I guess we should say happy anniversary, Steve.  I can't believe it's been a year.



STEVE:  I know.  I mean, it just shocked me.  I looked at  my profile on Twitter about three weeks ago, and it said "You've been a member for 49 weeks."  And I thought...



LEO:  Wow.



STEVE:  ...wow, okay.  And so I'd had it on my own radar to mention to all of our podcast listeners.  And then this morning I got a birthday tweet from Twitter.  So they knew also.



LEO:  They birthday tweet?  I never got a birthday tweet.



STEVE:  So one of the things they're doing now is to say you've been a member for a year.



LEO:  Happy birthday.



STEVE:  And so it was exactly, it was May 4th, the day that we're recording this is May 4th, 2011.  It was May 4th, 2010 that I created the @SGgrc account on Twitter.  Technically I guess I joined a little, a few days before that because remember my first account was AgileSynapse.  And then I realized...



LEO:  Yeah.  That was good.



STEVE:  I liked that a lot, actually.  Elaine moaned, I'm trying to think of - mourned, mourned the passing of AgileSynapse.  She really liked that name a lot.  But I realized that in retweeting you really want a shorter handle.  It's also easier for people to type and so forth.  But if you're going to retweet, then, like, I'm deliberately, often, if I'm posting something that I think may be retweetable, I'll leave room at the end so that there's room for an RT@SGgrc without people having to go in and shorten what I've produced.  So it's much nicer if it's short.



But I wanted to take this moment just to say, I don't know if people have sensed an improvement in the quality of our - the top of the show stuff.  I feel like it's gotten better in the last year, and maybe even more recently than that, because I've been a lot more active.  And our listeners have been, those who are following me and who are in Twitter, have been really effective in sending me tweets for stuff they run across.  And so, I don't know, I feel like there's more interest in our top of the show stuff.  And it's really a consequence of me being so well informed.  While I'm doing other things there's a constant Twitter feed that I keep an eye on of people saying, hey, did you see this, did you see this?  Now, yes, sometimes I get 300 of the same things.  But that's better than getting none of them.  So I just want to say thank you to our listeners for taking the time to keep me up to speed.  I really do think it improves the podcast, which was the whole reason that I wanted to do this.  And so it's effective.



LEO:  You can't go wrong putting more content in.  I think our, you know, we know our audience.  They're smart.  They want more meat.  And so more meat's always good.



STEVE:  Yup.  So everybody is involved in our updates.  We haven't had any updates for a couple of weeks actually.  That category has just been empty.  So everyone's there today.  We have Mozilla, who has released since we last spoke to our listeners a new version of Firefox, where they fixed a bunch of things across all three of their currently maintained upgrade trains, both Firefox 3, 3.5, and 4.  They fixed 53 flaws in the browsers, 12 of which were rated critical by them.  The flaws addressed in the new version of Firefox 4 include a pair of issues in the graphics libraries that could be exploited to bypass certain security protections in Windows.  So those are important to do.  You want to keep Firefox, of course, up to speed.



Chrome, meanwhile, in its sort of background stealthful updating, has brought itself current, addressing 27 vulnerabilities in the Chrome browser.  And so, let's see, so I said bringing the stable build of Chrome to v11 for Windows, Mac OS X, and Linux.  And interestingly, we know how Google pays security researchers for reporting problems they've found.  Well, these 27 vulnerabilities cost Google $16,000 in bounties to 11 different researchers who reported 17 of those 27 flaws.  So they are paying out money for people who find problems and report them.  Which I think is great.  None of these were critical, but 18 of them were given high severity ratings.  So Google, you don't really have to do anything to update Google.  There's no restarting necessary.  Normally when you just start it up, it silently updates itself.  I know every time I look it's already got the latest and greatest from them.  So it's doing it continuously.



We did have an update over on the Adobe Acrobat Reader, Acrobat and Reader side.  A "CoolType.dll" had a pretty serious memory corruption remote code execution vulnerability which affected their versions of Reader 10.0.1 and earlier for Windows, 10.0.2 and earlier for Mac, and Acrobat 10.0.2 for both Windows and Macintosh.  And this is about as bad as it can get because they fixed a number of problems.  But this one particular memory corruption vulnerability that existed in the CoolType.dll library, which is used by the Reader and Acrobat, was actively being exploited in the wild.  And all that was required for exploitation was that a user opened, just opened and viewed a PDF.  The action of viewing a PDF would allow a remote attacker to execute arbitrary malicious code on the target machine, both in Mac and Windows.  And interestingly, we do have some Mac news.  Mac has been having some problem in the last week.



LEO:  Yeah.  A little worrisome.  We've been problem-free for a while.



STEVE:  Have been, not a target.  And just in time for the podcast, Apple has updated iOS.  It is, depending upon which type of phone you have, it's 4.2.8 or 4.3.3.  This is the fix to what they call their "crowd-sourced location database cache."  In the window that you get, it says "This update contains changes to the iOS crowd-sourced location database cache, including reduces the size of the cache."  Remember they were keeping it apparently forever, and now they said they were going to - in what we read before, last week they were saying they were going to bring it down to just seven days because that seemed to be reasonable.  And they were saying, oh, yeah, it was a bug that it was keeping it forever.  It will no longer back up the cache to iTunes, which is actually news.  And it will delete the cache entirely when Location Services is turned off.  So those fixes that we've been awaiting have now just this May 4th been released from Apple, in the morning before we're recording this.



LEO:  Actually it's been pretty quick.  That's less than two weeks since it was discovered.  So that's - it's a pretty good response, I think.



STEVE:  Yeah.  I think so, too.  In security news, this doesn't directly bear on cybersecurity, but I did find it interesting to note that, in the successful - what word do I use?  In successfully apprehending and killing Osama bin Laden, which the U.S. Special Forces Navy Seals did a few days ago, they spent a substantial length of time going through the compound and then acquiring 10 hard drives...



LEO:  Oh.



STEVE:  ...five PCs, more than 100 storage devices including CDs, DVDs and thumb drives.



LEO:  So that's what those couriers were bringing, were taking.



STEVE:  Yes.



LEO:  Now, they had no phone service.  They had no Internet access.



STEVE:  Well, and I think that was really smart.  From a security standpoint, that represented some cleverness.  And they were also burning all of their refuse, all of their garbage, instead of having any of it taken out of that compound.



LEO:  Although, as we know, that was also a red flag for security services, that there was no connectivity in this mansion, and that periodically they were burning stuff.  That was also a little, you know, suspicious.



STEVE:  There was a lot that was screwy because none of the other homes that were there had 18-foot walls.



LEO:  Yeah, yeah.



STEVE:  And the third-floor balcony had its own seven-foot privacy shield, another wall, so that people could be out there on the third-floor balcony and not be seen.  So, I mean, it would have been clear to anybody that whoever was inside this thing was intending to maintain their privacy and their identity to be kept a secret and regarded as a high value.  Of course, no one, well, certainly we didn't, and lots of people did not know who was there.  So it was a win for intelligence.  And, but, yes, they certainly were taking measures to be secure, and having no contact with the Internet and just using couriers in and out.  And of course it was, we were told, it was tracking couriers was the way they ended up deciding that Osama must be located in there.



And relative to that, I did tweet a reminder to everyone that hot topics which are flashing across the Internet through Twitter and through email still are getting people to click on links that they might not otherwise.  That is, even trained people, when email comes in and it says "Post-mortem photo of bin Laden," or a photo of one of his wives supposedly used as a human shield or something, that in that moment of, ooh, wow, that's really newsy, or I really want to see that, that can cause people to forget their training and click.  And that has been happening ever since Sunday when this news broke is there have been a, I mean, immediately the bad guys jumped on this and used this to exploit just our interest in more information.



LEO:  Happens every time.



STEVE:  Yeah, it does.  So I just wanted to take the opportunity to remind our listeners, once again, just even if you, I mean, and that's the problem.  The more you want what the come-on is offering, the more likely you are to say, oh, well, maybe it's true.  Maybe this is a photo.  So just...



LEO:  And there are no photos.  In fact, I see now the news story that the President has decided not to release any photos.  So if you see that somebody's offering photos, unh-unh, they don't exist.



STEVE:  Yeah.  And the argument has been going back and forth, there have been some - the news agencies, of course, would like it.  But the point has been that there hasn't been a huge level of push and skepticism from outside the United States for confirmation.  Everyone is believing what we have.  And frankly, Leo, you know that probably high, high up, other heads of state have had access to, if nothing else, a diplomat would have opened the folder and said, see, here it is, and then closed it and put it back in his diplomatic satchel.  So you can imagine that people who absolutely have to know have had whatever level of convincing data that they've needed.  That's certainly going on behind the scenes.  But that's the kind of thing you just don't want loose on the Internet or it will never be pulled back.  So, yeah.



Had an interesting and disturbing story that Ars Technica reported that I wanted to share with our listeners in its entirety because Ars did a very good job.  And it's another reminder.  The story was "PC rental store accused of using webcams and keyloggers on customers."  This was just in Ars Technica yesterday.  They wrote, "Built-in webcams are becoming more and more common in computers these days; and, in turn, they are becoming more and more of a liability.  A Wyoming couple is now accusing national rent-to-own chain Aaron's, Inc. of spying on them at home using their rented computer's webcam without their knowledge."



LEO:  Oh, my god.



STEVE:  Uh-huh.  "Aaron's also allegedly used a keylogger and took regular screenshots of the couple's activities on the machine, leading the couple to file a class-action lawsuit in the U.S. District Court for the Western District of Pennsylvania.  According to the complaint filed on Tuesday, Aaron's has been using a product called 'PC Rental Agent' on its rent-to-own machines since at least 2007 in order to 'surreptitiously access, monitor, intercept, and/or transmit electronic communications' made by Aaron's customers.  Created by a company called DesignerWare, PC Rental Agent is advertised as a way to keep track of rent-to-own computers and lock out customers who fail to pay."  Okay, well, obviously it does way more than that.  I mean, this is full-on spyware.  "According to the lawsuit, the product was sold to Aaron's under the guise that it was undetectable by users, and Aaron's apparently conceals the fact that it has the ability to monitor customers' activity when marketing its services.



"Crystal and Brian Byrd found this out the hard way in 2010 when they rented a Dell Inspiron laptop from Aaron's, which they paid off in full in October of 2010 - one month ahead of schedule.  Aaron's didn't record the last payment correctly, however, leading an Aaron's store manager to show up at the Byrd home in December in order to repossess the computer.  The store manager then produced a photo of Brian Byrd using the machine, taken with the Inspiron's webcam, as apparent 'proof' that the Byrds were still using the computer.



"The Byrds ended up calling the police, and an investigation later concluded that Aaron's 'routinely installed the PC Rental Agent' on all of Aaron's rent-to-own computers.  Law enforcement confirmed that the product indeed permitted the company to routinely take webcam photos, screenshots, and log the keystrokes of its customers without their knowledge or consent.



"It's unclear how many other photos Aaron's might have collected on the family, but Brian Byrd told the Associated Press that he was concerned about the content of photos that were potentially taken of his wife and child."  He said, "'Chrystal gets online before she gets a shower and checks her grades.  Who knows?  They could print that stuff off there and take it home with them,' Byrd told the Associated Press.  'I've got a five-year-old boy who runs around all day and sometimes he gets out of the tub running around for 20, 30 seconds while we're on the computer.  What if they took a picture of that?  I wouldn't want that kind of garbage floating around out there,'" he said.



"The Byrds' situation is eerily reminiscent of one that occurred last year in" - get ready for it - the Lower Merion School District in Pennsylvania."



LEO:  Uh-huh.  That's right.



STEVE:  Which we talked about extensively.  "At that time, some parents discovered that the school district had used remote software to activate the built-in webcams on the students' school-issued computers in order to check up on them at home, while the district insisted that its 'spying' policy only applied to laptops that were reported stolen."  Which of course we know was not the case.  "The district ended up settling two lawsuits for a total of $610,000, despite apparent e-mail evidence that the IT staff responsible for monitoring the laptops regularly viewed the students' photos for entertainment.



"According to Brian Byrd, the computer in question is still in police custody as evidence, and no one from Aaron's has yet commented publicly on the case.  However, the Byrds are hoping to get the suit certified as a class action so that other customers who might have been affected can get in on the lawsuit.  After all, Aaron's claims to have more than 1,500 stores in the U.S. and Canada alone, and there are bound to be others who are only now discovering that they don't have as much privacy at home as they thought."



LEO:  As they thought?



STEVE:  Yeah.



LEO:  As they should have.



STEVE:  As they - yeah.



LEO:  As they deserve.



STEVE:  As they deserve.  So and that's another reminder.  I'm hoping that we will see physical shutters added to all webcams in the future.  But we're not seeing them still.  I mean, for example, all of the iPhones and iPads are shutterless.  And I smile every time I go to Starbucks and I see a friend of mine, who I told about these things, who just has a post-it note, a little sticky chunk of a post-it note stuck over the webcam on his laptop because he doesn't want to worry about his laptop staring at him and looking at him and getting infected with something that would do that.  So it's simple, physical security.



I have a very high-power laser, which is dangerously powerful, and some of the criteria for having that is that you need a key switch and a time delay from the time you turn it on and it actually energizes, and a physical shutter.  So we have - there's a law in place that requires lasers of a certain power to be physically shutterable so that you have multiple fail safes.  And it really is the case that our laptops should be the same way.  They ought to just have something where you can slide it, and this thing is blanked out.  It's a trivial thing to add.  And we're still not seeing it.



LEO:  We predicted this after the Lower Merion thing, that this would be in every laptop going forward, and it is not.  And I'm kind of surprised, to be honest.



STEVE:  Yeah.  It really does, I mean, we just need some pressure on the manufacturers to make that happen.



LEO:  It's an easy thing to do.



STEVE:  And in weird news, but important, I thought, or just I wanted to mention it because we talk about Kaspersky so often, Eugene Kaspersky's son Vanya was kidnapped...



LEO:  Saw that.



STEVE:  ...and safely returned.



LEO:  Didn't see that.  That's good.



STEVE:  And the bad guys were caught.



LEO:  Yes.



STEVE:  On 4/22, on April 22nd, Kaspersky Lab posted a statement:  "Kaspersky Lab respectfully asks members of the media to refrain from speculating and distributing unconfirmed information about alleged events relating to the Kaspersky family.  Eugene Kaspersky continues his day-to-day work at the company and has stated that the unconfirmed information being spread at the moment is harmful for the company."



Then two days later they posted the statement:  "Kaspersky Lab confirms that an operation to free Ivan Kaspersky" - I ought to mention that Ivan is his pseudonym, his son's pseudonym that he uses for posting and doing things online and in the company, where his real name is Vanya.  So it says:  "...operation to free Ivan Kaspersky was carried out successfully by the Federal Security Services (FSB), the Criminal Investigation Department of the Moscow Police, and Kaspersky Lab's own security personnel.  Ivan is alive and well and is currently at a safe location.  No ransom was paid during the operation to free him.  Eugene Kaspersky and Natalya Kaspersky express their profound gratitude to those who participated in Ivan's release and to all those who supported them throughout the last few days.  Both are currently unavailable for comment."



And then he did also, four days later, on the 28th, Eugene has a Facebook page where he posted, among other things, that "Vanya is back home safe and sound.  Thanks for your support."  So that all came out well for them, which is wonderful.



LEO:  What a relief, yeah.



STEVE:  Yeah.  We mentioned last week that the MySQL site itself, that is, the people who maintain and develop and move the MySQL server project forward, had been victims of a blind SQL injection attack.  I ran across an extremely  good treatment, a step-by-step coverage of exactly how this was done, specifically on their site, at a company called Acunetix.com.  If you go to Acunetix.com, up at the top there's a link to their blog.  And if you scroll down to their blog posting, "MySQL.com Victim of SQL Injection Attack," what you'll find is a very nice, detailed treatment, step by step showing how this was done.  We've talked about it in the past, so I didn't want to go through it again.  But I know that we've got a broad audience, and some might be really interested in the details.  So you can find them there at Acunetix.com on their blog.



A number of people, in the wake of the recent concern about Dropbox's lack of security, talked to me - or actually tweeted, that's how I learned about it, through tweet or through Twitter tweets.



LEO:  Tweeter.  Tweeter Twitter.



STEVE:  Yeah.



LEO:  Just don't call it TWiT.



STEVE:  Something that's in beta called "SecretSync."  The site is GetSecretSync.com.  I have not done a full analysis and appraisal.  I did spend some time looking at the site, literally every page that they've got that's available.  It's still rather sparse.  It is in beta at this point.  And I think I remember seeing that you would have to have Java installed.  So I think it's Windows only, but it's going to be multiplatform.  Thus they're using Java to get the multiplatform support, which makes their job easier.



And everything I saw leads me to believe that they're doing everything right.  That is, they're doing client-side encryption and decryption so that everything that is being stored in Dropbox - this is sort of a front end for Dropbox.  So you still use, you get to keep your existing Dropbox account, your existing usage of Dropbox.  But then installing this SecretSync service creates an encrypted folder in addition to your regular Dropbox folder.  And what it means is, essentially, that it is encrypting what you drop there before it leaves your machine.  So it's exactly the kind of security you want.  They're saying that all of the responsibility for not losing your key that you create as part of setting this up is on you.  That is, they don't have the key.  They're storing nothing but pseudorandom noise which you send them, which comes out of the encryption process.  All of that is exactly the right-sounding thing.



So again, I have not personally vetted this.  I haven't installed it because I'm not a Dropbox user.  So I can't vouch for it.  But I wanted to tell people who said, "Hey, Steve, look at SecretSync, what do you think," what I think is, from everything I've seen, this looks like they're done the right thing.  I don't know what plans they'll have in the future when it comes out of beta, whether they're going to charge people or what their deal is.  But from everything I saw, it looks really good.



LEO:  Does solve that issue, that's for sure.



STEVE:  Yes, yes.  Were I a Dropbox user, I would use this in a heartbeat.



LEO:  Well, we are, as you know.  We use it heavily.



STEVE:  Yeah.  Although you're using it more for...



LEO:  Yeah, I don't care if people find your file.



STEVE:  ...public, exactly, for public stuff, exactly.  And we have seen the first fake AV software targeting Mac users.



LEO:  Terrible.



STEVE:  It's called - there is a legitimate product called MacDefender.  And so this one is a - this is malware masquerading as MAC Defender, which claims - it's the bogus AV stuff.  It claims that Mac OS X has been infected and asks users who get themselves infected with this for anywhere between $80 and $99 to purchase antivirus software to fix the problem.  It is apparently spreading through Google Images somehow.  I don't know if it's - there's been no claim that the Google Images site itself is the problem.  It may be infected images.  I saw something, someone said that he was looking for images of piranha, and I guess he got bitten.



So the one tip that I have for our listeners is that some Mac users in the past will have allowed Safari to open files which it deems safe after downloading them.  And apparently it is people with this enabled which are getting caught.  So under Safari, go to Preferences > General, and then uncheck the option called "Open 'safe' files after downloading."  Turn that off so that Safari doesn't do this automatically behind your back.



LEO:  Well, no matter what you have checked, you still will be asked for a password.



STEVE:  Really.



LEO:  It does not - yeah.  That's my understanding.



STEVE:  To install software.  So people must be doing that.



LEO:  Yeah, oh, yeah, but that's the problem.  At least this was my understanding.  We discussed this yesterday on MacBreak Weekly.  But that's the problem, I mean, it's the same problem with UAC on Windows, which is you get kind of fatigued, and you go yeah, yeah, yeah, yeah, yeah.



STEVE:  Yup, exactly.



LEO:  Apple at least, unlike UAC, even if you're running as an administrator, you still must enter the password.



STEVE:  Right.  What was the - there was a joke Saturday night at the White House Correspondents Dinner.  Shoot.  I remember the punch line now, but I can't remember what the joke was.



LEO:  Was it Seth Meyers or...



STEVE:  I don't remember whether it was Seth or Barack.  I think it was Seth.  And the punch line was that - oh, shoot.  It was that I'm sure that most of us treat this the way we do updating terms and conditions on iTunes.



LEO:  Oh, yeah.  There was a little slam against that, yeah.  Yeah, yeah, I think that was Seth Meyers, yeah.  That was pretty funny.



STEVE:  Yeah, it was really great.



LEO:  Which shows you how...



STEVE:  And everyone knew what he meant.  Like, yeah, yeah, yeah, we all know.  Updated terms and conditions, yeah, click, you know.  And so on we move.



LEO:  So to be clear, it will auto download if you have that turned on.  The issue is it will not, even if you run it manually or automatically, you will have to give a password.  This is true in any case, even if you're running administrator.  You will have to give a password before it installs.  So the problem is it looks pretty credible.  I mean, it's a pretty credible-looking, you know, no obvious misspellings, no grammatical errors.  But we just have to drill into people's heads you don't just randomly - the problem is, I guess, if you click saying yes, I want this thing, of course you're going to give it permission to install.  You've already been fooled.



STEVE:  Yeah.



LEO:  It's terrible.  Don't be fooled by pop-ups.



STEVE:  Exactly.  So we have a lot more on our Attacks & Breaches section, mostly about Sony.  The news, the real news we have is that apparently the breach went further than just the PlayStation Network, such that on Sunday night the Sony Online Entertainment System, which is their online PC games network, was also shut down, and they sent email to another set of users.  And I remember seeing the number 12.5 million.  So there were, I mean, there are still problems happening.



Brian Krebs, our security follower and watcher, captured some screenshots which I saw, which then other people - which sort of annoyed him - other people were taking his screenshots and redisplaying them as their own without giving him any credit, which were of some forums where the people posting appeared to be saying that there were 2.2 million credit cards up for sale.  And also someone was claiming that Sony had been given the opportunity to buy the database back, but had not responded.  And there have been continuing reports surfacing of credit card details being sold on "carder  forums," as they're called.  And at least in one case there was a report that a Sony administrative password had been compromised.  Which may have given people access to more.



So, I mean, it really is a mess.  Now, Sony has said in an interview that was conducted in Japanese and translated, that the passwords were hashed, that is, they were not encrypted.  There was some miscommunication initially.  They're saying that they were not encrypted, but they were hashed, which is essentially the same thing.  We hope that it was a salted hash.



LEO:  That's the issue, isn't it.  We've talked about that before.



STEVE:  Yeah.  Otherwise rainbow tables could be used in order to reverse the hashes.  And then I'm wondering, I mean, I guess somebody really messed this up from a communications standpoint because they really scared people by telling people that, if you use the same username and password anywhere else, that you had to go change it.  But if they had properly cryptographically hashed the passwords, and if that's the only thing that the bad guys got, then that is an irreversible process.  If you have a salted hash, and the salt isn't known - and hopefully the salt would have been stored separate from the database, I mean, you wouldn't expect it to be in the algorithm and not in the customer records - then it's as good, I mean, that is encrypted.  It is, I mean, it's even better than encrypted because in typical encryption you can reverse, and a salted hash you cannot reverse.  It is inherently a one-way process.  So they really scared people, probably unnecessarily, if in fact they had hashed it well.  We just really - we really don't know.



LEO:  And if you're puzzled about salt, I think this show on randomness will help understand a little bit of that; right?



STEVE:  Yes, absolutely.  And I got a tweet from @LeonZandman, who sent me an interesting link to a new posting at CareerBuilder.  Now, on April 20th, on 4/20, the PlayStation Network outage began.  On 4/21, Sony posted on CareerBuilder for looking to hire a senior application security analyst in San Diego.



LEO:  Well, it's about time.



STEVE:  Which is where they're located.  Now, the good news is it's a full-time position.



LEO:  Yes.



STEVE:  And under required travel it says "none," which is good.  We want that person to stay put, stay in San Diego,  and do their full-time job of...



LEO:  No traveling allowed, yeah.



STEVE:  ...making us more secure.  And as I predicted last week, lawsuits have been filed against Sony for this.  I mean, I feel badly for them.  And again, it's unfortunate this happened.  And I guess there'll be some court battles to decide what culpability was on Sony's side of this.



There was an Xbox Live podcast where they took the opportunity to mention that the Xbox Live people take security very seriously, was what they said.  And so we're all glad to hear that.



LEO:  Thank you.



STEVE:  Yes.



LEO:  Just in case you were puzzled, or worse.



STEVE:  In case you people who are on Xbox and not on Sony were concerned.  And then, in an example of something done really well, that is, of the kind of confession that you really want to see, although you never want to see the problem, DSLR, DSL Reports, was also breached, through I believe it was a botnet.  In fact, I'm sure it was, or they believe it was.  They said that 8 percent of their historical users - now, this goes way back in time, too - 8 percent of their users' usernames and passwords were stolen.  They made a very responsible posting.  They said what happened, and I regarded this as the proper way to report and take responsibility for the breach.



They said, in brief: "An SQL injection attack by a botnet" - oh, so it was both.  It was SQL injection.  That's what I thought I remembered.  But it was conducted by "...a botnet on Wednesday afternoon," so that would have been one week ago today, "obtained a large number of email and password pairs.  The ones they obtained were basically random, so they covered the entire 10-year history of the membership, but were sprinkled randomly throughout that.  Some were very old accounts; some are new accounts; some inactive and deleted."



And so I'm reading from this posting, where the poster said, "I identified the newest accounts, those that were obtained and have logged in over the last 12 months, and have alerted those by email.  This amounts to some 9,000 accounts.  If your email/password was revealed, you received the alert email or discovered your login password has been changed by us already.  You also need to think of what other sites you use allowing logins using the same registered email address and password."  So in this case at DSLR they were not hashing the passwords, and the email and associated login did get loose.



LEO:  [Muttering].



STEVE:  "Some sites" - I know.  "Some sites, especially email services like Gmail and PayPal and Facebook, allow login by email and password.  If you are in the habit of sharing the same password among many sites, then the people who obtained this data from us can log in as you.  So you should secure your access to those sites by changing your password there immediately.  Your first priority would be your primary email account, if the password was shared with it.



"It is unclear how much data the logged intrusion requested which actually reached them.  The site was quite unresponsive during the attack.  And whether that data is being used yet, we don't know.  I'm going on a worst-case scenario here.  It is also unclear whether the emails obtained will be spammed or just searched for high-value targets such as PayPal, Gmail, Google Docs, et cetera.  Older inactive accounts involved are also being notified by email now, although the older the account, the less likely the email is still current or the password they use is still useful.



"Obviously having both an SQL injection attack hole, now closed, and also storing plaintext passwords, as we were, is a big black eye for us.  And I'll be addressing these problems as fast and carefully as I can.  My apology for any stress this causes.  If you are like me, you've also got the PSN network issue hanging over your head, as well.  Judging from the replies to the initial email, the impact is varied.  Some people used a unique email or unique password for the site, and others used the same password everywhere and will have to be much more careful."



So that was what was posted in DSLR's blog.  And I have to salute them and this person for being as, I mean, really taking responsibility and being as forthright as he was.  I mean, certainly no one wants to ever have to generate a blog posting like that.  They also had a short Q&A.



They said in the Q&A:  "A large network (botnet) of compromised windows machines circumvented individual IP access limits on unusual activity.  The attack was blocked before it had completed more than 8 percent of its work."  And then under a question, they asked themselves, "What is the likely use for the data gained?"  The answer is:  "Gaining access to email accounts, gaining access to accounts at PayPal/Google/Amazon/Facebook/Twitter or other big sites where login is via email and password."



Question:  "What kind of shoddy operation are you running here?"  And again, I salute them for, I mean, they posted this question.  Answer:  "Not making excuses, but it is sobering to read that just recently MySQL.com was hacked with an identical approach to the one used here (blind SQL injection).  More MySQL-based sites will suffer the same issue this year, so users should take care to reduce their password re-use on multiple sites to at most high/medium/low value passwords.  A common low value password for forums, unique ones for banking, et cetera."



And that's actually a good strategy.  If you don't want to go through the trouble of maintaining a truly unique password for every site, or, for example, if you're not using LastPass to automatically do that for you, then you are able, you could absolutely regard some passwords as low value and allow yourself to reuse them, for example, for posting in forums, but absolutely use known unique ones for banking purposes.  So anyway, it's unfortunate that DSLR got hacked.  But they couldn't have handled it any more responsibly than they did, so I take my hat off to them.



I tweeted earlier this week that I had finally had a chance to sit down and spend some time with and start using Certificate Patrol, which is an add-on I mentioned blindly last week that I knew of, I had found out about, also through Twitter, and hadn't had a chance to look at it.  I called it in my tweet "a terrific Firefox add-on for the security-aware power user, five-star Security Now rating, a total win."  And I continue to feel that way.  So I wanted to follow up on last week's mention of it, for those people who are not following me on Twitter, and say I'm really happy with this thing.



It's popping up, as it's designed to, whenever I go to a site that I have not - a secure HTTPS SSL site that I have not yet visited since I had installed it.  And so when it's caching those sites, that's when I am being shown information about the certificate being used, how long it's been there, how much longer it has till it expires, and who the issuer of the certificate is.  So so far I haven't run across an instance where one that it already has has expired.  But it will notify me of that explicitly.  Nor certainly have I run across one where I'm going to a site where everything seems changed about the certificate, which would be a real red flag indicating that potentially you're being spoofed somehow.



So again, I call it an "add-on for the security-aware power user" because initially, as you're going to SSL-enabled sites, you're going to be seeing these pop-ups a lot.  It pops up, and it's a modal dialogue, meaning in Windows terms that you have to say okay and close it before you're able to proceed.  Which is actually what you want in the case of something coming up and being bad.  I'm also, it's interesting, I'm using it to learn about the sites that - the certificate authorities that other of the major popular sites that I go to are using.  And this is not something I ever really, like, took the trouble to research before.  Now it's just being given to me.



And one of the things that I'm seeing is that major people are using DigiCert.  Facebook and Sony - I went to Sony's site, naturally, in the last week, doing some research for this podcast - they're both using the DigiCert high-assurance certificate authority.  Thawte is being used by Google, and Equifax is being used by Level 3, some various sites that I happen to have been visiting in over SSL recently.  But DigiCert's pricing is very good.  So there's a chance that VeriSign is finally going to lose me after all these years because their pricing is the worst, that is to say the highest there is in the industry.



LEO:  Thousands; right?



STEVE:  Yeah, it's insanely expensive.  And for example, I don't have a fancy, make-your-URL-turn-green cert, an extended validation, an EV cert, because they're too expensive from VeriSign.  And it's not like I only have to pay that once.  I've got to pay it every time.  So as I'm seeing people like Facebook, I mean, any CA that Facebook is using is obviously in every browser on the planet.  So that's all I really need is a certificate authority that's going to be issuing certificates that I'm sure that everyone's browser will be able to receive.  And I'm seeing now that a lot of high-profile sites are using DigiCert.  So that's good enough for me.



So VeriSign's got to get with the program here.  Maybe they'll just stay ultra high-end, you know, Level 3 uses them.  But GRC, unless they fix their pricing, I think they're going to lose me.  So it's been an interesting education.  And the Certificate Patrol is a handy little add-on for Firefox.



LEO:  Cool, yeah.



STEVE:  I received a tweet, or I saw a tweet, from Gabe Ormsby, who tweeted something that I pointed out, which was that password length limits are a strong hint that they're not hashed passwords on the server end.  And when I saw that go by, I thought, yeah, that is a good point, and I wanted just to remind our users of it.  We're all now becoming aware of the problem of people we rely on to protect our data - for example, Sony and others where we're trusting them.  Well, if you are presented with a length limit, and I've seen them, for example, passwords must be between eight and 16 characters long, seems typical, I mean, that's a very good clue.



LEO:  A minimum's okay.  It's the maximum that's scary.



STEVE:  Right, because what that implies is that in their SQL database, which the hackers are currently trying to get into, they've got a 16-character field into which you can put a password of up to 16 characters.  What we want is them to have a 256-bit field, which is, what, 16 characters, yeah, 16 bytes.  And we want them to hash however long a password you give them and not worry about it, so that is to say where they're not imposing a length limit on the user.  When they do, it implies they're storing the password itself.  So that's just a little tipoff.  When you see that, you might write a note to their support people or their security people or their privacy people, whatever, and say, hey, how are you storing this password of mine?  Are you hashing it or not?



LEO:  And salted hash is what you want; right?



STEVE:  Yes.  Yes.



LEO:  Even a hash by itself is not as good as a salted hash.



STEVE:  True, because a hash is going to be using a known algorithm.  And it's, for example, if the bad guys created an account on that service and then stole their own hash, they would know both the plaintext password and the hash.  And they could then run that through a bunch of all of the various hashing algorithms and quickly determine which one was being used by that site.  And then that would allow them, if it weren't salted, that would allow them to apply the - to know what the hash was, and then grab the rainbow table that's appropriate and see about reversing the hashes.  So, still, hashing is way better than not.  Salting is what everyone who's hashing certainly should be doing.  But storing in plaintext is just a bad idea.  And if they're giving you a limit on the length you're able to store, that really does raise a red flag.  It's like, okay.



LEO:  And that's because hashing kind of changes the length anyway.



STEVE:  Well, actually, hashing, no matter what you - you could put in a one-character password.



LEO:  And you'd get the same length.



STEVE:  And it would give you a 256-bit hash.  The hash...



LEO:  No matter what.



STEVE:  Yes, the output is always the same fixed length.  It's 128 for a 128-bit hash, 256 bits for a 256-bit hash, and so forth.  And then lastly, Jared in Redmond, whose Twitter handle is @jshoq, sent me a note just mentioning that Bank of America offers one-time-use credit cards, and even, as you mentioned, Leo, last week, recurring payments to a single vendor.



LEO:  That's what we want.



STEVE:  So I wish Chase did that.  But no such luck so far.



LEO:  It may also depend on the card you've got, I guess.



STEVE:  Yeah.  Under miscellaneous gizmos, something is going on with Bitcoin.  I don't know what it is.  But I mentioned that, last week I think it was, or no further back than the week before, I think it was last week, that they were at a dollar something, a little over, like, $1.10 or $1.20 or something.  It's now at $3.50.  So a single bitcoin is now trading for $3.50 in U.S. dollars.  I checked this morning to see what it was because I got a tweet either from Bitcoin or from someone notifying me, I don't remember which.  But it's like, whoa.  So those bitcoins are becoming valuable.



LEO:  They add up.



STEVE:  I'm glad I got 50 of them.  And Leo, I just meant to ask you, I've seen commercials for the BlackBerry PlayBook, and I know that on the show we mentioned you had just received one, I guess maybe toward the end of a podcast a couple weeks ago you were just unboxing it?  What do you think?



LEO:  Well, I'm playing right now, I'm playing Need for Speed Undercover, which was designed, it says when you launch it, for the PlayBook.  And you can see the power of the Tegra 2.  I mean, this isn't - hardware-wise, this is nice.  Now, watch.  Remember, we're running QNX.  I can slide up, and the multitasking continues.  And you see I have other things going, including, oh, there's Steve.  Playing back, by the way, in Flash.  Now, it's fake multitasking, as you can see, because it's paused the Flash.  But there we go, there's the live thing.  And it plays for a little bit, but the game is stopped over there.  But it kind of feels like real multitasking.



We also have the - Mediafly has made the TWiT application available, so that's kind of nice.  You can watch them after the fact.  But having Flash in a browser is cool.  It's a nice browser.  It's very much like the WebKit-based browsers on the iOS devices.  In fact, I'm sure it's WebKit-based.  It seems to work very well.  You can zoom in and zoom out and all of that stuff.  I do like the multitasking.



I think really the only thing wrong with it is the dearth of software.  It's not - it's a nice form factor.  It's a little thick, you know, compared to the iPad 2.  But it has a lot more in terms of capabilities.  It uses USB, micro-USB charging.  It's got a camera front and back that's I think better than the iPad's camera.  I like it a lot.  I mean, I think it's a nice device hardware-wise.  We just have to wait until - and, by the way, the OS really is well done.  We just have to wait until there's more applications.  Remember they're going to make it possible to run Android apps in emulation.



STEVE:  Right.



LEO:  We haven't seen that yet, so we don't know how well it does with Android apps.



STEVE:  Ah, so it didn't have that at all out of the box.



LEO:  No, it's not out yet.  And then they also have a developer kit that makes it supposedly easy for developers to port to Android, from Android to the PlayBook.  So that could help the problem.  I mean, it's another one of those chicken-and-egg things.  You've got a new operating system, a new platform, and you maybe haven't sold a whole lot of them yet.  You've got to convince developers that it's worth the investment to write software for it.  And you've got to convince people to buy the hardware, even if there's no software out there for it.  I mean, this doesn't even come with an email app or a calendar app.



STEVE:  [Laughing] And you can't get one yet?



LEO:  No.



STEVE:  Oh, my goodness.



LEO:  Now, I'm sure there'll be third-party versions.  If you have a BlackBerry now, you can use their bridge technology to put email on it.  And if you look, it says, oh, email.  But what it really is is it's using the browser.  So if you have browser-based email you can do it.



STEVE:  Right.



LEO:  But, I mean, it's not what I would call true email.  So they've got a little ways to go.  It's, you know, it's nice hardware, and the OS is very snappy, feels really good.  I think they've done a nice job that way.  But still and all I wouldn't say get it instead of an iPad 2.  It's the same price.  Oh, and no 3G option.  It's WiFi only.  So it's just too limited.  And I think the problem is - Paul Thurrott talks about Windows Phone 7 in the same context.  It'd be one thing if there weren't an iPad.



STEVE:  Right.



LEO:  But there is.



STEVE:  In the shadow of the iPad, good luck.



LEO:  Yeah.  It's just very tough to compete against an existing platform with hundreds of thousands of applications available.  By the way, while you've been talking, I've been downloading the iPhone 4 update.  I don't know if this is intentional.  It's a little weird.  666 megabytes, 666.  It's a satanic download.



STEVE:  Wow.  Wow.



LEO:  Well, I think that - and they say in the notes that all they're fixing is this location database.  But I don't think they have the capability of doing vector-based OS updates.  I think you have to download the entire firmware each time.



STEVE:  They just can't do a delta.



LEO:  No delta.  Not, yeah, not vector, delta.



STEVE:  Wow.  Wow.



LEO:  Let's take a break.  Did you want to do a SpinRite or anything, or...



STEVE:  Yeah, I've got a few more little gizmos I want to talk about.



LEO:  Oh, there's more, I see.  Good Morning America.  Did that happen?



STEVE:  No.  And I did want to follow up because a number of people, I get questions pretty much every day, whatever happened with Good Morning America.  And I have no idea.  My guess is that they may use the footage, it may just be in storage until a high-profile breach of some sort actually happens, and then they'll sort of dust me off because that's what they originally had me come up to talk about.  They may have decided that the Firesheep issue was just too scary, or a little too geeky and not mainstream enough for their mothers doing the ironing in the morning crowd, who knows.  But as far as I know, I mean, it's been so long now that I'm guessing it's just not going to happen.



I've also had a lot of people say, Steve, would really love to have the TechTalk columns from the old days of InfoWorld, which came up, I guess it must have been when you and John and Jerry and I were doing TWiT on Sunday a few weeks ago, Leo, that we were talking about the InfoWorld column.  I wanted to mention that...



LEO:  Are you going to do what he suggested?



STEVE:  Well, I've been struggling towards it.  I just found the DAT tapes which...



LEO:  Oh, my god.  They're on DATs.



STEVE:  Yes.  All of the backups, I mean, I see one here that is labeled "C: and D: August 1, '96."  So I remembered at the time that the machine I was using, I think I was under Windows 3.1.  I know that I published the books, the Passion for Technology books, in Ventura, which was the premier sort of geeky publishing tool at the time.  I think Adobe had theirs, but I was over on Ventura.  And it started off on the GEM platform actually.



LEO:  Yeah, yeah.  I was going to say, because if you just took all the text of the columns, it'd probably fit on a floppy.



STEVE:  Yeah.  Although I did, I did a diagram.  I went back, the column typically did not have diagrams.  And so, I mean, I really put a lot of effort into republishing the columns.



LEO:  That's great.



STEVE:  And when people were asking for them, it's like, uh, yeah.  They're around here somewhere.  And literally, I knew that they were on a hard drive that I probably have.  But I also know that I was backing them up on DAT tape constantly.  That was my backup medium.



LEO:  Now, here's the big question.  Do you have the DAT player?



STEVE:  I do.  I've got two drives and the software.  So I kept - in fact, what I don't have is a parallel port because it was a parallel port interface.  So I purchased a PCIE, I think it is, to parallel port adapter card, so that I could stick a parallel port in one of my current machines in order - and then I'm going to have to set up a DOS partition because this thing ran under DOS.



LEO:  Oh, my goodness.



STEVE:  It looked a little bit like XTree, as I remember the UI, so...



LEO:  And to be honest, it's '96.  This is 15 years ago.



STEVE:  Yeah.



LEO:  This is something we've got to keep in mind, that these data formats have the shelf life of a fruit fly.  And you've really got to either keep up or say goodbye.  Because, I mean, how many people really, I mean, nobody has ZIP drives, DAT drives, the software.  This stuff is - it gets antiquated so fast.



STEVE:  It's where me being a packrat comes in handy.  I actually had all this stuff.



LEO:  So that's good.  So we can at some point expect an eBook with the columns of Steve Gibson.



STEVE:  And it'll be free.  I would never charge...



LEO:  Oh, Steve, why not?  A buck fifty.



STEVE:  No.  It's just - I'd just rather make it available.  And I'd like it to be in PDF and...



LEO:  Unprotected open standards.



STEVE:  Absolutely.  It's just for people to, I mean, as you say, Leo, it's 15 years old.  It's like...



LEO:  Oh, yeah.  It's great stuff.  I bet you it's more - have you read it yet?  I bet you...



STEVE:  There's a lot of good stuff there.



LEO:  ...more of it's germane than you might think.



STEVE:  It's surprising, actually.  As you look through this, it's like, wow, nothing's changed.



LEO:  Yeah.  Yeah.



STEVE:  Okay, now, I have, I think, a reading assignment for our listeners.



LEO:  Ooh, I love that.  I fire up my Kindle.  You know I bought that new Kindle, the ad-supported Kindle, just to see what the ads are.  It's not bad.  Instead of those woodcuts, they've got the ads.



STEVE:  Because they are adding, I mean, they're advertising it on TV now at $114, and I always kind of grumble when I see that, thinking, well, is that really false advertising?  Because it is ad supported.  But it's not in your face, huh?



LEO:  No.  Once you're reading, it's gone.  It's just instead of the beautiful woodcuts, which I do miss, there's the screensaver.  It puts an ad there.  Those are rotated quite a bit.  They're different all the time.  And then when you're on the menu page there's a little bar at the bottom that's an ad.  That's all.  It's I think very unobtrusive.  I wish you saved more.  You only save $25.  But still, 114 bucks for a Kindle, not bad.  And that's my, I think, my fourth or fifth Kindle now.



STEVE:  Okay.  So our friend Mark Russinovich, whom we have spoken of many times, he's famously known as one of the two main, well, one of the two guys behind the Sysinternals website.  And Sysinternals tools have been used by all of us security people, I mean, they've got, like, great process explorer and all kinds of low-level tools, I mean, I've used them for years.  And of course we know, with a bit of a tear, Microsoft bought Sysinternals, which I'm sure was good for Mark, and I'm glad for that.



About a month ago he sent me a tweet saying, hey, Steve, I'd like to send you a copy of my new book.  Where can I send it?  And I got my address back to him, and Federal Express arrived the next day.  Now, the good news is, it is available in e-format for the Kindle.  So I bought it because I wanted to read it on the Kindle, but I really am tickled to have a physical copy of it from him.  The book is fiction.  And I had to stop myself from reading it last night because - and it'll be finished way before you hear from me again.  It's called "Zero Day."



LEO:  Yeah, we saw that he did that, that it's fiction, a novel.



STEVE:  It is good.



LEO:  Is it good?  See, that was my concern is like, well, Mark's a great programmer.  He's a brilliant systems guy.  But...



STEVE:  Yes.  It is - the reason I call it a reading assignment is, I mean, it is factually accurate and chilling.  He basically - and I'm at the 50 percent point.  I'm exactly at 50 percent.  It's when I finally said, okay, stop reading, Steve, you've got to go to sleep so you can do the podcast in the morning.  And I can't wait to finish it.  I have a sneaking suspicion of what's going to happen and where he's going to go with it.  But it is really good.  He does a very good job of painting the picture of the way we've become so dependent upon computers, and what would happen if this continues as we expect, and how it could happen that something really bad would happen.



Anyway, it's fiction.  I wouldn't quite call it science fiction.  I mean, it's really grounded in fact.  And it's not a long read.  It's just very pleasant.  So I haven't finished it yet.  As I said, I'm 50 percent of the way.  But I wanted to give our listeners a heads-up that someone we've spoken of who really knows his way around the technology has written a book based on this technology.  And, I mean, it's like a fictionalized version of this podcast because all the things that we've talked about, rootkits and viruses and propagation and nuclear reactors, I mean, it's weird that this thing came out when it did relative to things that have been going on.  So I just, so far, I can really recommend it.  I think it's a nice piece of work.



LEO:  I can't wait to read it.  It is on Amazon.  As you said, it's available for Kindle.  There is no audio book, unfortunately.  "Zero Day."



STEVE:  It would be too soon, I would think, for an audio.  But don't audios tend to lag a little bit because you've got to have time for someone to read them.



LEO:  Depends on the publisher.  Lately, if it's - and I think this is because it's not a well-known author.  But lately a lot of stuff is coming out day and date with the print version.  Very much more common.



STEVE:  Okay.  So a short note from James, he called himself "Jay," Truesdale, who is a podcast listener.  The subject is "SpinRite's temperature sensor."  And he said, "Dear Steve, I finally have a SpinRite story to share, but not like any other I've heard so far.  I went to look at a friend's computer that was really running slow.  I pointed out the whine that was coming from the computer as a bad sign, and got to work on the usual Windows cleanup, including running the defragger.  It was still slow afterwards, and I was out of time.  So I took the computer home so I could continue working on it there.



"I let SpinRite loose on the SATA hard drive and came back later to check on its progress.  I found a message from SpinRite stating that the drive was overheating.  I shut down the computer and checked for ventilation problems and found none.  I swapped out the friend's hard disk for one of my own hard disks, putting it into his machine, and ran SpinRite again.  SpinRite ran just fine with my hard disk.  So I knew there was not a ventilation problem, and that the original hard disk was suspect.



"I ordered a new hard disk, and when it arrived I ran SpinRite on the new hard disk.  No problems were reported.  I hooked both hard drives to the computer and used a small fan to keep the drives cool, and then used the open source tool Clonezilla to copy the old hard disk to the new hard disk.  The new hard disk booted right up, and Windows XP seems to be running just fine now.  I don't know why the original hard disk was running hot.  But due to SpinRite's temperature warning, we were able to replace the hard disk before any data was lost.  Thanks for the great podcast.  James Truesdale."



LEO:  You don't have a thermometer in SpinRite.



STEVE:  One of the things that SpinRite does is it continually polls the drive's SMART data.  And we talked about SMART data being sometimes turned off.  SpinRite checks and turns it on and notifies the user that it's doing so, so that it's able to keep an eye on the drive on the fly while it's running.  And actually this is one of the coolest things SpinRite does is that SMART, the Self Monitoring And Reporting Technology, is it's useful, sort of, but where you really want it is to be monitoring the SMART data while the drive is under stress, that is, while it's actually doing work.  That's when the parameters will demonstrate that the drive is having a problem.



But that's not normally the way SMART is used.  It's the way SpinRite uses it.  And as far as I know, SpinRite is unique in the industry in doing so.  And in fact, when I was developing it, a lot of people in the forum were saying, oh, Steve, I don't know if you're able to poll SMART data on the fly while you're using the drive.  And I said, well, we're going to find out.  And it turns out we've never had a problem with that.  Of course I wrote it carefully.



But one of the things it does is it polls the drive's temperature constantly.  And if it exceeds the manufacturer's upper safe temperature limit, SpinRite will stop because it turns out the act of running SpinRite will generate more heat from the drive because it's seeking constantly, it's tick tick tick tick tick tick tick tick tick from one cylinder to the next.  And each of that generates some mechanical energy which ends up actually increasing the drive's temperature.  And we find often, or more often than on desktops, laptop drives will overheat when they're, like, not in a place where they're able to get enough ventilation because laptops notoriously have a problem being so small and needing to have small fans and just small air openings.  They have a hard time moving enough air across their little drives to keep them cool.  And oftentimes, unfortunately, ventilation is an afterthought.  So that's just one more little goody that SpinRite brings.



LEO:  'Tis a goody.  Coming up we're going to talk about how random numbers work on a deterministic thing like a computer.  How would you make something random?  I mean, truly random?



STEVE:  How can you get randomness when there's nothing random there?



LEO:  Steve, let's talk random numbers.  What do you say?



STEVE:  Well, so, okay.  One of the reasons that I've always been a little bit annoyed by the people who talk about security through obscurity is no security is that, eh, it's not quite correct.  I mean, and I've hedged that often because there are - the fact is there is always a secret of some kind in security.  It may be the jaggedy, the exact pattern of jaggedy teeth on a key that you insert in the keyhole.  Or your fingerprint that you want to keep secret, and you don't want to spread around.  And we've talked about people being scanned at Disneyland.



But in all of the crypto that we've talked about, anytime we're establishing an SSL connection to a remote location, or we're encrypting a file just in place, or encrypting a drive, we're providing some sort of authentication and oftentimes a password.  But separate from that there is a secret key.  In some cases, in the case of asymmetric encryption, public key encryption, you've got two different keys, one able to encrypt and the other able to decrypt, that is, to reverse what the first one does.  But again, at least one of them, in typical use, is kept secret.



And remember that even asymmetric encryption is so slow that it doesn't actually encrypt the payload.  You don't actually, even if you're using public key encryption, you're not actually using the public key to encrypt the bulk data.  Instead, you come up with a random key, and that's what you encrypt with the public, the asymmetric public key.  And then you use that random key to actually do the data encryption, to do symmetric encryption, which is vastly faster.  But in all of these scenarios where you're using SSL to connect to remote location, you're encrypting a file, you're encrypting a drive, you always have some sort of key.  And that key is typically generated by some sort of random number generator.



Well, the problem, and this is a problem that goes way back in time, is that, as we know, computers are completely deterministic.  That is, given a known starting state with known programs and known inputs, they will always follow a path of instructions and jumps and so forth, I mean, it may be, and typically is, incredibly complicated.  But it's deterministic.  The program is always going to do the same thing, given the same program, the same instructions, and the same computer that's executing them.



So the question is, okay, that's unfortunately not what we want in the case of getting something random.  So let's step back a little bit and say, well, okay, what's the goal here?  The goal is that, say that we were encrypting a communication.  And we're not going to password protect it.  We just want - Point A wants to talk to Point B, such as, for example, over an SSL connection.  So we need to come up with a symmetric encryption key that cannot be guessed, that is unknown and practically unknowable by an attacker.



And so if we have - when we bring an attacker in, we need to define what the threat model is for sort of like what it is we're trying to achieve.  And by that I mean, if the computer we're using were compromised, that is, if there was already malware in the machine which is able to see what the computer is doing, well, you can - anything you used to generate a key, no matter how good, for example, it was as a source of randomness, once this source of randomness had arrived at a final key, if the machine you're trying to use which you're assuming is secure is not, then it doesn't matter how good your source of randomness is.  You've got something bad in your computer, malware which is able to grab your key.



So obviously that's not the threat model that we're trying to guard against in establishing a secure communication between two points because we can't guard against it.  There is no practical means to guarantee that with the way our computers are designed today.  In that sort of scenario, in a communications scenario, we're dealing with a situation where the bad guy has no access to the key.  They may have access to the result of the key, and typically do.  They would have access to the encrypted data, the results from applying this secret encryption key.  But they don't have access to the key itself.



And so the idea is that we need to generate a secret of some length, either in one end or in both ends, such that knowing - and this is where this concept of randomness comes in.  Knowing even like prior keys or even maybe future keys, there's no way to predict the key that we're generating, no way to determine what the next key is going to be from the standpoint of the attacker who can see the consequences and may even have information about recent history of keys, but not the one we're trying to get directly.



Now, an early algorithm that I've referred to a couple times in the past is very weak.  It's called a "linear congruential pseudorandom number generator," which is a fancy term for a very sort of simple-minded random number generator.  It's the kind that was in, for example, the BASIC language when we were all cutting our teeth on programming in BASIC in high school, where you'd give it the Rnd() function, and it would spit out something that looked random.  Turns out that those were very, very poor random numbers.  But they were typically random enough for the little Star Trek simulations we were running, or rolling the dice, or guess the number between 1 and 10, the kind of things that the computers were being used for at the time.  A linear congruential pseudorandom number generator takes a number and multiplies it by one constant and adds another constant in order to get the next number, the next pseudorandom number.



Well, it's very fast because all you have is a multiply and an add.  But it's also very weak.  It works within a register of a certain size, which might be 16 bits or 32 bits.  You're multiplying a constant and then adding a constant.  And that's getting a different, for example, 16 or 32-bit number.  And then you do it again, and you get a different 32-bit number.  Essentially, if you pick the two constants well, it will march the number all over the territory.  If you imagine, like, a big - if you had a 16-bit number, you could imagine that is like in a grid, where the pseudorandom number it generates is jumping around within this grid in what looks to you an obviously not visually detectable pattern.  But any kind of cryptanalysis would immediately, if you gave it a few numbers, it would break the algorithm and determine what the constants were and be able to go back in history or forward in time in either direction in the sequence of very poor pseudorandom numbers.



So that's an example of an early, very bad pseudorandom number generator.  What's happened as we've moved forward, and as we've had to get cryptographically strong pseudorandom numbers, is a huge amount of industry and creativity has come to bear, to the point now where we have a good understanding for the strength of random numbers.  Cryptographic algorithms that we've talked about often like AES-128 or 256 can be used, as can cryptographic hashes.  And we always, however, have a problem of this determinism because in that simple example I gave with this linear congruential pseudorandom number generator, it obviously itself is a weak random number generator.  But it's still being - it's being hosted by a computer.  Well, our cryptographic approaches and hashes are also being hosted by a computer.  So we have this problem of how do we break free of operating in a deterministic environment?  How do we get something which is good enough?  How do we know it's good enough?  How do we prove it's good enough?  And what is good enough?  And that's our subject for two weeks from now, solving this problem.



LEO:  Can't wait.  That's fascinating stuff.  Next week, of course, we're taking questions.  And if you've got a question for Steve, you go to GRC.com/feedback and leave a question there.  And we'll do 10 or so good questions about this or any other topic.  Actually, I bet if we got some good questions about randomness, this would be a good, so to speak, seed for the following week's conversation.  I think this is fascinating.  And anybody who learns programming learns about Rnd, you know, the random number functions, and then learns that they repeat.



STEVE:  Well, if you...



LEO:  It's totally predictable.



STEVE:  Yes.  It's really bad.  And in fact there was a randomize function, you'll remember, that sort of was supposed to break us out of that repetition.  Now, sometimes having numbers repeatable is very useful.  For example, if you've got a process where you're doing some modeling, and driving a model with random numbers, sometimes you do want to be able to repeat exactly the same string of random numbers.  Or say, for example, that - remember when eEye, the security firm down in Aliso Viejo, was pounding on Windows, throwing random stuff at the Windows API until it broke, well, they may want to be able to set up an identical system and give the same sequence of not really random but pseudorandom data to Windows and watch it fail.  So there are times when you actually do want repetition in your random numbers.



LEO:  Interesting.



STEVE:  Although not always.  There's a page that is public on GRC that's GRC.com/ - and you can put it in right now, Leo, if you're curious - GRC.com/r&d/js.htm, as in JavaScript.  It is actually - that's a platform that I developed, it's the first JavaScript code that I wrote after I taught myself JavaScript recently for the project I'm working towards finishing now, which is the Passcode Designer that I've spoken briefly of before.  Anyway, that page, GRC.com/r&d...



LEO:  I love how you comment even your learning JavaScript stuff.  I love it, Steve.  This is a pro.  This is a pro.  He diagrams the stuff that's not even public.



STEVE:  Yeah, it was just [laughing].



LEO:  Such a pro, Steve.  You're unbelievable.



STEVE:  Well, that is my first JavaScript.  And I had to solve the problem of running something in the user's browser which didn't necessarily have access to a lot of entropy because JavaScript's own random number generator is known, many of them are known not to be good.  And we really can't count on the user to give us lots of randomness.  For example, when you're establishing an encrypted drive in TrueCrypt, you know, they have you move the mouse around.  And it's like, that just always annoyed me because that's - you could demonstrate that's not very random compared to what's available.  So anyway, so I solved the problem, as that page demonstrates and documents, for anyone who's curious.  And it's the heart of the random number generator technology which is then going to surface in the Passcode Designer that I hope to be showing our listeners very soon.



LEO:  I have to say, I have no idea what you're talking about here, but it's very - it's very cool.  I just love it.



STEVE:  That's my first JavaScript.



LEO:  Steve Gibson is at GRC.com.  That's where you go to get SpinRite.  And you've got to get SpinRite.  It's the world's best hard drive maintenance and recovery utility.



STEVE:  It'll even take your temperature.



LEO:  It'll even take your temperature.  GRC.com.  While you're there, lots of free stuff, including ShieldsUP!, Wizmo, the passwords, all of the stuff that he does is so great.  The Perfect Passwords.  You can get a good 64-character password, totally random, from Steve.



STEVE:  3,700 people do every day.



LEO:  Is that - wow.



STEVE:  3,700 a day.



LEO:  That's almost encouraging.  It's like, wow, there's somebody who cares, there are 3,700 people a day who care about security.



STEVE:  Yeah.



LEO:  I'll take it.  GRC.com.  Steve, it's always a pleasure.  Next week we answer questions.  Two weeks from now we continue our discussion of how random numbers, real random numbers can be generated from pseudorandom situations.



STEVE:  Where we get them and how we get them from a computer that really doesn't want to give them to us at all.



LEO:  It's a fight.



STEVE:  Yeah, it is.



LEO:  It's a battle.  Thanks, Steve.  Have a great week, and we'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#300

DATE:		May 12, 2011

TITLE:		Listener Feedback #117

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-300.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 300, recorded May 11, 2011:  Your questions, Steve's answers, #117.



It's time for Security Now!, the show that covers your security, privacy online.  And the man of the hour, as always, Mr. Steve Gibson of GRC.com.



STEVE GIBSON:  Hey, Leo.



LEO:  Good to see you.  And we've fixed your camera.



STEVE:  Great to be with you as always.  Episode 300.



LEO:  Yeah, we should do something, party or something.



STEVE:  Yeah, well, that's not one of my favorite numbers, though.  I mean, it's not 256 or 512.  When we get to 512, baby...



LEO:  You're going to like it, you know, we were trying to figure out what to - we're going to sell bricks in the new studio.  People can put their names or their company name or their Twitter handle on it or whatever.  And we decided to make the prices of the new bricks $128.  And if you want the paver, the square paver, that's $512.  If you want a copy of your brick, it'll be $64.  So you'll like that.



STEVE:  Very nice.  Those are good numbers, absolutely.



LEO:  Yay.  Let us - we have - it is nominally a Q&A episode, but you have thousands of things to talk about.



STEVE:  Well, yeah.  So much happened this week, and some interesting things that I wanted us to take our time and talk about, that I was afraid if we tried to, like, rush through those in order to get to a regular large set of questions, that we would not do the front of the show justice, which I really, in this case, there's really some interesting things for you and me to talk about.  So I had a couple of questions that were actually inspired by questions that I saw through Twitter, but which I've also seen in the regular Security Now! /feedback page.  So I'm going to sort of wrap up some things at the end from previous shows, sort of in the Q&A format.  But otherwise let's just talk about what happened this week because there was all kinds of stuff.



LEO:  Oh, I love it.  I love it when there's good news.



STEVE:  And I'm sure we've got a good podcast for everybody.



LEO:  We will indeed.  All right, Steve.  Let's get down to work.  We've got business to do.  First of all, did you read, did you finish Russinovich's book?



STEVE:  Yes, a couple days later.  You'll remember that I, like, made myself go to sleep Tuesday night because I was at 50 percent of the book and really enjoying it.  And by a couple days later I had finished it.  And so I'm glad you reminded me of that because I want to tell everyone that I recommend it without hesitation.  As I was, you know, I was thinking about the surprise you expressed at, like, Mark can write.  And if it said "Written by Michael Crichton" on the front, I wouldn't have thought twice.  I wouldn't have thought he was turning senile or he'd lost his ability or anything.  I mean, Mark can write, believe it or not, not only computer code and deeply understanding the technology of Windows.  He's regarded, as we know, as probably the person who's more about Windows security than anybody else there is.  I mean, more than Microsoft employees because he was on the outside poking around and creating all those cool utilities back in his Sysinternals days, before Microsoft bought them.



Anyway, the book is, as you'd expect, is factually accurate.  And I wish I knew that everyone who would read it had read it, so I wouldn't be concerned about spoiling it.  But the title is "Zero-Day."  And so from what I said last week, we can imagine that this is Mark's very interesting, really gripping portrayal of how it could be that something really bad happened on a global scale.  So it's, I mean, it's really interesting.  And as I said last week, it felt to me like our podcast, a fictionalized version of the stuff we talk about.  So my sense is our listeners in particular, probably more than any other audience I can imagine, would just, if you're a book reader, if you like fiction, and you listen to this podcast, I mean, there's the criteria.  I recommend it without hesitation.  It was just very pleasant and not Hamilton length.



LEO:  I'm in the middle of "The Dreaming Void," and I know what you mean when you say "Hamilton length."  Oh, my god.  But, you know, Dr. Mom read this book, and on your recommendation.  She's a regular in our chatroom.  And she said the same thing.  She said, "I missed, like, a good night's sleep.  I couldn't...."  And, by the way, she said she was terrified by it.  And that's, I think, interesting.



STEVE:  Actually, Leo, I found myself thinking, I don't want the bad guys to know this stuff.



LEO:  Yeah.



STEVE:  I mean, he went further than we had.  One of the chilling things he does is he reminds us of how pervasive our use of computers has become in this book...



LEO:  We rely on them entirely.



STEVE:  ...by citing specific examples.  And, for example, there was, in one case, and this isn't giving much away, but I guess we have an advanced plane, the 787, which not only does the computer completely fly it, so that there are no more cables, I mean, it's all fly by wire, but computers designed it.  So the computers are designing it and then flying what it is that they designed.  Well, what happens if something goes wrong with that?  So, I mean...



LEO:  Come on, Steve.



STEVE:  And on and on and on.  So, I mean, I know what Liz meant.  It is, as I'm reading this, I'm thinking, well, this just tells them how to do this.  I mean, he goes further than we have gone in the show.  And it's wonderful, so.



LEO:  There's actually, in that light, the fly-by-wire airplanes, there's actually a debate.  There's one airline, which shall remain nameless, that its pilots' union insisted that a pilot be able to do anything, completely override that airplane.  And the other - what happens as a result is pilots can do things that will crash a plane.  And so the real question is, you know, I guess you've got, you put a human there for a reason.  They should be able to override.  But should a human be able to do anything is the question.



STEVE:  Well, and in fact it sounds to me like Mark did a lot of research for this because, I mean, he talks about exactly what you're saying.  He talks about the psychology of the pilots and how in demonstration after demonstration during their training, they were shown that no matter what situation the plane was in, it would do a better job of recovering than they could.



LEO:  Doesn't that sound like "War Games" or "Titanic" or, I mean, haven't we seen this movie?  We've seen this movie.



STEVE:  Yeah, yeah.  Well, and, I mean, so...



LEO:  He has a trailer, by the way, on his website now for this book.



STEVE:  I'm glad.



LEO:  I can't wait to read it.



STEVE:  I just - I would love to be able to say more.  But it would - it's not fair to the people who like the idea of, like, the kind of things we talk about in this podcast, fictionalized by, like, the leading Windows security person in the world, who also can tell a story and develops characters.  I mean, now sitting here, I know all these people that Mark created and their interrelationships, I mean, vividly.  I mean, he's really a fiction writer.



LEO:  Well, but it's, you know, they say write what you know.  He sure knows his stuff.



STEVE:  Yeah, but it wasn't just...



LEO:  Oh, I can't wait to read it.



STEVE:  It wasn't just dry, like a recitation of security nonsense.  I mean, there's a full plot.  There's, you know, I just can't say anymore.  But, I mean, there's...



LEO:  I'm going to get it.  I can't wait.



STEVE:  There's bad guys.  There's murder.  There's all kinds of stuff.  I mean, it's really - there's assassins and, oh, it's just wonderful.  So, yeah.  I'm so pleased to have read it and to be able to tell our listeners because I'll bet you, I mean, I know that our sci-fi recommendations - because you have followed me with Hamilton and everything, and of course Michael McCollum at SciFi-AZ.  I get so much feedback from people, it's like, oh, I'm so glad I got turned on to this.  So here's another one.  I don't know how much more Mark will crank out.  But I'm reading No. 2 if there is one.



LEO:  Zerodaythebook.com is the website.  You can buy it there.  And it's always a good idea to buy the book through the author's website because he'll get, in addition to royalties, usually he'll get like an Amazon...



STEVE:  Nice, what do they call it, affiliate, right.



LEO:  ...affiliate fee.  So it could mean a buck fifty or more, per book more for him.



STEVE:  Yes.



LEO:  Kindle, did you read it on the Kindle?



STEVE:  I did, yes, because I'm just a Kindle fanatic.  And I did get a tweet from Steve Wooding in Hampshire, U.K., a listener, who was disappointed to see that it wasn't available outside the U.S. on the Kindle store through Amazon.  So maybe it just hasn't happened yet.  I can't imagine why...



LEO:  Publishing is such a byzantine and medieval system.



STEVE:  You think it's the publisher who says...



LEO:  Oh, it's always the publisher.  It's publishing rights.  It's just - it always is.  There's no audio book probably for the same reason.  And sometimes the audio books are available in one country, not the other; Kindle editions in one country, not the other.  It's because the U.S. publishing rights are different from the overseas publishing rights.



STEVE:  Well, and we do know, for example, that some Kindles will allow themselves to be read in their audio mode, and it blanks, is blocked in many others.



LEO:  Great reviews, too, by the way.



STEVE:  Oh, really?



LEO:  Fifty-two five-star reviews, yeah.



STEVE:  Oh, I'm really glad.  Like I said, if there's this, like - it's exactly like your reaction.  There's nothing, as I'm reading it, and even as I'm reading the second half after hearing your comment last week, your surprise.  I mean, and I was also...



LEO:  Well, you don't expect a guy like this to be a good writer, to be honest.



STEVE:  I know.  I mean, I'm sorry, but...



LEO:  And look at Michael Crichton, who was a physician first.  I mean, it's not unusual.  Scott Turow, who is a lawyer first.  You don't have to be born and bred to be a writer to be a great writer.



STEVE:  Well, and Crichton, a lot of Crichton's work was writing what he knew.



LEO:  Right.



STEVE:  Because he was an M.D., and he gave us "Andromeda Strain," and he understood the biology and the molecular level thing.  Well, here Mark has done the same thing.  He's given us a book which would satisfy any listener on this show, I mean, in terms of what he tells us.  And, yeah, I can understand Liz being a little bit frightened.  It's like, it is, I'm thinking, whoa, it's too possible, the scenario he paints.



LEO:  The chatroom is saying Asimov was a biochemist.  John Grisham was also a lawyer.  So a lot of lawyers become writers because nobody wants to be a lawyer.  Seriously.  The happiest lawyers I know are all ex-lawyers.



STEVE:  Well, and Grisham's books also...



LEO:  He knows the law.



STEVE:  Exactly.  Exactly.



LEO:  Mary Jo Foley gave it five stars on Amazon, as well.  So, yeah, okay, sold.



STEVE:  Yeah.



LEO:  That's great.



STEVE:  Oh, they're Amazon reviews.  Oh, good, I'm going to go back.  I thought - I didn't know where they were.



LEO:  Give it an Amazon review, yeah.



STEVE:  Okay, good.  I'll do that when I'm through with the podcast.  We had a blessedly small Patch Tuesday just a couple days ago.  There were only two updates.  One contained two fixes; the other contained just one.  So, which is nice.  We get to take a breather following last month's once again record-breaking Patch Tuesday.  And one of them was critical.  But really nothing to worry about for typical end users.  It only affected enterprises who are the typical users of Windows Server 2003 or 2008.



And it was a vulnerability that was found in the Windows Internet Name Service, WINS, which is not even installed by default.  This was an early protocol that Microsoft used back in the dawn of the Internet, and DNS essentially replaced it, the Internet's name service, domain name service.  So it's not installed on machines.  It's a problem if you did have an enterprise system using Server 2003, 2008, and had the WINS service exposed to the public, that is, to the public Internet.  That would be a problem.



So this was disclosed responsibly.  Microsoft patched it.  And they rated it critical because, if you fit the scenario, then you're in big trouble.  You need to get thing fixed.  But most people aren't going to be.  And then the other two fixes in the other one patch were two things in PowerPoint.  And I don't know why Microsoft rated them important instead of critical because they were remote code execution.  You go to a website that launches a PowerPoint on you, and it can run code.  But for whatever reason Microsoft - oh, I guess it's that you did get prompted.  There was a - it wasn't an automatic thing.  You would get prompted by PowerPoint, do you really want to run this?  And there wasn't a way around that.  So I think that's what allowed them to drop it down a little bit.  So anyway, worth doing, as always.  But way more tame than the patch blast that we received the month before.



LEO:  Yeah, that was a record.



STEVE:  Yes, it was.  They broke, well, in order to keep breaking your record, you have to keep doing worse and worse.



LEO:  Yeah, we don't want a record.  We're not gunning for a record.



STEVE:  Let alone a succession of records where each one escalates the prior one's record.  Now, this is a really interesting development, I thought.  TOR, which we've talked about, The Onion Router - and I know that we're picking up new listeners all the time.  So if you don't know the acronym TOR, which is The Onion Router, it's definitely worth going back and listening to the podcast we did on it [SN-070].  The technology that was developed - and this was developed with the help of funding from our friends at the EFF, the Electronic Frontier Foundation, that are powerful privacy advocates.  The technology is such that it's an anonymizing system, which is encrypted and anonymizing, so that when your traffic gets out on to the Internet ultimately, it's impossible, I mean really, truly impossible, and I don't say that often, to know where it came from.



And the way it's done is that there's a series of hops - I'm going to just summarize the podcast, but really go back and listen to it if you want more - a series of hops that your traffic makes among TOR servers, essentially, or like TOR routers, that are - there's a large network of them.  So your particular traffic will choose some number of hops and routes, and you have control over that at your end.  Each of these routers publishes a private key, I'm sorry, publishes a public key, has a private key, publishes its public key.



Knowing then the order in which your packet traffic is going to hop among these routers, you successively encrypt your data, one after the other, in the reverse order that your traffic is going to be hopping among the routers.  So you first encrypt with the last router's public key.  Then you encrypt with the next to the last router's public key.  Then you encrypt that.  So you've got multiple levels of encryption, thus this concept of an onion, you know, the notion of layers of an onion.



LEO:  You peel it back, yeah.  But you also see there the negative of this, which is there's considerable overhead.



STEVE:  Yes, yes.



LEO:  Slows you down a little bit.



STEVE:  So you then send this big blob, this onion, off to the first router.  What's cool is that it has its private key.  Only it can decrypt what's inside that layer.  But it can't decrypt anything more because that next layer is encrypted with the next router's public key, can only be decrypted with its private key.  So all that router can do is take a wrapper, a shell off the onion and forward it to the next one.  And it can do the same thing.  It can only take off the outer wrapper that it receives and then forwards it again.  So at every stage the intermediates can never see your traffic until you get to the final endpoint, where that final router takes the encryption that it knows how to remove, which was, because it's the last router, that was the first encryption, finally decrypting your traffic, and it puts it out on the Internet.



So the point is that this is a big network of these.  All of the traffic among them is encrypted.  Oh, and I should mention also, the next router hop and all the IP stuff is also encrypted.  So it's not even the case that an earlier router knows where it's going to go after it goes to the router it sends it on to.  That's contained successively within these layers.  So it was really designed beautifully to allow people the freedom of accessing the Internet anonymously.  The problem is that you have, to actually use it, you need to download the TOR system and a client.  Then, for example, if you're using Mozilla, Firefox, you need to use its add-on in order to link to that.  And there's a bunch of configuration stuff.  And the point is it's all a lot of overhead.



What's happened is the TOR folks have recently just announced that they're going to fork the Firefox project from Mozilla and integrate all of the TOR technology into their own Firefox.



LEO:  Oh, my goodness.  That's interesting.



STEVE:  Well...



LEO:  So you'll have a - you'll essentially have a browser that does it automatically.



STEVE:  Yes.  Yes.



LEO:  Wow.



STEVE:  And they're excited because it dramatically simplifies the use of TOR.  I mean, I've never bothered because I don't really have anything.  But it's like, I could see having a copy of that around, if for some reason - like I'm doing some security research, and I wanted to poke at something but not leave my identity there.  The other thing, because it would be essentially a TOR/Firefox browser, is they can do other anonymizing things to the headers.  And, I mean, you can imagine it would turn on the DNT.  I'm just joking because you couldn't be tracked through this anyway.  But...



LEO:  Wouldn't that be funny.



STEVE:  It would give them - I guess what's happened is there have been times when the TOR folks have been a little frustrated that Mozilla's priorities have been different from theirs.  Or things weren't fixed as quickly.  Or they've been waiting for Mozilla to do things that they wanted.  And so they just decided, okay, we're going to fork the project and integrate TOR into this browser, which...



LEO:  That's the beauty of open source, you know?  That's why we love open source.



STEVE:  Yeah.  And it affords this.  And so, anyway, I'll keep an eye on this.  It's been announced, but it doesn't exist yet.  So as soon as it does exist, I will be sure to let our listeners know because it would just be cool to have this.  It'll be a lot slower, as you said.  There's a lot of overhead in doing this.  But just to have a browser as simple as opening Firefox, a state-of-the-art browser, which automatically uses TOR and deals with all of the overhead, knows how to access the network, and where you know that you are absolutely untrackable.



I guess what I like it about it, too, is that there are certainly so many people who have a bona fide, useful, sort of innocent interest in doing this that can't handle the technology.  All of the TOR downloading and configuring and add-on and all that, that's enough off-putting that they don't end up getting the benefit of it.  So now it'll just be much easier.



LEO:  By the way, we have a whole show on TOR [SN-070].  If you want to know more about TOR, go back to the archives because there's a lot to talk about with TOR.  And there is one, there's a little bit of a vulnerability in the sense that the endpoint can be compromised.



STEVE:  Yes, I'm glad you said that because it's worth mentioning here in this discussion, although we did talk about it then.  And we've talked about TOR from time to time since.  And that is that the so-called "exit nodes" of the TOR network, you can imagine that law enforcement would be very interested in the traffic to and from those specific points.  So in the same way that any VPN provider, you wonder, if you're routing all your traffic through a VPN provider, well, they end up being someone that bad guys, or even good guys, law enforcement types, would be interested in making - in, like, surveilling because there's some reason people are using TOR.  There's some reason people are using a VPN.  Hopefully just for security, but it could be for nefarious purposes, as well.  So you're right, Leo, there is that side to it.



Okay, this is weird.  We know that we've got problems right now with uprising in Syria.  Apparently the Syrian Telecom Ministry has been perpetrating a nationwide man-in-the-middle attack against their citizenry for Facebook.  What they're doing is - the EFF got involved.  Someone named Mohammad, who is a Syrian, inside Syria, brought this to their attention and shared his logs and was able to dump his certificate out in order for them, for the EFF to take a look at it.  And what they found was that what Mohammad had was the real IP of Facebook.  Which means that this was not using DNS spoofing or tampering in order to give him the wrong IP.  He had the right IP, which meant it had to be using routers and proxies, which means that someone is actively filtering the traffic in and out of Syria.  And in the case of HTTPS access to Facebook - and by the way, we'll talk a little bit about that later - which Facebook reports that 9.6 million users are now using Facebook over HTTPS, thanks to the fact that they've added that option that we've talked about, the persistent use of SSL encryption over connections to Facebook.  So somebody is intercepting that traffic and returning an unsigned Facebook certificate.



LEO:  Oh, wow.



STEVE:  So you get warnings.  I mean, any browser that sees a certificate claiming to be from Facebook which has not been signed by a certificate authority that the browser trusts will pop up a security warning.



LEO:  Of course.



STEVE:  But many users don't really understand what that means, and so they click past it.  And in clicking past it they're allowing essentially their government, in this case the Syrian government, to monitor - to decrypt and then reencrypt in a proxy, in a transparent proxy, all of their traffic that passes through in order to monitor what they are seeing and posting on their supposedly secure Facebook page.  Obviously there's no security here.  So it is a concern that many governments do control certificate authorities.  I don't know, apparently Syria doesn't and couldn't talk anyone into giving them a certificate for Facebook.  Which is a good thing because that would be bad to have...



LEO:  Because then you wouldn't know; right?  It would appear to be a...



STEVE:  Well, actually, anyone who was using the very cool certificate auditing tool I talked about last week, I'm trying to remember the name of it, just a minute here, let me look, add-on, it's at the top of my list, I remember.  Certificate Patrol.  I'm still using Certificate Patrol and really like it.  So anyone using that would be notified, even if Syria had a properly signed certificate, because Certificate Patrol, before Syria did this, and this has only been done recently, if you had ever connected with Facebook prior to that time, then Certificate Patrol would have cached the certificate that you had.  Then when Syria tried to do this, well, first of all, not only - oh, yeah.  If Syria tried to do this with a valid signed certificate, Certificate Patrol would say, wait a minute, this doesn't match the certificate you had last time.  And it would present them both to you and allow you to then look at what's going on.  And, I mean, it does some nice forensic analysis.



So it would say "This certificate is not signed by the same certificate authority that signed the Facebook certificate you were using before."  It's unexpected that the site you are connecting with would change certificate authorities.  I mean, certainly it can be done.  Actually I'm planning to do it because I think I'm going to drop VeriSign after seeing that DigiCert is signing so many, well, in fact they're signing Facebook's.



LEO:  Really.  That's the one that's less expensive.



STEVE:  Yes, way less expensive...



LEO:  Awesome.



STEVE:  Yeah, I mean, so I could afford...



LEO:  If it's good enough for Facebook...



STEVE:  I could do EV certificates.  Yeah, if it's good enough for Facebook...



LEO:  How much are they?



STEVE:  I think they're down to, like, $300.



LEO:  Oh, we really should do it for TWiT, then.



STEVE:  Yeah.



LEO:  We are going to start, with the new website, we will allow people to log in and post stuff and so forth.  So I think we should absolutely do that, yeah.



STEVE:  Yeah.  And for me, too, GRC, I can't, I mean, VeriSign is thousands.  And it's like, oh.  And it's not just thousands once.  It's thousands every time you have to renew, which we know is a good thing because it does keep bad certificates from never expiring, and they need to.  But, boy, they're just raking in the dough, so.



I wanted to bring to our users' attention an interesting study that some researchers in Belgium and France did.  This was actually picked up by the Register over in the U.K.  But there are many sites, I guess like a hundred file hosting sites - like RapidShare, FileFactory, Easyshare - which allow users to upload files of any size, typically large files, and then they give those files a unique URL, the idea being that, I mean, the URL almost looks sort of like a little crypto key.  It's not short like a little bit.ly key where the whole goal is to have it short.  It normally looks like it's very unguessable, and that's the point is they're saying that you don't have to worry about anybody else getting a hold of these files because, look at that URL, no one's ever going to figure that out.  Well,  these researchers conducted a couple of experiments.  They put some of their own web spiders on these sites and collected thousands of private files.  And they then...



LEO:  Wow.



STEVE:  Yes.  So...



LEO:  Just by randomly guessing...



STEVE:  Well, or maybe they looked at, like, at a succession...



LEO:  Maybe they found an algorithm.



STEVE:  Exactly, they looked at a succession of the URLs and saw what the pattern was.  And it's obviously not very good because, if it were really good crypto, and it was sufficiently long, then the chance of just by brute forcing, basically they're brute forcing the URLs.  The chance of brute forcing a sufficiently long URL would never make it worthwhile.  You just...



LEO:  There are many of these services.  Do they say which ones?



STEVE:  Well, they said a significant percentage of the hundred file-hosting services they studied made it trivial for outsiders to access the files simply by guessing the URLs that are bound to each uploaded file.  And RapidShare, FileFactory, and Easyshare were mentioned.  And so the second thing these researchers did was they put their own files up with beacons in them that would allow them to determine if somebody else downloaded them.



LEO:  Oh.



STEVE:  They never gave out the URLs.  And quoting from this, "They also used the sites to store private files that contained Internet beacons, so they'd know if anyone opened them.  Over a month's span, 80 unique IP addresses accessed the so-called "honey files" 275 times.



LEO:  Oh, dear.  So that's a reasonable thing is, well, one thing if we can brute it, but is anybody trying this?  And apparently they are.



STEVE:  Yes.  Which if course indicates "the weakness is already being exploited in the wild to harvest data many users believe is not available for general consumption."  So I wanted to give a heads-up to all of our listeners that this is an instance where you pre-encrypt what you are going to post up there.  And then through a separate channel you let your recipient know the passphrase for the encryption so that you could still use these file hosting services.  But don't just put a spreadsheet of important financial data up there and assume that no one is going to ever get to it or see it.  We have evidence now that these sites are being, literally, they are being dredged for information that people would not want to have made public.



LEO:  That just tells you something, wow.  Wow.



STEVE:  Uh-huh.



LEO:  Isn't that interesting.  I don't, you know, I use Dropbox and other stuff.  But I would not, I agree, I think it would be imprudent to use this for something private.  But I wouldn't always assume that, you know?



STEVE:  I have a new acronym.  Unfortunately, it's PEE, P-E-E.  I can't think of anything else.



LEO:  That's fine.



STEVE:  It's Pre-Egression Encryption.



LEO:  Oh, Pre-Egression Encryption.



STEVE:  Yeah.  So you pre-encrypt before anything egresses from your location.



LEO:  I think that's a good acronym.  I certainly won't forget it.



STEVE:  Pre-Egression Encryption.



LEO:  Wow.



STEVE:  So, okay.  I loved this next story because I couldn't have - it sounds like someone's been listening to the podcast who did this report.  First of all, it's based on a new bill that has been submitted by Sen. Rockefeller.  And this is the Do Not Track Bill, legislation that's the thing I've been saying we need.  It is the enforcement of the DNT header, essentially.  And this was a story carried by Cecilia Kang in the Washington Post.  I just want to read this because, like I said, I couldn't have written this any better:



"Sen. John D. Rockefeller ... on Monday introduced an online 'do not track' privacy bill that would allow consumers to block Internet companies from following their activity on the Web.  The Do-Not-Track Online Act of 2011 comes amid increased attention by lawmakers on creating privacy rules for the Internet.  The White House has called for such rules but has not supported a specific mandate that would block companies from tracking users.



"Rockefeller, chairman of the Commerce, Science, and Teleport" - teleportation.  I wish.



LEO:  I wish we had teleportation, yeah.



STEVE:  "...and Transportation Committee" - I've been reading way too much science fiction - "said in a statement that recent reports of privacy breaches show that companies have too much freedom to collect user data on the Internet.  His legislation would force companies to abide by a consumer's choice to opt out of such data collection.  The Federal Trade Commission would draw up specific 'do not track' rules.  The agency and states' attorneys general would enforce the law.  And the legislation would apply to mobile phones  a growing platform for accessing the Internet."



It says, quote, "'I believe consumers have a right to decide whether their information can be collected and used online,' Rockefeller said in a statement.  'This bill offers a simple, straightforward way for people to stop companies from tracking their movements online.'  Already, Microsoft's [forthcoming version of Internet Explorer] and Mozilla's Firefox browsers have been redesigned to allow users to block marketers from tracking what sites they visit and their other activities online."  Now, we know that's not quite true because they don't actively block, they simply request.  And thus has been the controversy of the DNT header, is because everyone says, yeah, but it's optional.  People can ignore it.



And it says, so going on in the article, it says, "But without a law, no Internet company is required to honor the consumers' request, privacy groups said.  'This bill will put regulatory support behind these industry initiatives and make sure that online providers listen to the many consumers who want to clearly say "No" to online tracking.  'This complements the comprehensive online privacy legislation introduced by Senators Kerry and McCain last month.'"



So I just wanted to bring this to the attention of our listeners.  This is, I mean, it is what we need in order for the DNT header to happen, essentially.  And...



LEO:  Now, it would not prohibit a website from tracking a incoming request's IP address, would it?



STEVE:  No.  And Leo, I've been thinking a lot about what you said when we talked about this, and TWiT.  And when you look at the detailed legislation, and I have, although I'm not going to bother our listeners with it because we know that at this point it's just been a bill that's been submitted.  It's been talked about being set up, being hooked onto Kerry and McCain's bill as an amendment to it in order to incorporate this technology.  But they all really do talk about information gathering.  And, I mean, like address and age and specific criteria, rather than just like using their IP address in order to disambiguate queries.  So I really think that what Podtrac is doing and which you and your industry depend upon for developing good numbers, I think that's going to be okay.



LEO:  Well, and not just me, but every website in the log keeps track of an incoming IP address.



STEVE:  True, true.



LEO:  I mean, that's just what happens.  And I don't know how you would turn that off.  That's how browsers work.  Otherwise they can't have a conversation.



STEVE:  True.  And I guess the problem is, when I was talking about, well, it'd be easy to just bring up a dialogue box to say we're Podtrac, we need to count you in order to credit TechTV with your download.  The problem is iTunes is downloading podcasts autonomously.  So it's unable to do that.  Yeah, I just don't - I don't think it's going to be a problem.  I mean...



LEO:  I hope not, for me.  I don't think either because I just think it would break the Internet if you said websites cannot record an IP address of an incoming request.  That would just break websites.  It would break everything.



STEVE:  Yeah.  Well, and remember we're talking, there's certainly a difference between first party and third party.  There's a general understanding, well, in fact Google and Facebook are screaming at the same time about newly introduced California legislation.  This is a Senate Bill 761 that was introduced by Alan Lowenthal, who's out of Long Beach.  He's got legislation which is proposing that companies doing business, doing online business in California would be required to offer an opt-out privacy mechanism for consumers.  And, I mean, and frankly, there's a long list of people who signed a letter objecting to this - Google, Facebook, Yahoo!, American Express, Experian, Allstate, Time Warner Cable, the MPAA of all people, Chamber of Commerce and, like, 20 other companies have said  whoa, whoa, whoa.  Actually they said in their letter that "Senate Bill 761 would create an unnecessary, unenforceable, and unconstitutional regulatory burden on Internet commerce.  The measure would negatively affect consumers who have come to expect rich content and free services through the Internet, and would make them more vulnerable to security threats."  I don't know how you get some of that.  I mean, that seems like it's - their response is being overblown.  But clearly there's a difference between people going to a site and third-party tracking, third-party data aggregation.



Now, the problem is, of course, that Google's existence is owed to the fact that they're able to, well, especially with the purchase of DoubleClick, they're able to serve ads that are interesting to people.  I think it's been clever that they're able to use the search terms the user is querying in order to choose ads.  There you're not really having to build a history or a profile, as many of these other media companies are.  So again, and I think that what Podtrac is doing is just totally benign compared to this.  But, well, and the good news is we'll end up with something somewhere in between that the legislators are happy with, and that the Googles and Facebooks of the world are saying, okay, we can live with that, too.  I don't know what the answer is going to be.  But there really is, really is growing tension on the Internet over this issue.  It's not going away.



LEO:  Well, I'm tense.  I would, you know, okay.  I don't want to go out of business.  We get a lot of free stuff based on advertising, including all of the things you listen to on TWiT.  And I don't want to go to a paid model.  But advertising does require - it's a quid pro quo.  I think...



STEVE:  It needs to have numbers.



LEO:  Yeah.  And I think that - I don't think - I think people understand that.  I would hope.  But the problem is, if it's opt-in, that's problematic. 



STEVE:  Yeah.  Well, okay.  Now, in your case, you're not interested at all in who your listeners are.  You're interested in not double counting them.



LEO:  Right.



STEVE:  But you don't care what their demographics are...



LEO:  We don't crack them.



STEVE:  ...their age range, how many children they have in the household.  That's the kind of stuff which really creeps people out.  When knowledgeable people look at the extent of what this data aggregation ends up meaning, and the fact that it ends up being de-anonymized ultimately - remember we went through that period of time where you'd, like, you'd have free offers, and you'd sign up for something?  Well, those free offer sites were using advertisers and providing all of that non-anonymous information behind the scenes back to the advertisers and being paid heavily for it because it meant so much.  So, I mean, that's what creeps people out.  And I think that's what we're, I mean, that's the tracking.  It's not just, hey, I went to a website, I want it to forget that I was there.  It's, no, it's like, I want DoubleClick not to know where I've been and all the sites I've been today.



LEO:  Right.  Interesting.  We live in interesting times.



STEVE:  We really do.



LEO:  You know, it's always a risk when you start a new business, especially in a new area like this.  I just read an article about a California state law that essentially puts money transfer companies out of business, if you're not doing it with a credit card, because you have to get a license from each state.  And each state can be lots of money.  Half a million dollars in the state of California.



STEVE:  Well, and iTunes blocked Bitcoin because they said...



LEO:  Yeah.  That's going to put Bitcoin out of business.



STEVE:  They said they were an inter- that Bitcoin was an intermediate currency, and that ran afoul of some iTunes regulation.  And so there will be no Bitcoin app for the iPad or iPhone.  Which is annoying.



A hacker, I guess he has to be a hacker because of what I'm going to explain here, named Gordon Maddern, who has a site called PureHacking.com, he wrote, and this ended up being a big story:  "About a month ago I was chatting on Skype to a college about a payload for one of our clients.  Completely by accident, my payload executed in my colleague's Skype client."



LEO:  Oh, boy.



STEVE:  "I decided to investigate a little further and found that the Windows and Linux clients were not vulnerable.  It was only the Mac Skype client that seemed to be affected.  So I decided to test another Mac and sent the payload to my girlfriend.  She wasn't too happy with me."



LEO:  I pwned her computer.



STEVE:  Although if she's his girlfriend she already knows what he's up to.  "She wasn't too happy with me as it also left her Skype unusable for several days."



LEO:  Wow, wow.



STEVE:  "At this point I figured out what was needed to execute code.  So I put together a proof-of-concept using Metasploit and Meterpreter as a payload."  Meterpreter is something we've never talked about before.  It's a piece of Metasploit that allows for the easier creation of DLLs for injection into compromised processes.  So it's like, okay, fine.  So, he says "Lo and behold, I was able to remotely gain a shell" on the remote Mac.  "So after a lot of trouble trying to find the right person in Skype to notify" - I don't know whether that's going to get better or worse, Leo.  We haven't mentioned on the podcast yet something that I'm sure everyone probably already knows.



LEO:  Call Steve Ballmer.  He could fix it.



STEVE:  Yeah, that Microsoft bought Skype for $8.5 million.



LEO:  Billion, yeah.



STEVE:  Yeah, billion.  I will say that I'm happy that we'll be moving to Vidyo.



LEO:  Yeah, I mean, I don't know if Microsoft will be a bad steward or anything, in fact.  And we'll still use Skype when we can't use Vidyo.  But it's nice to have alternatives.



STEVE:  Yeah.



LEO:  And I think Skype will be around.



STEVE:  Although you've got to wonder if they'll be as diligent about worrying and managing and maintaining the other platforms.



LEO:  One would hope.



STEVE:  Yeah.  Anyway, so he says, "After a lot of trouble trying to find the right person in Skype to notify, I was able to get the correct details for the security team in Skype.  I notified them on the security vulnerability and was given the standard, 'Thank you for showing an interest in Skype security.  We are aware of this issue and will be addressing it in the next hotfix.'"  And he says, "That was over a month ago, and there has still not been a hotfix released.  The long and short of it is that an attacker needs only to send a victim a message, and they can gain remote control of the victim's Mac.  This is extremely wormable and dangerous.  Pure Hacking...."



LEO:  Yow.  I don't like the word "wormable."  I don't know what that means, but it's not good.



STEVE:  And that was it.  That was what the news covered was Skype for Mac is wormable.



LEO:  Wormable.



STEVE:  What it means is that a non - because many people leave their Skype clients running all the time, and Skype up, and when you are in Skype you can see all the other contacts, this could be a flash worm that would run through Skype and in a matter of minutes take over all the Macs that are interlinked through Skype, is what we're saying.



LEO:  That's really amazing.  They didn't force an update, but they did offer an update.



STEVE:  Well, he says, "Pure Hacking won't give specifics on how to perform this attack until a patch from Skype is released.  However, we will give a full disclosure after Skype takes action or a reasonable, responsible disclosure period has elapsed."  Now, in his own update he has confirmed that Skype has fixed this issue in 5.1.0.922.  But you have to go, I guess...



LEO:  And push it.  No, you have to actually say I want an update.



STEVE:  Well, no, I tried that.  And it didn't give it to me.  I'm back on .914.  And I fired up my Skype, and I said check for updates, and it said no updates are available.



LEO:  Huh.



STEVE:  So I think you have to go to Skype and download new Skype in order to get it.  It didn't - not only did it not offer it, but when I said check for updates, it said nope, got none.  So...



LEO:  Well, I'm at 922, so I can't test it over here.



STEVE:  Oh, no kidding, so you're already updated.



LEO:  Well, I did it, yeah.  Soon as I read that story I updated it.  Are you kidding?  I run Skype.  Now, this is only Skype for the Mac, by the way.



STEVE:  Wait, you don't want to be part of the flash worm that...



LEO:  No, no, thank you.  But this is, again, only on the Mac.  And for those who are curious, we don't run Skype - we run Skype on Windows.  For right now that's what you're on, for instance, is a Windows instance.  But many of our users, many of our hosts use Skype for the Mac.  And most of them have actually downgraded because they hated 5 so much that they've gone back to 2.8.  So, which is, by the way, safe.



STEVE:  They did mess up the UI on...



LEO:  Oh, did they screw it up.



STEVE:  Yeah.



LEO:  That's interesting.  And now, on my other Mac, where I'm running 2.8, it says "New version of Skype available," and it's going to 935.  So...



STEVE:  Wow, okay.



LEO:  ...who knows now what's happening.



STEVE:  So it sounds like they probably did push out something quickly because they were aware that having a flash worm through interconnected Macs on Skype...



LEO:  Not such a good thing.



STEVE:  That would not be good, no.  No.  In fact, it may have lowered their purchase price to Microsoft.



LEO:  I don't know.  I don't know how it could get any higher.



STEVE:  Oh, wait, yeah, it took out all the Macs.  Huh, maybe that wouldn't be - well, anyway.  So.  Facebook applications...



LEO:  What?  Yes.



STEVE:  ...turn out to have been accidentally leaking access to third parties for all time.



LEO:  Again.



STEVE:  Uh-huh.  Okay.  So this was revealed by Symantec, who provided an analysis.  They said, "According to Symantec's analysis, the problem was caused by a flaw in the old Facebook API which apps use to authenticate their account access.  When a user grants account access to a web app" - like a Facebook app - "the app is given an 'access token' which it is then able to renew.  Symantec said that this access token can be mistakenly inserted into a URL returned by Facebook" and provided to the app server, which then receives it.  And so it will - okay.  So I got myself tangled up here.  "If the app loads an ad banner or analytics code as the next step, it will send that URL, which includes the access token, in the referrer field of its HTTP request for the content.  This referrer data is likely to have been stored in the log file on the advertising or analytics providers' server."



So we've talked about referrer headers before, and this is, like, this is a classic "oops" privacy leak.  So what happened is a Facebook app would identify itself to Facebook and say I need access to this user's account on their behalf.  And the user has given the app permission, which the user would have.  But the user has been assuming that the app would not leak that permission.  And so what happens is, if the app then receives the URL containing the access token, which it needs in order to impersonate the user, if that app then showed an ad, then as happens with referrer fields, the referred by essentially would be the URL that the app used which contained the token which allows the account to be accessed.



So essentially apps have been leaking an impersonation token that allows third parties, advertisers and analytics companies, I mean, apparently there are, like, logs out there with these HTTP referrer headers in them, because that's one of the things that web servers log.  And these never die.  These don't time out.  They don't get stale.  This is a cryptographic token that allows anyone who gets it to impersonate that Facebook user.  So all Facebook users have to change their password.  That's what this comes down to.



LEO:  What?



STEVE:  Yes.



LEO:  Like now?



STEVE:  Like now.



LEO:  What if I don't use apps?  I don't use any apps.



STEVE:  Then you're okay.  Then you would not have had...



LEO:  Of course, how do you know what's an app?



STEVE:  Exactly.  Any of these little goodies.  Apparently it's, if something says they want permission to act on your behalf, they want access to your wall, they want access to your whatever...



LEO:  Yeah.  I use a lot of that.



STEVE:  Okay, well, those are apps.  So...



LEO:  But that token's a one-time use token, or is it a permanent token?



STEVE:  It's a permanent token.



LEO:  Oh, fudgsicles.



STEVE:  I know.  Now, okay.  So...



LEO:  That means these will all be logged out, too; right?  All these apps I'll have to reauthenticate?  Or no?



STEVE:  No.  They will have to reauthenticate.  But they're doing that anyway.



LEO:  Oh, okay.



STEVE:  So what happens is, if you change your password, then you instantly obsolete all of this past leakage such that the app has to come back and get a new token and...



LEO:  Why isn't this a huge news story?



STEVE:  I know.



LEO:  Why isn't this on the front page of USA Today?  They have 600 million users, all of whom were just compromised.



STEVE:  Yeah.



LEO:  What can they do with this password?  What can they do with this?



STEVE:  Anybody who has one of these tokens, and Symantec's blog makes it very clear that server logs all over the world are full of these tokens, are able to impersonate the Facebook user.  They're able to do anything that the app, that the user gave the app permission to do.  That permission has then been leaked.



LEO:  I can't believe there's not a big banner on Facebook that says you have to change your passwords.  I don't understand.  I'm baffled by this.  That means, I mean, I'm thinking of my son, every one of his friends in high school.  They're not going to know about this.



STEVE:  No.  Now, maybe the reason this hasn't been made more of is that, well, first of all, Facebook would rather not.



LEO:  Well, yeah.



STEVE:  They have fixed the problem, and they've also moved to a new authentication system.  They'll be using what's called OAuth 2.0, Open Auth 2.0.  We're going to have to do a podcast about this in detail.



LEO:  OAuth is incredible.  I love OAuth.



STEVE:  Yes.  Stina and I talk about it every time we get together for coffee, from YubiKey fame.



LEO:  You're such nerds.



STEVE:  Ooh, let's talk about OAuth.  So the good news is that Facebook is really tightening things up.  They have implemented OAuth 2.0.



LEO:  Good.



STEVE:  It's not mandatory yet, but they are going to sunset.



LEO:  It would have to be mandatory with the apps, not with you, but with the apps that are requesting your authentication.



STEVE:  Correct, correct.  So nothing will change from the user standpoint.  But there'll be much tighter authentication using OAuth 2.0 for the apps.  And they'll be bringing in, they'll be shortly bringing online an SDK, a Software Development Kit, for apps, telling them we're lowering the boom on you on September 1st of 2011.  So you have between - I think the SDK is supposed to be available in June or July timeframe, so a couple months from now.  But all - and it's already running.  I mean, Facebook themselves has switched over.



So they're making good improvements.  And all apps will have to switch to that.  In the meantime, they are no longer leaking this user token in the URL that they provide to apps that are wanting to authenticate and then act on behalf of users.  But all the old ones do not expire.  And Symantec has said the only way to fix it is for the user to change their password to invalidate this.  So my sense is it's broad, and it's distributed.  But, I mean, change your password.



LEO:  I can't believe that this isn't, like, I mean, this is, well, okay.  Unless I'm misunderstanding what they can do with this.  I mean, they can't - all they can do is post to your wall, stuff like that.  Whatever permissions you gave these apps.



STEVE:  Yes.  That token is absolutely restricted to whatever it is you gave the app permission to do.



LEO:  Although this is what the bad guys do.  They post something on your wall that says, hey, you've got to see this video of the new TWiT cottage, and it links to what looks like YouTube, and then it says, oh, your Flash is out of date, and you say, oh, I'd better update it.  And then you've got malware.  So that's really - it's things like that.  I mean, I don't - my profile is public, so I'm not worried about that.  My son is.



STEVE:  As you said, Leo, it is people, for example, going to your Facebook page, that your page then infects.



LEO:  Right.



STEVE:  And I didn't...



LEO:  Could it do that?  Could it do that, a spontaneous infection?



STEVE:  Oh, yeah.



LEO:  Oh, crap.



STEVE:  I was just going to say, I didn't - we talked last week about Google Images, the problem that we're seeing with Google Images where the images are malicious.



LEO:  Right.  Injection.



STEVE:  Yes.



LEO:  And that's not coming from Google, but on the image search you get an image from the offending page which has an infection in it.



STEVE:  Exactly.  And I did see reference in some forums in the last week where people were commenting about the problem with Google Images and that just in hovering over the image where it zoomed in, like magnified it, that grabbed his computer.



LEO:  Fudge.



STEVE:  I mean, that was...



LEO:  And that's the kind of thing of course Facebook, you know, it's just a natural.



STEVE:  Yes.  And so here's the problem, is that the scenario would be the bad guys who now know about this will get the server logs of, like, advertisers or anybody with an affiliated relationship to these apps, and now they know to scan the referrer field for these tokens.  And those tokens will allow them to act as if they were the app to which the user had given permission.  Now, you could revoke the app permission, and that would protect you, too.  But it's easier just to change your Facebook password.



LEO:  Yeah, especially since you probably have hundreds of app permissions, as most people do, I mean...



STEVE:  Yeah, yeah.



LEO:  I'm just, again, I'm stunned that this isn't, I mean, holy cow.



STEVE:  I don't have a date here.  I don't know how old this is.  But this is just - it just happened.



LEO:  Well, I'm changing my password right now.  And why not, anyway.  It's a good thing to do from time to time anyway.



STEVE:  Yeah.  The title was "Facebook Applications Accidentally Leaking Access to Third Parties."  And, whoops.  Oh, and that's actually the title of Symantec's blog.



LEO:  It came out yesterday.



STEVE:  Okay.  So it's been just recent.



LEO:  There should be a big banner on Facebook saying...



STEVE:  Please, everybody...



LEO:  ...change your password.



STEVE:  ...change your password.  Yeah, you're right.  They really ought to step up and take responsibility for this.  Because, I mean, otherwise it's going to be - it'll never get enough attention.  Users won't change their passwords.  And there will be diffuse attacks.  There will be, where these logs are available, bad guys will pillage them and sort through them, find the tokens, and then get up to mischief.



LEO:  I'm trying to find - of course you can't find anything on Facebook.  I'm just trying to find in my account settings where I've given authorization.  Let's see, apps and websites.  So you have to go to Account - this is ridiculous - Account > Privacy Settings > Apps & Websites.  Down at the bottom, of course, not where you'd think it is.  I just went through this with my son last night.  He said, "People can see my pictures?"  I said, "Well, yeah.  You didn't know that?"  He said, "No," because the default is they can see his pictures.  So I showed him how to change that so only friends could see his pictures.  Now I've got to say, "And by the way, Henry, change your passwords."



STEVE:  Just "password."  Just your master login password.



LEO:  Just your password.



STEVE:  Yeah.



LEO:  So Pulse, Eventbrite, Empire Avenue, Seesmic Web, Foursquare.  No, there is one button, turn off all platform apps.  But then I'd have to change all of them.  I'd have to log them back in.  So it's easier just to change a password.



STEVE:  Yeah.



LEO:  Crazy.



STEVE:  Yes.  And speaking of getting up to no good, I just thought, oh, I wonder how many Firesheep downloads we've had so far.



LEO:  This is Firesheep-like, isn't it.  Kind of the same result.



STEVE:  Well, yeah.  I mean, it is an impersonation attack.  The bad news is, this has been happening since 2007, Leo.  So, I mean, ever since Facebook began making apps available, if the app was hosted in an iFrame, then this iFrame enabled the leakage.  And then if the app ever pulled any third-party content, the referrer field leaked that URL that the app used to the third party.  And that is a static persistent token that allows that third party the same access privileges as you had given the app.  So, I mean, for all time, until, like, a few days ago, when Symantec said, uh, gee, Mark, you've got a problem over here.



LEO:  Wow.  I'm just...



STEVE:  But anyway...



LEO:  I'm just, like, stunned by this.



STEVE:  Yeah.  We are approaching 1.5 million downloads of Firesheep.  Last time I looked we were at 1.3.  And we are at 1,492,829 when I last looked, although every time I looked, like an hour before that it was at 549.  So about 300 per hour, seems.  And so we'll cross 1.5 million downloads of Firesheep here in another week or two, probably.  Now, this is...



LEO:  I'm just depressed.  I am just so depressed.  Because nobody - this is massive, and nobody's going to change their Facebook password.  My wife isn't.  My kids aren't.  Their friends aren't.  Nobody's going to do this.



STEVE:  Yeah, I wonder that Facebook couldn't obsolete those tokens.



LEO:  Of course, of course they could.  But they won't because they know they would get a hundred million phone calls.  Can you imagine the cost?  When you have...



STEVE:  Well, it's like LastPass last week.  The site was down for a couple of days because they told everybody they had to change their password.



LEO:  And they probably only have a few hundred thousand users.  And by the way, they did exactly the right thing.  They didn't even have evidence, they didn't even know that there was an infraction.  They just through there might be.



STEVE:  Yes.



LEO:  And Facebook, knowing this, just blithely goes along.  I wish I could delete my Facebook account.  I can't because it's what I...



STEVE:  Well, you can just change your password, though.



LEO:  Well, I know.  But this is the tip of the iceberg.



STEVE:  Oh, I see.  I see.  You're again upset enough over this that - yeah.



LEO:  Well, and it's the tip of the iceberg.  We don't know what other crap's going on on Facebook.  We will never know.  I mean, obviously they don't want to tell you.  Wow.



STEVE:  Yeah.



LEO:  Okay, sorry.



STEVE:  Maybe it's, I mean, in the same way that our financial institutions were too big to fail, maybe Facebook now is too big to tell everyone to change their password.  It would just bring down the Internet.



LEO:  It would.  Oy gevalt.  All right.  All right.



STEVE:  Okay.  So Juniper Networks, that's not a security company, they're a big iron router manufacturer, essentially, Juniper Networks has been around forever.  They produced a report which I'm just going to - I've pulled some tidbits from.  And they called it their "Mobile Threats Report for 2010 and 2011."  So this is a little historical, reaching back, looking at what they've seen before.



So the key findings of the report, they called it - one is "App Store Anxiety," is that "The single greatest distribution point for mobile malware is application download, yet the vast majority of smartphone users are not employing an antivirus solution on their mobile device to scan for malware."  I mean, we don't really have that yet.



"WiFi Worries:  Mobile devices are increasingly susceptible to WiFi attacks, including applications that enable an attacker to easily log into victim email and social networking applications."



"The Text Threat:  17 percent of all reported infections were due to SMS trojans that sent SMS messages to premium rate numbers, often at irretrievable cost to the user or enterprise."



LEO:  Oh, yeah, that's a hell of a scam, yeah.



STEVE:  Yeah.  "Device Loss and Theft:  One in 20 Juniper customer devices were lost or stolen, requiring locate, lock, or wipe commands to be issued."  So 5 percent.  "Risky Teen Behavior:  20 percent..."



LEO:  Using Facebook.



STEVE:  "20 percent of all teams admit sending inappropriate or explicit material from a mobile device."



LEO:  Oh, everybody does that.



STEVE:  And then, finally - those darn cameras.  And then finally, "Droid Distress:  The number of Android malware attacks increased 400 percent since Summer of 2010."



LEO:  That's - to me, a percent, I don't want to know that.  That's, what, that's four times - if there was one, that's four.  I want to know the number.  Give me the raw number.



STEVE:  Yeah, good point.  And then, quoting from the report, they said:  "These findings reflect a perfect storm of users who are either uneducated on or disinterested in security, downloading readily available applications from unknown and unvetted sources in the complete absence of mobile device security solutions."  And this is Dan Hoffman, their chief of mobile security at Juniper Networks.  He said, "App store processes of reactively removing applications identified as malicious after they have been installed by thousands of users is insufficient as a means to control malware proliferation.  There are specific steps users must take to mitigate mobile attacks.  Both enterprises and consumers alike need to be aware of the growing risks associated with the convenience of having the Internet in the palm of your hand."



Now, their suggested actions are not going to impress any of us.  They say "Install an [add-on] antimalware solution to protect against malicious applications and spyware, infected SD cards, and malware-based attacks on the device.  Use an [add-on] personal firewall to protect device interfaces.  Require robust password protection for device access.  Implement antispam software to protect against unwanted voice and SMS/MMS communications.  For parents, use device usage monitoring software to oversee and control pre-adult mobile device usage and protect against cyberbullying, cyberstalking, exploitative and inappropriate usage and other threats."



So when I stand back and look at all of that, what I see, Leo, is an immature piece of the industry.  It's that phones are new.  And users are new to this kind of phone.  PCs are much more mature from a security standpoint.  Now all personal computers have firewalls built in.  And I guess there's a higher bar to using a PC securely than there is a phone.  A phone just sort of - it's hard to take it that seriously.  Is that what you think it is?



LEO:  Yeah.  Yeah.  And it's also hard to secure it.  So it's not obvious.



STEVE:  It is.  I mean, we know, for example, that the threat that PC users have is going to malicious web pages.  Sort of the similar threat that is still, I think, unappreciated is just malicious free toys for these phones.  I mean, I have hundreds.



LEO:  I download stuff all the time.  And who's checking this stuff, you know?



STEVE:  Yeah.  I mean, I see something interesting for the iPad, it's like, ooh, there's a neat toy.



LEO:  We presume that Apple is vetting these.  But the problem, as you can see, is it's almost impossible to be, you can never be a hundred percent sure that something is secure.



STEVE:  Well, and the reason Android is popular is that it doesn't have the boot of Apple on it to the same degree.  Unfortunately, what that also means is it is a larger target than Apple is.  And, I mean, Android, I'm sure you're seeing the numbers.



LEO:  Oh, yeah.  If I'm a bad guy, I don't worry about the iPhone.  I go right after Android, absolutely.  Yeah, much easier.  It's the Windows of the phone world.



STEVE:  Yeah, it is.  Okay.  Now, in another - this is, I guess, not quite my last bit of good news for the day.  We have a new attack vector which is presenting itself known as WebGL.  This is the next generation of web-based 3D graphics.  And essentially, OpenGL has been around for years.  It's a sophisticated, mature API, an Application Programming Interface, to allow applications access to powerful, hopefully powerful rendering hardware in the machine.  The problem is that, in the same way that there's nothing inherently wrong with scripting unless you go to a malicious site that scripts you maliciously, well, there's nothing wrong with OpenGL unless you go to a malicious site that uses that technology through what's known as WebGL, maliciously.  And it turns out it's possible.  All of the latest browsers are now supporting WebGL.



LEO:  How interesting.



STEVE:  Yes.  And listen to this.  The technology of this is interesting.  I wanted to just quote from Context Info Security's site.  They said:  "Traditional browser content would not normally have direct access to the hardware in any form."



LEO:  No, it seems silly on the face of it.



STEVE:  Of course.  "If you drew a bitmap, it would be handled by some code in the browser with responsibility for drawing bitmaps.  This would then be likely to delegate that responsibility to an OS component, which would perform the drawing itself."  Which is the way our stuff works.



"While this distinction is blurring somewhat with the introduction of 2D graphics acceleration in all the popular web browsers, it is still the case that the actual functionality of the GPU" - the Graphics Processing Unit - "is not directly exposed to a web page.  The salient facts are that the content is pretty easy to verify, has a measurable rendering time relative to the content, and generally contains little programmable functionality."  And that's the key.  An image is just that, it's an image.



"WebGL, on the other hand, provides by virtue of its functional requirements" - so this is not a mistake, this is the way it was designed - "access to the graphics hardware.  Shader code, while not written in the native language of the GPU, is compiled, uploaded, and then executed on the graphics hardware.  Render times for medium to complex geometry can be difficult to determine ahead of time from the raw data, as it is hard to generate an accurate value without first rendering it - a classic chicken-and-egg issue.  Also, some data can be hard to verify, and security restrictions can be difficult to enforce once out of the control of the WebGL implementation. 



"This might not be such an issue, except for the fact that the current hardware and graphics pipeline implementations are not designed to be preemptible or maintain security boundaries.  Once a display list has been placed on the GPU by the scheduler, it can be difficult to stop it, at least without causing obvious, system-wide visual corruption and instabilities.  By carefully crafting content, it is possible to seriously impact the OS's ability to draw the user interface, or worse.  The difficulty in verifying all content and maintain security boundaries also have potential impact on the integrity of the system and user data."



So what these guys are saying, and they have done proof of concept, they have been able to blue screen people's machines by visiting a web page with maliciously crafted 3D graphics.  And the problem is that, in order to do what - as we know, GPUs are very powerful.  Essentially the web server is loading code into your GPU, which it then runs.  And their recommendation, and actually US-CERT has recommended looking at the page that I provided a link to here and disabling WebGL if it is present on your browser.



LEO:  Wow, that bad.



STEVE:  It is that exploitable, apparently.



LEO:  We don't need to say it on this show, but just to reiterate, a blue screen is always the first step to pwning a computer.  If you can crash it, then you just have to figure out where to write the code.  It's not so hard.



STEVE:  Exactly.  It's a matter of finesse after you've demonstrated that, oops, you're able to kill the...



LEO:  That's always, yeah, always the first step.



STEVE:  So apparently the latest versions of Firefox, Chrome, and Safari all support WebGL.



LEO:  Oh, yeah.



STEVE:  And Opera has just released Opera 11, a preview, that supports it.



LEO:  I've used it.  I mean, it's cool.  But I guess it's not so good.



STEVE:  It's cool.  And unfortunately, as most cool things, there's a dark side.



LEO:  There's a dark side.  We continue on with Attacks & Breaches.



STEVE:  So I thought probably that's where this should go, although this wasn't a website that was attacked and breached, it was the famous Google Chrome sandbox that was breached.  Some developers using two previously unknown zero-day vulnerabilities were able to break out of the Google Chrome, the latest version of the Google Chrome browser sandbox and then not only get out of the sandbox, but then circumvent address space layout randomization, ASLR, and the data execution prevention, DEP, the two major technologies in the latest versions of Windows that are now on and active and used by Google in order to make sure that the components that are in their process space are in random locations and that you're not able to execute data.  And they were able to, using an exploit, essentially just going to a web server, able to download Calculator.exe from somewhere else and run it at minimum integrity level.  So, I mean, that's all you need to run, I mean, their demo downloads Calculator.exe, but it could also be malware like you've never seen before dot exe.



Now, what's really weird is I don't know what these guys are up to, exactly.  This is VUPEN.com, "pen" as in penetration testing.  And if you just go to VUPEN.com, down sort of like the top item in the lower part of the page, they'll talk about pwning Chrome.  And Kelly Jackson Higgins, who is writing for Dark Reading, sort of summed things up.  She said, "VUPEN - which withheld technical details of the bugs in its disclosure - had not disclosed the bugs or any details to Google as of this posting."



LEO:  Oh, I don't - that's not good.  I don't like it when they do that.



STEVE:  I know.  "The security firm provides details of vulnerabilities it discovers to its paying government customers.  Quote, 'We did not publicly disclose any technical details of the vulnerabilities for security reasons."  Well, good, publicly, of course.  "We did not..."



LEO:  That's fine.  But tell Google.



STEVE:  Yes.  "'We did not send the technical details of the vulnerabilities to Google, and Google did not ask us to provide these details,' says Chaouki Bekrar, CEO and head of research at VUPEN."  And then what of Google?  A Google spokesperson said in a statement that without any details of the hack, the company is unable to verify it.  So, quote, "We're unable to verify VUPEN's claims at this time as we have not received any details from them.  Should any modifications become necessary, users will be automatically updated to the latest version of Chrome."  So said the spokesman.  And what VUPEN is doing by way of proof is on their site and on many sites that have picked up this story about the Google Chrome sandbox being pwned.  They have a YouTube video showing them doing the exploit, basically going to a page, and the act of going there causes Calculator.exe to be launched, and that should absolutely be impossible because...



LEO:  Yeah, but it's a video that they, I mean, it's going to a local URL, I mean, it's not really a proof of concept.  It's just a video.



STEVE:  Right.  Well, no...



LEO:  It's meaningless.



STEVE:  Precisely.  So the problem is...



LEO:  It's not proof.



STEVE:  I don't get what it is that they're - I don't understand what it is that they're - what game they're playing.



LEO:  Well, they're saying we share these with our government customers.  So we aren't going to tell you because you don't pay for it.



STEVE:  Yeah.



LEO:  Which sucks.



STEVE:  Yeah.  I mean, Google will pay them for these - they've got two zero-day vulnerabilities.  One gets out of the sandbox, and the second one, once out, is then able to do the work outside in order to get an arbitrary executable downloaded from anywhere on the Internet.  I mean, those are powerful.  And so one hopes that the government, whoever it is that they're selling these things to, are being responsible with them.  But I don't...



LEO:  I don't know.



STEVE:  Just scratch my head on that one.



LEO:  Yeah, I don't - that's not - this is not good behavior.



STEVE:  It does not seem like the right thing to do.  I did want to follow up on, from one of our listeners, a D.M. Ovad, who said - who just sent email actually to my company saying please pass this on to Steve.  He said, "Steve, from last week's Security Now! podcast, I believe Episode 299" - which, yup, was last week - "you mentioned the possible high temperatures while using SpinRite on a laptop.  A few years ago, while preparing a hard drive on my wife's Fujitsu laptop, SpinRite did warn about the elevated temperatures of the drive and paused its processes.  All I did was to fill a one-gallon Ziploc bag with ice cubes, laid it on my desk, placed a washcloth over the bag, then the laptop on the washcloth.  Of course I positioned the laptop so the location of the hard drive was directly over the ice pack.  SpinRite continued, and the hard drive's temperature remained well below the maximum, and SpinRite was able to complete and successfully repair my wife's hard drive."



LEO:  Don't you worry about condensation, though, with something like that?



STEVE:  Well, I think that's where the washcloth comes in.  So he had a nice soft insulating layer and managed to keep his drive cool.  He says, "Thanks for a great solution to many hard drive issues.  Dave."  Oh, so his first name is Dave.



LEO:  I love it.  Thank you, Dave.



STEVE:  D.M. Ovad.  So, yeah.  Thank you for the tip.  I thought I'd pass it on to any listeners who may have overheating hard drives and need to run SpinRite anyway.



LEO:  Now, this is a Q&A episode, but we're about an hour and a half into it.  So we've got some tweets questions for you.



STEVE:  We do.  I did want to quickly mention that OpenDNS, that we have spoken of often...



LEO:  Yes, we have.



STEVE:  ...is now supporting IPv6.



LEO:  Oh, wow, that's great.



STEVE:  In advance support for World IPv6 Day, which is June 8th and approaching, that's next month, about a month from now, they are now supporting IPv6.  And in the announcement they said that their IPv6 addresses for the OpenDNS IPv6, what they called a "DNS Sandbox," which is to say the IPv6-enabled DNS servers are 2620:0:ccc::2 and 2620:0:ccd::2.



LEO:  Wow, that's interesting.  I'd never seen IPv6 addresses.



STEVE:  I've just - that's why I wanted to state them and show them, as our listeners will certainly be, in the future, hearing IPv6 addresses.



LEO:  What is the - why is it "::" at the end?



STEVE:  The way this works is, and this has been well thought out because the problem, of course, is that 128 bits is four times longer than the 32 that we've been using.  The 32 that we've been using used the so-called "dotted quad" format.  Well, we would have to have 16 of those if we didn't come up with a way of compressing it.  We'd have to have, like, 16 numbers ranging between zero and 255.  So instead what they do is they set them up as groups of 16 bits, representing by four hex characters.  So first of all, we're no longer decimal, we're now in hex.



LEO:  Hence cc, cc, ccc...



STEVE:  Exactly.  So ccc.  And there's always an - now, I said ":ccc:", there was only three c's.  But hex for 16 bits needs four.  So there's always an implied leading zero, if it's not specified.  And the "::" means that there are as many zeroes in between the two colons as necessary to push each side out to the ends.



LEO:  Ah.  So it's like a fill colon.



STEVE:  Yes, exactly.  So, and the way IP space is allocated, you'll generally have, like, a left-hand-side network and then a right-hand-side machine, or subnet.  So that's what we're seeing, where it's 2620:0:ccc, and the other one is 2620:0:ccd.  And then in both cases they end with a "::2", meaning then just do all zeroes until you get down to the end, and then we have a 2 at the very end.  And 2 will be a common number for machines and interfaces and so forth.



And I wanted to quickly say something to our listeners that I tweeted.  You probably know about this already, Leo.  But I went to IMDB on my iPad, the Internet Movie Database?  And it said "We have an app."  There's an app for that.



LEO:  Oh, yeah.  There's a great app.



STEVE:  And it's lovely.  And that's the end of my message.



LEO:  I could show it to you.  I have my iPad here.  But I also have my - I have an Android tablet, so I could show it to you, if you want to see it I could show it to you on the Android tablet here.



STEVE:  Anybody who is - yes.  So it's iPhone, iPad, iPod Touch, any iOS device, or Android.  And if you're a movie person, and you and I are, Leo, and I'm sure a lot of our listeners are, it's just - they just nailed it.  It is simple and elegant.  You're able to just, like, I love that they deal with, like, movies coming up in the future.  You can scroll through them.  You touch one, you go there.  You touch an actor, you go to the actor's profile.  It just, like, interlinks all of that so nicely.  It's just...



LEO:  I thought I had it, but I don't see it here.  So I'll - but I do, yeah, I love it.  I agree.



STEVE:  And I guess there are other IMDB apps.  Other people tweeted me...



LEO:  Yeah, but get the official.



STEVE:  The official one they just nailed it.  They did a great job.  In tweets from the field, Von Welch, whose @VonWelch is his handle, he mentioned covering webcam on MacBook Pro with sticky...



LEO:  Hey, before you do that, can I do an ad?



STEVE:  Oh, yeah.



LEO:  I'm sorry.  I haven't been paying close attention.  And here I am trying to log into Facebook.



STEVE:  Well, so Von Welch noted, he said, "Cover webcam on MacBook Pro with sticky, Mac thinks I'm in dark room and dims the screen."



LEO:  Oh, that's interesting.



STEVE:  Turn off auto-dimming under Preferences/Display.



LEO:  Oh, that's a good point.



STEVE:  So, yes.  Apparently the MacBook uses the camera also as its ambient light sensor for controlling the automatic screen brightness.  And I was pleased that Von Welch decided to follow up on my advice after hearing about another instance of people being spied on with their webcams.  But when he did it, his screen got dim.  So you can turn off auto-dimming under the Display panel under Mac Preferences.  So I just wanted to pass that on to our listeners.



And this is very cool.  Graham Wetzler tweeted about a security tool or I guess service that I really like.  It's the kind of thing I wish I could have done, or I have done.  But now it's been done, so I don't need to:  urlxray.com.  Give it a shortened URL, and it'll tell you where it leads.



LEO:  Oh, that's good.



STEVE:  Which is trivial to do.  I mean, all it does is it goes to the URL.  And the way these redirectors work is they return you a 301 HTTP Moved response with a location header telling the browser where it should jump to.  So, I mean, the trick is simple.  But obviously instead of jumping to it, it just shows you where your browser would jump to, if you had given that URL to it.  And I have to say, I mean, TweetDeck does a good job at showing those often.  But when people tweet me something and allow me to sort of get a sense for them and, like, what this link is they're providing, I do have a secure machine.  But I'll typically trust people and click it.  But sometimes I get a tweet that just says, "Oh, check this out."  And it's like, I'm not clicking that, honey.



And it reminds me of the famous scene from "The Wrath of Khan," where somebody is telling Kirk to raise his shields because he's not hearing anything from the oncoming starship.  And of course it's Khan, who then blows him up because he didn't have his shields raised.  And the idea that, it's strange, but if you get some communication from someone, you have some sense for who they are and what they're about and where it might be that you're sending your browser when you click the link.  But it's very different if you just get a URL and nothing.  It's like, well, okay, I'm just - I'm reluctant to click that.  So anyway, urlxray.com allows you to disambiguate these URLs prior to going there directly, which I think is very useful.  I'm going to be using it.  In fact, I may just implement it myself for GRC, and then we'll have one more little gizmo at GRC.



Okay, so real quickly, a couple of Q&As.  Niko Carpenter tweeted, and several people had asked who sent feedback to GRC.com/feedback, our regular place, he said, in a split handshake, how does a bad guy get the server to only send a SYN packet?  And I loved that because I completely forgot to talk about it.  Remember?  Okay.  So split handshake was - I talked about a week or two ago where it was a potential exploit where intrusion detection software could be debilitated, essentially confused by the exact sequencing of TCP packets back and forth.  So normally you send a SYN packet to the server, it returns a SYN ACK, and then you ACK it, and now you're connected, and you proceed.  In a split handshake, instead the server sort of ignores, basically ignores your SYN and just sends a SYN to you, essentially sort of turning the handshake around.  And that's what confuses the IDS, the Intrusion Detection Systems.  So he says, how does a bad guy get the server to send only a SYN packet?



Well, what I forgot to explain was that you would have to be going to a bad server in the first place.  So it's an exploit that the server, that only the server you are reaching out to can perpetrate against you.  So it's not like bad guys somewhere can use this to, like, get Google to connect to you, but you're really connecting to them or something.  It's, you know, if you were going to a site that wanted, that already wanted to do you harm, then that site would send a SYN packet back to you, rather than a SYN ACK, reversing this connection and using that in order to bypass intrusion detection software that would otherwise be protecting you.  So that's how that works.



Luis Fernando asks, whatever happened to that capacitor idea you announced a while ago?



LEO:  Oh, the supercapacitors, yeah.



STEVE:  The supercapacitor.  And it's funny because I had myself looked and wondered what was going on.  And this was a company called EEStor down in Texas.  And last we heard from them, they were in the process of working out the details of mass production.  And they disappeared.



LEO:  Oh, dear.



STEVE:  My sense is they probably could not make them, whether it was a quality control problem, a mass production problem, a couldn't hook enough of them together problem, we don't know what.



LEO:  We know they're for real because I actually have a screwdriver that charges superfast.



STEVE:  Yes.  No, you mean supercaps are real.



LEO:  Supercaps, yes.  We just...



STEVE:  Yes, supercaps are definitely real.  And in fact...



LEO:  These guys were going to make it for cars.



STEVE:  Yes.  And there was an automotive manufacturer in Canada that was getting all geared up and ready to go.  Interestingly, I saw a quote from the CEO of Tesla.  And we all know Tesla, the manufacturer of that fantastic little sports car that is ridiculously fast.  One and I were next to each other at a stop sign a couple weeks ago, and this thing just shot off, like, when the light turned green.  And I thought - and, I mean, silently.  Didn't make any sound.  I thought - and I looked, and sure enough "Tesla" was across the back of it.



LEO:  Awesome, yeah.



STEVE:  The CEO stated, "Supercapacitors are the future of automotive travel."  This is the CEO of Tesla said, yes, we're only doing batteries now because we don't yet have supercapacitors.  But remember, I mean, the reason I was so bullish about them is that they solved the wear-out problem, and they solved the slow charging problem.  If you had, like, a high-current pumping station with high-current delivery to the car, and the pumping station probably had supercaps, too, so it was always sucking power off the grid, filling up its own supercapacitors, then you bring your car in, plug it in with some mondo connector, and, I mean, many, many, many hundreds of amps, and the charging station would dump its supercaps into your supercaps, and off you'd go.



So I'm convinced it's the right technology.  And the CEO of Tesla, who's got a lot of experience with this, agrees with me.  We just don't have them yet.  But many people, I mean, I'm seeing work happening.  There's, like, there's lots of university research with nanotubes and all kinds of strange things that are, like, working on getting supercap technology to happen.  So I think we're not far from it.



LEO:  Good, good.



STEVE:  And finally, Carlos Cardona also twitted.  He said, you often talk about password hashing/salting.  Could you talk about password stretching?  And I touched on it last week when we talked about LastPass because that is the - we understand that, when you hash a password, you pass the plaintext through this cryptographic hash, and it turns it into a fixed-size token that represents what you fed in.  We know that when you salt the hash, you add something secret to the password, and then you hash them both.  And the benefit of that is that you then don't - because hashes use standard formulas, like an SHA-1 or an SHA-256, or MD5 is no longer considered very strong.  But the hashing algorithm itself is a universal standard.



So the problem is, if you didn't add salt, then somebody could figure out your password by brute forcing all possible, like, reasonable passwords through that hash to see if they get the same token that was stored, for example, when a secure website had stored the token.  But by adding hash, I mean, sorry, by adding salt, you essentially create a custom hash function.  That's what the salt does is it sort of customizes the hash function so that, by mixing in with the input you're providing, you're going to get a token out different than that universal function would otherwise provide if it weren't salted.  So that we have.



The one problem we still have is what if somebody got the salt?  And that was the concern, unverified, and still unverified by the guys at LastPass.  They were concerned that somebody may have gotten the salt, which would then have weakened the protection salt provides.



So there's one more thing we can do, and that's called "password stretching."  And what it does is it stretches it in time rather than in size.  And it's as simple as, rather than hashing once, you hash many times.  For example, the WiFi folks who did WPA, the current standard good secure WiFi, they understood this.  So they salt the hash with the access points, access point name, the ID of the access point, so that when you set your access point's name, you are increasing your security by mixing that salt in.  And then they repeat that 4,096 times, the idea being that anybody brute forcing can't just do it once, they've got to do it 4,096 times, which slows down their brute-forcing speed by 4,096.  No matter how fast they can do the hash, they're going to have to do it 4,096 times per brute-force attempt.



LEO:  Even if they have the database they still have to go through this.



STEVE:  Yes.  Yes.  And that's the beauty.  And, for example, in the LastPass case, they're talking about doing it 100,000 times.



LEO:  That should be enough.



STEVE:  So it'll really slow it down, yeah.



LEO:  Wow.  So this has been a great show.  And I think if nothing else I hope people have learned a little something from this Facebook thing.  This is why you listen to this show, folks.  Because I don't know, I can't understand why this isn't being more publicized.  PC Magazine just published an article about it, and I've linked that on my Twitter account.  Wow.



STEVE:  Yeah.  Well, I imagine it'll get picked up by...



LEO:  I hope so.



STEVE:  ...Techmeme and Boy Genius and those guys, and then hopefully then by the mainstream.  And ultimately you have to imagine that Facebook will be forced to do something.



LEO:  Well, they've already said, oh, yeah, it's not a big deal.



STEVE:  Okay.  Yeah.  As I said, my sense is it will allow diffuse attacks, meaning that because it's a function of that authentication token being found, and that only allows them access to one Facebook user's account.  So there's a lot of Facebook users.  And...



LEO:  Well, somebody would really most likely create a malicious app to take advantage of this, if you were going to do this.  Facebook's response, they said "We've worked with Symantec to rectify the issue," but took issue with how Symantec characterized the situation.  "We've conducted a thorough investigation," says Facebook, "which revealed no evidence of this issue resulting in a user's private information being shared with unauthorized third parties.  In addition, this report ignores the contractual..."



STEVE:  Oh.



LEO:  Oh, dear.  I'm starting to - "the contractual obligation of advertisers and developers which prohibits them from obtaining or sharing user information in a way that violates our policies."



STEVE:  Oh, goodness.  Well, and Part A there is, well, we weren't looking to see if this has been happening, so we didn't see it happening.



LEO:  There's no evidence.  Well, how would you know?  What, are you going to look back at all the logs for - it's been going on for years.



STEVE:  And people's Facebook accounts are being hacked all the time.  Gee, I wonder how.



LEO:  Symantec says, "We estimate that over the years hundreds of thousands of applications may have inadvertently leaked millions of access tokens to third parties.



STEVE:  Yes.



LEO:  But we have no evidence, says Facebook.  And by the way, it would be a violation of their terms.



STEVE:  Oh, they didn't read the fine print.



LEO:  Oh, I'm just - I am just done with Facebook.  It's so - I'm so done.  Holy cow.  Just horrible.  Steve Gibson is at GRC.com.  There at the bottom of the screen are all his Twitter handles:  @SGgrc is his main Twitter account.  @SGpad for pad for tablet-related news.  And @GibsonResearch, the official account for his company, the Gibson Research Corporation.  Of course that's GRC.com.  That's the place to go if you want to get SpinRite, the world's finest hard drive maintenance and recovery utility.  For questions in future episodes, GRC.com/feedback is a good place to go.  I also suggest that you check out his other free programs and all sorts of information at GRC.com.



STEVE:  Okay.  I'm going to do something really strange, Leo.



LEO:  Okay, I'm ready.



STEVE:  My Passcode Designer that I've talked about several times came alive yesterday.



LEO:  Ooh.



STEVE:  And it is - I think it's going to live up to my expectations.  Probably by next week, I'm going to tweak the graphics a little bit - and this is my big JavaScript program.  This is my project.  I taught myself JavaScript so I could create this thing because it runs on a web page.  This idea just hit me because the guys in the GRC user group are really anxious to see it.  I've been talking about it more to them than I have been on the podcast.  But I'm going to introduce it next week to the listeners of this podcast as something of a puzzle.



LEO:  Fun.



STEVE:  Because it will exist, but the documentation won't.  And it's a little machine that I've built.  And when you click things and do things, things happen.  And I realized people could scratch their head and think, what is this doing?



LEO:  Might be kind of fun.



STEVE:  I mean, you poke it over here, and it does this; and you poke it over there, and that happens.  And so next week I will - I'm sure I'll be ready by then because it's running now.  I'm going to give everyone access to it and just say, I haven't written anything yet.  There's no documentation.  But if you want a toy to play with that involves passcodes, you can poke at this and see if you can figure it out because it's something that needs to be figured out.  So...



LEO:  Well, don't tell anybody.  We'll find out next week.



STEVE:  Yup.  And we will - we're going to plow into randomness, how we solve the problem of needing random numbers from a computer that cannot make them.  It can't.  That's not what it's for.



LEO:  Part 2 of Going Random.  Steve Gibson.



STEVE:  Thanks, Leo.



LEO:  GRC.com.  Thank you, Steve.  We'll see you next week on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#301

DATE:		May 19, 2011

TITLE:		Going Random, Part 2 of 2

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-301.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's security and privacy news, we conclude our two-part series discussing the need for, and applications of, random and pseudorandom numbers.  We discuss the ways in which a computer, which cannot produce random numbers, can be programmed to do an extremely good job.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 301, recorded May 18th, 2011:  Going Random, Part 2.



It's time for Security Now! the show that covers your security online; your privacy, too.  And here he is, our security guru, Steve Gibson from GRC.com.  He's the man behind SpinRite and many other wonderful inventions.  Can we call software an "invention"?



STEVE GIBSON:  Oh, unfortunately, too many people do.



LEO:  Yeah, that's a hot topic lately, issue of software.  You never did patent any of your stuff, did you?



STEVE:  I never did for myself.  I did some subcontracting for a while where the people I was doing the work for said, oh, we've got to get patents on this.  And in fact I did apply for one patent on a CryptoLink technology which would allow it to stealth its open ports so that you could be running a CryptoLink server, but no bad guys could see it.  Essentially it's a single-packet authentication technology.  I did get the response back from the patent office just recently; and they said, ah, this looks like bunk.



LEO:  Really.  They refused it.



STEVE:  Oh, yeah.  Apparently that's the dance you do.  And it of course enriches the attorneys because so far I've already spent $10,000 on this thing.  So it's like, okay.  So I have on my list of things to do is to figure out what it is they're complaining about.  And then this is just the way it works now is you say, no, that doesn't apply because of this, and you apparently didn't read paragraph 3B because that's what's different about this, which makes this unique.  I mean, we did a full search, and nobody else has done this before.  So it looks like it's a new thing.  I'm only doing it, though, because there's some provision in the tax code that allows income derived from the sale of all substantial rights and title to a patent to be treated as long-term capital gains.



LEO:  Oh, that's good.



STEVE:  And that's actually the way I sold my light pen to Atari was I had patents on various aspects of the hardware.  And so I was able to get the income that I received treated as capital gains.  It was much more beneficial than regular income.



LEO:  Much lower tax rate, yeah.



STEVE:  But my CPA has recently told me that I'm too close to GRC for me to license it to the corporation because I own all of GRC.



LEO:  You can't really license it to yourself.



STEVE:  So I can't.  So frankly, I'm probably just going to abandon the effort.  The only reason I was doing, I mean, I absolutely don't care about, and I'm actually sort of against, patentability.  And I also thought, well, it would give somebody something to own someday if they wanted to buy it from me.  But that's probably never going to happen, either.  So it's like, I don't think I want to keep sending money to the attorneys in wheelbarrow-size quantities.



LEO:  No kidding.  I know that feeling.  So today we're going to complete our Going Random conversation from two weeks ago.



STEVE:  Exactly.  We started, sort of laid the foundation for why it is that crypto systems need randomness.  I'm going to review that briefly after we catch up with the week's news, but then talk about how we get randomness from machines that are designed not to be random, which of course is our computers.  Every time you multiply or add, you want the same result.  So how can you ever get a machine to give you something random?  And the answer is you can't.  But that's not good enough.  So we still need it, even if we can't have it.



LEO:  But we're going to get it.



STEVE:  Yes, we are.



LEO:  Steve will explain how.  Now it is time to get the latest news of the security world from Mr. Gibson.



STEVE:  So there's something interesting going on with Mozilla that it's not really an update, but it's a planned update.  Essentially, Mozilla is getting a little annoyed with the fact that 12 million people are still back on Firefox 3.5.



LEO:  How many?



STEVE:  12 million.  They're the people who do not listen to us, although I can't really say much because I'm on 3.6 and not willing to move until I'm sure that 4 settles down and all the add-ons that I cannot live without now are compatible with v4, which...



LEO:  Is this analogous to Microsoft moving people off older IE versions?  Is 3.5 insecure in that way?



STEVE:  No, I think it's a matter of the problem of, I would say, one of the other reasons Microsoft moves people off of old versions, is they just get tired or stretched too thin of supporting them because, I mean, Mozilla is an open source project.  And it's being done for the good of humanity.  But for people to stay back on 3.5 as they're, for example, fixing things that come from the common code base that all versions of Firefox share, they've got to take the time and trouble to sort of remember what 3.5 was and then make the changes that are relevant to 3.5 when they're also fixing 3.6 and 4.0.  So here's the news:  5, version 5 of Firefox will be released on June 21st.  So here we are, this is May...



LEO:  What?  They just did 4.



STEVE:  I know.  So here we are on May 18th.  And so literally four weeks from now we're going to have 5 already.  So what they're going to do is, on June 21st - and their goal is to get everybody off of 3.5 by the end of June.  So on June 21st, with the release of v5 of Mozilla Firefox, on that day they will release the next version of 3.6.  Right now I'm, for example, using the latest, which is 3.6.17.  So on June 21st they will release 3.6.18 - or one eight, I feel more comfortable saying it that way because that's right.  And that will be offered to everybody on 3.6.17, like the one I have now, but also those using 3.5.19.



So the point is, and this is the first time they will have ever done this, they're going to be automatically updating people to a major revision change, not just a minor revision change.  So the good news is 3.5 and 3.6 are very close to each other.  But essentially, they're not going to be asking people or requiring 3.5 users to do anything because they've come to the conclusion these people aren't.  I mean, they're just sitting back on 3.5 and staying current with that, but they're not making the move to 3.6, very much like I'm staying with 3.6 and haven't made yet the move to 4.0.  But with this on June 21st, they will silently upgrade 3.5.x users to the latest 3.6, essentially retiring the whole support and forward-moving updates for 3.5.  So, I mean, if that weren't enough to move people off of it, if they were security conscious, and Firefox users tend to be, then the fact that they're just making it automatic would do that.



Now, what's interesting is they've got a bug, it's Bug 650030, which prevents this from working.  So on their bug list, the bug's title is "major update automation should support background updates, not just advertised ones."  And so what they call a "major update" is, for example, a 3.5 to 3.6 change, as opposed to updating the next decimal dot versions.  And "background updates" are those where the next restart of Firefox automatically brings the user to the next version.  So Firefox downloads it silently in the background and has it prepped and ready so when you launch it, it just is running the newer one.  And then what they call an "advertised update" is one where the user is prompted and needs to accept that before downloading and applying the update.



So they need to fix this problem that they have.  And when they do, they will update Firefox silently, and we're going to be saying goodbye to 3.5 on that day and hello to 5.  Which as you say, I mean, I was surprised, too.  It's like, wait a minute.  We had 3 for a long time.  Although I did see some things - you may have run across it to, Leo - where there was some commentary about the Mozilla Project being too slow, that they were just moving too slowly and weren't keeping up with the pace that we're seeing, for example, from Chrome, which is really moving itself along, and even IE.  So I think they're deliberately working to improve their rate of adding features.



LEO:  It's kind of silly because, especially on Chrome, version numbering doesn't really mean anything.  I mean, what's the difference between Chrome 10 and 11?  You tell me.  I can't tell.



STEVE:  Right.  It's just changed.



LEO:  It's just changed.  So is there a version race?  I mean, that's crazy.  A version number race?  That would be crazy.



STEVE:  I think it's not so much numbering as the Mozilla people themselves feel like their whole process had become somewhat bogged down.  And so they're working to streamline the process so that they're better able to just get stuff vetted and tested and beta tested and out to users so that, I mean, I'm looking at Chrome thinking, hmm, you know, looks pretty good.  Of course you thought that a while ago...



LEO:  Oh, I love Chrome, yeah.



STEVE:  ...and made the jump.



LEO:  Yes, I'm a big Chrome fan, yeah.



STEVE:  So we've got some bad news in the Mac space.  Ed Bott, whom you and I have known forever, who's been in the PC business forever, has a column or a blog over on ZDNet.  And he managed to get a hold of an AppleCare employee who provides the AppleCare support, and sort of officially but anonymously interviewed this person about what the AppleCare people are experiencing relative to this Mac Defender problem that we've talked about.  We introduced Mac Defender on this podcast a week or two ago, noting that in the last couple weeks it was becoming a growing problem for Mac users, that Mac users were not accustomed to fighting the virus wars that Windows users have been fighting for years.



And what was really interesting - so Ed Bott in his blog posting posted a sanitized dialogue that he had with this AppleCare employee.  And one of the things that really caught my eye I thought was interesting, which was that, because Mac users tend to believe that their Macs are impervious to these kinds of problems, they consequently tend to believe the Mac Defender pop-up - which sometimes also calls itself Apple Security, but it's basically the same code with just a different name.  They tend to believe those to a much greater degree than Windows users do because Windows users are so beaten up at this point by all of this nonsense that our guard is up to a much greater degree.  So the fact that Macs haven't historically had a big problem with viruses is giving these newly created malware for Macs sort of a boost, sort of a head start, more than would otherwise be the case, which I thought was really interesting.



What came out in this dialogue with this AppleCare Apple employee was that it is true that the Macs are more secure at this point, or at least to this first-generation malware, by needing to have the admin password in order to install themselves permanently in the machine.  Yet social engineering is still being effective.  And what we are seeing in general, I mean, if we looked at the thousand-mile view of the history of the last 10 years, what we're really seeing is, as security is becoming more of a focus for people, as people are in fact doing a better job with security, and our operating systems are getting tightened up, and there are just today far less obvious openings for malware to get into machines, it is social engineering, even over on the Windows side, which is still catching people out and getting them to install these things.



So, for example, the Mac Defender problem, this employee said that in the course of two weeks he went from maybe getting a call or two a day to more than half of the calls he now receives being Mac Defender problems.  And that Mac Defender does trick people into having them put in the admin password that allows it to install into their system.  And the people he had spoken to had not fallen for this fake purchase, enter your credit card information so you can purchase the software so that we're going to fix your system.  But he had spoken to other AppleCare reps whose users, when they called Apple for help, had input their credit card information.  And the scam is - I thought this was interesting, too - is that the software, even when they give it a good credit card information, says, oh, we were unable to process your card.  Give us another one.  And in some cases users went through, like, their five credit cards, putting them each in in succession, which of course...



LEO:  Oh, that's clever.  Now I understand why they kept, I mean, they would want that.



STEVE:  Yep, yep.  So...



LEO:  I have to, by the way, validate that it is on the rampage because I'm getting more calls on the radio show.  But also lots of calls from Windows users bit by the same thing.  The same idea, you know.



STEVE:  Oh, yeah, exactly.  The one thing that was a little disturbing was that the AppleCare employees had been instructed by Apple, despite the fact that it is easy to remove and easy to instruct people to remove, AppleCare has been told not to remove it for customers who call, on the theory that customers should not be given the expectation that AppleCare will be responsible for these things.  Apple is saying that's the role of antivirus.  That is not something that falls within our purview.



And this employee whom Ed interviewed said, well, I've helped some people out when they've explained their situation or they really needed help.  I mean, he's had, I guess, I don't know what this thing shows people, but in the interview they talk about mothers screaming on the phone to AppleCare over the images that her children are being subjected to as a consequence of this being on their Macs.  So whatever it does, apparently it's producing offensive imagery of some sort when this happens.



And so Ed says, well, aren't calls, AppleCare calls being monitored by Apple?  And so if they heard you doing this, you could get yourself in trouble.  And the guy said, yeah, I know, but even though Apple is saying we shouldn't help people, we sometimes have no choice but to do that.



LEO:  Interesting.



STEVE:  Yeah, interesting.  And in related news there is now the first do-it-yourself malware kit for Mac OS X.  There have been famous Zeus and - Zeus is probably the most well-known malware kit for Windows.  There's another one, Spybot, I think, or it's Spy something.  Anyway, there is now one just that is being - percolating around the underground forums.  It's called the "Weyland-Yutani Bot."  And what's kind of fun for sci-fi people, Weyland-Yutani was the name of the fictitious corporation that ran terraforming in the second "Alien" movie, in "Aliens."  And their slogan was "Building Better Worlds" or something.



So anyway, that's the name of this is the Weyland-Yutani Bot is what this do-it-yourself malware kit creates.  Brian Krebs was able to get into a Russian-language forum and have a dialogue with the author, who provided him with a video.  And there is a video on YouTube, also, of this thing operating, which shows the various UI components of the builder and the admin panel and the fact that it supports encryption.  It's still low profile.  And at the moment it supports what's called "web injection" and local form grabbing in Firefox and Chrome, not yet Safari.



Web injection is the process whereby, when a legitimate web page is displayed on your computer, like a banking web page, these bots will now inject additional content into the page.  For example, if you're only being asked normally by the bank for your username and password, the bot will add your credit card CSC code and your billing address and things.  It'll add additional fields.  So it's legitimately coming from the bank, yet you're providing much more information in response than you normally would.  And of course this is the malware gathering additional information so that they're able to collect data so that they can steal more information from you.



So this is, I mean, we're beginning to see what was inevitable, Leo.  And that is that the Mac is catching up, as it has caught up in popularity, or as it is catching up in popularity, it's now become a target for the bad guys.  And it's going to be a problem for Mac users who at some point are no longer going to really be able to say it's a much more secure platform than Windows.  But I need to say, I tweeted this earlier today when I ran across this, one of the coolest bits of wisdom and advice I've seen.  Brian Krebs on a different blog posting of his quoted three things.  He said, If you've installed a program, update it regularly.  Okay, well, that's something our listeners hear you and me say all the time.



LEO:  Know very well.



STEVE:  They know very well.  Number two, if you no longer need a program, remove it.  And that's also one of my main focuses.  We've talked about getting rid of Java if you don't need it because it's a problem.  Certainly disabling JavaScript if you don't need it and so forth.  And just in general getting rid of stuff you're not using because it's all baggage, and it's just more opportunities.  What he adds to that wisdom that we've commonly shared, which I think is just fantastic, is the best advice for protecting users from social engineering attacks.  And that is, if you didn't go looking for a program, an add-on, or download, don't install it.



LEO:  Yeah, but the problem is people feel like they did, right, because they got a warning that said you've got spyware which looks like, it's designed to look like it came from the operating system.  And then the offer to download a fix so that - that's why they enter the password, both on Windows and Mac.  They go, well, yeah, I want to install this.  I asked for it.



STEVE:  The other thing, the other main vector, for example, is like Koobface on Facebook will provide you a link.  And the dialogue that comes up says, oh, you need to install the following video player in order to play this video.  And so the user goes, oh, well, that makes sense, and so they do it.  But my point is that the reason I really like what Brian says is, if you didn't go looking for it - and I understand, Leo, this is what confuses people.  So that's why this is so important, if you think about it.  If you didn't go looking for a program, an add-on or a download, don't install it.  That is to say - and unfortunately it also means, I mean, it applies to legitimate.  You would not be responding to legitimate offers also.  But the idea would be, if something is being offered to you, treat it with skepticism.



LEO:  Right.



STEVE:  Because that's how these social engineering attacks are getting you is...



LEO:  If you see a message that makes your heart pound, don't trust it.  I mean, part of their success is they scare you.  So if that message scares you, that should be a sign that maybe it's not all it looks to be.



STEVE:  Well, but for me this decision point is, was it offered to me, or did I go get it?  Did I go looking for it?  Because I think that's really, I just - I tweeted it because I thought that's exactly right.  You'd be skeptical to the point of just not doing it if something is offered to you.  As opposed to, I mean, and this is what you and I do, we sort of have that intuitively, it's like, oh, well, I'm going to go find this somewhere else.  Or I'm going to go do my own Google search to find the...



LEO:  That's exactly what I tell the radio audience, is if - see, I don't know if it's enough to say don't install it if you didn't go out looking for it because there are many of them running security software that would say, would you like me to remove this virus?  They see these messages.



STEVE:  Although someone responding to my tweet this morning did say that he tells people, make sure you know what your antivirus program is, and don't respond to different antivirus messages.



LEO:  Well, and there is no such thing as the Apple Security Center.  That's a Windows thing.  And I had a call on the radio show last week who said, I was scanning - my friend invited me, was having problems with her computer.  She invited me over.  I scanned it with MSFT, and it said, oh, I can't disinfect, you need the Windows Advanced Toolkit - which doesn't exist - and I installed it.  And I said, did it cost you any money?  He said, yeah, it was $79.  And I said there's no such thing.  There is no Microsoft Advanced Toolkit.  And so it's know your operating system, be skeptical, and I think that Google has a very good tip, which is, if something like that pops up, just Google its name.  Because if it's malware, you will see hundreds of entries immediately that say, "Don't install that."



STEVE:  Right.  But also, Leo, look at the fundamental effectiveness of this new approach, the social engineering approach.



LEO:  Well, it's always been the case.  Social engineering, in fact, Steve, Kevin Mitnick, our favorite hacker, wrote a whole book on the subject.  That's the best technique.  Social engineering, it works.



STEVE:  Yeah.  Too often.  So I just caught a little blurb that I wanted to inform our listeners of, that just sort of made me shake my head.  And that is that the American Civil Liberties Union, the ACLU, is kind of keeping an eye on what law enforcement is doing.  And I'm glad they're doing that, keeping people honest.  They filed a Freedom of Information Act, an FOIA request asking for information about the FBI's warrantless wiretapping, the FISA provision, and, for example, which ISPs were providing that information, how was this being used, what was being done, and who was the FBI working with.



In court documents which were filed in reply by the FBI, the FBI formally stated:  "Specifically, these businesses would be substantially harmed if their customers knew that they were furnishing information to the FBI.  The stigma of working with the FBI would cause customers to cancel the companies' services and file civil actions to prevent further disclosure of subscriber information."



LEO:  [Derogatory sounds]



STEVE:  So I just think there's something we're doing wrong here if that's the situation.  That is, if the FBI is afraid to tell us what it's doing, then doesn't that seem wrong somehow?  I don't know.  I mean, I guess it's that it's warrantless, that without warrant they're able to now use FISA to compel ISPs to spy on their users just because they want to, because they ask.  And then when                      privacy rights organizations say, okay, just tell us what you're doing, you're a taxpayer-funded organization, what are you doing?  They say, well...



LEO:  We can't.



STEVE:  ...we can't.



LEO:  It would be bad for business.



STEVE:  Yeah.



LEO:  If you knew your ISP was spying on you, you probably wouldn't use them.  So we'd better not tell you.



STEVE:  Yeah, no kidding, yeah.



LEO:  Oh, come on.



STEVE:  I know.



LEO:  Holy moly.  Holy moly.



STEVE:  So also, just Thursday, new legislation was put forth, I think it was in the Senate with 11 co-sponsors, called PIPA, the Protect Intellectual Property Act.



LEO:  I don't like the sound of that one.



STEVE:  I know.  Well, now, we know about the old unpronounceable acronym.



LEO:  COICA.



STEVE:  COICA, right, C-O-I-C-A.  And that was Combating Online Infringement and Counterfeits Act.  And we know what it tended to stumble around doing because we covered the fact that they blocked out a top-level domain because some subdomain was in fact offering counterfeit purses or something.  But they didn't realize that this was a multidomain hosting provider, and as a consequence tens of thousands of other websites were taken down by mistake.  So, whoops.  The so-called "domain seizure" didn't work so well.  So...



LEO:  This is going to turn me into a libertarian, they keep this stuff up, I'll tell you.



STEVE:  I'm there, Leo.  I know.  So instead of domain seizure, the new PIPA, P-I-P-A, it would allow the Justice Department - I mean, if it passes, right now it's just introduced legislation - to allow the Justice Department to obtain court orders compelling ISPs' DNS servers to stop returning results for particular websites.  Meaning that the sites would still be available outside the U.S.  So rather than essentially removing domains from the root name servers, from the root servers on the Internet, they will instead send to ISPs - I don't even know what the mechanism would be because, I mean, there's lots of ISPs and a gazillion DNS servers.  But this plan is to place filters in the results of DNS servers so that lookups will fail.



So it's like, okay, I mean, that's not going to work either.  These attempted sort of lame technological approaches to solving problems that are legitimately created by the nature of the Internet and digital media are bound to fail.  There's all kinds of ways around this.  If you're trying to get this kind of content, you can just use foreign DNS servers.  They work just fine.  And there's way more of those than there are local ISP DNS servers.



So it's just - it's nuts.  I have to say, though, I was surprised by something I saw just the other day.  Another of my recent tweets actually is that Netflix is now the No. 1 source of traffic on the Internet.  Which was - I think it's very cool.  But what surprised me...



LEO:  It's giving Comcast ammunition, that's the unfortunate thing.



STEVE:  Yeah, it is.  But what surprised me is that BitTorrent is No. 2.



LEO:  You obviously don't know many BitTorrent users.



STEVE:  I don't.  I'm not a torrent user.  But that's like, whoa, No. 2 is BitTorrent.  So it's like, okay, yeah.



LEO:  Is email still in that list anymore?  I don't think it is.  Used to be that was, like, No. 1 by far.



STEVE:  No.  In fact, some amazing things got bumped off the list, they don't even show up on the chart anymore, that were interesting.



We talked last week about the breach in Chrome's sandbox.  Remember that the French security group VUPEN came up with a zero-day exploit against Chrome.



LEO:  And I was skeptical.  I said I would like to see the code, which they weren't showing anyone.



STEVE:  Well, what happened was there was a little bit of a Twitter war, it turned out.  Three days later Google's Chris Evans, who's their information security engineer and a tech lead, he tweeted, "It's a legit pwn, but if it requires Flash, it's not a Chrome pwn."



LEO:  Except that Flash comes with Chrome.



STEVE:  Yes, it does.  But it does turn out that this was a Flash exploit.  So this was Flash in the sandbox that allowed Flash to get out of the sandbox.



LEO:  But, I mean, Google's the one who said, look, we're sandboxing Flash.  That's why we bundle Flash.  We want to make it safer.  So they're the ones who were trying to protect us.



STEVE:  I agree.  And in fact...



LEO:  So I don't think that that gets them off the hook by any means.



STEVE:  Well, and the VUPEN guys tweeted in reply, they said, "Flash bugs are equivalent to Chrome sandbox escapes from an attacker's perspective.  You're thinking like developers."



LEO:  Right.  "It's not our code."



STEVE:  Exactly.



LEO:  "It's our product, not our code."



STEVE:  It's code that we install by default in the browser so that it's able to run.



LEO:  That's a good point.  That is thinking like a developer.



STEVE:  Okay, so I completely forgot last week, Leo, to talk about LastPass.



LEO:  Well, didn't we talk about it two weeks ago?  I thought we did.



STEVE:  No, what happened was this all happened just after we began, after we finished recording.



LEO:  Oh, that's right.



STEVE:  So I did a special appearance with Tom on This Week in Tech.  And I thought, well, why is everyone asking me why I forgot, why I didn't mention LastPass last week?  And so looking at my own tweet stream, I realized, oh, I said I was going to.



LEO:  You have my problem, which is I do so many shows, of course we talked about the LastPass issue ad nauseam, but perhaps not on this show.



STEVE:  Exactly.  So I have to do so briefly.  Essentially what happened, for those who didn't see my special appearance on This Week in...



LEO:  No, TNT.  Tech News Today.



STEVE:  TNT, Tech News Today, right, which I did that afternoon with Tom because you and I had already recorded it, but this was important.  The guys at LastPass saw some traffic, some just sort of like traffic volume that they couldn't explain.  They didn't know what it was because it's all encrypted.  So they're just seeing blobs going back and forth of pseudorandom stuff, but it looked uncharacteristic to them.  And so just, I mean, that's all it took.



LEO:  I loved it that they blew the whistle on themselves, being proactive.



STEVE:  Yes.  I mean, as far as we know, there wasn't even a breach.



LEO:  We don't even know, right.



STEVE:  Exactly.



LEO:  They just wanted to be extra cautious.  I love that.



STEVE:  It was very impressive.  So what they did was they sent out the word to users to change their master password because the worst that could have happened, and this is what I talked about with Tom, the worst that could have happened is that an attacker could have gotten the hash that they use for authenticating users and the users' encrypted blob.  Some people don't understand the way LastPass works and thought that a breach of LastPass's database security immediately meant that bad guys were able, consequently, to decrypt the blob.  But that's the whole reason I endorse LastPass is LastPass themselves cannot decrypt that blob.  So, for example, you don't have to worry about them responding to an FBI subpoena for your information.  They can't.  They don't have the ability to decrypt the information.  And that means that an attacker who gets what they have can't do it either.  So they don't have it to give.



Now, the only weakness would be a brute-force attack against the hash, and we've talked about that, what that means, also.  So if you had a good master password for LastPass, then the algorithm is your email address is lowercased because email addresses are not case sensitive.  So LastPass wanted to eliminate the possibility that you would be entering your email address with different case when you're trying to authenticate to LastPass, to log on to LastPass, than you normally use.  Since email doesn't care, they don't care either.  So you lowercase the email address.  Then you merge that with your password.  And that's hashed to create the private key which you use to encrypt your database.  That never leaves your browser client.  Then your password is hashed again with that key.  And that's what is sent to LastPass to authenticate you.



So again, they're getting a hash of your password and your secret key, which itself is generated from a hash of that password and your email address after it's lowercased.  And hashes, hash functions are beautifully designed to be one way.  They used SHA-256, the strongest state-of-the-art hash we have, generating a 256-bit result, so certainly strong enough.  I guess SHA-512 obviously is twice longer, but it's not clear that there's any point in using that.  And so what an attacker would have to do would be to repeat that process with every possible password.



LEO:  Do they go one extra by doing multiple salts?  Is that the one we talked about last week?



STEVE:  That's actually what they're going to do.  When they looked at what the vulnerability, what the theoretical vulnerability was, it would be somebody using a very weak password, like a dictionary word or something, the kind of password that no one should now be using, which because it was weak, you could mount an offline attack where the user's email address, which again the attacker might have because LastPass does have that, that would be hashed with this test brute-force password.  That would get hashed.  Then it would be hashed again to produce the authentication token.  And if the attacker did have that, they would look for a match.  That would then - they still wouldn't be able to decrypt the user's data.  But then they would be able, then they would have the password as a consequence of going forward through the two hashing functions, brute forcing it.  Then they could authenticate to LastPass and obtain the blob which then they would be able to decrypt it.



So if bad guys got the database, and if users had weak master passwords, then there's a possibility of doing, over some length of time, a brute-force attack.  And so erring way on the side of caution, the LastPass guys said, okay, just change your master password.  We're sorry to put you through the inconvenience.  You don't have to change any of your other site passwords, just the one master password.  That way nothing that might have been taken, if anything was, and we don't know that anything was, nothing that might have been taken would still be vulnerable even to a brute-force attack.



LEO:  And they also offer, and I use, two-factor authentication.  So if you use that, you're safe, too.



STEVE:  I was going to say, anybody with a YubiKey, for example, absolutely was safe because, again, these guys have looked for every opportunity to help make us secure.  They take the fixed portion of the front of the YubiKey token and mix that in also, which no attacker could ever have.  So there's just no way to compromise if you were using the multifactor authentication.  So bottom line is, they responded immediately.  Their site was overwhelmed by people who needed to change their master password.  They're now thinking, well, maybe we did overreact, frankly.  But better safe than sorry.



Now, the one thing they're going to do is, and we talked about this last week, this notion of key stretching.  And that's what you were referring to, Leo.  The problem with brute-forcing a hash is hash functions have been - there is hardware, for example, to really perform very fast SHA-256's.  For example, that's how Bitcoin mint guys are using GPUs in order to try to sign and generate the hashes for the Bitcoin transactions.  So code exists for GPUs in people's machines to do SHA-256 very fast.



So the solution is to require a great many of them per authentication.  And the number I saw was 100,000, which is to say, to authenticate, the SHA-256 function would be run 100,000 times, meaning its output put back into its input, maybe mixed with something else, and then that generated and done again.  And so what that does is, no matter how fast a brute-force attack on that content could be mounted, this would slow it down by 100,000 times because every single guess would have to be done 100,000 times.  So I'm going to keep track of that, and I'll let our users know whether that gets implemented and when.  But, I mean, basically they've just done - they had done everything they could before.  This further raises the bar, and it's not clear whether actually anyone even got data from them.



LEO:  The bar needed to be raised.



STEVE:  Yeah.



LEO:  I think that's really a good model for companies like Sony and others.  I mean, be proactive.  Jump on it.



STEVE:  Yeah.  In miscellaneous news, I wanted to mention that I've been receiving really nice feedback from people who took my recommendation of Mark Russinovich's "Zero Day" book to heart, many of them saying they're only a few chapters in and hooked already.  So people are liking it a lot.



There was a really interesting TED Talk about the danger of filter bubbles, as it was called.  I tweeted the URL for that and recommended that my followers check it out.  You can also find, if people are not following me or aren't using Twitter, just - of course you can always look at my Twitter stream by going Twitter.com/SGgrc, and you can see everything that I've tweeted recently, that I've been referring to as it happens in this podcast.  Or just go to YouTube and just search for "filter bubble."



It's a really interesting nine-minute TED Talk which demonstrates sort of the social issue of the fact that increasingly the results that we're getting from searches are being customized for us, and what that means.  I just - I recommend it to our listeners.  It's a little scary.  This guy doing some research [Eli Pariser] had two different friends both Google 911.  And he shows the radically different search results that Google returned because of what Google knows about these people.



LEO:  Now, only if you're logged in.  I mean, if you log out of your Google account, nothing.



STEVE:  Is that the case?



LEO:  Yes.



STEVE:  Okay.  Because, I mean, they...



LEO:  So you have to opt into that, basically.



STEVE:  Google has cookies and IP addresses and...



LEO:  No, no.  You can opt out.  You can log in and opt out of history and tell them not to keep history.  If you don't log in, they have no history.  And so you will not get customized results.



STEVE:  He also shows a result with Facebook, with Facebook noting over time the kinds of things he clicks on.



LEO:  Well, that's true.



STEVE:  And that Facebook, in trying to do a better job of giving him what he wants, he ends up not seeing information that he wishes he were seeing.  Anyway, YouTube, 'filter bubble," search for that.  It's a really interesting nine minutes.  Just apparently it's happening more and more and worth just being aware of.



LEO:  It's intentional.  And it's designed to make your search results better.  But if you don't like it, you can, at least with Google - obviously Facebook you can't turn it off because you're always logged in.



STEVE:  Well, and in general, search in general, we know that, for example, the reason we're being given custom advertising is that advertisers are able to charge more when their message is going to an audience that's more likely to care about what they're offering.  So in general we're seeing the web attempting to conform to who it thinks we are.  And that's why tracking is become so controversial is a lot of people started to have an "ick" factor relative to the notion of profiles being assembled about them.  And of course those are being used to customize their experience of the web.  And he just brings up the point that, well, maybe that's not such a good thing in all cases.



LEO:  Yeah, be aware of it, I guess.



STEVE:  Yeah.  My favorite tweet of the week was sent to me from @luridsorcerer, that's his Twitter handle, it's Andrew Lingenfelter.  He said, "The online software license option I'd like to see would have a third option.  You have 'agree' and 'disagree'?  The third option would read, 'Didn't read the license, but agree anyway.'"  Which I just got a kick out.



LEO:  Well, that's what I do.



STEVE:  That's what we all do.



LEO:  That's what we all do.



STEVE:  No one reads the license.  You can't.



LEO:  So I think it would be nice to have that checkbox, yeah.



STEVE:  Yeah.  That'd be nice for a third option.  And someone else this morning, Simon Bodger in Canada, he said, "Steve, love the PEE acronym."  P-E-E.  He says, "As a parent" - and remember that PEE stands for Pre-Egression Encryption, that is, encrypting stuff before it leaves your system in order to be safe with your data in the cloud, Pre-Egression Encryption.  So he says, "As a parent, I'm always saying, 'Before we leave, did you pee?'  Sounds like good advice for my data, too."



LEO:  I love the acronym.



STEVE:  I had some interesting tweets about that.



LEO:  I bet you did.



STEVE:  That was a fun one.  And a listener of ours, Jeffrey Wurzbach, he said, "I downloaded a copy of SpinRite from someone."  Or borrowed.  "I borrowed a copy of SpinRite from someone.  After SpinRite..."



LEO:  What?



STEVE:  Well, you know, that happens.  I recognize that.  But he says, "After SpinRite unbroke my machine, I decided to buy it.  My computer was taking a very, very, very" - got three verys there - "long time to boot Windows.  Both my main boot disk and my secondary disks were randomly powering up and down.  I suspected something was broken in the hardware of the disk.  But not having the money for a new computer, I had to do something.  So I used SpinRite  on the main disk.  It was able to get the computer to boot about 50 percent faster and get all of my critical data onto my network storage drive.  SpinRite saved me many hours of frustration and four-letter words.  If only I had SpinRite four years ago when my parents' computer died."  So the good news is he tried it, liked it, bought it, and has it now.



LEO:  Yay.  Yay.



STEVE:  For the next disaster.  So thank you for sharing that, Jeffrey.



LEO:  Let's talk randomization.



STEVE:  So, yeah.  One of the things, and I mentioned this briefly last week, that sort of annoys me sometimes is the people who make the blanket statement that security through obscurity is no security at all.  Because the fact is, all security depends upon obscurity.  It just depends upon having and knowing what the attack model is and understanding what needs to be obscure.  So let's draw an example.  Say that you had a non-keyed cipher algorithm, that is, an encryption algorithm that did not use a key.  So it was just this algorithm that, when you ran it, you put in something and out came a blob that was encrypted.  And you'd think, wow, that's fantastic, that's great.



The problem is, you absolutely have to keep the algorithm secret because the only protection that you have that's created by this algorithm is the algorithm itself.  So in order for this to be effective, that has to be kept absolutely secret.  If it gets out, then anybody can look at what's been encrypted and decrypt it, or impersonate you by encrypting something themselves.  The point is that that's a perfect example of bad crypto and bad security because you're inherently depending upon the algorithm being kept secret.



Now, contrast that to the way we know things are correctly being done these days.  We have public algorithms where, I mean, they're public from day one.  There are public competitions, as we saw with the AES competition to end up choosing Rijndael to be the standard cipher that so many people are now using.  So, I mean, it was way public.  It was taken apart by academicians.  It was analyzed.  It was really torn apart.



The reason we can do that, though, is there's only one reason.  And that is, it's a keyed cipher.  Which is to say the strength of the result is the combination of what is absolutely well known, which is to say the cipher itself.  And it's because it's well known that we trust it because academicians, cryptographers, have been able to pound on it.  They've been able to, like, reduce its strength by having it go fewer rounds and, like, watch it work, and see how quickly, as you increase the number of rounds the cipher goes, it becomes impossible to reverse engineer it.



So it's two things.  The total secrecy that we get is composed of something we know, which is how this algorithm works, but something which is still obscure, that is, it's still kept secret.  And that's the key which is used to run the cipher.  So it is not the case that we get security if everything is known.  It's that we carefully design what parts of our system are known, but we then still have secrets which we keep.  And the reason then that we need, in cryptography, we need random numbers is that we don't want an attacker through any means at their disposal to be able to guess what the secret is.  We're going to have a secret.  In SSL communications, HTTPS that we've talked about, there is a secret.  There is a handshake which goes on between the endpoints where they arrive at a secret by using random number generators.  And we depend upon the randomness for security.



For example, this hasn't always been done correctly.  The very first version of Netscape's SSL, Netscape back in the original early browser days, they were the designer of SSL v1.0.  They used the time of day, the process ID, and something else.  There were three components.  I don't remember what they were.  But the point was they weren't - and they used those to seed the random number generator which their SSL connections then used for establishing secure handshakes.  And it wasn't long after - but they didn't publish it.  They kept it secret.  And of course these are the kinds of secrets you can't keep.



A year later, some researchers figured out what Netscape was doing, looked at the fact that they were using time of day, process ID, and one other factor, but still predictable.  And it turns out that something like process ID, it's like, well, we don't always know we're going to have the same process ID; but if you start a computer up, and you do a couple things with it, it's typically going to be this.  Or it's going to be some range which allows an attacker from the whole possible spectrum of process IDs to zero in on, well, it's probably going to be one of these.  The point is, they didn't start with enough randomness.  And it turns out that version 1 of their SSL protocol could be attacked by virtue of its lack of good random number generation.



So we've seen that over and over.  And in fact it's a lesson which some people don't learn very well.  Microsoft in '07 had the same problem with the pseudorandom number generator that was in Windows 2000, and it's the same one that's in XP.  They had some researchers who - and again, Microsoft didn't publish this.  They maintained - they kept it strictly secret and tried to obscure it.  Some researchers ended up taking it apart, figuring out how it works, and were then able to demonstrate that, because of what Microsoft had done, the decisions they had made were not cryptographically sound.  And if they were ever able to obtain the state of the random number generator, then they were able to know everything about its future.  So if something ever got into your computer, they could take a snapshot of it.  And there was no more mystery, even though Microsoft had gone to some effort to try to enforce that.  It just - it wasn't done well.



So there's a strong incentive for saying whatever it is that is done, in order to have it cryptographically sound, you really need to have it looked at by people.  You need it to be public, never secret.  And you need to just say, this is what I have done.  What does the world think about it?  Have I forgotten anything?  Because we know mistakes can happen.



So one of the problems that computers have, as we've discussed, is that they're 100 percent deterministic machines.  If you start the computer in a known state, and it goes through a series of processes, it's always some time later going to arrive at another state, that is at a given state.  It's adding and subtracting, multiplying, dividing.  It's jumping, it's doing the things it's doing.  But it's always following instructions, which unless they change, what it does and where it arrives is not going to change.  So there's this notion of state which can be thought of as a quantity.



For example, I was talking about, last week or two weeks ago when I introduced this, the idea of taking a 32-bit integer and using a simple algorithm calling a linear congruential pseudorandom number generator, where you multiply that value by a constant, and then you add a different constant, and it produces a new result.  And if you choose the multiplier and the addend correctly, that 32 bits will jump all over the place until it comes back to the original one.  And it'll occupy the full, every possible combination of 32 bits before it returns back to the beginning.



The problem is that it is a very weak algorithm.  It's simple for, like, a cryptographer would just not take two seconds to figure out what this thing was doing and be able to predict the entire future of numbers being generated.  The other problem it has, though, is that its state is only 32 bits.  That is, at no time can it have more complexity than that.  That is, it's got one of 32-bit values, and it's next going to move to a different one of 32 bits.  And there's no way for it to be more unknown than that.



So what we try for in contemporary pseudorandom number generators is much more entropy, much more state, so that the system is not easily knowable.  And if someone did get, if a bad guy somehow got a snapshot of it at a given time, there would still - the future is not completely predictable.  That's key for real security.  We can often assume that the bad guys cannot get into the system.  For example, if someone's eavesdropping on an SSL communication, well, we want a protocol and a random number generating system which is strong against someone looking at all of our packet traffic.  And no matter how many connections we establish, if there was a man in the middle or someone sniffing the initiation of connections over SSL, we would want them, no matter how much they looked at the output, never to be able to guess what the past or the future had been.



Sometimes we don't have strength.  For example, a malicious process could get into the computer where it has access to the machine and could get a snapshot of the pseudorandom number generating system.  If we're trying to prevent against that, then we need some ongoing source of entropy always sort of being added into a pool.  And cryptographers talk in terms of entropy pools, the idea being that you feed in anything that you can get which is not predictable by an attacker, certainly not one outside the machine, and often not one in the machine.  That would require them to constantly be monitoring your random number generator.  And frankly, we're really not designing our systems to be strong against an attacker in the machine, but rather if we generate a large random key that we use to encrypt our drive, or we use to encrypt communications.  The point is that we want anyone coming along afterwards to have no basis for knowing what that key was, how we arrived at that key.



So we're still faced with a problem of where do we get this kind of true random information.  Historically, all kinds of things have been done.  What we want is we want the notion of uncoupled independent events where things happen that are not related to events that have already happened in the past or would happen in the future.  A popular source, for example, is some sort of electrical noise.  There's noise generated in electrical processes that are the result of quantum fluctuations, low levels of heat, low levels of photon radiation entering the system.  There's, for example, been a project where a CCD imaging array, a Charge-Coupled Device imaging array is put in a completely black box.  And it turns out that even though there's absolutely no light getting to this imaging array, the signal it outputs still has some non-zero content.  There's noise.  It's like sort of imaging hiss.  And it's extremely random.  There is absolutely no way for an attacker to know what that hiss is going to be from one instant to the next.



Another possibility is just using the least significant bit of an analog-to-digital converter.  For example, the sound input on a sound card, even with nothing plugged in, you typically don't get an absolute flat line.  You get a few values in the least significant bits, which is just noise in the amplifier that feeds into the analog-to-digital converter.  So, and that again, it won't be following a pattern.  It's just, it's noise.  It's not exactly predictable.  And that's what you want.  Or a radio, just that hiss you hear when you tune a radio in between carrier frequencies is just the electronics in the radio sort of just listening to what's going on in the environment.  And that white noise that you hear is also not exactly predictable.  Or a Geiger counter, which is measuring individual photons which are coming in and ionizing the gas in the Geiger tube, is producing a not absolutely predictable series of events.  And famously, SGI, who years ago wanted a good source of real random content, actually patented, they have Patent 5,732,138, which is aiming cameras at lava lamps and using the...



LEO:  That's a chaotic system, I think.



STEVE:  It absolutely is.  You cannot, I mean, you can stare at it, no matter how long you stare at the lava lamp you really don't know what it's going to do.  You cannot predict what it's going to do.  And so SGI set up a lab, a darkened room where they had cameras looking at lava lamps, and they were digitizing the images of the lava, which is hot wax, moving through that fluid.  And as you said, Leo, it's a chaotic system.  You cannot predict what it's going to do.  More recently there are some very good random number generators using a partially silvered mirror.  For us, when we look at a partially silvered mirror, we can sort of see through it and sort of not, that is, we'll sort of both see what's on the other side of it and what the mirror is reflecting.



But at the quantum level, what that actually means is that some light photons are reflected off of it, and some go through.  You need that behavior in order to partially see through a mirror.  What that means is that you can put a photo detector, a photon detector, on one side of it, and have it count the events of things that go through.  And it turns out that's quantum uncertainty down at the quantum mechanics level, and it is extremely random.  It is not producing a predictable result.  It may not be 50/50, but it turns out you really don't need 50/50-ness in order to generate a source of something that is, while it may not be purely random, it is absolutely unknowable.



So then there's other things that have been done.  For example, people have looked at the arrival time of Internet packets, network traffic packets.  And in fact anything that you do, if you have sufficiently high resolution in a counter, in a timer - and that's the key.  What's really neat about our current trans-gigahertz machines, we've got 2.4GB, 3.0GB and so forth, there's a counter in all of our Intel chips, and non-Intel chips have them, too, that is running at the speed of that system clock.  It is running at 3 billion, that is, gigahertz, 3 billion counts per second.



Now, if you took a snapshot of that timer when a network packet arrived, and then another network packet, and another network packet, well, if you didn't have much resolution, if that counter weren't running very fast, then you wouldn't be really getting much randomness, much entropy from that.  But with it running at 3 billion counts per second, even if you tried to send packets to your computer at an exactly perfectly timed rate, variations in the packet assembly, in the interrupt system, in the computer, I mean, just 3 billion counts is so fast relative to sort of the real world events that are happening, that the least significant bits, the one bit, the two bit, the four bit, they're absolutely unpredictable.



And that means you can use other things that are happening.  You can use the timing of reads and writes on disk drives because, as we've spoken about in the past, disk drives are not spinning at an absolutely constant rate.  The sector timing is used to servo the drive to keep it running at about the right speed, as is the distance from the heads to the platters.  But that's varying.  So that means that, if you look closely enough, you're going to get a huge amount of uncertainty.  I mean, again, look closely enough.  If you use this 3GB counter that we have, or 2.4 or whatever, there's no way to predict what the least significant bits are when you take a snapshot of it.  Or when you move the mouse, or press keys on the keyboard.  They're just, if you're spinning that counter fast enough, the lesser significant digits are much more predictable than the least significant digits, which in the case of the 1 bit, it's changing 3 billion times per second.  And you're going to say, okay, now.  What is it now?  I mean, that's so fast, that gives you really good unpredictability.



And then, finally, just because you could never have too much randomness, we know, for example, that the Trusted Platform Module, the TPM, which is in most laptops today - I wish we were seeing it more in desktops.  I know that it is available in some desktops, but not yet universally.  The TPM has a true random number generator in hardware in it.  There it's using thermal noise down at, again, at the quantum level in order to generate an offer on behalf of the system that is hosting this TPM, true physical random numbers.  Not pseudorandom.  Anytime we have pseudorandom we're saying that there's an algorithm which is generating these.  And by the nature of an algorithm, we know what each number is going to be in succession.  With a true random number generator, it's not algorithmically based.  It's just every number that it produces, it's producing freshly.



Now, the problem is that the rate at which we're collecting entropy may be lower than the rate at which we want to consume it.  Let me say that again.  It may be that the rate at which we're producing it or able to collect new randomness, new entropy, is lower than the rate that we want to consume it.  So, for example, the true random number generator in the Trusted Platform Module will have some bandwidth.  It'll have some rate at which it's able to give us numbers based on the physical processes that it is tracking.  And you can imagine lava lamps, yeah, they're chaotic, but they're not moving very fast.



LEO:  We need more bits.



STEVE:  We need more bits.  So what has been done is very clever.  And this is represented by the state-of-the-art pseudorandom number generators which, for example, Bruce Schneier has designed.  There's one called Yarrow that Schneier and John Kelsey designed, and a newer one called Fortuna which Bruce designed with Niels Ferguson.  The way they work is they have an entropy pool, that is, they have a - think of it as a buffer, just a big buffer.  And whenever something happens that they can say, okay, well, we're not sure how much entropy is there, but it's probably got some.



For example, imagine that every time something happened you took a snapshot of that 3GHz counter and added it to the entropy pool.  So packets come in, hard drive sector read or write happens, mouse gets moved, keyboard gets hit, even something like the graphics display adapters often have a 60-cycle or a refresh interrupt.  And that's not coupled to the counter running in the machine.  It's generated by a separate crystal on the display card, separate from the crystal on the motherboard.  So there you could, at 60 times a second, you could sample on the display interrupt the exact count of this 3 or 2.4, whatever it is, gigahertz timer running very fast in the computer and just dump it into the entropy pool.  You don't really care how much entropy it has.  You just know there's a lot of uncertainty in the least significant bits of that.  Nobody can guess.  And in fact, if you did, if you plotted them out, and people have, you would see absolutely no predictable pattern in those least significant bits.  They're just uncoupled, and they're related to physical processes down at the quantum level.



So what state-of-the-art random number generators do is they collect this entropy pool, adding it to this pool, until they decide that they have collected enough of it to reseed a pseudorandom number generator.  And, for example, the most recent one, Fortuna, which Bruce and Niels did, they hash the content of the pool to generate a new key for our friend the AES Rijndael cipher, which they have being driven by a counter.  And after they have hashed the pool, they empty it.  And then they begin again putting new entropy into it.  Meanwhile they have an absolutely unknowable key which is the key to the AES cipher which they're driving from a counter.



Now, what they know is that they cannot pull from this forever because the counter will wrap.  And we can't ever allow the counter to wrap around with the same key or it will be reproducing the identical sequence of pseudorandom numbers that it originally produced.  But that's not a problem.  We've got 128 bits that we're encrypting with Rijndael which will last us a long time, relative to the rate that we're able to collect new random things happening from the environment, which collect up to, we only really need - we need at least 128 bits, or, for example, 256 if you wanted to use a 256-wide key for Rijndael.



So as soon as we collect, like, maybe say 1,024, just so we know that we've got more, then we hash that down into 256, and we rekey the cipher so that it is - it's constantly being rekeyed.  But it's able to give us a tremendous bandwidth of pseudorandom data which is based on the truly random data which we're accumulating in this pool at a much lower rate.  So our physical processes won't give us megabytes per second of true randomness, but they will give us enough that we can use that to constantly reseed a pseudorandom number generator which can run at whatever speed we want.  And that's what we're doing now in state-of-the-art crypto systems, is we're using some sort of physical processes to accrue pools of true entropy, which is absolutely unpredictable, which we then hash into a key to drive a very simple and very efficient pseudorandom number generator which gives us, while not absolutely random numbers, it meets our need of both having a high bandwidth and being absolutely unpredictable.



And that's all we need.  We can't know - no attacker, looking at the past or future, can know what the number is we're going to have now because of the strength of this cipher, even when just driven by a counter with an unknown key.  That much we know we've proven.  And by using an entropy pool, there's no way for us or anyone else to know what it is that we're going to be giving to that counter and cipher as its key from one moment to the next.



And so we've solved the problem very cleverly.  Even though we've got technically a deterministic system, there are enough nondeterministic bits, literally, that are available because of the resolution at which we're able to measure these various physical processes that they're unpredictable, unknowable, and they give us a source of absolutely cryptographically strong pseudorandom numbers, at whatever speed we want them.



LEO:  Now we understand that weird JavaScript page that you've put together.



STEVE:  Well, actually, yeah.  What I did on that JavaScript page, I mentioned it a week before last, it's GRC.com/r&d/js.htm.  What I'm doing there is I am tracking mouse and keyboard movements.  The problem is I don't have access to, in JavaScript, to a really high-precision counter.  I've only got a millisecond resolution.  Which is better than nothing, but it's not really good.  So the way I solved the problem of a client, a JavaScript client, a  browser having really good entropy, is I have GRC give the page a starter 256 bits.  And then everything the user does at their end is unknowable by GRC.  So I seed the random number generator with something that is really good, that is, a pseudorandom number coming from GRC.  The problem is, from a security standpoint, I know - I, GRC, know what I gave the user.



LEO:  That's right.



STEVE:  So we want to immediately diverge what GRC provided from what the user's going to use.  So, for example, the JavaScript takes a snapshot of the time of day when it starts to load.  It takes another snapshot of the time of day when it finishes loading.  It asks the JavaScript pseudorandom number generator, which is not very good, but it's got an unknown state to GRC, it asks it for 270 bits, which the JavaScript pseudorandom number generator provides.  And so the point is, everything that I can capture that is going on on the user side is poured into a hash that hashes what GRC provided, immediately diverging it in a way GRC can never know because it's happening all on the client side.



So we get the best of both worlds.  We're not only dependent, that is, the user's browser, whatever process it's doing, isn't only dependent upon randomness coming from his computer because we know that's not very good.  But I'm able to provide, I GRC am able to provide a starter which is very good, but we don't want me to know what the user's going to use.  So we immediately hash everything we can on top of it to diverge it from anything GRC knows.  I mean, and if you just hash one bit, it's instantly going to be a different value.  And we're just - I have no idea what the user's time of day clock is, how long a page is going to take to download, certainly not what the state of their JavaScript pseudorandom number generator is.  So you put all that together, and it's extremely strong.



LEO:  And it changes as I move my mouse, so it's always different.



STEVE:  Yes, exactly.  Every event is rehashing that event timing.  And any details, like the X and Y position of the mouse, any information I get is being poured into the hash and rehashing the key so it's constantly evolving and ends up being very secure.



LEO:  Yeah.  Cool, too.



STEVE:  Yeah, it's neat.



LEO:  Well, thank you for filling us in on random.  I think that's it, that's everything we need to know about random.



STEVE:  I think it is.  We've never talked about it before, but it is crucial that we have, for crypto processes, that we have a source of really good random numbers.  And I hope Microsoft is listening because this is better than anything that they were doing back with Windows 2000 and XP.  And I do think that they have evolved their technology since then because they finally understand it's important.



LEO:  Yeah.  And I think it's also, from a pure computer science point of view, a fascinating conversation.  It's certainly practical, but it's also interesting.



STEVE:  Well, and the NIST has published a set of tests that can be used to measure the quality of randomness.  There's, like, 16 of them:  mono bit frequency, block frequency, cumulative sums, runs, longest run of ones, binary matrix rank, DFT spectral, non-overlapping template matchings, overlapping template matchings, Maurer's universal statistical test, approximate entropy, random excursions, random excursions variant, serial, Lempel-Ziv compression, and linear complexity.  And it's funny because some very good random number generators fail various of these tests in different ways.



LEO:  Really, that's interesting.



STEVE:  Yes.  Some pseudorandom number generators fail them in different ways.  But I got a kick out of that Lempel-Ziv compression.  That's LZ compression.  That's the original technology that we all use in, like, PKZIP and everything.  That is the zip compression.  And of course, as we've talked about it, one of the measures of randomness is compressibility.  Right?



LEO:  Yeah.  Yeah.



STEVE:  Because anything with a pattern can be compressed because the compressor finds the pattern and uses that in order to get compression.  But pure random noise is incompressible.  There's nothing that a compressor can latch onto in order to make the result smaller.  So that's kind of cool.



LEO:  Yeah.



STEVE:  And the DFT spectral, that would be discrete Fourier transform, which would be to say do a Fourier transform of the noise to see if there are any frequencies which are occurring in it because it ought to be absolutely flat spectrum.  There should be no peaks of any particular frequency.  Sort of like you'd see in a gas chromatograph, where you have, like, peaks, you're identifying something.  So these are tests which are really ruthless and very rigorous that the NIST has solidified on as part of their formal publication of, like, is this random enough?



LEO:  Fascinating stuff.



STEVE:  Cool stuff.



LEO:  But hardly random.  In fact, you could find this show right there on the Internet at GRC.com.  Steve makes 16KB versions available, as well, for those of you who have bandwidth caps or don't want to spend a lot of time downloading.  Transcripts, that's the smallest version, if you like to read along, and all the show notes, including that R&D page, is at GRC.com.  That's also where you'll find SpinRite, the world's finest hard drive maintenance and recovery utility, a must-have.  If you've got hard drives, you need them.



STEVE:  It works.



LEO:  Next week a Q&A episode.  Go to GRC.com/feedback to leave your questions.  And you can follow Steve on Twitter, @SGgrc.  GRC.com's the thing to know.  Just memorize that, Gibson Research Corporation.  You can also watch us do this show every Wednesday live, 11:00 a.m. Pacific, 2:00 p.m. Eastern, at live.twit.tv, or subscribe on iTunes or any other podcast client.  Or just go to TWiT.tv/sn for Security Now!.  We've got all the episodes there and all the subscription buttons you could want.  And the chance to buy a brick for the brick TWiT house.  Thank you so much, Steve.  We will see you next week.



STEVE:  Talk to you then, my friend.



LEO:  On Security Now!. 



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#302

DATE:		May 26, 2011

TITLE:		Listener Feedback #118

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-302.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 302, recorded May 25, 2011:  Your questions, Steve's answers, #118.



It's time for Security Now!, the show that protects you and your loved ones online, your privacy too.  And here's the guy who does it all, from GRC.com, the great Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Hello, Leo.  It's great to be with you again, as always.



LEO:  Let's get ready to secure yourselves.



STEVE:  This is Episode 302.



LEO:  Oh, my god, I can't believe it.  You know, you're just one behind, well, I guess you're, yeah, you're just half a week behind TWiT.  Because TWiT did 302 on Sunday.  I know that was your goal.



STEVE:  And TWiT started before Security Now! did.  You had them as your flagship podcast.  But since we keep counting ours, and you've had some TWiT vacations...



LEO:  Yeah, but never again, by the way.  Lisa has informed me that I may no longer miss any episodes of any show ever, ever again.  No, TWiT especially is a show we don't want to miss.  So unless something surprising happens, you're going to be at parity forever.



STEVE:  Sounds good.



LEO:  I think that's fine.



STEVE:  Yeah.



LEO:  I think that's fine.  You caught up.  That was amazing.



STEVE:  So we have our regular roundup.  This is a Q&A episode, our 118th Q&A.  We've got a roundup of News of the Week and some great comments and feedback from our listeners to cover this week.  And the last question is actually a lead-in to next week's episode that is going to surprise everyone.



LEO:  Oh, really.  Something new.  Something exciting.  Something different.  Something we've long awaited?



STEVE:  I would call it, actually, no, it's probably nothing less than a breakthrough.



LEO:  Whoa.



STEVE:  So, yeah.



LEO:  Whoa.



STEVE:  Yeah.  It's going to...



LEO:  All right.  Whoa.



STEVE:  Yeah.



LEO:  Before we get to it, I'm just looking at the notes, we've got security updates to talk about.  There's a lot of security news.  Sony's been breached again.



STEVE:  Oh, they are just - they ought to just get off the Internet.



LEO:  Well, now it's like a matter of pride, I'm sure, for hackers.  It's going to be really tough for them to get off this horse.



STEVE:  Well, we're going to talk about what happened because it's something we've talked about before, which is, well, I won't...



LEO:  Save it, save it.



STEVE:  ...negotiate with myself.  Yeah, I'll save it.



LEO:  All right, Steve.  Time to get to the security news.



STEVE:  So Google has been updating Android, actually 99.7 percent of their devices, of the Android devices.  SANS wrote that "Google is rolling out a fix for a vulnerability in the majority of Android phones that allows attackers to access and modify users' Google Contacts and Calendar when they are being accessed" - and listen to this carefully because this is important for us - "when they are being accessed over unsecured WiFi networks."



LEO:  It's a Firesheep thing.



STEVE:  Exactly.



LEO:  Now, didn't they fix it server-side, though, right away?



STEVE:  Well, the flaw, for those who are interested, the flaw affects versions 2.3.3 and earlier on the Android platform, which is virtually all, all but .3 percent of Android devices.  And it requires no action from the users.  It'll be pushed out automatically.  The reason this caught my eye is that we've had a number of listeners who have essentially asked this question, which is, well, if I'm using a smartphone which has both a 3G cellular connection or a WiFi connection, but as is the case with smartphones it will preferentially use WiFi when it's available, what do we know about the security of the phone's use of WiFi versus 3G?



And this is a perfect example of the concern that this creates, which is, if you're not using your own WiFi, which we know would be secured, and if you're using open WiFi, that is less secure from in the air near the phone than if you were using 3G, which, while its cryptography is not uncrackable, it's still very strong and much better than, as you say, the Firesheep stuff, which basically just takes advantage of the fact that there is, over an unencrypted connection, there is data moving between the phone and the access point which can be sniffed and is in the clear.  And this was happening to people who were using Android phones.



So the question that's been posed to me, I've seen it a number of times, is should I turn off my WiFi when my phone would like to use it, but it's unsecured?  And from a security standpoint, I would say yes.  I would say, unless you really need the bandwidth, if you're just doing things that can work over 3G, if the choice is between that and open WiFi, I would use the cellular connection because it at least has local encryption.  And so, while Google has fixed this for Contacts and Calendar, we don't know what's going on with all those other apps that are loaded on the phone that might very well have...



LEO:  That's a good point, yeah.



STEVE:  ...yeah, Firesheep-ish problems.  I mean, it's unfortunate...



LEO:  Like the Facebook app, for instance, or something like that.



STEVE:  Precisely.  All of the other apps that are doing communication, they're probably glad to be on Android.  But security may well not be a priority for them.



LEO:  If they offer SSL, as some do - like Foursquare or whatever, Twitter, do that; right?



STEVE:  Oh, absolutely.  So, for example, in the case of Facebook, if you're able to turn that on and keep it on - of course we know the problem with Facebook is that there are still Facebook apps which don't support SSL, which unfortunately require that you drop completely out of SSL rather than it being more granular.  I'm hoping that Facebook is first going to make it more granular and then go the next step and just make it a requirement of apps to bring their security up, if they want to play in Facebox world.  Facebook's world.



And Adobe has one again updated Flash.  I noted that they're no longer even talking about quarterly updates.



LEO:  Not even close.



STEVE:  They've dropped that whole idea of, well, we're going to wait till June.  Fine, just give it up.  Because they had a big problem which was affecting all versions of Flash Player for Windows, Mac, Linux, and Solaris, any versions 10.2.159.1 and earlier.  And the same thing, 154.28 for Chrome, 157.51 for Android.  And I just, when I turned my Win7 box on in order to fire up Skype for this conversation with you, Leo, I got the notice, and what they were giving me was 10.3.  So I imagine that's where they moved to.  So you do want to make sure that you're using the latest since it's broad platform.



And so they've released patches for multiple security vulnerabilities affecting Flash Player.  And Adobe reported that malware in the wild is exploiting at least one of those known vulnerabilities, which is a memory corruption problem.  And so merely by enticing a target to view a maliciously crafted file, an attacker can exploit at least one of those vulnerabilities, well, actually all of those, but has been exploiting one of them in order to execute arbitrary code.  And so I just see Adobe saying, well, we're just going to - we're going to update our stuff as we need to and not try to follow any schedule because that hasn't worked very well.



I did want to mention, since we're talking about Facebook, that they have added phone-loop, two-factor authentication.  Some users have been a little put off by that because it requires giving Facebook your cell phone number.  And people that have been concerned about Facebook's privacy practices are already sort of fed up with telling Facebook anything that they're worried Facebook may leak.  But the two-factor authentication approach seems to be a good one.  They probably use cookies because they identify machines that you have used before.



So the idea is, if you attempt to log on, in their jargon, from a device that they have not seen you use before, then and only then, if you have it configured, and it's not automatically turned on, so Facebook users need to go and activate this in order to make it happen, you activate it in your security settings, give them your cell phone number, they will send you an authentication code which you then need to enter into your logon point on this device where you've never done it before.  Then they stick a permanent cookie on that device which authenticates it in the future.  Which is a really nice tradeoff.  It means you're not being harassed all the time.  I think it's typical Facebook user-friendly.



I got a tweet from someone saying, well, yeah, but why aren't they supporting VeriSign or YubiKey or blah blah blah?  It's like, well, I would call that advanced one-time password multifactor authentication.  It's probably outside the scope of what most Facebook users can do.  But for people who know that they're going to have a cell phone around, at least when they're using a new device, this is great because it means that the bad guys aren't going to be able to close that phone loop by providing the information.  Also, you'll know if someone is trying to log on as you because your phone will send you a code that you're not expecting.  Which means someone induced Facebook to send you this.  So it's also sort of a cool notification that someone is trying to get into your account.  So I think it's a good thing.  It's certainly a step forward.  And we could say long overdue.  But it's great that it's here finally.



And Kaspersky has found operating in Brazil, and it's just sort of located there so far, another rootkit, another Windows rootkit which boasts x64, that is, 64-bit support.  It's a variant of a prior rootkit known as the "Banker Rootkit," which targets online banking access credentials.  Okay, now, this ties into a question that we're going to run across later on.  Of course, I guess everything we talk about ties into everything else.  But this thing leverages a hole in an obsolete version of Java.



So we've talked about the problems with just pretty much having anything on your system that you're not using.  And I have in the past encouraged users, if they don't know they need Java, to remove it.  Sun is doing as good a job as they can of keeping it current.  But they're only able to patch the things they know about.  And it's the things they don't know about that can catch us out.  So if in this case users are not keeping their Java current, but something installed it on their Windows machines in the past, and they do whatever behavior it is, which wasn't made clear in Kaspersky's note, that they visit a website that leverages Java to install this.



The first thing this thing does is it disables Windows User Account Control (UAC) because that just gets in its way.  And that lets it go about its business without being interrupted because that User Account Control, that's pesky, you know.  You don't want that if you're malware.  Then it installs bogus root certificates into the system and modifies the hosts file so that accesses to popular banking websites are redirected to phishing sites operated by the criminals.  Thanks to the fact that this thing installs root certificates in the user's machine, no SSL warnings come up when the user is connected to the wrong system.



The hosts file is like a DNS patch.  Remember that Windows systems, well, actually all UNIX and Internet-connected machines have a hosts file, as do Windows and Macs and so forth, where it looks first, before it does any other DNS lookups.  So they put the domain names of banking sites, the legitimate domain names of banking sites into the hosts file, associating them with the IP address of their malicious server.  When the user puts correctly, like clicks on a valid shortcut that they had set up beforehand, a true and correct URL, their system looks at the hosts file for BofA.com or Brasilia, whatever, gets the wrong IP because it is no longer using DNS.



The hosts file hack intercepts DNS.  Their browser then connects to the malicious IP.  Over SSL, that's the other thing.  The padlock is there.  SSL is shown.  I mean, everything about this looks legitimate because this rootkit has installed a bogus certificate which the malicious server has had its certificates signed by.  So SSL, proper URL in the browser, nothing looks wrong about this, yet you are connected to a malicious site where you're then going to provide your logon credentials.  And basically that allows this rootkit to obtain your banking access credentials by spoofing the proper appearance of the web page.  Nothing that you see looks out of order.



LEO:  I like it that it's called the "Banker Rootkit."



STEVE:  Banker Rootkit, yeah, because it's going to suck out all your money.



LEO:  Now, Bank of America does a SiteKey, for instance.



STEVE:  Yeah, and this defeats that, too.



LEO:  Doesn't help.



STEVE:  Right, because what it does is it turns around and obtains the page, exactly.



LEO:  That's what I always wondered about SiteKey, is like, how it this supposed to help?  If I can see it, a bad guy can see it.



STEVE:  This essentially is a man-in-the-middle attack where, thanks to the fact that your local system has been so deeply compromised with DNS redirection thanks to the hosts file, and bogus root certificates thanks to the fact that this rootkit was able to bypass UAC.  The other thing it does that you just sort of shake your head at is it needs, in order to pull off some of this, it needs to install a kernel driver.  Well, we know that 64-bit systems are protected with PatchGuard that we talked about years ago when Microsoft introduced this in Vista.  So now it ought to be very mature.  Now we're at Windows 7.  And PatchGuard, one of the things it does is absolutely require that drivers be signed.  Except, you know, Leo, that's inconvenient for developers because when they're writing drivers and compiling them, they don't want to have to keep signing them to test them because that's pesky.  So there's a "test mode," which bypasses that requirement.



LEO:  And it's accessible to anybody, of course.



STEVE:  Of course.  And the rootkit says, well, having bypassed the User Account Control because we don't want those pesky little pop-ups to warn the individual that we're modifying their system, we'll turn on test mode so that we don't have to bother with having signed drivers because we don't have any.



LEO:  What a pain.



STEVE:  Yeah.



LEO:  Now, if I have - okay, one more question.  The chatroom is now all atwitter.  I have on my Bank of America accounts and my PayPal account and so forth turned on that cell phone second-factor authentication; right?  So I log in, and it says, okay, send this to your cell phone, and I enter it in.  I guess because it's on my machine, it's still there.  I mean, once I get into BofA, I mean...



STEVE:  They would be able to hijack that session, but they would not be able to hijack successive sessions.



LEO:  They have to do it separately each time, of course.



STEVE:  So that logon they would be able to hijack because the bank would send you the authentication, and you would go, oh, look, I mean, that would almost prove to you that you're talking to your bank because you would get the second factor or third factor, whatever factor it is, challenge, which you would respond to, typing it into the page.  The bad guys would forward that, because they're intercepting your traffic, to the bank.  The bank would be happy, and you'd be able to log on.  They could not, however, reuse your credentials in the future.



And if they were smart enough, and if they're not now, they will be, to recognize that you're using a multifactor authentication,  they would do all their dastardly work right then and there.  And they have a connection with your bank.  So as soon as you've given them credentials access, right then they're able to do what they want to.  And we have seen banking trojans which will empty, which transfer all of the money out of your account prior to you being able to complete the first transaction of the session.  So the bad guys understand this.  The moment they get access, they turn around and send all your money off to Russia or wherever.  And you look at your account, and it's empty.  So they don't even need to come back for further access.  Although that's one of the things this thing apparently does acquire.



LEO:  Does it impersonate your computer, if there's a cookie on my computer that says I'm me?  Because that's another thing banks do.



STEVE:  Oh, absolutely, because remember the cookie goes through the channel.  And these guys get - they're monitoring the channel.  They have full man-in-the-middle activity.  So even if the bank said you have to do special things if you log in from a computer you haven't used before, your computer sends that to the bad guys, who then turn around and send it on as part of - just it's echoing the traffic that your computer sends.  And so here we're looking at the future.  And it's a rootkit, meaning that what that driver has done that they've installed is it's patched the actual API, the low-level operating system function, so that you can't see any of it.  It's removed itself from the directory listings.  And so things that scan your system, which are unable to scan underneath the rootkit, which is an additional layer of difficulty, and rootkits are becoming increasingly aware now of anti-malware and anti-rootkit technology, these things are becoming insidious.  And, I mean, this is a perfect example of, once something like this gets on your system, you've pretty much lost your system.  You just need to start over.



LEO:  And what's the attack vector?



STEVE:  Java.  If you didn't have - I know.  I know.  So you go to some site that is malicious, or that the bad guys have installed using, for example, an SQL injection attack.  So you're just - you're at DSL Reports, because they had a problem recently with SQL injection.  And you're just looking at a forum.  And you trust DSL Reports because it's a good site.  But they've got a problem with their backend server technology.  You browse someone's posting.  Just looking at it in your browser allows this exploit to leverage the fact that you've got a known problem in the version of Java on your system, and the jig is up.



LEO:  Oh, boy.



STEVE:  Yeah, I mean, this sounds like science fiction, but this is what's happening now.



LEO:  Well, there you go.  There you have it.



STEVE:  So I did want to follow up a little bit on - apparently this is just in Brazil.  So it's not widespread yet.  Kaspersky found it.  They got a copy of it.  They reverse-engineered it.  They figured out what it was doing so that I was able to tell our listeners.  But there's just no better reason to keep yourself current, patched, with the things that we talk about, and run with the minimum target profile, which frankly means not having JavaScript on because it's JavaScript that then allows Java.  JavaScript invokes Java in order to do Java applet sorts of things.  So you really, really want to just, where you can, minimize the profile that you're presenting to the target.



Speaking of which, there was a little bit more, we talked about it last week, sort of the questionable conduct of Apple support for their AppleCare customers.  Now we've had a support document apparently leaked from Apple which directs AppleCare workers not to, quote, "confirm or deny" whether a user's Macintosh is infected, and not to attempt to remove or uninstall any infections.  At this point, I mean, I give Apple some leeway because frankly they're late to the game in terms of how you handle these kinds of problems.  They've had the privilege, the benefit for so long of having a small enough market share that they just weren't a target for the attackers.  And their prices were so high that Mom and Dad weren't buying Macs for Junior Hacker, they were getting him a PC.



And as we've talked about before, hackers cannot develop attacks for machines they don't have.  You can only develop attacks for the machines you own.  And increasingly now those are Macs.  Graham Cluley, who is one of the chief technical guys at Sophos - who is, by the way, as we know, Astaro's new parent - he wrote that Mac's increased market share has "Effectively ... reached a tipping point where people are now getting hit with malware on their Macs.  On the support forums you'll see plenty of people who say they were just Googling around when a message popped up and convinced them they had a security problem."  He says, "In terms of Mac malware, Mac Defender is the biggest event to date.  There were earlier viruses and malware, but this one is big."  So the Mac grows up, unfortunately, in a way that we've been discussing Windows' trials and travails for many years now.



LEO:  And they're sitting ducks because Mac users haven't had to deal with this.



STEVE:  And that's a brilliant point, yes, we talked about that last week also.  You're right, Leo, it's that in general there isn't a level of on-guardness on the side of Mac users because, as you say, this hasn't been the way their world has been until now.  So, yeah.  And I was about to say, again, that the problem is all of these systems are porous.  And then my eye falls on the next topic here, under Attacks - speaking of porous.  Under Attacks & Breaches is Sony's continuing trauma.  Now that the target has been painted on them, attackers have just been having a field day.



Sony, I wrote "GMG," but that's GMC in Greece, and also some Asian sites, have been attacked.  In the case of the site in Greece, email address, usernames, passwords, phone numbers, personal information, basically it's another big mistake on Sony's part.  And this is sort of like, I mean, I liken this to the problems that Adobe had with Flash, is for the longest time Adobe was just pouring technology out, and nobody was trying to attack it, so Adobe didn't need to harden it against attack.  And what we have as a consequence is a huge code base that has never been hardened, and it's huge, meaning that it's full of problems.  Similarly, here we have Sony.  Someone says, well, why are there so many problems with them?  Well, the problems have always been there.  But they never needed to harden themselves against attack.



And it's difficult to do.  I mean, it's not the default case.  The default case is something works, and so you put it online.  And, I mean, we're talking about a world now that is different than it's going to be in a decade because the world certainly is quickly coming up to speed.  And frankly, even in the United States, Congress is becoming increasingly concerned that super popular sites like Facebook that have tens, hundreds of millions of users are increasingly posing a threat to their own users.



So NASA similarly confirmed that an FTP server at their Goddard Flight Center had been breached in this last week.  And the same person, a Romanian hacker known as TinKode, T-i-n-K-o-d-e, also breached the security at a European Space Agency network last April, last month.  He refused requests to discuss the details of the network vulnerability he exploited in the NASA intrusion.  Oh, and he said he had not been contacted yet by NASA.  And he said that he had obtained confidential satellite data from that Goddard Space Flight Center FTP server.  So our systems, unfortunately, are not secure enough to withstand really strong scrutiny when bad guys decide that's where they want to focus.



In miscellaneous notes, I wanted to mention that I've been getting great feedback from our recommendation of Mark Russinovich's "Zero Day" novel.  Lots of people have purchased it.  I got feedback quickly from people who bought the eBook version on the Kindle, saying that they were only into the first chapter, and already they couldn't put it down.  So I just wanted to thank them for letting me know and to remind people that it's a good book.



And in our Unintended Consequences sideline, don't know if you saw this, Leo, but it turns out that Bitcoin Miners, that is, those who run high-power machines...



LEO:  Like you.



STEVE:  ...like me, trying to mint bitcoins - I turned mine off because I figured I just got lucky making 50 bitcoins in less than a week.



LEO:  Well, how do you get bitcoins if you don't make them?



STEVE:  Oh, you're able to trade them.  You're able to buy and sell goods using bitcoin as a currency.  But turns out that - initially these were just rumors on some IRC chats.  But there has since been confirmation that bitcoin miners have been subject, in Canada at least, to some house searches.  The Canadian town of Mission, BC has a bylaw on its books that allows the town's Public Safety Inspection Team to search people's homes for what's called "marijuana grow-ups" if they use more than 93 kWh of electricity per day.



So what's happening is, apparently, I guess a marijuana grow-up is you buy a whole huge, like, rooms full of grow lights, like fluorescent grow lights, in order to, like, have this incredibly bright, UV-rich environment to grow your marijuana plants.  And it's detectable by the fact that you have a sudden spike in electricity usage.  Unfortunately, that's the same characteristic as bitcoin miners.



LEO:  Yeah, but you're not going to use 93 kWh a day, are you?



STEVE:  Apparently yes.  I read some of the dialogue from people...



LEO:  People must be having, like, 10 servers running.



STEVE:  No, they have a roomful.



LEO:  Oh, please.



STEVE:  These people have gone nuts.



LEO:  You know how much you're spending to make bitcoin?



STEVE:  And that's just it.  Now, it was the case when we first talked about this that there was no economic - people were arguing that there was a power consumption cost disincentive.  But Leo, I looked today at the leading exchange that is exchanging Bitcoin.  It is north of $7, hovering around $7.50 U.S. per bitcoin.



LEO:  So you made 350 bucks like that.



STEVE:  When you and I talked about it, when we first talked about this, it was like an event when it reached parity with the U.S. dollar, when one bitcoin was one U.S. dollar.  We're now at $7.50.  So that tilts, again, tilts the game in favor of bitcoin mining.  Now, one of the other things that's happened, though, remember that one of the cool things about the bitcoin network is that it is entirely self-regulating.  As this distributed peer-to-peer network sees that the rate of bitcoins being minted by these crazy people with houses full of servers and probably air conditioning, or at least their windows open and fans, it automatically increases the level of difficulty of the problem that must be solved, that is, this hashing problem that must be solved, in order to continuously regulate the rate at which new bitcoins are being minted.



So what this ultimately means is that it's going to be more difficult to mint bitcoins.  And we know that the whole process is asymptotic.  It's slowing down and leveling off over time so that there is only ever going to be, I think it's 21 million.  I don't remember the number now.  But some fixed number of bitcoins ever minted, like within X number of years.  Again, I forgot a lot of these details.  I knew them all...



LEO:  To avoid inflation.



STEVE:  Exactly.  You cannot inflate this.  There is no way to create more bitcoins than the technology was originally set up to create.  Now, I have to mention also here that I got a ton of tweets from our listeners who apparently picked up Jason Calacanis...



LEO:  Oh, yeah.  His link bait.



STEVE:  ...being quoted that "Bitcoin is the worst idea ever."  And I've never watched Jason Calacanis.  So I thought, what?  What is he saying?  Well, I still can't say that I have watched him.  I tried.



LEO:  It's just link bait.  It doesn't even make any sense.  I don't even understand what he's saying.



STEVE:  He's not very impressive.  He's not a techno guy much.  To all the people who tweeted me, I'll say that I wasn't endorsing Bitcoin, I was just - we were Security Now!.  We were being what this podcast is, which is how does this stuff work?  Is the crypto sound?  Does it make sense?  Can it be hacked?  And the answer is this thing is really cool.  It is a robust cyber currency that, as far as I can see, was absolutely done right.  So that's all I'm saying.  Jason must be grumbling that it can be used for terrorists to exchange value, I mean, who knows what it is he was...



LEO:  I don't - I couldn't figure it out, what it was.  I think it's just pure link bait.  Rob Tercek responded, I think, with a pretty good rebuttal.



STEVE:  And frankly, I did watch those guys.  He had two Bitcoin gurus on, and they were really good, articulate, and nice.  And so if anyone's interested, if you want to find that - I don't know even where it was.  I must have just put in "Jason Calacanis Bitcoin" or something.



LEO:  Yeah, you can find it that way.



STEVE:  To find it on YouTube.  So anyway, I don't know what he's talking about, but I'm not evaluating the morality of currency.  The fact is, yes, you can use it for laundering, money laundering.  It's not the money's fault, it's what you do with it.  In the same way that you can use crypto to hide secrets that our states should have access to, but the bad guys use crypto.  Well, it's not crypto's fault, it's the technology.



LEO:  It's just a nongovernmental currency, that's it, right, in a nutshell.



STEVE:  Yes.  And governments have a way of stomping those out.



LEO:  Oh, yeah.



STEVE:  They're not happy with those.  So in the Really Annoying Overreach department, we have the fact that the RIAA, our friends in the entertainment industry - who I was reminded have basically sued every technological advance that has ever been.  I mean, they actually sued the people who made player pianos in the beginning because they felt that it was copyright infringement to have a player piano.  And of course they famously tried to prevent the VCR from being made available to consumers.  So everything that has come out which has ended up benefitting them tremendously, they tried to keep from happening.  Now they have filed a legal action against Box.net, which is one of the leading cloud data storage providers.  They are suing the cloud to get access to what users are storing in the cloud to see whether it violates copyrights.



LEO:  Well, I want to have this case.  This is good.  We should get this court case.



STEVE:  Yes.  There was an article, I'm reading from it, in Techdirt:  "The RIAA really just doesn't know when to give up attacking and to start innovating.  Its latest legal move is to file for a subpoena to get information from cloud storage provider Box.net to see if some people are using the service to store and share unauthorized music."  Then I went back to the source article that Techdirt came from.  And this was in Hollywood Reporter, reported that the Recording Industry Association of America, "fresh off a proclaimed 'milestone' in securing" their $105 million  settlement against LimeWire, has now "set its sights on the burgeoning cloud-computing world.



"On Wednesday, the RIAA filed legal action against Box.net, a service that purports to let its users share, manage and access business content.  The trade group seeks to investigate a couple of the company's users believed to be using the service to infringe sound recordings."  And this goes on.  I have the links in our notes.  So I just wanted to point out that that's another reason why the concept of absolutely never putting anything in the cloud that you don't encrypt first one way or another, what I called "Pre-Egression Encryption," really has got to be the way we deal with cloud computing.



We still have the problem, of course, with cloud computing, of loss of access.  So there are problems with putting things in the cloud.  But people talk about security of the cloud all the time.  And to my way of thinking, that's easily solved.  I mean, you have to deliberately do it.  You have to know what technology you're using and whether in fact it is doing Pre-Egression Encryption or not, that is, is it leaving your system encrypted with a key that the provider does not have so that it doesn't matter whether the RIAA or anybody else serves them with a subpoena, or law enforcement or anybody.  They can say, well, here's the data, but we don't have the key.  Or we used our key, and it still looks like gibberish.  So good luck to you.  Ugh.  Anyway.



Oh, and from the Twitterverse, a listener, Michael Leonard in San Diego, he said, "Just listened to SN, great show.  I think I have a better name for you:  PIE, Pre-Internet Encryption."



LEO:  Instead of PEE.



STEVE:  Which, you know, is urination, unfortunately.



LEO:  PIE.



STEVE:  So I like PIE.  And it's a little broader.  And besides, "egression," it's like, okay, a lot of people don't know what that means, to egress.



LEO:  I like PIE.



STEVE:  I do, too.  PIE, Pre-Internet Encryption.  It's easier, friendlier, and so that's the acronym from now on.



LEO:  Tastier.



STEVE:  They're definitely tastier.  And I did want to share a nice testimonial from Mark Wright in Oregon, a listener and SpinRite user.  He said, "After having SpinRite for almost a year now, and using it on many of my systems, I finally have a wonderful testimonial.  I frequently use SpinRite whenever I have strange problems with my systems.  But until now, I have never actually seen it declare that it had fixed anything.  Even though numerous times SpinRite reported no errors, the systems would then behave themselves from that point on."



Which of course is the case.  We talked about that before.  SpinRite often fixes things working with the drive, but doesn't report an error because it's reporting what it left behind, not what it encountered.  And so it is fixing things, it's just there's no way really for me to say we fixed something because it's sort of the nature of the way it interacts with the drive.  Anyway, he says, "A couple of months ago I gave one of my older PCs to a co-worker who couldn't afford to buy one.  They called last week with that dreaded question:  'My PC isn't working.  Can you fix it?'



"Well, the problem they were having was that Microsoft was now sure that they were using pirated Windows software, and they were getting all the warning pop-ups in XP for that.  On top of it, they couldn't use the web because IE kept hanging and crashing.  Since it was an older box, I decided to run SpinRite, and just let it run overnight.  Well, the next morning, 12 hours later, it was only 5 percent completed and still working on two bad sectors it had found.  I noticed in the data it was working on, it was Microsoft's, and wondered if the failure had munged a file related to software validation.  I decided to just let it run its course.



"About 36 hours later SpinRite had finished testing the drive with a total of about 16 blocks marked bad.  When I booted into the system, I was able to launch IE now, and ran Windows Update.  After installing all the patches and the software validation tool, lo and behold, the errors were all gone.  I got the window message that Microsoft had recertified the box, and all was well with the world again.  Thank you, SpinRite, for saving me the trouble of backing up data and reinstalling everything.  Hopefully the drive will last long enough now for them to afford a new one.  Great product.  Mark in Oregon."  And thank you, Mark Wright.  I really appreciate you sharing that with our listeners.



LEO:  Time for questions and answers.  Are you ready?



STEVE:  You betcha.



LEO:  Well, of course you are.  Why wouldn't you be ready?  The question is, is Leo ready?  Let me get the document up here, and then I can answer the questions.  Where are they?  It says they're in there.  It seems to end at the SpinRite thing.  Is there a second?



STEVE:  Oh, I'm sorry, Leo.  There's two documents.



LEO:  Oh, well, there you go.



STEVE:  They're a separate PDF.



LEO:  Of course they are.  Oh, there it is.  All right, I'm ready.  Sorry about that, Steve.  Sometimes I'm a little slow.  Question #1 comes to us from a listener and programmer.  In fact, I know his name, Jim Hyslop.  He rants against Steve's claim:  Steve, in Episode 256, Q&A #115, your very passionate claim that it is possible to have bug-free software is a major slap in the face to those of us who build software for a living.  Well, I'm going to let you defend yourself, Steve.  But I think that Steve has been very clear about this, and it's not quite as you say.



Sir, you have stained the honor of all professional programmers, and I will have satisfaction.  As the injured party, I hereby challenge you to a thumb wrestling duel to be held at a place and time that is mutually convenient.  All joking aside, though, you exclaimed, "Come on, it's math!"  No, it's not.  Good programming is communication - communicating your intentions to the compiler, and more importantly to other programmers in such a way that there can be no confusion.  That's why, as you pointed out in your very much justified rant against JavaScript, every browser interpreted a particular code snippet in a different way.  Communication is a human activity, and no matter how carefully you choose your words, someone will interpret what you say in a different manner.  I can't count the number of times I've had QA testers file bug reports, only to tell them, "No, that's how it's supposed to work.  Look at this section in the design document."



And of course people make mistakes, too.  Add in the complexities of multithreaded and event-driven programs, you're now talking about programs whose complexity is several orders of magnitude greater than most programs that could be written in assembler.  At that point, proving that a program is bug free is almost an impossible task.  You said, "By definition it's possible for us to have an absolutely bug-free environment and not a bug in any apps," and I want to underscore this, "but it'll never happen."  You said that.  Well, it is also possible to win the lottery five times in a row, but that'll never happen.



Just to be clear, I'm not saying because we can't write bug-free code we should just shrug our shoulders and say "Oh, well," or that we should expect such basic mistakes as not sanitizing inputs, allowing buffer overruns, and so on.  Good software developers should, nay, must always do their best to write code that is as bug free as they know how to make it.  And yes, Steve, I'm afraid that means there will always be bugs, and people will always make mistakes like shutting off a firewall.  Well, in your defense, you've always said that.  It's exactly what you've always said.



STEVE:  [Laughing] First of all, I also build software for a living.



LEO:  You know a little bit about this.



STEVE:  Yeah.  And he says that "add in the complexities of multithreaded and event-driven programs, and you are now talking about programs whose complexity is several orders of magnitude greater than most programs that could be written in assembler."  Well...



LEO:  Not so.



STEVE:  I write all of my programs in assembler.  And they're all multithreaded, and they're all event driven.  So I think what he's saying there is that, if you were in assembler, then you're at the bare metal, so you're not depending upon, for example, the whims of the compiler or the JavaScript interpreter and communication.  I mean, I certainly agree with him that communication is one of the problems.  One of the things I like, for example, about the way the Internet's RFCs, the Requests for Comment, have been structured, is they make a very good point, and they always use all capitals, they say SHALL do this, MUST do this, MAY do this, SHALL NOT, MAY NOT, MUST NOT, you know, they are extremely careful when they're writing these specifications about what behavior they want.



So certainly communication is part of it.  Yet I will, at the same time, I will stand by my statement, which is that there isn't anything analog, from the beginning, of the way our computers work.  And so, while, yes, it's not going to be the case that massively complex systems written by, when you aggregate all the people involved, tens of thousands of people speaking different languages, thinking different things, meaning different things, and then having it all come together, that it's going to work.  In fact, when you phrase it that way, it's amazing these things even boot.  Still, from a theoretical standpoint, and this is really what I was saying in Episode 256, is it can be perfect.  It absolutely can be perfect.  Will it be?  No.  Can it be?  Absolutely.  There's nothing preventing our operating systems and our programs from being perfect.  Yeah, they're not going to be.  But...



LEO:  Yeah, I mean, in your defense, you've always said that we will never get rid of bugs.



STEVE:  Right.



LEO:  So there's a difference between making an assertion that theoretically it is possible, as with anything like this, to make it perfect.  But practically it's impossible.



STEVE:  Correct.



LEO:  Would that be a fair way to describe what you believe?



STEVE:  Yes.  Practically, it's, well, practically it's never going to happen.  It's not impossible, it's never going to happen.  I love Donald Knuth's book on, is it LeX?



LEO:  No, TeX.  TeX, it's called, T-e-X.



STEVE:  Yeah, TeX.



LEO:  He pronounces it "Tech," just to be additionally obscure.



STEVE:  And in the preface he says, "I believe on" - and he quotes a date - "the last bug in this program was found."  And I think he says, "And the person who found it got $2.56.  And I will double the reward for every successive bug that's found, except I don't think there are anymore."



LEO:  Wow.  That's bold.



STEVE:  And I love that.  No, I mean, again, I mean, this is Donald.  I mean, this is the guy - he's an artist of software.



LEO:  That's the name of his book.



STEVE:  And TeX is massive.  I mean, it is a serious piece of code.  And it may very well be perfect.



LEO:  So no one's found another bug?



STEVE:  No.  There probably aren't any.



LEO:  Wow.



STEVE:  I mean, he probably did find them all.  Because he wrote it in a language that he knew, well, actually in a language that he invented, and wrote it very carefully, and, I mean, that's just the way he is.  Now, is that a commercial practicality?  No.  I mean, he would have been fired by any employer.  But he's the person we all bow to as the master of the art and science of computer programming.  Not the economics, not the practical reality.  But boy, he knows what he's doing.  And he wrote a perfect program.



LEO:  Okay.  One.  There's one.  There's been one.  Pat Cho in Sacramento, California wonders about disabling browser plug-ins:  Steve, while I would prefer not to have Java and other - now we agree - Java and other plug-ins installed on my computer, I do need them for a few sites.  Firefox and most other browsers give you the option to disable them, which I do unless I need them for a specific web page.  Am I gaining any additional security by doing this?  Or am I just wasting my time because the malware can somehow access the needed DLL files even if they aren't enabled because they exist on the computer?  If this does provide some additional security, I hope someone develops an extension to make it easier to turn the plug-ins off and on.  Thanks for the great show, and thanks for SpinRite.  I would add it's probably also programmatically possible to tell the browser to turn them back on anyway.



STEVE:  Yeah.  I don't know whether you could do that, at least in Firefox.  So, okay, Pat's question is a good one, as we just saw, we dragged ourselves over the horrible details of a new rootkit which installs itself thanks to having an obsolete version of Java installed on the machine.  And as I mentioned, it is scripting that enables the Java applet to be loaded and run, just as it's scripting that enables Flash applets to load and run.



So it is definitely the case that browsers have control over what technologies, what add-on technologies, plug-in technologies they're hosting and running within their windows; and that it would be possible to do something more granular than NoScript, where, for example, when you load a page, up pops like a menu of the technologies that this page needs in order to go.  And there would be a field for Java, and one for Flash, and one for JavaScript, and PDF rendering, and all the different sorts of plug-ins that you have to enhance your browsing experience.  And then you could decide which of those, based on this site, which of those you wanted to turn on.



That's sort of what we do with NoScript in a less granular fashion because, without scripting, pretty much nothing has a chance to get going, because scripting is the way everything runs.  So it is, though, the case that when you turn scripting on, you are then allowing anything the script wants to do on that domain to do whatever it wants to.  I like the fact that NoScript does give you granularity.  So you can turn scripting on for that first-party site.  But then it shows you a list of all the other third-party contributors to that page and allows you to decide whether you want them on or not.  And frankly, I typically leave them off.  I look at them, and they're typically third-party advertising or tracking, overtly marketing/tracking-related things.  It's like, eh, it'll see if the site works if I only enable first-party scripting.  Actually, that'd be sort of a nice feature to have for the browser.



LEO:  Yeah, no kidding.



STEVE:  Sort of by default.  And I know that Chrome does allow you to disable JavaScript and then enable it selectively.  It'll give you a warning if the page has scripting, and you can then turn it on for that page, though it does turn on for all other parties to that page, as well.  So it gives you some of the feel of what NoScript does over on the Firefox side.



So, yeah, we don't have anything like that.  I could foresee a version of NoScript in the future that gives us more sort of easy popup granularity control over these plug-ins because they are now - they're the source of the problems that we have out on the 'Net.  It's leveraging mistakes and errors in these plug-ins, whether it's the PDF viewer, the Java renderer, the JavaScript itself.  Typically we're seeing less problems with scripting, and it seems to be moving now to the second-level targets which are those plug-ins that the scripting runs.  So I think it's a great idea, Pat.



LEO:  Question #3 comes from Cory in New York City, and his subject is "Police State."  Police State.  Dear Steve, first of all, thanks for your great work on Security Now!.  Now, on to business:  I came across an interestingly disturbing article on Ars Technica yesterday.  That's actually now a little while ago.  Basically, they describe the technology the police can and often do use to grab data from cell phones when they pull someone over.  They can do it with a physical connection, or even Bluetooth.  I was wondering what, if anything, could be done about this.  Would encrypting your phone help?  Certainly a TrueCrypt-style encryption would mean nothing useful could be gotten.  But are such things readily available or computationally feasible on phones?  What about older phones or early generation smartphones like the 3G or the first Droid or the G1?  Surely they would take the biggest computational hit for encryption.  Is there anything else that could be done?  I'm sick and tired of governments assuming that wanting privacy means we're hiding something.  Can't wait to hear your thoughts, and thanks for all your work.  And he includes a picture on here of a cell...



STEVE:  Actually I did a little research.  You see that thing sitting there, this little handheld deal with a little cord going over to the phone.  And in the second picture, over on the right, is a bank of all the different connectors which are available for that thing.  So get a load of this.  While I'm reading this, Leo, Google "Cellebrite UFED."  Again, that's C-e-l-l-e-b-r-i-t-e space UFED.  So an article in TheNewspaper.com for Michigan says "Police Search Cell Phones During Traffic Stops:  ACLU seeks information on Michigan program that allows cops to download information from smartphones belonging to stopped motorists.  The Michigan State Police have a high-tech mobile forensics device that can be used to extract information from cell phones belonging to motorists  stopped for minor traffic violations.  The American Civil Liberties Union (ACLU) of Michigan last Wednesday demanded that state officials stop stonewalling freedom of information requests for information on the program.



ACLU learned that the police had acquired the cell phone scanning devices and in August 2008 filed an official request for records on the program" - that is, the ACLU filed a request - "including logs of how the devices were used.  The state police responded by saying they would provide the information only in return for a payment of $544,680."



LEO:  Why?



STEVE:  "The ACLU found the charge outrageous."  Yeah, no kidding.  Okay.  So I thought, what is going on with this thing?  So this device is called the Cellebrite UFED.  I tracked it down, went to their site, and I'm looking at a picture with this array of cords and the Cellebrite UFED system real-time mobile forensics.  This is a handheld thing.  Says:  "The Cellebrite UFED forensic system is the ultimate standalone mobile forensic device, ready for use out in the field or in the lab.  The UFED system extracts vital information from 95 percent of all cellular phones on the market today, including smartphones and PDA devices - Palm OS, Microsoft, Blackberry, Symbian, iPhone, and Google Android.



"Simple to use, even in the field, with no PC required, the UFED can easily store hundreds of phone books and content items onto an SD card or USB flash drive.  Cellebrite UFED supports all known cellular device interfaces, including serial, USB, infrared, and Bluetooth.  Extractions can then be brought back to the forensic lab for review and verification using the reporting/analysis tool.  Cellebrite" - get this - "works exclusively with most major carriers worldwide, including Verizon Wireless, AT&T, Sprint/Nextel, T-Mobile, Rogers Wireless - Canada, Orange France, and Telstra Australia, as well as 140 others."  Get this.  "This ensures that future devices are supported prior to retail launch."  And then under "Secure Extraction and Complete Content," they say "The UFED allows you to extract a wide variety of data types, including contacts, SMS text messages, deleted text messages, call history, received/dialed/missed, audio, video, pictures and images, ringtones, and phone details including the ESN and the phone number and so forth."



So essentially what we've got is a device designed to hook up to phones, which apparently by design gets in underneath any password protection or encryption that the phones offer because this has been set up in advance with the cell phone providers to make sure this is going to be compatible with every connector shape known so that anyone who gets your cell phone is able to essentially suck it dry.  And the problem is, this is being done by just simple traffic stops in Michigan.



LEO:  Well, that's the issue.  I mean, I don't think they have probable cause to search your cell phone for a traffic stop.



STEVE:  Exactly.



LEO:  But this is similar to a device that they'll use at the phone store to copy your phone numbers off your phone and put it on a new phone.



STEVE:  With your permission.  With your permission.



LEO:  Yeah, with your permission, of course.



STEVE:  As I understand it, the police demand the cell phone of someone who they've pulled over, and then take it back to their car.



LEO:  Problem is they can do it so quickly, you might not even know it's happened.



STEVE:  Right.



LEO:  Let's see a court case based on that evidence, then we'll see what happens.



STEVE:  Yeah, we'll see how it develops.



LEO:  I mean, it's clearly an illegal search and seizure.  But anyway, I'm no attorney.  I mean, you've got to have probable cause.  You can't just take somebody's cell phone, search it on a fishing expedition.  That's clearly illegal.  That's why the ACLU got involved.



STEVE:  Well, the problem is we are certainly seeing an erosion of our civil liberties as a consequence of the Patriot Act, that was just recently renewed for another four years without any debate in Congress.



LEO:  Martin Rojas, Atlanta, Georgia wants to set up a secure email community:  Steve, I love the show, and I've been listening since Episode 30.  I have to say it's made me appreciate what I was learning at my computer science classes and how it applied to the real world.  I love hearing your explanations and propeller hat episodes.  But recently my friends and myself have been trying to figure out how to encrypt email while communicating within our group.  I immediately thought of public key encryption, but I have no idea of any software or how I would go about setting this up for our group.  I know most time topics are theoretical, but I think a lot of people would love a practical way to apply encryption to our mail.  Love the show.  Please keep up the awesome job you and Leo do with the podcast.



STEVE:  And Leo, I turn this one over to you.



LEO:  I guess because I do it.



STEVE:  Because you do it, and I never have.



LEO:  Yeah.  There's a very easy way.  There's a service called Hushmail that Phil Zimmermann of PGP fame worked with.  They use PGP's technology in the background.  They allow you to create encrypted mail to and from friends or anybody else.  It's just like Gmail or any other service, but encryption is one of the features.  Now, that may make you a little nervous because you'd have to trust that they weren't in fact storing the key and all that.  So many of us just put encryption on our own system.  Most email programs allow you to do this.  Outlook does.  Apple's Mail does.  Thunderbird does.



There are kind of two ways to do it.  One is with PGP, Pretty Good Privacy.  So if you search for PGP, or the one I use which is GNU Privacy Guard, or GNU GP, you'll find implementations for many email programs.  That's one way to do it.  The other way - and by the way, both these systems will provide you with digital signing as well as encryption.  Which means you don't necessarily have to encrypt the mail, but it will validate that the mail came from you and no one else.  And that's what I use.  If you get email from me, it's always signed.



The other way to sign and/or encrypt is with certificates.  And you can go to - there are a lot of places you can buy certificates, from all the usual authorities.  Email certificates are usually cheap.  I got a free one recently, it used to be Thawte would do this, and I can't remember who does the free email certificates.  But if you search around, you can find those.  Those are a little bit easier because you install the certificate into your email program, and it handles all the details kind of transparently.



I don't know if Gmail or Yahoo Mail or those other webmails have their own encryption systems.  They might.  But I would suggest Hushmail if you want to do it with webmail.  And I would suggest either GNU Privacy Guard or a certificate-based system, S/MIME is what it's called, Secure MIME, if you want to do it on email.  Did I get that right, Steve?



STEVE:  You did.



LEO:  And I do it, and I like it.  Mostly because I think, if we all encrypt, then that just kind of takes away that thing, well, only crooks encrypt; right?  The implication is, if you didn't have anything to hide, you wouldn't hide it.



STEVE:  Good point.



LEO:  So I hide everything.  Apparently there are browser plug-ins that will allow you to use PGP with web-based mail.  So that's worth looking into.  Oh, I guess it's back to me.  Question #5 from Tim Roesslein in Saint Louis, Missouri.  He wonders about optimum password brute-force strategies.  Steve, I'm listening to Security Now! thanks to a friend of mine, Andy Gibson.  Good job, Andy.  I started from the beginning, and I'm almost up to Episode 100, and I'm excited to find out what the surprise was you promised for that milestone.  I don't even remember anymore.  That was 200 episodes ago.



Every once in a while I'll sprinkle in a more recent episode, just finished listening to 297.  I'm writing this shortly after hearing you say that in terms of password or passphrase vulnerability, the attacker has no knowledge of your character scheme, with Leo adding it might even be foolish for the attacker to make assumptions about it.  We talked about tricks you might use that make it easier for you to remember, theoretically would make it easier to crack, if the attacker knew the trick you were using.



He does say:  But they have to start somewhere, and that got me wondering if brute-force attacks were tiered.  In other words, does a typical brute-force attack in fact start with the assumption of a simple password, perhaps with a limited character set, all lower-case alpha, and then tier up to include upper case, then numerical, ultimately special characters?  The bottom line is, if so, wouldn't you be most secure by only picking from the special character set, as that would be the tail end of any brute-force attempts, thereby making the attacker's job more difficult by simply choosing exclusively from the last upper tier.



P.S.:  You can't very well listen to 100 hundred episodes of Security Now! without eventually buying a copy of SpinRite, so one of those Yabba Dabba Doos was me.  No problem with any of my drives, but it's nice to have a bit-level confirmation they're still in good shape.  Grateful for your and Leo's contribution to the field, Jim Roesslein, Saint Louis.  We're grateful you listen, Tim.



STEVE:  Yeah, and it's a great question.  If I were trying to design a password brute-forcing technology, and we can assume that other attackers understand this problem domain as well as I do, that's exactly how I would tackle the problem.  The first thing you would do is use the readily available dictionaries of most common passwords, the things that people most often do, for example, abc123 is, like, right up at the top of the list.  And then after doing that you'd run through actual dictionary, like the dictionary in the language of the person whose password you're trying to crack, and see if they just use a dictionary word.  And maybe you'd capitalize the first letter, or maybe not, but try it both ways.  But, for example, you wouldn't try all caps because that's harder to type in, sort of less likely that that's what they did.



So again, as Tim suggests, you would sort of ramp up your attack, trying successively less likely things, not overlapping the later tests with the earlier ones, that is, skipping those because you've already - you would have tried them earlier.  But eventually you'd get all the way out to the kind of password that we've talked about often, which just looks like gibberish.  But most people to this day aren't using passwords like that.  They're using something much simpler, which is - unfortunately they're using things that are too simple.



But it certainly is the case, exactly as Tim suggests, that the wise attacker would not just start a-b-c-d-e and then aa-ab-ac-ad-ae and so forth, and go through all of them.  Instead they'd strategize their attack to maximize the chance of hitting on the solution in the minimum time.  That's how I would imagine those attacks would be designed.  And I have seen literature that indicates that's what the bad guys are doing.



LEO:  Well, just as a bad guy can't guess your method, we can't guess or guarantee their method.



STEVE:  Correct.



LEO:  So, I mean, making assumptions about the method works, but only occasionally.  And if you make the wrong assumption, it's going to be worse.



STEVE:  Well, and it's inherent in this that we're talking about a large population of users.  That is, the world's users probably are using dictionary-oriented poor passwords, not the Security Now! listeners.



LEO:  Right.  I think why reduce entropy by limiting it to a certain character set.  Just throw all the entropy you can at it.  Question #6, Levi D. Smith in Oakridge, Tennessee wants his WebGL:  This afternoon I listened to Security Now! #300.  I was concerned about the comments about WebGL.  WebGL is a powerful technology, which provides a standard method for rendering 3D applications in web browsers.  I agree there are security flaws in the initial implementations of the standard, but to blackball the entire WebGL API as a security risk is unfair.  The focus should be placed on fixing the security vulnerabilities of the browser implementations, instead of rejecting the WebGL library in its entirety.  This is actually a debate Steve and I have because basically Steve doesn't like a web page to have any programmability at all.  Right?



STEVE:  [Laughing] That's right, it's dangerous.



LEO:  It's dangerous inherently.  So plaintext is always best from Steve's point of view.  But we live in a world where we're trying to do more and more with our web pages.



STEVE:  Right.  So my answer to Levi is, yes, by all means, we want the implementations of WebGL to get better and stronger with time.  My job here with the podcast is to keep our listeners aware of the threats that are lurking.  And from a standard security standpoint, it is always the case to operate with the minimum attack surface, that is, the fewest number of things that can be attacked.  So I don't think I've ever gone to a WebGL-based site.  There are demo sites and demo pages.  It's like, whoo, look at that.  That's in my browser.  It's like, okay.  But the sites I go to don't use WebGL.



So today, while it's a known attack vector, while we're working on solidifying it and shoring it up, I'm disabling it.  I'm turning it off.  And if I go to a site that'll say, oh, you apparently don't have a WebGL-enabled browser, it's like, oh.  That's my clue, if I care, to turn WebGL on selectively for that site.  It's like a firewall.  Firewalls deliberately restrict the incoming ports.  They don't have - we know that there are 65,535 possible ports.  But the whole reason we have a firewall is to hugely constrict the flow of communications to only the things that we know we want.  And so disabling WebGL is like using a firewall.  It's like saying, I don't know that I need this.  Or it's like disabling Java or JavaScript.  I don't know that I need this, and now I know it's a potential vulnerability.  It's just crazy not to disable it until it stops being a vulnerability, or maybe ever, and turning it on more if WebGL catches on.  Maybe it'll always be just sort of a curio and never be a major factor in the industry, in which case I'll probably just leave it off.



LEO:  All right.



STEVE:  So there.



LEO:  So there.  I have a feeling, because it's HTML5, we're looking at this as a standard.  But we'll see.  I think it's part of HTML5.  Maybe not.  I might be wrong on that.  Question #7, an anonymous listener writes:  Hi, Steve.  I just finished listening to #299, went straight to your page, the JavaScript demo page, GRC.com/r&d/js.htm.  Of course I used NoScript, duh.  So, best "No JavaScript" warning ever.  Oh, I haven't seen it.  What did you do?  What did you do?



STEVE:  [Laughing]



LEO:  I should turn off JavaScript and go there.



STEVE:  I got a kick out of his mentioning that because I had forgotten that I had fun with the warning that the page will give you, or the explanation, if you go to either of my JavaScript pages with JavaScript disabled.  Which of course I would expect our listeners to do, much as this anonymous listener did.  And so I just give people a fun message.  So I thought I would share that with our listeners who may be curious now.  It's GRC.com/r&d/js.htm.



LEO:  I'm trying to figure out how to turn off JavaScript without NoScript in Chrome.  Oh, well.  I'll just have to leave that as an exercise for the viewer.



STEVE:  Yeah.



LEO:  Question #8, Aaron in Bend, Oregon wonders about USB prophylactics.  That's something new.  Steve and Leo, I'm sitting here with my thumb drive stuck deeply inside a friend's infected PC, trying various tools to clean it, including the new MS Safety Scanner you mentioned a couple of episodes ago.  When I am done and want to use this thumb drive again, what is the safest way to use it in my own computer again, after being in an infested PC?  Is it enough to have autorun turned off on my PC?  Then I'd format and copy the programs I use back on it.



I did some Googling tonight and found a couple of free programs that claim to make your USB flash read-only.  Oh, that's interesting.  I also see you can buy flash drives with write-protect switch, like an old floppy disk.  But I don't want to buy another flash drive when I have so many lying around, and I didn't find any software from a source I recognized and trusted.  I also thought of formatting while on the infected PC after I'm done, but I don't trust malware not to hop back on after it's formatted and before I can yank it out.  As always, thank you for the podcast.  Aaron.  Boy, that's a good point.  If you stick something into an infected PC, it might get infected before you could take it out.



STEVE:  It is a fantastic point, and I loved the question.  And it raises - it is a great question.  We know that malware jumps onto thumb drives.  That's how Stuxnet got itself all over the place, and it's a common thing to do because thumb drives are sort of today's version of the floppy that was how the original viruses spread around among PCs, back in the old DOS days.  And thinking about this, the only thing I could suggest that is safe - and he's absolutely right.  I mean, I would have exactly his reaction.  If I was using a thumb drive in a known infected machine, that thumb drive is absolutely suspect from now on.  I mean, I'd be tempted just never to use it again, just drop it off in the next garbage can, because it's scary.



LEO:  Wow.



STEVE:  Well, and because to really fix it you have to jump through some hoops.  I would say boot from one of the boot CDs, like an Ubuntu Linux distro CD, instead of booting from your main regular bootable system.  He asks is it enough to have autorun turned off, and we know it's not because unfortunately there are bugs in the display of the contents which allow malware to gain control just by, like, viewing the contents in Explorer is all it takes.  And that's one of the things that Stuxnet used.  And there are still some unknown exploits that have never been made public that were being leveraged by Stuxnet.  So we still don't know what those are or if they've been fixed.



So I just don't think it's safe.  Unfortunately, we've got too much automation in our systems to allow a USB drive to be plugged in safely.  So I would say boot from a boot CD without your hard drives connected, that is, so that there is nothing writeable on this machine except the thumb drive.  And that's why I'm saying it's sort of impractical.  But frankly that's what I would do.  I would disconnect my hard drives, boot a bootable CD, and then use that to reformat the - and don't just erase the files because you could have hidden files.  Do a full format of that drive in order to clean it.  Or what's easier, I mean, they're so inexpensive these days, I'd just maybe consider this one your malware fixer thumb drive, put it in a red box with the skull and crossbones on it, and use it the next time there's a problem.



LEO:  No, because then you infect the next machine.



STEVE:  Yeah, that's a problem, too.  It really is a good question.



LEO:  Anybody who does this does not use a thumb drive, they use a CD or a DVD with all the tools on it.  I presume the reason he's bringing a thumb drive is because he's got his tools on it.  Just burn a CD.



STEVE:  Very good point.  Simply burn it to a CD.                                               It's a much better solution.



LEO:  Admittedly, a DVD's only 4.7 gigs.  But I think that's enough.



STEVE:  Oh, I would imagine, yeah.



LEO:  How many tools do you have?  If you need two, burn two, or three.  Now, if it's a Netbook, and there's no drive, yeah, I guess you - I mean, it's conceivable there's reasons.  But, boy, that's a good point, I tell you.  You can't trust it now.



STEVE:  Yeah.  Once it's been in a bad drive, I'm not so happy with it.



LEO:  Frank Varela in Boyle Heights, California wants more on - we're going to call it PIE.



STEVE:  Yep.



LEO:  It was PEE, Pre-Egression Encryption.  Now it's Pre-Internet Encryption.  Long-time listener, always fascinated with the topics.  You brought up the term PEE - PIE.  Could you talk a little more about what is Pre-Internet Egression?



STEVE:  Well, I'm not going to spend much time on this because we have already talked about it.  I pulled all these questions together before I put the top of the show stuff together, which brought me into this discussion.  So I'm sure all of our listeners understand, and I'll just make sure that Frank does, that this concept is using technology and, for example, Jungle Disk is an example of PIE, Pre-Internet Encryption, where although it's not the default, you have to manually establish your own encryption key, for example, in Jungle Disk.  And there are some others that people have been tweeting me about that I'm going to try to make time to look at in order to vet them.  Because I'm not really happy with the direction Jungle Disk has taken.  It was once free; now it's not.  It's still inexpensive for in-the-cloud backup.  And I think if you use their Rackspace version, and you use your own key, then you have a PIE-compatible, a Pre-Internet Encryption system.



But the idea is many systems, like Dropbox, are very user-friendly, and they say, oh, we encrypt.  We use SSL 256 encryption so that all of your data is safe as it's coming to us.  The problem is, they encrypt it, and then they decrypt it at the other end.  So they're storing it, or they have it, at least, in an unencrypted state.  In the case of Dropbox, they then would encrypt it for storage.  But they encrypted it for storage.  They have the key that was used.  The only way any of this stuff is safe is if you do the encryption before it goes out on the wire, and that key never leaves your control.  In which case we're using the cloud as a big opaque storage container in the sky.



We still have the problem that it could go offline, and so that's inconvenient.  But at least we have zeroed the problem of security.  This stuff is absolutely secure because it was encrypted before it left us.  And encryption these days is trivial.  It's available.  It's inex- well, it's free, not even inexpensive.  So it does require that you carefully choose and vet the technology you're using.  I ought to mention, this is why I did the same thing with LastPass.  I'm using LastPass.  I understand how it works.  And it is PIE-compatible, Pre-Internet Encryption.  It encrypts everything that we entrust to LastPass.  They never get the key.  Which is why it qualifies.  Dropbox didn't, and they got caught because people now understand that Dropbox employees, or Dropbox when served with a subpoena, could decrypt the data that is in our Dropbox.  And so that's not PIE-compatible.



There are systems that are.  And I believe in the future, as we become more security aware, it'll be something that's made more clear.  It's very frustrating when I look at something that's got a beautiful-looking website, oh, clearly they spent a lot of money on the graphics, but they don't tell me anything about how the thing works.  In which case I can't say, oh, this looks great.  It's like, yeah, look at the pretty buttons, wow.



LEO:  Most people judge the quality of software by the quality of the UI, and that's why, don't you think?



STEVE:  Yeah.



LEO:  Our last question, #10, comes from Kevin Yong in Los Angeles.  He asks about password strength and dictionary attacks:  I'm a fan of Security Now!, had a question about password strength and dictionary attacks.  I know from your past advice that any normal word used as a password can easily be cracked in a dictionary attack.  Does the same hold true for a dictionary word with alphanumeric additions mixed in, such as "eXample05%"? 



Also, what about longer passwords containing a mix of dictionary words with numbers and symbols?  For example, if my 20-plus character password was something like "I Can't Remember," but replaces one space with a tilde, another with an asterisk, and uses a back tick instead of an apostrophe, and an exclamation at the end, and then adds brackets and #8, would it still be vulnerable to a dictionary attack or a similar brute-force hacking?  I guess what he's saying is I can see a dictionary word in there, but it's mixed up, it's muddled up with other stuff.



I'm trying to strike a balance between password strength and memorability and being able to include words or phrases within the mix of alphanumeric characters would make things easier for me.  I don't want to make it easier for hackers, too, though, especially if I use it for something like a LastPass master password.  Thanks for any advice you and Leo might have.



STEVE:  Now, Leo, you would think that we had beaten this thing to death.



LEO:  It's a good question.



STEVE:  It is a good question.



LEO:  Which we've answered.



STEVE:  And I stunned myself Sunday.



LEO:  Uh-oh, what happened?



STEVE:  With a breakthrough in password technology.



LEO:  A breakthrough in password technology?



STEVE:  I know how loony that sounds.  Again, you'd think we had, I mean, in the 302 episodes, we would have - I mean, on our first episodes, way back, 1, 2, and 3 were on passwords.  And we've mentioned passwords over and over and over because, like it or not, they're the way we all authenticate, still, to this day, the majority of us, on the Internet.  I mean, they have...



LEO:  It's probably the most important security thing we deal with day in, day out.



STEVE:  Yes, it is.  And so earlier this year I came up with an idea, and I mentioned a couple weeks ago the Passcode Designer that I was working on.  It's why I taught myself JavaScript.  And you can see it, Leo, if you go to GRC.com/passcodedesigner, all run together, that's passcode, not password, so passcodedesigner.  You can tack on a .htm if you want.  If you don't, my server will.  And it's a little machine that I built over the last month or so, very cute and graphical.  You can click on things.  You can type in the field.  You can play with it.



LEO:  And it's got a big "obsolete" stamp on the front of it.



STEVE:  Yes.  Not only is it obsolete, but GRC's Perfect Passwords are obsolete.



LEO:  What?



STEVE:  Everything is obsolete.  I'm not kidding you.  This is unbelievable what I came up with.  And I've been just, like, reeling from it for a couple days.  Now, when I use my own passwords, I think, boy, is this stupid.  I've got to get this changed to the new scheme.



LEO:  You have a new password scheme.



STEVE:  A whole new, I mean, this is unbelievable.  Next week we're going to change the whole balance between strength and memorability in a way that means we can now type in - we'll be able to enter our WiFi router passwords.  They will be as strong as if you used a Perfect Password from GRC.  But it's vastly simpler.



LEO:  Oh, thank you.  So this is just something you were noodling around, and it came to you in a flash?



STEVE:  Well, what happened was, and this is the nature of research, is I built this machine, this Passcode Designer.  And the concept behind it, I thought, okay, well, we know that, like, if you used all lower case, that's obviously weak.  And so what that says is that having other classes of symbols, like numbers of special characters, is important.  And so I thought, hey, how about if we treated it like a state machine, where we have four different classes.  We have lowercase alpha, uppercase alpha, we have symbols, and we have numbers.  And you want to encourage the user to, in their password, have transitions between those classes.  So on that concept I built this passcode designer, with the goal being to create maximum entropy, minimum length, maximum strength passcodes.



And when I got all done - and it's finished, it's there working.  I realized when I got finished it was wrong.  And I got stalled for a couple weeks because I couldn't figure out what was wrong, but my intuition was, like, itching me, saying, okay, this isn't right.  And I showed it to the folks in the newsgroup.  And a lot of them, you know, we went back and forth and tried to figure out - they didn't quite understand what I meant, and I explained it.  And so I ended up figuring out what was confusing me.  And then on Sunday I got it.  And it's like, oh, my god, this changes everything.  So nothing I've ever said about passwords...



LEO:  I can't wait to listen next week.



STEVE:  Nothing I've ever said about passwords is right.  I mean, nothing everyone - anyone thinks.  I have got some news.  I know it sounds like I've lost my mind.  But I think I can - I'm working on a new page now which is going to lay it all out and explain it and give people something to play with so they can test passwords using this new scheme.  And when you hear it, you're going to go, oh, my god.  Why didn't anyone ever think about this before?



LEO:  Oh, my god.



STEVE:  So Episode 303, next week.



LEO:  I can't wait.  What a tease.  I love it.  Next week.



STEVE:  I'm not kidding.  We're going to change our passwords.  Everyone here who is listening to this is going to change their passwords.



LEO:  I can't wait.



STEVE:  Because I've got something far, far better.



LEO:  And this is based, because we've been kind of having this conversation all along, and then it was stimulated by that article about why something is, "joy is fun" or something was a better password than xyzzz.  And so we've been doing this thinking lately.



STEVE:  Oh, we've talked about entropy.  And, I mean, the Perfect Paper Passwords concept is still a good one, the one-time pad, because that's different, the one-time tokens.  But GRC's Perfect Passwords, that 3,500 people a day go to, it's just junk.  Don't need that anymore.



LEO:  I presume you will be replacing it soon as we do the show.



STEVE:  It's sad because I really liked it.  But it's stupid.



LEO:  You put a lot of work into it.



STEVE:  Wait till you - I've got something so much better.



LEO:  Steve, you're the greatest.  Steve Gibson is at GRC.com.  That's the place to go if you want to know more about SpinRite and all of those other great applications, many of which he gives away.  Actually, SpinRite's the only one he charges for.  GRC, the Gibson Research Corporation.  If you have a question, we do Q&A episodes every other episode.  Go to GRC.com/feedback.  You'll find all of the Security Now! episodes there in 16KB versions for the bandwidth impaired, plus Steve pays to get transcriptions made so you can read along, which is great.  It also makes it easier to search for the content you're looking for.  That's all at GRC.com.  Steve's on Twitter, @SGgrc.  And every week we do this show, Wednesdays at 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC, at live.twit.tv.  So join us live or subscribe at TWiT.tv/sn, and you can get it every week.  You wouldn't want to miss one, that's for sure.  Not next week, anyway.



STEVE:  Not next week.  Not #303.



LEO:  Somebody in the chatroom, Beatmaster is saying, "Could you sell that idea to Sony, please?"  All right.  We'll talk again next time on Security Now!.  Bye bye, Steve.



STEVE:  Thanks, Leo.  We're going to give it away next week.



LEO:  Yay, it's free.  



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#303

DATE:		June 2, 2011

TITLE:		Password Haystacks

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-303.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve shares something of a revelation about the true nature of passwords and why "password entropy" really doesn't matter.  He explains, therefore, how it's possible for passwords to be both memorable AND impossible to crack at the same time.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 303, recorded June 1, 2011:  Password Haystacks.



It's time for Security Now!, the show that covers your security and privacy online, with our guru, our man of the hour, Mr. Steve Gibson of GRC.com, the guy who wrote SpinRite, the world's best hard drive maintenance utility, but also spends a lot of time on security these days and has written many great security tools.  Why are you giggling?



STEVE GIBSON:  Well, first of all, I'm probably more like man of the hour and a half.



LEO:  Or two.  Or two.



STEVE:  Or two in some cases, yes.



LEO:  But today we actually have something that is hotly awaited.  You teased us last week.



STEVE:  Yes.  I did.  I got a lot of tweet feedback from people saying, oh, my - and I got a sense also for the fact that people are listening to the podcast over the course of the week because these tweets were coming in over the course of the week as people would catch up and listen to the podcast and then get to the tease for this week at the end of last week's podcast.  And they would send me a note saying, oh, what have you come up with?



LEO:  What is it?  What is it?  We can't wait a week.



STEVE:  Now I have to wait for a week.  And in some cases, when it came in yesterday, I said, no, you don't, you just have to wait till tomorrow.



LEO:  That's true.  That's true.



STEVE:  That's now today.



LEO:  So do you want to reiterate the tease?  This came to you almost like Archimedes in his bath.



STEVE:  Well, and we should tell everyone, you know what's going on because I thought it would be much more fun for you to grok it and be able to work with me as we explain this.  So what I'll say is, I'll remind people that I had been working on an idea that I called the Passcode Designer, which is up on GRC.  If you go to GRC.com/passcodedesigner.htm, that's actually the reason I learned JavaScript.  I'd never, I mean, I knew it was evil, but I hadn't used it, and I didn't know it because all the stuff I've ever done has been server-side code.



LEO:  It's kind of the ultimate high-level language, and you do low-level languages.



STEVE:  Yeah, and I have to say, Leo, I'm very comfortable with it now.  And I had forgotten, frankly, because I'd been writing assembly language all my life, and I hadn't had any need to mess around with high-level languages - I mean, I do see when I'm over in UNIX land and things, but that's sort of like, okay.  And I have Perl as my scripting language over on UNIX.  But after I've written, like, a chunk of functionality, I'll look at it and think, my, that's only 10 lines.  Look how much I got done in 10 lines.



LEO:  Good morning, Steve.  Time to wake up and smell the coffee.



STEVE:  Hello, yes.  The last person on Earth to understand, gee, those high-level languages are kind of handy.



LEO:  If you know C, JavaScript in structure is very C-like.



STEVE:  It is.  But, oh, boy, I mean...



LEO:  But it's object oriented, which makes a big difference.



STEVE:  Well, yeah.  There's an object-oriented flavor.  But for me mostly it was that its scoping rules are really bad, so that you have to go to real - jump through hoops in order to, like, make sure you don't have a name collision with a module that you might import, somebody else's library.  So it doesn't handle scoping very well.  It's very lax about type conversion.  But now I'm using that to my benefit.



There was a little chunk of code I shared, that I just wrote the other day, with the guys in the newsgroup, where I was deliberately using an array that contained integers in one place - oh, in fact it's on the "haystacks" page we're going to be talking about - where I'm assembling the first line of that chart showing the size of the alphabet.  In one place I'm using the integers and knowing that JavaScript will convert them to strings, so I'm concatenating them onto a string after adding a plus sign.  So it's 26 plus 26 plus 10 plus 33 for a large alphabet.  And then the line right below I'm summing that into an integer, knowing that JavaScript will leave it alone, so that that's where I'm able to say "equals 95."  And so, I mean, once you understand the rules, and you're careful, I mean, one of the things I guess I'm bringing to this is, because I'm coming to it from a lifetime of assembly language programming, my focus is extreme because it's had to be to survive in assembler.



LEO:  That's true.  I mean, you talk about scoping, assembly doesn't really, I mean, scoping rules are a high-level language construct.



STEVE:  Right.  And so anyway, as a consequence, I don't want to set up another tease, but I'm not quite done.  But today we've got round one.



LEO:  Well, if you go to Steve's Passcode Designer site, you'll see the big, boom, "OBSOLETE" stamp right across it.  We saw that last week.  So today we discuss what it was, the insight Steve had that obsoleted the work he'd done previously and how...



STEVE:  Well, and all of the common wisdom that we, into our sixth year, continue to share.  I think it was before we began recording, Leo, that I mentioned that I immediately scrapped my WPA WiFi password because it's obsolete.  And how many times have I mentioned that I can't type it in.  I've never had my iPod Touch on my WiFi because I just can't enter it.  The only way to get it in was a copy and paste because it was 63 characters of nightmare.  Now I've got something I can enter with my eyes closed.  Friends can come over, and I can easily put them on my guest WiFi.  And none of us have any less security.  So it's a realization about what it is about passwords that actually matter, and it's different than what we thought.



LEO:  So I always do this.  I log into my computer to do the show.  Seems like they always do this on Wednesday.  Apple's got an update.  And this is the one we've been waiting for.



STEVE:  Yes, it is.  And it's good news, but unfortunately not as good as we were hoping.  This is Apple responding to the new MacDefender threat that we've talked about for the last couple weeks that has been causing some serious trouble for Apple users and for Apple's own AppleCare folks, who've been getting, like, one out of every two calls they get now is about this MacDefender problem.



Between the time we last spoke about it and now, MacDefender the malware was updated so that it no longer required the social engineering of getting the user to enter their administrator password in order to install itself permanently.  So we're seeing the typical evolution of this cat-and-mouse game.  Apple just yesterday, on May 31, released an update, their third for 2011.  It's tiny, it's only 2.1MB, so it's not one of these multi-hundred megabyte, replace your whole OS updates.  And it fixed three things.



The third, under the title of "Malware Removal," they said, "Impact:  Remove the MacDefender malware if detected."  Which means, whereas they were telling, you know, the official policy at Apple was for the AppleCare employees handling customers not to take responsibility for removing malware, presumably Apple already had in the works that they were going to automate this and just do it for everybody.  So the good news is, if it detects the MacDefender malware, all the variations that Apple knew, it will remove it.



So in the description they said:  "The installation process for this update will search for and remove known variants of the MacDefender malware.  If a known variant was detected and removed, the user will be notified via an alert after the update is installed.  Additional information is available in this Knowledge Base article...."  And if anyone's curious, because there is some more information which is sort of interesting, shows you dialogues and things, it's support.apple.com/kb/HT4651.  And in fact there it says:  "Security Update 2011-003 provides additional protection by checking for the MacDefender malware and its known variants."  It says, "If MacDefender malware is found, the system will quit this malware, delete any persistent files, and correct any modifications made to configuration or login files.  After MacDefender is identified and removed, the message below will be displayed the next time an administrator account logs in."  And it shows you a little pop-up note just indicating that MacDefender had been found and was removed.  So this isn't something which is fighting - MacDefender is not currently fighting Apple tooth and nail to hold on.  However, Ed Bott, who was writing for ZDNet, just wrote that the new Apple antivirus signatures, meaning what was just updated, were bypassed within hours by malware authors.



LEO:  Oh, dear.



STEVE:  And this is an update from this morning at 6:00 a.m.  He said:  "The bad guys have wasted no time.  Hours after Apple released this update and the initial set of definitions, a new variant of MacDefender is already in the wild."



LEO:  See, that's the problem with definition-based antivirus fighting.  They're looking for strings.  So all you have to do is change the strings, and the search engine stops working.



STEVE:  Yes.  We don't have any behavior-based protection yet.  And he said:  "This one has a new name, Mdinstall.pkg, and it has been specifically formulated to skate past Apple's malware-blocking code.  The file has a date and time stamp from last night, 9:24 p.m. Pacific time.  That's less than eight hours after Apple's security update was released.  On a test system using Safari with default settings, it behaved exactly as before, beginning the installation process with no password required.  As PC virus experts know, this cat-and-mouse game can go on indefinitely.  Your move, Apple."



LEO:  That's what's really scary is that it doesn't require an admin password.  That's the thing that worries me.  Now, there's one thing Apple users should absolutely do if they're using Safari.  There's a checkbox right in the General tab of Safari Preferences that they need to uncheck, this "Open safe files after downloading," because it isn't a safe file, and yet Safari will automatically open it.



STEVE:  Because it assumes safe unless it knows otherwise.



LEO:  Right.  So just uncheck that.  It's a little bit of an inconvenience because PDFs don't just pop open.  But they really shouldn't be anyway.



STEVE:  As we well know about PDFs.



LEO:  As we well know.



STEVE:  Over under Windows, yes.  So my thousand-yard read of this is Apple is maturing.  They're developing big market share.  And the hackers now have Macintoshes.  So Apple and the Mac OS move into, unfortunately, where everybody else is, where Android is and Windows is, becoming a high enough profile target that those things about it that have not yet been hardened sufficiently are going to cause some problems.  And it won't take Apple users long to wise up to it.



LEO:  Yeah.  I guess, I mean, but if you don't get a warning, it's more than wising up to it.  This is scary.



STEVE:  Well, and as you and I have said, we have the problem also that, as a class, probably the majority of Apple users who...



LEO:  We don't care.  We haven't had to.



STEVE:  Exactly.  Just don't have their guard up, haven't been afraid to click on things.  I mean, someone sent me, a friend, a good friend sent me a forwarded email with a Windows Media file, WMV, Windows Media Video, that was apparently really, really funny.  And she was saying, this is just fantastic.  It's like, I didn't open it.  I don't know what it was.  I just - I can't.  She didn't create it.  And I saw this whole list of forwards, so she's not a super-sophisticated email user, either, because everyone she'd ever sent it to or received it from was there in this huge list.  It's like, nothing can make me look at that.  I don't care how funny it is.  I just - it's not worth it.  So those are the habits, unfortunately, that all PC users are going to have to be developing.  And Windows users are a little bit ahead of the Mac users at this point.



LEO:  Yeah.  It makes me sad, but it was inevitable, I think.



STEVE:  It really was inevitable, Leo, that Apple is...



LEO:  What's interesting is, this solves the raging debate between people who thought the Apple platform was inherently more secure.  And I was in that camp early on but realized a couple of years ago, after seeing Pwn2Own and all these other security flaws, that it wasn't merely that we were more secure, it was really that the hackers didn't care about the Apple platform.  It's a numbers game.



STEVE:  Our systems - it's a complexity game, from my viewpoint.  These things are so complicated, the targets.  Our computers today have - they're feature rich.  Users want features.  And the fact that Windows keeps selling, despite the fact that it's, I mean, viruses and malware on Windows is old news.  But people still use it.  And for example, look at that period of time when the Mac really was the safer choice.  Windows was still charging ahead full speed.  What this really says is that, okay, people realize there are problems.  This is not all safe.  But, boy, look at all those features.  Or I can run all the software that I want under Windows, whereas I have lesser choice over on the Mac.  And so what do they choose?  Even though there's more security on the Mac traditionally, it didn't slow Windows down at all.  Not detectably, anyway.



LEO:  No.  And the numbers game is that, as Windows users get more sophisticated, and 80 percent of Windows users now run security software, that 20 percent remaining is roughly equal to the penetration of the Mac in the marketplace.  So now the Mac is at parity in terms of insecured users, unsecured users, so of course it's going to attack.  I mean, it's actually, you could just watch that number as it went up to 70 percent, which is now roughly equal to 20 percent unsecured Windows users.  Okay, I guess it's worth the effort.  And hackers are watching it, and they go, yeah, let's do it.  And they've had such success with MacDefender.  I'm sure this is not the last of it.



STEVE:  Well, and fun, too.  I mean, it's a new target.  It's a whole new crop.



LEO:  Let's not ignore the fun factor.



STEVE:  Let's not encourage them.



LEO:  No.



STEVE:  Well, speaking of Windows and malware, I was tipped off by one of my very good participants over in the GRC newsgroups and someone who tweets stuff to me, Simon Zerafa, whom I've mentioned before, that Microsoft has in beta a new rootkit removal tool.  So this is new.  It's connect.microsoft.com/systemsweeper.  And this is brand new from Microsoft.  I haven't seen it mentioned anywhere else.  I immediately sent the news out to everyone following me on Twitter and got a lot of people responding, hey, you know, thanks, didn't know about it, add this to the toolkit.  This is a downloadable ISO image which you can install onto a CD or a USB drive.  And so it boots an OS, a stripped-down Windows, which contains an antimalware and rootkit remover.  And so it's - and it's free.



LEO:  You have to boot into a clean version of the OS because otherwise you won't see the rootkit.



STEVE:  Precisely.  And that's the trick is you have to - it's only by booting something you know is safe that you're then able to look into the target system and see whether there's behavior which is indicating known malware or the presence of a rootkit.  And so Microsoft recognized that they're going to have to take this move, too.  I mean, to their credit, rootkits are among the hardest problems to deal with.  They're like, as we know, the next-generation malware is able to very rigorously hide itself from antimalware that's looking for it.  And the trick is that, if you get in there first and modify the tools that the antimalware, antispyware, antivirus tools use themselves to find the malware, then it's able to hide.  So anyway, this is connect.microsoft.com/systemsweeper.  And I don't have any mature evaluation of it, how it compares to anything else.  Being from Microsoft, I imagine it will always be there now, and it will get better over time, as all of their stuff does.  So...



LEO:  You know, I'm looking at this, it says, "Thank you for contacting Microsoft support."  This is clearly intended to be a site that they would, when you call Microsoft saying I've got a problem, they would direct you to.



STEVE:  Exactly.  It's like, oh, go here and download this and run it.



LEO:  It says, "You've been directed here to download and install the beta version."  So, yeah, it's interesting.  They're not publicizing it.  But if you call Support with a problem, they're going to say, hmm, maybe you need this.



STEVE:  And there are 32- and 64-bit versions.  You can boot either on a given platform.  But you have to choose the one that matches the target computer that you're wanting to scan.  So I would imagine our super-savvy listeners will probably grab one of each and burn some CDs or create some bootable USB drives and have a very cool little bootable OS scanner for systems which they think may have a problem.  And in fact I have already heard from someone who followed my tweet, got the kit, and discovered a rootkit that was unknown to them at the time.



LEO:  Wow.  Oh, man.



STEVE:  Yeah.



LEO:  That's interesting.



STEVE:  So come to think of it, it's probably a good idea just to grab one and do the scan, even though you don't, I mean, that's just it, you don't know you have a rootkit because it's all about hiding itself.



LEO:  And if you're, as I'm sure many of our listeners are, the geek that people call on when they've got problems, and you have some CDs - I know we all do, we have that little bag of CDs we bring around - two CDs, a 32 and a 64 of this, obviously.  Good place to burn that now.



STEVE:  Okay.  So before that happened, the big news of the week that I had at the top of my list was just, like, oh, crap.



LEO:  Oh, gee.



STEVE:  We talked extensively about the breach at RSA and how, despite the fact that they never confirmed it - I immediately took the position, and I think I blogged it, that - oh, I did, I'm sure I did - that, look, the only thing they had to lose that was really important were the keys, the master keys to the kingdom, which were the secret private keys for the RSA SecurID tokens.



Well, now we have two confirmed reports of attacks on government contractors.  The first was Lockheed Martin, who confirms it came under attack using spoofed RSA SecurID tags.  And then next was a company called L-3 Communications that are much less well known, but sort of an off-the-map, high-end government contractor that's providing, like, communication technologies for the wireless attack technologies that our Defense Department has.  So we now - we have confirmation that, in the quotes from these companies, that they detected attacks using compromised SecurID credentials, which is what we know escaped from RSA.  So that's what we expected, and it's now confirmed.



And clearly these companies were lulled into some unfortunately false sense of security, followed RSA's weak recommendations.  I mean, there's nothing you can do except absolutely stop using any of the authentication that might have been compromised.  And RSA wasn't telling people to do that because that would be too horrific.  Instead they were saying, oh, well, make sure that people don't get enough information that would allow them to leverage the fact that they may have compromised credentials, and they only need a username or a password or something other than the SecurID technology, which apparently got loose.  So that was bad advice to follow, and we've got at least two contractors.  I have heard more are under attack, but we don't have confirmation of those.  So that's about as bad as it could get for RSA.



I commented a couple weeks ago when I noted that Netflix was now the No. 1 traffic generator on the Internet.  And you and I have talked about it, Leo.  And what surprised me was that BitTorrent was No. 2.  It was like, wow.  I mean, I just - I wasn't aware that there was so much torrenting going on.  And anyway, I picked up a story that I thought I would share with our listeners because there is a takeaway for our listeners.  And that is that Voltage Pictures, which is the production studio for the film "Hurt Locker," has decided it's going to go after, in court, and sue 24,583 BitTorrent users who illegally, they are alleging, downloaded and presumably watched "Hurt Locker," the movie that they produced.



LEO:  Yeah.  Almost 25, what is it, 20...



STEVE:  Just shy, it's 24,500 BitTorrent users.  They've already filed lawsuits against 5,000 BitTorrent users.  And the demographic breakdown I thought was sort of interesting.  Of the large amount, the 24,583, 10,532, so nearly half, but by far the majority, are Comcast customers.  About half of that amount, 5,239 are Verizon customers.  About half again that amount, 2,699 are Charter.  And about half again that amount, 1,750 are Time Warner customers.  Now, in the case of Verizon and Charter, they are only disclosing the names of either 100 or 150, respectively, customers by IP per month.



So it's going to take a few years for this Voltage Pictures company to get around to everybody.  But they've put a stake in the ground and said, this is what we're going to do.  They have said that they would prefer to reach cash settlements with these customers as opposed to taking each one to court individually.  I don't have any idea, I don't think they want you just to pay the cost of the movie, like the DVD or the Netflix download fee.  They probably want something punitive as well because they have to be wanting to send a message to people who are doing this.  But anyway, I said there was a takeaway.  And I'm not a BitTorrent user, so I can't speak to the practicality of this.  But I wouldn't do this from home.



LEO:  Do it from work?  Don't tell my employees that, please, okay?



STEVE:  Starbucks has free WiFi.  That's where I would go.



LEO:  I wonder.  I bet you they must filter, or they'll want to start filtering.



STEVE:  I don't know, but...



LEO:  I think that the courts have ruled that you're libel for what people do with your network, aren't you?



STEVE:  Yes, we just saw that recently.  There was a very - it was a very - it got a lot of press.  I didn't mention it on the podcast because I thought, okay, well, our users all know about that.  But it was some guy who got in trouble for something his neighbor or some unknown person was doing.  It's like, "Well, it's your IP, sir."  "But I didn't do this."  And they said, "Well, it's your IP."



LEO:  Well, and that, by the way, that's one of the problems with these John Doe warrants that companies like these "Hurt Locker" guys are doing, is that it's IP based.  So, I mean, BitTorrent is not anonymous.  BitTorrent, your IP is known.  And it's IP based.  So what they do is, as you said, they subpoena Comcast and say, well, who is this?  But it could be your neighbor using your open WiFi.



STEVE:  Well, I mean, years ago, I mentioned this years ago, there were - I got five IPs that were attacking GRC, that were on the Cox Cable network and appeared to be in Orange County.  So I thought, well, I wonder what is going on?  I mean, why is GRC being attacked?  And this was back in the old DDoS days.  So I called one of my FBI contacts, and I said, hey, can we find out who these guys are?  Because I'd like to pay them a house call.  And they said, yeah, sure.  So they opened a case, and they asked Cox for the names that corresponded with these IPs.  One was literally down the street.



So the FBI guy called the family, who said, "Hey, we've got someone that we work with would like to come over.  You probably don't know this, but your computer is infected with malware."  And they said, "What?"  And they had a couple teenagers who were - oh, it's funny, too, because when I went into the house, it was summertime, and so they were both there.  They looked like they'd been deboned, these two teenagers.



LEO:  Yeah, that's what teenagers look like.



STEVE:  They were, like, limp on the couch.  They didn't really move at all.



LEO:  I know that well.



STEVE:  But they did...



LEO:  I know that look very well.



STEVE:  They did complain that their computer could no longer burn CDs of illegally obtained music.



LEO:  It's kind of a bummer, man.  Can't burn it, man.



STEVE:  This thing was so infested with junk.  And I can't remember now the current popular music downloading...



LEO:  It's probably LimeWire, or maybe then it was Gnutella.



STEVE:  Before that.  Gnutella, it was Gnutella.  They had Gnutella.  And so I didn't want to get them in trouble.  I didn't want to be, like, the nark that arrived at the front door.  So I was gentle with the family.  And I realized that the kids were going to do what the kids were going to do.  But I explained that this machine would no longer burn CDs because it could barely boot.  It was so busy, there was like a war going on of king of the hill of malware in this machine.  So it was interesting to see a real-world case of that.  But I visited them because I had their IP from the not-very-sophisticated attack that they were doing on GRC's web servers.



LEO:  But they, again, they weren't doing it.  Their machines were.



STEVE:  Exactly.  It was a bot.



LEO:  They probably weren't smart enough to attack you.



STEVE:  They had an IRC-controlled bot.  And it was one of many things that Gnutella had happily brought into their system.  And I guess the mixed blessing was they were able to boot their CD after I cleaned their machine.



LEO:  Man, that Gibson guy, he is rad.  He fixed our machine, dude.



STEVE:  Oh, in fact I do remember the one comment that I got out of one of the teenagers when I was explaining to the parents who were there and concerned that this thing - that their machine had been all infested.  And I said, "Well, yeah, unfortunately, it's because of the file downloading probably," I said.  "I see that there's Gnutella here."  And this one teenager said, "Wait, that's our music.  We need that for our music."



LEO:  Exactly what my kids would say.



STEVE:  And I thought, oh, uh-huh.



LEO:  I give them an allowance to buy music, and they still keep installing LimeWire.  It's like, don't you understand, the music industry would love, love to prosecute me.  Please stop.



STEVE:  And years ago I did speak to the American Bar Association, their technical conference at the ABA, I was the keynote.  And they asked some questions after I was through sort of bringing them up to speed about what was going on in the world.  And they said, well, with all that's going on, how can we, like, keep our machines safe?  Oh, and they said, if we have teenagers?  And I said, okay.  We all, all of you who are parents, and I have had plenty of girlfriends with teenagers, so I'm a virtual parent, we understand that there's no way to control them.  And there was like all these heads nodded out in the audience.  And I said, "Give them their own machine."  I mean, and these were attorneys I was talking to, so they could afford their own machine, even though this was a while ago.  I mean, it's easier to do now than ever.  I mean, they probably all do have their own machine now.



LEO:  Oh, yeah.



STEVE:  But there is no safe way to share a computer with someone who's going to be downloading everything that happens.  And stuff their friends bring over, it's like, oh, you've got to see this, you know.  And it's just going to be a disaster.  But as you said, Leo, it all filters out 

through the one communal IP.  And we now know from this example that IPs are not safe against BitTorrent enforcement.  So as I said to our listeners, don't do it from home.  Go somewhere to get your stuff.



LEO:  There's your advice from Steve Gibson, security expert.  There are legitimate uses, many legitimate uses for BitTorrent, including downloading Linux distros and so forth.



STEVE:  And those you can do from home.



LEO:  You can do those from your home.



STEVE:  In fact, I did get some flak back when I talked about that way with BitTorrent, back through Twitter, people educating me that, just as you said, Leo, there are people who depend upon BitTorrent for, like, nightly downloads and things that are being legitimately shared, not just copies of "Hurt Locker."



LEO:  Yeah.  So, I mean, people, we like to emphasize that because I don't want BitTorrent to go away.  It's not a piracy tool, unlike, let's say, LimeWire or Gnutella or Kazaa, which really were piracy tools.



STEVE:  Yes.  Okay.  So since we last spoke we have a new zero-day problem with all versions of IE under all versions of Windows.  Microsoft is blowing it off because it requires some social engineering.  Unfortunately, IE is still by far the majority browser.  And there's just no doubt to me, in my mind, that we're going to see this escalate fast.  This was demonstrated by a hacker at the recent Hack in a Box conference in Amsterdam.  It requires a drag-and-drop operation, that is, a mechanical, user-end, client-side, pick this up and drop it over.  That's something that's a new feature in HTML5.  So non-HTML5 browsers will be safe.



Microsoft was advised of this problem back toward the end of January.  And so, like, they've had six months.  They believed they had fixed it and claimed it fixed before the release of IE9.  But it's still broken.  And this hacker demonstrated under a state-of-the-art, fully patched IE9 that he was able to do this.  He set up - he has a Facebook account with 180 Facebook friends.  He set up a puzzle.  He created an app which was a puzzle and shared this with his friends.  He collected 80 Facebook session cookies.  And this happens even if you're HTTPS, even if you've got maximum security.  Basically this puzzle was a drag-and-drop puzzle.  And so Facebook people said, oh, how cool, solve the puzzle.  I don't know what it was, rearrange the pieces to form a picture kind of thing.  That's all it takes.



It turns out that Microsoft made a mistake with their security zones.  We talked historically about the IE security zones, where you've got untrusted and trusted and local, and you're able to set the settings differently, depending.  Well, it turns out that, if you leverage HTML5 with drag-and-drop and iFrames and security zones, put it all together, you're able to steal session cookies from users.  Now, Microsoft's official statement is, oh, you know, we're not that worried about it because it requires manual action on the user.  Well, wake up and smell the coffee, Microsoft.



LEO:  Not that much manual action.



STEVE:  No.  And, I mean, Facebook is a made-to-order target for this.  So whereas, for example, Firesheep was stealing session cookies, but would be defeated even in open WiFi if the whole session was kept secure, and of course in response to Firesheep we know that Facebook added persistent HTTPS connections.  This works anyway because it's working at the browser end and sending these session cookies to a malicious site where, the moment someone gets them, they can log in, impersonate the user, and get up to mischief.  And what they'll do is they'll then post other malware on those compromised users' pages and use it as a means of launching further exploits.  So I expect Microsoft will fix this - where are we?  We're June 1st.



LEO:  Second Tuesday's coming up, couple weeks.



STEVE:  Yeah, but they've got the maximum time because we're one day past the first Tuesday.  Or, I mean, if this were yesterday...



LEO:  They got 15 days or something, yeah.



STEVE:  ...it would already be the first Tuesday.  So they've got the maximum time to respond to this, if they could do so within that window.  And, well, they already thought they fixed it with IE9.  So they understand the nature of the problem, and they didn't fix it.  So I'm sure they can tweak it again, and I'll be very surprised if in two podcasts from now we're not talking about the second Tuesday patch of the prior day compared to that podcast.  And like I said, it would be #305 where we say, okay, they fixed the drag-and-drop problem.  But until then, this is going to - people will have fun with it.



LEO:  Tune in at Episode 305.



STEVE:  And we'll see how good our crystal ball is.  Now, I got a lot of interest shown in something that got picked up and spread around about Google speeding up SSL.  Don't know if you saw that, Leo.



LEO:  Yeah, I did.  That was a couple weeks ago.  And I hadn't played with it, I just noted it.  I'd love to know what you think.



STEVE:  Yeah.  There's nothing really to play with.



LEO:  Just wanted to say how easy it was.



STEVE:  Well, they wanted - what they said was that they were getting a 30 percent improvement, and that was big.



LEO:  And it was kind of a hack, though.



STEVE:  Well, not kinda.  It makes me feel uncomfortable.



LEO:  Yeah, yeah.



STEVE:  Because, okay.  We did a podcast on SSL, so anybody who wants to go back and, like, refresh on exactly how SSL works, it's all there for you, both in transcript and in audio form.  I don't know which podcast it was, but it was in the not-too-distant past [SN-195].  We spent the session, the podcast going through exactly how SSL handshakes work, how the protocol works.  One of the things that happens is that you need to guard against man-in-the-middle attacks, that is, for example, when the client says to the server, here's all the security ciphers that I know about, and here's all of the authentication key exchange protocols I'm aware of.  Then the server says - it gets that list, and it selects the one that they will use from among those.



Well, one of the ways to attack SSL, and it has been successful in the past, is to weed out and remove from that list as it goes by, the man in the middle, as it goes by is you remove the strong ones, and you keep the weak ones.  Like one of them is none at all.  Like I'm sorry, I don't do security.  And so you could actually have an SSL connection with no encryption if the server accepted it, and if the server thought that that's the best the client could do was none of the above.



So as a consequence of that, in order to guard against, during this protocol establishment while they're getting themselves synchronized and connected, the very last thing which is exchanged is called the "finished message," which incorporates in it the hash of all the prior messages sent, so that when the recipient of the finished message receives it, they can take a hash of everything they've received previously and make sure that it matches what the sender sent.  And if it didn't, that would indicate either a glitch in the line or, more onerously, somebody fiddled with their traffic as they were exchanging it back and forth.



What Google does with what's called "SSL false start" is they allow the client to send its first traffic prior to receiving the acknowledgment from the server that everything is copacetic.  And so it's pushing the security envelope.  Now, Google understands that.  They understand there are some dangers.  So, for example, in their spec for this, which they have sent to the IETF for consideration - I'll read something from it because it explains what Google understands the problems are.  They said:



"When the client has sent its 'ChangeCipherSpec' and 'Finished' messages, its default behavior following the standard RFC is not to send application data," that is, the stuff we want to have protected, "until it has received the server's 'ChangeCipherSpec' and 'Finished' messages, which completes the handshake.  With the False Start protocol modification, the client MAY send application data earlier (under the new Cipher Spec) if each of the following conditions is satisfied."  And they enumerate:



"The application layer has requested the TLS False Start option.  The symmetric cipher defined by the cipher suite negotiated in this handshake has been whitelisted for use with False Start according to the Security Considerations in Section 6.1."  So what they're saying there is they acknowledge that some ciphers are not safe to use with this.  So this is what makes me think, okay, I hope they got this right.  And going on:



"The key exchange method defined by the cipher suite negotiated in this handshake has [also] been whitelisted for use with False Start, according to the Security Considerations."  And in the case of a handshake with client authentication, where the client is offering a certificate to authenticate who it is, which is not the normal case for anonymous SSL, for example, with users on the Internet talking to servers, "the client certificate type has been whitelisted for use with False Start according to the security considerations."



So it's like, okay, well, how much do we really need to save one handshake exchange during SSL?  How badly do we need that to be 33 percent faster by sending our traffic forward to the server before we've received its confirmation that it agrees with the integrity of the handshake that's been established.  I'm not so sure.  It can be disabled.  They've been playing with this since Chrome v9.  And they've been sort of doing it quietly.  They found that most, with very few exceptions, all the websites around are false start-compatible already.



So this doesn't require any change in the SSL protocol.  This is just sort of fudging it in a way that it really wasn't designed to be fudged.  And the list of non-compliant IP addresses or domains is so small that there is a - that now Chrome contains that list in it.  And so if you're trying, if a client, a user is trying to connect to one of those very few non-false start-compliant sites, then Chrome will know not to do that.  It can be turned off by command-line option, but whoever launches Chrome with a command line?  I guess you could create a shortcut and put that into the command line, build it into the shortcut so it would always be off.  Maybe it'll be an option or a feature through the UI at some point.  But Google thinks this is really wonderful.  I hope it turns out to be, and not have problems.  I mean, it does sound like the kind of thing that hackers are going to just jump on and say, ooh, how can we subvert this?



LEO:  Well, I'm really glad you talked about this because I read it, and I thought, I wonder what - this doesn't seem quite right.



STEVE:  Yeah.  Basically they're jumping the gun.  And it's like - and having to do it in such a way that they recognize the gun might misfire if cipher suites and authentications, key exchange protocols, are not hardened against some potential exploits of this.  So it's like, okay.  I love that Google is pushing themselves for more performance.  We've seen a number of things, like there's a cool add-in that you can get where it really helps web designers see where their servers are slow, what things are slow, how pages are, like, does a forensic analysis of what takes time on a web page.  Google, to their credit because they've got so much eggs in the basket of web-based, in-the-cloud stuff, are really working to improve the performance of our experience, which I'm glad for.  I just - I hope that this doesn't end up biting us in the end.



From the Twitterverse I have a bunch of quick little bits of feedback that are interesting.  Again, my tweeting friend Simon Zerafa told me about QuickJava, which is a plug-in, quickjavaplugin.blogspot.com.  And it does what we were talking about last week for Firefox.  It gives you granular control over Java, JavaScript, and a number of things.  I didn't enumerate them here, but I just wanted to give Simon a thanks and also to tell our listeners that there is something, if you were interested in disabling Java and being able to reenable it easily, the quickjavaplugin.blogspot.com will point you to it for Firefox.



Ben Pike followed up, or @BenPike.  He wrote, "I work for a major wireless retailer.  We use Cellebrite machines to copy customer data from old phones to new phones."  So just as you suspected, Leo, here's someone who heard us talking about that, the problem with the Cellebrite technology which police officers are apparently using when they pull people over to, without a warrant, obtain all of the data in their cell phones.  And as you surmised, some wireless companies like Verizon and AT&T and so forth were using it in order to help their customers move their data over.  And here's someone who's doing that.



@holtcg, whose name is Chris Holt, says, "Most of the Imation brand flash drives have a write-protect switch, perfect for carrying around your suite of antimalware tools."  That's following up on last week's discussion in our Q&A of the problem of, if you were using forensics on a flash drive to help clean bad stuff off of someone's computer, how do you know you didn't infect your own drive?  And so a write-protect switch on the flash drive does that.  And he says that Imation brand flash drives often have them.



Bryan Dort said, "Holy cow, @freshbooks is sending me a cake..."



LEO:  Yay.



STEVE:  "...for just signing up for their service."



LEO:  Yay.  See, I wasn't lying about that.



STEVE:  And @TechJeeper, whose name is Cody Dean, said, "Thanks for the recommendation of the book 'Zero Day' by @markrussinovich.  I'm hooked on this book."



LEO:  I'm seeing that everywhere, by the way.  People really, really do love that book.



STEVE:  Yes.  And then also @jlanners, whose name is Josh, said, "Thanks @sggrc and @leolaporte for 'Zero Day.' It was fantastic."  So he finished the book.  And I also saw someone blogging, saying "Do not read this if you're on a plane."



LEO:  Wait'll you land safely.



STEVE:  And anyone who's read the first chapter knows why you do not want to be reading this book on a plane.  It would, I mean, oh, it would really give you the creeps.



LEO:  They need to do an Audible version.  Dr. Mom's saying I should read the Audible version.  I'd like to.



STEVE:  And, by the way, Mark has tweeted, and I did also get this from Simon Zerafa, Mark has tweeted that there will be a sequel.



LEO:  Oh, good.



STEVE:  So he's going to do a follow-up.



LEO:  Good, good, good.



STEVE:  And lastly, @zkam, he tweeted, "New privacy settings for Firefox."  And this is hot off the press.  This is not something we have yet generally.  This is in their nightly builds that they published.  But there is a new, very tasty-looking feature in Firefox which you get to from the URL bar by putting in "about:permissions."  It is a new UI that shows every site that you have been to.  At the top of the list is a global setting for all sites, where you're able to control on a site-by-site basis whether sites are allowed to store passwords, share location, set cookies, open pop-up windows, and maintain offline storage.  So this is going to give us very granular privacy-related control once it's in the main Firefox build.  At this point it's only available in the nightly build, and apparently it just happened.  So I thank him for the tip and the heads-up.  And we'll be sure and note when that actually goes out into mainstream.



And finally, I have, in my quest for strange but true new stories of SpinRite success, David J. Sauro just sent this, actually the mail is dated June 1st, so today.  He said, "Steve, love the podcast with Leo.  No idea of where I should send this, but I figured your sales department would read it and pass it on," as indeed Sue did.  "Security Now! got me to investigate SpinRite, and it really is magical.  Seriously.  I'm sure there's some other coincidence going on here, but you have to hear this story.



"My machine started misbehaving all over the place.  And I had heard so many success stories about SpinRite fixing everything from bad sectors to gremlins in systems.  When I turned my computer on, it took forever to boot.  But that really isn't out of the ordinary.  After booting Windows, I realized now I had no network connection, and that my machine could not get an IP from my router.  After some testing, I determined that somehow both of my NIC cards" - Network Interface Cards - "had died.  Tried many cables, ports, et cetera.  Nothing worked.  To make sure it was not an OS-specific problem, I booted into my Ubuntu partition and could not get a network connection, either.



"I decided that I had enough and figured, what the hell, I'll run SpinRite.  It was my last resort before buying new NICs.  I let it run at Level 2 for three hours.  SpinRite didn't find or report anything, and I rebooted the machine.  Both of my NICs now work.  How is this possible?  It had to be a symptom of powering down the machine and switching out some internal cables or something.  But in my mind, SpinRite can fix broken NICs.  And I will be telling all of my friends.  Thanks, Steve."



So of course what I think, given his symptoms, is that there were problems with his hard drive.  SpinRite often, as we have said, fixes things without reporting anything, so it's just good to run.  And then so it was probably a combination of things, one of which was problems on his hard drive, and then maybe an intermittent electrical connection with his NIC.  But he got it, and it fixed his machine, so that's all good.  So thanks, David, for the report.



LEO:  Finally, the big reveal.  We're going to finally find out about this new password technique.



STEVE:  Okay.  So I started to create something based on a theory for how to make guaranteed strong passcodes, as I was calling them.  We've talked about we have our - the Perfect Paper Passwords is the one-time password system which I created and is open sourced and published and discussed and actually being used a lot.  I did a Google the other day for Perfect Paper Passwords, and it's all over the place.  And people are actually using it to, you know, they've installed it in servers, and they're using it for their own free one-time password system.



For static passwords, we know that we need passwords which are not obvious, not in dictionaries.  And in fact, Leo, I did some looking through password dictionaries, and I got a big kick out of the fact that your prior old password, you mentioned last week you used to use "monkey."



LEO:  Yeah.  Many moons ago.



STEVE:  That's #14 on the hit parade.



LEO:  So in other words, it would take milliseconds to crack my system.



STEVE:  Yeah, the monkey, yeah, would be on your back.  The #1 most common password is "123456."



LEO:  Oh, boy.  A lot of people use that.



STEVE:  And this is from a 35 million user password database that was hacked and escaped from a site, and so this was a statistical analysis of that.  The word "password" is fourth in line.  And there's some strange things, like "Michael" is on the list.  I don't know, I mean, like, tens of thousands of people use "Michael" as their password.



LEO:  Probably their name.



STEVE:  But, well, no, I don't think so.  But many more people use "monkey."  And if you use your own...



LEO:  That's my name.



STEVE:  That's #14.  Okay.  So we know that passwords have to be - you cannot use passwords which are going to be on a most common list which the hackers have.  Failing that, then they'll use a so-called dictionary attack, literally using a dictionary, often in the language of the user, but sometimes even in foreign languages, the idea being that they want to find your password.  They want to figure out what it is.  So trying passwords is the only thing they can do.  And that's one of the key things, I mean, we all know that.  But it sort of forms one of the pillars of something that I realized that I've never in all these years had occur to me or talked about.  And from the reactions that I've had to this, no one has, either.



So all the attacker can do is check a password and see if it's right or not.  Well, I also created the Perfect Passwords page on GRC which enforces an SSL connection.  It'll only come up under SSL because it's using GRC's very good and fully documented on that page pseudo-gibberish generator, pseudorandom number generator, to present users with various forms of ultra-high entropy text.  63 characters long, for example, you're able to copy and paste and drop it into your - use it as a WPA password or drop it into your WiFi, and those things are super-high entropy and thus very useful for passwords.



LEO:  And completely unmemorable.  And untypeable.



STEVE:  Oh, my god, yeah.  I mean, I've complained many times that my iPod Touch has never been on my own WiFi network because there's no way I can type in my own WPA password.  And so what I realized was that, good as that kind of password is, the kind that the Perfect Passwords page gives you, it is not friendly.  I mean, it's a non-user-friendly password.



The problem has always been that we've assumed that user-friendly passwords, things we could remember, were probably also weak.  And what I hit on is that's not necessarily true.  What matters when, as soon as the attacker has exhausted all of his lists, common password lists, maybe site-specific likely passwords based on the site they're trying to hack, or the specific user.  You don't want to use your own name as a password because that might be your username also, so it might be that the bad guy knows something about you.  Then they'll fall back to dictionaries.  Then maybe dictionaries with a digit tacked on the end because we know now that some password policies require at least one digit.



So users who don't really, I don't know what it is, they don't think it's ever going to happen to them, or they're just trying to create a throwaway login because they want to post a comment on a blog and this dumb site requires them to create an account in order to do so, whatever, they'll just tack a zero on the end, or a one, or whatever their favorite digit is.  So the bad guys who want to get in will try those tricks, too.  So you can imagine there are things that bad guys could do, attackers, to try to figure out something that the lazy user has done.



When all else fails, when all of that fails, they fall back to the traditional, often spoken of, brute-force attack.  Because we understand how it's possible to create every possible password, first you start with A, then B, then C, then D and so forth, up through Z.  Then AA, AB, AC, AD and so forth up to AZ.  Then BA, BB, BC, BD and so on. So it's possible, given time, to run through every possible password.  That's why, in the past, we have chosen passwords that are nonmemorable, these horrors like what you get from the Perfect Passwords page at GRC, because they are just absolutely off the map.  They're ultra-high entropy, and there is no way to guess what they are.



So what this means is that the only vulnerability after your password isn't going to be quickly found in a list is the bad guy trying them all.  Trying them all, since they don't know how long your password is, and the only feedback they get back is yes, that was a match, or no, that wasn't.  One of the most often seen lies told by Hollywood is when the cracker uses some algorithm, and one by one determines what the digits of the combination is.



LEO:  Yeah, yeah, because...



STEVE:  Oh, we've got, exactly, oh, locked in another one.  Exactly.  We all know that isn't the way these things work.  If the bad guy guesses wrong, the only information he gets is, that wasn't it, either, sucker.  Try again.  And the bad guy can try again.



So what occurred to me was that we get our protection from the size of the space that we force the bad guy to search.  The larger the space, that is, the greater the number of combinations of wrong passwords the attacker has to try during a brute-force, try-everything attack, the greater security we have.  So the first thing that says, the most obvious thing that says is longer is better.  The longer it is, the better it is.  Because length is one way we know - for example, say that we just had all lowercase.  Don't do that, but say that we did because it makes the math easy for a second.  Then every time we add one lowercase letter to lengthen our password, we've made it 26 times harder to attack us because, as we all know from the way binary works and even decimal, it's like, if it's easier to think of it in terms of decimal, we just imagine passwords as digits zero through nine.  Every time you add a digit, it's 10 times more of them.  We understand well how that works in decimal.  The same thing works with alphabets and passwords.  So longer clearly extends the password search space.  And since the attacker doesn't, has no feedback as to the length of our particular password, and they're hoping we've done something dumb and used a small one, they start at the low end.  Actually they could only start at the short end because nothing sets the upper end.



Now, if a site had a policy that limited passwords to 16 characters, sure, the attacker could start with a 16-character password and then work their way down.  But they're sort of starting at the hard end, at the deep end of the pool rather than the shallow end.  So attackers who are in a hurry, trying, because there are so many of these, they've got to do the best job they can, they start at the short end.  So long is better.



Okay.  The other thing we know is that making the alphabet as large as possible is also important.  I use the example, for example, of just decimal.  That's, like, the worst you could possible do would be a digits-only password because each character only makes it 10 times stronger.  Whereas, for example, if it was lowercase, each character makes it 26 times stronger because you've got an alphabet of 26.  But if you put in even just one uppercase character, suddenly now that's radically stronger because the alphabet is lowercase 26 plus uppercase 26, which is to say, by putting in an uppercase character, you have made the attacker use brute forcing that includes uppercase.



Now, think about that for a second.  Again, the attacker is going to be as smart as - infinitely smart.  We'll give them that.  They are the smartest password cracker ever born.  So one of the things, one of the other things they know is that 46, I can't remember the exact number, I think it's 46.67 percent of all passwords are all lowercase alphabetic.  That's a true statistic, 46.67 percent, all lowercase alpha.  So the smart password cracker says, well, if he's going to make me brute force because I haven't been able to discover it so far, and if I'm going to have to try all passwords, I'm first going to try all lowercase passwords because the search is much smaller because the alphabet is only 26 characters.  So the bad guy can search some ways out in length using all lowercase.  And 46.67 percent of the time, that's where the unwise password will live.  Even if it's long, it's still going to be there.  So the bad guy's going to try that first before trying any passwords that have uppercase in them, or digits in them, or symbols, special characters like exclamation point, pound sign, so forth.



So the other rule of this, make the search as bad as possible, as hard as possible, in addition to length, which clearly lengthens the search, is you absolutely want to use at least one uppercase, one lowercase, one digit, and one symbol because what you've then done is you've moved your password out of any of the abbreviated searches.  Those will all happen first if the attacker is infinitely smart.  Finally, with all of those having failed out to whatever length this guy was searching, will try - will have to start brute forcing passwords containing one of each type of symbol, which is the last thing the bad guy wants to do.  



Okay.  What hit me like a thunderbolt was the password, and on the page where I've documented this I show a, I think it may have been 23 characters of random gibberish that I did get from my own Perfect Passwords page, I just snipped a chunk out, compared to the password D0g and 21 dots.



LEO:  21 dots?  What kind of password's that?



STEVE:  It's stronger than the first one.



LEO:  Wow.  That's really interesting.



STEVE:  And isn't that cool.  What hit me was entropy doesn't matter.  You have to have some.  You've got to have enough so that you're not, like, just all dots.  That would be bad.



LEO:  What you're really saying is that length trumps entropy.  In a way.



STEVE:  As they always said, size matters, Leo



LEO:  Size matters.



STEVE:  Size does matter.  And, yes, that's exactly right.  Length matters radically more than a password's entropy.  As long as your password is not in a dictionary or in a list, then the only way to attack it is brute force.  And brute force, trying everything, only gets yes or no.  It's either it didn't work or it did.



LEO:  It doesn't give him a clue, unlike the movies, as to what's next.



STEVE:  Yes.  He doesn't know you have 21 dots after the word "D0g."



LEO:  In fact, he might even know you used dots, but he has to know 20 won't work.  22 won't work.



STEVE:  Correct.  It's got to be an exact match.  Now, I am not suggesting...



LEO:  Don't use dots.



STEVE:  ...that people use dots.  Nor am I suggesting that it be as simple as that.  For example, you could put some dots, some somethings in front, some somethings in the middle, some somethings afterwards.  Or, and here's what I would encourage people to do is invent your own scheme.



LEO:  But have a pattern that's memorable, it's okay; right?



STEVE:  Well, and Leo, I immediately changed my WPA WiFi password.  You can imagine, now our listeners can imagine what it kind of looks like, except it doesn't matter if you can imagine what it looks like because there's no way to tell.  The only attack that we know of against WPA is an offline, brute-force attack, trying them all until you get a packet that has clearly been decrypted.



LEO:  So I'm just looking at your brute-force cracker.  And "monkey," in the worst-case scenario, would be cracked at .0000000321 seconds.



STEVE:  Yeah, we should tell our listeners that there is a new service...



LEO:  This is such a good service, I love it.



STEVE:  ...a new page at GRC.  You can find it from the main menu under Services.  I called it "Password Haystacks" because this is all about hiding your needle in a large haystack.  And so what the page does, which is just GRC.com/haystack.htm - but if you leave off the .htm it'll put it on for you - it's a cool little real-time client-side calculator I wrote in JavaScript which you can play with.  You can put passwords of various constructions in.  And what this does is, this is not a password strength meter.  That is, if you put in "monkey," we know that's 14th most common, so that won't survive a second or two.



LEO:  But even with brute force it's pretty quickly...



STEVE:  Even with brute force, it's all lowercase, and it's not very long.



LEO:  But if I add 10 dots, it suddenly becomes centuries, thousands of centuries to crack.



STEVE:  Yes.  Yes.



LEO:  Now, 10 dots, somebody might guess.



STEVE:  Yes.  If dots became popular, bad guys would start trying dots.



LEO:  At first I thought, oh, I'll just put happy faces.  But then I realized that's a little too ordered.



STEVE:  Yeah.  I would be creative, use some, like, maybe how about like start with an open bracket, then a couple dashes, then something.  But the point is, as you said, Leo, you can even take a simple word, a dictionary word will no longer be found if it's padded.  And that's what I call this.  I call this "password padding" because this notion is padding a password that is already good enough makes it unbreakable and leaves it memorable.  You can invent your own padding methodology.  Don't tell anybody.  I mean, so that's one of the weaknesses is somebody could see it and go, wow, that's cool.  But look, one glance at it, and they would be able to memorize it, unlike one of the nightmare high-entropy passwords.



This is actually a low-entropy password, but it exists in a massive search space so it cannot be found within the lifetime of the universe if it's sufficiently long.  And in fact this little Haystack page shows you, makes assumptions, three different types of attack - an online attack, assuming a thousand attempts per second...



LEO:  Which is pretty fast, but still.



STEVE:  Which is, yeah, I wanted to worst-case it.  It's probably more like 10 or maybe 100 if you had multiple, if there wasn't a lockout policy and if you had multiple, like instances all trying to guess the password at the same time.  And then an offline attack is the one we were talking about, for example, with the WPA password, where you get some data of some sort, and you sit there trying to crack it, trying all possible ones.  Or like, for example, we talked about LastPass.  The concern there was that users may have had weak master passwords to protect their LastPass database.



Now we know, because your password is hashed locally, you can use one of these large haystack passwords, or a "padded password," as I call it, to come up with something that is incredibly robust, I mean, cannot be cracked.  You've got to go to GRC.com/haystack and play around with this because, as you saw, Leo, as long as you've got uppercase, lowercase alpha and a symbol, and you'll probably have plenty of symbols because you'll probably pad them with symbols, but you don't have to.  You can also pad them with zeroes, or 10101.  I mean, you want to invent your own thing.  And then you are really safe.  You've got the best of both worlds.



LEO:  Now, I'm going to bring up two possible problems.



STEVE:  Okay.



LEO:  One, and we mentioned this also, remember we talked about that page a couple of - the year-old page where the guy said "Dogs are fun" is better than a random password, and we kind of debunked that.  But one of the things that was a problem in general with this stuff is, if somebody's looking over your shoulder, and they see you going dot dot dot dot dot dot dot or whatever it is, they might be able to guess that pattern.



STEVE:  That's true.



LEO:  More significant, if you use the same pattern on multiple sites, that's a concern, isn't it, because your pattern might be guessed.



STEVE:  Yes.  And it's why I still have one more trick up my sleeve that I mentioned at the top of the show.



LEO:  Of course you do.  Of course you do.



STEVE:  So I would, for example, you wouldn't want to write down what your padding methodology is.  You know what it is.  The point is you can memorize it.  It's easy.  It's something you invented, and you add it to passwords yourself.  But the reason I gave, specifically, the reason I gave the example of WPA and LastPass is there is no way to compromise the password other than by brute force.  That is, it's hashed in your browser, or it's in your router.



But it's exactly as you said, Leo.  If a malicious site, well, for example, wasn't storing hashed passwords, if they were storing the password in plaintext, and if they lost control of their database, as we know happens too often, then a bad guy could see your username, which might be your email address, and a low entropy, although unbreakable by brute force, they'd be looking at the plaintext and go, oh, well, I see how this guy forms his passwords, and then go try to log on as you elsewhere.  So you still need to have a password which is changing from one site to the other.  So our longstanding advice about not reusing passwords on multiple sites stands.  But the idea is you can take any good password and make it great, I mean, make it unbreakable from any kind of offline attack.  And there is no downside to your use with this kind of password with a WPA WiFi or in LastPass, where it's hashing locally.



LEO:  Good point.  I still use SuperGenPass, which is a JavaScript-based hashing algorithm that takes a master password, hashes it with your domain name that you're on, and creates a, I think it's a 10-character password.  But what I've been doing unconsciously is exactly what you suggest here, which is padding it with four more easily memorable digits, in effect a PIN.  So I have a unique password for every site.  I have a recognizable, memorable pattern that I add to.  Those extra four digits give me a 14-digit password that is mixed characters, upper and lower, and numbers.  And it's easy for me to recreate the password.  But even if you knew my SuperGen master password, you wouldn't know that I always add these - well, now you do.  You wouldn't know that I always add these digits to it.



STEVE:  Exactly.



LEO:  So that's the kind of thing you're talking about.



STEVE:  Yes.  Well, yeah.  And with WPA, as far as we know, and it's been looked at very, very closely, there is no attack against it other than brute force.  That is the only attack against WPA.  And so what struck me is that, so long as you're not worried about your scheme getting loose - and there's no way for it to get loose from WPA or LastPass because that's all being done with you locally.  There's some concern if you do this for logins on the 'Net because unfortunately our browsers are not hashing our passwords for us before they leave.  That would be really cool, if sites began hashing locally, and so the remote server never had that.  But that's not the way things work today.  So the downside is the lack of entropy on a long password, that is, a padded password, does, if someone sees it, arranges to see it somehow, it betrays the scheme.  But given that an attacker is only doing brute force, a site is hashing passwords, for example, it buys you a huge amount of strength at very little cost.



LEO:  Do rainbow tables help, or anything like that?



STEVE:  No.  The rainbow tables are useful, for example, up to a certain size.  But again, if you look at GRC.com/haystack - I sound like Dvorak.



LEO:  You do.



STEVE:  If you look at that page, play with it a bit, and you'll see with a deep, what I call a "deep alphabet," meaning at least one of each type of character, so that the brute forcer is forced out of any of the quicker searches, that's an alphabet of 95 characters.  And every, I mean, so every character you add makes it 95 times more difficult.  Which may not sound like a lot, but that's why I actually - I show the exact number, and then I show it as a power of 10.  And then I do the division for the user, dividing by a thousand attacks per second and, what, a hundred billion attacks per second, and a hundred trillion attacks per second.  Now, a hundred billion may seem farfetched, except that I just increased it because there was a page I found, actually it was Simon again who pointed me to it, a security researcher has used AMD GPUs and built a homebrew setup that is cracking passwords at 33 billion per second.



LEO:  Wow.  But, now, they have to have access to the password data in a lump at that point.



STEVE:  Yes, that's got to be an offline password, yes.



LEO:  But that happens.  Looks what happened at the PlayStation Network.  The Sony password database was hacked and downloaded.  And now the attacker has, at their leisure, the time to do this massive brute-force attack.



STEVE:  So a hundred billion passwords per second is only three times what currently exists right now.  And the reason I did the hundred trillion is imagine the NSA, who probably the reason, if there's a graphics card shortage, you know who bought them all.  So I just, I wanted to really worst-case the performance of offline hacking and brute forcing and create a calculator that people could use to give them a real-world sense for how strong this is.  But again, Leo, if it's long, and you force them into a brute force, which any long password will, because by definition that won't be in a table, the only way they can get it is by looking, by trying them all.



LEO:  Ironically, your padding, here's a - I put a random password, a 10-character random password in here which is just numbers, upper and lowercase letters.  2.37 hours in that massive cracking array scenario.  But if I add 123456, that very commonly known password, 1.54 hundred thousand centuries.



STEVE:  Yes.



LEO:  And so even - and you can remember 123456.  The point being that, yes, by itself, that would be a crappy password.  But by adding that to a generated password you're adding a huge amount of security, simply by adding length.



STEVE:  Exactly, even though it's low entropy.



LEO:  It's entropy free.



STEVE:  Length matters.



LEO:  Length matters.  What an interesting thing.  So everybody then - the takeaway from this would be - somebody asked in the chatroom, well, Steve, you should write a program to do this.  No, you don't need a program to do this.  This is the whole point.



STEVE:  Yes, exactly.



LEO:  Everybody should, in their mind, come up with whatever pattern they could remember and they could use, and then just tag that on to everything that you create.



STEVE:  Yeah.



LEO:  And it's simple.  So we're not saying use that pattern as your sole password.  That is important.



STEVE:  Correct.  And so, for example, my WPA password - and I'm so happy, my iPod Touch is now on my WiFi network.



LEO:  Woohoo.



STEVE:  And guests can come over, and I can say, oh, yeah, I mean, I now have a password that I can type in.  It's a miracle.



LEO:  Yay.



STEVE:  And it's just as strong as that nightmare that I used to have.



LEO:  So how did you generate that password?  Did you generate a good, short good password and then tag this pattern that you've invented onto it, or did you not even, I mean, in other words, you still need a base that's unique.  Not for WPA, you don't.



STEVE:  Well, you really don't.



LEO:  Not for WPA, you don't.



STEVE:  Let's say, for example, open bracket, 10 dashes.



LEO:  Right.



STEVE:  And then something and 10 more dashes, and something else and 10 dashes.



LEO:  That's long.



STEVE:  And then close bracket.



LEO:  That's as good as your 64-character password; right?



STEVE:  Oh, absolutely, because even though, I mean, even though WPA accepts 63 characters, it hashes it down to many fewer bits, which means that those are not, all those passwords are not technically unique.  There'll be many collisions within the SHA hash which WPA uses.



LEO:  So you could make your password be bracket dash dash dash password bracket dash dash dash, and that would be...



STEVE:  Or dash dash dash bracket closed bracket, yeah.



LEO:  Yeah.  That would be a nice, long password and easy to remember.  Very little entropy there, but very, very hard to brute force.



STEVE:  Exactly.



LEO:  Yeah, yeah.  Now, will people start searching for patterns once this becomes widely used?



STEVE:  The only thing that could be done - the problem is there is, I'm not going to say infinite number of patterns, but...



LEO:  There's quite a few.



STEVE:  ...people are very clever.  We've also got forward slash, back slash.  We could make little teepees.



LEO:  Right.  But that's why we don't use smileys or any kind of pattern pattern.



STEVE:  Yeah, again, remember, it's got to be exact.  So we have, during this podcast, we have massively expanded what an attacker would have to do before trying everything.  The problem is, it's truly a massive expansion because all we've said is "make it longer."  You could put it in the beginning, in the middle, in the end.  And you can put anything, anything you want in the beginning, the middle, the end.  Or, as I did for my own WPA, put a couple special things spaced out among some other numbers of something else, and just no one's going to find it.  There's just too much uncertainty there.  And the only way to find it is try them all.  And GRC.com/haystack will just show you exactly how many you've created.  And what's surprising is that they do add up so fast.  As you said, Leo, just adding 123456, the most common password in the world, hugely strengthens a password that could otherwise be broken with a massive array in an hour or two.  Now it's trillions of centuries.



LEO:  Yeah, every effective.  Really cool.  And a great insight.  And that's why I love this show.  So if you can't remember the URL, if you go to GRC.com, surely you can remember that, it's in the Services menu, Password Haystacks.  Just go to there.  Actually, while you're there you should browse around.  There's so much great stuff.  There's of course the Security Now! podcast.  And there's 200, I'm sorry, 303 of them now, including 16KB versions for the bandwidth impaired.  Full transcripts, too, for those who like to read.



A lot of people in the chatroom have been asking about passwords in general, and LastPass specifically.  This is a great time to go back in time at that website.  You can read the transcripts of Steve's discussion of LastPass, Steve's discussion of passwords.  And it's just a great resource for learning.  Of course he also offers a lot of other great free tools, including the Haystack.  It's all at GRC.com.  And while you're there, please buy ShieldsUP!.  I mean SpinRite.  Don't buy ShieldsUP!, it's free.  Please buy SpinRite, the world's best hard drive maintenance and recovery utility.  You want this thing.  If you've got a hard drive, you need SpinRite.  And it keeps Steve in quinti venti lattes.



STEVE:  Well, it allows me the opportunity to come up with these kinds of things.



LEO:  Yeah, exactly.



STEVE:  It gives me the chance to think about this.  And I've got one more idea.  I don't know how it's going to work out.  I've got to do some cryptanalysis, believe it or not.  But so, I mean, it doesn't obsolete this.  This is good in the meantime.  But this journey has opened up some other ideas.  So I'm not going to tease everybody.  I don't know when it's going to be.  But we'll have a Q&A next week, and then I'm sure some great content the week after.  But I've got one more thing, I think, up my sleeve.



LEO:  Oh, there's more than one more thing up Steve Gibson's sleeve, I can guarantee you that.  Steve's on Twitter @SGgrc.  You might want to follow him there.  And of course we do the show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern, 1800 UTC at live.twit.tv.  So you can watch us do it live if you want to get the latest, freshest version.  But if you miss it, hey, and I understand, people actually have jobs and things like that, you can always catch it later at TWiT.tv/sn or on Steve's site, GRC.com.  Steve, thanks so much.  This is great.



STEVE:  Thanks, Leo.



LEO:  I'm going to go change all my passwords.



STEVE:  Talk to you next week.



LEO:  See you next time on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#304

DATE:		June 9, 2011

TITLE:		Listener Feedback #119

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-304.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 304, recorded June 8, 2011:  Your questions, Steve's answers, #119.



It's time for Security Now!, the show that covers your security online, and privacy, too.  And here he is, our guru, our leader, our fearless leader Mr. Steve Gibson - actually, he's fearless, but he scares the hell out of me - from GRC.com, the Gibson Research Corporation, creator of SpinRite and a lot of great utilities, and now the king of passwords, too.  Did you get some good reaction on the Haystacks episode last week?



STEVE GIBSON:  Tons of reaction.  I didn't want to make this Q&A all about the reaction to last week's Password Haystacks episode, so it's about 50/50:  some great comments, some things that I sort of forgot to mention that people brought up, some very valid criticism saying, you know, padding's not the same as entropy.  So we've got some good things to cover, and not too much news today, but some interesting news.  So I think overall a great podcast for everybody.



LEO:  I can't wait.  All right, Steve.  Happy IPv6 Day.  What the hell does that mean?



STEVE:  Well, I noted months ago that this date, June 8, would fall on a Wednesday.  And so I thought, hey, cool, we'll actually be talking to each other, we'll be recording a podcast on IPv6 Day.  My biggest disappointment, though, is there's no fancy Google logo for it.



LEO:  Oh, you'd think they'd have a Google...



STEVE:  Oh, there's Google logos for, like, when people discovered navel lint.  I mean...



LEO:  Yeah, and there's nothing here, nothing.



STEVE:  It's just ridiculous.



LEO:  Just a blank old Google.



STEVE:  I went there, and I thought, okay, come on, give us something really cool, like Rube Goldberg plumbing or something.  But no.  We got nothing.



LEO:  And I imagine Google is fairly involved in IPv6 Day.  This is in their interest, isn't it.



STEVE:  They're one of the big people, and Facebook, and Yahoo!, and a number of other big ones.  First of all, it means really nothing for end users.  The idea is for major websites to bring up IPv6 services, sort of as a dry run, sort of as a test.  And the idea is to sort of test the infrastructure, let the engineers see it in use, see if anything happens.  I'll have more news next week when I've been able to aggregate the reactions from what's going on today.  I've seen some indications that some small percentage, like 0.02 percent of the 'Net might have connectivity problems if, as a consequence of this being activated, their traffic happens to go over IPv6 through really no effort of their own except that their infrastructure or the extra structure is using IPv6, and if there are problems.  So...



LEO:  Where would the problem lie?  Is it my router that I'm going to have a problem with?  Is it...



STEVE:  Well, here's the deal.  The entire Internet today is IPv4, which means every single piece of equipment between you and me, Leo, or you sending out this real-time stream, and every single one of the listeners knows IPv4.  That is to say that that's the protocol that wraps the data packets which move from point to point.  Today it is not the case that even the majority of the Internet's plumbing equipment knows IPv6.  Which is to say, for most equipment on the 'Net, if an IPv6 packet came to it, it wouldn't know what to do with it.  It would just ignore it because there's a version that's, I think it's a byte in the IP header that says this is my version.  All of them in the world say "4."  Every packet out there has a 4 in there.  And that's one of the things the router hopefully checks as the data's coming in, it checks to make sure that it's 4.  Well, when packets arrive and it's 6, the router's going to go, huh?  Because, I mean, everything's different, the 128-bit IP, for example...



LEO:  You hope it checks because if it doesn't check it would be worse than "huh."  It would barf; right?



STEVE:  Yeah, and, I mean, we know that the way things are engineered, since everything has always been 4, it might very well be that there is equipment out there that doesn't check.  Which means it might crash, it might stumble, it might hang, it might drop the packet.  But the key is, for it to work, for IPv6 natively to work, every single piece of equipment, and there's a lot of it between any two IPv6 endpoints, has to know IPv6.



Now, there are tunneling solutions where you can chop up bigger IPv6 packets into multiple IPv4, hide them in IPv4 so that the existing infrastructure still works, like if it had to pass through a realm of the Internet that couldn't transit, for whatever reason, or wasn't yet able to, IPv6.  You could have tunneling endpoints that rewrap the incompatible IPv6 in IPv4.  It goes where it needs to go, then it gets unwrapped again.  So, I mean, there are those kinds of kludge-y solutions.  But those are no better than, like, NAT routing that we have because we're running out of IP space.



So ultimately what the goal is, everything will be running IPv6 and still know about IPv4.  But we're an unknown length away from that.  I mean, even companies which have their own IPv6 big monster allocations, their traffic will be converted to IPv4 not very far after it gets out of their facility because that's all the 'Net actually works on today.  It doesn't actually work on IPv6 yet except there are some sites that are, today, on June 8th, giving it a shot, sort of like offering their services there to see how it goes.



LEO:  So you have to request an IPv6 packet.  It won't just spit it out at you.



STEVE:  Well, the way it works is you have - we've talked about TCP/IP stacks.  And every TCP/IP stack for several generations of our operating systems has been IPv6 capable.  So, for example, when you enable IPv6 on XP, and there's like a command you can do to turn it on in XP, when you do that, then it will attempt to issue traffic over IPv6.  And when that fails, as it invariably does today, it falls back to IPv4.  So eventually, when you connect that machine to something that does know about IPv6, then it'll work.  And it'll just sort of work seamlessly.  So Mac OS X has had it for several versions.  I just saw this morning where, like at what point they added it.  It might have been Leopard.  Was that a while ago?



LEO:  Yeah, Leopard.  Now, Snow Leopard's the current.  I bet you they did in Leopard.  That would make sense.



STEVE:  Okay, Leopard, yeah.  And UNIX has had it since 2002.  And Microsoft has been experimenting with it.  You can, like, install an experimental IPv6 stack.  Even as far back as Windows 2000 the Microsoft Research folks had that working.  So it's in all the current operating systems.  But right now there's no way - and if you were to plug two IPv6 machines directly into each other with a crossover cable, they'd happily talk IPv6.  But it's the connectivity problem.  It's all the equipment in between.  Every single piece of it has to be able to handle IPv6 or translate to IPv4, tunnel, and then translate back.



But we're just not there yet.  I mean, we're not even close.  I'm having to fight to get IPv6 service on my T1s.  And it's like I had to go through a big conference call with Level 3 to get it at GRC.  So it's not, like, just happening.  And it won't really be until - it's just like raising the debt ceiling on the U.S.  It won't be until it absolutely has to be done that somebody will say, okay, fine.  And then people will scurry around and...



LEO:  IP chicken, we're playing.  So Dr. Mom asks, in the chatroom, and I'm sure everybody wants to know, is there anything we need to do as end users?



STEVE:  At some point our routers will become an interesting issue.  That is, if cable suppliers need to provide their customers with more IP space because the cable supplier itself is out of IPv4 for its own use, then they would upgrade their cable modems and/or their associated routers.  It's conceivable that at some point an ISP could say, we're discontinuing IPv4 support to you, Customer X, on a certain date.  And it will be a ways out in the future.  In which case Customer X would need to go to Staples or Fry's or Amazon, wherever, and upgrade their router.  Maybe flash the version of the kernel on their router to a new version, that's possible.  But probably just get a new router because the old one's going to be old anyway.  And then that router would be able to understand IPv6 on the public side.



Now, if it passed IPv6 through on the private side, then, finally, all of these machines that have been sitting around, our operating systems, for the last couple years waiting, would suddenly be able to use IPv6.  I mean, it doesn't do anything really more for us.  We'll be talking about it in detail.  It's got some security IPSEC protocol built into the definition rather than being layered on top.  So there are a few nice things about it.  Mostly it's massive address expansion and also has a bunch of features that make routing tables for the Internet, which are already a problem because they're just so fractured and fragmented, it brings a new architecture there that allows the Internet's infrastructure to work a little bit more efficiently.



But what I'm betting is any home router, any SOHO router that people buy will always be offering IPv4 and DHCP so that our older appliances, our operating systems that we've had for the last couple years, will always be able to talk to the router with IPv4, and then it will do the translation to IPv6 to get out onto the public Wide Area Network, on the WAN side.  But this is still years away.



LEO:  There's also been a lot of speculation that what'll happen is that there will be ISP-level NAT translation, and you won't even see it.  Won't even happen.



STEVE:  Precisely.  I wouldn't be at all surprised.



LEO:  I bet you, I mean, that seems like the - nobody's going to - you're going to ask my mom to upgrade her router?  The ISP would get all these calls.



STEVE:  There is mess at every level.  I mean, this is why there's the inertia and the reluctance is everyone's, like, well, if we don't have to do it, we really don't want to.  Maybe it'll just go away.



LEO:  Well, it won't go away.



STEVE:  It's not going to go away.



LEO:  We know that.



STEVE:  Yeah.



LEO:  It's just a question of how we deal with it.



STEVE:  So I rebooted my machine the other day.  I don't remember why.  I don't do it often.  But I got the notice from Adobe that I was getting a new version of Flash, which...



LEO:  That's why you should reboot every day.



STEVE:  ...we've been waiting for.  We talked about how there was a new cross-site scripting vulnerability which was affecting Flash players and how Adobe might as well just give up this notion of quarterly updates.  And so what they did was an out-of-band fix for this zero-day vulnerability that we have been speaking of in the last couple weeks.  Google's Chrome browser got it fast and first, and there is now a new version for Windows, Mac, Linux, Solaris, and Android.  So sort of across the board that's been fixed.  So that's good.



The big news, the other shoe to drop, essentially, on the RSA fiasco from 90 days ago - I looked back at my blog posting, and that was March 17 when I went out on a little bit of a limb, and I said, okay, the only way to read what RSA is not telling us is they lost the keys.  And, I mean, there just isn't any other way to interpret it.  Well, they have 'fessed up.



LEO:  They lost the keys.



STEVE:  They lost the keys.  And we're talking 40 million of them.  And in an open letter to RSA's SecurID customers, the chairman, Art Coviello, said in an interview that RSA, well, he said in an interview separate from the open letter, he said:  "RSA is offering to provide security monitoring or replace SecurID tokens for virtually every customer we have."



LEO:  Every one of them.



STEVE:  Every one.



LEO:  So they really did get compromised.



STEVE:  They did.



LEO:  Wow.



STEVE:  And Fox News also reported that Northrop Grumman was another defense contractor that had been attacked using compromised RSA credentials.  So they have formally admitted that they lost the keys.  And now people are saying, okay, I mean, they're saying what you and I were saying three months ago, why were they on their network?  I mean, why could those have been compromisable?  And the answer is always the same:  convenience.  It's easier.  So that's what we did.  Well, they've certainly learned a lesson the hard way.  And I hope so many other people are paying attention because we don't want everyone to have to learn the lesson the hard way.  Be nice if people could - if CEOs or chairmen of the board could say to their CIOs, hey, tell me how this cannot happen to us.  Prove to me that it cannot happen to us.  So I hope that's happening.



We have early feedback from the really cool new Microsoft Safety Scanner, which remember is the malware and specifically rootkit scanner which you boot and check your systems.  I've seen a number of tweets from people who follow me, mentioning that they had found malware on their machine.  Microsoft reports that it's been downloaded, at the time of this report, which is pretty recent, 420,000 times, and has found and removed malware from 20,000 machines.  Looking at what it was that it found - it provides feedback to them so they're able to get a sense for what it's doing - seven of the top threats that were found to install malware, the malware that this thing found and removed, were Java-based exploits.  Remember, Java, not JavaScript.  I want to make sure - in email that I receive and in tweets that I see, I see that mistake being made all the time.  And so I want to make sure people understand Java is not JavaScript and vice versa.  So these are Java-based exploits, not in this case JavaScript-based.  However, the SANS Institute editor Eugene Schultz made a good comment when SANS was reporting this.  He said, "I believe Microsoft's reported infection rate is too low.  Users who do not have a clue concerning how to secure their systems almost certainly have much higher infection rates."  And the story did say 5 percent.  So he says, "...almost certainly have much higher infection rates."



LEO:  And they ain't running any Microsoft Scanner software.



STEVE:  That's exactly his point.  He says, "These users are not aware of Microsoft's Safety Scanner, let alone of how to download and run this tool; but more sophisticated and security-aware users are.  Microsoft's statistics thus in all likelihood apply almost entirely to the latter group."  So that's a very good point is that, I mean, anyone who's running this is already savvy.  They're listening to this podcast.  They're able to burn bootable CDs or USBs and reboot systems.  This is not your typical user.  So it says something that 5 percent of those users are being caught out by seven out of ten are Java-based exploits and finding rootkits on their machine that were otherwise hidden from them.



LEO:  Although, as we noted, when you go to that site, it says, "You've been sent here by Microsoft Support."  Presumably, of the people sent by Microsoft Support, it's like 90 percent have rootkits.  So that may skew the numbers also.  It's hard, I think you just can't tell from the 5 percent.  It's not meaningful.



STEVE:  Yeah.  I went to docs.google.com an hour ago in order to put these documents up for you, Leo, and it was over HTTPS.  Certificate Patrol, which is the add-on I have mentioned a number of times and have been liking, popped up and said, "Certificate exchanged.  Mostly harmless."  And then in the far right it said docs.google.com.  This is the first time I have received that.  And I was tickled that it did this.



So what this was doing was - this is exactly what it's for.  And so far all it's been doing is popping up every time I go to a site that I haven't visited since I installed Certificate Patrol.  It would give me a dialogue saying, hey, here's a new certificate that I'm in the process of putting into my cache.  And so that's not very informative, although that's how I learned, like, for example, that Facebook is using DigiCert, I think it was.  And I looked at them, and their certificates are far less expensive than VeriSign's.  And if Facebook's using it, good enough for me, too.  So I'll be switching and saving myself a lot of money because I've been using VeriSign from day one.



In this case, Certificate Patrol did what's really cool, which is it noted a change in SSL certificates when I revisited a site that I had already visited.  In this case, I don't know what Google's doing, but the old certificate, that is, the prior one that it had, was only issued 28 days ago, and the new one was issued 13 days ago.  And what's nice is it provides you with a side-by-side display where you're able to see, sort of like allow your eyes to just scan down and see what parts have been changed.



And everything was the same except of course the serial number, which is a hash that's always going to be different.  That was different on the two.  And then some MD5s and other stuff toward the bottom were different.  But and then of course the issue date and the expiration date and how much longer that the certificates have.  And it commented that this certificate was exchanged, even though the prior one wasn't near expiring.  So it does some nice little interpretation for you to sort of help you understand what's going on.



So I just wanted to raise it to our listeners because it's the first time I've had a certificate change, and it works.  And of course what this does is this alerts you to, if there were a man-in-the-middle attack, if your employer or your school district or somebody were changing certificates on you and using a different cert in order to filter your SSL traffic, this would pick it up.  And there's no way you could be fooled because the certificate would change, even if the issued name were the same, for example, if a government was going to play this game, and we talked about a story recently where some governments were trying to use fraudulent certificates, presumably to monitor their citizens, even though they were over SSL connections.  So this prevents that, or at least alerts you that something fishy is going on, and then also helps to interpret what it is.  So it's very cool.



LEO:  Very interesting, yeah.



STEVE:  And this has got to be the best thing I've seen in a long time.  In our Attacks & Breaches section, my subhead was "Endless Sony Breaches."



LEO:  Oh, it just won't stop.



STEVE:  I know.  We're at 13 now, different breaches of Sony.  And my friend on Twitter, Simon Zerafa, sent me a link this morning that's got to be the funniest and best website I've seen.  The URL is hassonybeenhackedthisweek.com.  And, I mean, it's a legitimate website.  And I went there, and there's a big red "Yes" with a frowny face.



LEO:  He probably doesn't have to update this site that often.



STEVE:  Hassonybeenhackedthisweek.com now exists.



LEO:  Then it says "Latest hack," so you can always see when the latest hack is.  That is a hoot.



STEVE:  Yup.  And in fact - isn't that great?  Hassonybeenhackedthisweek.com.  I mean, that's the kind of website you really don't want to have your name in.  But Sony does.  Attack #13 occurred two days ago on June 6th, which was Monday.  And it was Sony's European website for professional broadcasting equipment.  The attacker of the website said that he just used standard injection techniques for SQL - now they're standard, Leo.  They're not even a big deal.  It's like, yeah, yeah.



LEO:  We go get them at the SQL injection store.



STEVE:  Oh, absolutely - in order to access the database where he got information of usernames, plaintext passwords, mobile numbers, and emails for around 120 users - not 35 million, like we've seen recently, but 120 - in another attack Sony had previously experienced.  So apparently there was some overlap.  The person to blame seems to be a Lebanese hacker known by the name of Idahc.  And he is the same one behind the attacks on the Canadian Sony Ericsson site that took place last month, in May.  And he was quoted as saying, "Yeah, I was bored, and I play the game of the year, Hacker vs. Sony."



LEO:  And now this makes me wonder if it's really Sony's fault at this point because now they're really a target.  I mean, it's obviously their fault.  But how many of us targeted by this many hackers would have a similar problem, I guess is the question.



STEVE:  Well, and as I said last week when we were talking about it, it's a matter of hardening.  And hardening is hard.  And Sony obviously had never hardened their sites.  They're learning now.  And again, I hope everyone, I hope the industry is paying attention, and chairmen of the board are saying, I mean, making their CIOs prove to them that they're not responsible.  SQL is a real problem because it mixes commands in with the data, which makes it very easy to produce back-end database-driven websites.  But this is the consequence.



LEO:  Well, if you don't sanitize your inputs.  I mean, which is very - it's a very straightforward, very well-known thing, and this is kind of shocking.  Also sometimes these MySQL injection attacks take advantage of flaws, patched flaws in my SQL, and so you've got to keep MySQL up to date.



STEVE:  And also sometimes many people are using canned packages, which they drop into an existing server, and they customize it.



LEO:  Oh, yeah.  These guys are script kiddies that are hacking this.  This is all stuff that's well known, and these canned packages are wide open.



STEVE:  Yup, exactly.  There was one more site was breached, which was PBS had their site breached.  It caught my eye, I got a kick out of it because PBS themselves said that hackers broke into their website and posted a phony story on the PBS website falsely claiming that deceased rapper Tupac was alive and well and living in New Zealand.



LEO:  Of course he is.



STEVE:  So apparently the group Lulz Security, LulzSec, is believed to have attacked PBS due to them being upset about the WikiLeaks story.  So here again it seems that, well, if you want to attack a site, the site's just there waiting for you to do so.  Crazy.



And I got three little blurbs from the Twitterverse that I want to share.  @andronicus, whose actual name is Andrew Skretvedt - I'm sorry, Andrew.  S-k-r-e-t-v-e-d-t.



LEO:  Skretvedt.



STEVE:  Skretvedt, thank you, Leo.



LEO:  I don't know.  I'm making it up.



STEVE:  He says, "So I'm staring at 26 USD/BTC."  So...



LEO:  No.



STEVE:  ...at the time that he tweeted this, we're now at $26 per bitcoin.



LEO:  No.



STEVE:  He says, "If you're still holding your 50, how does it feel to have $1300 of value?"  He said, "I spent mine back at 35 cents.)"



LEO:  Do you still have your 50?



STEVE:  Yeah.



LEO:  See, the only reason it's inflating at this rate is because people are using it for money laundering.  It has to be.  It has to be.  Right?  How could it possibly be worth $26 a bitcoin?



STEVE:  Well, it's scarce.  It's hard to make them.



LEO:  And it's useless.



STEVE:  You get government employees knocking on your door wondering if you're growing weed.



LEO:  My fingernail clippings are scarce.  It doesn't mean they're worth $26 each.



STEVE:  No, I've got fingernail clippings, too, Leo.



LEO:  But mine are...



STEVE:  Yours are not that scarce.



LEO:  I'm just saying scarcity alone - there's no inherent value.  I'm very puzzled by this.  I think it's money laundering.



STEVE:  It could be scarce and abandoned.  And I've seen some interesting criticism recently, people talking about how this doesn't make economic sense.  I mean, to me, all of these arguments sound a little evangelical, I mean, like they've got a cross to bear.  All I'm talking about, all we did on the podcast was talk about the very cool technology, and I analyzed it from a crypto standpoint.  And it's just bulletproof.  I mean, it was beautifully designed for what it is.  So, yeah.



LEO:  Actually I think this is what's going on.  There's speculation going on because there are some people thinking, yeah, maybe I should buy up some bitcoins because it's possible this will become a nongovernmental currency, a valid nongovernmental currency.  And down the road, as you said, there is a limited number of bitcoin.  This could be a very valuable scarce resource.  It's got to be speculation at this point.



STEVE:  I would agree.  I think it has to be speculative.



LEO:  Crazy.



STEVE:  @muoncapture, whose real name is Michael Boleman in Mobile, Alabama, he said, "Tried the MS Sweeper rootkit detector/removal tool mentioned on last SN episode.  Doesn't work on a TrueCrypted hard drive."  And I meant to bring that up, which is why I wanted to say it now.  Many people have tweeted that fact, that it is not TrueCrypt compatible.  And that's of course true because TrueCrypt, remember, has to boot from the special boot sector that it has, which then enables its boot time encryption and then basically installs a short-term driver to get the OS going at which time the OS takes over with a TrueCrypt driver in the OS in a seamless handoff.



But what that means is, and this of course is why you have TrueCrypt, is to the outside world it's just gibberish.  It's random, literally pseudorandom noise.  So unfortunately, the only way to run it on your system would be to go through the time-intensive process of removing TrueCrypt from the hard drive, then running the scanner on it, and then re-True encrypting it, which I think few people are likely to do.  But I did want to acknowledge all the people that have made the comment that, whoops, this thing won't work if you've got your drive encrypted.  And that's absolutely the case.



LEO:  Hey, here's a...



STEVE:  Go ahead.



LEO:  Just a side note on the Bitcoin story.  Today Senator Charles Schumer of New York and Joe Manchin of West Virginia wrote to Attorney General Eric Holder a letter expressing concerns about Silk Road, which is a bitcoin exchange site, and the use of bitcoins to make purchases there.  The senators have asked the attorney general and the DEA to shut down Bitcoin.



STEVE:  Well, they can't.



LEO:  They can't.



STEVE:  No.



LEO:  This is interesting.  The Senate is now aware of Bitcoin, is a little concerned.



STEVE:  Yeah.



LEO:  What if the government closed the bank accounts associated with Bitcoin?



STEVE:  Well, they can attack the U.S. domestic exchanges.  That they could get because they have a known clear public presence.  They cannot do anything about exchanges offshore, outside the U.S.  And they certainly can't do anything about the network itself.



LEO:  It's a peer-to-peer service.  There's no central place to shut it down.



STEVE:  Right.



LEO:  But they could close the membrane that allows bitcoins to get turned into real currency.



STEVE:  Correct.  Well, they could close it domestically.



LEO:  Locally, right.



STEVE:  So it would just be the U.S. that didn't have access to it.  Or unless we used a non-U.S. provider to do that.  So, yes, technology meets the Senate once again.



LEO:  Although in this case they say they feel it's a drug issue, a drug-laundering issue.



STEVE:  It's just money.  I mean, sure, once upon a time the Internet was only porn.  That's all it had.  Now it's way more than that.  So fortunately the Internet survived the porn stage, just as VHS did and DVD did.  So, I mean, I just don't blame, I never blame the technology.  The technology is neutral.  It's ethically and morally neutral.  It just provides a capability.



LEO:  You're right, yup.



STEVE:  So people will be people.  @xino, who's Joe in Wisconsin, asked, "What was the max range of the portable dog killer?"  Now, there's going to be the return of the portable dog killer.



LEO:  You're going to make one?  You're going to make a new one?



STEVE:  I have to.  I spent a really annoyed afternoon with a friend of mine barbecuing on Sunday with this little yappy dog next door that will not stop.  And Mark has done - he's been so patient with the neighbors.  He texts them, and then they apologize, but they're not at home, and then they come back, and they bring the dog in.  And this has been a year now he's been putting up with this little yappy dog.  Now, many people in response to the portable dog killer story - and if anyone listening to this doesn't know what we're talking about, we're not talking about something that kills dogs.  That's the whimsical name for something I built when I was 16.



LEO:  It does not kill dogs.  It annoys them.



STEVE:  38 years ago.  Yes, it trains them.  It's an acoustical trainer.  So many people have asked for plans for the portable dog killer.  And many people have said, hey, Steve, here's a link to one.  Well, I've purchased, out of curiosity, about six of these things and given them to Mark to try to use.  And they don't work.  They're just useless.  So I will be recreating - this is a background project.  I don't know what the timeline will be.  But I will document it.  I know that it will be based on a 1600-watt tweeter, which ought to do the job.  And probably a piece of tuned PVC piping in order to provide aiming.  And we'll set up a standing wave in the pipe in order to maximize the effect.



LEO:  Oh.  Aiming and amplification, mmm.



STEVE:  And amplification, and directionality.  So it'll be fun...



LEO:  Will you sell this for bitcoin, if people want to buy it?



STEVE:  I'm not going to sell it.  But I'll fully document the project with plans and everything that I went through, and it'll be on the website at some point in the future.



LEO:  You should tweet about that tweeter, I think.



STEVE:  I saw this, and I thought, okay, well, I ought to tell people what's going on, that there will be a return of the portable dog killer.  And anybody who needs a - this is going to be overkill, probably.  But if you're going to make something that's loud, you might as well make it as loud as you can.  So he's got some problems with birds up in the trees, too.  This ought to just blow them right out of the tree, so...



LEO:  Geez Louise.  We're going to have to get the ASPCA to monitor this podcast pretty soon.



STEVE:  And I do have a nice bit of SpinRite feedback from Mark Botner, who wrote on June 7th, so just yesterday.  He said, "Dear Steve, a co-worker and friend of mine recently told me about Security Now! Episode 291, which is all about the Stuxnet worm.  As I listened to more episodes of Security Now!, I figured out that you were indeed the inventor of the Gibson Light Pen, which I fondly recall from my early days of learning to program computers."



He said, "Also as I listened to Security Now! I became curious about SpinRite because I frequently troubleshoot, diagnose, and repair PCs for my family, extended family, and friends.  I did not purchase SpinRite immediately but planned to use it the next time I had a problem with a hard disk.  Well, as luck would have, shortly after listening to Episode 291 the hard disk in my teenage son's PC started making a strange noise, and the system ran very slowly.  Normally I just replace disks at the first instant they start acting unexpectedly because that's usually an early indicator of imminent failure.  This time I purchased SpinRite instead and ran it on my son's system in Level 4 mode.



"SpinRite reported no problems, but the system has worked perfectly ever since, and I have been saved the cost of purchasing a new drive.  By my calculations, SpinRite has now paid for itself and is essentially free for all my future use.  Thanks for a great product.  Mark Botner, Little Rock, Arkansas."  And he says, "P.S.:  I'm now listening to all of the Security Now! podcasts, starting with Episode #1, and am currently up to 64.  They are fantastic."  So thank you very much, Mark.



LEO:  Awesome.  All right, Steve.  I've got questions for you.  Are you ready?



STEVE:  You betcha.



LEO:  Number one comes from Shaul in Israel, a third-year geography student at Ben-Gurion University, and an avid Ubuntu user.  He says:  Steve, I just watched the last Security Now!.  In the next show, can you please talk about how the new quantum computing will affect cryptography and passwords?  I think you got this one from Twitter because he's got all the hash tags in it.



STEVE:  Yup, he tweeted this.  And I thought, okay, how can I best describe the problem that quantum computing will represent to cryptography?  And the analogy that first popped into my mind was it'll be very similar to what will happen to bank vaults when we have teleportation.



LEO:  [Laughing] You're right, Steve.  That could be a problem.  Beam me in, Scotty.



STEVE:  Yes.



LEO:  So what you're saying, I think, is that teleportation and quantum computing are equally likely in our future.



STEVE:  Exactly.  That's why the analogy works on so many levels.  Teleportation, of course, completely destroys the utility of bank vaults.  And Fort Knox would be...



LEO:  However, highly unlikely.



STEVE:  Fort Knox would be in trouble, yes.  And it's extremely unlikely to happen in any time soon.



LEO:  So you're skeptical of the claims people have made for quantum computing.



STEVE:  Okay.  Here's why.  The way a true quantum computer would function, if anyone knew how to make it, and if it was of sufficient complexity to be a threat to crypto, is it would instantly be able to instantly try every possible key.  That's what a quantum computer does.



LEO:  Oh.



STEVE:  It tries all of them at once.



LEO:  It's massively parallel.



STEVE:  It's the end of crypto as we know it.  It's back to smoke signals.



LEO:  So just as a recap, of course everybody's listened to your fantastic explanation of crypto going back way back when to early episodes.  But modern crypto relies on the difficulty of factoring large primes.



STEVE:  Yes.  And so there are a number of ways a quantum computer could end crypto as we know it.  One is that it could simply say, oh, here's the factor of this big prime.  One of the ways that crypto works is that, for example, public key crypto relies on that we don't have, no matter, I mean, we've tried and tried and tried and tried, all the best minds in the world have tried, the math guys, to come up with a way of determining what two factors are of a really big prime, and they can't.  Or, I mean, what two prime factors are of a large composite, basically to perform a prime factorization.  And there's just no solution for it that we've found.



Presumably, a quantum computer, that's one of the first things you ask it, is when you hatch it or grow it or whatever you do, is do this.  The other possibility is that you could set up a problem with any kind of a key where it's literally able to brute force the key instantly.  It would try all bit combinations at once.  That's what a quantum computer can do.  So it's the end of life as we, well, crypto life as we know it.  And again, we're nowhere near it happening.  It needs to have a level of complexity that can handle that.  And it's purely theoretical at this point in the first place.  And when we start having them, they won't be able to be that complex.  And in order to be complex enough, the challenge just scales exponentially. 



LEO:  You're basically saying it's as likely as an Einstein-Rosen bridge from here to Mars.



STEVE:  Yeah.  It's not something that we need to worry about today.  And we'll have plenty of notice.



LEO:  It seems to me, maybe I'm wrong, it's like cold fusion.  There are people who claim to have kind of done this or something like it.  Or is that not the case?  Is it purely speculative?



STEVE:  Well, it's absolutely in the lab, where you've got to wear goggles.  And there's cool, like, smoke moving around the floor.  And you're in a university where you don't pay your own bills.  And, I mean, it's way out.  And they're able to say, oh, look...



LEO:  There's this company in, I seem to remember, in Vancouver that claims to have made one.  I remember, you know, people, I was doing this TV show up there, said, oh, we've got to interview him.  And I had the same reaction, I said, well, no, we don't.  They say they've sold one to Lockheed Martin.



STEVE:  As long as they don't give one to the NSA, we're fine.



LEO:  Well, I'm sure the Lockheed Martin is just a front for the NSA.



STEVE:  They sold one to Lockheed Martin.  Which may be the reason that they were cracked with RSA SecurID.  Actually Lockheed Martin wouldn't need to have SecurID.  They'd just crack it instantly.



LEO:  Hmm.  Moving right along to Question #2.  Daniel Summers, also from a Twitter question, @DanJSum in Albuquerque, New Mexico:  Your "hash on the client" comment got me thinking.  Is there a good way to have secret salt on the client?  Would secret matter?  You'd better untwist this tweet.



STEVE:  Yeah.  I made just an offhand comment, threw it out there at one point last week, saying that, if when we're logging into websites, the website we're logging into were to locally hash our password, then all of these problems that we've been discussing disappear.  That is, the client, the browser, would hash it, turning whatever we use, I mean, it could be "Hi Mom."  Actually that's probably a bad example.  But, I mean, it could be something very simple.  The browser would hash it so that only the hash would go over the line, the wire, over to the server.  So the plaintext hash, the plaintext password would never be available to be stolen and so easily reused elsewhere, which is what we've been seeing.  And we're complaining that, like, Sony apparently never hashed a password in its life.  Sony just stores them all in plaintext.  All the ones that get out are in plaintext.



LEO:  I think they said they hashed them.  Didn't they say they hashed them?



STEVE:  Well, I mean, hackers are posting plaintext passwords from Sony.



LEO:  If it's an unsalted hash, can you solve it with rainbow tables?



STEVE:  Well, you can solve it with a rainbow table if the hash is up to a certain size.  And I think I've seen where at, like, six, or maybe seven characters - because remember, as my own Haystacks page shows, if you're solving for a large character set, the number of possible combinations goes up very fast.  And that means the rainbow table size goes up very fast.  The whole point of a rainbow table is that it's a sorted list of all the hashes that came out of putting things in.  Which means you've got to store them somewhere.  And yes, mass storage is coming down in price.  But, I mean, we're talking escalation.  Add one character, and now you need 95 times as much storage as you had before.



LEO:  So it's straightforward, trivial, and should have been done to hash it sufficiently so that you couldn't crack it.



STEVE:  Yes.  I think that what we're seeing is, this is another symptom of us still being in the wild frontier stage of the Internet, where anyone is storing a non-hashed password.  And I wouldn't be at all surprised, with JavaScript as prevalent as it is now, I mean, it's virtually ubiquitous, that it's a great idea to hash the password in the client so that it's always obscured.  So the user sees something friendly, and before it goes anywhere it's turned into something that looks like pure gibberish, all high entropy, and then that's what gets sent to the server.



LEO:  Sergey Romanov, whom one would think is one of the last members of the Russian royalty, but in fact lives in Minneapolis, suggests he's got a solution - he must have sent this before last week - that he knows what your password secret is.  I got it.  He says:  I think I already know the solution for stronger passwords that you are going to talk about next week, and I agree this will change many passwords of Security Now! listeners.  I've been listening for more than a year now.  And just as you are, I like assembly language.  I used to practice my programming skills many years ago on my 8088 processor, an MK-88 with 256K of RAM.  He is Russian.  He says that's the Belarus version of the IBM PC is the MK-88.  Wow.



Since then, with the invention of - I should read like this [Dracula accent].  Since then, with invention of virtual memory addressing in 386 and advancement of scripting languages, I've lost interest in programming as a profession.  So he says - here's his technique.  He says:  Let me put it in one sentence.  Use the whole range, all 255 ASCII characters when creating your passwords.  For example, in a Windows-based PC, do so by pressing ALT + 137.  That'll give you a .  This way, instead of entropy limited only to the number of characters available on the keyboard, which is roughly 26+26+10+32, those are the typeable characters - 26 without any modifier keys, then shift, alt, and so forth.  In other words, 94 keys.  One can use all 8 possible bits of 255 ASCII character range and thus achieve a maximum entropy per character entered.



Now, I don't know how you - on the Mac it's very different.  You can't use ALT 137.  You have to press option, shift, and it's a modifier key combination.  So he says:  Try to guess, for instance, }%, I don't know what that is, a little angstrom mark, then another , then an , then an em-dash, then a <, and then a cross, and then a smart left quote - anyway, you get the idea.  First one seems to be harder, don't you agree?  But using this password scheme represents a small difficulty for smart phones - yeah - and Linux because ASCII characters are not simply typed using such operating systems, but I'm sure apps are written to do it.  Did I guess right, Steve?  If I did, can I have a copy of SpinRite signed by the author?  Signed, Sergey Romanov, Minneapolis.



STEVE:  So actually I noticed that, in his little sample, I wonder if he's trying to claim it as a registered trademark because he's got the last character in there is a registration, the circle R.  Okay.  So the problem, first of all, yes.  If you had an operating system that made it practical to enter those - and I would go even further and say Unicode, which is 16 bits, more even than 8 bits, if there were some way to do that.  And if the web form you were entering it into accepted it, and if the website at the other end accepted it...



LEO:  Oh, that's a bigger if.



STEVE:  And that's the big if.  I mean, we're seeing - I've had a lot of feedback from people saying, gee, Steve, I tried to use the haystacks approach and put one of each type of character in explicitly, and nothing I could do worked.  And so the big problem is that the recipients of - well, there's two big ones.  The recipients need to be able to handle any kind of character you could throw at them.  But also you need to be able to input it reliably.  I mean, yes, we all know, all us old IBMers, the ALT something.  I mean, I use ALT 7 to give me a bullet on my PC all the time.  Or is that CTRL 7?  No, it's ALT.  And, like, 145.  Anyway, I have a bunch of those codes memorized that I've used through the years.



LEO:  Yeah, me, too, yeah, yeah.  There's no standard way to enter those.



STEVE:  Precisely.  And so if you're anywhere else, on a different device or in a different location where you don't have access to what you entered before, you're out of luck.  So I think it's very important - and this is the reason my own Haystacks page only focused on that base set of 95 characters, because I counted space also, 33 special cases.  I don't know whether space is an alphabetic or a symbol.  But anyway, I counted it there.  The only reason I did that was to say, okay, here's the lowest common denominator.  Sure, if your particular use case would allow you to use a wacky character, and that means that the recipient of it understands the wackiness also, by all means go for it.  I mean, that instantly means that you're off the reservation completely, and that thing is never going to be found.  The downside is you're in trouble if you need to log in anywhere else that may make it much more difficult to enter those wacky characters.



LEO:  Well, nice try.  But no SpinRite for you.



STEVE:  Not quite yet.



LEO:  Thank you, Sergey.  Jerod Lycett in Duncannon, Pennsylvania asks:  Please keep Perfect Passwords.  It's still useful, even if it's not passwords.  He says:  There is a use for the Perfect Password page that Steve has at GRC.com.  I don't think you've taken it down, hope you haven't taken it down.



STEVE:  I won't.



LEO:  No.  He says you may have overlooked this, but I use it for salt.  If you use SHA512 10,000 times, it still won't prevent a determined hacker.  The important thing is, of course, an unguessable salt.  So he's saying it's one thing to hash it, but another thing to hash it and have a really strong salt key.  If you use a known cleartext such as "turtle," as a password, and then gain access to the hashes, you'd simply have to figure out how many times they hashed, what the salt is.  If the number of times they hash is known - and companies for some reason like to brag about  how many times they hash, big mistake - then all you have to do is run an attack to find out the salt.  I use Perfect Passwords to generate the salt for everything I do.  Even if you plan on removing it, please leave the salt generator up for everyone.



STEVE:  And the page will stay, GRC.com/passwords.



LEO:  Thank you.  No, I would keep that up.  That's a useful page.  Not everybody wants to use Haystacks, for a variety of reasons.  Question #5, Dave Anderson, Grass Valley, California.  He says:  USB prophylactic achieved.



STEVE:  Only on this show, Leo, do we have USB prophylaxis.



LEO:  This is in response to the listener who was concerned about using a flash drive after it was connected to an infected computer.  And we said, yeah, that's kind of risky because flash drives could be written to.  He said:  This got me wondering if there are any USB flash drives with write-protect switches.  Turns out there are, though not in great proliferation.  I found this site which seems to be trying to collect a list of them.  Fencepost.net has the post.  I'll put a link in our show notes.  Seems like a great tool for the purpose of having a maintainable toolkit which is protected from infections and fits in your pocket, unlike a CD or DVD.  And actually I meant to ask you about this when you brought this up.  We said use a CD because that's for sure write-only, I mean read-only.  But does the hardware protection on a flash drive, is that reliable?  Can that be overwritten by software?



STEVE:  No, it is enforced at the hardware level inside the drive.  And for any listeners who don't have ready access, I checked.  And if you Google "USB flash drives with hardware write-protection," which is the tail of this URL, USB flash drives with hardware write protection, the first link that Google finds is this post.  And it is a nice page that by make and model runs through, I mean, that's what it is, obviously, is a page listing all that.  So I just thought that might be of use to our listeners.  However, I then encountered something very cool which is - it's our last question of the podcast, and it's one of the two Hot Tips of the Week, which I just completely overlooked.



LEO:  Ahh.  Well, we'll get to that in a moment. 



STEVE:  We will.



LEO:  Yes, yes.  Question #6 from Lynne in Maine.  Lynne has thought about the best passwords ever:  Steve, first the pleasantries.  I've been listening to Security Now! for several years and have gradually ratcheted up my security per your suggestions - LastPass, NoScript, Certificate Patrol, to name a few.  I really appreciate your going into the nuts and bolts of how things work so I can make informed decisions about security.  Now, I just finished listening to 302 and the password revelation which you would be sharing with us next week.  I am now very curious if it's at all like what I have been doing for years.  I'm a network engineer for a major cable ISP, and I'm responsible for coming up with the enable passwords for routers, switches, et cetera.



Here's what I do:  First I come up with an 8-12 word phrase I can easily remember.  Then I take the first letters of the words of that phrase.  Then I make various substitutions such as zero for the letter "O," 3 for "e," $ for "S," et cetera.  Then I mix up the capitalization.  Then I add punctuation.  This has the advantage of being memorable, although some of my co-workers may disagree.  But I dare any brute-force attack to succeed in anything like a reasonable amount of time.  Just curious if this will be anything like what you've come up with.  Can't wait till 303.



And I have to say I actually, and have mentioned before that I use that.  I take song lyrics because I can easily remember the song lyric.  And then I will use the initials of the first, say, 10 or 12 words of the song lyric, capitalize, punctuate.  I don't like using a zero for "O" and a 3 for "E" because that's leetspeak, and it's probably the first thing anybody would try.



STEVE:  And that was exactly the comment I was going to make, Leo.  I didn't mention it last week, and I thought I should because I've run across comments a number of times.  And you're right, it is a well-known, those simple sort of visually approximate substitutions are known by attackers and are in their dictionary attack arsenal.  So that's the one thing that won't get you a lot more safety.  Certainly mixing up capitalization, we know why that works because you have to have an exact match.  And adding punctuation, we know why that works because you have to have an exact match.  So those are all good things.  But I did want to mention not to depend upon changing letters for numbers or symbols, characters that look similar, because that's really not providing the kind of protection that someone would hope.



LEO:  Yeah.  I use the punctuation.  And I have an algorithm which I won't tell you for uppercase/lowercase that is non-obvious.  And then I guess you could, if you wanted to put numbers in for letters, if you had your own algorithm, you've replaced all E's with twos, that's not going to be likely guessed.  I mean, maybe that's going too far.  I don't know.



STEVE:  I did want to mention that I've updated the Haystack page with a bunch of links at the bottom of password-related web pages that I think anyone who's interested in passwords will find interesting.  I've found, I mean, you could imagine, since last week's podcast I've had a whole ton of interest.  And there have been people posting about GPUs, Graphics Processing Units, that are able to crack through passwords that are too short; a bunch of interesting analysis of the recent password databases that have been breached, things showing percentages of what - that's where I know that your prior, your old favorite password of "monkey" was #14 on one database.  Which means that everyone was choosing "monkey" for some reason, which I just...



LEO:  It just, I don't know, it's just something about monkeys.  Isn't that funny?  I mean, I certainly wasn't choosing it because I thought everybody else was.



STEVE:  No.



LEO:  I gave that up, by the way, using that, in 2004.  Just so if anybody wants to try to crack my system, it's been some time since I used "monkey."



Javi Harris in Iowa wonders how to get started as a kid:  Hey, guys, let me start with this.  When I first started listening I had no clue what any of this security stuff was.  I almost gave up, but iTunes insisted that I had subscribed to your podcast, so with a great deal of patience I've slowly started to really understand all the topics you cover.  Javi, well done.  That's great.  What really got me interested is how easy it is to be safe and even easier to be unsafe.  I didn't realize that a simple change of your password could make a huge change.  All of this crazy hashing and salting passwords still sometimes makes me dizzy, but I think I have the overall concept.  I will be forever a listener, and I hope to learn a lot more.  Wow, that is so cool.



Oh, before my question, did I mention I was 16?  Now my question:  What can we as teens do to make our computers more secure?  Yeah, it really is teens that seem to be the people who are getting their parents in trouble most of all, as you've spoken about in the past.  We don't have a bunch of money or the resources most adults do.  Do you have anything I could start looking into to learn more about security?  As the future to computer security I think it would be nice to know what we can do, my generation can do.



Well, I'll let you guys get back to saving the world.  Before I do, one last thought.  I realize I've been going on for a while.  Maybe you could have a little segment on the show where you teach something new to beginner security experts or something along those lines.  Just an idea.  Thank you so much for having an amazing show, and keep on getting the word out to people.  I've changed my perspective on Internet security, and I hope many more kids like me can, too.  See you guys.  Wow, what a great letter.



STEVE:  So, okay.  Two things.  The bad news, Javi, is behavior is the biggest problem with security.  In today's world, it is unsafe behavior which gets people into trouble more than anything else.  I mean, we'd like to have some technological solution, you could download something and install it and run it and so forth.  And if we had that, that would be great.  That doesn't exist.  It's behavior.  Which I know is like the last thing you want to hear because you want to do what you want to do.  But unfortunately, it's doing that which causes the problems.  So clicking on links, questionable stuff, unknown stuff that your friends send you.  Or going to areas of the Internet that are perhaps unsavory and not as safe.  People who stay with Google and Amazon and Yahoo! and MSNBC and CNET, they're not typically getting themselves in trouble.



LEO:  And they're not teenagers, either.



STEVE:  And they're not teenagers.  Exactly.  So there does seem to be, like, a demographic sort of bias in that direction.  So the first thing I could say is unfortunately there aren't any shortcuts.  And the thing you want to hear the least is behavior is really the way to be safe, basically not do some of the things that you're currently having fun doing with the Internet, which might not be safe.  And the second is, relative to segments to teach beginners, I don't know when you got hip to the podcast, but the very start of the podcast, five and a half years ago, Episode #1 and moving forward, we spent a lot of time laying down some foundational stuff, which if you haven't heard it, frankly, I recommend doing that more than anything else, is go back to Episode #1 and work your way at whatever speed you're comfortable with forward because we really have covered a huge amount of content in a very carefully, this builds on that, that builds on this, that builds on that.



So, for example, when I'm talking about hashing and salt, I use the term now assuming our listeners have enough familiarity with it to be comfortable with it.  But there was a podcast where we did nothing but talk about that.  I mean, really carefully, what is a hash, what is salt.  So all that still exists, and it's available.  GRC.com/sn for Security Now! will take you to that page where the entire archive is there.  And Leo, I think people can get it on TWiT.tv, too; right?



LEO:  Yeah, what we do, just so people know, is if you go to TWiT.tv/sn, every show is there.  It's kind of a pain.  We're redesigning the website, by the way.  And roughly the same time the new studio opens we will have a new website that'll be much easier to navigate.  But right now you can go previous, previous, previous.  But if you know our naming convention for episodes, it's really easy.  It's TWiT.tv/sn and then the episode number.  So #1 is sn1, #2 is sn2, #3 is sn3.  So you can go back to any arbitrary episode, even start with #1 and go forward, if you know that naming convention.  I apologize.  You shouldn't have to know a URL naming convention to find stuff.



And the truth is you can go - there's search, and you can go back and stuff.  But it's all there.  We also - you have the transcripts, which I think are great, at GRC.com.  And we also have show notes on our TWiT wiki.  Almost always, most of the time, I don't know how far back those show notes go, but for current shows anyway I'll make sure that your notes get entered into our wiki.twit.tv, so you can search for any show note there, as well.  So that's another place.



And actually there's a link, if you look at the show notes, there's always a link to the transcript and other information there.  So that's another place to go, wiki.twit.tv.  And if you are a listener, and you find that useful, and you want to help out, please, don't hesitate to sign up for an account.  It's free on the wiki.  We do ask you to attach an email address to your name before you start editing, just so we know who you are. But everybody is encouraged to edit this.  This is a community project, the wiki, and I think very useful.



Returning to our questions - by the way, I'm just - thank you.  It's great to know you're listening, Javi.  And keep up the good work.  The truth is, if one in a hundred 16 year olds listen and then you take it on yourself to spread this information among your peer group, this would be a much safer place.  You can be the leader here, Javi.



Thomas Kingston in Longmont, Colorado.  He said he loved last week's Haystack episode, your new password technology.  I've been listening to Security Now! since Episode #1.  Crazy, isn't it.  And I must say Episode 303, Password Haystacks, is by far my favorite.  While I agree 100 percent that password length plus a combination of all four character types - lower and uppercase, number, and special character - in a padded style is far superior in password strength than sheer entropy, there do appear to be some examples in which your Brute Force Password "Search Space" Calculator don't match up with this logic.



For instance, many websites will give you a limit on the number of characters your password can be.  For example, a website that allows 32 characters, filling in 32 a's in your calculator yields an offline attack scenario of 6.29 trillion trillion centuries.  Right?  Seems unreasonable to me.  So I figured it best to pass along the finding - oh, I guess because if you were doing a brute-force, all lowercase a's might be one of the very first things you do.  And you didn't take that into account, I guess.  So he said I figured I'd pass along the findings so people can be encouraged to use something like this after seeing the calculator's results.  So in case people are encouraged.  Anyway, great job as always, and I really appreciate all that you and Leo do.  Thom.  And I think you were very clear not to use the calculator as a way to test passwords.  It's not a password test.



STEVE:  Right.  There has been some confusion.  And immediately after, right below the calculator, I say what this is not.  And it is not a password strength meter.  And it can easily, because it can so easily be mistaken for one, I wanted to make it very clear.  Then I drew the example that the word "password" the little Haystack meter ranks as very good, but of course it's very bad.  So this wasn't attempting to analyze the word for its probability of being in a dictionary or anything.  It was just to say, what character set does the word occupy?  And based on its length, how long would it take a brute-force search to find it?



And the common theme that I've received in feedback from people who took exception to this whole notion is they've said, wait a minute, but you could design other brute-force attacks which attack padding.  And it's like, absolutely, I mean, and their point was there is no brute-force strategy for pure entropy.  And they're very right about that, too.  If your password is 24 characters of gibberish that's really random, there is no strategy for finding it.  And so the purists were arguing that any padding that involves any pattern necessarily means that there would be a strategy for finding it.  And I don't discount that, either.



So really the core takeaway was to appreciate that length really does matter in a brute-force search.  So you wouldn't want to take, you couldn't securely take something really weak and add padding that was like obvious padding and feel super comfortable with that.  I would say take a password like you're already using and just extend it because you lose nothing by making it longer.  And even if it's simple padding, that's easy to remember.  You don't have to pad, or the whole password doesn't have to be crazy complex.



So that was really the point was, yes, pure entropy has value because there's no - you cannot design a strategy to crack it.  Any padding, any lowering of entropy, means by definition that there could be a cracking strategy designed to find it.  I'm not sure that's such a problem because don't use all dots, don't use all a's, be clever, come up with something.  And Leo, just as you're not telling us what your capitalization strategy is, don't share what your padding strategy is.  Don't rely on the padding.  But it's an inexpensive bonus for making existing passwords stronger.



LEO:  Yeah, so if you go to a site that allows 32-character passwords, and your normal nominal password would be 12, then you just add 18 a's, and that would be good.



STEVE:  Yes.



LEO:  That's not going to show...



STEVE:  Because it's going to be as good, absolutely as good as what you had before, and inexpensive to pad, exactly, and make it stronger.



LEO:  Brian Drake in Gallatin, Tennessee also wonders about Password Haystacks.  He says:  As someone who has been using leetspeak - oh, we were just talking about that - for a couple of years now to create passwords, I was happy to learn by using your Haystack tool that this yields passwords that would take 1.66 hundred centuries to crack.  Problem I've run into using this method, however, is that a disturbing number of websites simply will not allow you to  use anything other than numbers and letters for your password, and many of these same sites have a restriction on how long your password can be.  This kind of makes it difficult to use your method.  And in some cases there's no choice in using a different company if you discover that they only allow you to have weak passwords.  For instance, my university.  I'm not going to change schools even though they allow weak passwords only.



Do you have any suggestions as to what one can do in those cases?  Or how we can get organizations to adjust their password requirements?  And while we're at it, would it be too much trouble to get people to put in the password requirements, put them beside every box where you have to enter them in?  It's a pain to punch in a password and have the system reject it for some unspecified reason so you keep trying it until you realize it doesn't like the special characters you've been typing in.  That's a pet peeve of mine, too.  I hate that.  It happens to me all the time because, if you use strong passwords, you will frequently run into sites that say, oh, by the way, you did this, or you did - that's annoying.  Tell me upfront, please.



STEVE:  Yeah.  I posted this for that reason.  I thought Brian made some very good points.  I'm sure all of us who are trying to be strong with our passwords are constantly, just as you are, Leo, running across sites where they don't make it clear upfront.  It's only after you give them one, then they say, oh, we forgot to tell you, here's the following criteria for passwords.  Well, the fact that they have any is purely customer service.  I mean, their reps don't know what that "a" with a circle around it, it's called an "at sign," or "back tick," or circumflex.  If you don't know the names of these things, it would be hard to explain it to somebody.



But I don't know, it's just, again, Brian and listeners, we're clearly in a frontier era still.  And I think things with huge, high publicity problems like Sony is having, like RSA is having, it's got to be the case that companies are going to be looking at making sure this doesn't happen to them.  And putting pressure on the company, when Brian asks is there anything we can do, I would say yeah.  If you find yourself stymied by a company that won't let you use a strong password, complain.  Everyone's got a support link.  And they may blow you off and ignore it.  But it's worth doing.  If nothing else, you'll have the peace of mind of saying, well, I tried to give them some feedback.  Please remove the restrictions from your passwords because I want strong passwords.



LEO:  Well, and as you've mentioned in the past, a fixed-length password or a maximum-length password means that they're not hashing their passwords.



STEVE:  It certainly implies it.  We don't know for sure, but it's a good tipoff because, if they're hashing, they don't need to have a length restriction.



LEO:  Right.  So that's a bad sign.



STEVE:  Yeah.



LEO:  Sony.  Let's see.  Is it Jonathan next?  Yeah, Jonathan Simon is concerned about long but low-entropy passwords:  How robust are long but low-entropy passwords against new brute-force attacks that reorder the guessing so that it is not in alphanumeric order but rather in low-entropy to high-entropy order?  That is, if the algorithm tries passwords that would, for example, be compressible to smaller passwords or that contain dictionary words, earlier than true high entropy passwords in the Shannon sense.  Jonathan.



STEVE:  Well, I just answered that.  I forgot that I had this question here.  I wanted to make sure that I covered...



LEO:  In other words, aaaaaaaaaaaaaaaa, which is low entropy, but long.



STEVE:  Yes.  I want to make sure that everyone understood that I get it, and that I shared with everyone that I recognize that the gold standard is a long and high-entropy password because you can't brute-force it, nor could there be a theoretical strategy for finding it sooner than doing pure brute force; and that it's absolutely true, if you lower the entropy, then that implies - and he mentioned Shannon, who is of course the famous scientist...



LEO:  Claude Shannon, yeah.



STEVE:  ...that talked about information theory, that if you lower the entropy, then it means that there's something theoretically attackable.  So, I mean, I wanted to let everyone know, I wanted to give them the satisfaction of knowing, those who felt that they were correcting me, that I get it.  I understand that.  But I would still argue, take something good and pad it to make it better.



And I will also say that I'm not going to tease again, like I did two weeks ago, but I had a really good session at Starbucks last Thursday, the morning after I recorded last week's podcast.  And it's looking good for I have one more really cool new, really new thing to add to the whole password bag of tricks that everyone's going to get a big kick out of.  Again, I need to do some more work on it, so I don't know when.  I'm going to drop the issue until I have an announcement.  And then we're going to have a lot of fun.



LEO:  Cool.  Can't wait.  Curtis in Sayreville, New Jersey needs a secure hard drive eraser:  Steve, I have a few hard drives that I need to erase.  I mean erase erase.  I've heard there are programs out there that will write over the existing data and do a set amount of passes.  What program, if any, do you use or recommend for this?  Thanks for an awesome podcast.  Curtis.



STEVE:  It was such an important question, and a quickie, that I just threw it in here, even though it extended the length.  We like Darik's Boot And Nuke, also known as its acronym, DBAN.  You can download the ISO, burn it to a CD or stick it on a USB drive.  You just boot a machine that's got the evil hard drive you want wiped, and it'll do it.  I mean, and it does it really thoroughly.  I think it's overkill.  I believe, like, three or four pseudorandom passes ought to wipe any hard drive for reasons we've talked about before.  I know there are some that do 33, and it's like, oh, boy, okay...



LEO:  I think two is probably enough.  But anyway,  yeah.



STEVE:  Yeah.  The key is, the idea is you can always read back what you just wrote.  That's what the hard drive is designed to do.  But then if you subtract out the big signal that you know was written, that's going to leave the signal that it overwrote.  And so if you subtract it out,  then you get the signals that it overwrote, which might have been what was stored before.  And that's probably the limit of what we're able to do.  So my theory is you record pseudorandom data so that you don't know what it was you recorded, and then do it a second time just so that the top two layers are just absolute noise.  And that's going to do a really good job at wiping out anything that was stored magnetically beforehand.



LEO:  Just Google DBAN, that's it.



STEVE:  DBAN.



LEO:  Finally, Question #12 comes to us from Mark Hull in Charlotte, North Carolina.  It's the Double-Header TIPS of the Week:  I've been a listener since the beginning.  I just want to comment on the easy way to remember the PIE (which we've replaced PEE with PIE, by the way), Pre-Internet Encryption, acronym.  When sending things to the cloud or sky, it's easy to remember "PIE in the sky."  In other words, encrypt before you PIE, or you sky.  PIE before you sky.  Also, when doing troubleshooting on machines that might be infected, I use a USB-to-SD adapter, with the SD's "lock" - most SD flash have lock.



STEVE:  I think by definition, in the spec, it has to.



LEO:  Okay.  And so he does it, he sets it to read-only on the SD card, puts it in a card reader.  That turns it into a flash key that's write-protected.



STEVE:  And that's what I loved.  I thought that was such a great tip, Leo, because here we're like, oh, I mean, I've got all these thumb drives around.  They don't have write-protect on any of them.  But I also have SD cards for different things.



LEO:  They all have write-protect.



STEVE:  And every single one has a write-protect on it.  So that's a perfect solution.  I mean, and now you can get them huge, SD cards.  You can put all kinds of stuff on it.  But write-protecting an SD card and then putting it in an SD-to-USB adapter, you've got the best of both worlds.



LEO:  I'm still wondering if that - so you're saying that's a hardware lock that prevents - you just cannot write.  You can't go around it.  Software can't end-around it or anything.



STEVE:  Correct.  There is, at the hardware level, is a write-request line in the actual hardware spec which you raise this wire in order to enable writing, and then it latches the data at the connector into the chip.  This switch disables that.  It breaks that connection so that it just - it is dead to writing.  You cannot write to it.  Now, I remember back in the antivirus days, there were people that were getting - I mean sneakernet, pre-Internet, when we had floppy disks.  The floppy drives had a notch on the side, the larger - was it 8.5 and 5.25?  Or just 8-inch, the big 8-inch floppies and the 5.25s.  And then we got the 3.5s, and they had the little slider.



It's surprising back then how many write-protect switches back then didn't work.  That is, the disks didn't have them.  They just had a window that was open or closed.  But there was a little micro switch in the drive somewhere that you were depending on to provide you with write protection.  And it was - I remember being really surprised the percentage that were broken, and most people never knew because you would only know if you attempted to write to a protected disk, and you succeeded, which is normally not something you do.  So the one thing I would say to people is, when you lock your SD, try to write to it, just to make sure the switch really does work.



LEO:  Good idea.



STEVE:  So a little double-check.



LEO:  Steve, we are done, 12 questions good and true.  And you have answered them all to the best of your ability and knowledge.  Congratulations.  Do you have a plan for next week?



STEVE:  I don't.  We'll see what brings.  I've got a list of things I want to get to.  Something could happen between now and then.  If not, I'll pull something from the list, and we'll have a great podcast.  That I can guarantee.



LEO:  Steve, thank you for a great show.  Everybody should visit Steve's website, GRC.com.  That's where you'll find SpinRite, the world's finest hard drive and maintenance utility.  You can also find all the previous shows there.  You could find Password Haystacks, even Perfect Passwords, everything is there.  There's a great menuing system.  And if you've got a question for Steve's next Q&A episode, GRC.com/feedback is the place to go.  We do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern at live.twit.tv.  That's 1800 UTC.  So please stop by and watch the live show, but you can always subscribe after the  fact.  It's on iTunes, it's on the Zune Marketplace, everywhere podcasts are.  Or find it on GRC.com or TWiT.tv/sn.  And there we have it.  Thank you, Steve.



STEVE:  Thanks, Leo.



LEO:  Great to see you, and we'll see you all next time on Security Now!.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#305

DATE:		June 16, 2011

TITLE:		Ghostery

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-305.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 





DESCRIPTION:  This week, after catching up on the week's security and privacy news, Steve and Leo take a close look at "Ghostery," a highly recommended, multi-OS, multi-browser extension that reveals all of the tracking bugs and cookies websites are hosting to track us, and optionally allows them to be blocked.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 305, recorded June 15, 2011:  Ghostery.



It's time for Security Now!, the show that covers your security and private online.  And what would Security Now! be without the man who has been riding the horse, at the helm, skippering this ship since - for, what, six years now.



STEVE GIBSON:  And watching it slowly sink.



LEO:  No, no, no.  Not at all.  Mr. Steve Gibson.



STEVE:  Oh, the industry, I mean.  The industry.



LEO:  The industry's been getting worse.  You know, it's so funny, I mean, we started this in, what was it, 2006?  2005.  2006.  And at the time it wasn't as bad as it is now, was it.



STEVE:  It really wasn't.  I mean, we didn't have an Attacks & Breaches section until recently.  And now I'm thinking, how did we ever survive without one?  Because, I mean, it's just - it's nuts.



LEO:  Well, when we started it was really a show to teach you about topics and concepts in security, to talk about things going on.  But we didn't do a lot of news.  Now it's at least half news because there's so much going on.



STEVE:  Yeah, and interesting stuff.



LEO:  What is our topic of the day today?  I see "Ghostery."  What is that?



STEVE:  Yeah.  This is something that a number of our listeners had pointed me to, that I had on my list of things to track down.  And it is very cool.  I would describe it as a comprehensive website surveillance monitoring and blocking add-on.  The nice thing is that it's multiplatform and multibrowser so supports Internet Explorer, Chrome, Firefox, and Safari on all platforms.  And it essentially - we've talked about cookies extensively, and of course even web bugs of different sorts, all these things that track us.



So I'm not sure why they call it "Ghostery."  But it started off initially just being a monitoring tool.  But its users said, you know, you're showing us all the things that are following us around and tracking us.  Like you go to MSNBC, and it's just like, oh, my goodness, there's a list of eight different third parties which are participating at MSNBC's behest, tracking us.  And Ghostery makes all of that visible, gives us lots of information about it, but now also allows us to block that.



So that's our topic for this week.  I'm going to introduce our listeners to Ghostery and talk about its features and what I've found using it.  And we've got a big Errata "whoops" at the top of the show about SD cards and write-protecting them, following up from last week's discussion.  And I actually have probably the most controversial SpinRite testimonial we've ever had.  So we're going to have some fun this week.



LEO:  It'll be fun.  And Marc Pelletier, who's in our chatroom, just told me that the Futures in Biotech show, which still feels to me like one of our newer shows, is five years old as of yesterday.  So we've been doing this a while, Steve.  It's funny how this network has grown and changed.  And we were talking a little bit off the air about the new studio and the capabilities of the new studio.  And what'll be interesting is that Security Now! won't look so very different.  In fact, it will pretty much look exactly the same.



STEVE:  'Cause I'm not going anywhere.  I'm going to be right here in front of my bookcase with lights blinking behind me.



LEO:  As will I, because we're duplicating this particular studio over there.  So people tuning in in a month, which is about when we will start this change, will say, hmm, looks the same to me.  And that's kind of what we want.  We don't want to discombobulate you unnecessarily.  It'll only be in the shows that need more production value than this show that we'll have that capability.  And we may surprise you once in a while.  We may have graphics fly in from the left.



STEVE:  Or monkeys.



LEO:  Or monkeys.



STEVE:  Many of our very, very astute listeners immediately jumped on me via social networking connections, I think mostly Twitter, saying that what I had said about SD cards was wrong.  And in retrospect, it was obvious that what I had said was wrong.  So I wanted to immediately correct that.  An SD card's little write-protect switch, which they all have as part of the spec for an SD card, as I did say, is just a piece of plastic.  So in that sense, it's exactly like diskettes were in the old days, where you're relying not on electronics in the SD card, but in a sensing switch in the SD card holder to honor the write-protect request that the card is making via the position of that little bit of plastic.



LEO:  So the reader is the key here.



STEVE:  Exactly.  So...



LEO:  But we said that, Steve.  We said that a properly configured reader would honor it, but it would be possible to get around it.



STEVE:  But I was talking about an electrical connection that would be made.  And, for example, I was correct in the USB side, which is to say, since the spec doesn't have write-protect, and there's, like, no means for enforcing it the way there is on an SD card, the USB devices are absolutely going to be an electrical connection because that's the only way to do it.  But in the SD spec, they spec it as a switch which is readable, and it can be a function of the device driver to honor it.  So you really do want to verify that write-protect is being honored by your system.



And I would argue that, if in fact, as I have been told, although I did not pursue it, it is device driver sensible, that is, the device driver can sense the setting of the switch and then choose or not choose to honor it, I know that's the case at least in some cameras because some people talked about how they've got firmware which they can provide on an SD card in some high-end cameras.  And the camera can write to the card with the SD card set to write-protected, that is, to read-only mode.



So overall a better solution, if this is going to be what you're going to do, I would say trust a USB device.  And the SD card advice is probably not - well, except in the case of an SD-to-USB adapter, where you want to verify that the adapter supports write-protection.  But then it's not an option for the device driver to enable it or not, that is, pay attention to it or not.  That would only be the case if the SD slot is actually hosted by the PC.  If you're using an adapter, then the adapter's electronics, if it supports write-protection, it would be enforcing it there.  So that bit of advice that we offered last week is correct with the strong caveat that you verify the adapter you're using does support SD write-protection.  So I wanted to make sure we got that corrected.



We have just passed the second Tuesday of the month.  And we didn't break a record this month for Microsoft's Patch Tuesday, but we're right up there near the top.  They fixed 34 security vulnerabilities, 11 of which were in IE, and that spanned 16 different updates.  More than half of those were critical, meaning by Microsoft's terminology that they are wormable, which means they require little or no user action in order to be exploited.  And the rest were information disclosure and privilege escalation and so forth.  So sort of our generic large monthly update.



And I read somewhere something I really hadn't noticed before, but a commentator was saying that Microsoft tends to alternate bug sizes.  So this was a big Patch Tuesday.  And if this observation holds true, last month was - we know that it was small, but that would say that July will be small and August will be large.  So we'll see if that's the case.  I don't know why that would necessarily be.  But we certainly do see that Microsoft has very small ones every so often.  Not so this time.



Java we've been talking about a lot recently because, for example, in the case of Microsoft's own intelligence that they've collected from their rootkit scanning and malware removal tool that we talked about, they talked about how I think it was eight out of ten of the top vulnerabilities had gotten into users' machines through Java vulnerabilities.  Well, Oracle has just updated Java to Update 26.  So it's Java 6, Update 26.  If you are using Java, and we've talked about if you know you don't need it, by all means remove it.



If you do need it - and there are an increasing number of instances where I'm seeing things require Java to be there, so I'm beginning to feel like, okay, we're losing the battle there.  Although I did note that NoScript is able to control and corral Java also.  So it's another one of the things that you'd want to have disabled on sites you don't trust, since, as I mentioned last week, since scripting is required to invoke a Java applet anyway.  I know for example I've had to enable JavaScript in order to allow a Java applet to run on a site where I'm visiting for the first time.  NoScript is also your friend in that regard.



They've fixed 17 vulnerabilities in this update.  I had 25 before.  Now I'm at 26.  So if you've got Java, you really want to follow up on this because it's a serious way that is being exploited now to get malware into our machines.  They fixed 17 vulnerabilities, all of which would allow code to be executed remotely without authentication.  So these were big, bad holes.  And nine of the vulnerabilities of that 17 were given a 10 out of 10 in terms of security risk, and that's Oracle's own ranking.  And this update's available for Windows, Linux, and Solaris.  Apple users will have to wait until Apple issues an update to address the flaws due to Apple's relationship with Sun and now with Oracle.



And I have to say I'm still annoyed that I have to say "no" to the Yahoo! toolbar that they're trying to stick in my browser and in my machine.  That's just annoying.  When I'm being forced to update Java because of security problems, and they're trying to hope that I don't remember to turn that thing off.  Because it's on by default.  That just - that really seems wrong.



LEO:  No kidding.



STEVE:  Also, for Windows users, and I didn't look over on my Mac to see, but you can check the current version because there's a Java applet that you can get to on the Control Panel.  So Start, Control Panel, then open the little Java applet, and there's a button you can click to do an "About" to see what version you've got.  The other thing is, Java is willing to check for updates.  And for some reason it's set to a month.  And I thought, you know, Java being as big a problem as it is, even though Sun isn't updating it frequently, maybe if something really, really bad happened they would.  So I'd like to have my computer checking more than monthly, which is the default.  So I changed it.  There's a tab there, you can change how frequently it checks.  And I'm having it check daily because it's just a tiny little ping that's going to go out to Oracle to see if there's a newer version, so why not do it more often?  I would say monthly, if you've got Java, and it's enabled, is probably not often enough.



LEO:  So I Googled "Java update."  There is a Windows - is this what you're talking about?  This is a Windows program that checks.  But does this only check monthly?  I think it checks all the time.



STEVE:  People can go to Java.com.  So Java.com is where you get this.  But for Windows it does, installing Java puts a little applet in the Control Panel that allows you to get to it.



LEO:  That must be this Java Update, okay.



STEVE:  So last week we talked about Wednesday was the 8th, which was World IPv6 Day.  And mostly it went okay.  As I said, I would have more news this week, and that's what's happening.  There were little implementation glitches, the kind of things that people would iron out and will iron out when they finally switch over.  For example, some sites that were supporting IPv6, when they see that you're trying to get to them on what they consider a mobile platform, like a phone or an iPad, for example, they will redirect your browser over to their "m" - instead of www.something.com, it'll be m.something.com.  I know I've seen that, for example, with Twitter and with various news sites.  They'll give you a simplified, streamlined, mobile version that's more meant for a smaller screen.



Well, there were some oopses that occurred on IPv6 day because the "m" versions of their sites were IPv4 only.  And so they had upgraded their www.whatever.com to IPv6.  And so if an IPv6 user went there, they would be redirected to the m-dot version over IPv6, and that wasn't even available.  So it's like, oops.  That didn't work.  So some mobile people found that sites they were trying to get to over IPv6 didn't work.



For example, there's something called MTU Path Discovery.  MTU is Maximum Transmission Unit, which is basically packet size.  And the way the Internet works, packets will be fragmented if they encounter a router that is unable to forward the packet to the next router without breaking it up in smaller pieces.  For example, the router will know that the link that it's using is only able to handle, only able to carry packets of a certain size because of the limitations, for example, either at its end or at the other end.  So it'll fragment packets.



But there are instances where packets have to be sent at a smaller size.  So there's the ICMP protocol has always had this notion of path discovery, that is, a means whereby a router will send back an ICMP packet to the source of a packet, telling it, whoops, you need to make your packets smaller in order to get them through without them being fragmented.  And in some cases fragmentation can't be used.  So there were some failures there also, a week ago during IPv6 Day, where apparently some filters somewhere on the Internet were blocking the v6 version of this ICMP MTU Path Discovery packet.  So they weren't ever getting back to the sender.  The sender didn't receive the news that it had to reduce the size of its packets outgoing.  And consequently people were unable to access sites that were, like, caught up in this problem.  So that kind of thing.



The IPv6 traffic was way up for that day, but only relative to regular IPv6 traffic, which is almost nonexistent.  So, yes, it was like many times more, but still minuscule.  However, Facebook did put up a posting saying that their test went very well.  And I think it was 0.03 percent of their users came to Facebook over IPv6, which was a million users that day.



LEO:  Isn't that funny, it can be such a low percent and such a high number?



STEVE:  Yes.  If you're something like Facebook, that's the case.  And one of the other observations was that a huge amount was tunneled IPv6.  We talked about tunneling IPv6 the other day, the idea being that you could encapsulate IPv6 protocol in IPv4 packets in order to route it across the IPv4 Internet.  And that's what - still a vast amount of traffic had to go through tunneling, which tells us that major portions of the Internet are still to this day, as we're counting down the end of IPv4 space, still unable to transit IPv6 traffic.  So, I mean, we're really not here yet.



Also and finally, a few participants, such as, for example, Xbox.com, had everything go so well that they're keeping IPv6 addresses in DNS.



LEO:  Wow.



STEVE:  And that's actually the way sites like Xbox.com and Facebook and Google and Yahoo! and others, that's the way they did this was they added IPv6 DNS to their existing IPv4 DNS, so that a query for DNS would receive IPv6 records in addition to IPv4, thus advertising the fact that here's, if you want IPv6, here's our 128-bit address for accessing us.  And Xbox.com said, yeah, we're going to leave it because it all worked really well.  So that's cool.



I did get some listeners telling me about a site which probably happened or at least got some news just recently called Encipher.it, as in Encipher It, clever name in the .it top level domain.  It uses bookmarklets and offers bookmarklets for IE, Firefox, and Chrome, which performs an in-browser AES encryption of text that you paste in.  So its sort of an add-on, for example, for web-based mail.  You could put in a bunch of stuff that you want to encrypt, and then mark it and give it a passphrase, and it will do an in-place encryption.



Now, it's cool, but there's one caution that I have.  And this is not something I have pursued yet, but I intend to.  And that is that, as I understand it, bookmarklets run in the context of the site that you're visiting.  And it's one of the reasons why I'm a little cautious of the gizmo you use, Leo, I can't remember the name of it now, but you'll know.  The thing you use for generating passwords based on the sites you're visiting.  Help me out here.



LEO:  LastPass.



STEVE:  No.  No, no.  It's something that you...



LEO:  Oh, SuperGenPass, you mean.



STEVE:  SuperGenPass.



LEO:  Yeah, yeah, yeah, yeah, I use that.  I still use that.  But I do the padding that you now recommend with haystacking.



STEVE:  Okay, good.  Because there's some concern about SuperGenPass's security, inasmuch as it is similarly a bookmarklet-based deal.



LEO:  Yeah, it's JavaScript.



STEVE:  And what I've seen is the claims that an untrustworthy site can compromise its security.  That is, bookmarklets run in the context of the site you're visiting.  So I would trust Google, but there are TNO people who perhaps wisely trust no one because...



LEO:  But could they reverse - so what happens, what they'll see - would they see my master password?  Because that would be the only risk there.



STEVE:  Yes, potentially.



LEO:  Okay.



STEVE:  Yeah, they have access to the script, as I understand it, which has access to your password.  Again, I haven't had a chance to research it fully.  But I did want to let people know that if they're wanting to do encryption, it's a cool idea, but you are trusting the site you're visiting.  And you're also trusting that nobody has inserted any scripting on that page.  So you want to be doing it over HTTPS for sure, as well.  And I intend to pursue this because I'm interested in finding out what the security dangers of bookmarklets are.  That would be a great topic for a podcast.



LEO:  And if I add padding, arbitrary padding, and it could be the same on each site, that's going to obviate their ability to figure out what's going on.



STEVE:  Yes.  They would not be seeing that, yes.  Also a bunch of people noted that - this hit the news, the security news this week - that LinkedIn, Foursquare, and Netflix had been found by a security auditing firm to be storing their passwords for Android phones - and we're not sure about iPhones, but all these same companies offer iPhone apps, as well - were storing their passwords in plaintext text files.



LEO:  And probably sending them in the clear, I would guess.  I wonder.



STEVE:  It was not clear.  Foursquare has since updated their Android application.  And I just have to shake my head, the idea that in this day and age applications could be that dumb, I mean, could just be that lackadaisical about their users' security.  And, now, someone might say, well, okay, but what's the big deal about my username and password for Netflix, except that we do have the problem that many people reuse username and password elsewhere.  And so you really don't want some compromise to get a hold of that information out of your phone and see if they're able to log in, well, first of all, you probably don't want them logging into your Netflix account or any other account.



LEO:  They could watch my movies.



STEVE:  Or LinkedIn or whatever.  But...



LEO:  I think that would be the bigger risk, is if you use the same password everywhere.  Which I don't.  And people should stop doing that in general.



STEVE:  Yup, and I'll have something to say about that before long, too.  IE and Firefox are both losing market share to Chrome and Safari, which are both gaining market share.  I just thought I would - I saw a nice little blurb, I thought I would just sort of give us an update on that.  Even though, okay, we have new versions of IE9 and Firefox v4, soon to be v5.  Firefox users are upgrading from their 3 versions up to 4.  IE users largely are not.  We're not seeing much rapid adoption of IE9.  Most IE users are staying with 8.  And 10 percent of IE users are still on IE6.  So, which Microsoft is beginning to get upset about and, as we talked about previously, beginning to launch a campaign to get people off of IE6.



So at the moment IE is still the majority browser.  It has 54.27 percent of market share.  Firefox is in No. 2 place at 21.7.  Chrome is in third place at 12.5.  And Safari is at 7.25 percent.  And Opera dropped a bit.  They're down at 2 percent.  But what this means is Chrome is currently the only browser now seeing consistent month-to-month gains.  So Chrome's share is coming at the expense of every other browser.  Firefox users are holding on.  They're loyal, as I am.  But people who are adopting Chrome are leaving IE and Opera.  And Safari's share is gaining just because of Mac market share gain that brings Safari along with it.  So I thought those were some interesting statistics.



And one last little bit of security news, it turns out that the new Nissan LEAF, which is the Nissan EV, is sending its location constantly.  It comes with a GSM cellular connection to the Internet - it's one of the sort of built-ins for the car - which provides voluntary telemetry information to Nissan and also, for example, is used to provide, like, to update the in-car map with the location of new charging stations as they become available.  And there are some, like, wacky competitive driver rankings where you can see who's able to, like, drive, then get the greatest battery mileage.  And so you can participate in a network to compete with drivers to see who can be softest on the gas pedal and economize the most on electricity.  But it also offers RSS feeds.  That is, you're able to configure it to receive news from anyone who's an RSS provider.  And collectively this thing is called "CARWINGS," is the service.



Well, what Nissan never discloses and has no way of allowing their users to disable, although I imagine there'll be an update coming soon, is that every RSS query, which is a standard HTTP "get" query, and we've talked about how "get" queries can have headers, the headers are just chockful of information that drivers may not want sent because RSS feeds are constantly, sort of a constant background polling for any news.  With that your current latitude and longitude is sent, your car speed and compass direction is sent, as well as the destination latitude and longitude configured into the navigation system.



Now, to mitigate that concern, there does not appear to be any unique car information.  So it doesn't look like you individually are identified.  But anyone - and I could see it as a benefit, if it was optional, where, for example, you might get location-based weather.  So if you wanted weather updates, it would know where you were, and the weather service could check to see what was going on near you, or regional news and so forth.  Yet it ought to be disclosed, and it ought to be something that you're able to suppress, which currently is not available on the LEAF.  So it's like, okay, well, these are lessons we're still apparently learning.



In Attacks & Breaches, we've got a widely publicized and, I guess, significant breach of the IMF, the International Monetary Fund.  Little is known still about what exactly happened.  It appears that attackers were able to get software on a computer that was persistent for some length of time which allowed them to access the IMF's network and reportedly exfiltrate a large amount of data.  It's believed that this was preceded by a targeted spear-phishing campaign.  And Bloomberg reported that the attack appears to have been mounted by a foreign government, although no specific country was named.  And Bloomberg's unnamed source also stated that the IMF lost, quote, "a large quantity" of data.  And the bad news is that much of that data is extremely sensitive, dealing with the internal financial state of various countries' economies and the state of their negotiations with the International Monetary Fund.



LEO:  That's not good.



STEVE:  So sensitive stuff got loose in a big breach.  Also Citi, as in Citibank, but Citicorp disclosed that earlier last month - and people are a little upset that it took Citi so long to tell us - as many as 210,000 customer names, email addresses, and account numbers and contact details were lost.  But Citi said that the associated PINs and the card security codes and other data aside from names, email addresses, and account numbers existed on different systems and were apparently not breached.



Not much is known about the attack.  But I did read one report which indicated that the hackers were manipulating the URL of, like, while logged in, as if to say, and one account did say, that the actual account numbers were in the URL query.  So just by changing the queries, they were able to get into other people's accounts.  Which sounds really screwy, but...



LEO:  Oh, that's wrong.



STEVE:  Really wrong.  And people apparently in the know are saying that Citi's security was virtually nonexistent.  So it does sort of sound like it may have been that dumb.  And we've talked about the dangers of putting sensitive information in URLs because, remember, any third parties that were presenting information on Citi's site received that URL in the so-called "referrer field."



So we'll know when we're talking a little bit later about Ghostery, if you go to Citi.com, Leo, Ghostery will show you all the third parties which are putting content on that site.  And if they're also putting content or trackers on the sites where those account numbers occur, they would be receiving the account numbers of the users in addition to their IP addresses and so forth.  And they're all about aggregating information.  So really you don't want to leak account numbers in URLs.  That's - there's all kinds of bad things that can happen.  I mean, that's, like, second and third order effects from that.



LEO:  It's actually listed, from OWASP.org, one of the top 10 insecurities on the web.  I mean, it's, like, well known and easy to fix.  And it's just ridiculous.  That's just ridiculous.



STEVE:  Yeah, and we just keep seeing over and over instances of very lax security.  And I'm hoping that enough attention is being brought to this, as I've said before, that people will start fixing this stuff preemptively.  I mean, instead of it just getting on the web and everyone screams with joy that it's working, yeah, but is it working securely, is the question.  And the U.S. Senate.gov server was breached.  They have said that only that one server was breached, and it only contained content for public consumption.  So no sensitive information got loose.  But it was the LulzSec group which have claimed responsibility for many of the Sony breaches and Nintendo and the PBS breach recently, were the same folks who did this one.  So those guys are getting around.



And I've actually seen some interesting commentary where security researchers are saying, yeah, well, we think it's really bad that these guys are so successful in breaching sites.  On the other hand, this is what's giving companies a wakeup call that they may be next.  And so fix yourself before you suffer a big black eye from having an outfit like this LulzSec breach your company.



And I picked up on a piece of news following up from two years ago, a report that we discussed, actually maybe it's three years ago.  No, two.  I saw both SANS and Brian Krebs reported.  Our listeners may remember we talked about it.  In May 2009 a company called Patco Construction, they had cyber thieves, as they called it, used the Zeus Trojan to steal their online banking credentials - and this is known, this was reported two years ago, in fact we talked about it - and transferred $588,000 in batches of fraudulent ACH, the automated clearinghouse transactions, over the course of a week, over seven days.  So Patco sued their bank, claiming that the bank's security was insufficient for their customers' protection.



In the weeks that followed that original breach, the Ocean Bank, which is the bank that was sued, was able to recover $243,000 out of that $588,000, but that still left $345,000 that Patco ended up bearing the loss for.  So this is significant today because just recently a magistrate in Maine recommended that the court make Patco the loser in this suit by denying Patco's motion for summary judgment and granting the bank's motion that the case be dismissed.  It's believed to be unlikely that the judge in the case will overturn the magistrate's findings.  So here we have a case where, I mean, with a lot of money involved, where a company who suffered a breach as a consequence of a trojan that was in their machine, captured their online banking credentials, which is username and password, and actually even a security question.



I dug into this a little bit deeper, and it turns out that what happened was the bank, Ocean Bank, used to have a system in place where, for transfers over $100,000, one of three security questions was asked.  And it was by having that in place that the bank was able to say they had multifactor authentication.  Well, what happened was they were having so much problem with much smaller transfers that they dropped that $100,000 limit to $1.  So almost all transactions, well, virtually all transactions, anything at a dollar or above, would be asked a challenge question.  So what that of course meant was that the challenge question was being asked all the time.



So the Zeus trojan was able to capture the questions and the responses from much smaller payroll transactions that this Patco Construction was doing and then be able to log-on on behalf of Patco Construction.  So the result of all this is that the bank is not being held liable, and there is zero case law until now, and what the case law we have is that, if a company gets hacked in a way like this, even a username and password and additional protection which ends up being breached is the fault of the customer, not the bank.



So I wanted to use this opportunity to reiterate what I have said a couple times, which is, if you're a small business, or even an individual, and you do not need to be doing electronic funds transfer with some of your accounts or any of your accounts, disable them.  You can tell your bank you want to disable that feature.  And I have on all of ours.  And Sue, my operations gal, is forced to walk checks around.  But there's just no way I'm going to allow this kind of a breach to drain GRC's money out of us, and then for there to be no recourse, that money is gone, and if it can't be recaptured electronically, which in this case some of it was, it's my loss.



So my feeling is, sorry about that, this technology, we just don't have enough security yet today to make this kind of major account access available electronically for it to be safe.  So we're still using paper.  And if the bank then makes a mistake and does honor a charge, when we have explicitly told them not to, then they absolutely are liable for it.  So that's where I want the responsibility to be.



There was an interesting, in our Miscellany section, an interesting survey of iPhone passcodes.  We've been talking about passwords recently, so I thought users would get a kick out of knowing that the number one most popular passcode used on iPhones, you probably can't guess it, Leo, or maybe you probably can.



LEO:  Monkey?



STEVE:  Monkey.  These of course happen to be numeric because the iPhone has a numeric keypad.  So the number one passcode is 1234.



LEO:  I could have told you that.



STEVE:  That's what people use to protect their phones.  And number two is 0000.  Then for some reason comes 2580.  And I'm not sure why.  I looked at the keypad, it's like...



LEO:  Straight down or something?



STEVE:  It's up the center and then down to the bottom.  So, yeah, so it's 258 are directly vertical, and then down to the bottom.  The fourth most popular is all ones, 1111.  Then comes all fives, 5555.  Then 5683.  And I'm not sure what, let's see, 568 - that's a kind of a strange thing.  But a lot of people use 5683.  Then 0852.



LEO:  It spells "love," somebody said.



STEVE:  Ah.



LEO:  Is that true?



STEVE:  5683 on a phone pad?  I don't have one near me.



LEO:  Don't you have that memorized?  Apparently somebody on my staff does.



STEVE:  I'll bet that's the case.  And, okay, how about 0852?



LEO:  0852, what's that?



STEVE:  "0" doesn't have anything, that's just operator.



LEO:  Huh.  Is it going up?  Yeah, it's going up.  It's going up.  So, see, if you look at it, that's the key.  If you look at it, 2580 is going straight down the middle, and 0852 is going straight up the middle.  That's why.



STEVE:  Okay.  And then we've got 2222, 1212, and 1998.  And it was interesting, they did a breakdown of the 1900s.  And it looks like people are using, based on demographics, the expected demographics of iPhone owners, they're using, like, their graduation dates, or maybe their birthdates.



LEO:  Or maybe the current year, and it just happens to be that that's the one that's been around the longest; right?



STEVE:  Well, no, because we haven't had iPhones...



LEO:  Oh, wait a minute.  You're right, it would be 2007 that it came up.



STEVE:  So there's a huge peak, like in the late 1990s.



LEO:  It's 22 year olds.  There are a predominance of 22 year olds or 23 year olds on iPhones.



STEVE:  Probably year of birth.  And then there's been some news about Bitcoin which I wanted to share just because it's sort of interesting to see what's going on with Bitcoin.  The largest bitcoin holder has, or had, well, I'm not sure because there was a break-in.  Someone lost their bitcoins.  You and I were talking about it before we began recording the podcast.  I heard that it was a half a million dollars' worth.  I don't know when that was because bitcoin currency exchange rates have been fluctuating a lot lately.  But the largest bitcoin holder has 297,000 bitcoins.



LEO:  Wow, that's a lot.



STEVE:  That's a lot of bitcoins.



LEO:  I mean, at what, 20 bucks a pop?



STEVE:  $31 last week, $9.2 million worth of bitcoins.



LEO:  If you could find somebody who would buy it.



STEVE:  Well, but there's an active brokerage.  Now...



LEO:  Yeah, but I doubt you could unload 200,000 bitcoins on it.



STEVE:  Well, okay.  Here's some stats.  The MtGox.com exchange, which is the largest bitcoin exchange, has been charging 0.65 percent as a brokerage fee.  A few months ago, that was only minting it pennies a day.  Last Wednesday it was making $40,000 a day.



LEO:  What?



STEVE:  There's that much bitcoin transaction.  In one day, $2 million of bitcoins were traded in 5,871 transactions.



LEO:  That's surprising.



STEVE:  So this is really going on.  Now, what did happen was that last Friday Bitcoin suffered its first depression.  It was called "Black Bitcoin Friday."  At the opening of the day, bitcoins were trading at $28.91.  By midday that had dropped to $20.01, a drop of 30.8 percent over the course of half a day.  And I have to say, I mean, I talked about it last week.  We noted that I have 50 bitcoins, and at $30 each, that was 1,500 bucks.  And I was tempted to say, huh, maybe now would be a good time to cash in my 50 bitcoins.



Well, apparently I wasn't the only one to think so.  I did not cash them in.  I still own those 50 bitcoins because it'd be kind of fun to see what happens.  But many people must have decided that, whoa, 30 bucks a bitcoin?  I'm taking my money out of this.  And so of course the consequence was it drove the price down over the course of a day.  So it'd be fun to see where it goes in the future.  But, I mean, it really is happening, Leo.  I mean, money, serious money...



LEO:  According to Mt Gox, it's currently 19 bucks, I think.  So you should have sold.



STEVE:  Well, who knows where it's going to go?  We'll see.



LEO:  But this shows how much speculation is going on.



STEVE:  Well, speculation and trading.  I mean, people, if you're trading $2 million a day and nearly 6,000 transactions, I mean, there's actual money that is being exchanged anonymously, as it was designed to be, through bitcoin.



LEO:  Yeah.  I think it's when it's this volatile, I have a feeling that's a sign of speculation.  Of course, as soon as it hit the low on Black Friday, it peaked up almost to its all-time high as people bought them up.



STEVE:  Bought them up again.



LEO:  Then there was a minor selloff, back up, a bigger selloff, back up, and now it's kind of stabilized right around 20.  It's interesting.



STEVE:  Yeah.  Okay.  So the most controversial SpinRite testimonial we've ever had.  I think I'm going to leave this anonymous.



LEO:  Okay.



STEVE:  Because he didn't ask me to, but I think I should.  So the subject was "SpinRite rescues some pictures, and a question of etiquette."  This was sent from Daventry, England on the 27th of May.  He says, "Hello.  I'm a regular Security Now! listener, and I'd like to share this story with you.  I'm always on the lookout for broken computer parts.  When a friend's laptop broke down, he asked me if I wanted it, which I did.  In the conversation he told me he was a little depressed as there were lots of unbacked-up photos on the laptop.  He had done 'everything,' in quotes, to try to rescue the files, but he had lost all hope of recovering them."  Well, we know where this is headed.



"I wondered if 'everything' included SpinRite, but decided against asking as I didn't want to depress him or get his hopes up.  Instead, I gave the laptop to a friend, a fellow Security Now! listener, and asked him to try his copy of SpinRite on it.  Next day he reported that it worked, but warned that the disk was not long for this world, and I should make a backup while I still can."  Which of course is one of the things that SpinRite will tell you.  "Buzzed for a chance to be the hero, I booted the laptop up and prepared to copy the files onto a USB hard disk.  Not knowing where his pictures were, I browsed into the My Pictures folder and found myself looking at some very pornographic pictures of my friend and his wife."



LEO:  Whoa [humming].



STEVE:  "I quickly made a copy of the files..."



LEO:  Yeah, close your eyes and move on.



STEVE:  Uh-huh, "...slightly embarrassed at what I saw.  He must have been really convinced the contents were gone for good."



LEO:  No kidding.



STEVE:  "Now I'm not sure what to do.  He didn't ask me to recover the files, but I know he really wants the pictures back."  I guess those he can make some more, but probably other pictures, too.  "If I give him a copy, he'd know I must have seen them.  Any advice?"



LEO:  Yeah.  Hmm.  That's one for The Social Hour.



STEVE:  That's a tricky question.



LEO:  Dan Savage, maybe.  Boy, I don't know, that's a really interesting question, isn't that.



STEVE:  It's an ethical dilemma.  SpinRite recovered the pictures, which were believed to be long gone, and, ooh.



LEO:  It worked too well.



STEVE:  Yeah, there was a reason that drive was overheating.



LEO:  All right, Steve.  We are ready to get underway here with Ghostery.  I have installed it, and I'm going to sites and shocked.



STEVE:  Well, I'm really impressed with it.  It's a free add-on for IE, Firefox, Safari, and Chrome, so all the major browsers on all the major platforms.  I used it over on a MacBook Air yesterday and on my PC today.  And what it does is it is watching the web pages that are watching us.  And in a very innocuous, just sort of "oh, by the way" fashion, shows users who visit sites what third parties are tracking them.



So, for example, I go to MSNBC.com.  And in the upper right-hand corner of my browser window - and that's user configurable, you're able to change how long the window stays there.  If you click it, it disappears immediately.  Also where it pops up, so there's plenty of configuration settings.  But MSNBC.com, if I hover over the toolbar tool, it says "7 trackers found on this page, and 7 blocked."  And then it lists them:  DoubleClick, DoubleClick Spotlight - yeah, because DoubleClick didn't have me in enough of a spotlight already, so we got the second, DoubleClick Spotlight.



LEO:  These are ad trackers.



STEVE:  Yup.  Insight Express, Microsoft Atlas, MSN Ads, Omniture, and Pulse 360.  Now, what I like about this - well, I like everything about it.  I recommend it for anyone who's curious.  I mean, even just run it for a while just to sort of see what's going on.  It's just really innocuous.  And the blocking is optional.  But if people want to use it for tracking blocking, you absolutely can.  when you install it, it asks you three questions.  It asks you if you want to enable GhostRank, which is disabled by default, that is, so that's opt-in.  And it explains that enabling GhostRank will allow you to anonymously participate in an information-gathering panel designed to improve Ghostery performance and create a consensus of advertisements, tracking beacons, and other page scripts across the web.  The data collected is used only in aggregate, contains no personally identifiable information, and will never be used to target advertising.



Now, I did enable it.  And one reason I did is one of the things that they'll show you, and I'll explain where here in a second, is, for example, what sites have these particular trackers.  So, for example, you're able to drill down and say, okay, what's Omniture, and get a really nice, very even-handed description of all of these things.  And you can get that by clicking on the Toolbar button.  Then it'll relist for you everything that it found.  And from there, there are submenus where you're able to go in and bring up a page from Ghostery's own directory that explains in very good detail what's going on, what the company does, what their policies are, what informative it is that they collect and so on.  And on that page it also shows, for example, here's a bunch of the sites which have this.  Well, the only way they know that a bunch of these sites have it is if the users of this product allow their browser to send that information anonymously back to the Ghostery folks.  So anyway, I turned it on.



So this continues to say, "When you encounter a script and have GhostRank enabled, Ghostery sends a record that includes the following:  the page elements identified by Ghostery; the elements blocked by Ghostery; the number of times the element has been identified; domains identified as serving those elements; advertisements served at particular domains, including companies associated with each ad; the information about the type of notice associated with each ad; the browser in which Ghostery has been installed; and the Ghostery version number."  So that's something you do not have to do.  But if you do, it increases the accuracy of their database.  So I liked the fact that it was opt-in.



The next feature, after you select that, enables an "alert bubble," as they call it.  It's that little window that I talked about which pops up, which I enabled.  Again, you can disable it later.  You can change how long it stays up.  And I think it defaults to 10 seconds, or maybe 15 by default.  So you're able to just sort of glance at it.  And if nothing else, you can see how long it is quickly because some sites only have a couple; some look like a dictionary of every nightmare that you ever saw.  And then they maintain this notion of "web bugs," which are all the little either ads or tracking beacons or bugs.  And when I installed it, there were initially - it knew of 518 different companies that they had encountered who were installing these on my machine.  And out of that 518, 345 also were planting cookies on my machine.  So not all, but certainly the majority.



LEO:  It's really nice to have that information.  But what you'll find immediately is that many, many, many sites have this stuff on there.  I was just looking at TWiT.tv because I didn't know what we use, and we only use one thing, a little "Add This" button.



STEVE:  Yes, I did see that.  I went to TWiT.tv also and saw that.  And, yeah, it's just, I mean, it's sitting there on the side.  It's not in your face.  I mean, it does proactively block.  And in fact, in one of their early blog postings, a user asked the question, "Does Ghostery stop the tracking process?"  And I really liked their response.  They said, "It's an option, but most of our users like to allow some page elements and disallow others.  The free content on the Internet is paid for largely by advertising, and data collection is part of that.  We don't want to deprive publications or advertisers of their revenue.  That would be bad for the content on the web.  But we do want our users to know who is collecting their data and control it wherever possible.  How much data collection a person will tolerate is up to them.  It's their own subjective decision, and we would never try and make that on behalf of others."



So this is very comprehensive.  For example, I went to their own blogging service - they use a third-party blog.  And I thought, well, who's - and when I went to that page, up came the little balloon window that had three entries.  It had Facebook Social Plug-ins.  It had something called New Relic, and then Twitter Button.  And so I'm able to explore into those by using the toolbar.  And I should remind people that that isn't made visible, the toolbar button is not made visible automatically, at least in Firefox.  I had to right-click on the toolbar and then hit Customize and then drag the little ghost, it's a little ghost icon, looks a little like a blue Casper, up onto the toolbar.  And it has a nice presentation under Safari and Firefox on the Mac.



And the button, even though the little balloon goes away, there's a little sort of highlighted number on the button to sort of remind you, you can just look, and I remember seeing a "7" when I was on MSNBC because there were a total of seven different things that were tracking me on MSNBC.  So you're able to, by company, you can enable or disable all of those cookies and tracking.  And then separately you're able to whitelist individual domains where you want to allow all of that to go on.



Now, the one caveat for people who are NoScript users is that many sites use their scripting in order to bring their third-party trackers onto the page.  So if you are already blocking a page with NoScript, then NoScript has prevented the tracking activity, and Ghostery won't see it.  So I found that sites I'm not trusting, Ghostery will see some things.  If I then deliberately trust them, Ghostery will see more, meaning that the scripts which I'm then allowing to run are responsible for exposing these additional trackers.  So there is some interaction between NoScript and Ghostery.



But overall, I just think it's a great little app.  I played with it for a while.  I poked around.  I'm going to run with it now on my browsers.  I know there are people who just wouldn't be into this at all, they're just going to use the web and not worry about it.  There's another class of people who might want to be informed, but not block because it's just sort of additional information.  And it's the kind of thing you might want to use for a couple of months and then decide, okay, now I have an intuitive sense for how much of this is going around.  Or there are certainly another class of people that like the idea of just flatly blocking everything, even on sites that they trust with NoScript.  So that's one way that these two work nicely together.



I normally am trusting MSNBC.com.  I've got that permanently allowed in NoScript, which is why I'm seeing all seven of these things come up and track me.  But I want to block the tracking, thank you very much.  So Ghostery allows me to do that.  So I think it's just an across-the-board cool little add-on for our browsers - multiplatform, multibrowser.  It's out of the way.  You can uninstall it later if you get tired of the information, or you can leave the tracking enabled and disable the popup balloon.  And then all you get is the little number on the little Casper ghost on your toolbar, if you decided to have the button there.  But it can also operate as a completely invisible blocker of all these web bugs, 557 of them at last count.



LEO:  What page has the most that you've ever seen?



STEVE:  I think MSNBC might be up there.



LEO:  Oh, I could beat that.



STEVE:  What's Disney.com look like?



LEO:  Yeah.  I just went to a nonprofit site.  I was looking up a Senate bill we're going to talk about on TWiG this week.  It had 17.  GovTrack.us, which is a great site, has 17 on there.  So, yeah, that's a good question.  Let's see what Disney has.  I think what might surprise you is that - and this is probably why it's fun to just browse around with this turned on for a while, just to see what you could see - is that you may be surprised by the number of sites you wouldn't expect.  Wikipedia, as far as I could tell, had none, which was good.



STEVE:  Yup.  I did go to Wikipedia, and it was a big zero, which is just beautiful.  So that site is pulling revenue from those 17...



LEO:  Not necessarily.  I mean, a number of these - Comscore Beacon, Google Analytics, Quantcast - are merely measurements.  They want to see tracking.



STEVE:  And Google Analytics, by the way, is all over the place.  I had a hard time finding a site that didn't have Google Analytics on it.



LEO:  And we use that.  Facebook Connect is designed to make it easier to log in.  But then there are a number of ad networks.  You know, it's interesting, Disney only seems to have two.  Microsoft Atlas...



STEVE:  I see that a lot, too.  What the heck is that?



LEO:  Well, I wonder if that's a - it's an ad center.  So it's another - it's a Microsoft ad system.



STEVE:  Okay.



LEO:  You're going to see a lot of these.  I mean, let's face it, the Internet is free.  And that's often how you pay for a site.



STEVE:  Well, again, it's one thing to see the ads, and another thing to have information sent back.  And Ghostery does follow up.  I mean, if you, like, click on Omniture and dig down, it'll say this is the information that they're collecting, and it'll give you a link to their privacy policy.  I mean, so it really allows you to do some research beyond just enumerating how many things have been loaded on there to follow you around the Internet.



LEO:  Happy to say EFF.org, which you would think would not have a lot of privacy intrusions, has zero.



STEVE:  Nice.



LEO:  That's how it should be.  It's kind of interesting.  You get to be the judge.  That's the point.  This is information that you can use and you should use and be aware.



STEVE:  I think it's very nice browser instrumentation that can be used to block, to inform, to entertain, and also to educate a lot because, I mean, there's no doubt that users, our listeners, are going to be interested in this, are going to install it, and are going to spend some time digging down, saying what the heck is this company?  Pulse 360, okay.  And then decide, yes, I like that; or no, let's keep it on the block list.  Because you can tailor this exactly the way you want to, also.



LEO:  People are asking about live.twit.tv.  We have three trackers on there, and all of them are used to - actually I don't know why we have AdWords on there.  I don't think we use AdWords.  But we do have Google Analytics and Quantcast on there.  And those are - I think Chartbeat's on there, too.



STEVE:  Well, so that's kind of cool, too, because now that reminded you that maybe you should remove the AdWords script.



LEO:  Yeah, why is AdWords on there, yeah.  I don't think we use that.  Maybe that comes with Analytics, I don't know.  And we use Quantcast.  And I thought Chartbeat was on here, as well, which is another monitoring service, because it's a way we have of - yeah, there's Chartbeat.  It's a way we have of...



STEVE:  There's that little...



LEO:  Actually that's all we have is Chartbeat, Google Analytics, and Quantcast.  Those are the three that are on there.  And that's all traffic measurement.  Now, some of them do leak information.  Some of them don't have a policy about that, and so that's - maybe this will also stimulate people to update their policies.



STEVE:  That would be great.



LEO:  Yeah, yeah.  Good stuff.  I like this plug-in.  Steve, we're done, I guess, I gather.



STEVE:  We're done.



LEO:  A great show, as always.  If you want to know more about all of these topics, the place to go is Steve's website, GRC.com.  That's where you'll find, of course, a copy of the great SpinRite, the world's finest hard drive maintenance and recovery utility.  You'll also find lots of freebies that Steve gives away, and a place to ask questions of Steve that we use on every other show.  In fact, next week is a feedback show, so GRC.com/feedback for that.  Also his Password Haystacks article from last week, that was great, or two weeks ago.  That was great stuff.



Show notes, 16KB versions, full transcripts of all 305 shows, it's all there, GRC.com.  We do this show every Wednesday morning, 11:00 a.m. Pacific, 2:00 p.m. Eastern, that's 1800 UTC, at live.twit.tv.  And you can watch us live, or you can get the show after the fact at Steve's site or TWiT.tv/sn.  Steve's on Twitter, @SGgrc, that's the place to go.



And don't forget, we are still selling bricks.  In fact, we're getting close.  I think we're about a month off from moving into the new studios.  And if you want to have a brick on the wall with your name, your Twitter handle, your Facebook handle or whatever, just go to bricks.twit.tv.  That Wall of Honor is looking so cool.  Literally, the honor's all mine.  It's really amazing.  Bricks.twit.tv.  Did you get one, Phil?  He wants to buy one.  All right, he's giving me a credit card.  I can't take credit cards, but we'll figure that out.



Hey, Steve, thank you so much for being here.  We really appreciate it.  And we will be back next week, same time, same channel, for more security news on Security Now!.  Bye bye.



STEVE:  Thanks, Leo.



Copyright (c) 2011 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




