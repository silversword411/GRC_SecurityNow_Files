GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#1020

DATE:		April 8, 2025

TITLE:		Multi-Perspective Issuance Corroboration

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-1020.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  Canon printer driver vulnerabilities enable Windows kernel exploitation.  Astonishing cybersecurity awareness from a household appliance manufacturer.  France tries to hook 2.5 million school children with a phishing test.  WordPress added an abuse prone feature in 2022.  Guess what happened?  Oracle?  Is there something you'd like to tell us? Utah's governor just signed the App Store Accountability Act.  Now what?  AI bots hungry for new data are DDoSing FOSS projects.  No Microsoft Account?  No Microsoft Windows 11.  Gmail claims it now offers E2EE.  It kinda sorta does.  Somewhat.  A dreaded CVSS 10.0 was discovered in Apache Parquet.  A bunch of terrific listener feedback.  What's Multi-Perspective Issuance Corroboration, and why must all Certificate Authorities now do it?



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about, including a 10.0 CVSS score for a problem in Apache Parquet.  French schoolchildren are not gullible, it turns out.  The French government tried to trick them and failed.  And then we'll find out what multi-perspective issuance corroboration is and why you might need it.  That and a whole lot more coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 1020, recorded April 8th, 2025:  Multi-Perspective Issuance Corroboration.  It's time for Security Now!, the show where we talk about your safety, your privacy, your security, and a bunch of other stuff that geeks are interested in with this guy right here, I think you officially are the King of Geeks, Steve Gibson.



STEVE GIBSON:  I would wear that badge proudly, Leo.



LEO:  Wouldn't you?  Yeah.



STEVE:  Yes, I would.



LEO:  You have earned it over the years, now 70 of them.  Congratulations.  That's amazing.



STEVE:  We had a listener who had a T-shirt made and sent me a photo, "Just Say No to Port 80."



LEO:  I love it.  I love it.



STEVE:  From last week's podcast.  Which reminded me, I had some made a while ago that just said "Born to Code."



LEO:  Yes.



STEVE:  Because I put on - I make a fresh cup of coffee, put on some quiet music, sit down in front of my computer, and, like...



LEO:  It's the best, isn't it.



STEVE:  Some problems to solve.  It is my happy place.



LEO:  Me, too.



STEVE:  There's, like, nothing like it.



LEO:  Yeah.



STEVE:  That is just - that's it.



LEO:  I get sad when I hear about Vibe coding and AI replacing engineers because I think it is, independent of whether it's a useful economic exercise, a wonderful, fun thing to do.



STEVE:  A buddy of mine sent a link yesterday to a blog post.  There's a guy named, I think it's Ken Schiff, but that sounds like it's, like his last name, I've shortened it.  Anyway, he's been - he, like, pops the lids on Intel chips, Intel processors.



LEO:  Oh, wow.  Oh my god.



STEVE:  And then takes photomicrographs of the chip and then reverse engineers the circuitry.  And this particular blog posting was about the times three multiplier hardware in the Pentium that was like, they had like a dedicated strip of silicon that was for multiplying by three.  That's all it did.  And then it was like, okay, why is there a hardware times three multiplier?  And actually it's not difficult to multiply by three in binary, right, because you just shift over by one, and sum.  But it turns out that they don't do binary multiplication.  They do base 8 multiplication in the hardware.  It's like, what?



LEO:  What?



STEVE:  Anyway, so this guy has just gone so into this.  And so I read the blog posting, and I thought, you know, this kind of thing, the designers of that never were understood.  They didn't get credit for it.  I'm sure they were working within a small community of just incredible silicon design wizards.  And hopefully that was all they needed.  But there's just - there's like this incredible wizardry in stuff back then.  And it does feel like those days are leaving, sort of like turning coding over to AI.  Unfortunately, coding makes so much sense for AI because it is so rigorously logical and so complex.  And you should be able to say to an AI, does this do what I want?  And it would just say, no, not even close.



LEO:  Well, you know, it's a computer talking to a computer.  Of course it kind of makes sense that a computer would do that well.



STEVE:  Yeah.



LEO:  But at the same time it's, you know, people in grade school, I know everybody said, well, what am I learning, you know, algebra for; right?  I'm never going to use algebra.  It's not about the algebra, it's about the pleasure of it and kind of the formal reasoning, which is a great thing to learn.



STEVE:  Right.



LEO:  I think everybody - I think coding should remain in the curriculum, even if it's not something you end up using.



STEVE:  Well, and teaching math is much the same way.  It's just it's good for your brain.



LEO:  Yeah, yeah.



STEVE:  To think, you know, in abstractions some of the time.  Which is why we have this podcast, Leo.  This is Security Now! Episode 1020.



LEO:  Wow.



STEVE:  For Patch Tuesday.  We actually have a picture that is apropos.  I think you're going to enjoy it when we get to it.  Today's title, I wasn't sure it was going to fit.  Actually it strained the margins of the show notes.



LEO:  It's a little long, and also a little obscure, I might add.



STEVE:  It's very obscure, yes.  And it wasn't until my own description of the backstory behind this grew that I thought, well, this is our topic for the week:  Multi-Perspective Issuance Corroboration, MPIC.



LEO:  Okay.



STEVE:  And why, as of the middle of last month, the CA/Browser Forum, you know, the people who manage the certificates, the issuance and the consumption for web browsers, why they unanimously voted to require themselves to do this:  Multi-Perspective Issuance Corroboration.  So this is a big change that just happened in the requirements for issuing web browser certificates.  Which we're going to get to after we look at Canon printer driver vulnerabilities enabling Windows kernel exploitation, and the astonishing cybersecurity awareness which has been shown by a household appliance manufacturer.



A listener pointed me to this company, I think they're Australian, or maybe they're - I don't remember where they are.  Yeah, New Zealand, maybe?  Anyway, unbelievable that they have a page because they're into connection and connected appliances, they understand what their obligation is if they're going to do it, like none other.  Also, France tried to hook 2.5 million schoolchildren in a phishing test.  We're going to look at the results of that.  WordPress three years ago added an abuse-prone feature.  Any guess what happened?  Oh.  And Oracle, is there something you would like to tell us that you have not so far?



LEO:  Got to keep it a secret, just between us.



STEVE:  Yeah, some problems over there.  And they're like, what?  No.  Nothing to see here.  Just, you know, what's that big lump under the carpet?  Don't worry about that.



Utah's governor just signed the App Store Accountability Act into law.  We've talked about the legislation passing through their lower bodies.  It's now law in Utah.  Now what?  Also it turns out that AI bots hungry for new data are inadvertently DDoSing FOSS projects.



LEO:  Yeah.  This is a problem, yeah.



STEVE:  Wow.  Also, no Microsoft Account?  No Microsoft Windows 11.  A change has been made to the Dev Channel, coming soon to your next Windows 11 installation.  Also, Gmail claims it now offers end-to-end encryption.  Well, it kinda sorta does, somewhat.  It is the definition of a hack, and we'll talk about it.  Also, a dreaded CVSS 10.0 was discovered in something called Apache Parquet.  Not good.



LEO:  Butter.  Oh, sorry.  Sorry.  I've been programmed.



STEVE:  But 10.0, everybody, so that's as bad as it gets.  We've got a bunch of listener feedback.  Believe it or not, I had time for that, too.  And then we're going to look at what is Multi-Perspective Issuance Corroboration, and why must all Certificate Authorities now do it?  And of course we've got a great Picture of the Week.  So I think maybe, Leo, this podcast will finally be a good one.



LEO:  Finally, after 1019 episodes.



STEVE:  I think we've got the hang of it now.  There are people who...



LEO:  You know, Sunday you should stop by and say hello.  Our 20th Anniversary TWiT is this Sunday, after 20 years.  Patrick Norton's going to come by.  Sam Abuelsamid will be on, Allyn Malventano, and we're getting videos from all of our viewers.  I've been asking everybody if you want to share your memory of the first time you saw TWiT or the first time you saw me and Steve, maybe back in the Screen Savers days.  Share a video with us.  We've got a lot of them.  It's going to be a lot of fun.  That's on Sunday.  Can you believe it?  Long time we've been doing this, Steve.



STEVE:  Well, and I asked Benito, I said, I thought that the number of Sundays TWiT was 1027.



LEO:  It is, I think.



STEVE:  And today is 1020 for us.  So Security Now!...



LEO:  We're just a little ahead.



STEVE:  ...only started seven weeks later.



LEO:  You're right.  Well, maybe because you never stop.  You know, for the first 15 years you wouldn't even take the Christmas holiday off.  So, and maybe we missed...



STEVE:  It was that tattoo.  That did it.  I thought, okay, I'm quitting Christmas from now on.



LEO:  There might be a few day - but, yeah, roughly seven weeks later.  It was very quickly after it, yes, yes.  And you're coming up on your 20th; right?  When is that going to be?  Do we know?



STEVE:  I don't know.



LEO:  August, I think, yeah.



STEVE:  Yeah.



LEO:  Twenty years.  I don't feel that old.  I really don't.  It doesn't, you know, we started doing this in our late 40s.



STEVE:  What's cool is that we have really been on the podcast through huge changes in the industry.



LEO:  Yeah.



STEVE:  I mean, like, you know, viruses moving from one person's thumb drive to the next, or computer to computer.  I mean, that was a thing.  And, you know...



LEO:  There's a great movie just came out called "Black Bag."  I don't want to spoil it.  It's Michael Fassbender and Cate Blanchett, and you should watch it.  Have you seen it?



STEVE:  No.



LEO:  But the only reason I mention this is there's a moment when they're talking about this exploit that is a deadly exploit, and they said it's based on Stuxnet, and we've designed it for air-gapped computers.  And I was thinking, man, they must listen to Security Now!.  It was a really - it was technically a really great moment in that movie.  It's a fun spy movie.  But, you know what, that's one of the things, I think, maybe you could take a little bit of credit for.  Hollywood is a little more savvy in the content, the computer content that you see onscreen.



STEVE:  Been very impressed with what they're doing now.  I just think that it's percolated down into the culture.



LEO:  The people who are writing this now are part of the...



STEVE:  Or they actually know we need to get a tech guy to, you know, help us with the script.



LEO:  Yes.



STEVE:  And so there's some script polishing going on.  There was a series, and I meant to mention it, except it wasn't that good, but it was about prime factorization.



LEO:  Yes.  I was going to ask you - I haven't watched it.  I was going to ask you about it.



STEVE:  Yeah, it was worthwhile.  The premise was that it was known that our security industry, our security infrastructure understood that it was possible to factor primes.  So they didn't want it to be made public, so they were spying on all the top mathematicians who were working in the field that might stumble upon this.  And so anyway, it was, you know, I mean, again, that's where I was thinking, wow, they got a lot of this right.



LEO:  I was ready to lambast them.  I thought, this is going to be terrible.  But good, that's good to know.



STEVE:  Well, there were some things that were not correct.



LEO:  Okay.



STEVE:  They didn't actually say - it wasn't factorization, but it was primes.  They understood that something about primes.



LEO:  They understood primes were important.



STEVE:  Something about primes.  Oh, it was patterns in primes.  It was some guy was like, oh, he, like, figured out like a pattern in primes.  But it turns out that this - so this was a conspiracy to keep this from being...



LEO:  Keep it quiet.



STEVE:  ...discovered, to keep it quiet, that went back decades.  And so anyway, it was - I would say it was fun.



LEO:  And you and I both watched Robert De Niro's "Zero Day," which also had some technical accuracy in it.  So, you know.  They're getting better.  Anyway, time to take a break.  Nothing but technical accuracy just around the corner, and our Picture of the Week.  But first...



STEVE:  Also technically accurate.



LEO:  Yes.  Is it?  Oh, good.



STEVE:  Uh-huh.



LEO:  I haven't looked yet.  All right.  I like to save it for the show.  All right.  Let us go back to the show and Steve Gibson's Picture...



STEVE:  You know, those .security domains cost $2,500 a year.



LEO:  Oh, you looked at it, I bet, yeah.



STEVE:  And I don't think that's in keeping with the founders' intent for the way the Internet would work.



LEO:  That's expensive.  Yeah, these custom emails really, you know.  But on the other hand, they're nice.  Like I have Leo.pizza.  And I think if you wanted to...



STEVE:  Well.



LEO:  All right.  Let's look at the Picture of the Week, Mr. Gibson.  I'll scroll up here.



STEVE:  This one I gave the caption "Making the Switch from Windows to Linux."



LEO:  I'm trying to understand it.



STEVE:  Apropos of last week's podcast about the EU OS.



LEO:  If you scroll all the way up you get it a little bit better.  Okay.  Broken telephone pole.



STEVE:  Ah, yes.  And again, this just - these pictures beg so many questions.  So for those who can't see, we've got a buckling, broken telephone pole that some hapless lineman has tried to keep erect with duct tape.



LEO:  Oh, my god, duct tape's keeping the world together, yes.



STEVE:  It looked like maybe there's some sticks on the outer side that were used...



LEO:  Like splints?



STEVE:  Some splints, exactly.  So it was, like, splinted, and then duct taped - the splints were duct-taped to the pole, just trying to keep it up.  But then over to the right we see the one that I've labeled Linux which has like a new pile of dirt at its foot.



LEO:  It's the replacement pole, clearly.



STEVE:  Exactly.  It must be the - and then I don't know why there's little rope strung between the two.



LEO:  That's the funniest thing.  I don't understand that, either.



STEVE:  It's like a leash.  It's like, don't go away, boy.  Stick close.



LEO:  That is the funniest thing ever.  Duct tape, man, it holds the world together.



STEVE:  It is, yes, exactly.



LEO:  Wow.  And Windows is the duct-taped solution, and of course the brand new, perfectly formed pole is Linux.



STEVE:  That's right.



LEO:  I like that, Steve.  Thank you.



STEVE:  That's right.  It's one of the expressions we have around the house when one of us wakes up and something is stiff.  We say, oh, get the duct tape.



LEO:  Really.  Okay.  I'm not sure, that was maybe a little too much information.  That's good.



STEVE:  Oh, like a stiff muscle is what I meant.



LEO:  Oh, sore.



STEVE:  Like a shoulder.



LEO:  Sore, yes, Steve.



STEVE:  Like a stiff shoulder.  Sorry.  Whoops.



LEO:  Of course.  Get the duct tape.  You never know.



STEVE:  That's right.



LEO:  I have a vision of you duct-taped to the bed.  Okay.  So maybe that's not...



STEVE:  Okay.  So the Microsoft Offensive Research and Security Engineering - this is one of those reverse engineered acronyms.  The abbreviation is MORSE, M-O-R-S-E, Microsoft Offensive Research and Security Engineering.  They've identified a crucial security vulnerability within a range of Canon printer drivers - Canon, you know being a leading, very popular printer - which threatens users across, well, anybody who's using that printer who would be a target.  The vulnerability could reportedly allow malicious actors to compromise printing operations and, in severe cases, execute arbitrary code on affected systems.



We did a podcast years ago that I thought was one of our better ones, where we looked at the threat that something as innocuous-seeming as a network printer in an enterprise could pose, because it was discovered that Advanced Persistent Threat actors were actually setting up shop in enterprise's printers, which were not being scanned.  You know, they didn't have Windows Defender running on them.  It was just a printer.  But it turns out, you know, it's a computer, probably running Linux of some flavor.  And they were able to just stay ensconced inside this printer for quite some time.



Anyway, this has a CVSS - the concept of a printer driver in this case, not the printer itself, but the printer driver in a Windows system - has a CVSS score of 9.4.  As we know, that's a high-severity risk.  That's up at the high end of the scale.  And it has a 9.4 due to its lack of complexity.  Very easy to leverage the bugs in these Canon printer drivers.  You do not need any elevated privileges to use it, nor any user interaction.  The potential for high-impact compromise of confidentiality is there.  So 9.4.  It provides a path to deliberate memory corruption during the EMF Recode processing, which is something that the printer driver does.  Probably EMF is Enhanced Metafile, I'm pretty sure.  And unfortunately, this opens systems that do not use Canon printers to the infamous BYOVD attacks, where BYOVD is short for "Bring Your Own Vulnerable Driver."



The problem is, these vulnerable Canon printer drivers were originally signed by Microsoft.  You know, Microsoft blessed them, allowing them to then to be loaded without a second thought into Windows.  So they can't be altered at all, or that would break the signature, and then Windows would refuse to load the driver into the kernel.  No need to alter the driver because it's buggy, and now the bugs have been found.  So malware can bring along one of these flawed Canon printer drivers, drop it onto the system, get it loaded into the kernel, and then leverage the flaw in order to take over the system.



When an entity has Canon printers, they're there by default, across a variety of printers including their production models, home and office automation multifunction printers, and laser printers.  So all that a malicious application needs to do is cause a print job to be processed through the vulnerable driver.  That allows the attacker to gain control, you know, and have kernel-level access, which is to say root on the system.



Canon has acknowledged the issue and has promised to be releasing updated drivers as soon as they can.  So if you are a Canon user, that means your system already has these vulnerable drivers in it.  And, you know, the malware doesn't need to bring its own along.  So keep an eye out for any updates that the Canon offers.  You'll certainly want to make sure that you are receiving Canon's notifications of updates.  And I imagine that what will happen as soon as the new drivers are present, and given some opportunity for them to filter out into the ecosystem, is that before long Windows Defender and the other endpoint management, you know, third-party software will start explicitly looking for these known vulnerable drivers and say you really don't want to be loading this.



And that's the way the Bring Your Own Vulnerable Driver problem will get resolved is that, as soon as replacements are available, so that functionality isn't killed when the vulnerable driver is removed, then those drivers will just be blacklisted, and you won't be able to load them into Windows anymore.  So all this takes time.  And as we know, everything now is an arms race to see how much infiltration and how much damage can be done before the problem is resolved.



Okay.  I've talked about an astonishing home appliance company.  This was thanks to a piece of feedback that we received from listener David Morrell.  David wrote:  "Every home IoT device maker should follow the lead of this home appliance maker.  About the only thing" - and Leo, I have to say when I was looking at the site, I thought, oh, these look like appliances Leo would want.  I mean, they are really beautiful.



LEO:  Don't tempt me, Steve.



STEVE:  The company is Fisher Paykel.  Yup, you've got it up on the site now.  He said:  "About the only thing they could have added is advice to use a YubiKey or similar."  Meaning they really get it.  And he said:  "They really get it."  He said:  "And it even looks like you can buy these" - oh, they're New Zealand.  "You can buy these New Zealand-made home appliances in the U.S.  Personally, I'm quite happy not having IoT in my home appliances."



Okay.  So David's note made me curious.  I went over to the Fisher Paykel website.  It's F-I-S-H-E-R P-A-Y-K-E-L dotcom.  And I discovered that they have an entire page devoted to the cybersecurity of their well-connected appliances.



So to give everyone a sense for what's there on this home appliance maker's site, they wrote:  "We are vigilant about securing your connected appliance.  We understand that the security of our products is of the utmost importance to our customers.  We build appliances around these core security values."  The fact that they even know the term "core security values."



LEO:  They use WPA3.  That's all I needed to see.  It's like, wow, wow.



STEVE:  Like, astonishing.  It's like, and I have to say...



LEO:  There's a geek in there somewhere.



STEVE:  I have to say, Leo, I wonder if someone's going to be smiling when he hears me reading this because he's a Security Now! podcast listener.  I mean, because, like, I mean, some guy at Fisher Paykel because...



LEO:  It feels like it, doesn't it.  It's everything you would say.



STEVE:  It sounds like the guy's been listening to us.  The page says:  "Security is ingrained in our business culture and in the way we developed your connected appliance.  It's a business policy that security is built-in to every aspect of our process.  It's built-in during all phases of development, manufacturing, and maintenance.  Your appliance is secure without user configuration or specific router settings."



He said:  "Security by Design:  Security controls to protect appliance data, user authentication and authorization, and how the system will be securely maintained are integrated into the functional features of the appliance.  The software meets industry best practice coding standards" - who talks about the coding of their dishwasher? - "and is developed by the Test-Driven Development software method."



LEO:  Yeah, right on.



STEVE:  I mean, the guys must have like some nephew who's into serious security or something.  This is just amazing.  They said:  "Any third-party and open-source software is analyzed for security and the safety of your appliance and data.  Prior to deployment, the appliance undergoes extensive software security and performance testing.  Security penetration testing on the connected system and its components - the appliance, mobile app, and cloud - is done regularly post-deployment.  Software updates are released to ensure the appliance has the latest security code to protect your appliance and data."  I mean, I almost want to buy this stuff just to support these people.  It's amazing.



They said under Security by Default:  "Every connected appliance has all security features enabled when the appliance is first connected.  No special configurations or specific router settings are needed.  Your appliance connects to your WiFi router using the WPA3 network security protocol as standard, with WPA2 for backwards compatibility.  The appliance does this even if your router is not set to this configuration.  That's just one example..."



LEO:  So awesome.



STEVE:  "...of how Security by Default is engineered into your appliance."  And then, Defense in Depth:  "Every component of our connected appliance ecosystem has security controls that provide independent redundancy to protect against malicious attacks.  We ensure security controls are implemented in layers for data protection at rest and in transit."  I wish these guys made, like, some social networking software because we could give it to our government, and it would be way more secure than what they're using.



LEO:  Wow.



STEVE:  They said:  "This layered approach strengthens the security of our entire ecosystem.  We are continuously testing and reviewing the security systems.  If needed, these layers can be updated and improved by software updates."



And for Transparency:  "Our security controls and methodologies are industry standard.  Our goal is to communicate our actions with openness and accountability.  We are industry leaders in IoT security and promote transparency to help educate our customers.  Reach out to us if you have any questions or concerns.  Please see below under our ratings section for current evaluations of our appliance products."



LEO:  They look pretty darn good, you're right, Steve.  And you can buy them in the U.S.



STEVE:  Oh, they're gorgeous.  I mean, the equipment is beautiful, Leo.



LEO:  Yeah, yeah.



STEVE:  I mean, the people who did the industrial design are friends with the people who did the security design.  I mean, it is topnotch.



LEO:  Look at that, yeah.  Also top prices.  $15,000 for an oven.



STEVE:  Oh, but honey, it'll sing you to sleep.



LEO:  I have Internet connectivity on my oven.



STEVE:  Of course you do.



LEO:  The only value at all is it will tell you when the oven's preheated on your phone, say "Hey, your oven's ready."



STEVE:  Go put your roast in.



LEO:  Go put your roast in.  It's ready.  That's it.  Door's open.



STEVE:  Industry leaders in IoT security.  Actually, we could use that for our refrigerator.  Luckily, our refrigerator sounds an alarm.



LEO:  Beeps at you.



STEVE:  Lorrie just walks away.  I don't know what's going on, but like, honey, you know, not only are the lights on, but the refrigerator's open.



LEO:  Yeah, yeah, I've done that, yeah.



STEVE:  So anyway:  "Reach out to us," they said, "if you have any questions or concerns.  Please see below under our ratings section for current evaluations of our appliance products.  We ensure these best practices are applied to your appliance and its IoT ecosystem through regular penetration testing.  We work with ethical hackers and security researchers to evaluate the security of your smart appliance and system through third-party evaluations."  It's just astonishing.



And then they said, under Our Ratings:  "We are proud to have achieved the Gold verification level for UL's (Underwriter Laboratories) IoT Security Rating."  I didn't know Underwriter Laboratories did IoT security rating.  "With thorough evaluations conducted every year since we first achieved this rating, we continually demonstrate Gold Level security capabilities that align with industry best practices."  This is an oven, folks.  This is not like a server or a router or, you know, or an endpoint security device.  This is somebody's microwave.  It's just...



LEO:  Unbelievable.



STEVE:  ...astonishing.  So anyway, props and a salute to  FisherPaykel.com.  And if anyone from there is listening to this podcast, congratulations.  Oh, and Leo:  "If you suspect that your appliance has been compromised, or you have identified a security vulnerability in one of our connected appliances, we urge you to contact our Appliances Security Incident Response Team."



LEO:  Holy cow.  Wow.



STEVE:  "At is@fisherpaykel.com."  And here it comes.  "Note:  We support PGP encryption using the Fisher & Paykel Appliances Information Security PGP Key."



LEO:  All right.  Now I'm going to give you the bad news.



STEVE:  Oh.



LEO:  It's a subsidiary of Haier, which is a giant Chinese multinational.  So, I mean, you know, maybe they could spread the word throughout the entire Haier ecosystem.



STEVE:  I wonder if they - they probably use open source, but don't publish their firmware.



LEO:  Yeah.  I mean, I think, you know, every - nowadays every - this company was acquired, obviously.



STEVE:  Yeah.



LEO:  Haier's a giant monster conglomerate.



STEVE:  Right, so they just sucked them up because they said these guys are doing it right.  We want...



LEO:  And they have got a high-end brand, right, yeah.



STEVE:  We want a piece of their action.  Boy, it's beautiful.



LEO:  Just as they have low-end brands, yeah.



STEVE:  Oh, and get this, Leo.  I just - I couldn't imagine.  After all that, they then have sort of an FAQ Q&A thing where they talk about to their customers how to enhance their security.



LEO:  Wow.



STEVE:  And they finish with "Separate Networks:  Security experts recommend creating separate and secure networks dedicated for your IoT devices" - which makes me think, are they listening to this podcast? - "that separate from your network used for banking or ecommerce activities, or that which handles your most private and sensitive data.  You can further segregate your networks based on the IoT device itself.  There are two methods for this when using one Internet connection:  using one router and setting up a 'guest access' or a 'guest network' within the router settings; or use separate routers paired with your Internet connection."



LEO:  Oh, they definitely listen to this show.



STEVE:  Incredible.  "If you choose to set up a guest network, ensure the password for the guest network is strong; and, if available, ensure that access to local network resources is turned off.  This may also be called 'isolate.'"  Anyway, I am utterly astonished by these people.  And it's a good thing this is April 8th and not last week's April 1st podcast because this would have made the best imaginable April Fools Spoof, since no one would ever believe that I hadn't made this entire thing up from scratch.  And Leo, if the rest of the world designed and built their equipment like these guys, it feels as though our job here would be done.



LEO:  That's impressive.  I wish all, yeah, I wish all IoT stuff was like this.  That's incredible.



STEVE:  Incredible.



LEO:  Yeah.  All right, Steve.



STEVE:  Okay.  So the French government recently conducted a large-scale phishing test targeting more than 2.5 million middle and high school students.  The bait was a link that advertised cheats and cracked games which instead redirected any students who were foolish enough to click on it to a phishing awareness video.  Now, what was interesting was, according to France's privacy watchdog, over 210,000 students did click the link, but that's only one in 12 students out of a population of 2.5 million.



LEO:  Impressive.



STEVE:  Yes, 8%.  And, you know, while, yes, 210,000 is a lot of individual students, they fared way better than the one-third click rate which is typically seen in corporate environments.  So the old folks in the corporations, eh, like, oh, I can get free socks for life?  Great.  But, you know, these kids are like, eh, I don't think so.  This looks like junk.  So congratulations.



As we've observed before, with 521 million websites built on WordPress - 521 million.



LEO:  That's mindboggling, yes.



STEVE:  It is.  It's like...



LEO:  It's almost half.



STEVE:  ...43.5% of all websites in the world are WordPress.  So its security, WordPress's security, is always a top concern.  So much of the Internet depends upon it.  So when, three years ago, in 2022, WordPress added a feature attackers could only dream of having, it's hardly surprising that it didn't take long for it to be abused.  WordPress's site describes this nifty new feature known as "Must Use Plugins,"  It's like, what?  What could possibly go wrong?, which is, you know, our rhetorical question.



They said, this is how they described this feature:  "Must-use plugins (a.k.a. mu-plugins) are plugins installed in a special directory inside the content folder and which are automatically enabled on all sites in the installation.  Must-use plugins do not show in the default list of plugins on the Plugins page of wp-admin, although they do appear in a special Must-Use section.  And they cannot be disabled except by removing the plugin file from the must-use directory, which is found in wp-content/mu-plugins by default.  For web hosts, mu-plugins are commonly used to add support for host-specific features, especially those where their absence would break the site.  Must-use plugins are always on, with no need to enable via admin, and users cannot disable them by accident.  They're enabled simply by uploading a file to the mu-plugins directory, without having to log in," even.



This, of course, as I said, is where we cue one of our favorite rhetorical questions:  "WHAT could POSSIBLY go wrong?"  Yes, you just have the file there, and WordPress won't show it to the admin, won't require you to be logged in to enable it.  In fact, you can't enable it.  It's always enabled.  And you can't disable it because they said, well, it would break the site if this plugin wasn't there, so we're just going to, if it's present in this directory, run it.  GoDaddy's Sucuri security team provides the answer to the question about what could possibly go wrong, and unfortunately that's not rhetorical.



To no one's surprise - except I suppose the creators of this very abuse-prone feature, I mean, they must be surprised, but, like, duh - hackers are now abusing this little-known WordPress feature to install and hide their malware from site admins.  According to GoDaddy's team, threat actors have been found to be abusing, to no one's surprise, Must-Use Plugins since at least February of this year.  And that abuse has recently grown worse.  It's like, hey, this works.  Let's use it everywhere.



Hackers are breaking into WordPress sites and dropping malware in the mu-plugins folder, knowing it will get automatically executed and won't show up in the site backend management.  As an added benefit, because it's a relatively unknown and under-the-radar feature, many WordPress security tools don't even scan the mu-plugins folder for threats.  They're not even looking.  Sucuri has seen attackers use mu-plugins folder to deploy backdoors and web shells, host SEO spam on hacked sites, as well as hijack and redirect traffic to malicious sites.  The wide and widening spectrum of abuse suggests this feature is gaining popularity and traction among underground groups.  A Sucuri analyst said:  "The fact that we've seen so many infections inside the mu-plugins directory suggests that attackers are actively targeting this directory as a persistent foothold."



WordPress site owners and admins are advised to keep a watch on the content of that folder.  If it's currently empty, unused and unneeded, delete it entirely and make sure it stays deleted.  So stepping back from all this, it appears that the design of this makes it far too easy to both use and abuse.  With a design like this, it's not possible to have ease of use without also inviting ease of abuse.  So again, to our listeners, given that more than 500 million sites, or more than 43% of the Internet is WordPress, it must be that our listeners, that a big chunk of our listeners are affiliated one way or the other with sites that are being run by WordPress.



So take a check.  It's under the wp-content directory, the default content directory, mu-plugins.  It's probably empty.  WordPress brought it along for the last three years, since 2022.  It's more than likely, whatever your host is, it doesn't need it; but it's there waiting to be abused.  First of all, make sure that, if there's anything in there that you know what it is and why it's there, get rid of it and get rid of its directory, if you don't know that you need it, because this is under active exploitation.  You know, they do have to break in somehow first.  But achieving persistence or planting malware somewhere where it won't be found and quickly discovered is the second part of the challenge.  And if it's a WordPress-based site, and the mu-plugins directory is there just waiting to run something that you drop in, that's what the bad guys are going to do.  Meanwhile...



LEO:  Meanwhile.



STEVE:  Meanwhile.  Oracle, the massive organization with designs on running TikTok, although I thought that was interesting, Leo - by the way, we should mention that on Sunday's TWiT show you had Jason Calacanis, who - he's a great guest.  You've had him through the years.



LEO:  Yeah, he's an old friend, yeah.



STEVE:  He's an old friend.  Super smart guy.  And he happened to mention, the thing that made me think of it is he was thinking that Amazon, right, wasn't that what Jason thought?



LEO:  He said Amazon's going to be the TikTok - yeah.  We'll see.



STEVE:  Manager.  We'll see.  What we'd heard was that it was going to be Oracle, that down in Texas, you know, the big database company, and they were going to be, you know, managing TikTok and retaining TikTok's U.S. domestic data.  Anyway, whether or not that happens, whether it's Oracle or Amazon, and TikTok just got another 75-day extension, right, because the boom was about to be lowered on it again.



LEO:  Yeah.  Yeah.  Yeah, Saturday was the deadline.



STEVE:  Yeah.  Okay.  So Oracle appears to be having a problem with confession.  According to Bloomberg sources, hackers breached Oracle Health and stole medical data from the company's servers.  The hack took place well back at the end of January, and the hackers are using the stolen data to extort U.S. medical providers.  So this is not apocryphal.  This actually happened.  Yet Oracle has said nothing.  They've made no report of any breach, as is required by law, to the U.S. Securities and Exchange Commission.



But wait, there's more.  This is the second suspected breach at Oracle after a different hacking group claimed to have hacked the company's Cloud service in early March.  Lawrence Abrams wrote about this for his BleepingComputer site under the headline "Oracle customers confirm data stolen in alleged cloud breach is valid."  Lawrence wrote:  "Despite Oracle denying a breach of its Oracle Cloud federated single-sign-on login servers and the theft of account data for six million people, BleepingComputer has confirmed with multiple companies that associated data samples shared by the threat actor are valid.



"Last week a person named 'rose87168' claimed to have breached Oracle Cloud servers and began selling the alleged authentication data and encrypted passwords of six million users.  The threat actor also said that stolen single-sign-on and LDAP passwords could be decrypted using the info in the stolen files and offered to share some of the data with anyone who could help recover them.  The threat actor released multiple text files consisting of a database, LDAP data, and a list of 140,621 domains for companies and government agencies that were allegedly impacted by the breach.  It should be noted," wrote Lawrence, "that some of the company domains look like tests, and there are multiple domains per company.



"In addition to the data, rose87168 shared an Archive.org URL with BleepingComputer for a text file hosted on the 'login.us2.oraclecloud.com' server that contained their email address.  This file indicates that the threat actor could create files on Oracle's server, indicating an actual breach.  However, Oracle has denied that it suffered a breach of Oracle Cloud and has refused to respond to any further questions about the incident.



"The company told BleepingComputer," meaning Oracle told BleepingComputer:  "'There has been no breach of Oracle Cloud.  The published credentials are not for the Oracle Cloud.  No Oracle Cloud customers experienced a breach or lost any data.'  He said:  'This denial, however, contradicts findings from BleepingComputer, which received additional samples of the leaked data from the threat actor and contacted the associated companies.'"  Bleeping Computer reached out to the affected companies.  "'Representatives from these companies, all who agreed to confirm the data under promise of anonymity, confirmed the authenticity of the information.  The companies stated that the associated LDAP display names, email addresses, given names, and other identifying information were all correct and belonged to them.'  



"The threat actor also shared emails with BleepingComputer, claiming that it was part of an exchange between them and Oracle.  One email shows the threat actor contacting Oracle's security email (secalert_us@oracle.com) to report that they had hacked Oracle's servers.  'I've dug into your cloud dashboard infrastructure and found a massive vulnerability that has handed me full access to info on six million users,' reads the email seen by BleepingComputer.



"Another email thread shared with BleepingComputer shows an exchange between the threat actor and someone using a Proton email address who claims to be from Oracle.  BleepingComputer has redacted the email address of this other person as we could not verify their identity or the veracity of the email thread.  In this email exchange, the threat actor says someone from Oracle using an @proton.me email address told them that:  'We received your emails.  Let's use this email for all communications from now on.  Let me know when you get this.'



"Cybersecurity firm CloudSEK [S-E-K] has also found an Archive.org URL showing that the login.us2.oraclecloud.com server was running Oracle Fusion Middleware 11g as of February 17th of this year, 2025.  Oracle has since taken this server offline after news of the alleged breach was reported.  This version of Oracle's software was impacted by a vulnerability tracked as CVE-2021-35587 that allowed unauthenticated attackers to compromise Oracle Access Manager.  The threat actor claimed that this vulnerability was used in the alleged breach of Oracle's servers.  BleepingComputer has emailed Oracle numerous times about this information, but has not received any response."



So in the face of this overwhelming evidence, which arguably borders on proof, Oracle has deliberately chosen to remain entirely silent, even though doing so is a clear breach of reporting law.  The U.S. Securities and Exchange Commission mandates that publicly traded companies adhere to specific reporting requirements following a material cybersecurity incident, such as a database breach affecting U.S. citizens.  These requirements, which have been effective since December of 2023, are designed to ensure timely and transparent disclosure of significant cybersecurity events.  Specifically, within four business days after discovering that a cybersecurity incident is material, publicly traded companies are required to file a Form 8-K disclosure under Item 1.05.



That disclosure must include the nature, scope, and timing of the incident; the material impact or reasonably likely material impact on the company's financial condition and results of operations; and determination of materiality.  Companies are required to assess the materiality of an incident without unreasonable delay upon discovery.  Oracle knows this.  Yet nothing about either of these clearly material major breaches has been publicly disclosed.



And I would argue, I mean, you know, Lawrence did a beautiful job of really pursuing these facts and essentially demonstrating proof of a material breach.  And the fact that they had a server running known buggy and patched four years ago authentication frontend, and the attacker said that's the bug they used to get in, and now that server is gone, I mean, it seems like an open-and-shut case.  And Oracle is really misbehaving badly.  So for what it's worth.  Unfortunately, their lack of responsibility-taking is exposing the authentication credentials for six million people who trust them.  So it's not like this is nothing.  This is not good, and those six million authentication credentials are now for sale on the dark web.  And apparently there's a means of decrypting them using information that the attacker also has.



So, you know, this is not just Oracle choosing not to say anything because they don't want to affect their stock valuation.  It's also materially hurting their customers.  I mean, this is, you know, a class-action lawsuit against them pending.  It's hard to see how it wouldn't be, not that you or I are in favor of that.  But, you know, they need to take responsibility.



Meanwhile, I wanted to note that nearly two weeks ago, as we mentioned two weeks ago, that Utah law we talked about which had passed through their legislature was now signed into law by Utah's Governor Spencer Cox.  Formally known as the App Store Accountability Act, or S.B. 142, the new law mostly takes effect a little over one year from now.  So as always when, you know, some new law goes into effect, it is going to require a significant change in behavior, then a period of time, you know, a grace period, that's the word I was looking for, a grace period is part of the law to allow people to get themselves ready.  That occurs on May 6th of 2026, given that the law stays in effect until that time.



It's on May 6th, 2026, a little over a year from now, that the law's core requirements, including age verification and parental consent mandates, will take effect.  So that'll give, you know, the app stores, developers, regulators time to prepare for coming into compliance with these new regulations.  And of course it will give other states time to decide if they want to follow suit.



As we've discussed, this will require Apple and Google's mobile app stores to verify user ages and require parental permission for those under 18 to use certain apps.  The law is the first of its kind in the U.S. and represents a significant shift in how user ages are verified online.  The law states that it's the responsibility of mobile app stores to verify ages, which shifts the onus to Apple and Google as those who run the stores, and away from the individual apps like Instagram, Snapchat, and X to do the age checks.



This does beg the question, though, what about apps that are already downloaded and installed from app stores when May 6th rolls around next year?  Are those grandfathered in because they're already there, and they're allowed to stay without verification?  Or will they need to then be reverified?  Don't know.  Regardless, the passage of this App Store Accountability Act is expected to trigger something.  South Carolina and California have both been rattling their sabers, saying that they're looking into doing this.  One of the bill's sponsoring senators said that the new law is designed to protect children, who may not understand apps' terms of services and therefore are unable to agree to them meaningfully.  Todd Weiler said:  "For the past decade or longer, Instagram has rated itself as friendly for 12 year olds."  He says:  "It's not."



So the Utah law is expected to face legal challenges in fights over its validity; but, as we know, my own take on that, on this whole thing, is that, yes, in cyberspace something needs to be done.  If we're going to decide that children's age matters, then responsibility needs to be taken somehow.  And I think that the most recent begrudging proposals that have been made by Apple and Google make the most sense.  App store apps need to carry API-readable age appropriate indicators, and the devices being used by minors may need to obtain parental permission before inappropriate applications can be downloaded and/or used on age-restricted devices.



And that solves the problem.  The apps don't obtain any information about the ages of their users, and the devices are responsible for getting permission if they've been configured to require it.  So, you know, Apple and Google have both articulated that solution, and I imagine that we're going to see that happen.  And that'll be good, and not a huge loss of privacy.



This was an interesting piece, and I guess you saw that, Leo.  It turns out that AI bots are inadvertently DDoSing FOSS, you know, Free and Open Source Software repositories, in their endless quest for more publicly available content.



LEO:  Yeah.  Wikipedia's been complaining about this.  It's a real problem for them.



STEVE:  Yeah.  Oh, Wikipedia has.



LEO:  Yeah.  Think about it.



STEVE:  I guess that means...



LEO:  Yeah, Wikipedia's a great resource for that.



STEVE:  And they want to be a public, I mean, they want to not restrict themselves in any way.  They want to be a public resource.  Wow.  So Ars Technica did a great job of reporting on this worrisome trend that's been developing and worsening through the year.  They said:  "Software developer Xe Iaso reached a breaking point earlier this year when aggressive AI crawler traffic from Amazon overwhelmed their Git repository service, repeatedly causing instability and downtime.  Despite configuring standard defensive measures - adjusting robots.txt, blocking known crawler user-agents, and filtering suspicious traffic - Iaso found that AI crawlers continued evading all attempts to stop them, spoofing their user-agent strings and cycling through residential IP addresses, using them as proxies.  So, you know, actively working to avoid being blocked.



"Desperate for a solution, Iaso eventually resorted to moving their server behind a VPN and creating Anubis, a custom-built proof-of-work challenge system that forces web browsers to solve computational puzzles before accessing the site."  Basically, you know, proof of work in the browser, you know, again, solve computational puzzles.  So spend time per access, per query, to validate themselves.  We've probably run across this on Cloudflare.  Sometimes you'll come to a Cloudflare page where it'll just sort of hold you for a while, while something appears to be going on.  And that is typically a proof-of-work, you know, requiring some script in your browser to do some heavy lifting which no high-rate bot is able to afford because every single time the bot tries to access, it's hit with this barrier to entry, essentially.



So Ars wrote that Iaso had written in a blog post titled "A desperate cry for help," he said:  "It's futile to block AI crawler bots because they lie, change their user agent, use residential IP addresses as proxies, and more.  I don't want to have to close off my Gitea server to the public, but I will if I have to.



"Iaso's story highlights," they wrote, "a broader crisis rapidly spreading across the open source community, as what appear to be aggressive AI crawlers increasingly overload community-maintained infrastructure, causing what amounts to persistent distributed denial-of-service attacks on vital public resources.  According to a comprehensive recent report from LibreNews, some open source projects now see as much" - get this - "as 97% of their traffic originating from AI company bots" - 97% are just bots trolling - "dramatically increasing bandwidth costs, service instability, and burdening already stretched-thin maintainers.



"Kevin Fenzi, a member of the Fedora Pagure project's sysadmin team, reported on his blog that the project had to block all traffic from Brazil after repeated attempts to mitigate bot traffic failed.  GNOME GitLab implemented Iaso's Anubis system, requiring browsers to solve computational puzzles before accessing content.  GNOME sysadmin Bart Piotrowski shared on Mastodon that only about 3.2% of requests, that's 2,690 requests out of 84,056, passed their challenge system, suggesting the vast majority of traffic was automated.  KDE's GitLab infrastructure was temporarily knocked offline by crawler traffic originating from Alibaba IP ranges, according to LibreNews, citing a KDE Development chat.



"While Anubis has proven effective at filtering out bot traffic, it comes with drawbacks for legitimate users."  Naturally.  "When many people access the same link simultaneously, such as when a GitLab link is shared in a chatroom, site visitors can face significant delays."  Ah, so something triggers that challenge, like when there's enough repeated access to a link, that suddenly switches on the challenge, which is not always on there all the time otherwise.  So they said:  "Some mobile users have reported waiting up to two minutes for the proof-of-work challenge to complete, according to the news outlet.  The situation isn't exactly new.  In December, Dennis Schubert, who maintains infrastructure for the Diaspora social network, described the situation as 'literally a DDoS on the entire Internet' after discovering that AI companies accounted for 70% of all web requests to their services.



"The costs are both technical and financial.  The Read the Docs project reported that blocking AI crawlers immediately decreased their traffic by 75%, going from 800GB per day to 200GB per day.  This change saved the project approximately $1,500 per month in bandwidth costs.  According to their blog post, 'AI crawlers need to be more respectful.'



"The situation has created a tough challenge for open source projects, which rely on public collaboration and typically operate with limited resources compared to commercial entities.  Many maintainers have reported that AI crawlers deliberately circumvent standard blocking measures, ignoring robots.txt directives, spoofing user agent strings, and rotating IP addresses to avoid detection.



"As LibreNews reported, Martin Owens from the Inkscape project noted on Mastodon that their problems weren't just from 'the usual Chinese DDoS from last year, but from a pile of companies that started ignoring our spider configuration and started spoofing their browser info.'  Owens added:  'I now have a prodigious block list.  If you happen to work for a big company doing AI, you may not get our website anymore.'"  Meaning a false positive, actually a true positive detect on a large company's IP address block because they just had to shut down all access to that company to their site because their blocklist has become so large.



"On Hacker News, commenters in threads about the LibreNews post last week and a post on Iaso's battles in January expressed deep frustration with what they view as AI companies' predatory behavior toward open source infrastructure.  While these comments come from forum posts rather than official statements, they represent a common sentiment among developers.



"As one Hacker News user put it, AI firms are operating from a position that 'goodwill is irrelevant' with their '$100 billion pile of capital.'  The discussions depict a battle between smaller AI startups that have worked collaboratively with affected projects and larger corporations that have been unresponsive despite allegedly forcing thousands of dollars in bandwidth costs on open source project maintainers.



"Beyond consuming bandwidth, crawlers often hit expensive endpoints, like git blame and log pages, placing additional strain on already limited resources."  And by that they're talking about an expensive endpoint is some page which requires a lot of database access or backend work in order to produce the page.  And so if the robot just hits that continuously, it's very resource expensive in terms of computation and access resources.  "Drew DeVault, founder of SourceHut, reported on his blog that the crawlers access 'every page of every git log, and every commit in your repository,' making the attacks particularly burdensome for code repositories.



"The problem extends beyond infrastructure strain.  As LibreNews points out, some open source projects began receiving AI-generated bug reports as early as December 2023, first reported by Daniel Stenberg of the Curl project on his blog in a post from January 2024.  These reports appear legitimate at first glance, but contain fabricated vulnerabilities, wasting valuable developer time."  Right?  You know, to track them down and realize this isn't - what is this?  It's not an actual vulnerability.



"AI companies have a history of taking without asking.  Before the mainstream breakout of AI image generators and ChatGPT attracted attention to the practice in 2022, the machine learning field regularly compiled datasets with little regard to ownership.  While many AI companies engage in web crawling, the sources suggest varying levels of responsibility and impact.  Dennis Schubert's analysis of Diaspora's traffic logs showed that approximately one-fourth of its web traffic came from bots with an OpenAI user agent, while Amazon accounted for 15% and Anthropic for 4.3%.



"The crawlers' behavior suggests different possible motivations.  Some may be collecting training data to build or refine large language models, while others could be executing real-time searches when users ask AI assistants for information.  The frequency of these crawls is particularly telling.  Schubert observed that AI crawlers 'don't just crawl a page once and then move on.  Oh, no, they come back every six hours because why not?'  This pattern suggests ongoing data collection rather than one-time training exercises, potentially indicating that companies are using these crawls to keep their model knowledges current.



"Some companies appear more aggressive than others.  KDE's sysadmin team reported that crawlers from Alibaba IP ranges were responsible for temporarily knocking their GitLab offline.  Meanwhile, Iaso's troubles came from Amazon's crawler.  A member of KDE's sysadmin team told LibreNews that Western LLM operators like OpenAI and Anthropic were at least setting proper user agent strings, which theoretically allows websites to block them, while some Chinese AI companies were reportedly more deceptive in their approaches.



"It remains unclear why these companies don't adopt more collaborative approaches and, at a minimum, rate-limit their data harvesting runs so they don't overwhelm source websites.  Amazon, OpenAI, Anthropic, and Meta did not immediately respond to requests for comment, but we will update this page if they reply.



"In response to these attacks, new defensive tools have emerged to protect websites from unwanted AI crawlers.  As Ars reported in January, an anonymous creator identified only as Aaron designed a tool called Nepenthes to trap crawlers in endless mazes of fake content.  Aaron explicitly describes it as 'aggressive malware' intended to waste AI companies' resources and potentially poison their training data.  'Any time one of these crawlers pulls from my tarpit, it's resources they've consumed and will have to pay hard cash for,' Aaron explained to Ars.  'It effectively raises their costs.  And seeing how none of them have turned a profit yet, that's a big problem for them.'



"On Friday, Cloudflare announced the AI Labyrinth, a similar but more commercially polished approach.  Unlike Nepenthes, which is designed as an offensive weapon against AI companies, Cloudflare positions its tool as a legitimate security feature to protect website owners from unauthorized scraping.



"Cloudflare explained in its announcement:  'When we detect unauthorized crawling, rather than blocking the request, we will link to a series of AI-generated pages that are convincing enough to entice a crawler to traverse them.'"  Okay, I'm not quite sure how that's that different from Nepenthes.  "'Cloudflare reported that AI crawlers generate over 50 billion requests [wow] to their network daily.  AI crawlers generate over 50 billion requests to their network daily, accounting for nearly 1% of all web traffic they process.'"  Which says they're handling, what, 5,000 billion requests?  Yeah, 5,000.  So...



LEO:  Five trillion.



STEVE:  Yeah, five trillion.  Five trillion requests per day.  Wow, Cloudflare.  "The community is also developing collaborative tools to help protect against these crawlers.  The 'ai.robots.txt' project offers an open list of web crawlers associated with AI companies and provides premade robots.txt files that implement the Robots Exclusion Protocol."



LEO:  Yeah, they should honor those.  That's key; right?  Yeah.



STEVE:  Yes, yes, exactly.  "As well as .htaccess files that return error pages when detecting AI crawler requests.  As it currently stands, both the rapid growth of AI-generated content overwhelming online spaces and aggressive web-crawling practices by AI firms threaten the sustainability of essential online resources.  The current approach taken by some large AI companies, extracting vast amounts of data from open-source projects without clear consent or compensation" - and I would add, and deliberately ignoring their clearly established standards for saying please don't - "risks severely damaging the very digital ecosystem on which these AI models depend."



And finally they wrote:  "Responsible data collection may be achievable if AI firms collaborate directly with the affected communities.  However, prominent industry players have shown little incentive to adopt more cooperative practices.  Without meaningful regulation or self-restraint by AI firms, the arms race between data-hungry bots and those attempting to defend open source infrastructure seems likely to escalate further, potentially deepening the crisis for the digital ecosystem that underpins the modern Internet."  Yeah.



LEO:  Yeah.  If they don't honor robots.txt, then anything you do to them is fine.



STEVE:  Right.  If they're - exactly.  If they're deliberate - that's a very good point, Leo.



LEO:  Yeah.



STEVE:  If, you know, we might say, hey, it's kind of foul play, sending them into an AI-driven tarpit.  But if you first said "Don't go in here because of what's in the robot.txt..."



LEO:  Right.  Exactly.  



STEVE:  And I presume they do.



LEO:  Cloudflare does do that.



STEVE:  Yes.



LEO:  Yes.  By the way, Nepenthes is funny.  So Cloudflare calls it a tarpit.  But a Nepenthes is a pitcher plant.  It's the plant that traps bugs.



STEVE:  Oh, right.  That, like, the...



LEO:  It's not a Venus fly trap.  It's a pitcher.  It has dew in it, and the bugs move into it, and then of course it eats them.  So it's just like a tarpit, but it's a plant version.



STEVE:  Very nice.  Very nice.



LEO:  From the plant kingdom of a tarpit.  I think that's very funny, yeah.  All right.  Back to you, Mr. G.



STEVE:  So if you're attempting to install Windows 11 on a machine using only a local account, without signing into Microsoft, and you're wondering why doing so appears to have become more difficult or obscure, it could be because Microsoft now intends to make that completely impossible.  In their recent announcement of Windows 11 Insider Preview Build 26200.5516 for the Dev channel, toward the end of a long list of tweaks and changes that they've made, under the section "Other," Microsoft wrote, and I love the way they phrased this:  "We're removing the bypassnro.cmd script from the build to enhance security and user experience of Windows 11.  This change ensures that all users exit setup with Internet connectivity and a Microsoft account."



So, okay.  It's unclear to me how forcing either Internet connectivity or being logged into a Microsoft account enhances either a user's security or their convenience or experience.  But that's, you know, what will henceforth be required for all users setting up Windows 11.  And I don't mean to make a bigger deal out of this than it is.  I imagine that anyone setting up Windows 11 will have already made whatever adjustments to their thinking and expectations may be required.  But it is a change that I wanted to let our listeners know about.



Some of the reporting I saw about this phrased it a little differently.  They said:  "Microsoft has been trying to force Windows 11 users to install the OS with a Microsoft account for years, but this marks the first time when the company has made it a public policy in one of its blogs."  So anyway, having shared all that, I won't be surprised if there isn't soon a workaround for this, we've seen those before, when this has sort of been there.



LEO:  It's actually a little more - it's simpler than this.  We talked about this on Windows Weekly, which is how I know.



STEVE:  Oh.



LEO:  That was a script, a powershell script, actually maybe not even a powershell script, there was a shell script that launched a series of commands.  Those commands are still there.  And so what Microsoft has done is make it so that somebody who is non-sophisticated won't have a simple, oh, just click this and it'll run, the bypassnro script.  But all of the commands that do bypass the Microsoft login are still there.  They have not removed those.  So Paul's position on this is you still can set up Windows 11 without a Microsoft account.  But you need to be a little more sophisticated than you used to be.  And that's Microsoft's intent because, for instance, if you're using Windows Home, it turns on BitLocker, but only if you turn on your Microsoft account because you need a way to store that certificate.  So many people lose their certificates.



STEVE:  Right.



LEO:  So Microsoft's erring for the - I think this is, I've always said this is the ideal solution, which is - and Apple does this, too.



STEVE:  Kind of a way around it.



LEO:  Yeah.  By default you make it more secure, but less flexible.  But if you're in the know, if you're a sophisticated user, there are ways to disable it.



STEVE:  So they took it out of the GUI.



LEO:  Basically.



STEVE:  That little skip for now or local account that they used to have.



LEO:  Right.  But Paul says, at least for now, and he believes this will continue, it is absolutely possible to do this.  You just don't have that script to do it anymore.



STEVE:  Well, and it's...



LEO:  But if you look in bypassnro.cmd, you could see the commands.  It was just...



STEVE:  Well, and it would seem to me that even if you - they wouldn't remove the ability to have a local account.  So even if you had to temporarily create a Microsoft account to get installed, then you add a local account and delete the Microsoft account.



LEO:  That's what Paul's recommended workaround is.  You know, you can make a dummy Microsoft account that you don't use.



STEVE:  Right, that's just to get you installed.



LEO:  Exactly.



STEVE:  And then, yeah, and then...



LEO:  And they can't get rid of that.  As long as there is a local login at some point, yeah.



STEVE:  Right.



LEO:  So I think it's not, just as you say, you said that you wouldn't be surprised if there's a workaround.  There is, basically, and they're never - they didn't get rid of that.  Yet.



STEVE:  Okay.



LEO:  Yet.



STEVE:  Well, and again, as I said, I don't mean to make a big deal about it.  You know, it's just annoying to be constantly asked if you want to - you haven't backed up your drive.  It's like, hey, I've got my own backup.  You know, there's no way to tell it to shut up.



LEO:  It's not for you, it's for normal users.



STEVE:  Yeah.



LEO:  That's the problem.  And it's always been the challenge in technology to make it reliable and safe for normal people, but to give us hardcore users the power that we really want.  And deserve, yeah.



STEVE:  Okay.  So I love this.  Last week Google announced and unveiled what they called "end-to-end encryption" for corporate users of Gmail.  But, boy, is it funky.  It does encrypt a message in the sender's web browser, where it remains encrypted until it's opened in the recipient's web browser, where it's then decrypted.  So, technically, yeah, end-to-end.  But otherwise, Google jumped through some weird hoops to offer this.



Okay, now, since the technology is interesting, and since it might well be of interest to our listeners whose corporations might find value here - because, I mean, it's not nothing.  It's just not really, you know, what we're used to.  I want to take us into the details.  And for that, Ars Technica's Dan Goodin did a terrific job of setting this up, creating the appropriate context, and explaining what goes on.  Ars's headline last week about this was:  "Gmail unveils end-to-end encrypted messages.  Only thing is:  It's not true E2EE."  And their tag line was "Yes, encryption/decryption occurs on end-user devices, but there's a catch."



So Dan opens by saying:  "When Google announced Tuesday that end-to-end encrypted messages were coming to Gmail for business users, some people balked, noting that it wasn't true end-to-end encryption, as the term is known in privacy and security circles.  Others wondered precisely how it works under the hood.  Here's a description of what the new service does and doesn't do, as well as some of the basic security that underpins it."



I'm going to interrupt here just for a moment to note that the way the conventional end-to-end encryption operates is pretty straightforward.  So let me set that context first because he doesn't do that.  Each party, as we know, has a public key pair, consisting of a public key and a private key.  And the public keys are published in some way.  So when Alice wishes to send an encrypted message to Bob, she first creates a high-entropy secret symmetric key which will be used to encrypt the message, anything she wants.  That's the so-called "bulk encryption" key.  And that's just randomly, you know, she creates a high-entropy random secret symmetric key which she uses to encrypt her stuff.  She uses that symmetric key to encrypt everything that she wishes to send to Bob.



Next, Alice encrypts that secret key twice, first with her private key, then a second time with Bob's, the recipient's, public key.  She then packages the encrypted message up along with the result of the double key encryption and sends that package to Bob.  Upon receiving Alice's package, Bob first decrypts the double-encrypted key using his secret key, which undoes the second encryption that Alice put on which used Bob's private key.  And of course only Bob knows his private key.  He then looks up Alice's publicly published public key and uses it to decrypt the result of the first decryption.  And the beauty of this is that only if all four of these keys were correct will Bob now have recovered the properly decrypted secret symmetric key, which he can then use to decrypt the package that Alice prepared for him.



Now, the elegant beauty of this simple system is that Alice wishes to send something that only Bob can decrypt, and Bob wants to know that whatever he received was truly sent by Alice.  Since both parties' private keys must be used, and only each party knows their own private key, not only do we get strong encryption protection from anyone attempting to intercept that communication, but Alice knows that only Bob can decrypt what she encrypted, and Bob knows that only Alice can have sent what he decrypted as having come from her.  So that's true end-to-end encryption, and that's not what we got from Google in Gmail.



Okay.  So Dan explains what we did get.  He wrote:  "When Google uses the term end-to-end encryption in this context, it means that an email is encrypted inside Chrome, Firefox, or just about any other browser the sender chooses.  As the message makes its way to its destination, it remains encrypted and cannot be decrypted until it arrives at its final destination, when it's decrypted in the recipient's browser.



"The chief selling point of this new service is that it allows government agencies and the businesses that work with them to comply with a raft of security and privacy regulations and at the same time eliminates the massive headaches that have traditionally plagued anyone deploying such regulation-compliant email systems."  So in other words, they sort of skinned the cat here in a different way.  They've come up with something that complies with the regulations for end-to-end encryption, yet made it much easier to deploy.



Dan said:  "Up to now, the most common means has been S/MIME, a standard so complex and painful that only the bravest and most well-resourced organizations tend to implement it.  S/MIME requires each sender and receiver to have an X.509 certificate that's been issued by a Certificate Authority.  Obtaining, distributing, and managing these certificates in a secure manner takes time, money, and coordination.  That means that if Bob and Alice have never worked together before, and an urgent or unexpected need arises for him to send Alice an encrypted message promptly, they're out of luck until an admin applies for a certificate and sees that it's installed on Alice's machine.  So much for flexibility and agility.



"Google says that end-to-end encryption Gmail abstracts away this complexity.  Instead, Bob drafts an email to Alice, clicks a button that turns on the feature, and hits send.  Bob's browser encrypts the message and sends it to Alice.  The message decrypts only after it arrives in Alice's browser, and she authenticates herself."  Okay.



"To make this happen, Bob's organization deploys what Google calls a 'lightweight key server,' known as a KACL, short for Key Access Control List.  This server, which can be hosted on premises or most cloud services, is where keys are generated and stored.  When Bob sends an encrypted message, his browser connects to the key server and obtains an ephemeral symmetric encryption key.  Bob's browser encrypts the message and sends it to Alice, along with a reference key.  Alice's browser uses the reference key to download the symmetric key from the KACL and decrypts the message.  The key is then deleted."  Thus ephemeral.



"To prevent Mallory or another adversary-in-the-middle" - Mallory-in-the-middle - "from obtaining the key, Alice must first authenticate herself through Okta, Ping, or whatever other Industry Identity Provider, or IDP, Bob's organization uses."  So Alice must authenticate herself to Bob's organization's identity provider.  Dan said:  "If this is the first time Alice has received a message from Bob's organization, she'll first have to prove to the IDP that she has control of her email address.  If Alice plans to receive encrypted emails from Bob's organization in the future, Alice sets up an account that can be used going forward.  Bob's organization can add an additional layer of protection by requiring Alice to already have an account on the IDP and authenticate herself through it.



"Julien Duplant, a Google Workspace product manager, told Ars:  'The idea is that no matter what, at no time and in no way does Gmail ever have the real key.  Never.  And we never have the decrypted content.  It's only happening on that user's device.'"



Okay, now, I'm going to interrupt here again to note that in no way is any web browser a safe place to decrypt super-secure, you know, like national security level or extremely proprietary corporate material.  You know, like in the same way when we were talking about Signalgate, as it's now being called, of national security-level secrets being transacted on people's individual smartphones, it's not Signal that had a problem because it's true end-to-end encryption.  It's that it's on the smartphone device.  It is decrypted after it arrives.  So we have the same problem with a web browser; right?  You know, you still have JavaScript or WebAssembly running in a web browser which is as authentically secure as we've been able to make them, but they are still being updated to cure serious, often zero-day style security vulnerabilities.  That's still happening.



You know, if you really need to send something securely, my advice would be encrypt it offline, away from any web browser, then send it in the clear through any email system.  Doesn't matter because it's been, you know, it's PIE, Pre-Internet Encryption.  Pre-web browser encryption.  You know, and I'm not intending to take anything away from Google.  The system they've created is an interesting hack, but a hack it is.  And it also represents a security tradeoff for convenience since it's running in the largest attack surface, which is today's web browser, that any computer system has today.



Dan finishes his description by writing:  "Now, as to whether this constitutes true end-to-end encryption, it likely doesn't, at least under stricter definitions than are commonly used.  To purists, end-to-end encryption means that only the sender and the recipient have the means necessary to encrypt and decrypt the message.  That's not the case here, since the people inside Bob's organization who deployed and manage the KACL have true custody of the key.  In other words, the actual encryption and decryption process occurs on the end-user devices, not on the organization's server or anywhere else in between.  That's the part that Google says is end-to-end encryption.  The keys, however, are managed by Bob's organization.  Admins with full access can snoop on the communications at any time.



"The mechanism making all of this possible is what Google calls CSE, short for Client-Side Encryption.  It provides a simple programming interface that streamlines the process.  Until now, CSE worked only with S/MIME.  What's new here is a mechanism for securely sharing a symmetric key between Bob's organization and Alice or anyone else Bob wants to email.  The new feature is of potential value to organizations that must comply with onerous regulations mandating end-to-end encryption.  It most definitely is not suitable for consumers or anyone who wants sole control over the messages they send.  Privacy advocates, take note."



So anyway, if anyone was wondering, you know, heard about Google's, you know, end-to-end encryption, now we have some context.  It's certainly better than what they had before.  If your organization wants to use it, then, you know, it does keep things encrypted.  But, you know, if you're using Gmail in your browser, you have an HTTPS connection to Gmail.



LEO:  Right, right.  And anything that goes Gmail to Gmail remains encrypted.



STEVE:  Yeah.  It's never been in the clear at any point.



LEO:  Right, right.  I think this is really for businesses that don't want to give up full encryption, right, because they want to make sure that they can monitor your emails.  In fact, they may have a regulatory requirement.



STEVE:  I think it's an interesting regulatory hack.



LEO:  Yeah.



STEVE:  I think that's it.  I think it's, you know, it's like Google was under some pressure to come up with a way for regulations that require end-to-end encryption, like the letter of the law, that it's encrypted on your device, decrypted on the recipient's device.  And Google said, oh, yeah, we can do that.



LEO:  Did you ever wonder who Bob and Alice are?



STEVE:  I do.  And boy, they have some longevity.  They're still talking.



LEO:  Sometimes there is a Ted and a Carol that gets involved in these conversations.



STEVE:  Yeah.



LEO:  And it all comes from a 1969 movie about wife-swapping called "Bob & Carol & Ted & Alice."



STEVE:  Ted and Alice.



LEO:  You remember that; right?  Yeah.



STEVE:  Yup.  We're older.  We've been around long enough.



LEO:  Yeah, us oldsters know where that came from.  It's pretty funny.  And I would imagine people listening who don't know that are going, who are these Bob and Alice that everybody's always talking about when it comes to encryption.  I think that's where it came from.  It seems like a coincidence if it didn't.



STEVE:  Must be.  And it has the advantage of having A, B, and C - Alice, Bob, and Carol.



LEO:  Yeah.  Ted we just can throw out.  We don't...



STEVE:  Yeah, Ted, you know.



LEO:  He doesn't fit.



STEVE:  And then Mallory as Mallory-in-the-middle.



LEO:  Oh, there you go.



STEVE:  Mallory is also the name used for your attacker.



LEO:  For man in the middle.  Oh, nice.  That's nice.  Do  you want to pause, or do you want to keep going?  We've got time.



STEVE:  I've got a little bit more, and then we've got some - oh, yeah.  One more, and then feedback, when we will pause.



LEO:  Okay.



STEVE:  So, but this is an important one for anyone who is running Apache Parquet.  A CVSS 10.0, which we know is very difficult to achieve.  It's like the Olympics of bad vulnerabilities.  Apache recently received the much-dreaded full CVSS 10.0 with a widely used module known as Apache Parquet, which is spelled P-A-R-Q-U-E-T.  Apache Parquet is an open-source, columnar - as in, instead of rows, it's columns.  So columnar storage format designed for more efficient data processing.  Unlike row-based formats such as CSV, Parquet stores data by columns, which makes it faster and more space-efficient for analytical workloads.  It's widely adopted across the data engineering and analytics ecosystem, including big data platforms like Hadoop, AWS, Amazon, Google, Azure cloud services, data lakes, and ETL tools.  Some large companies that use Parquet include Netflix, Uber, Airbnb, and LinkedIn.



And now a new, low-complexity, remote code execution vulnerability has been identified in all current versions of the Apache Parquet system.



LEO:  Wow.



STEVE:  Yeah.  Unfortunately...



LEO:  How widespread is Parquet use?  Is it a pretty popular...



STEVE:  Among those who use it.  I mean, Netflix, Uber, Airbnb, LinkedIn.



LEO:  So, okay, yeah.



STEVE:  I mean, Hadoop, AWS, Amazon, Google, Azure cloud services.  So, yeah.



LEO:  Okay, yeah.



STEVE:  It's got some wings there.  Unfortunately, the problem was disclosed on April 1st.  But since this is no joke, and it would be horrible for those affected if they thought it was, I hope no one dismissed it as an April Fools event.  This maximum severity remote code execution problem impacts all versions of Parquet up to and including 1.15.0.  The problem stems from the - here it is - the deserialization, we've talked about deserialization flaws because they're tough, of untrusted data.  And of course deserialization is also known as "interpretation."



And we know how hard it is to do interpretation correctly.  It could allow attackers with specially crafted Parquet files to gain total control of target systems, exfiltrate or modify data, disrupt services, or introduce dangerous payloads such as ransomware.  The vulnerability is tracked as CVE-2025-30065 and, as I said, carries a CVSS v4 score of 10.0.  It was fixed with the release of Apache version 1.15.1.  So it is some solace that in order to exploit this flaw, threat actors must convince someone to import a specially crafted Parquet file for Parquet to then deserialize.  But we all know that social engineering attacks remain some of the hardest to defeat.  And it might well be that there are other vectors.



So anyway, I wanted to put it on everyone's radar.  If you happen to know that you're using Parquet or know someone that does, the good news is it has not been publicly leveraged.  It's not known to be used.  It was discovered by Amazon AWS security folks because AWS uses it.  They told Apache.  Apache's updated it.  But we know how that goes.  So the bad guys will look at new and old Apache, do a dif of it, see what's changed, reverse engineer the exploit, and then go looking for publicly exposed Parquet instances.  So if you're using Parquet, update immediately because you want to beat the bad guys to it.  And now, Leo, let's take a break.



LEO:  Butter.  Oh, I thought you wanted me to say "butter."  Okay.



STEVE:  Butter, butter.  Parquet.



LEO:  Butter.



STEVE:  Parquet.



LEO:  All right.  Back to Steve.



STEVE:  So @TechnoAgorist, so this must have been through X where I checked in, he wrote:  "Regarding Neal Asher's novels, they may not be on Kindle Unlimited, but I found them at my local library."



LEO:  Nice.



STEVE:  "That's how I've been reading them.  Thanks for the recommendation."  And I appreciated being able to share a reminder about printed books.



LEO:  Yeah, nothing wrong with them.



STEVE:  Yeah.  I'm still enjoying Neal.  I'm Book #4 of the first five-book Agent Cormac series, as it's called, and I'm having a great time.  The books are long and involved.  The style Neal uses for the first three, at least - and yeah, I guess it's to a lesser degree now in Number 4 - was to create several parallel plot lines that initially don't appear to bear any connection to each other.  There's no obvious relationship.  So you'd sort of move around between them, and you're thinking, okay, why do I care about this person?  But, you know, as the story progresses, they eventually converge, and you end up - I remember at one point thinking I'm having a lot of fun with this book.  So anyway, thank you to TechnoAgorist for your note about books are still available from libraries in print.



LEO:  Amazing.



STEVE:  That's certainly a way to get it.



LEO:  Who'd a thunk it?



STEVE:  It wouldn't occur to me, Leo, I have to tell you.  Eric Seidel said:  "Hey, Steve.  I just listened to part of your podcast, and it was funny that you mentioned something that happened exactly to me, as well.  In the past couple of days, I had Microsoft two-factor authentication reset requests show up in my email, and then happened to look in my sign-in activity.  And it is a sign-in request every minute to my account.  It's just insane.  Make sure you have your two-factor authentication turned on.  Holy smokes."



And I put in the show notes just a snapshot that he had sent me that does, you know, indeed show, in fact, sign-ons like every minute or several times in the same minute.  So again...



LEO:  All this because they didn't have the 2FA code.



STEVE:  Yeah, the idea that some guy, I mean, or that, you know, the bots apparently are just sitting here...



LEO:  Amazing.  Hammering it.



STEVE:  ...pounding on people's email without better protection.  And it is really disturbing.  Matthew West said:  "Hi.  Love the show.  I bought a used Fitbit with a cracked screen.  I forgot that I would need the PIN shown on the screen in order to pair it.  I'm trying to pair by the constantly changing one-time code in the hopes it eventually works."  In other words, he's guessing.



LEO:  Oh, forget about it.



STEVE:  He said:  "This made me wonder what the best strategy is, and how many attempts would be needed to reach a 50% chance.  Sorry if this was already answered.  I should look through the transcripts.  Thank you."



Well, Matthew, we previously addressed this question a few months back, when we took a deep dive into the precise operation of hash-based one-time passwords.  That podcast was 1009, and we received an unusual amount of positive feedback from our listeners...



LEO:  Yeah, it's great.



STEVE:  ...who enjoyed thinking about the various aspects of a six-digit code that was changing randomly every 30 seconds.  The answer to the first part of your question, Matthew, what's the best strategy, is that since the proper PIN code at any given instant is completely random, there can be no "best strategy" since no guess can, by definition, be any better than any other.  So if patience could be considered a strategy, then patience would be the best strategy because a great deal of that is going to be necessary.



So exactly how much?  The second part of your question asked how many attempts would be needed to reach a 50% chance?  And that is something that's knowable.  At the bottom of page 21 of Episode 1009's show notes, I wrote:  "The probability of things happening is something that often trips people up.  If the probability of something random happening is one in a million, and that is the case, if the probability of a correct guess is one in a million, since it's from 000000 to 999999, that's a million possible combinations.  We might tend to assume that giving that one-in-a-million thing one million opportunities to occur - or in our case one million guesses - we would probably obtain a collision of six-digit values.  And that's true, but it's not guaranteed.



"Probability theory tells us that, even given one million guesses of a one-in-a-million event, there's a 36.79% chance of never hitting upon the value we're seeking.  But that means that, given one million guesses, there is a 63.21% chance of hitting it.  So, you know, better than 50/50."  Okay.  "For random events, it's all about probabilities."



And so here's the answer to your question, Matthew.  693,147 guesses, so just shy of 700,000, would be required to hit the 50/50 point, for an even chance of any of those one-in-a-million guesses being correct.  So that's why patience will be the best strategy.  Maybe getting a different Fitbit would be a better idea because you're going to be guessing for - I don't know how fast you can guess, but it's going to take just shy of 900,000 guesses to reach the 50% point.  That would try my own patience.



LEO:  Yes.



STEVE:  Actually, if you were to walk up a step for every time you made a guess, you wouldn't need the Fitbit because you would be fit by the time you got the guess, yeah.



LEO:  There you go.  That's clever, yes.  Just take the stairs.



STEVE:  Jason wrote:  "Hi, Steve and Leo.  Longtime listener and happy Club TWiT member."



LEO:  Yay.



STEVE:  Thank you, Jason.  He said:  "As we all move to delete our 23andMe data, I have a maybe amusing story.  When I signed up for 23andMe years ago, I thought I would attempt to get some privacy by obscurity.  I created my 23andMe account with a fake name, with a new Gmail for that fake name.  My thought was, if they were ever hacked, as they were, or sold their data, as they are, at least my DNA would not be tagged with me by name.  So I also made up a fake birthday, in keeping with the obscurity strategy.



"Cut to this week when I went to delete my data and found that birthday is used as a form of authentication.  I have no idea what date I gave them, and I never thought to record it.  I tried permutations of my own birthday until I ran out of guesses and locked myself out.  Emails to their support revealed that the only way to prove my identity was to provide government-issued ID.  I'm not likely to give my ID to someone actively selling all of their assets to the highest bidder anyway, but I certainly can't when no such ID exists.  Oh well, guess I'll have to continue to rely on obscurity.  Thanks for all you do, 'Jason.'"  And he put that in air quotes, so I don't think that's even his name. 



LEO:  We don't know his name.  We don't know his birthday.  We know nothing.



STEVE:  I loved that Jason put his own name in quotes, you know, suggesting that he's quite deeply committed to remaining anonymous and obscure, as indeed he is.  And given that no one knows whose DNA his is anyway, let alone who he is, I'd say there never was any need to delete it in the first place.  But I understand, you know, for the sake of why not, you know, giving it a try.  Anyway, he sort of prevented - he locked himself out from being able to do so.



An anonymous listener wanted to share some thoughts about leaving Windows.  He said:  "Hi, Steve.  Please keep my name, company, and project private because it would be easy to reverse engineer who my company is."  He said:  "I've been listening for years.  Thank you for all you do.  I'm a security researcher and developer at [really big company X]. I mostly maintain a popular open source tool [name redacted].



"With respect to moving away from Windows to an open source solution" - and again, remember, really big company X, I know the name of the company, and it is really big.  He said:  "With respect to moving away from Windows to an open source solution:  Much of my company's software, which is firmware, build chain is built upon Windows.  Microsoft is in the process of re-licensing all of our Server Win OS and MS SQL agreements, and as a result our cost will be going from a per compute device license to a per core license."



LEO:  Oh, boy.



STEVE:  And I don't know about you, Leo, but I've got 20 cores.



LEO:  Yeah.  That's a massive increase.



STEVE:  He says:  "As such, the cost would be going from thousands of dollars to millions of dollars.  In response, we are simply moving as much of our infrastructure as we can to an open source variant."  He said:  "It seems crazy to me that M$ is so arrogant that they think there's no alternative to them, or at least that the cost would be too much for us to absorb.  About that, they have miscalculated.  Yes, it will cost us to move, but it'll be so nice once we've done so.  Now we just need to move all of our clients from Windows to Linux, and I'll be a happy camper.  Thanks again for all you do.  /Anon.



LEO:  Wow.



STEVE:  So this person was actually, Leo, just one of many of our listeners who wrote to me in response to last week's EU OS podcast.  I heard similar stories over and over and over.  Microsoft apparently believes that they will be maximizing their bottom line profit by squeezing more money out of fewer customers because the theme that I kept hearing playing out over and over was that people were finally and at long last throwing in the towel, giving up, and biting the bullet to move to free and open source solutions.  Those solutions have been steadily maturing through the years and are finally solid enough to be depended upon.  And the message was more so than Microsoft.



And the message is, you know, the message was that they will be moving because Microsoft's policies appear to be predatory.  "Predatory" was the word that several of our listeners independently used.  And I thought, whoa.  So, and I suppose it makes sense.  If Microsoft can increase their profit and reduce the burden of support for all those pesky customers that they'd rather not have, then fine.  Go to Linux.  People are saying, okay.



LEO:  Yeah.



STEVE:  TJ Asher said:  "Steve, I heard Leo mention Jackpot Junction in that list of companies on the ransomware site."



LEO:  Oh, yeah, yeah.  They were one of the hacks or ransomware companies, yeah.



STEVE:  Right.  He said:  "That's a casino here in Minnesota.  So I went to their website, and they have a big notice.  It says:  'Slot machines and kiosks are currently unavailable.  Bingo is canceled until further notice.'"



LEO:  Oh, no.



STEVE:  "The special Bingo" - no, don't take my bingo.



LEO:  No, no, not the bingo.



STEVE:  "The special bingo session is postponed until a later date.  Continuity is postponed until further notice.  Promotional drawings are postponed until further notice.  Dacotah Dining is closed until further notice."  Boy, this really hit them hard.



LEO:  Oh, I feel bad for them.



STEVE:  "Full Deck is open for breakfast from 7:00 a.m. to 11:00 a.m., with regular menu from 11:00 a.m. until close.  Table Games and Circle Bar will remain open.  Thank you for your patience and understanding.  We will provide updates as they are available."



LEO:  They got hacked, all right.



STEVE:  And TJ signed off, saying:  "Definitely looks like they got hacked.  Keep up the awesome work.  Regards, TJ."  So for anyone who's interested, remember, I think it was, what was it, last week's podcast, I think it was GRC.sc/1019 was the shortcut that I created to take us over to Ransom List or whatever it was called.  Oh, yeah, ransomlook.io.  Yeah.  GRC.sc/1019.  And that's ransomlook.io.  And, I mean, I looked again, and it's just - it's hopping over their recent posts on the left.  It takes you to the listing.



LEO:  Oh.



STEVE:  Yeah.



LEO:  This is today.



STEVE:  Yup.



LEO:  This is just today.  These are all places that have been...



STEVE:  National Association for Stock Car Auto Racing, they're gone.  Third Avenue Management gone.  Crystal-D.com gone.  Coop57 gone.



LEO:  RoyalSaudiAirForce.gov.sa.  Oh, wow.



STEVE:  Liberty Tax.  They're going to be paying some tax.



LEO:  Yeah.



STEVE:  CVTE.



LEO:  This is the list you don't want to be on.



STEVE:  Oh, boy.  And again, if any of our IT friends listening are having a problem with their CFOs, just say, okay, CFO, just go over here.  Not one of these companies wants to be there, and they didn't give their CIO enough money.



LEO:  Yeah.  Yeah.  Wow, incredible.  And it was good to have that confirmation that, you know, we saw that casino on there.



STEVE:  Somebody listed there is SOL, yup.



LEO:  I mean, not a good thing by any means.



STEVE:  No Bingo for Bongo.



LEO:  No bingo for you.



STEVE:  No.  Henrik Johnson said:  "Hello.  I just thought I'd clarify something you and Leo said in Episode 1019 about Cloudflare hosting 20% of the web.  The 20% figure most likely refers to sites behind Cloudflare's WAF (W-A-F), you know, Web Application Firewall, not actual hosting, especially since they referred to their free plan, which does not include hosting.  That said, when behind a WAF, Cloudflare does terminate TLS, which means that they are an intentional man in the middle that can see request information including login credentials. /Henrik."  So thank you, Henrik.  So a better way to say it would be that Cloudflare is "fronting" for 20% of the Internet's website properties.



Harry Pilgrim said:  "Steve, you and Leo continue to say that you use 'certificates' to login to SSH servers.  This is not completely accurate.  SSH can be configured to use public/private keys for authentication."



LEO:  Yeah, that's what I say.  I never say "certificates."



STEVE:  Oh, okay, then it's I who am saying "certificate."  But these are not "certificates."



LEO:  No.



STEVE:  "A certificate is composed of uniquely identifying information," anyway, blah blah blah.  He explains that.  So thank you, Harry, for correcting us.  I certainly stand corrected.  But this gives me the opportunity to mention my absolute favorite SSH client and server solution for Windows-centric users, which is Bitvise, Bitvise.com.  They're not a new discovery of mine because I would never recommend something like an SSH client and server without first obtaining sufficient experience for any such recommendation.  I've now been using their solutions since 2018, so I've gained seven years of experience with their software and their company, and I cannot recommend them more highly.



If all you need is an incredibly good SSH client for Windows, for accessing remote SSH servers, you can use theirs free of change.  The Bitvise client is free.  If you want a matching terrific SSH server for Windows, you can take theirs out for a 30-day spin for free, after which a one-year license is $100, but only the access to upgrades expires after a year.  That server software will run forever.  Mine's expired a few times, and they've had some updates, and I've thought, okay, I should re-up because I'm using their server very happily.  I've been with them for seven years.  I can attest that they are not constantly fixing mistakes.



Only very occasionally do they have something that they need to tweak.  And normally it's for some edge case that doesn't affect me.  But I want to stay current with them anyway.  I could not be more pleased with them, and I cannot imagine ever having a need to switch.  So just for the record, Bitvise, B-I-T-V-I-S-E, is my SSH solution for Windows.



LEO:  That's one of the main reasons I'm not a Windows user is I need a command line that I can do things like that.



STEVE:  Ah.



LEO:  I should say like this, and login to a remote server.  I like having a command line.



STEVE:  I like it, too.  It is, it's a good thing.



LEO:  So I always, for a long time, I mean, I haven't used Windows in a while, but I used Cygwin.  Is that, like, all done?  Is that old hat?  C-Y-G-W-I-N?  Maybe it is.  Bitvise looks pretty nice.



STEVE:  It's really nice.  I mean, it manages our public and private keys, synthesizes keys.  The server tells you it's never seen this key before.  It tries multiple styles of authentication in sequence.  You're able to maintain a list of previous SSH servers and select.  It'll bring up a console window for you.  So like when I SSH in to my FreeBSD Unix, I get a console window.  Or when I SSH even into Windows, I get an admin prompt window.  And I'm able to bring up a two-pane file copy so I can drag and drop files back and forth.



LEO:  Oh, that's nice, yeah.



STEVE:  Anyway, it's just a great solution.



LEO:  Bitvise.  Free.



STEVE:  Highly recommended, Bitvise.  David Spicer said:  "Steve, I was listening to podcast Episode #1019.  And as you talked about Troy Hunt getting phished, I couldn't help but wonder how one could help prevent this type of quick-acting attack.  I know Passkeys would solve a lot of this in the first place, but I often see cloud services that support Passkeys also allow for username and password as a backup.  I personally find it difficult to see how sites that support both options are safer."



Of course you're singing my tune; right?  I've said, as long as you offer a fallback, then email continues to be the weakest link in the chain.  I just logged into Hover a minute ago when you were giving our first advertiser, our first sponsor, because I wanted to see how much a .secure domain would cost.  And I noted that right there, under my prompt for a one-time authentication, was "I don't have access to my authenticator."  Well, okay.  Then how good is this?



Anyway, he said:  "My online banking site requires a one-time password code just to login once."  He said, "I can view all of my account information normally.  However, if I want to perform any money transfers, I am prompted for a new one-time code before I can do so.  That made me think that this method might be useful with other online services that only support one-time password multifactor authentication login, such as Mailchimp.



"Even after you have signed in, if you wanted to perform a security relevant action, such as exporting data," which of course Troy got bit by, which is what made David think about this, "changing authentication methods, or viewing API keys, that would require a new one-time password code from your authenticator.  This would help prevent attackers who phish a login from you from being able to make changes or steal sensitive information without having to phish for a second OTP code from you.  Well, that's just my thought, anyways.



"I'm glad I found your podcast nearly a decade ago.  I love listening to you and Leo every week.  Every episode is a good one" - except today is extra good - "and your tools like SpinRite, ValiDrive, and the DNS Benchmark are amazingly useful.  Really looking forward to buying the Pro version of the DNS Benchmark when it comes out for my lab environment.  Have a great week.  Thanks, David."



So I agree with David completely.  Requiring the re-use of a one-time password or, you know, OTP token before proceeding with any extra-sensitive action after being logged in makes a ton of sense.  And think about it.  It's exactly analogous to pretty much any site asking us to re-supply our current password as part of the process of changing that password.  Right?  You know, why?  We're obviously already logged in.  In order for us to even be presented with that opportunity of changing our password, we have to be logged in with our password.  The site already knows who we are enough to allow us to be roaming around inside it.  So why ask us to reassert our current password before we're able to change it?  Obviously, because changing our password is seen as a particularly sensitive action.



But to David's point, it's interesting that most, you know, that this re-use of one-time passwords does not seem to have filtered down into the operation of most sites beyond login authentication, his bank and others being a common exception.  And I think I know why.  My presumption is that the reason for this is that most sites are still using some canned OAuth login authentication solution and have not bothered to build-in one-time password re-verification.  Perhaps in time, you know, this will change, since re-prompting for one-time passwords I think makes so much sense.  It really ought to be done.  But his point's a good one.  No one's doing it.



John Rostern said:  "Steve, I've been a longtime Security Now! listener and have always appreciated your insightful commentary and analysis, mixed with some humor, on all things related to cybersecurity.  I was a bit taken aback therefore by your somewhat dismissive comments regarding the Security Technical Implementation Guides (STIGs) in Episode 1018.  The STIGs" - and they are at https://, and Leo, you should go there, public.cyber.mil/stigs - "represent an authoritative resource for secure systems deployment.  The voluminous..."



LEO:  Voluminous, yes.



STEVE:  Voluminous.  There it is, voluminous.  Thank you.  I got started off on the wrong foot.



LEO:  Yeah, you've got to start right, voluminous.



STEVE:  "The voluminous STIG documentation" - and it is voluminous - "and tools are provided free of charge" - in the upper right, click on STIGS - "free of charge including the Security Content Automation Protocol benchmarks.  Misconfiguration has been and remains a primary threat vector, and following guidance such as that provided by the STIGs or the CIS Benchmarks in the deployment process is a critical preventive control.  Your show is a valuable resource for security practitioners that helps elevate the state of the practice across the community.  It would be a disservice to minimize the potential value of a resource such as the DISA STIGs.  Kind regards, John Rostern."



LEO:  Nice.



STEVE:  So thank you, John.  I stand before you willingly chastened. I did not intend to be dismissive of the STIGs because I was not at all familiar with them.  But I'm always wary, just sort of generally, of bureaucracy and, by extension, the trappings of bureaucracy.  This is why, for example, I've been so pleasantly surprised by the value and effectiveness of CISA.  You know, value and effectiveness is never what I expect from government agencies, especially cyber agencies.  So thank you for correcting me on the matter of the value of the STIGs.  For anyone who's interested in the Security Technical Implementation Guides, I have a link to them, which John provided, in the show notes.



Michael Swanson said - and it appears that many of our listeners have encountered these STIGs.  Michael said:  "Hi, Steve.  In a recent episode Dan Linder brought Security Technical Implementation Guides (STIGs) to your attention.  I thought a little more info might be useful to your listeners as STIGs are very useful in hardening systems against threat actors.  These STIGs are created and maintained by the U.S. Department of Defense in cooperation with the manufacturers and developers of various hardware and software.  They are reviewed and updated continuously with a quarterly publishing cycle.



"STIGs exist for a wide variety of hardware devices (most notably firewalls and network switches), operating systems (Windows, macOS, various Linux distros, VMware, iOS, Android, et cetera), web browsers (Chrome, Firefox, et cetera), common applications (MS Office, Adobe, et cetera), even Active Directory, one of the most important if you want to keep attackers from moving laterally in your network.



"As Dan mentioned, some of the settings are policy and procedure (user accounts are deleted from the system when an employee leaves the organization and so forth), while others are technical (two factor authentication is required to access the system).  Bottom line, these checklists of settings work.  Searching for 'DISA STIG' will take your listeners to the library.  Best regards, Mike Swanson."



So Mike, thank you.  This makes absolute sense.  I went over - oh.  I know where I was, Leo.  It was at STIGviewer.com (S-T-I-G-V-I-E-W-E-R dotcom /stigs) and took a look around.  There is a lot of interesting security content organized by the name of the hardware or software that's the topic of each of the many individual Security Technical Implementation Guides.  You can go to STIGviewer.com and then just choose "STIGS" in the upper - that's what I was thinking of, in the upper-right-corner top-of-screen menu - to see a huge alphabetically sorted list of very useful security-hardening checklists.  I will be, my next Windows server will be, I think it's Windows Server 2022, which was the latest, the last of the Windows 10 equivalents.  And they have a long list of things you absolutely positively want to do.



I already stumbled on one that was a little gotcha in IIS, some weird thing that was not blockable that would allow an undocumented protocol to get through.  And I thought, whoa.  And it worried me, like what else is in there?  So I will definitely be going through the list before I deploy Windows Server 2022.  It looks like a great resource.  So thank you, listeners, for not letting me just blow that off because I didn't know any better.



LEO:  Good.



STEVE:  And Leo?



LEO:  Yes.



STEVE:  Let's not blow off our last supporter, sponsor.  And then we're going to talk about, doo-to-doo, Multi-Perspective Issuance Corroboration.



LEO:  Finally.



STEVE:  And why all Certificate Authorities gotta have it.



LEO:  1020 episodes, we finally got around to it.



STEVE:  Well, it didn't exist until last week, but okay.



LEO:  Never mind.  Our show today - well, in that case we're on it.  We are on top of it.



STEVE:  Oh, baby.  Oh, yeah.



LEO:  Breaking news.



STEVE:  We got you some of that multi-perspective issuance corroboration.  You betcha.



LEO:  It's finally here.  Steve, now, whatever the hell this is, multi-perspective issuance corroboration, it's time to dig into it.



STEVE:  That's right.  Today's main topic was an outgrowth of an interesting change that the famous CA/Browser (CA/B), CA/Browser Forum just ratified.  The CA/Browser Forum consists of those people who determine what criteria are needed for web browser certificate issuance, how long various issued certificates will be permitted to live, how browsers will deal with certificates, and everything else that's relevant surrounding the increasingly crucial need for clients on the Internet - whether they be people or automated systems - to be assured that the servers they're communicating with at the other end, somewhere else, anywhere else, in the world are really the entity they claim to be.



A couple of weeks ago the CA/Browser forum agreed to - and this was a unanimous agreement - agreed to significantly up the ante for all Certificate Authorities everywhere - on one crucial aspect of the mechanism that is relied upon for verifying the ownership and control of the domains for which certificates are being issued.  I first learned of this from Google's announcement of this news.  Google wrote, because of course Google is an active participant in the CA/Browser Forum thanks to Chrome, and they have their own root program.



They said:  "The Chrome Root Program led a work team of ecosystem participants, which culminated in a CA/Browser Forum Ballot to require adoption of MPIC" - which is the initials of today's podcast topic - "via Ballot SC-067.  The ballot received unanimous support from organizations who participated in voting.  Beginning March 15, 2025" - so that's last month, middle of last month - "CAs issuing publicly-trusted certificates must now rely on MPIC as part of their certificate issuance process."  Whatever that is.  "Some of these CAs are relying on the Open MPIC Project to ensure their implementations are robust and consistent with ecosystem expectations."



Okay.  So something recently happened in the world of web server certificate issuance.  This whole area is a fascinating subject which this podcast has spent time examining through the years.  So what exactly is MPIC?  Here's how Google explains it, and then we're going to digress.  So Google said:  "Before issuing a certificate to a website, a Certificate Authority must verify the requestor legitimately controls the domain whose name will be represented in the certificate.  This process is referred to as 'domain control validation,' and there are several well-defined methods that could be used.  For example, a CA can specify a random value to be placed on a website, and then perform a check to verify the value's presence has been published by the certificate requestor.



"Despite the existing domain control validation requirements defined by the CA/Browser Forum, peer-reviewed research authored by the Center for Information Technology Policy of Princeton University and others highlighted the risk of Border Gateway Protocol attacks and prefix-hijacking resulting in fraudulently issued certificates.  This risk was not merely theoretical, as it was demonstrated that attackers did successfully exploit this vulnerability on numerous occasions, with just one of these attacks resulting in approximately $2 million of direct losses."



Okay.  So "Multi-Perspective Issuance Corroboration (referred to as 'MPIC') enhances existing domain control validation methods by reducing the likelihood that routing attacks can result in fraudulently issued certificates.  Rather than performing domain control validation and authorization from a single geographic or routing vantage point, which an adversary could influence as demonstrated by security researchers, MPIC implementations perform the same validation from multiple geographic locations and/or Internet Service Providers.  This has been observed as an effective countermeasure against ethically conducted, real-world BGP attacks."



Okay.  So let's clarify this.  In order to really understand the problem, we need to first revisit the operation of the Internet at its most fundamental level.  It's been a long time since we've done that, so let's first do a quick bit of review about how exactly the Internet works.  As we discussed way back in the dawn of this podcast, the brilliant way the Internet works and the thing that has ultimately been wholly responsible for the Internet's robustness, is that it has never tried to be perfect.  Its original brilliant design relied only upon a "best effort" packet routing system.  In this system, data to be sent from point A to point B was first "packetized" by breaking anything larger than a packet, which is around 1500 bytes, into multiple individual packets.  Each individual packet indicates where it's from and where it hopes to go.  The packets are then dropped one by one onto the Internet.



The Internet itself, as we've come to know it, consists of a massive network of so-called "big iron" Internet routers, each of which is connected to a bunch of its neighboring big-iron Internet routers.  Each of these routers has multiple high-bandwidth interfaces, each of which connects to other similarly well-connected Internet routers.  So the Internet itself is actually nothing more than a huge global quilt of large industrial-strength routers, each of which is interconnected to its nearest neighbors in a huge, largely ad hoc, array.  The Internet's users are individually connected to one of these big local Internet routers by their ISP, which then drops their packets onto the big iron router that's run by the ISP.  So that's the entire structure.  That's it.



So upon a packet arriving at the first Internet router, that router obtains the packet's requested destination, then looks up the destination in its own routing table to determine which of the many other big iron Internet routers it should send that packet to in order to move that packet closer to its requested destination.  So the packet is then forwarded to that next router which moves it closer to its intended recipient.



These individual routers have receiving buffers on their interfaces which allow incoming packets to queue up while they're waiting to be forwarded.  But it might happen that too many packets arrive from too many different interfaces, all requesting to be forwarded out through the same destination interface, and that might not be physically possible.  There's too much incoming, all trying to go out of a narrow pipe outgoing.  In that case, the router's incoming packet buffers would overflow, with nowhere left to temporarily store any newly arriving packets, and those packets would be dropped and lost forever.



At first this might seem like a very bad thing, like a critical flaw in the fundamental design of the system.  But it turns out that this reflects the original brilliance of the Internet's designers.  They said, okay, no, that's not good.  So let's make it okay.  Let's make it survivable.  Let's design the protocols that place these individually potentially lost packets onto the Internet in such a way that a packet loss is okay.



So, for example, in the case of the UDP protocol being used for DNS lookup, if an answer to a query for a domain's IP address that was sent out in a UDP packet, just sort of hopefully and blindly, if it's not received within a reasonable amount of time, the query will be retried and often reissued to all the other DNS servers that the client knows about.  And this will continue, the retrying will continue until it finally gives up.  But a lost packet will just simply be retried.



So, crazy as it might seem at first, every Internet protocol that generates and receives individual Internet packets assumes that its packets may not arrive at the other end and arranges for that possibility.  This brilliant design decision takes the pressure off the Internet's packet delivery system, which is simply a massive ad hoc network of loosely interconnected routers.  That's all it is.  A whole bunch of routers, all connected to each other.  This allows them to do the best job they can of receiving packets on their various interfaces and sending them along their way toward their destination by routing them out of other interfaces.  And if incoming packet buffers overflow, that's not the router's problem.  The protocol which originally generated the packet will deal with that.



Okay.  So what does all this have to do with BGP?  This massive network of interconnected routers need some means of knowing which IP address ranges should be sent out of which of their many interfaces.  To answer this question, each router contains a routing table to specify which addresses can eventually be reached through which interface.  How are these big routing tables determined and maintained?  That's where the Internet's BGP, the Border Gateway Protocol, comes in.  BGP is used by the Internet's big iron routers to coordinate, synchronize, and update their understanding of which packets should be sent where.



An ISP's big iron Internet router uses BGP to "advertise" the various blocks of IP addresses it has been assigned, "it" the ISP has been assigned by the Internet's governing bodies and which its customers are busy using.  BGP sends this information to all the routers that connect to the ISP's router so that they in turn know to forward any packets they receive on any of their other interfaces to the interface with which they connect to the ISP's router.  After setting up their own routing tables appropriately, each of those routers in turn use BGP to forward their updated routing tables to all of the neighbors that they connect to, and so on and so on and so on, until eventually every big iron router anywhere on the Internet has received the information, the propagated information, about where to send any packets that are destined for that ISP's big iron Internet router.



And believe it or not, this entire system works, and it works with astonishing reliability that we're all spoiled from now.  When it fails, failures are generally local and are quickly fixable.  The system is not perfect.  Through the years we've covered the news of mistakes, innocent mistakes made with the Internet's big routers which, for example, for a few very hectic minutes might attempt to route all of the entire Internet's traffic through a bungalow in Myanmar.  But, you know, perfection is understood to be impossible, so a system that's self-healing and resilient in the face of mistakes is what we want, and it's what we have today.  And also through the years, the original vulnerabilities in these systems have been found, recognized, shored up, and improved.



So this finally brings us back to the rules change that the CA/Browser recently enacted.  In order for me to obtain a TLS certificate from DigiCert, my Certificate Authority, for the GRC.com domain, I need to demonstrate that I'm in control of the GRC.com domain.  So DigiCert gives me a simple file with a random gibberish name, and random gibberish data content, for me to place in the root directory of my web server at GRC.com.  Once I've done so, I let DigiCert's automation know, and it attempts to obtain that file by that name, with the proper contents, from the root of GRC.com.  If that can be done, that proves to DigiCert that, whoever I am, I'm able to affect the content of the website located at GRC.com, which no one else is supposed to be able to do, and thus I'm allowed to obtain an identity certificate which covers that domain.



But here's the problem:  When DigiCert's automation reaches out to my web server at GRC.com, it's just sending packets to, you know, DigiCert is sending packets to its ISP in Utah, which then drops them onto its big iron Internet router for them to then be sent from Utah to my ISP in California and then to GRC's web server.  In other words, DigiCert in Utah connects to my web server in California which has the IP address of GRC.com, and verifies the contents of a specific file which they created for the purpose.



The implicit and crucial assumption is that the packets DigiCert caused to be dropped onto the Internet in Utah were actually routed to and received by the web server at GRC.com in California.  Everything about the legitimacy of the certificate GRC has requested depends and relies upon the truth that DigiCert obtained that file from my web server and not from someone else's.



A so-called BGP Prefix Attack involves someone arranging to insert the network prefix for a small network into a big iron Internet router which would then cause it to misroute any packets bound for any IP address within that small network prefix.  In other words, the traffic for a specific network would be effectively hijacked.



Following further with our example, if this were done to a router near DigiCert through which the packets bound for GRC was traversing, those packets would be sent, not to GRC, but presumably to an attacker.  In doing this, the attacker's server, not mine, would be hosting the domain control validation file, and they would be proving that they, not I, control the GRC.com domain.  And DigiCert would then, having done their due diligence, issue them a web server TLS identity certificate for my domain, GRC.com.



And here's the crucial point:  The only way and reason this BGP router prefix-hijack attack works, which as Google mentioned has been shown to be real and effective and has proven to be a true problem, is that a router close to DigiCert, through which an attacker was certain DigiCert's packet traffic destined for GRC.com would be flowing, could be compromised.  While this compromise was in place, and my web server at GRC.com was effectively unreachable by DigiCert, it would still be reachable by everyone and anyone else located anywhere else through other non-compromised routers.



And this brings us to the need for MPIC, Multi-Perspective Issuance Corroboration.  And now we know what that term means.  With the researchers at Princeton University's Center for Information Technology Policy having demonstrated the real world feasibility of these BGP prefix-hijack attacks, all Certificate Authorities going forward must perform domain control validation from multiple geographically diverse locations.



Immediately, as of March 15th last month, validation must be made from at least two remote network perspectives.  CAs have a year to bring that number up to three, and from at least two distinct Regional Internet Registry regions.  By June 15th of next year, 2026, that number grows to four, also from at least two RIR regions.  And by the end of next year, December 2026, at least five remote network perspectives must be used in order to verify domain ownership and validation.  Five.  Wow.



So it's clear that, once again, these guys are not taking any chances.  It would be so supremely difficult to somehow arrange to simultaneously intercept traffic originating from as many as five different locations that it's safe to say that this makes this mode of validation attack infeasible and takes it off the table.



LEO:  Very cool.



STEVE:  So that is MPIC, Multi-Perspective Issuance Corroboration, you know, verifying ownership of a domain from multiple perspectives on the Internet in multiple locations.



LEO:  You could still screw up the border router, though; right?



STEVE:  Yes.  The Border Gateway Protocol, I mean, it's, you know, it's meant to be resilient, but it can happen.



LEO:  Yeah, yeah.  That's cool.



STEVE:  And I also wanted to note I heard your mention of the passing of the guy who...



LEO:  Bufferbloat man, yeah.



STEVE:  And we talked about bufferbloat on the podcast and explained that it was messing things up because the Internet is designed to drop packets, and consumer router manufacturers thought, oh, we've got so much RAM, we'll have big buffers, and then it'll be great the packets aren't dropped.  Well, it messed everything up.



LEO:  That's not what you want.



STEVE:  You want to drop 'em.



LEO:  Yes.  He was only 59.  He was a young guy.  Let me see if I can pull up the story because we did, we talked about it on This Week in Tech on Sunday.  And it was, it was a sad story.



STEVE:  Do we know how, I mean...



LEO:  We don't know what happened, no.  The only reason I knew what happened is Eric Raymond, ESR, posted something on X, eulogizing him.  That's why I want to get the story because I've forgotten his name now.  But that's kind of the story, in a way, is this technology that saved all of us, you know, bufferbloat was discovered and corrected, pretty much.



STEVE:  Yup.



LEO:  By this one guy.  So it's kind of a neat story.  Let me see if I can - oh, shoot.  Where is his name?  I did so many stories.  I'm looking through the show notes, and I don't see it.  So, but yeah, it was a very...



STEVE:  Toward the end of a podcast.



LEO:  Yeah, you'd think that these show notes would be in order, but - his last name was Taht, I think, T-A-H-T.



STEVE:  E, I think it had an E on the end?



LEO:  Maybe it had an E on the end.  Oh, now, this is going to make me mad because I do want - I do think we should bring it up real quickly.



STEVE:  How about we just - what if we google "bufferbloat"? 



LEO:  Google bufferbloat.  Why is it not in the show rundown?  That's the strangest thing.  I must have accidentally deleted it after the show was over or something.



STEVE:  Okay.  Wikipedia's got an entry, and I'll bet they give him credit.



LEO:  Sure.  Dave Taht (T-A-H-T) is his name.  And here's the eulogy from Eric S. Raymond, who of course is a well-known open source guy, wrote "The Cathedral and the Bazaar."  He says:  "Dave Taht" - there's an umlaut over the "a" - "died yesterday, one of the unsung heroes of the Internet."  He discovered bufferbloat and then went out and basically got router manufacturers to fix it.  So it's less of an issue right now.  So something to note.



STEVE:  Yeah.  Wikipedia says it was initially described back in '85, and that of course predates this podcast.  But it gained more widespread attention starting in 2009, and that's when you and I were together, and we said, hey, let's talk about this.  It's cool.



LEO:  Yeah.  There's his X account.  He lived in Half Moon Bay.  There's not much more except that Eric Raymond message.



STEVE:  Lost him too young.



LEO:  Yeah.  And I guess he might have been on FLOSS Weekly back at March because Dave re-shared a FLOSS Weekly link.  So, yeah.  Unexpected, I think.  I gather.  Dave Taht, a guy whose name very few of us know, even those of us who know what bufferbloat is.  But we do own him a debt of gratitude.  So thank you, Dave.



Copyright (c) 2025 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#1021

DATE:		April 15, 2025

TITLE:		Device Bound Session Credentials

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-1021.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  Android to get "Lockdown Mode."  What's in the new editions of Chrome and Firefox?  Why did Apple silently re-enable automatic updates?  My new iPhone 16, Chinese tariffs and electronics.  Dynamic "hotpatching" coming to Win11 Enterprise & Edu.  Why is it so difficult for Oracle to 'fess up?  Another multiyear breach inside U.S. Treasury.  An Apple vs. the UK update.  "Thundermail."  (Can't someone come up with a better name?)  The (in)Security of Programmable Logic Controllers.  When LLMs write code and hallucinate nonexistent packages.  WordPress core security, and PHP gets an important audit.  Device Bound Session Credentials update session cookie technology.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about, well, there's a lot of things.  The 100-some fixes in Microsoft's Patch Tuesday last week.  Why it's so difficult for Oracle to 'fess up.  An Apple vs. the U.K. update, and the arrival of Thundermail.  All that and more coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 1021, recorded Tuesday, April 15th, 2025:  Device Bound Session Credentials.



It's time for the moment you wait for all week long, Security Now!, the show where we cover your security, privacy, your safety online with the king of all of that stuff, Mr. Steve "Tiberius" Gibson.  Hello, Steve.



STEVE GIBSON:  Actually, Leo, what they're waiting for all week long is the next protracted event in their life, typically a five-hour commute or a plane flight or something.



LEO:  Oh, yes, something they can listen to this show and...



STEVE:  Yes, because now it's in their queue, and it's time to spool this into their brain.  And, boy...



LEO:  Think of us...



STEVE:  ...have we got a spool for you today.



LEO:  Think of us as a pressure driver, spooling up all this information for you to unwind.



STEVE:  Yes, even the title needed to be spooled because it...



LEO:  It's a little...



STEVE:  It stretched out the screen there down at the bottom.



LEO:  Yeah.  What is Device Bound Session Credentials after all?



STEVE:  Okay.  So for Security Now! Episode 1021 for Tax Day - and by the way, I heard you saying before you could be listening to MacBreak Weekly while doing your taxes.



LEO:  Yes.



STEVE:  And I thought, only if you have a time machine, and once they're finished, you can go back.  Unless you're filing estimated, in which case...



LEO:  You could be listening right now and doing your taxes.



STEVE:  Oh, that's true.  And then get in line...



LEO:  You don't have to mail them till midnight.  You've got time.



STEVE:  Yeah, that's true.



LEO:  And maybe, it's just me, but I always, I mean, I did mine yesterday.  I was way ahead of the game; okay?



STEVE:  That's right.  Yeah.  Well, that's - you had the day off.  No podcasts to do.



LEO:  I think it's - you know what's funny, I actually listened to an old TWiT while I was doing it.  I don't know why, I just - Dan Patterson sent me an email saying the first time - he was on TWiT on Sunday - "The first time I was on was back in 2009," this episode.  And it had - it was a great episode, had all these great people.  And I thought, I'll listen to it.  And it was kind of fun to hear about the beginnings of surveillance capitalism.



STEVE:  How was Sunday's big anniversary TWiT?  I haven't had a chance to...



LEO:  Oh, Steve, we had so much fun.



STEVE:  Aww.



LEO:  Because I had more than 20 videos from listeners and viewers talking about when they first found TWiT.  It was very - it was wonderful to celebrate the audience.  You know this because you get the emails and the comments.



STEVE:  Yeah.  I have a good connection.



LEO:  We love our audience.



STEVE:  Yeah.



LEO:  We really do.  And so I thought, to celebrate 20 years of TWiT, you're going to be celebrating 20 years of Security Now! in a few months, it'd be fun to, instead of honoring the hosts or the things we've done, to hear from the listeners.  And it was really great.  I really enjoyed it.  We had a fire eater.  We had a guy on a boat.  We had, not one, but two guys in tractors.  I mean, it was a very interesting...



STEVE:  Oh, I thought you were going to say "traction."  It's like, whoa.



LEO:  No, nobody was in traction.  There was one person incarcerated, however.  One prisoner sent us an email.



STEVE:  He got good bandwidth connection?  Can he...



LEO:  He, and I didn't know...



STEVE:  Because those steel bars, they tend to block WiFi.  That's not...



LEO:  No, no, no.  They give him an iPad with podcasts on it.  And I don't know if we were ever asked, but apparently Security Now! is on some of them.  This one he only was able to get one of the shows, TWiT.



STEVE:  I don't know if you want Security Now! going into the prison, Leo.



LEO:  Maybe that's - maybe the warden says...



STEVE:  How do I do that hack again?  How do I get over to Russia?  How do I call a strike?



LEO:  You know what, good point.



STEVE:  Anyway, so, oh, boy.  This is going to frost your snow cone, Device Bound Session Credentials.  What we finally have, after 35 years, is a change in the way we manage session cookies, session cookies being the cookies which our browsers receive which continually identify us to websites that we're logged into, the session being our logged-on session.  And I'll go back over a little bit of the history of this when we get to it later today, sometime this evening, because we have a lot to cover today.



LEO:  It's going to be a long show?  Is that what you're telling me?  I'd better go get lunch.  Okay.



STEVE:  But, yeah.  You can maybe plan your vacation.  So...



LEO:  I'll do my taxes for 2025.



STEVE:  But don't take it yet because, yes, you do have to lick the stamp on your taxes.



LEO:  Yes, I do.



STEVE:  Anyway, we're going to talk about the industry finally coming up with what looks like the replacement for and far more security connected to maintaining logged-on state with browsers.  And really, we've been asking an awful lot of the lowly cookie which was created, you know, as I said, back in the mid-'90s by some guy named Lou at Netscape.  Anyway...



LEO:  I didn't know his name.  That's funny.



STEVE:  Oh, yeah, Lou.  We're going to have a lot of fun.



LEO:  Lou's cookies.



STEVE:  And I'll explain that you do not need to understand it all on this first pass.  We're going to be - no doubt we'll be looping back to this a number of times because this is big news.  This is a change in the way we, like, the security of logging on in terms of the browser identifying it to the server.  And it is very cool.  I mean, like we have so much in our toolbox now with all of the crypto that we're able to bring to bear, rather than some little gibberish of ASCII that is like, oh, that looks like him.  Anyway, we're also going to, before we get to that, because that's just the coup de grace, we've got Android believed to be getting a lockdown mode next month.  What's new in updates to Chrome and Firefox, and there is some cool stuff.  Actually, it was the blurb about Chrome that put me onto this.  And then I saw that Firefox and Safari were also already working on this.



Why did Apple silently reenable automatic updates?  My new iPhone 16, Chinese tariffs, and electronics.  Dynamic hotpatching coming to Windows 11 Enterprise and Edu.  Cool new tech from Microsoft.  Why is it so difficult for Oracle to 'fess up to what is obvious to everybody else that happened?  We have another multiyear breach uncovered inside U.S. Treasury, making it the third of three.  An Apple vs. the U.K. update.  Something I just - I can't get over the name that they've given this, Thundermail.  And can't we get a better name?



LEO:  Thundermail.



STEVE:  You know, it works for a bird to put "thunder" in front of it.  It's like, you know, thunder...



LEO:  It sounds like a male strip show, like Thunder Male Down Under.  



STEVE:  It just, every time I see it, I go, oh, god.  I'd be embarrassed to be steve@thundermail.com.  Anyway, Mozilla's going to do something.  We also have the insecurity of programmable logic controllers, why that matters.  Oh, and Leo, it turns out that - you probably ran across this because you're amazingly up to date and informed, I find - when LLMs write code and hallucinate non-existent package names...



LEO:  I know the perfect library for this code, yeah.



STEVE:  ...it's going to be weaponized, yes.



LEO:  Yeah.  I guess so, yes, if you know ahead of time, yeah.



STEVE:  So, and it's got even a worse name than Thundermail, it's slurp something or other.  It's like, oh, my god.  Well, anyway, we'll be covering it today.  We also have WordPress's core security.  And PHP had a very important audit funded, and the problems they found are barricaded.  No one is talking about them because they're so bad.



LEO:  Uh-oh.  So bad, yeah.



STEVE:  So, but they're being fixed.  And I think what we're going to end up seeing, as we'll see, is an important retroactive, you know, everybody who still has supported versions of PHP, uh, now would be a good time to update them.  Also, once all that's done, if there's anything left of us, we're going to talk about Device Bound Session Credentials.  And I so much want to hyphenate Device Bound.  It's not.  And it's like, that's wrong.  But, you know, we put up with referer being misspelled in HTTP headers all our lives.



LEO:  That's right, one "R," yeah.



STEVE:  So I suppose we'll leave off the hyphen in Device Bound.  Oh, and of course we've got a great picture.  So maybe, Leo, we actually have a good podcast this week.



LEO:  Maybe?



STEVE:  I hope we don't disappoint.



LEO:  No maybe about it, Steve.  I guarantee, I guarantee it.  Boy, you're a stickler.  I didn't even really think about this.  But you're right, device-bound should have a hyphen, shouldn't it.



STEVE:  Bugs me.



LEO:  Yeah.  I never even thought about that.  Well, we just have to go with whatever the IETF thinks is right.



STEVE:  Maybe somebody at the World Wide Web Consortium is listening to this podcast and thinks, he's right.  That's a typo.



LEO:  Put in a hyphen.  That's a typo. 



STEVE:  Let's fix that.



LEO:  Steve Gibson, ladies and gentlemen.  We'll get to our hyphenless discussion in just a moment.



STEVE:  Well, and you know, if you were entitled to watch the game while you were home...



LEO:  Right.



STEVE:  ...and you were traveling...



LEO:  Right.



STEVE:  ...then it's not like you're doing anything wrong by still watching it.



LEO:  No.  In fact, I asked Netflix because I thought, well, should we be promoting this.  They said, as long as you have a Netflix account, you can be watching Netflix in any other geographic location.  That's fine.  So that's, you know, that's what you can use a VPN for, too.  And it's the only reason, you know, people say, well, you should use Tailscale or something local.  But I can't do that, really.  That doesn't work as well if I want to be in London because my house is not in London.  So there's an advantage to using ExpressVPN.



STEVE:  More flexibility.



LEO:  More flexibility.



STEVE:  All right.  So...



LEO:  Let's take the Picture of the Week here.



STEVE:  I think we're going to have to not expose what this picture reveals because it would be a spoiler for those who want to encounter it and solve this puzzle themselves.  Because this picture is...



LEO:  It's a puzzle.



STEVE:  It takes the form of a puzzle, yes.



LEO:  All right.  I'm going to scroll up.



STEVE:  So by all means.



LEO:  And I see Neil DeGrasse Tyson.



STEVE:  Yup.



LEO:  And I can read it right away.



STEVE:  Yup.  See, I knew you would be able to.



LEO:  Yeah.



STEVE:  Yes.



LEO:  But I won't tell you what it says.



STEVE:  You cannot tell us what it says.



LEO:  But this is a famous example.  I've seen other examples where they don't add numbers for letters, but where they take away letters.



STEVE:  Okay, right.



LEO:  And it shows you how adaptive the human mind is.



STEVE:  Yes.



LEO:  How able to fill in the gaps we are.



STEVE:  Yes.  Yes.  So this picture, I gave it the caption "Here's one to think about."  And it's a T-shirt that Neil deGrasse Tyson is holding up, credited to a famous physicist in our midst.  And I think everyone will enjoy taking a look at the picture.



LEO:  Do people have a hard time reading this?  Do people look at this and go "I don't know what it says?"



STEVE:  Yes.



LEO:  Really.



STEVE:  I've had some feedback saying that they, you know, had to spend some time thinking about it.



LEO:  Interesting.



STEVE:  So, and I knew you wouldn't, Leo, because you're just - you're no fun.



LEO:  It's not LEET, exactly.  Well, it's pretty close to LEET.  It's pretty close to LEET.  So maybe it's - I've spent too many years reading leetspeak.



STEVE:  Ah, that's a very good point.  It bears a strong resemblance to that.



LEO:  Yeah, yeah.



STEVE:  Okay.  So nothing's been announced yet, and it's certainly not official. But it would make sense for Android to follow in Apple's footsteps with a higher security mode for their handset, similar to what Apple calls "lockdown mode."  And with Google's annual I/O developer conference happening next month, it might be announced then, which might make it available in, you know, kind of the August-September timeframe as part of Android 16.



It's believed that Google has been quietly working on a new, more secure mode for Android that, as I said, was probably inspired by Apple's iPhone Lockdown Mode.  According to a placeholder documentation page, which currently 404s, and based on analysis of Android Beta images, the new feature would be named the Android Advanced Protection Mode (AAPM).  As with Lockdown Mode, AAPM would not be intended for regular Android users.  It would be of use for probable target individuals who are more likely to face threats from oppressive regimes, you know, advanced spyware, network surveillance attacks and so forth.



It's believed to disable older and less secure 2G cellular connections; block users from sideloading apps from unknown sources.  Presumably it prevents them from running apps that have already been sideloaded, I would imagine.  I don't know.  Enable "Memory Tagged Extension," which is a feature to block the exploitation of memory-related exploits; and force a reboot of any devices after more than three days of disuse.  That forced reboot feature was spotted by Android Authority as a means of flushing RAM of any resident malware that may have taken up residence in the device during its owner's absence through whatever means, but then wasn't able to obtain persistence so that it, you know, wasn't able to write itself into the file system.



Although Google has offered no official confirmation of any such new Android Advanced Protection Mode, a large amount of code to support it is present in Android 16 betas.  We've seen instances where something ended up in a further in the future release, not the most current, next, you know, forthcoming release, so maybe not 16, maybe not till 17.  But this doesn't - it's not like this is rocket science, to like turn off things that it already has.  So why wait?  Anyway, the fact that it's in 16 Beta suggests that it will probably be official soon.  Android Authority found the message that informs users that they may not sideload apps.



There's also support - I thought this was cool - for a new API which allows apps to detect whether the handset mode has this enabled so that they may apply any of their own security-enhancing behavior.  You know, for example, a web browser might disable its internal JIT, its Just-In-Time compilation mode, when it detects that the handset is in this advanced protection mode because we know that the Just-In-Time compilers tend to be where a lot of security flaws have been found to reside in the past.  Or, you know, another example may be Instant Messaging apps might disable their automatic display of multimedia content since, again, we've seen security vulnerabilities often discovered and leveraged in the interpreters that are used to display media.



So there are signs that something resembling Apple's Lockdown Mode may be coming soon to Android.  And, you know, like Lockdown Mode, it probably reduces the device's convenient functionality too much to be used by most people.  But, you know, it would make the smartphone much less fun to use.  But the tradeoff is convenience versus security.  And in this case, you know, you would be opting for security if you for some reason didn't have an Apple device, and this allows Android to do that.



Also while I was perusing recent news I saw that Chrome had recently moved to their release 135, and Firefox was now at 137.  Among the changes, as I mentioned, in Chrome was the title of today's podcast, missing its hyphen, "Device Bound Session Credentials," which we'll be getting to here for a very deep technical dive at the end of today's podcast.  But nothing else really stood out about Chrome's 135 beyond that.



The biggest news for Firefox 137 appears to be Tab Grouping, although the ability to use Firefox URL field as an ad hoc calculator for quick math actually excites me more, and I'm sure it's going to get much more use by me.  Anyway, somehow I've broken the habit of having a seemingly near infinite number of tabs serving as placeholders for things I plan to get back to eventually.  I remember maybe 10 years ago I had over there to my left a Firefox browser, and if it ever crashed, or I lost its tab lineup, it was my knowledge base.  I had so many open tabs.  I don't do that anymore.  I don't know what happened.  But I just kind of got out of that, I guess.  But I know from our feedback from our listeners of this podcast that there are many people who do still organize their life around browser tabs.  And this is probably going to be a godsend for them.



So the Firefox 137 blog page explains, says:  "Tab groups begin rolling out today.  Stay productive and organized with less effort by grouping related tabs together.  One simple way to create a group is to drag a tab onto another, pause until you see a highlight, then drop to create the group.  Groups can be named, color-coded, and are always saved.  You can close a group and reopen it later."



Okay, so I thought, great, let's try it.  But no matter what I tried, and I was using Firefox 137 when I attempted to drag one tab on top of another.  At some point, presumably once some center line somewhere was crossed, the underneath fixed tab that I was in the process of covering up would suddenly scoot over to fill the gap that was left from the tab I was dragging.  No matter what I did, I was unable to, in any way, merge two tabs into a single group.  I'm just telling everybody in case they have the same experience that I did that it didn't work for me.



Then I noticed that the phrase "Tab groups" was highlighted in the blog posting as a link.  Clicking that, I discovered the likely cause of my trouble.  That more detailed page, after I drilled down, said:  "Starting in Firefox version 137, you can use tab groups to manage open tabs in Firefox by grouping them together and labeling them."  Okay, right.  Except it's not working.  Then it said: "This feature is experimental and is being introduced" - I'm like, how hard is this to do?  Why do you have to experiment with it?  Anyway, it's being introduced to the Firefox user base through a progressive rollout.  It may not yet be available to all users.  Number me among them because I just can't get two tabs to merge.



So okay.  You know, the Mozilla folks seem pretty excited about this, and they also noted that Firefox's new Tab Grouping system also works for Vertical Tabs.  I long ago satisfied my absolute and utter need for vertical tabs using a pair of Firefox add-ons:  "Tree Style Tab," which allows a hierarchy of tabs; and also "Tab Session Manager," which allows me to save current sets of tabs as a session and keep them in XML files, load them, save them, restore them, move them around.  Love it.  Anyway, together those two things do everything I need.  But once support for native Tab Groups does finally arrive in my Firefox, which I don't yet have, I may look at switching to Firefox's native vertical tabs and using tab groups.  Maybe that'll give me the same stuff that I have now.



LEO:  I hate it when they do progressive rollouts like that.



STEVE:  Isn't it?  It's like...



LEO:   You just never know what features you have.



STEVE:  Right.  And Leo, how hard can this be?  You know, it's not like, oh, you know, we're going to upset people, or we're going to break things.



LEO:  Well, I think that's - I think it's more that than is this going to work.  I think it's more like people go, oh, my god, what happened?



STEVE:  I just, yeah, two tabs merged.  How do I unmerge them?



LEO:  Oh, they merged.



STEVE:  Wow.



LEO:  Oh, well.



STEVE:  Anyway, earlier I said that the feature that appealed to me most was the ability to use Firefox's URL field as a quick ad hoc calculator.  And even though that...



LEO:  That puzzles me.  Tell me how you do that?



STEVE:  Works.  You just start, like, 35+7.



LEO:  Really?  That's a weird feature.  Okay.



STEVE:  I kind of like it.  Anyway, that one was enabled for me, and it worked.  And it couldn't be any easier.  Mozilla writes:  "You can now use the Firefox address bar as a calculator.  Simply type an arithmetic expression" - and you can use parenthetical, you know, prioritizing and so forth - "and view the result in the address bar drop-down.  Clicking on this result will copy it to your clipboard."



LEO:  I wish I had known this when I was doing my taxes yesterday.



STEVE:  Ah, there you go.



LEO:  I had to fire up a calculator.



STEVE:  Anyway, yes.  And now, you know, I'm often reaching for the calculator that's located next to me at my workspace.  In fact, here it is.  I've never talked about this.  I love this.  This is from the SwissMicros guys.



LEO:  Oh, that's cool.  Is that an - it's an HP-51 clone?



STEVE:  It's an HP-35 calculator clone, so it's RPN.  It just - it's an extremely nice calculator.  Took me a little while to get used to it.  You can see that it's got next to the, up there, ABCDEF, so it's got - it's also hex.  So it's multi-base calculator.  Anyway, just I love this little thing.  It took a while to get used to it, but I've got one in each of my locations.  Anyway, so my point is I always have a calculator next to me.  But, you know, sometimes if I just want to do a quick little bit of math, it's now in the address bar.  Also what I noted was that this integrated calculator appears to be part of a larger address bar refresh and update.



LEO:  Ooh, it's 250 bucks.



STEVE:  Even though they sort of list it on its own.  Mozilla explains that we now have a Unified Search Button:  "A new, easy-to-access button in the address bar helps you switch between search engines and search modes with ease.  This feature brings the simplicity of mobile Firefox to your desktop experience," they said.  So I guess mobile Firefox has already had that, and now we're getting it on our desktop.  "Search Term Persistence," they said:  "Now when you refine a search in the address bar, the original term sticks around, making it easier to adjust your queries and find exactly what you're looking for."



They also have a Contextual Search Mode.  And this was freaky.  "Firefox detects if you're on a page that has search capability and offers that option to you directly to search from the page's engine from the address bar."  What?  Anyway, they said:  "Use this option at least two times, and Firefox will suggest adding the search engine to your Firefox."  Which that was interesting.  And then also finally "	Intuitive Search Keywords:  You can access various address bar search modes with convenient and descriptive keywords.  So, for example, you start with @bookmarks or @tabs, or @history, or @actions."  And the search will then be aimed at or focused on that specific aspect of Firefox.  So anyway, that "Contextual Search Mode" where Firefox is supposedly detecting pages which offer their own searches, to me that's surprising and seems both aggressive and error-prone.  So it'll be interesting to see how that all works out.



Anyway, beyond all this, Firefox 137 now identifies all links within the PDFs which its integral PDF viewer displays, turning them into hyperlinks, so it'll do that for you.  You don't have to, like, you know, copy and paste them and all that.  It's also possible to add your own signature to PDFs without leaving Firefox, and signatures can be saved for reuse later.  And also Firefox now provides native support for the HEVC media format codex under Linux.  So anyway, it occurs to me that all this further supports my ongoing contention that our web browsers have become incredibly complex, and only continue to become more so.



LEO:  And this from a guy who uses a Reverse Polish Notation calculator, ladies and gentlemen.



STEVE:  That is true.



LEO:  By the way, I did the search.  I found SwissMicros.



STEVE:  Oh.



LEO:  They have a whole bunch of different models.



STEVE:  They do.  Now, those little credit card size ones have very cheesy keyboards.  So, I mean...



LEO:  Nah, I don't want that.  Oh, you already ordered one, it sounds like.



STEVE:  Oh, I own them.  I own them all, of course.



LEO:  I want to get the DM42n.  That's...



STEVE:  And it's got - they have nice fonts.  They've got, I mean, there's just - they're so much in them.  These guys are just...



LEO:  You can connect them to external storage.



STEVE:  Yes, yes.  And you're able to upgrade their firmware.  They have a USB port along the top.



LEO:  This is pretty cool.



STEVE:  They're neat people.



LEO:  I might have to buy one.  And I have no use for it.  Zero.  I still might have to buy one.



STEVE:  Well, there's always tax time next year, Leo.



LEO:  That's right.  Oh, yeah.  That's what I bought it for, honey.  It's for taxes.  That's it.



STEVE:  No, I am, you know, often doing things.  I'm computing, you know, currents and microamps and milliamps.



LEO:  You've never shown me that before, I don't think.



STEVE:  I never have.  I've never mentioned it.



LEO:  Very cool.



STEVE: Yeah.  They are, they're neat people.  I mean, it is a well-made - because you cannot, you can no longer get, which just boggles my mind, any of the good HP Scientific Calculators.  The financial calculator was, like, the 15 or the 12.  I don't remember.  Not the 12.  Anyway, there's the financial calculators that HP still makes.  But they've given up, all the scientific ones are now algebraic notation instead of RPN.



LEO:  No.



STEVE:  And they've got big screens that do graphics and all this crap no one really needs.  They're just gimmicks.  And so these people, they're the real deal.  So, I mean, although we have 42 for our iPhone.  And so I wonder, I mean, that's a gorgeous calculator, too.  So...



LEO:  Yeah, yeah.  I'll put it next to my slide rule.  I should have a collection.



STEVE:  It's nice to have clicky buttons.  This thing's got beautiful, really nice, you know, keys. It's a great device.



LEO:  It's pretty cool.  I don't know what the price is because it's in Swiss francs, and I hate to see what the conversion's going to be.



STEVE:  It's a couple hundred dollars, and it takes a while to get it to you.  But, and I don't know what tariffs...



LEO:  What tariffs will do, yeah.



STEVE:  ...Trump has aimed at Switzerland.  But, you know, I haven't heard them mentioned.  So maybe they're just going to get the blanket tariffs.  But it's got semiconductors in it.  We'll be talking about that a little bit later because I was induced to upgrade my phone.  Let's take a break.  We're half an hour in, and we're going to talk about Apple and what they just did with their most recent upgrade, which caught some people by surprise.



LEO:  Yeah.  And by the way, there was one other reason that you might want this reboot thing after three days.



STEVE:  Yeah.



LEO:  If somebody steals your phone, of course it's great to wipe the memory.  But if somebody steals your phone, and they can't, you know, and they don't use it or you lose it, and they don't use it, it's nice to have it go into the fully locked mode.



STEVE:  Yes.



LEO:  After a reboot.  Because then it requires a password and all that stuff.  I'm sorry, I'm a little busy right now ordering something from Switzerland.  Don't - oh, he would want to - he would want to do an ad right now.  All right.  I got it.  I ordered it.



STEVE:  And take a look at the - for our listeners who are interested, it's SwissMicros.



LEO:  It's pretty cool.



STEVE:  All the documentation is there.  I mean, they're engineers.  They're Swiss engineers.



LEO:  Oh, yeah, look at the people who are making your SwissMicro.  I mean, this is a serious, serious device here.  That's on the...



STEVE:  That's what happens when we give up China, Leo, is we go back to...



LEO:  We'll make iPhones in the U.S.  Sure we will.  Sure we will.



STEVE:  Put some wheels on it.



LEO:  Wow.  Let me, yes, let's talk about the advertiser for this segment of Security Now! so you can get right back to our device bound...



STEVE:  And you can get back to ordering your next...



LEO:  I already bought it.  It's too late.  I've got it.  You've got to work fast on this show.  I bought the 42N.  I thought, why not just get the grandpa; right?  No idea what it's going to cost me.



STEVE:  What do I have?  I got the DM32, whatever it is.



LEO:  Yeah, yeah.  They both have RPN.  I want to write little software programs.



STEVE:  You've got to, oh, and fully programmable and, oh, and, yeah, it's cool.



LEO:  We were talking about Forth last week.  It's kind of like having a little Forth calculator in your house.  So this, the DHL delivery alone is 70 Swiss francs, so I may get it someday in the next six months.



STEVE:  DHL's a good delivery, though.



LEO:  Oh, yeah, for international you kind of have to use DHL, yeah.



STEVE:  Yeah.  Okay.  So a posting over in OSXdaily had the headline of a Public Service Announcement.  The headline read:  "PSA:  Automatic Update Enables Itself with MacOS Sequoia 15.4 & iOS 18.4."  Now, maybe the guy got up on the wrong side of the bed, as they say.  I'm going to share his posting.  There's a grain of this that I kind of agree with.  But, whoo, not quite to the extent that, I mean, he's really bent.



So he writes:  "This is important and relevant to most Mac, iPhone, and iPad users:  Installing the latest updates for MacOS Sequoia 15.4 for Mac, iOS 18.4 for iPhone, and iPadOS 18.4 for iPad will forcibly enable automatic software update for system updates on your device."



LEO:  Yeah?



STEVE:  Okay, now, given the fact that Updates can again be turned off, his use of the phrase "forcibly enable" seems maybe a little over the top.  That implies that it would no longer be possible to again disable automatic updates, which is indeed possible.  Anyway, the piece continues:  "Some people may already have these auto-update features enabled on their devices and not mind this change."



LEO:  Who wouldn't?



STEVE:  "Nor would they notice a difference."



LEO:  No.



STEVE:  "Whereas there may be other people who intentionally disable automatic update and do not wish to have the auto-update feature forced upon their devices."  Oh, well.  He writes:  "With Automatic Updates enabled, this means your Mac, iPhone, or iPad will automatically download and install system software updates onto your devices" - yeah, no kidding - "as they become available, without your approval or prompting."



LEO:  Well, that's not true.



STEVE:  I know.  "Automatic Updates may be problematic for many reasons.  For one," he writes, "not everyone has the bandwidth available" - in their brain, apparently - "to automatically download huge software updates.  Additionally, not everyone wants to install the latest software updates when they become available.  Many users prefer to wait a little while to see if there are any critical bugs or issues discovered before putting the latest system software on their device."  He says:  "And this is a reasonable caution.  Though it's not common, Apple has dumped out some bad software updates in the past..."



LEO:  That's true.



STEVE:  "...that had to be pulled due to various issues."



LEO:  That's true.



STEVE:  Yeah.  And, of course, many Mac, iPhone, and iPad users just simply prefer to manually update and manage their devices on their own, without the computer or device doing it for them.



LEO:  I've always has automatic turned on, and it always says, "There's an update.  Would like to proceed?"  



STEVE:  Yeah.



LEO:  It's just downloading it ahead of time.



STEVE:  Right.  He says:  "But your personal computing behaviors and your" - get this, Leo.  "But your personal computing behaviors and your opinion is irrelevant, as Big Cupertino knows what is best for you, your iPhone, your Mac, and your iPad."  Right.  "As we know, for the vast majority of their users they probably do know what's best."  And he says, he finishes:  "Apple has decided that you will have automatic updates enabled on your devices, and your installation of iOS 18.4, MacOS Sequoia 15.4, or iPadOS 18.4 was apparently used as an agreement to that setting change.  If you don't like that, you can change it back and disable automatic system software updates."  Well, and the rant continues, believe it or not.



LEO:  And by the way, you still can turn it off.  I'm just checking right now.



STEVE:  Of course.



LEO:  You can turn it off.



STEVE:  I did, too.  I did, too.  I went over and looked, and like, okay, there's a big switch.  Yeah.  He says, anyway, we don't learn anything more from him beyond the fact that this author really, really...



LEO:  Is upset.



STEVE:  ...dislikes the idea that Apple might feel that having automatic updates enabled for the masses is sufficiently important that it should be done.  I can certainly agree that it would have been polite for Apple to ask before re-enabling disabled automatic updates, since if Apple were to find them disabled on a device, it would have had to be deliberate on the part of the device's owner to turn them off.  But perhaps there are instances where that could have been malicious.  I don't know.  Maybe malware gets in and flips that off.



LEO:  Oh, good point.  Good point, yeah.



STEVE:  In order to keep itself around.



LEO:  That's exactly why they do it, yes.



STEVE:  Yes.



LEO:  But we've seen that kind of behavior in the past, yes.



STEVE:   Yes.  And there might be something that they have done with this update that they might actually need to emergency roll back.  But if automatic updates were off, they wouldn't be able to.  So maybe they're saying, look, look, you know, we need to just kick this on again so, you know, for safety's sake.  In any event, since I know there are many listeners of this podcast who do strongly prefer taking and having manual and deliberate control over the updating of anything, I wanted to make sure that everyone knew that the move to these latest macOS, iPhoneOS and iPadOS releases will have re-enabled, if we believe this guy, I don't know because I leave mine on, my phones are set to automatically update, so it was on after the most recent update, and I don't know if it turned it on.



LEO:  If it turned it off, yeah.



STEVE:  Yeah.  [Crosstalk]



LEO:  Benito's saying he turns all updates off, always, on all of his devices.



STEVE:  Yes.



LEO:  I don't know, did you notice 18.4 turning it back on again?  You know, there is something I do get upset about.  They turn on Apple Intelligence every single update.  That's like a five or six gigabyte download.  That you should get upset about because there's no security reason for that.



STEVE:  Yeah.  Let's let this guy know because that would be good for another big rant.



LEO:  Yeah, he's got a whole 'nother link baby blog post [crosstalk], yeah.



STEVE:  That's exactly right.  Okay.  Now, I also want to take a moment to note that I'm now the proud owner of a shiny new iPhone 16 Pro.



LEO:  Ooh, fancy.



STEVE:  Now, as I've mentioned before, I had been happily using an older iPhone 12 Pro without any problems.  But I became concerned last week over the threat of Chinese import tariffs significantly inflating the prices of iPhones.  The threat appeared to be real, with Apple in a panic, you know, flying iPhones in from India.  And, like, all kinds of, you know, kerfuffle about this.  But after poking around Apple's site for a while, like looking at the 16 and, okay, and my 12 is still working good, I decided that my older iPhone, which was, as I said, still working just fine, would almost certainly last me through whatever tariff turbulence we were going to be experiencing even for the next few years.  I later mentioned this to my wife, Lorrie, whose response was, "My god, buy yourself a new phone.  Yours is old and small!"



LEO:  She was talking about the phone.



STEVE:  Yes.



LEO:  Now, see, this is why we get married.  She's absolutely right.  I would have said the same thing.  You deserve a modern phone, Steve.



STEVE:  Right.  I was driving a 20-year-old BMW when we met.  And she was a little - it's a little sketchy.  Why are you driving, you know, do you have any resources?  Do you, you know, am I going to be picking up the tab?



LEO:  Honey, I broke down on the 405.  Can you come get me?



STEVE:  So last Thursday, I returned to the Apple Store, and I did that.  Now, as we know, I'm not somebody who always needs to have the latest and greatest.  My stash of Palm Pilots in the refrigerator is testament to that.



LEO:  Oh, I hope Lorrie doesn't find those.



STEVE:  I'm also a testament to the "If it's not broke, don't fix it" school of thought.  So I usually use electronics until they're worn right down to the nub.  But I have to say that the 16 is a lot more responsive than the 12 was.  And since I no longer wear a watch, every time I saw Lorrie's phone displaying the time of day on its dim OLED screen, I thought that was a terrific feature.



LEO:  Yes.  Mm-hmm.



STEVE:  You know, we purchased hers for her birthday, and she lives on that thing, way more than I do on mine.  She'll - I don't get this.  She'll be sitting right next to a booted-up desktop computer with a full-size screen and a keyboard that actually invites typing, rather than actively fighting against your data entry.  And she'll be squinting at websites on her phone.



LEO:  That's because she's a modern woman, Steve.  She's modern.



STEVE:  I don't get it.  I don't get it.  In any event, last Friday, the day after I purchased the 16, the news broke that imports from China of smartphones and electronics were being exempted from the 154% import tariffs that had formed part of my purchase motivation.  But then over this past weekend the U.S. Commerce Secretary, Howard Lutnick, explained during an interview on ABC's "This Week" Sunday morning show that, in another month or so, a new set of tariffs specifically targeting all semiconductor imports would be taking effect, and that smartphones would be caught up in that.



LEO:  Sigh.



STEVE:  Now, a few months ago I purchased a new set of servers for GRC that I have not gotten around to deploying yet, but they're here.  When the second one of an earlier set of five died a few months ago I decided that I needed to be ready in case I lost another one.



LEO:  Wait a minute.  You buy five at a time?



STEVE:  I had five running.



LEO:  Oh, you have five servers all at once?



STEVE:  Yes.



LEO:  Are they load balancing?



STEVE:  No.  A couple are running - I think three are running Windows, two are running Unix, and they're in various state - you know me, security.  So they're physically isolated.  I'm  not sharing function between a secure server and a server that's running PHP.



LEO:  So each does something else.



STEVE:  Yes.



LEO:  Okay.



STEVE:  Yes.  So they have very specific...



LEO:  Like an image server and a - right, okay.



STEVE:  Yeah.  But also security boundaries.  And as I said, the server that I have that has PHP on it, it's all by its lonesome.  And it's got its own physical firewall.  There are only a few things that it's able to do because PHP.  And we're going to get to the audit which demonstrates the wisdom of that.



LEO:  Yes.



STEVE:  So, and the fact that I myself just had to update PHP because of that CGI vulnerability that my version of PHP had at the time that this was happening.  So anyway, so I've got three new, brand new servers.  And I'm now somewhat more glad that I already have those in hand in case their cost might soon be increasing.  You know, they were not inexpensive, and it appears that a few months from now they might become more expensive.



LEO:  Can I ask you which company you buy from?  I'm just curious.



STEVE:  Yeah, the servers that have been dying were Intel motherboard, you know, Intel SIRIUS, the best I could get servers at the time.  And now I've switched to Supermicro because I do have a Supermicro machine that has been going for about 40 years.  And it just will not die.  So I thought, okay, I'm going to go back to the ones that seem more solid than Intel.



LEO:  I think a lot of people will be very interested in your choice, so thank you.



STEVE:  And I've looked at - I've looked at the Intel motherboards, and I'm no longer impressed with their build quality.  You know, they've got stuff like...



LEO:  They used to be the king of the hill; didn't they.



STEVE:  I know.  And that's why I thought I'm going to go with the best because, you know.  And they end up paying for themselves in the long term.  But two out of the five of these identical Intel servers just stopped working.



LEO:  Do you buy towers or blades?  What form factor do you have?



STEVE:  They're all - originally I had three 2U Intel servers, and these are all 1U.  The other five are now 1U servers.  And they're all 3.5" across drives in the front, all running RAID 6 with physical RAID 6 controllers because I'm still old-school.



LEO:  And this is in your living room?  Where are you...



STEVE:  Oh, no.  These are all in a - over at Level 3.



LEO:  Oh, they're over at Level 3.  Oh, okay.



STEVE:  In their datacenter.



LEO:  They're colo.  Okay.



STEVE:  Yup.  Yeah.



LEO:  Cool.  Thank you for sharing that.



STEVE:  Anyway, so - yeah.



LEO:  You should have - I made on my website an "I use this" page.  I don't use anything nearly as interesting as you do.  But for people who are interested in what microphones we use and stuff, you should make a little "I use this" page.  I think that'd be interesting.



STEVE:  Well, what's really interesting is that I also found myself purchasing some - oh, shoot.  Now I'm forgetting.  I ended up using a router that we've talked about in the past.



LEO:  MikroTik?



STEVE:  No, it wasn't.



LEO:  Not Ubiquiti.



STEVE:  Yeah, yes, it was Ubiquiti.



LEO:  It was Ubiquiti.   Yeah, I love my Ubiquitis.



STEVE:   Only the - there was one particular family of Ubiquiti routers that allowed me to do the static port address translation that I really need to do.  I have some other big iron equipment that I was using back in the day, and one of them is still alive.  Several of them have died.  And I thought, okay, I need, you know, I need to have this functionality.  And Ubiquiti is the router that, you know, it's - and boy, am I impressed with their technology.



LEO:  Me, too, yeah.  I'm really happy with it.



STEVE:  You know, you'll remember this.  One of the things, speaking of, you know, what hardware I'm using, the most famous thing I did back in my TechTalk column days on InfoWorld was Steve's Dream Machine.  Where, you know...



LEO:  Yes, I remember.



STEVE:  ...I chose this motherboard, these drives, this controller, you know, this keyboard, you know.  And I basically kitted out, like if you were going to build the ultimate machine that was also tricky because it was like, okay, these drives say they're only this big, but they actually have these extra cylinders on them, and you can format them to this size and get the maximum size partition, blah blah blah.  I really spent a lot of time, you know, finding, like, the best value, not the most expensive, but the best value in each different category.  And anyway, that was popular then.



Anyway, what I wanted to say is I have no crystal ball.  And any rational actor, looking at the past month of tariff actions, would be foolish to place any large bet because who knows what's going to be true in the next hour.  I'm quite certain that no one really knows what the future holds.  But I very clearly heard the U.S. Commerce Secretary state that the administration's intention is to use higher import tariffs on all products containing semiconductors to force a shift in semiconductor manufacturing from offshore to the U.S.  So independent of the practicality, feasibility, and sanity of any of that, we may indeed see the cost of devices containing semiconductors rising.  What I would be willing to bet on is that prices are certainly not going to be dropping anytime soon.  I don't see any way that happens.



So I just wanted to take a moment to talk about this since I'm now more glad than I was that I had purchased those new servers a few months back.  I would likely be doing that now for strategic savings if I had not already.  I certainly don't know anymore about what's going to happen than anyone else.  And this could all change tomorrow.  That's the nature of where we are today.  But if any of our listeners were waiting on the purchase of any big-ticket items containing semiconductors, it might be worth considering that prices may indeed be higher six months from now than they are today.  I would certainly not place any bets on them being lower.



So, you know, as for my iPhone 16 Pro, if Apple ever does get around to deploying some useful AI, I'll be glad to have a device that allows me to experiment with it.  My 12 wouldn't have.  And in the meantime, it's nice to have a dim clock on the lock screen, and to be able to edit text messages that I've already sent.  So happy that I made that jump.



LEO:  Good.



STEVE:  And yes, Leo, we both have wives that said, oh, my god, come on.



LEO:  Steve, you deserve it.  Get it.



STEVE:  Your phone is old.



LEO:  I mean, I understand the desire to run something into the ground.  You still, I mean, you don't want to use the latest Windows either.  So I understand that.  That's commendable.  But you deserve a nice phone.



STEVE:  Well, yeah.  I just discovered yesterday that my iPhone 6, it used to be all pooched out because the battery expanded.  But it turns out that goes down over time.  So maybe I can bring that back to life.



LEO:  No, no, no.  No. and don't bring it on an airplane, either.  Oh, my god.



STEVE:  Okay.  So we were just talking about Apple silently enabling updates.  Microsoft also recently made some news for Windows 11 Enterprise and Education users.  And I'll bet you guys are going to be talking about it tomorrow on Windows Weekly.



LEO:  Oh, yeah.



STEVE:  Windows 11 Enterprise and Education users will be getting updates on steroids in the form of the much-anticipated no-reboot-required hotpatching.



LEO:  Hallelujah.



STEVE:  Yeah.  Microsoft will then only require a once-per-quarter full cold reboot with all of the other interim updates able to be applied directly to Windows running in memory.  So in other words, reboots dropped from 12 a year to four per year.  



LEO:  Wow.



STEVE:  So not over; but, you know, only one third as often.  Microsoft's announcement blog posting about this is titled "Hotpatch for Windows client now available," where David Callaghan, writing for the Windows IT Pro Blog, says:  "Hotpatch updates for Windows 11 Enterprise, version 24H2 for x64, both AMD and Intel CPU devices are now available.   With hotpatch updates, you can quickly take measures to help protect your organization from cyberattacks, while minimizing user disruptions.



"Hotpatching represents a significant advancement in our journey to help you, and everyone who uses Windows, stay secure and productive.  So let's talk about the benefits," he writes, "how it works, and how you and your organization can take advantage of this advancement as part of your Windows servicing journey.  Hotpatching offers numerous enhancements when it comes to keeping Windows client devices up to date.  Immediate protection:  Hotpatch updates take effect immediately upon installation, providing rapid protection against vulnerabilities.



"Consistent security:  Devices receive the same level of security patching as the monthly standard security updates released on the second Tuesday of every month.  And minimized disruptions:  Users can continue their work without interruptions while hotpatch updates are being installed.  Hotpatch updates don't require the PC to restart for the remainder of the quarter."  He says:  "Note:  OS features, firmware, and/or application updates may still cause a restart in the quarter."



He says:  "You'll first create a hotpatch-enabled quality update policy in Windows Autopatch through the Microsoft Intune console.  All eligible Windows 11 Enterprise, version 24H2 devices managed by this policy will be offered hotpatch updates in a quarterly cycle.  The hotpatch" - and one also thinks, Leo, that maybe at some point in the future, once hotpatches have been proven and seen not to cause any trouble, Microsoft could certainly be pushing them out more frequently than quarterly.



LEO:  That's a good point.  Maybe monthly, yeah.



STEVE:  I mean, yes, more frequently than monthly if something bad happens and they want to immediately fix it.  It's like, why not?  It doesn't require, you know, any big change.  So they said:  "The hotpatch updates follow the same ring deployment schedule as standard updates.  Devices receiving the hotpatch update will see a different Knowledge Base number tracking the hotpatch release and a different OS version than devices receiving the standard update that requires a restart."



Hotpatch updates operate on a quarterly cycle.  So cumulative baseline month.  So they said:  "In January, April, July, and October, so four times per year, devices install the monthly fixed security update and restart.  This update includes the latest security fixes, cumulative new features, and enhancements since the last cumulative baseline.  Then subsequent two months:  Devices receive hotpatch updates, which only include security updates and do not require a restart.  These devices will catch up on features and enhancements with the next cumulative baseline month, which is to say quarterly.



"This cycle," he wrote, "reduces the number of required restarts for Windows updates from 12 to just four per year, thanks to eight planned hotpatch updates annually.  To enable hotpatching for Windows client devices, you'll need:  A Microsoft subscription that includes Windows 11 Enterprise E3, E5, or F3; Windows 11 Education A3 or A5; or a Windows 365 Enterprise subscription.  Devices running Windows 11 Enterprise, version 24H2 (Build 26100.2033 or later) and with the current baseline update installed.  	An x64 CPU including AMD64 and Intel," and he said:  "ARM64 devices are still in public preview," but coming, so not available yet, but that'll happen.  And, finally, "Microsoft Intune to manage deployment of hotpatch updates with a hotpatch-enabled Windows quality update policy."



Okay.  So we've known for some time that patching Windows on the fly without rebooting is both possible and practical, since this has been an aftermarket feature that the gang over at 0patch have been offering for some time.  So, you know, they do in RAM patching of DLLs that are loaded on the fly.  So in instances where Microsoft has strategically decided to abandon Windows security, the ongoing availability of those zero-patches may be a godsend.  But, bringing this to Windows enterprise and education client machines means that millions more systems will be able to receive the benefits of on-the-fly hot patching.  Microsoft is not yet suggesting that this boot-avoidance technology might be available for their latest server platforms; but, boy, avoiding unnecessary server reboots would appear to be a nice feature for the future, you know, not having server downtime.



I don't have any problem with a brief once-a-month reboot of any of my workstation machines.  You know, it's just not a problem for me.  And, you know, Microsoft has already invested heavily in minimizing the time required to install updates.  As we know, they no longer require the huge amounts of time they once did.  I remember, like, sitting around, like for hours, while something spun around on the screen, or we watched dots chasing each other.  You know, it's gotten a lot better.  So for me, the monthly updates aren't causing much trouble.



Okay, now, a little bit just checking back briefly on where we are with Oracle before we take another break.  The TL;DR on this is "They're still lying and denying."  Which is just, it's like to everyone's amazement.  Security researcher Kevin Beaumont, who we've followed often because he's very involved in the industry, published on Medium from his DoublePulsar.com site, under the headline "Oracle attempt" - Oracle, he uses the term "Oracle" as a...



LEO:  That's British.



STEVE:  ...a plural, yeah.



LEO:  Yeah, that's how the British do it.  Companies are singular; in other countries it's often plural.



STEVE:  It keeps, it's like, you know, data technically is plural, but I never did it right.



LEO:  Yeah, exactly.



STEVE:  Anyway, so he says:  "Oracle attempt to hide serious cybersecurity incident from customers in Oracle SaaS service."  Kevin wrote:  "Being a provider of cloud SaaS (Software-as-a-Service) solutions requires certain cybersecurity responsibilities, including being transparent and open.  The moment where this is tested at Oracle has arrived, as they have a serious cybersecurity incident playing out in a service they manage for customers.  Back on March 31st, BleepingComputer ran a story around a threat actor named rose87168 claiming to have breached some Oracle services inside *.oraclecloud.com.'"



And of course our listeners may recall that the fact-digging Lawrence Abrams did for BleepingComputer, which we talked about,  was so thorough as in my appraisal to cross the line from evidence to proof of Oracle's apparently deliberate obfuscation and misdirection about the incident.  So Kevin continues:  "Oracle told BleepingComputer and customers:  'There has been no breach of Oracle Cloud.  The published credentials are not for the Oracle Cloud.  No Oracle Cloud customers experienced a breach or lost any data.'"



He says:  "The threat actor then posted an Archive.org URL and provided it to BleepingComputer, strongly suggesting they had write access to login.us2.oraclecloud.com, a service using Oracle Access Manager.  This server is entirely managed by Oracle.  Oracle have since requested Archive.org take down the proof, and the Wayback machine no longer shows the page.  The threat actor then provided a several hour-long recording of an internal Oracle meeting, complete with Oracle employees talking for two hours.  The two-hour video includes things like accessing internal Oracle password vaults and customer-facing systems.  Both Hudson Rock and BleepingComputer were then able to confirm with Oracle customers that their data  including staff email addresses  was in data released by the threat actor.



"The threat actor, rose87168, is still active online and releasing more data and threatening to release more.  They've also released data to cybersecurity threat intelligence providers.  In data released to a journalist for validation, it has now become 100% clear to me that there has been a cybersecurity incident at Oracle, involving systems which processed customer data.  For example, the threat actor has publicly provided complete Oracle configuration files  current, also.  As one example, they've provided Oracle web server configuration files.  All the systems impacted are directly managed by Oracle.  Some of the data provided to journalists is also current.  This is a serious cybersecurity incident which impacts customers, in a platform managed by Oracle.



"Oracle are attempting to wordsmith statements around Oracle Cloud and use very specific words to avoid responsibility.  This is not okay.  Oracle need to clearly, openly, and publicly communicate what happened, how it impacts customers, and what they're doing about it.  This is a matter of trust and responsibility.  Step up, Oracle, or customers should start stepping off."



Kevin then provides three updates.  In Update 1 he said:  "Oracle rebadged old Oracle Cloud services to be Oracle Classic.  Oracle Classic has the security incident.  Oracle are denying it on Oracle Cloud by using this scope, but it's still Oracle Cloud services that Oracle manage.  That's part of the wordplay."  Second Update:  "Although Oracle used the Archive.org exclusion process to remove evidence of writing to one of the Oraclecloud.com web servers, they forgot to remove a second URL that clearly shows the threat actor rose87168 having posted their email address on an Oracle Cloud page."  And by the way, I went to that URL, and it is still there, and I saw rose87168@protonmail.com posted there.



LEO:  On an Oracle hosted page.



STEVE:  Yes.



LEO:  So that's pretty conclusive.



STEVE:  Yes.  And then the third and final update:  "Multiple Oracle Cloud customers have reached out to me to say Oracle have now confirmed" - get this, Leo - "Oracle have now confirmed a breach of their services.  However, Oracle are only doing so verbally.  They will not put anything in writing.  So they're setting up meetings with large customers who query."  He writes:  "This is similar behavior to the breach of medical PII (Personally Identifiable Information) in the ongoing breach at Oracle Health, where they will only provide details verbally and not in writing."



Over on Mastodon, Kevin posted:  "And now, a class action lawsuit has been filed against Oracle over a data breach at Oracle Health, which Oracle has not acknowledged in public."  I have a link, if anyone's interested, to the class action breach court document PDF.  He said:  "This Oracle thing keeps getting more and more wild.  I've never seen a response so bad from a large organization.  They're throwing their own security staff under the bus by having them face customers, rather than the corporation actually take responsibility."



And, you know, Oracle's handling of all this could be taught, and should be taught, as a short course in how not to ever handle a data breach.  This whole business of only having verbal conversations and refusing to put anything into writing feels like attorneys being asked how to run a company. I'm not sure that's a formula for success.  Through my years as a small businessman I've had occasion to receive the advice of attorneys.  I always thank them, and pay them, and carefully consider the value of their advice.



LEO:  And then move on.



STEVE:  Yes.  But what they would advise often seems to follow reactions to worst-case scenarios.



LEO:  Right.  They're there to protect you from the worst, yes.



STEVE:  Yes.  Whereas I've found that being more open and trusting and optimistic has always worked better for me.



LEO:  Me, too.



STEVE:  One of our listeners, whose name is Keith, wrote from Canada.  He said:  "Hi, Steve.  Thank you for covering the Oracle Cloud breach in the latest episode highlighting the significance of the breach and the SEC violations.  Given the 'OCI classic' breach, as they're dubbing it now, and the separate Oracle Health breach, I'm thoroughly confused on how they haven't had to disclose to the SEC.  As a Canadian Oracle Health customer, it's very frustrating to me that they seem to be above SEC regulations and still refuse to disclose breaches to us so that we can be proactive in protecting our organizations.  I'm a huge fan of you, Leo, and the show."



LEO:  Aww.



STEVE:  "Thanks for everything you guys do."



LEO:  Thank you.



STEVE:  And I wouldn't know what to tell Keith.  You know, regulations only have teeth if they're backed up by the certainty of enforcement.  And to say that things are somewhat confused in the U.S. at this particular moment could safely be considered an understatement.  Both our DOJ and SEC are currently preoccupied with trying to figure out which end is up and what their priorities should be.  So it may be that Oracle lucks out on this one, and that it slips by on the government side.  But as I noted, U.S. citizens have already filed lawsuits that may force depositions to be taken and place additional facts on the record, which ultimately makes enforcement a given.  So we'll see.



Okay.  So the United States Treasury has something known as the Office of the Comptroller of the Currency, OCC for short.  A couple of months ago, in January of this year, CISA discovered that the emails for nearly 100 of the OCC's staff had been intercepted since the breach originally occurred - get this, Leo - back in June of 2023.



LEO:  Oh, my god.



STEVE:  Nearly two years.



LEO:  Two years.



STEVE:  Encompassing more than 150,000 pieces of email.  Someone has been rummaging around in there.  None of the nearly 100 staffers at the U.S. Treasury's Office of the Comptroller of the Currency have enjoyed any actual email privacy.  It's all just been an illusion.  And Treasury does appear to be either a high-priority target or to have less than adequate security...



LEO:  Or both.



STEVE:  ...since this OCC breach - yeah, both - is the third Treasury office to recently disclose a breach.  Before this, we had the Office of Foreign Assets Control (OFAC) and the Committee on Foreign Investment in the U.S. (CFIUS).  For both of those two previous intrusions the U.S. government has now credited the Chinese-backed hacking group Silk Typhoon.



Now, this news connected with something I heard over the weekend.  An Asian analyst was interviewed by Fareed Zakaria during his Sunday morning show on CNN.  She made the comment about how at some point, as tensions between the U.S. and China escalated, China might decide to weaponize all of the data they'd been collecting through their pervasive cyber intrusions into the U.S.  That gave me a bit of a chill because, unfortunately, it really made sense.  We've seen a great deal of evidence of Chinese, apparently state-sponsored, actors rummaging around inside U.S. government and industry networks.  But nothing overt and obvious has come of it.  It might be that an "attack" as such, and I have that in quotes, would take the form of using all of the information that's been gleaned against U.S. interests.  In other words, "weaponizing all of that data."



We don't know, you know, that this recent and long-running U.S. Treasury Office of the Comptroller of the Currency email breach was the same as who previously was found to have breached those other two U.S. Treasury offices.  So far there's been no attribution.  But at this point it would almost be surprising if it wasn't the Silk Typhoon group backed by China.  So it would be so much better if we could all just get along.  That doesn't seem to be happening, though, sadly.



There's some news on the Apple vs. the UK and what Apple will do about the UK's demands to be able to obtain the stored iCloud data for anyone in the world they request.  Apple Insider's headline was:  "UK iCloud backdoor mandate hearing must be made public  eventually."



LEO:  Oh.



STEVE:  They wrote:  "After a legal challenge by Apple, the hearing about blowing open Apple's iCloud encryption in the UK for the sake of national security will not be kept secret, but it's not clear when the details will be made public.  After the hearing about a mandated backdoor happened behind closed doors, Apple very nearly immediately filed an appeal, with the backing of most of the world's governments, privacy advocates, and journalism organizations.  That appeal has been heard, and at some point the results of the hearing will be made clear.



"The Investigatory Powers Tribunal rejected claims from the UK government that national security would be hurt by revealing the results of the hearing, or exposing who attended the hearing.  In short, the appeal found that there was no reason to restrict what it calls "open justice," so the results of the hearing must be made clear in due time.  It's not clear when that will happen, as case management orders will be made only after Apple and the UK government have time to consider the ruling and propose drafts."



So at least we're going to find out what that, you know, is about.  Basically we've got bureaucracy.  Whatever is going to happen will apparently grind away slowly.  But the fact that the UK government now knows that it will not also be able to conduct everything in secret may, hopefully, dampen their zeal somewhat and reign them in.  What's interesting about this is that there's no middle ground here.  There's no gray area.  UK users either will or will not have the ability to enable Apple's Advanced Data Protection for their stored iCloud data.



It seems unlikely in the extreme that the UK's demand to be able to obtain the data belonging to anyone they choose anywhere in the world has any chance of ever happening.  But they might well force Apple to disable ADP for citizens in the UK.  We'll see.  But again, the only good thing about this is that it's black and white.  That is, either you have it or you don't.  So hopefully the fact that there's a sharp point on this will help, you know, a clean decision, a clean and clear decision to come out of all this.



Now, I missed this news, this next news, when it happened 10 days ago.  But I felt the need to come back to put it on everyone's radar because what Mozilla is doing with a suite of new cloud service offerings which they're calling, unfortunately, Thundermail...



LEO:  Thundermail.  That's what you need.  You've got to say it right.



STEVE:  Oh, thank you.  I will need you again when we're talking about Roskomnadzor.



LEO:  Roskomnadzor.  I'm sorry.



STEVE:   No, it's good.  We have Thundermail and Thunderbird Pro.  I'm sure this will be of interest to many of our listeners for much the same reason we choose to use Mozilla's Firefox.



LEO:  Mm-hmm.



STEVE:  So Mozilla wrote:  "Today we're pleased to announce what many in our open source contributor community already know.  The Thunderbird team is working on an email service called Thundermail."



LEO:  Good.  Another way to make money.  That's good, yes.



STEVE:  Yes, exactly.  Exactly, Leo.  "As well as file sharing, calendar scheduling, and other helpful cloud-based services that as a bundle we have been calling Thunderbird Pro.  First, a point of clarification:  Thunderbird, the email app, is and always will be free.  We will never place features that can be delivered through the Thunderbird app behind a paywall.  If something can be done directly on your device, it should be.  However, there are things that cannot be done on your computer or phone that many people have come to expect from their email suites.  This is what we are setting out to solve with our cloud-based services.



"All these new services are, or soon will be, open source software under true open source licenses.  That's how Thunderbird does things, and we believe it is our super power.  It's also a major reason we exist, to create open source communication and productivity software that respects our users.  Because you can see how it works, you can know what it's doing, and that it's doing the right thing.



"The Why for offering these services is simple."  Okay, now, the truth is they want to survive.  But, okay.  They wrote:  "Thunderbird loses users each day to rich ecosystems that are both products and services, such as Gmail and Office 365.  These ecosystems have both hard vendor lock-ins through interoperability issues with third-party clients, and soft lock-ins through convenience and integration between their clients and services.  It's our goal to eventually have a similar offering so that a 100% open source, freedom-respecting alternative ecosystem is available for those who want it.  We don't even care if you use our services with Thunderbird apps.  Go use them with any mail client.  No lock-in, no restrictions, all open standards.  That is freedom.  So what are the services?"



They have Thunderbird Appointment.  "Appointment," they write, "is a scheduling tool that allows you to send a link to someone, allowing them to pick a time on your calendar to meet.  The repository for Appointment has been public for a while and has seen pretty remarkable development so far.  It's currently in a closed Beta, and we're letting more users in every day.  Appointment has been developed to make meeting with others easier.  We weren't happy with the existing tools as they were either proprietary or too bloated, so we started building Appointment."



Then there's Send.  "Send is an end-to-end encrypted file sharing service that allows you to upload large files to the service and share links to download those files with others.  Many Thunderbird users have expressed interest in the ability to share large files in a privacy-respecting way, and it was a problem we were eager to solve.  Thunderbird Send is the rebirth of Firefox Send - well, kind of.  We've rebuilt much of the project to allow for a more direct method of sharing files, from user-to-user without the need to share a link.  We opened up the repo to the public earlier this week.  So we encourage everyone interested to go and check it out.  Thunderbird Send is currently in Alpha testing, and will move to a closed Beta very soon."



Thunderbird Assist.  "Assist is an experiment, developed in partnership with Flower AI, a flexible, open-source framework for scalable, privacy-preserving federated learning that will enable users to take advantage of AI features.  The hope is that processing can be done on devices that can support the models.  And for devices that are not powerful enough to run the language models locally, we are making use of Flower Confidential Remote Compute in order to ensure private remote processing, very similar to Apple's Private Cloud Compute.  Given some users' sensitivity to this, these types of features will always be optional and something that users will have to opt into.  As a reminder, Thunderbird will never train AI with your data.  The repo for Assist is not public yet, but it will be soon."



And then Thundermail.  Thundermail is an email service in search of a better name.  No, okay, that's not what it actually says.  I just think that "Thundermail" sounds dumb.



LEO:  It's because it's Thunderbird.  I guess I understand.



STEVE:  Right.  You know, you just can't put "thunder" in front of everything...



LEO:  In front of anything.  It's Thundernow.



STEVE:  It's Thunderdome.



LEO:  It's Steven "Thunder" Gibson.



STEVE:  Oh, god.  Anyway, it also supports calendars and contacts as well as mail.  They wrote...



LEO:  I'm interested.  I mean, I'm a Fastmail customer, which does all the same things.  But I'm very interested.  I'd like to find out more.



STEVE:  They said:  "We want to provide email accounts to those who love Thunderbird, and we believe that we are capable of providing a better service than the other providers out there, email that aligns with our values of privacy, freedom, and respect for our users.  No ads, no selling, no training AI on your data, just your email, and it is your email.  With Thundermail, it is our goal" - I can't, my god, please, something else.



LEO:  You can't resist.



STEVE:  I can't.  "It is our goal to create a next-generation email experience that is completely, 100% open source and built by all of us, our contributors and users.  Unlike the other services, there will not be a single repository where this work is done.  But we will try and share relevant places to contribute in future posts like this.  The email domain for Thundermail will be Thundermail.com" - thank god - "or tb.pro.  Additionally, you will be able" - here it is - "to bring your own domain on day one of the service."



LEO:  Nice.  Good.  That's critical for me.



STEVE:  Now, that starts being interesting, having Mozilla behind a 100% open source privacy-respecting email service where we're also able to bring our own domain, presumably by pointing our own domain's MX records at Mozilla.  That would be cool.



So everyone listening can head to Thundermail.com.  You will get - the only thing there at Thundermail.com is a simple signup page demonstrating their inherently techie nature.  You'll see what I mean when you see the page.



LEO:  Yes. It's command line based.



STEVE:  Yes.  And that allows you to sign up for their Beta waitlist, which will give you notification as soon as this thing is, you know, as soon as you're able to actually sign up for the service.  And I did that immediately.



LEO:  Oh, yeah.  Me, too.  Yeah, I'm very curious, yeah.



STEVE:  So they said under Final Thoughts:  "Don't services cost money to run?"  And they said:  "You may be thinking this all sounds expensive.  How will Thunderbird be able to pay for it?"  And they say:  "And that's a great question."  Right, answering it, or asking it of themselves.  And they said:  "Services such as Send are actually quite expensive.  Storage is costly.  So here's the plan.  At the beginning, there will be paid subscription plans at a few different tiers.  Once we have a sufficiently strong base of paying users to sustainably support our services, we plan to introduce a limited free tier to the public.  You see this with other providers.  Limitations are standard as free email and file sharing are prone to abuse."



LEO:  Yes.



STEVE:  Yeah.  "It's also important to highlight again that Thunderbird Pro will be a completely separate offering from the Thunderbird you already use."  Or in my case "once used," since I still am happily switched away from Thunderbird to eM Client.  They said:  "While Thunderbird and the additional services may work together and complement each other for those who opt in, they will never replace, compromise, or interfere with the core features and free availability of Thunderbird.  Nothing about your current Thunderbird experience will change unless you choose to opt in and sign up with Thunderbird Pro.  None of these features will be automatically integrated into Thunderbird desktop or mobile, or activated without your knowledge.  This has been a long time coming."



And the person who posted this wrote in the first person:  "It is my conviction that all of this should have been part of the Thunderbird universe a decade ago.  But it's better late than never.  Just like our Android client has expanded what Thunderbird is, as will our iOS client, so too will these services.  Thunderbird is unique in the world.  Our focus on open source, open standards, privacy, and respect for our users is something that should be expressed in multiple forms.  The absence of Thunderbird web services means that our users must make compromises that are often uncomfortable ones.  This is how we correct that."  In other words, they're going to be providing a complete suite of web services like the other guys do.



And he finished, writing:  "I hope that all of you will check out this work and share your thoughts and test these things out.  What's exciting is that you can run Send or Appointment today, on your own server."  I thought that was interesting.  You can run Thunderbird Send or Thunderbird Appointment today on your own server.  He said:  "Everything that we do will be out in the open, and you can come and help us build it.  Together we can create amazing experiences that enhance how we manage our email, calendars, contacts, and beyond.  Thank you for being on the journey with us."  And so we all want Mozilla to stay alive.  If not for Thunder whatever, then for the sake of Firefox.



LEO:  Yes.



STEVE:  So if their addition of cloud-based services appeals to people as a reasonable alternative to Office 365 and Gmail, and that creates a revenue stream to support all of Mozilla, then I'm all for it.  So again, Thundermail.com to sign up for the news.  And yay.



A quick note is that over in the category of age restrictions, Meta has extended teen account protections.  The existing "teen accounts" security protections which exist on Instagram are also being extended to Facebook and Facebook Messenger accounts.  Now, the feature prevents children under the age of 16 from modifying a series of privacy settings on their accounts without a parent's approval.  This includes settings related to who can contact the account, and what content they see on the sites.  Meta is also expanding these restrictions so that, for example, teens won't be able to live stream on their sites without a parent's approval.  So that's good.



Okay.  So with our podcast two weeks ago falling on April Fool's Day, that made last week's podcast fall on the earliest possible Patch Tuesday day, April 8th.  Looking back at the news of last week, Microsoft patched 126 vulnerabilities.



LEO:  Wow.



STEVE:  Because, you know.



LEO:  Every month.



STEVE:  Every month.



LEO:  It's always.



STEVE:  That's right.



LEO:  I mean, I guess it's good they're patching them.



STEVE:  It's better than not.



LEO:  Yeah.



STEVE:  You know me, I wish they'd just leave it the heck alone and stop messing with it.  But no.  One of those was an actively exploited zero-day.  It was an Elevation of Privilege in the Windows Common Log File System driver, which tends to be a vulnerability magnet for some reason.  They've had a lot of problems with that driver over the years.  Microsoft's security team, I mean, okay.  So it's a log file system driver.  Probably some summer intern.  They said, hey, just go do the, you know, write the logging driver while you're here for the summer.  We saw that happen with the color mapping that NT did once, and it was a disaster.  So anyway, you want to put your good guys on the things that are going to run in the kernel.



Microsoft Security Team indicated that the now-patched zero-day was being exploited by the RansomExx ransomware group.  And that makes sense since, once you somehow arrange to get your code running on a well-locked-down Windows machine, that code will likely be running under the account of the user who somehow made a mistake that allowed it to come in and run with deliberately restricted privileges.  So even though you may be in as a bad guy, it's still generally necessary to arrange to obtain admin privileges if you're, you know, in the case with a ransomware intrusion, your goal is to do a lot of damage.  You need to get root on the machine to do that.



Google also patched a pair of zero-days last week with Android.  One of the fixes is a patch for a Cellebrite exploit used by Serbian authorities to unlock the phones of journalists and anti-government protesters.  The exploit and the hacks were first detailed in an Amnesty International report in February.  There are no details on the second zero-day other than that it leverages an undisclosed flaw in the Android kernel USB audio driver.  But being in the Android kernel suggests that it was likely a powerful root-level exploit.  This also makes it the third month in a row that Google has fixed zero-days in the Android OS.  And as we know, these things are complicated, and it's very difficult to get every little detail right.  But that's what security requires.



If I wasn't so excited about talking about Device Bound Session Credentials today, as we will be shortly, I would be spending our time digging into a 25-page, recently published piece of security research which was just so juicy.  It examined the status of the security of PLCs, you know, the critical Programmable Logic Controllers that generally contain just enough computational ability to figure out when to turn off the toilet paper rolling machine, to then cut the paper and start on another role after first painting a little bit of glue onto the cardboard tube so that the new end of the paper sticks to it.  You know, that's what these things do.



In a very real sense, PLCs are what actually run the world.  We've talked about them extensively in the past on this podcast specifically because they're silent workers that essentially make all of today's infrastructure go.  In a very real sense, they are today's infrastructure.  And as a consequence, their security is crucial.



In the Abstract of their 25-page paper, the team of researchers wrote:  "Billions of people rely on essential utility and manufacturing infrastructures such as water treatment plants, energy management, and food production."  You know, not to mention nuclear reactors.  "Our dependence on reliable infrastructures makes them valuable targets for cyberattacks.  One of the prime targets for adversaries attacking physical infrastructures are Programmable Logic Controllers because they connect the cyber and the physical worlds.



"In this study, we conduct the first comprehensive systematization of knowledge that explores the security of PLCs.  We present an in-depth analysis of PLC attacks and defenses, and discover trends in the security of PLCs from the last 17 years of research.  We introduce a novel threat taxonomy for PLCs and Industrial Control Systems.  Finally, we identify and point out research gaps that, if left ignored, could lead to new catastrophic attacks against critical infrastructures."



Now, as I promised, and as I said, I'm not digging into this.  I mean, I would love to.  But we don't have time.  But here's a brief summary of that research written by a security reporter who did dig into it.  He wrote:  "A team of academics has conducted a review of 133 papers, 119 attack methods, and 70 defense methods that target PLCs to assess the actual impact of a possible cyberattack targeting these devices.  The research found that, even if most PLCs have built-in access control features, most of them have been shown to be ineffective.  Where encryption has been used, the algorithms are often ineffective.  Disabling unused protocols and monitoring is the best way to prevent and detect attacks."  So if anyone is interested in more detail, I have a link to their 25-page research analysis in the show notes.



Okay.  I've got one that's pretty much guaranteed to make you just shake your head.  And Leo, I know you already know about this.  Six researchers, four from the University of Texas at San Antonio, one from Virginia Tech, and the last one from the University of Oklahoma, just published a paper titled "We Have a Package for You!  A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs."  You know, large language models.  In their usage, just to be clear, by "package" they mean a reference to some open source code library that would be handy to have and to add to a project in order to provide some missing functionality.  So here's what this team of six wrote for their paper's Abstract.  I have a link to their entire paper in the show notes.



They wrote:  "The reliance of popular programming languages such as Python and JavaScript on centralized package repositories and open source software, combined with the emergence of code-generating Large Language Models (LLMs), has created a new type of threat to the software supply chain:  package hallucinations.  These hallucinations, which arise from fact-conflicting errors when generating code using LLMs, enable a novel form of package confusion attack that poses a critical threat to the integrity of the software supply chain.  This paper conducts a rigorous and comprehensive evaluation of package hallucinations across different programming languages, settings, and parameters, exploring how a diverse set of models and configurations affect the likelihood of generating erroneous package recommendations and identifying the root causes of this phenomenon.



"Using 16 popular LLMs for code generation and two unique prompt datasets, we generate [get this] 576,000" - over half a million - "576,000 code samples in two programming languages that we analyze for package hallucinations.  Our findings reveal that the average percentage of hallucinated packages is at least 5.2% for commercial large language models and 21.7% for open source large language models, including a staggering 205,474 unique examples of hallucinated package names, further underscoring the severity and pervasiveness of this threat.



"To overcome this problem, we implement several hallucination mitigation strategies and show that they're able to significantly reduce the number of package hallucinations while maintaining code quality.  Our experiments and findings highlight package hallucinations as a persistent and systemic phenomenon while using state-of-the-art large language models for code generation, and a significant challenge which deserves the research community's urgent attention."



Okay.  So that's part one.  LLMs are still just making stuff up, including the names of add-on packages that it would be nice to have.  And just as "typosquatting" has developed over time into a serious threat, researchers are warning that something which unfortunately is being called AI "slopsquatting" is on the horizon.



LEO:  Let me see if it sounds better when I say it this way:  "AI Slopsquatting."



STEVE:  Uh, no.



LEO:  No, no better.



STEVE:  Still bad.  Here's what the Risky Business security newsletter wrote.  They said:  "Security firms, open source experts, and academics are warning about a new supply chain vector they're calling "slopsquatting."  The technique's name is a combination of terms like AI slop and typosquatting.  It revolves around the increasing use of AI coding tools to generate blocks of source code that may sometimes make their way into production systems.



"A recent academic paper" - and that's the one whose Abstract I just shared - "analyzed 16 AI coding models and found that these tools generate shoddy code that often includes and loads packages and libraries that don't exist.  DevSecOps company Socket Security says that such behavior opens the door to slopsquatting, where threat actors study the LLMs and then register package names hallucinated or likely to be hallucinated in the future."  It turns out that's actually feasible.



"The attack looks farcical and impractical, but so did typosquatting," they write, "when it was first described years ago.  Yet, years later, it is one of the most pervasive and common sources of supply chain issues in the software development industry.  It may sound ridiculous that developers would not spot a typo in the names of packages they install, but reality has shown that they don't.  Does it actually sound that far off," he poses, "that developers would not spot nonexistent packages in huge blocks of code they're using when cutting corners?"



LEO:  Yeah, see, that's the problem; right?



STEVE:  Yes.  "The use of AI coding tools is increasing, and the chances that developers may use code blocks generated through these tools is also growing exponentially, along with the chances of a successful slopsquatting attack."  So that's Risky Business wrote.  This raised my curiosity, so I looked further.



The Socket Security folks further summarized some of the paper's findings.  They wrote:  "The researchers tested 16 leading code-generation models, both commercial (like GPT-4 and GPT-3.5) and open source (like Code Llama, DeepSeek, WizardCoder, and Mistral), generating a total of 576,000 Python and JavaScript code samples.  Their key findings were 19.7% of all recommended packages did not exist.  Open source models hallucinated far more frequently, 21.7% on average, compared to



commercial models at 5.2%.  	The worst offenders (Code Llama 7B and Code Llama 34B) hallucinated in over a third of its outputs.  GPT-4 Turbo had the best performance with a hallucination rate of just 3.59%.  Across all models, the researchers observed over 205,000 unique hallucinated package names.  These findings point to a systemic and repeatable pattern, not just isolated errors."



And here's the key:  These hallucinations are not just one-offs.  If they were, they could not be weaponized; right?  They are persistent and recurrent.  The Socket Security guys explained.  They said:  "In follow-up experiments, the researchers reran 500 prompts that had previously triggered hallucinations, 10 times each.  They found an interesting split when analyzing how often hallucinated packages reappeared in repeated code generations.



"When re-running the same hallucination-triggering prompt 10 times, 43% of hallucinated packages were repeated every time, while 39% never repeated at all.  This stark contrast suggests a bimodal pattern in model behavior:  hallucinations are either highly stable or entirely unpredictable.



"Overall, 58% of hallucinated packages were repeated more than once across 10 runs, indicating that a majority of hallucinations are not just random noise, but repeatable artifacts of how the models respond to certain prompts.  That repeatability increases their value to attackers, making it easier to identify viable slopsquatting targets by observing just a small number of model outputs.  The consistency makes slopsquatting more viable than one might expect.  Attackers don't need to scrape massive prompt logs or brute force potential names.  They can simply observe LLM behavior, identify commonly hallucinated names, and register them."



So just a cautionary tale here about the potential for the weaponization of large language model outputs.  We know that bad guys would like nothing more than to get their code included into high-profile product offerings.  If future coders become too comfortable with directly using LLM-created code without scrutinizing it carefully, I would argue line by line, just copying and pasting and testing what the LLM produces, it's no longer far-fetched to imagine that the LLM's mistaken output itself might have been weaponized for the purpose of causing the download and inclusion of a malicious library.



If we were to take this a step further, imagine arranging to seduce LLMs to train on tasty valid libraries, which they would tend to then invoke into their solutions, only to have any retrieval by a non-LLM return a malicious version of that package.  There's no such thing as a free lunch, coders.



LEO:  And how do you test it?  Because you can't just say, well, does this exist because it does exist now because of...



STEVE:  Right.



LEO:  ...slopsquatting.  And, you know, so now you have to validate all the libraries to make sure it's doing - not doing anything malicious.  Ay ay ay.  What a mess.



STEVE:  Yup.  A real supply chain mess.



LEO:  Yeah.



STEVE:  Basically the LLM has a knowledge that the coder lacks of available packages and is pulling stuff in from all over.



LEO:  Right.



STEVE:  So the coder either needs to truly educate themselves about the nature of the libraries that the LLM knows about and has invoked, or just hope for the best.  And hoping for the best could really bite you in the - what is not the best place.



LEO:  Yes.  Wow.



STEVE:  We wind up talking about WordPress because such a large portion of the Internet's websites are running WordPress CMS (Content Management System) code.  The core WordPress offering has become extremely solid over time.  But its very large plug-in ecosystem is another matter entirely.  That plug-in ecosystem is WordPress's primary attraction, but also its primary weakness as a secure platform.



WordFence is an independent WordPress-focused security firm.  During the previous year, security researchers at WordFence discovered and disclosed more than 8,000 WordPress site vulnerabilities.  8,000 WordPress site vulnerabilities.  But fully one quarter of those have remained unpatched.  2,000 unpatched today.  Many of the affected plug-ins are obscure, but many are popular and unmaintained.  But as I noted, the WordPress core has grown increasingly solid, with only five of those 8,000 known issues disclosed last year impacting the WordPress core, and all of them were immediately fixed.  



So the takeaway here is this.  As I've said every time we've previously considered the important WordPress landscape, be very, very careful about what you add to the base WordPress core offering.  Only add those features you really need and will really use, and check to see the history of any add-on's maintenance to verify that someone is still around to maintain that code, or that it really looks like it is sufficiently solid because add-ons are the WordPress security Achilles heel, not the core offering.



LEO:  It's the plugins, yeah.



STEVE:  Yup.



LEO:  But you really can generalize this advice to everything.  Don't install apps you don't need.



STEVE:  Same with your iPhone.



LEO:  Yeah.  Don't use libraries you don't know.



STEVE:  That really is true.



LEO:  That, you know, the browser you use is probably secure.



STEVE:  And the add-ons to the browser.  The more crap you add to these things, yup, the greater the probability that one you add will be bad.  Yup.



LEO:  Especially nowadays.  Holy cow.



STEVE:  And there are of course degrees of badness.  And one could argue that WordPress add-ons - the problem is, you know, they're just written by, you know, Johnny in the closet.  I mean, they're just random.



LEO:  And what are they written in, Steve?  They're written in PHP.



STEVE:  Uh-huh.  They are.



LEO:  Johnny in the closet using his personal home page software.



STEVE:  That's right.  And that's why the only server I have that is running any PHP has its own port on an isolated router, and it doesn't get to talk to any of my other stuff at GRC.



LEO:  That's smart.



STEVE:  Because I just do not trust it.  It can melt down internally, but it can't touch, you know, GRC.com where, you know, ecommerce and other things live because, you know, I take my own advice.



So speaking of PHP's language interpreter, it just got a much welcomed security audit, which it turns out was also much needed.  WordPress, like a great many other web-facing systems such as I was just talking about, GRC's web forums, our email system, our link shortener, all written in PHP.  I love them, but they're on an isolated server.



So also in the news was that PHP's language interpreter recently received a security audit.  Quarkslab received a commission to really examine the core component of PHP.  Last Thursday they posted their results.  They wrote:  "The Open Source Technology Improvement Fund, Inc., thanks to funding provided by the Sovereign Tech Fund, engaged with Quarkslab to perform a security audit of PHP-SRC, the interpreter of the PHP language.



"The audit aimed to assist PHP's core developers and the community in strengthening the project's security ahead of the upcoming PHP 8.4 release.  The codebase was analyzed with a defined scope, which was established and agreed upon by both PHP's core developers and the OSTIF (Open Source Technology Improvement Fund) teams.  Based on this scope and the allocated timeframe for the audit, an attack model was developed and approved by the PHP team.  The assessment was conducted within a set timeframe, with the primary focus on identifying vulnerabilities and security issues in the code according to the defined attack model.



"The following scope of work was defined by PHP Foundation and the OSTIF.  The key tasks included base tooling evaluation;



improve SAST tooling to enhance the existing GitHub CI without extra cost and with low maintenance; build fuzzers compatible with oss-fuzz for potential critical functions that are not



currently covered; cryptographic and manual code review.  High-priority tasks were the php-fpm master node and php-fpm worker glue code.  Those are the modules that invoke PHP for handling web queries.



"Also FPM pool separation; the MySQL Native Driver;



RFC 1867 PHP header parsing and MIME handling; PDO emulated prepares; JSON parsing with a focus on json_decode; OpenSSL external functions and its stream layer external openssl; libsodium integration with ext/sodium; functionalities related to passwords ext/standard/password.c; functionalities related to hashing ext/hash; and functionalities related to CSPRNG, the Cryptographically Secure Pseudorandom Number Generator, ext/random/csprng.c."



So that was their mission and scope.  How did they proceed?  They wrote:  "To assess the security of PHP-SRC, Quarkslab's team first needed to familiarize themselves with the structure of the project and understand the key tasks outlined in the audit's scope.  To achieve this, Quarkslab experts gathered and reviewed the available documentation and project resources.  With a clear understanding of the features to be evaluated, Quarkslab developed an attack model that incorporated all the requested key tasks.  This model was then presented to PHP's core developers; and, once approved, the assessment began.



"The evaluation employed a combination of dynamic and static analysis.  The static analysis focused on scrutinizing the source code to visually identify vulnerabilities related to the implementation and logic of the specified assessment targets.  Dynamic analysis was used to complement the static review by speeding up the process through fuzzing and validating or refuting the hypotheses generated during the static analysis."



So, you know, and they're taking this formal approach because they've been contracted, essentially, to perform this audit.  And it would be easy to say, oh, yeah, we did.  But, you know, they're getting paid.  So they need to say, what do you want us to do?  Okay.  Here's how we're going to do it.  Okay?  Okay.  Now we're going to do it.



So what did they find?  They wrote:  "During the timeframe of the security audit, Quarkslab has discovered several security issues and vulnerabilities, among which were two security issues considered as high severity; six security issues considered medium severity; nine security issues considered low severity; and 10 issues considered informative.  Most vulnerabilities have been shared," they wrote, "via security advisories on the PHP-SRC GitHub repository.  Other bugs and issues are provided only in this report.  Four CVEs were issued, one for each of the two high severity vulnerabilities, and two others for two of the nine low severity vulnerabilities."



Okay.  So they produced a detailed - oh, boy - a very detailed 106-page full audit report, and I have a link to it in the show notes for anyone who wants to dig in.  However, they also wrote:  "This audit report contains two security issues currently redacted, while PHP maintainers are actively working on the fixes.  Details will be provided after fixes are applied by PHP maintainers.  Fixes are complex and in progress."



In other words, two of the 17 security-related problems they discovered were too severe to publicly report until they have been fixed.  Although it's speculation at this point, this strongly suggests that many earlier releases of PHP are also very likely to be in identical trouble; and that, depending upon what bad guys could do with it if they knew about it, we may be facing a critically important security update across all still supported release versions of PHP.  So we will certainly be, you know, standing by and staying tuned and see whether PHP needs an update.  They're not talking about what they found.



But it is very, very cool that a truly worthwhile audit was done of PHP.  And really, you end up feeling a lot better about PHP 8.4, knowing that it has had this kind of audit.  It's like back in the days of VeraCrypt, or TrueCrypt, that got audited.  And it's like, okay, people really did take a look at it, and it came out the other end with no big problems found.  So couple things need to get fixed; but once they are, yay.  And Leo?



LEO:  Yes.  Okay.



STEVE:  Let's take our last break and then, finally, we are going to get to...



LEO:  I've been waiting all day for this.



STEVE:  The unhyphenated Device Bound Session Credentials.



LEO:  Well, it's about time.



STEVE:  And people may be a little glad that what we've done so far has been a little fluffy by comparison because you're going to need to have conserved your strength for what's coming.



LEO:  I think all my session credentials are device bound, but what do I know?  Let's find out.



STEVE:  None of them are.



LEO:  None.  All right.  What are device bound session credentials, with or without their hyphen?



STEVE:  So as I said at the top, while I was scanning through recent events, I noted that Chrome had recently moved to 135 and Firefox went to 137.  So I scanned through Chrome's mind-numbing list of things that had been fixed and added and changed.  There were several truly new features added by the W3C, the World Wide Web Consortium, which Firefox and Safari are also echoing.  The most interesting of them was something called "Device Bound Session Credentials," which is the soon-to-be-available feature that named today's podcast, obviously.



Once I understood what this was about, that it was right, and given that this new technology is intended to be an extremely secure replacement for an aspect of session cookies, not entirely, as we'll see, but the way you get them essentially, I knew we needed to update the record because session cookies would not, as they have been forever, not be long for this world, and that's a big deal that will change everything.



As we've had the discussion many times in the past, the entire model of the web is for a user client, typically an interactive web browser, to request some resource from the Internet using a URL which contains the unique address of the requested object, unique Internet-wide.  Somewhere there's something, the browser says "I want that."  As a result of the browser's connection to it and then supplying the address of the requested object, a web server returns whatever it is that the browser requested, and then they may, and often do, disconnect.  So when you think about it, it's to me incredible to consider how far we have stretched that simple basic query and reply model.  We've created the modern Internet world with it.  Browser, ask for something, a server somewhere sends it back, says here you go, disconnects.



This original model, the thing that Sir Timothy John Berners-Lee first conceived of as the World Wide Web, never had any notion of a "session."  That is, there was no way originally for anyone to logon to anything, since doing so would require that this "logged on" state would be saved somewhere.  And Tim's original idea was entirely stateless.



LEO:  Interesting.  I didn't realize that.



STEVE:  Yes.  The "web" was just a mass of pages containing links to other pages.  And that was it.



LEO:  But that's very limited.



STEVE:  Yeah, oh, yeah.



LEO:  Because you can't identify yourself.



STEVE:  All it was, was like a big knowledge base.



LEO:  Just a blob; right.



STEVE:  A big directory, just like - and remember back then, Leo, like the original websites were like a list of links.



LEO:  That's right.



STEVE:  They were just like link lists.



LEO:  It was hypertext.  That's hypertext.



STEVE:  That would take you, yeah, to somewhere else.  So that...



LEO:  Yeah.  No memory, nothing.  No state, nothing.



STEVE:  Right, right.  All of that changed in June of 1994 when MCI asked Netscape to come up with some way for the user's browser to retain transaction data so that MCI would not need to retain it at their end.



LEO:  Otherwise you have to log in every time you go to MCI Mail.



STEVE:  Actually, it's worse than that.  Every query, you actually...



LEO:  Oh, yeah.  That's right.



STEVE:  There isn't - you can't actually log on.



LEO:  You can't remember them.  Yeah, I don't know who this is.



STEVE:  The server does not remember you.



LEO:  Wow.



STEVE:  Ever.  There's no memory of a previous query.  And that's the way the 'Net originally was.  So a Netscape engineer by the name of Lou Montulli came up with the idea of a web browser cookie that a web server would give to a visiting web browser.  And every time thereafter, if the web browser contained a "cookie" that matched the domain that the browser was querying, the browser would voluntarily return that cookie token in all of its queries to the server.



LEO:  So you save state locally on your machine.  So the server doesn't have to do it.  You re-identify yourself.  By the way, the original name for this was Persistent Client-Side State Information.  And it to this day irks me they didn't call them "pixies" instead of "cookies."  It should have been a pixie.



STEVE:  Oh, that'd be much better. 



LEO:  Much better.



STEVE:  Yeah.



LEO:  Although maybe it sounds a little scary that you have some pixies in your machine.



STEVE:  Well, and you really can't do that, you can't do pixie in that monster voice of yours.



LEO:  Pixie.  No, you do it - you do it in this voice.



STEVE:  Oh, that's good.  Okay, so believe it or not, Leo, even back then, when this was first introduced, it was somewhat controversial.



LEO:  Oh, really.  Wow.



STEVE:  It suddenly meant that not every query from a browser was independently and entirely anonymous as they originally were.  But by the same token, if you'll pardon my pun, the web server would usually have the browsing user's IP address.  Still, people were aware of this back in the mid '90s, that a cookie, suddenly you lost a little bit of the anonymity that you had previously enjoyed.



Now, through the years, the cookie specification was formalized, and many new features were added.  You know, expiration of cookies and other various flags.  Many years ago we talked about the Firesheep hack, where HTTPS was only briefly used during login to a website, like Facebook, after which the connections would drop back to less compute-intensive plaintext HTTP.  The trouble was that this exposed the user's "session cookie," which is how the user was logged in, how the user's interaction with the remote Facebook server kept being reidentified as being them.  That was the only way remote servers had to recognize a user's repeated activities because all web queries stand alone otherwise.



So if a bad guy were to sniff a cookie, they could instantly impersonate that logged-in user.  And they could because the traffic was just plaintext.  Anybody looking at plaintext - and, you know, I remember doing it in my local Starbucks.  I didn't log in as a person, but I saw a whole column down the right-hand side of the other people at Starbucks whose authentication tokens my browser had just sniffed.



So this obvious flaw was fixed, for example, by switching to always keeping all traffic encrypted using HTTPS, as we do now.  As we know, virtually the entire Internet has switched to always-on HTTPS.  But if a browser ever even once made the mistake of issuing an HTTP query to a remote server, whatever cookies it might be carrying for that server's domain would still be sent in the clear.  So the formal cookie specification was again tweaked so that the server who's setting the cookie could set a "secure" flag with a cookie.  This would instruct the browser to never send the cookie over any unencrypted HTTPS query.  So today, all responsible cookie setting now also uses the "secure" flag to prevent any cookie leakage.



But if you stand back for a moment and consider how much work we're asking these poor old original cookies to do for us, and how much more technology we have readily available to us today than we did 31 years ago back in 1994 - especially our lovely crypto technology today - the need to replace these trusty and crusty old cookies, which are just dumb pseudorandom bits of gibberish, with something far more powerful, resilient, and resistant to abuse, it's hard to resist.  And today it's something we can do easily.  That session cookie replacement is now on the horizon, it's everything it could be, and it's called "Device Bound Session Credentials," or DBSC for short.  And it actually does a lot more than cookies ever could.



Okay.  So what are Device Bound Session Cookies?  The World Wide Web Consortium's (W3C's) public GitHub page, part of which I'm going to share, is quite dense and quite matter of fact.  But don't worry if some of this is initially confusing and flies over your head.  It'll be flying over most of our heads.  This is enough of a change from the way things have always been done for the past 31 years that it will likely take another podcast or two for all of what this means to sink in.  We'll all get there together.  I'm sure we'll be going back to this multiple times in the future.



LEO:  So this is going to be a cookie replacement.  Is this going to be implemented for sure?



STEVE:  Yes.  It is already on, you know, Safari, Firefox, and Chrome are all working on it right now.  And it is in, well, Firefox, Safari and Firefox have it.  And Chrome got it with 135, with the update that just happened.



LEO:  That's hysterical.  Because what are we going to do about all the cookie banners that we have to click through?  Are we going to have DBSC banners?



STEVE:  Yeah, it's going to be a mess.



LEO:  Yeah.



STEVE:  Okay.  So here's what the W3C considers to be their "explainer."  And I'll take a break here because at one point what they're saying becomes more clear.  So I'll end up explaining what's going on.  So they write:  "Device Bound Session Credentials aims to reduce account hijacking caused by cookie theft.  It does so by introducing a protocol and browser infrastructure to maintain and prove possession of a cryptographic key.



"The main challenge with cookies as an authentication mechanism is that they only lend themselves to bearer-token schemes."  Okay, that meaning where the browser is the bearer of and holder of a token, which is useful, but there's a lot it can't do.  So this says "they only lend themselves to bearer token schemes.     On desktop operating systems, application isolation is lacking, and local malware can generally access anything that the browser itself can, and the browser must be able to access cookies.  On the other hand, authentication with a private key allows the use of system-level protection against key exfiltration."



In other words, if we think about TPM, and we think about having a private key and proving that we have it by signing a challenge, and someone verifies our signature with our public key, that is, if we take this to a whole 'nother level, all of these other mechanisms exist today, and we've not been using them for the past 31 years.



So they said:  "DBSC offers an API for websites to control the lifetime of such keys, behind the abstraction of a session, and a protocol for periodically and automatically proving possession of those keys to the website's servers."  Now, I should explain that, as I'm reading this now, because I understand what it is doing, this all makes sense to me.  The first time I read it, I was like, what?  Okay.  So this is the first time everyone's hearing it, so I understand.  You're having my reaction.  It's like, what?  Anyway, this is going to get clear.



So they said:  "There is a separate key for each session, and it should not be possible to detect if two different session keys are from one device."  That's for privacy's sake.  "One of the key goals is to enable drop-in integration with common types of current auth infrastructure.  Meaning the rest of the world doesn't have to change to incorporate this.  By device-binding the private key, and with appropriate intervals of the proofs, the browser can limit malware's ability to offload its abuse off the user's device, significantly increasing the chance that either the browser or server can detect and mitigate cookie theft."  In other words, cookies are going to still exist, but they're going to be short-lived, and the key is not in the browser.  The key is in the device.



LEO:  Uh-huh.  So this eliminates that whole Firesheep thing of I got into your thing, I stole your Facebook cookie, and now I can logon as you on my machine because it's device bound.



STEVE:  Correct.



LEO:  That makes sense.  Although haven't we fixed that with HTTPS?



STEVE:  No.  All that is, is the communication.



LEO:  Right.



STEVE:  It isn't the authentication.



LEO:  So it prevents somebody from getting in and stealing the cookie.  But if they could still get the cookie, it would still be good.



STEVE:  Right.



LEO:  Got it.



STEVE:  But this periodically re-authenticates, requires that cookies be re-authenticated.



LEO:  To the device, yeah.



STEVE:  To the device.  So if someone takes them elsewhere, they can't use them for long.  And if there's any question about them, then reauthentication can be required.  Anyway, so this says:  "DBSC is bound to a device with cryptographic keys that cannot be exported from the user's device under normal circumstances.  This is called 'device binding'" - unfortunately it's not hyphenated - "in the rest of this document.



"DBSC provides an API that servers can use to create a session bound to a device, and this session can periodically be refreshed with an optional cryptographic proof the session is still bound to the original device."  Which I didn't understand the first time I read it, but it'll get clear in a minute.  "At sign-in, the API informs the browser that a session starts, which triggers the key creation.  It then instructs the browser that any time a request is made while the session is active, the browser should ensure the presence of certain cookies.  If these cookies are not present, DBSC will hold network requests while querying the configured endpoint for updated cookies."  Now, okay, let me stop because I didn't understand what the heck they were talking about the first time I read that.  Now I get it.



So we're going to log into a service.  So with DBSC present, after the user authenticates themselves with a browser on a device, there is now a new API that causes the device's DBSC public key to be sent to the remote server, to the website server.  So as part of the user authentication on the device, the DBSC public key is sent to the remote server.  That's what it uses then to reauthenticate the user whenever necessary.  And we also now need to think of, not just a web server, but an authentication side of the server.  That is, there's sort of an asynchronous separate authenticator on the website that is running adjacent to the regular website.



So what happens then is the website tells the browser, you need to have session cookies, and you're not sending me any session cookies.  So the browser then queries this new authenticating portion of the site through an API and says I need updated session cookies.  Please challenge me.  So that authenticating side sends a random blob to the browser.  The browser uses like the system's TPM, the Trusted Platform Module, that maintains a private key that never leaves, that cannot leave, to sign that challenge.  The blob is a challenge that has never existed before, never exist again.  And it'll just be an always increasing random number.  Doesn't matter.  Just has to be unique.  And that's a good way to get it unique.  It signs it and sends it back signed.  So that proves to the authenticating portion, this DBSC authenticating portion, that it's still in communication.



This browser is on the device that originally logged in because that's the only way that it could sign a challenge using the private key that exists only on that device.  And having performed that, successfully performed that cryptographic challenge, that authenticating portion, the new authenticating portion of the website then sends new, fresh, but short-lived session cookies, old-school cookies, to the browser.  Which the browser then returns to the regular website, saying hey, look, it's me.  And I've just re-proven who I am.  And so the website says, oh, good, okay.  Now we can proceed.



So, and that's where in what I just read it said:  "If these cookies are not present, DBSC will hold network requests, meaning keep them pending, like not answer them, while querying the configured endpoint for updated cookies."  So it goes through all that to get the updated cookies.  Then it's able to provide them, and we proceed.



So they wrote:  "DBSC's goal is to reduce session theft by offering an alternative to long-lived cookie bearer tokens" - that's what we've always had up until now - "that allows session authentication that is bound to the user's device.  This makes the Internet safer for users in that it is less likely their identity is abused, since malware is forced to act locally and thus becomes easier to detect and mitigate.  At the same time, the goal is to disrupt the cookie theft ecosystem and force it to adapt to new protections.



"DBSC's primary threat model is that of an attacker who can read and tamper with the user agent, such as with a malware-compromised browser" - or like, for example, bad extensions in your browser - "in which the malware can read and modify browser memory and secrets stored on disk.  In many operating systems, malware may be able to obtain privileged (root, kernel, et cetera) access.  DBSC aims to address this threat by establishing a cryptographic protocol in which secrets can be stored in dedicated systems (such as secure enclaves), though DBSC does not specify how implementers should store, backup, or sync keys as long as such storage is robust against the described threat.



"As a secondary consideration, DBSC also mitigates against certain types of network and server compromise, such as network Attackers-in-the-Middle (where an attacker can read or modify network traffic) or HTTP server log leaks (where a server mistakenly logs full HTTP request and response headers to logs which can be read by unprivileged insiders)."  And of course if they had full headers they would be seeing the cookies that are being transacted.



"In all of these scenarios, DBSC aims to enforce the specific constraint that temporary read/write access to a user agent or network traffic does not enable long-lived access to any established DBSC sessions.  For example, if an attacker has malware running within a victim browser process, they should be unable to continue to authenticate as the victim browser once that malware has been removed.  (Note, however, that the definition of 'long-lived' depends upon the configuration refresh period.  Within that period, attackers may continue to have short-lived access to any established sessions.)"



And the reason for that is we're still using cookies.  And the reason we're still using cookies is that it's still too expensive to use this crypto all the time.  I mean, it's important to understand what an insane number of queries our browsers are generating.  I mean, it's just a flood of queries coming out of our browsers.  They cannot be each individually cryptographically authenticated every time.  It's still too expensive.  So the idea is we're going to compromise.  We're going to be able to periodically reauthenticate short-life cookies.  And, importantly, before something critical is done, like acknowledging a funding transfer, or confirming a purchase or something.  It's absolutely practical to ask for an updated reconfirmation of the device's authentication.  So on an interactive level, we certainly have the speed to do that.



And so a compromise has been necessary.  The previous approaches to replace cookies for binding sessions have failed because they were unwilling to make a compromise, and it's just too expensive.  So this is a nice solution.  And the other important aspect of this is that most of the website doesn't need to change.  Most of the website, all of the website that is not about DBSC, it just sees session cookies, so it's got everything it's always had.  We're only adding a new authentication slice to the overall site.



So they said:  "What are the non-goals?  DBSC will not prevent temporary access to any browser sessions while the attacker has ongoing access to a compromised user-agent."  Right, because we're still, you know, we're still using cookies, but not long.  "An attacker with ongoing access to a compromised user-agent (or decrypting middlebox, et cetera) will be able to continuously access fresh DBSC-controlled bearer tokens [cookies]; and an attacker with malware running on a compromised device will, on many modern operating systems, be able to treat even secure elements as a signing oracle" - meaning able to get it to sign on their behalf - "in order to provide proof-of-possession of the DBSC secret keys."  So again, as do all modern security protocols, they clearly outline, these are the things we do.  These are the things we know we don't do.  And we're not claiming to be able to do everything.



So they said:  "So what makes Device Bound Session Credentials different?"  And they wrote:  "DBSC is not the first proposal towards these goals, with a notable one being Token Binding.  This proposal offers two important features that we believe makes it easier to deploy than previous proposals.  DBSC provides application-level binding and browser-initiated refreshes that can make sure devices are still bound to the original device.



"For websites, device binding is most useful for securing authenticated sessions for users.  DBSC allows websites to closely couple the setup of bound sessions with user sign-in mechanisms, makes session and key lifetimes explicit and controllable, and allows servers to design infrastructure that places verification of session credentials close to where user credentials (cookies) are processed in their infrastructure.



"Other proposals have explored lower-level APIs for websites to create and use protected private keys, for example via Web Crypto or APIs similar to WebAuthn.  While this works in theory, it puts a very large burden on the website to integrate with.  In particular, since the cost of using protected keys is high, websites must design some infrastructure for collecting signatures only as often as needed.



"This means either high-touch integrations where the keys are only used to protect sensitive operations like making a purchase, or a general ability to divert arbitrary requests to some endpoint that collects and verifies a signature, then retries the original request.  The former doesn't protect the whole session and violates the principle of secure by default, while the latter can be prohibitively expensive for large websites built from multiple components by multiple teams and may require non-trivial rewrites of web and RPC frameworks."



Finally they said:  "DBSC instead allows a website to consolidate the session binding to a few points:  At sign-in, it informs the browser that a session starts, which triggers the key creation.  It then instructs the browser that any time a request is made while that session is active, the browser should ensure the presence of certain cookies.  The browser does this by calling a dedicated refresh endpoint specified by the website whenever such cookies are needed, presenting that endpoint with a proof of possession of the private key.  That endpoint in turn, using existing standard Set-Cookie headers, provides the browser with short-term cookies needed to make other requests."



Okay.  So again, there we finally get some sense for what's going on.  Many previous efforts, as I said, to replace cookies have been proposed.  None have taken hold.  This one demonstrates a carefully crafted compromise.



Rather than constantly and continually using expensive public key crypto to prove its identity, DBSC sets up a secondary, essentially a "cookie supplier" for a website.  The website tells the browser which cookies it needs to be providing.  If the browser doesn't have those, or if they're near expiring,  then, and only then, it separately connects to the "cookie supplier," where it uses rigorous state-of-the-art crypto to authenticate its device - not its browser, not its user, its device to the hardware, I mean, the device's hardware to the website's cookie supplier.  Having done so, the cookie supplier returns regular old-fashioned cookies, which the browser will then use when subsequently transacting with the main website's pages.



The explainer continues, saying:  "This provides two important benefits.  First, session binding logic is consolidated in the sign-in mechanism, and the new dedicated refresh endpoint.  All other parts of the website continue to see cookies as their only authentication credentials.  The only difference is that those cookies are now short-lived.  This allows deployment on complex existing setups, often with no changes to non-auth-related endpoints.  And second, if a browser is about to make a request where it has been instructed to include such a cookie, but doesn't have one, it defers making that request until the refresh is done.



"While this may add latency to such cases, it also means non-auth endpoints do not need to tolerate unauthenticated requests or respond with any kind of retry logic or redirects.  This again allows deployment with minimal changes to existing endpoints."  They said:  "Note that the latency introduced by deferring of requests can be mitigated by the browser in other ways, which will be discussed later."



And, interestingly, under "TPM Considerations," you know, Trusted Platform Module, they wrote:  "DBSC depends on user devices having a way of signing challenges while protecting private keys from exfiltration by malware.  This usually means the browser needs to have access to a Trusted Platform Module on the device, which is not always available.  TPMs also have a reputation for having high latency" - meaning they're not fast - "and not being dependable.  Having a TPM is a requirement for installing Windows 11, and can be available on previous versions.  All our studies are for public key cryptography using Elliptic Curve DSA_P256 algorithm.



"Chrome has done studies to understand TPM availability to understand the feasibility of secure sessions.  Current data shows about 60%, and currently growing, of Windows users would be offered protections.  Studies have also been done on the current populations of TPMs, both for latency and predictability.  Currently the latency for signing operations averages 200ms" - so one-fifth of a second - "with only 5% of signing operations exceeding 600ms, and the error rate is very low, currently around 0.001%."  And if you got an error you just retry.



"Based on this research, TPMs are widely available, with a latency and consistency that is acceptable for the proposed usage."  And as we know, TPMs of the future having some crypto engine as part of every device is absolutely the future.  So the spec is here.  We already have 60% coverage.  And that's only going to be going up over time.



So they ask:  "What about privacy considerations?"  They said:  "An important high-level goal of this protocol is to introduce no additional surface for user tracking.  Implementing this API for a browser or enabling it for a website should not entail any significant user privacy tradeoffs.  There are a few obvious considerations to ensure we achieve that goal.



"Lifetime of a session and key material:  This should provide no additional client data storage, for example, a pseudo-cookie.  As such, we require that browsers MUST clear sessions and keys when clearing other site data like cookies."  So, like, no DBSC residual will outlive cookie life.  "Cross-site/cross-origin data leakage:  It should be impossible for a site to use this API to circumvent the same origin policy and similar cookie policies.  Implementing this API should not meaningfully increase the entropy of heuristic device fingerprinting signals."  Right?  So you're not, I mean, they're designing this very much with the state of the art of privacy in mind.



"This API, which allows background 'pings' to the refresh endpoint when the user is not directly active, must not enable long-term tracking of a user when they've navigated away from the connected site."  That's a very good point because there is a new communications protocol set up between the browser and the refresh endpoint to obtain updated cookies.  But that only needs to be happening while the user is actively looking at that tab on that site.



"Each session has a separate new key created, and it should not be possible to detect that different sessions are from the same device."  So the keys are all isolated.  "Registration and refresh will only be performed over a secure connection, or with localhost for testing."  They said:  "To achieve these goals, we add the following constraints to DBSC requests:  Registration and refresh are made in the context of the request that triggered them.  For registration, this is the request serving the Sec-Session-Registration header.  For refresh, this is the request deferred due to missing cookies."  They said:  "Cookie refresh only occurs if the cookie is accessible.  DBSC will not attempt to refresh a third-party cookie if the third-party cookies are blocked.  And proactive refreshes must only occur if any tab has a page from the site currently loaded."



And then lastly:  "While DBSC addresses a general problem of session hijacking and can be applicable to any browser consumer, it is possible to expand this protocol to better support enterprise use cases.  By adding specifics to key generation, we can provide a more secure environment for enterprise users.  This is the goal of DBSC(E), which is an extension to DBSC.  The high-level design of DBSC(E) is described in the DBSC(E) Overview.  DBSC(E) removes the vulnerability DBSC has, where a malware, if already present in the device during the key generation, can potentially take over a session.  DBSC(E) proposes to mitigate this vulnerability by introducing device key chaining."



Okay.  So I am fully aware that what we've just done was a lot to digest.  And we're at the end of a lengthy podcast with no time to dig further into this.  But at least the essence of this new system is probably now clear:  Cookies still exist, but they are short lived, rather than persisting, as they often do these days, essentially forever.  I mean, I can't remember the last time I logged into many services that I use every day or two.  They are staying current.



As cookies near what will now be their shorter end of life, the browser will be able to ping a website, a newly defined website endpoint, meaning, you know, something that is part of the specification, where it'll be, you know, some dot name directory off of the root, where a specific service, newly defined service will always be available if DBSC is supported.  The browser will be able to ping that at any time separately in order to obtain a refresh of the cookies that are about to be expiring, and at that time reauthenticate its device to that remote site.



So to do this, that authenticating endpoint will send a cryptographic challenge that the browser must sign and return, and the browser can only do so using an unexportable private key that's buried in the hardware of the device that the browser is running on top of.  The only thing that can be done with that key is signing cryptographic challenges to prove that the device has the key.  Once the browser returns the challenge properly signed, the cookie provider will refresh the cookies for the domain, and the browser will then continue to be able to use the original website without trouble.



The cleverness of this solution is that it minimizes the changes that are required for the rest of the website by concentrating the new authentication scheme in one location.  And by using shorter lifetime old-school cookies, it achieves compatibility with existing systems while also using the cookies as a form of short-term identity cache so that the system's far, far slower crypto hardware is not overwhelmed and is only needed to occasionally refresh the cookies.



Chrome, Firefox, and Safari have all added support for Device Bound Session Credentials to their web browser offerings.  So now people, websites, researchers can begin experimenting with this and start bringing this onboard.  And I'm sure we'll be talking about this more in the future.



LEO:  Is it a done deal?  I mean, is this for sure what's going to happen?



STEVE:  It requires adoption, like anything else.



LEO:  Yeah.



STEVE:  I mean, you were saying on MacBreak Weekly that you wished Passkeys - or maybe it was on our podcast - that, you know, you wished Passkeys had more adoption than they do.  But recent surveys show less than half of people are using anything other than username and password.



LEO:  Yeah.  Yeah.  Yeah.



STEVE:  So, you know.  So it has to be in the browser.  It has to support a TPM.  That's the first step.  Then it's up to the web server...



LEO:  The sites; right.



STEVE:  ...to decide that it wants to adopt it.



LEO:  Right.



STEVE:  And so it'll be like, you know, you know all the extra hoops you have to jump through if your financial advisor sends you email, and you've got to authenticate, or your bank is making you do extra stuff.



LEO:  Right.



STEVE:  It'll be places where they really, really care about knowing that you're using a particular device.



LEO:  Right.



STEVE:  But what's cool is, once you create a binding, as they call them, a binding between the private key in a device and a remote entity like a bank or your domain name supplier, like I would like to have much stronger authentication between the computer I'm sitting at and Hover.com.



LEO:  Right.  Right.



STEVE:  And so we have never had a mechanism to offer that.  This offers that.



LEO:  Yeah.



STEVE:  When I am sitting up my account at Hover, they could query this, get the public key for the private key in my device, and that would be part of my Hover account.  And then anytime in the future they could require me to be sitting at this computer in order to authenticate to Hover.com.



LEO:  Or they could say, well, you're at that computer, so you don't have to go through the extra multifactor authentication or something; right?



STEVE:  Correct.  Correct.



LEO:  Because right now with Hover I have to do multifactor every single time I log on.



STEVE:  Exactly.



LEO:  And so it kind of makes sense that sites that do have this higher need for security might adopt it first.  I'd love it if my bank adopted this.  That'd be fantastic; right?



STEVE:  Yes, yes.  And essentially it would be extremely good for short-term reauthentication of a device.  You are at this device.  Because we just gave you something, and your device signed it for us, and only that one device in the galaxy could do so.



LEO:  Very - I think this sounds like a good idea.



STEVE:  We need it.  And so...



LEO:  And this is no effort on the user's part.  The user might not even be aware of it.



STEVE:  You would never see it. 



LEO:  Yeah.



STEVE:  It would be completely transparent.



LEO:  Love it.



STEVE:  It might say, you know, we just authenticated your device.  You're done.  



LEO:  You wouldn't need more CAPTCHAs.  You can get rid of those CAPTCHAs.  You could reduce the number of MFA logins.  You know, Hover could say it once, put that special cookie on my hard drive, and then I wouldn't need to do it again on that device.  I think that's...



STEVE:  Right.  Actually, Hover would receive the public key for this feature on your device.



LEO:  Right.



STEVE:  And that's all they would ever need.  It would be part of your account.



LEO:  You still would want to log in.  I think they would still want a password and a login.



STEVE:  Yes.  Yes.  In order to authenticate that it was you at that device.



LEO:  On your device; right, exactly.



STEVE:  Yes.  But this allows cryptographic binding of device to remote account.



LEO:  I think this is good.



STEVE:  It's a good thing.



LEO:  I'm glad they're implementing it, yeah.



STEVE:  Yeah.



LEO:  Did this come from the IETF?  W3C?  Was this...



STEVE:  W3C, and it's in all three browsers.  It's in Safari, Firefox, and Chrome.  And now all of our listeners know about it.



LEO:  I mean, and that presumably means it's in all the Chromium derivatives like Edge, Brave...



STEVE:  Yeah.  And it's because it was just added to Chrome 135 that we're talking about it today.



LEO:  Yeah.  Great.  You know what?  This wasn't so bad.  This was great.  As always, Steve makes it clear.  And I tell you what, that's why you listen to this show because it keeps you up to date on these kinds of things.  I really appreciate that, Steve.  I don't think - I doubt there's any other podcast in the world that has spent any time on Device Bound Session Credentials at all.  We're the first, and we'll probably remain that way.  This is why we listen every Tuesday, right about  1:30 p.m. Pacific, 4:30 Eastern.  And we'll see you next week on Security Now!.



STEVE:  Thanks, buddy.  Bye.



Copyright (c) 2025 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




