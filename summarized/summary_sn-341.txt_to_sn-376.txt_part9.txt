GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#341

DATE:		February 23, 2012

TITLE:		Can "Anonymous" Take Down the Internet?

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-341.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, after catching up with the week's security and privacy news, Steve and Leo examine the feasibility of the hacker group "Anonymous" successfully taking the Internet offline after a disavowed Internet posting has claimed they intend on March 31st.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and we are going to get in a fight over Google, Apple, and the iOS cookie incident.  That and a look at why Anonymous may or may not be able to take down the Internet next month.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 341, recorded February 22, 2012:  The Anonymous Threat.



Time to protect yourself online with - boy, there couldn't be a better time for this show - Security Now!.  Steve Gibson is here, the Explainer in Chief.  And, well, first of all, welcome, Steve.  Good to talk to you.



STEVE GIBSON:  Thank you, Leo.  Our recorded audience don't know that you and I have spent the last 30 minutes talking about coffee, before we pressed the Record button.



LEO:  And we're feeling so good now.



STEVE:  And we're a little self-conscious about whether they would not have enjoyed our exploration as much as we did.  But, oh, well.



LEO:  Let us know.  Let us know.  Tell us.  More coffee or less?  I tell you, the chatroom is going crazy with recommendations and suggestions because there's something about geeks and caffeine.  It merges together.  And it all started because I saw Steve's ginormous cup.  Look at the size of that thing.  And I thought, somebody's got some coffee today.



STEVE:  And I love it, Leo.



LEO:  There's something about coffee.  And I believe we are now of the opinion coffee is good for you, not bad for you.



STEVE:  Oh, it is good.  Not only the caffeine, but it turns out now they're finding that, because coffee bean has a plant origin, the plant-based chemicals are believed to have additional health benefits aside from just the pure stim effect, the so-called polyphenols that the coffee contains.



LEO:  Now, this was a week, boy.  The last three weeks, I would say, have been not security - sometimes we get weeks where there's just lots of hacking and stuff.  And then this week was all about privacy.



STEVE:  Oh, my god, have you seen all this Google stuff happening?



LEO:  Yes, yes.



STEVE:  We've got it all covered here this week.



LEO:  We'll talk about that.  And then there's a huge story, the folks at Anonymous - whoever that it is.  It could be a guy named Jason who lives in Surrey, we don't know.  But whoever that is has said they're going to take the Internet down.



STEVE:  A posting appeared on Pastebin, which is a way of anonymously putting things up and then sharing a link, which I will share with our listeners, stating the intent by the infamous Anonymous group, who everyone takes very seriously now.  In fact, I've got a really interesting story from the director of the National Security Administration, the NSA, worrying about Anonymous's growing capabilities.  So this is not something anyone ignores when they say this.  They knocked off Visa, MasterCard, and PayPal during the whole WikiLeaks deal.  When those payment processors announced that they would stop processing payments for WikiLeaks, Anonymous just took them down.  They were blasted off the Internet for a substantial length of time.  And RIAA has had continuing problems and so forth.



So they're now saying they're going to take the entire Internet down on March 31st.  So I thought, well, let's not wait to talk about this because we have more than a month now.  And so then there has been some follow-up with people claiming to be Anonymous, saying, no, that's not us.  And of course the problem is, if you're truly Anonymous, you have no way of, I mean, I guess there ought to be, like - they ought to use PKI.  They ought to have a way of signing their thing so that it could be proven that it's them.  I don't know.



But anyway, so even if this was a bogus posting, trolling, as they have said, not from them, it doesn't make the question any less significant and interesting, and that is, is it possible to take down the Internet?  And they're talking about doing a denial of service on the Internet's root servers, the root DNS servers, which is arguably the single focus point of the Internet.  I mean, we all need DNS in order to, as we know, resolve domain names into IP addresses.  So I thought this was a great occasion for us to examine the technical feasibility of launching a denial of service attack against the Internet's root DNS servers.  That's what we're going to talk about today, can Anonymous take down the Internet, if the wanted to.



LEO:  I guess there's no point in saying who the heck are they, or is they, or what is Anonymous.



STEVE:  I think they call themselves a "hive."  One of the postings I saw in Twitter with them saying, "That's not us," was them saying, "The hive is not going to do this.  This is a bogus posting."  It's like, oh, okay.  Well, be a hive.



LEO:  But that's the problem.  How do we know?  Who is "they"?  I mean, if you're anonymous, who knows?  All right.  Well, let's get to that right now.  I have a Ford commercial, which I will do sometime in a few minutes.  I do want to kind of - you have some other things to talk about.



STEVE:  Oh, yeah.  In fact, two important things relating to last week's discussion of the discovery that there was so much collision among the prime numbers that were being generated, which are the basis for public key technology on the web.  Well, we'll remember that an academic analysis was done by a group of researchers who looked at the public keys and saw a surprising level of collision among them.  Well, first of all, I don't know what I was thinking, I just misspoke, which is just a classic brain fart, is what you'd have to call it, where I talked about how the certificate authorities had to do a better job of generating prime numbers.  Which is not how it works at all.



How many times have we talked about the fact that what they do is sign our public key?  We generate the public and private key.  And the essence of the elegance of the system is that the private key, which is to say the prime numbers which we choose, never leaves our control, never needs to.  We generate the public key from the two prime numbers.  We send that off along with verifications of our identity to the certificate authority that then signs the public key, thus blessing it and proving that we're the people who have the public key.



So this actually makes the problem a little more worrisome because it means there isn't a single point of, like, heightened responsibility where we can say, oh, well - as I, in a bonehead fashion, did last week - like all we need is for the certificate authorities to do a better job generating the certificates.  They don't.  All they do is sign the ones we provide them.  Which means that what this tells us is that, I mean, the individual servers or machines that people who generate the so-called CSR, the Certificate Signing Request, which is what's sent to the certificate authorities, all of those machines are where we need them to be doing a better job of choosing random prime numbers, which are then aggregated, multiplied together in order to generate the matching public key.  So that's like, well, okay, that's more of a problem.  So that's one.



The second thing that I missed, and actually a buddy of mine, an online friend, Paul Byford, who goes by the handle "Sparky" in our newsgroups and has become a sort of long-term contributor, he said, "Steve, you forgot about the Euclidean algorithm aspect of this."  And it's like, oh, of course I did.  And that needs to be discussed, mostly because it's just so cool.



So Euclid figured out, like in 300 B.C., that there was a cool way of finding the greatest common divisor, the GCD, also the greatest common factor, the GCF, same thing basically, of any two numbers.  And I really recommend that our listeners go take a look at Euclid's algorithm on Wikipedia because Wikipedia has a very nice treatment of it.  This is not rocket science.  You don't have to have a degree in math.  What's so cool about it is how simple it is.  It's sort of a construction-based algorithm.  Remember, this is 300 B.C., so he didn't have access to advanced math...



LEO:  He had rocks.



STEVE:  ...and all that.  And remember, like, construction things, like when we were learning in geometry how to form the chord of a circle, or how to inscribe an isosceles triangle in a circle, where you basically just sort of do things with a compass.  This is sort of like that.  The idea is you have two numbers - and on Wikipedia they have a beautiful little diagram where they sort of explain graphically how this algorithm works, where you take the shorter, if you think of the numbers as lengths, you take the shorter of the two and subtract that from the longer until the result of the subtractions is smaller so that you can't subtract anymore.  Then that gives you a certain length.  Then you apply that against the other ones, similarly, and you go back and forth until you can't go anymore.  And then that is the way you're able to find the greatest common divisor.  It's just this incredibly simple, very clever system.



But think what that means in terms of public keys, which are the product of two primes.  It means you don't have to find two public keys that are the same.  All you need to see is whether two different public keys have a common greatest common divisor, which is prime.  So, and since the public key is a product of two primes, you basically take all the public keys, and you apply Euclid's algorithm against every pair, even if they're different.  So it's not that they have to be the same.  It's that, if two different public keys share one prime number, this algorithm instantly, I mean, easily finds the common prime because that will be the greatest common factor that these two public keys share.  And once you've got that prime, of course, you divide that back - you divide the public key by one factor, and that gives you the other.  So you can crack the private keys of both websites if they happened to share a common prime.



And thus the title of the paper.  The title of this academic paper was "[Ron was wrong, Whit is right]."  And so what their point was, okay, Whit Diffie was the guy who came up with a public key system that only used one secret.  Ron Rivest, who's the "R" of RSA, he uses the two primes.  The point being you're in much worse shape if you have two secrets, meaning these two prime numbers, than if you only need one secret.  And so what they were saying was that the fact that it is so trivial to take two products of primes, which is to say the two public keys, and almost instantly find their greatest common factor, dramatically weakens the fundamental security of our public key infrastructure in the situation of there ever being a chance of sites using the same prime.



And what's been found was sites are stumbling on, by pure chance because the random number generators are not very good, they're stumbling on the same primes, multiplying them together, and then, turns out if you analyze a large database of public keys, you find many more collisions than was ever expected before.  So that is really cool.  Not good news, but just such an elegant hack, essentially, on something that we assumed was going to be much secure than has turned out to be.  Okay.  So Google.  Whoo, boy.



LEO:  Whoo, boy.



STEVE:  Oh, boy.  One thing I needed to say was that Google is working on a password generator for Chrome.



LEO:  I saw that.  I would presume it's something like SuperGenPass.



STEVE:  It's like LastPass



LEO:  Oh, you mean they're going to be a password storage thing, too.



STEVE:  Yes, yes.  They will generate and store and cloud sync.  So it's the whole LastPass enchilada, essentially, that will be built into Chrome because Google recognizes that, I mean, in their own blog posting about this, they say, okay, so passwords are not what we wish we had.  We need something better.  But they're all that we have at the moment.  So let's make them as good as we can in the short term.  So essentially they recognize that LastPass is a great solution, and they're going to build something like it natively into Chrome.  It's not happened yet, but they're exploring it.  And it looks like they're going to do it.



So, yeah, I'm with you, Leo, for dyed-in-the-wool Chrome users, that's only good news because I guess what I like about it is that it will expose this technology to a much larger audience.  I mean, if everyone in the world were using LastPass, problem solved, largely.  But everyone in the world's not, and everyone in the world's not going to.  If it were built into Firefox, then Firefox users would all have it.  And when it gets built into Chrome, all Chrome users will have it.  And it'll just end up increasing the overall security on behalf of the users of Chrome because it'll just be there.  And we know, from all of our experience, that what's there matters.  Things that are there get used.  Things that you have to go out and find and install and then configure, eh, not so much, unfortunately.



LEO:  I just thought, when I read it, and I didn't read it very closely, that it was going to be something like SuperGenPass, where it would generate secure passwords for you.  But I guess it would have to remember them, or what good would it be?



STEVE:  Yeah, exactly.  And cloud syncing is the other thing that LastPass gives us that'll be there, too.  And so it'll be across all Chrome browsers on all platforms.



LEO:  Right.  I mean, I use Chrome everywhere, and I use their syncing capabilities and their password syncing already.  But I also use other browsers and other platforms and mobile platforms.  So I think LastPass is not going to be out of business.



STEVE:  I agree.  That's what's really nice about LastPass is I've got it over on Chrome, and suddenly Chrome knows all of my LastPass passwords, too.



LEO:  Exactly.



STEVE:  Speaking of which, somebody tweeted - I'm jumping out of order here, but we're on the topic, so I will.  David Ward, who tweets from Sydney, Australia said, "Re giving loved ones access to your passwords when you pass on, what about a LastPass OTP left in a safe?  I think that works."  And I'd forgotten that completely.  That's a perfect solution.



If you Google "LastPass OTP" or "one-time passwords," remember that another feature of LastPass is that you can generate one-time passwords which they save encrypted in their servers.  And what they do that for is to solve the problem of needing to access LastPass in a public setting, like on a library computer, for example, although I don't know that there is any safe way to do that.  But still, if there were a key logger, for example, which could log your keystrokes, you would be ill advised to log into LastPass using your normal, everyday LastPass master password because the keystroke logger could glom onto that, and your security would be breached.



So you can pre-generate and carry in your wallet a series of one-time passwords for LastPass to solve that problem.  You log in once using it.  It will allow you to then access your LastPass account, but you will never be able - in the act of using it, you tear that one up.  You can never use that one again.  So that's a perfect solution.  You generate one or more and give it to your attorney, stick it in your "When I die" bank vault or whatever, and that's a way for your loved ones to get access to your accounts.  And then that solves the problem of, and this was the point that was brought up last week, was the regular user wants to be able to change their LastPass master password periodically for security, which is perfect.  You can still do that any time you want to.  That does not obsolete your one-time passwords, which will live on until they're used.  So David, thank you for bringing that up.  That was a great tweet and a great solution to the problem.  Okay.  Back to Google.



LEO:  That's the good stuff.  Now the bad stuff.



STEVE:  So, okay.  There were two main issues that were brought up and got wide coverage.  Jonathan Mayer, who we've spoken of before, is a researcher at Stanford University.  And he discovered something rather disturbing, which was that Google and three other advertisers were deliberately bypassing Safari's anti-tracking.  Safari is, and I love Apple for this, and I love Safari for this, the only browser that has third-party tracking cookies disabled by default.  It's just amazing to me.



One of the last things I still need to get to, and it's on my very short list of things I need to wrap up in order to get on to my next big project, is my cookie system.  If you go to GRC.com/cookies/cookies.htm, Leo, you will see a still-unpublished set of pages with technology that's been actually running now for several years at GRC.  Last week GRC had 73,356 unique visitors.  Of those 73,356 unique visitors, 84.59 percent of them had third-party cookies enabled.  So almost 85 percent.  Think about that.  I mean, the vast majority of people surfing the 'Net still have third-party cookies enabled.  Why?  Because that's the default setting in all browsers except Safari.  And if you scroll down that page, I'm tracking all of the cookie usage by browser.



LEO:  Are you using cookies to do this?  No, I guess you couldn't.



STEVE:  Oh, yeah.  Oh, yeah, yeah.  I've got some amazing technology.  If you look at, in the block of links at the bottom, look at the stats.  I think it's the top link on the third column because I clicked it just before this as I was generating the URL.  This is showing it dynamically tracks the statistics of cookie usage by browser version and manufacturer.  And there's a bar chart, if you scroll down a little ways, showing how different Safari cookie usage is than every other browser.  Why?  Because Safari has them off by default.  Only 26.65 percent of Safari visitors have third-party cookies enabled because it's off by default.  So that's, I mean, that's a radical difference, demonstrating, once again, the importance of default settings.  Most people are going to just be using default settings all the time.



LEO:  You and I have kind of a disagreement on this issue.



STEVE:  Ah, okay.



LEO:  Well, I don't think - so perhaps you might explain why third-party cookies are bad.



STEVE:  Well, oh, no.  And we don't disagree, actually, as much.  One of the things that we will get to, and I'm glad you brought it up, is okay, so what?  How much does it matter?  Is it a big deal, and so forth.



LEO:  In fact, a lot of sites won't work.  We don't use third-party cookies particularly on our site.  But occasionally we do, if you have an ad banner.  What a third-party cookie is on our site, you come to TWiT.tv, and there's an ad banner there.  That ad banner can set a cookie on your page and use that cookie to determine that you visited the page and so forth.  And that's how we get paid.  And in fact that's how - third-party cookies are in fact how the Internet monetizes.  So I think you could make a case, and John Battelle made this case, that Apple in fact isn't doing this for privacy purposes, but to, as Apple is wont, keep others from profiting when it's Apple's job to make all the money on Mac users and iOS users.



STEVE:  That's interesting.



LEO:  Anyway, I'll just bring that up.



STEVE:  Okay, so...



LEO:  Go ahead, what's wrong with third-party cookies?



STEVE:  Well, okay.  So, arguably, I think the user should be informed.



LEO:  I don't disagree with you on that.  I completely agree with you on that.



STEVE:  And so I would have...



LEO:  But setting a default, in a way, is not a form of information, it's merely blocking it on their behalf, determining what they want.



STEVE:  Agreed.  And so, for example, if third-party cookies are important to a site for its own monetary support, I would have no problem with the site saying, "Hi there, welcome.  We're happy to have you, but you've got third-party cookies disabled, and we need those in order to get paid.  So if you want to use our site's free services, click here to turn on third-party cookies so that our advertisers can know where you came from and can pay us for the fact that you're browsing around our pages."



And, I mean, if we had a system like that, and it's entirely doable, but it just hasn't happened yet, then I think the problem is solved.  It would be built into browsers.  Yes, it would get in people's face, but be much gentler than NoScript, which is the page doesn't work at all, and people are wondering why and so forth.  But it just says, for those sites that want to, to ask their visitors to turn on third-party cookies.



Now, users could then decide how they feel about that.  Savvy people might say, well, you know, I don't really need to be here, and I'd rather not be tracked because the concern that people have had is that third-party cookies, the whole point of them is that it's not the site that you're visiting, it's the site whose resources the site is presenting, like ads, that then allow profiles to be made of people over time.  I know from my own experience that there are people who feel very strongly, I mean, they delete their cookies, they flush their cookies, they go through all this work.  They just don't like the idea that they're going to be tracked.  It's like, okay.



So you and I are on the same page that users ought to be informed.  And I have no problem with a site saying, "Hi.  You don't have third-party cookies enabled.  We need them in order to be paid by our advertisers, so please turn them on for this site."  And that technology exists in all the browsers.  You can do per-site enabling of third-party cookies, which solves the problem.  Right now, it's just not easy, and it ought to be made easy.



LEO:  Yeah, I mean, I go back and forth on this.  I think that most, the vast majority of people have no idea what a cookie is.  And unfortunately, I think that there's a lot of paranoia building about cookies.  I don't think cookies are harmful in the least.  In fact, I think they're how the Internet works.  And I think that blocking cookies, first or third-party cookies, breaks the Internet.  And people prey on the, I think, incorrect paranoia people have about cookies.  People delete cookies like crazy, as if that's some magic process.  It is not.  And as we have talked about before, it also does not in any way prevent companies from tracking you.



STEVE:  I was going to say, exactly, and there are many other ways of locking onto someone.  Still, cookies are the main way.  They're the easiest way.  They're the most straightforward way.  And you could argue, I mean, they were built into browsers in order to create this sort of state, in order to create a stateful connection to visitors.  So, yeah.  I guess, what, long-term, in the same way that scripting is something that you can increasingly not live without, cookies are probably something that you will increasingly need to allow.



LEO:  Turn off cookies and see how the Internet works.  It doesn't.



STEVE:  Yeah.



LEO:  The good news is you can turn off third-party cookies.  Apple calls them "Allow cookies only from sites I am visiting."



STEVE:  Right.



LEO:  And you can in fact disable that without any apparent hardship.  Although there are some sites, somebody in the chatroom said the BBC site will not show videos without third-party cookies.  There are some sites that does break.  But because this is so prevalent on Apple hardware, most sites have found ways around it.  And that's what Google was doing, and these other ad agencies.



STEVE:  Precisely.



LEO:  The question is, why does Apple do that?  Are they on the side of the angels?  And it's merely my opinion that Apple, they do this all the time, they don't want anybody to have information about their users except Apple.  So that's the real issue.  Apple knows exactly where you're going and serves you ads in response.



STEVE:  There could be a real reason.  They actually do say it's for user privacy.



LEO:  Well, of course they do.  That's what I would say, too, were I Apple.



STEVE:  Okay.



LEO:  That doesn't mean that's why.  It just means what they say.



STEVE:  The way their cookie system works softens this a little bit.  And this is what I learned from this cookie forensics experiment that I did years ago because this thing characterizes the exact cookie handling of all browsers.  And it turns out no browser is free of actual bugs in their cookie handling, some worse than others.  In Safari, if you disable third-party cookies, it doesn't simply kill them or stop them.  If you had any third-party cookies, they continue to be sent to any third-party site that you visit.  So it won't accept new ones, but it still transmits any that you have that match that domain.  If you are at a third-party site, and you have a cookie for that site, that one site has the ability to write cookies to you.  So a third-party site that your browser doesn't currently have a cookie for cannot write new cookies.  But a third-party site that your browser does have a cookie for, first will receive it, and can modify it, is able to write cookies.  So in order to, if you were concerned, you'd have to disable cookies in Safari, delete them all, then restart Safari because there's also a whole restarting thing that comes into this, whether they're, like, many browsers still don't obey your requests until you shut them down and start them up again.



But the third interesting aspect is, in Safari by design - now, this was removed from WebKit seven months ago, but it hasn't yet migrated into Safari.  And that is, if you submit a form to a third-party site, then that third party is allowed, even if third-party cookies are disabled, the response to a form submission to a third-party site is allowed to submit cookies.  And that's what Google figured out.



LEO:  So you're saying that WebKit disabled this months ago.



STEVE:  Yes.



LEO:  And of course Safari is based on WebKit.  But Apple did not.



STEVE:  Apple hasn't.  I don't know if Safari is tracking the current WebKit.  But Google took it out of WebKit seven months ago.



LEO:  Google took it out.



STEVE:  Yes.



LEO:  So WebKit is an open source project that many companies contribute to, including Google and Apple.



STEVE:  Right.



LEO:  And their browsers, both Chrome and Safari, are based on.



STEVE:  Exactly.



LEO:  But it was Google that removed that from the WebKit code?



STEVE:  Seven months ago.



LEO:  In Chrome, or in the WebKit open source project?



STEVE:  In the WebKit open source project.



LEO:  So if you use the WebKit browser - see, the problem is on iOS you can't use the WebKit browser.  But if you're using the WebKit browser on the desktop, this trick wouldn't work.



STEVE:  Correct.



LEO:  Interesting.



STEVE:  But it works on Safari because Apple hasn't been pulling those changes from WebKit.



LEO:  Interesting.



STEVE:  So it's still there in Safari.  So what Google figured out, and three other advertisers, as well, and this is what Jonathan Mayer at Stanford University caught them doing, is they needed to bust Safari's blocking - Google "they."  Google needed to bust Safari's blocking of third-party cookies for their +1 feature to work on ads because ads are from third parties, and they needed to essentially enable third-party cookies.  But they couldn't in Safari by default.  And it was a problem because Safari has this disabled by default.  So as we've seen, more than three quarters of Safari users have third-party cookies disabled.



Google didn't like that.  So what Google figured out was - get this, Leo.  A web form in an iframe in an ad can be submitted by JavaScript.  And that allows them, through this really convoluted mechanism, to get a third-party cookie set.  And what Jonathan discovered was that Google's code looks at the user agent.  And he tested 400 different user agents and has a spreadsheet available in his original posting showing this, that only when the user agent is Safari, any variant of Safari on any of the Safari platforms, then different code is issued which uses this iframe form posting trick, which is then submitted so the user has no interaction needed because JavaScript triggers the submit function of the form in order to get this +1 functionality to work.



LEO:  That's, by the way, very common practice in JavaScript.  You test user agent because JavaScript itself has so many bugs.  So this is not - it sounds like, again, I think it's important not to overblow this.  It sounds like, oh, my god, they were searching for user agents.  It's throughout all JavaScript code that you do this because you always have different code for different user agents.  That's unfortunately a necessity because JavaScript is so buggy.  And what did Google do with this end-around?  Were they tracking people as they surfed the 'Net?  No.  They turned on a +1 button for people who were logged into Google.



STEVE:  This was allowing, exactly, this was allowing third-party cookies to be set.



LEO:  Right.  And as far as we know, it's possible they were doing other stuff, including tracking people's iPhones, I guess.  But it was, in my opinion, I think Google's justified.  But again, there's two sides of this story.  I'm just trying to give you both sides.  What Google's doing is, for people who are logged into Google,  is to turn on the +1 button so that you may +1 ads as well as +1 pages.  That does not work, just as the Facebook Like button does not work, if third-party cookies are disabled.



STEVE:  Right.



LEO:  And one could say, in fact, as many do, the Like button and the +1 button are invasive on all web pages because, as soon as you go to a page with a Like button or a +1 button, unless you've disabled third-party cookies, Facebook or Google, respectively, know you're there.  In fact, we've even talked about it.  Even if you're logged out on Facebook, apparently, the Like button still sends a signal.



STEVE:  Right.



LEO:  So the real question, I guess, is how nefarious - it does look pretty sleazy to end-around, to look at a workaround for something like this.  And I think Google probably should stop doing that.



STEVE:  Yes.



LEO:  On the other hand...



STEVE:  And they have said they're going to.  They have said we're sorry, we'll figure out some other way around this.



LEO:  Right.  But on the other hand, companies like Facebook and Google provide some significant services for free.  And the way they monetize is this way.  And so it's kind of how - it's kind of how that works.



STEVE:  Yup, the reason it's free.  Now, to their discredit, Microsoft jumped on this.  And this is Part 2 of this brouhaha.  Microsoft said, well, Google is abusing our P3P technology, which is Microsoft's Platform for Privacy Preferences.  Quoting from The Verge, which is an online news source, they said, "Just a few days after the Wall Street Journal reported that Google, Facebook, and others have been using a workaround to bypass the cookie restrictions in Apple's Safari and Mobile Safari web browsers, Microsoft now claims that Google has taken similar measures to bypass privacy settings in Internet Explorer.  Microsoft says that Google is improperly representing its cookies by using a non-standard P3P cookie policy statement.  It claims that 'Google's P3P policy is actually a statement that it is not a P3P policy,' which allows Google's cookies to pass through without being blocked."



Google's response to this is also reported by The Verge:  "Earlier today, Microsoft accused Google of manipulating Internet Explorer's default privacy restrictions in order to 'bypass user preferences about cookies.'  Google has just responded with a lengthy rebuttal, arguing that Microsoft's P3P cookie technology is 'widely non-operational,'" - love that phrase - "and that the issue has been around since 2002.  The response also points to other offenders, citing a 2010 Carnegie Mellon research paper that says over 11,000 websites don't use valid P3P policies."  And then Google talks about Facebook and Amazon, saying that they also are doing the same thing.



Now, in this, I completely agree with Google.  What happened was Microsoft, in an earlier version of IE, entertained disabling third-party cookies also by default.  There was a version for a while in beta that had third-party cookies disabled by default.  Microsoft generated so much flak from doing this by big business that just screamed.  And this is years ago. This is 10 years ago or so, and I don't know, maybe it was an early version of IE6.  But Microsoft got so much flak that they backed off from turning off third-party cookies by default and came up with this bogus approach, where a website, in the query headers going to a server, can assert what their cookie policy is in a machine-readable header of little three-character tokens.



And what really annoys me is that, if you, in IE today, all versions of IE, if you turn up your privacy to maximum, such that it says you are blocking third-party cookies, yet if a third-party website has a specially crafted P3P policy header, IE goes, oh, well, they say that they're going to do good things with your cookie, so we'll let third-party cookies work anyway.  And so this is a complete override over IE's clearly stated policies that the user can control, even on a per-site basis.  If a site says, no, no, we're nice people, then IE just says, oh, well, in that case, let me have your cookie.  So that's what Google is saying.  They're saying this is ridiculous.  IE allows any site that wants to, to override the user's and the browser's preferences.  So we're doing it, yes, and so is Facebook and Amazon and 11,000 other sites.  So that's what that was.  What do you think about that, Leo?



LEO:  Interesting.  Well, it's not a surprise.  I mean, look, everybody wants to make as much hay as they can out of this because - the real issue, the very significant issue, unfortunately, is this is highly technical stuff, and there's a lot of issues involved that are very complex.  And even the tech press is - it makes a great headline.



STEVE:  They're never going to get it right.



LEO:  It makes a great headline.  And so people are - I get a lot of accusations whenever I bring this up, oh, you're biased in favor of Google.  And I think anybody knows who listens to everything I do that I don't have a bias in favor of Google at all, or Apple.  But I think what has to happen is that, as best we can, to this audience which is highly technical, is for the audience to understand not merely how has it happened, but there are whys.



And there's a deeper issue, which is how the Internet monetizes itself.  And as someone who, I mean, I'm kind of above this because we monetize by ads, which we force you to watch, and I'm about to do one.  But you have no choice.  So we do have some banner ads, and we are going to start doing more banner ads on the website, and that's where all this starts to happen.  That's when all this third-party cookie tracking and so forth starts to happen.  It is the means that, frankly, powers the Internet.



And the good news, Google, I think, is extremely upfront in their privacy policy.  And the good news is, if you do not log into a Google account, or if you do not create a Google account, or you delete your Google account, none of this will happen to you.  You do have control of this.  This only happens to people who are logged into Google at the time that they're using the browser.  And why do you log into Google?  Because you want to use their free services, chiefly Gmail, or perhaps Google Plus or other services.  You can use Google search completely anonymously.  It's a completely free service.  They do not monetize that directly by tracking you.  They put ads in the search results, but they do not track the results unless you log into a Google account.  And I think they've been remarkably upfront about this in their privacy policy, which they urge people to read over and over again.



STEVE:  I guess the part that I don't get, though, is why third-party cookies have anything to do with monetization.



LEO:  Well, a perfect example is the +1 button.



STEVE:  Okay.  But that's new.  So, for example, if you host ads on TWiT, then...



LEO:  There's a third-party ad on the banner site; right?  Those ads are not delivered from TWiT.  They're delivered from an ad server, which is a third party.  How do they know that ad was viewed?  Oh, they get hit by the IP address, that's right.



STEVE:  No, the referrer header says we're serving this ad to TWiT.tv.  And so that's where you get your impression count.  The fact that a cookie wasn't sent with it only really means that this user doesn't have their cookie.



LEO:  That's right.  That's a good point.



STEVE:  So they would like to know who you were because then they could aggregate all the other places you have been and everything they know about you, and maybe serve a higher value ad to you.  So it's really a - its argument is it's a user benefit because, if you are profiled by the third party, then they know you're 75, based on the fact of the medication that you've been looking at.  And they're not going to give you a diaper ad, which isn't relevant to you.  And so the idea is...



LEO:  Well, there's value to both sides.  There's value, of course, to the ad server because they can sell that ad for more money because it's a targeted demographic.  So I think the real issue - and I don't think most people would have a problem, or having understood that, I don't think that is - because they're not tracking you personally.  It's not like they say, how can we get an ad to Leo Laporte?  I don't believe that ever happens.



STEVE:  Well, yeah, the argument is that they really do know who we are, that there's enough privacy...



LEO:  They don't care.  But that's not - what they really want to know is what's my age, income; they want to know demographic information.  That's what's of value to them, not my name, age, and social - not my Social Security number, you know what I'm saying?  They don't care about me as an individual.  It's an aggregate.  At least my understanding of how ads works.  Now, the real question for people who are worried about this is exactly that.  Are they trying to find out something about me personally?  And I don't believe that's the case.



STEVE:  Well, people who have worked in the third-party advertising world have said you wouldn't believe how much information they have about people.



LEO:  Of course.  In fact, there's a great article in the Sunday Times which I recommend everybody read about how Target knew that a teenager was pregnant before her parents did.  And it's not, by the way, necessarily online behavior.  They're aggregating tons of data about you.



STEVE:  Pulling it all together.



LEO:  But again - and I think part of this is a disconnect in how we interpret the word "privacy" in the Internet age.  It isn't really that they cared about that girl and they somehow wanted to know is she pregnant, that particular girl.  What they want to do is identify second trimester customers so they can target particular kinds of advertising, its higher value ads, for a lot of reasons.  Read the article, it's fascinating.  And it doesn't have anything to do really with online privacy, it's just in general.  Is that an invasion of privacy?  It's not like there's a guy at BBD&O who says, hey, Steve Gibson loves a certain kind of coffee.  Let's send Steve Gibson - he doesn't care who Steve Gibson is.  That's too small.  That's too granular.  That's not how you make money.  Maybe someday.



STEVE:  Databases are huge.



LEO:  Right.  Maybe some day you'll make money selling individually to Steve.  But it's much better if I know the three million people who have a burr grinder.  That's what I want to know, not the one person.  So I guess my question, again, is do you feel that people are trying to figure out what Steve Gibson is up to, like they want to know you?



STEVE:  What I know from lots of discussions in privacy newsgroups is just - it's a creep factor.  When someone hears, for example, your story, that Target knew a girl was pregnant before her parents, some percentage of people are going to get creeped out by that.  They're just not - they just don't like the idea.



LEO:  And I understand that's your right, to be creeped out by and to protect yourself.  Completely agree with that.  And so my point is not that it's - you have to make the decision for yourself.  But I want people to make the decision based on absolute fact as opposed to the kneejerk sensationalistic headlines that is what is being distributed around.  And for me, I don't think - they don't care about me.  It's not like they're peering in my window.  Yes, they know a lot of information.  There's a lot of information about me in a database, with the idea toward sending me targeted advertising.  I don't find that particularly intrusive, but maybe some do.



STEVE:  And just so we're clear, my fascination is just the technology.  I get off on how all this stuff works.  I love understanding it.



LEO:  I agree.



STEVE:  And our listeners are saying, hey, how does this work?  I want to know how it works so that I know what it means.



LEO:  And it's our job, it really is our job just to get as much of the information, as technically accurately as possible, out to you.  And then it's ultimately up to each individual what they want to do about it, and whether they're up in arms at Google or not, or all of that.  So I just want - I only bring it up because I think that there is another point of view that needs to be expressed about what this stuff is so that you understand fully what they're doing with it and why they want it.  And we get a lot of free stuff on the Internet, and that's why.



STEVE:  But it's not.  I mean, tracking isn't really necessary.



LEO:  Well, but it's necessary for a certain level of income.



STEVE:  Yes.



LEO:  Now, I don't know how much it costs Facebook to give me a Facebook page.  And so I don't understand the economics of that.  They made $1 billion last year.  Is that enough to pay for 850 million or users or not?  I don't know.  They can make a lot more money with more targeted ads.



STEVE:  Yes.  I was just going to say, it is one thing we do know for sure, and that is that ad targeting does dramatically increase the value per impression.



LEO:  And they may need that.  It may not be sufficient just to get the click.  That's all we get is the CPM.  But it may be that $10 or whatever it is we charge per thousand impressions, that money may be predicated on the fact that the server, ad server, knows more about the viewer than I know.  I don't know anything.  They know it all.  So I just know that we have a certain cost of doing business.  We need to be able to charge a certain amount for ads.  And I don't think it's for any...



STEVE:  And if the ads you show are...



LEO:  Targeted, they're more valuable.



STEVE:  ...of higher value to the advertiser, then that's good for you.



LEO:  Right.  So I don't think we can say that it's not necessary.  We just don't know.  And you can opt out.  There are plenty of people who watch this show who use ad blockers.  There are plenty of people who listen to this show who don't listen to the ads.  You're getting something for free that you're not paying for with your attention.  And so I think this is the problem, is that I don't think people think of their attention as a currency, but it is in fact a currency.



STEVE:  Oh, Leo, I'll confess, I can't watch live television.  I can't.  If I didn't have the ability to jump over commercials, I'd just go crazy.



LEO:  Right, right.  Moving along, Mr. G.



STEVE:  So I did notice that Gizmodo picked up on the spray-on antenna story.



LEO:  Ah, I was wondering if we'd hear more about that.



STEVE:  Yeah, I haven't - there's no additional information so far.  I've watched a lot of background Twitter going around.  They have patents.  Apparently this, was it Cham something, Cham, can't remember the name of the site, but I don't think it's Sham.



LEO:  It is spelled C-h-a-m, so there is some...



STEVE:  It is.  But apparently they are a government contractor, and they've got a bunch of patents on stuff.  So I guess we'll just kind of keep our antennae up, so to speak, and tell you if we hear more from them.



LEO:  Chatroom says it's "ChamTech" like "chameleon."  That makes sense, like "chameleon," because they're painting this.  It's bizarre, bizarre, yeah.



STEVE:  Cool.  Let's see.  I found an interesting site I wanted to share with our listeners, BuiltWith.com, and also Trends.BuiltWith.com.  What this is, is it's a search engine that goes out and inventories all of the sites on the Internet and looks at the technology that the sites are using, what versions of PHP, are they using Flash, are they using Shockwave, are they using RealMedia and so forth.  And their trends page is really interesting because you can see things like the ebb of the use of Flash over time, where sites are, sure enough, moving away from using and relying on Flash to an increasing degree.  So anyway, I just thought it was kind of a cool site that came across my radar that I wanted to share with our listeners, BuiltWith.com.



And in sad news, Chrome has lost its side tabs.  I went looking for them the other day.  You could go to about:settings or about:config or something and turn those on.  Well, apparently it was only just an experiment.  They said on their blog posting about this:  "As an experiment, side tabs were not a success.  A small number of people really passionately loved them" - yup, count me - "but they ended up not being compelling enough to make the cut.  We torture ourselves over stuff like this.  It comes down to painful decisions about keeping Chrome lightweight.  We know that a feature like this is really important to some number of users and Chrome developers!" - exclamation point - "but at the same time we have to continually cut and trim, knowing that those cuts will annoy people, so that Chrome doesn't turn into bloatware and satisfy no one."



LEO:  Now, if Google had said "will annoy Steve Gibson," would you have felt your privacy was invaded?  I think that's who they were thinking of.



STEVE:  They said, "We do hope to have a better solution to the 'I have too many tabs' problem someday soon, but side tabs wasn't it.  I'm really sorry that we let the experiment linger too long.  It meant that many of you became dependent on it, making the end of the experiment an even bigger pain than we wanted it to be."



LEO:  They knew that there were people out there.



STEVE:  Oh, there was a lot of flak from that.  And anyway, I also ran across something called Tabs Manager for Chrome that I wanted to give people a heads-up on.  I don't know what happens when you have too many tabs on Chrome because I'm not yet a full-time Chrome user.  I'm still over on Firefox with, like, 58 tabs open at the moment.  Actually I do know that that is the number that I have open.



LEO:  What, did you count them?  Or is there a number there?



STEVE:  No, there's a tab session manager.



LEO:  Oh, that's funny.



STEVE:  And so sometimes I'll just save all the ones I've got because I don't want a crash to cause me to lose them.  I mean, I just use them as bookmarks.  They're like things I want to get back to when I have a moment.  When I surface from coding, I'll, like, read a few pages that I just didn't want to interrupt myself to read.  So it's just like bookmarks on the Internet is in that fashion, is managed that way.  Anyway, this Tabs Manager, two words, Tabs Manager for Chrome, it just puts a little button up on your button area of Chrome.  And when you click it, it gives you a nice listing of all your tabs that are organized, and you can drag them around and see them easily.  So it's sort of like having the tabs all there because it's easy then to click on one and access a tab.



So anyway, I'm glad - I want Chrome to solve the problem.  If they come up with a better way than actually having tabs on the side, hey, that's fine, as long as there's some way to deal with it because many people like myself organize our web browsing and our lives around mass quantity of tabs.  So figure out how to do that, Chrome, or Google.  That would be great.



LEO:  My suspicion is Google is going to invent something besides tabs that they will say is a better way.



STEVE:  Yay.



LEO:  That they're trying to solve this.



STEVE:  That would be - I'd be happy to have them do that.  And speaking of happy, a subject, "SpinRite made my wife cry"...



LEO:  No.



STEVE:  ...caught my attention.  On February 8th, Andrew said, "Hi, Steve.  I'm not a super tech, but I love the podcast for all the great information and news you and Leo provide.  To get right to it, I have had a hard drive that apparently died on me about six years ago.  Multiple attempts were made to recover the data as it had three years of family photos, including one of my sons' births and two years of his infancy.  The only other option I felt I had was to send the drive off and pay a large sum to have the data recovered.  I figured maybe in the future someday I could do this, as money was short currently.



"I've been a listener for a year now, and I figured, what the heck, let's try it.  I purchased SpinRite and began the recovery process.  The scan ran for approximately two weeks."  And now I'll just remind people, that's like a worst-case scenario.  SpinRite will work as long as it has to, to do the recovery.  Normally it's two hours.  But it can be two weeks if there's, like, lots of extensive damage.  And he said, "I assumed 'It's probably not going to work.'  When the scan finally finished, I connected it as a secondary drive to my PC.  The drive appeared, and the data was now accessible!!!"  Three exclamation points.



"I immediately copied over all the data.  I put together a slide show of our precious photos and ran it.  When my wife was passing by the computer and realized what had happened, the biggest smile and streaming tears came to her face.  Thank you so much for saving us hundreds, if not thousands of dollars, and making a very memorable moment in our lives."



LEO:  She cried in joy, not in sadness.



STEVE:  So Andrew - tears of happiness.  So thanks for sharing that, Andrew.



LEO:  We're going to get to the meat of the matter in just a second, the Anonymous threat.  But I thought, given our discussion of privacy, I should mention that after this show we're going to do This Week in Google with Jeff Jarvis and Gina Trapani.  And our guest actually has written a book about this subject.  It's called "The Consent of the Networked:  The Worldwide Struggle for Internet Freedom."  And one of the topics is, she says, "It's time to fight for our rights before they're sold, legislated, programmed, and engineered away."  She's talking about privacy, among other things.  And so this will be a good discussion.  Rebecca MacKinnon will join us on This Week in Google in about 20 minutes, for those of you watching live.  And for those of you listening, that would be a good one to download, if you want to hear more about this debate.



STEVE:  Very cool.



LEO:  Yeah, fascinating subject.



STEVE:  Very cool.



LEO:  Anonymous.  They're after us.



STEVE:  Okay.  So we don't take Anonymous lightly.  They did actually take down the CIA.gov website earlier this month.  On February 10th was the news about that.  And when I saw the news, I immediately went to - I think I saw it in real time via Twitter, and I went there, and the site sure enough was down.  And it was down for a while.  The Associated Press on Friday the 17th reported that Anonymous had breached the United States Federal Trade Commission's Consumer Protection Business Center website, as well as a National Consumer Protection Week website.  Both sites were temporarily replaced by a "violent German language video," focused on the Anti-Counterfeiting Trade Agreement, the ACTA that we've talked about.  So, I mean, these guys are the real deal.  And The Wall Street Journal on February 21st quoted the director of the NSA, the National Security Agency, warning about the growing strength of the group Anonymous.  And in The Wall Street Journal article they wrote:



"The group has never listed a power blackout as a goal." That's what this NSA guy was worried about was that they were acquiring the ability to access the United States power grid and take parts of it offline.  So The Wall Street Journal article continues:  "The group has never listed a power blackout as a goal, but some federal officials believe Anonymous is headed in a more disruptive direction.  An attack on a network would be consistent with recent public claims and threats by the group.  Last week, for instance, Anonymous announced a plan to shut down the Internet on March 31, which it calls Operation Global Blackout."  And of course, as I mentioned at the top of the show, they have taken Visa and MasterCard, PayPal and other payment providers offline and so forth.



So in this Pastebin posting, I created a short link, a bit.ly link using this Security Now! episode number.  So it's bit.ly/SN341.  That'll get you there, if you're curious.  I won't read it in detail because I don't want to just take up the time for that.  But essentially this appears to be a legitimate posting from Anonymous saying, "To protest SOPA, Wall Street, our irresponsible leaders, and the beloved bankers who are starving the world for their own selfish needs out of sheer sadistic fun, on March 31st, Anonymous will shut the Internet down."



LEO:  Aw, you kids.



STEVE:  Yeah, I know.  Those pesky Anonymous guys.  Then they go into how they're going to pull this off, which is what I wanted to talk about.



LEO:  Well, it's interesting because in fact we have identified this vulnerability before as a significant vulnerability on the Internet.



STEVE:  Yes.  Now, the beauty, as we all know, of the Internet is that it isn't located in one place.  It is inherently individual servers linked to the users through this completely heterogeneous network of interconnected links and routers, where the routers know how to send the traffic in both directions through a series of hops between any two points.  So literally it's just a huge grid of interconnectivity, no single central location.  The one part of the 'Net which is arguably centralized, in a sense, is the DNS root servers.



DNS, and we've talked about this, too, is inherently a hierarchy.  There are the root servers which are the one place that other DNS servers can turn, or users can turn, if they want to sort of start looking for a website.  There needs to be an anchor.  And so these 13 root servers, which are named a.root-servers.net through m.root-servers.net.  So in short, they're known as the A through M root servers.  There's 13 letters, A, B, C, D, E and so forth, to M, that's 13.  13 was chosen just due to some technical record size limitations.  So there's no reason that, like, 13, and it's not 12 or 14 or something, or more, it's just that that's how many conveniently fit technically in terms of the size of their name in the record.



So the argument is that, or the reason the DNS name servers come to people's attention, the reason, if this is a legitimate posting, and I should mention that this Operation Blackout, if you search Twitter for # - I had it written down here.  I'm not seeing it in front of me.  Oh, wait, it's in the Pastebin posting, so I could find it easily there.  Oh, yeah, it's #opGlobalBlackout, not surprisingly.  You can find a lot of dialogue which has occurred recently about this.



And as you and I were saying at the top of the show, Leo, the problem with Anonymous being anonymous is that they're anonymous.  And so someone can post something saying that they're from Anonymous, and then Anonymous can say, no, that's not us, that's somebody else.  So there's some argument about whether this is bogus or not.  And I'm taking the position, well, whether it is or not, March 31st will be interesting to see if anything happens.  And it may well be that nothing will happen.



Why can 13 servers withstand a big attack?  The No. 1 reason that 13 DNS servers aren't going to be affected is that there aren't actually 13 root DNS servers.  There are 13 IP addresses.  And that's very different than 13 servers because, for example, just one of the servers, I happen to know that the "I" server, i.root-servers.net, exists in 25 different countries.  And this is achieved through something known as "anycast," which is not a technology we've talked about yet.



We've talked about "multicast," which is a way of having an IP address sent simultaneously to many different recipients, or another way of thinking about it is it's a way of many recipients all asking for the same content, and instead of the server having to individually send it to individual IP recipients, they can send it to a multicast IP address, and it's automatically routed to many different locations.



Anycast is different than that.  The way anycast works is that individual routers, and we've talked about, we already know routers are the way the Internet routes traffic, spread all over the globe.  Individual routers have an ability to send traffic based on an IP address to the closest matching server.  Now, we're used to thinking of IP addresses as being unique.  So, Leo, you've got an IP address for TWiT.tv, and that's a server located in a location.



LEO:  It's like a phone number.  Everybody has to have a unique phone number, or you'd have collisions.  Every server has to have a unique IP address.



STEVE:  Right.  However, the technology, for example, that content delivery networks are using, is anycast, the idea being that, if you're a content delivery network, you'd like to be able to have servers stationed on both coasts, East Coast and West Coast, maybe in the middle; on other continents on the globe; and you'd want the same URL being used by different people anywhere in the world to somehow find the content closest to you.



LEO:  And we use that, as well, for content delivery.  So when you watch our stream or you listen, Cachefly or Ustream or Justin.tv, all the various providers we use, almost all use CENs.



STEVE:  Exactly.  And so do the root servers.  There are not 13 root servers, there are hundreds of actual physical root servers scattered all over the world.  So the DNS root is actually much stronger than people tend to believe.  Just, as I said, just the "I" IP address, what's funny is that the root servers are the one thing, if you think about it, you cannot access by name.  That is, yes, they have names, i.root-servers.net.  But you can't use that to access them because they're the root of DNS.  So the one thing that you ultimately need is their IP addresses, if you have to go all the way back up the hierarchy to them in order to start looking up, for example, the address of a COM server, then the address of a, like, GRC.com, and then to actually get our IP address.



So the "I" root server is 192.36.148.17.  That's set in stone.  Those 13 IPs are never going to change because they are hardwired into the Internet all over the place.  But the actual servers behind those IPs are free to come and go as they please.  Right now there's hundreds.  It would be easy over time - there's probably even more, I mean, like many, many hundreds.  They're easy to set up.  You create one.  You put it in place.  You essentially broadcast your IP to a router.  And then, if you're closer to that router than another server at the same IP, the anycast technology - actually it's BGP, the Border Gateway Protocol, that routers use for communicating their routing tables - the router will go, oh, I've got somebody closer.  And so anybody, any traffic coming through that router to that common IP will end up going to the shortest server.



So what this means is that an attack against the DNS root, even if the attack were - first of all, it would have to be attacking all 13 IPs.  It would have to also be attacking all of these hundreds of actual physical servers hiding behind those IPs.  And the only way to do that is to be attacking from all possible locations in the world because the only way to get to those physical servers is to be physically close to those physical servers.



Now, I have to say we don't know, no one knows truly whether it's possible to hold them all offline.  You have to attack them.  You have to flood them so much that they're not able to deliver results.  Arguably, you have to flood the links coming into them, or maybe the routers on those links, because it might be that the routers are less capable of handling a flood of small queries than the servers themselves are.  We really don't know.  But remember, caching is another aspect of DNS that DNS absolutely relies on.  These root servers are actually not very loaded most of the time because all they're being asked for is the IPs of the second-level domains, the so-called GTLDs, the .com, .net and so forth servers.  So those records in the root servers have multiday expirations, maybe even longer than that, maybe weeks.



So the point is that the only time somebody refers to them is when the .com or .net or .org, that second-level domain record that they have, expires, causing them to need to update that.  The reason those don't last forever is that allows the .com and .net and .org and so forth servers to move around if they need to, and for that cached IP address for them to ultimately expire.  But it doesn't expire immediately.



So that's a huge, that's an important distinction.  When you flood Visa or MasterCard, you're flooding one server, and you're holding that site offline immediately for the duration of the flood.  If you were able to flood these many hundreds of root DNS servers, nothing at all would happen for a while.  It would, and this is what we've talked about before, as you mentioned, Leo, it's necessary to, in order for individual and users to feel the effect, which apparently is what this - if this is Anonymous and not a bogus posting, and they're trying obviously to get end users to believe that the Internet is down, that they've taken the Internet down, the only way to have that happen is to keep all of these hundreds of actual physical DNS servers offline until the DNS cache drains.



LEO:  And that's at least a day or two.



STEVE:  Oh, many days, probably, yes.  For example, when I have needed my own IP address to be more agile, I've decreased the cache time so that I could change my IP address, and users and the Internet would have their records updated relatively quickly.  But normally you run with multiday, sometimes seven days.  Seven days is quite common.  You run with a seven-day expiration because there's just no reason for it to be any shorter.  You'd rather people got to your website quicker because, remember, if you have to do a DNS lookup, that delays access to your website until your browser is able to perform a multilevel DNS query, get the new IP, if it is new, and then access you.  But if it's not going to be new, you'd rather let your DNS record last a long time because that's going to help people get to you more quickly.  So there really is, there's an incentive for the cache being as long as practical.  And it's typically a long time.



So it is, in the first place, we really don't know today what the effect of a high-bandwidth, high-transaction rate, globally dispersed, distributed denial of service attack against those 13 IPs would be.  We know that in '07 there was a denial of service attack against the DNS root, and a few of the weaker IPs were hurt.  Several of them crashed.  Several of them were offline.  But that was, like, four out of 13.  The balance of that, the other nine, sailed through it without a single glitch because they were on strong connections with strong routers in front of them, and they themselves were strong servers.  And so we have some calibration.  And you could argue, because this is understood to be the one Achilles heel of the entire Internet because of the nature of this one focus point - that was in '07, so five years ago.  Since then, I'm sure these things are even stronger than they were.  And there's just been more growth of the Internet.  There's more root servers, more widely distributed.  I really do think we're probably okay.



But there is one very cool site that I will leave you with.  I didn't make shortcut for it.  I will create one for next week.  There's a DNS monitoring page.  If you're looking at the show notes, Leo, you can see it there at the end, "On March 31st."  It's cymru.com/monitoring/dnssumm.  That's the page.  It's a very nice real-time display that shows the health of the DNS root servers as viewed from many different locations around the globe, showing the root response time and a bunch of other information, also.  So I don't think...



LEO:  Pretty much green.  But this would be fun to go look at on March 31st, anyway, just to see.



STEVE:  Yup.  I don't think anything is probably going to happen.  And also, why March 31st?  Well, it occurs to me that's the day before...



LEO:  April Fools'.



STEVE:  ...April Fools'.  So if they were going to do it on April Fools', I mean, if they said they were going to do it on April Fools', then everyone would think - wouldn't take this very seriously.  So they did it one day before.  Maybe that's so that the 'Net will be down on the 1st?  I don't know.  But I don't even know if this is a legitimate posting.  But...



LEO:  Well, in fact, one of the Twitter accounts - the problem with being Anonymous is no one knows who's in charge.  But there is a Twitter post from yesterday saying it's a fake operation.  But who knows?  You just don't know.  That could be disinformation.



STEVE:  Yeah, it could be somebody else claiming that it's a fake.



LEO:  Yeah.  And by the way, this is nothing new.  We're not telling them anything everybody doesn't know.  There's a whole Wikipedia page devoted to how to do this, that talks a lot about it and even mentions Operation Global Blackout 2012.



STEVE:  It's already been updated.



LEO:  Yeah.



STEVE:  Yes, in order to cover this.



LEO:  And Boing Boing posted an article - all of this comes from the chatroom, thank you chatroom - that points out, probably shouldn't make too big a deal of this, but the people who would be using this Low Orbit Ion Cannon software to do this DDoS are in fact blasting their IP address out to the public, as well.  So good luck with that.



STEVE:  Yeah, they talk in their posting about a so-called "reflection attack," where they would send queries to DNS servers with a spoofed IP, a spoofed source IP, so that those DNS servers would then bounce that request to the root server.  So they would be spoofing the root server IP so that the secondary server would think that it was a root server making a query, which is bizarre because root servers would never do that.  And in fact...



LEO:  That would be an easy thing to thwart.



STEVE:  Yes.  All you would have to do is block root server queries from those 13 IPs, block those incoming, and then your server would never bounce the traffic back to the root.  And the other thing is, it's not clear what they would be asking because, as DNS drains out, then those servers would have to query the roots in order to get the addresses to query.  I mean, anyway, it's sort of convoluted, and it's chasing its tail.  It is probably unlikely anything's going to happen.  It's also really not clear how this makes sense.  Like Anonymous is pro Internet but anti some factions of the Internet, like anti-SOPA and RIAA and so forth.  So why does taking the entire 'Net down even serve their ends?  It's not clear.  Probably really don't...



LEO:  I think it's bogus, but who knows.  Certainly...



STEVE:  Yeah, but interesting topic for the show.  Interesting to consider where we are.



LEO:  Steve Gibson, I know where he is, he's at GRC.com, kids.  And that's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility, GRC.com.  It's also where you could post questions, if you've got them, and next episode will be a Q&A episode, so this would be a good time to go to GRC.com/feedback.  He also has lots of free stuff there, including 16Kb of the show and transcriptions, if you'd like to read along, and his show notes, as well.  You can also get audio and video of the show from our site, TWiT.tv, and wherever greater podcasts are offered for free.  Do get the subscription.  That way you don't miss an episode.  You can have a collection of Security Now! episodes on your system.



Let's see, what else?  Oh, we do this show every Wednesday, if we aren't talking about coffee, at 11:00 a.m. Pacific, 2:00 p.m. Eastern, at TWiT.tv.  Do tune in live.  And if you miss it, don't worry, you can always download the show, except for the coffee stuff, at the site.



STEVE:  And we might be changing our schedule for March 7th because the rumors are that that will be the iPad 3 announcement.



LEO:  You have been paying attention.  That's right.  We talked about that yesterday on MacBreak.  And so we're just waiting for the invites to go out.  And if they do, we'll just flop, flip-flop.  The Tuesday MacBreak Weekly will be on Wednesday, and you'll be on Tuesday.  But that's not next week, that's the week after, so...



STEVE:  Exactly.



LEO:  We'll know, I think we'll know by next week.  Usually Apple sends out invites about a week ahead of time.  Thank you.  Actually, you know what, next Wednesday is the day that Microsoft ships the consumer beta of Windows 8.



STEVE:  Ah.



LEO:  So that might be kind of interesting.



STEVE:  Yeah.



LEO:  We'll talk about that.  Thank you, Steve Gibson.  Thanks for joining us, everybody.  And we'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



LEO:  Bye bye.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#342

DATE:		February 29, 2012

TITLE:		Listener Feedback #138

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-342.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!. Steve Gibson is here, and we have a lot to talk about, including the missing coffee episode, why third-party cookies are bad - or are they? - and a brand new product from Yubico.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 342, recorded February 29, 2012:  Your questions, Steve's answers, #138.  It's time for Security Now! 



STEVE GIBSON:  You forgot where you were for a moment.



LEO:  No, no, I just wanted to give it a long Security Now!.  There he is, Mr. Third-Party Cookie, Steve Gibson.



STEVE:  Boy, did we stir up a hornet's nest last time.



LEO:  Oh, I bet we did.  We're doing a Q&A, so I know I'm going to hear it.  I've been hearing it all week.



STEVE:  I know, I know.



LEO:  And I think rightly so.  I just think it's a good conversation to have, and so we will have it.



STEVE:  Yes.  This was the wrong place to try to tell people that tracking wasn't a bad thing.  That didn't go over very well.



LEO:  We've been inveighing against third - you have been inveighing against third-party cookies as long as there's been such a concept.  And I still have the question, what's so bad about third-party cookies, but I'm sure you will explain in the Q&A.



STEVE:  Well, I actually have an innovation of my own that I've never seen anywhere, and I'll share it in the Miscellanea section at the top of our show today, just something that solves the problem.  And I don't know why no one has done it.  But maybe by speaking it, there'll be somebody with some influence listening.  I know that we do have influencers listening, so that would be great.



LEO:  From your mouth to the influencers' ears.  But we also have Q&A.  I only have one little commercial.  I can do it any time.  So why don't you just get into the news of the week?  How about that?



STEVE:  Okay.  I like that idea.  So - if I can find it.  Where did it go?



LEO:  I have it.  You want me - I have all your notes.



STEVE:  Here I am, waiting for you to get ready, and I'm not.



LEO:  Let's start with DNT, Do Not Track.  Actually, that was the biggest news that I was really pleased that came out of the week's news was the Obama administration threw its support behind Do Not Track.



STEVE:  Well, and more importantly, I think, Google did.  So we now have Firefox, IE, Safari, and Opera, and Google has announced they're going to support it, too.



LEO:  And they have now some governmental clout behind it, so using it will have some meaning, which is equally important.



STEVE:  Well, yes.  Everyone says, oh, well, but all that does is it just puts the DNT header in your query.  It's like, yes.  But again, let's not make the - what is it?  Let's not make perfect the enemy of...



LEO:  The good.  



STEVE:  ...the good.  And this is good.  This is to allow people to express their desire.  That's where we start.  And we'll certainly be moving forward from there.  It's the creep factor, I think.  It's the sense that companies will exploit, if they can.  And also I think it's people - you're in a position, Leo, of really understanding this very well.  So you're like, well, yeah, but - you understand the implications.  A lot of people who don't understand it, don't know the limitations of what could be done, and so they're a little more frightened by it.



LEO:  Well, and now here's a question.  Will Do Not Track be turned on by default on all these browsers?  Or will we have to know to turn it on?



STEVE:  Really good question.



LEO:  I bet not.



STEVE:  My guess is it'll be there, but not enabled.



LEO:  So now we'll have to educate people.



STEVE:  Yup.  I have the technology on my site, which I implemented back when I was doing the cookie project.  And the technology, it sounds trivial because lots of people do it, but they all do it client-side.  Mine was a server-side include of a little banner to alert visitors of things.  And it's general purpose.  And the idea would be, if somebody was poking around my site, and I noticed that they had third-party cookies enabled, I'd just give them a little notice and say, oh, by the way, you've got third-party cookies enabled.  And if you don't know what that is, click, and I'll tell you all about it.  And the idea was...



LEO:  You did something like this before, I thought.



STEVE:  Oh, I've had it for years.  I just haven't finished the darn thing.  So it's on my short list.  But I tend to get distracted by portable dog killers and ridiculous other projects.  So, yes.  So as you said, the administration is stepping up the issue of privacy.  And what's interesting also is that the big online advertising group have said they're going to comply.



LEO:  Now, they have to; right?  It's a public relations thing; isn't it.



STEVE:  Yeah, it's having some traction.



LEO:  I do fear for the future of the free and open and unpaywalled Internet at some point.  We can balance privacy and monetization, I guess.



STEVE:  Yeah, and I would love to have some numbers, or for someone to provide us with some numbers that was definitive about to what degree it really matters who we are because, remember, when you go to a site that's serving ads, that site gets revenue from advertisers by displaying the advertiser's ads, and extra revenue, of course, if you click on those ads.



LEO:  Not necessarily, by the way.  We don't charge for clicks, for instance.



STEVE:  No kidding.  Okay, so...



LEO:  And we get to charge more if we can tell advertisers more demographics of the people who are visiting.  Or, and I think this is built into the price, the advertisers themselves know, because that's really what this is all about is DoubleClick, let's say, knowing who's seeing the ad and valuing that more.  You see what I'm saying?



STEVE:  Yes.  But we don't have any quantification of that.  Because my point is that third-party cookies are the way that additional information is aggregated, but not the way the site presenting the ad is identified.  That's the referrer header that goes along with the request for the ad.  So DoubleClick, for example, knows that somebody went to TWiT.tv and is looking at one of their ads.  Now, the question is, do you actually get more money if they know something about the user?  Now, remember that they're putting ads on your site, so they know about in general your site's demographics.



LEO:  Very general.  Very general.  In fact, we don't collect that information, so they don't.



STEVE:  Well, you don't.  But that's of course what they're...



LEO:  Well, but if they are keeping third-party cookies, they might.  So that's the problem is we don't know, as a seller of ads, we don't know how that price is determined.  We can set our own price, but whether it's worth that is not - only DoubleClick knows, or whoever buys the ads.  We actually don't use DoubleClick or anything like that.  We don't do that kind of thing.



STEVE:  I saw something years ago that said the whole concept of profiling had really not succeeded, although I think that's obsolete because I think Google has raised the bar because, when you put in a search query, right then and there you're saying this is what I care about.  This is what I'm searching for.  Well, that's why Google is Google.  The size and the success they are is that their response page is able right there to show you ads that you essentially just asked for.



LEO:  Right.



STEVE:  So it's not profiling you, it's looking at your query and saying, oh, we've got some advertisers who are paying for the use of the keywords that this person is just searching on.  That kind of thing, that absolutely makes sense to me.



LEO:  All I could liken it to is adblock.  There are lots of our listeners block ads.



STEVE:  And this is very different.  Yes, adblocking...



LEO:  No, I understand, but I'm just - let me explain what I'm thinking, the analogy here.  Such a small number use adblock that we can ignore it.  We can safely ignore it.  But obviously the person who uses adblock, and many people feel it's their right to use adblock, will not see ads and is not in fact contributing to - by the way, one of the reasons we monetize by reading you ads in the middle of the show is because we completely avoid this issue.  You could skip it, but it's not automatic.  But let's say we were making money, as we plan to, by the way.  One of the ways - I told you we're developing The Tech Guy site.  It's a $100,000 project.  That is paid for by the banner ads that will be on The Tech Guy site.  So this is a relevant issue to me.  So if you use adblock, you're not paying your fair share of attention.  But fortunately, very few people use it, so it's de minimis.  If the default on the Internet suddenly became adblock, we would have to do business very differently.



STEVE:  Yes, everything would change.



LEO:  Everything would change.  So that's why the choice of defaults on third-party cookies might well be relevant.  Again, we don't have the information to know.  And we should get that information.



STEVE:  Would be nice to know.  I know that Mark Thompson has a good friend whose site is SnapFiles, a really nice, high-quality, file-downloading site.  And it's entirely run by - it's entirely financed by ads.  The guy is making himself a fantastic living.  And because the site has done so well, it's the only thing he has to do.  And so he's able to spend a disproportionate amount of time actually looking at the freeware that he's posting, himself evaluating it, writing things up.  Essentially, it absolutely closes the loop.  The fact that he's displaying ads, advertisers are paying him for that display, the site is popular enough and so forth, I mean, it really does work.  And so the question is, does it matter if the people who go there and see the ads are also being tracked?



LEO:  Well, let's say he makes more money if they are than he doesn't.  Who has the right to say how much money he makes?  I think that there's this perception about that, oh, well, he shouldn't have to make that much, he shouldn't need that much money, he should just make what he can make without tracking.  But that's not a decision for - that's a conversation we all need to have.



STEVE:  I always hail from a technical standpoint.  And tracking is a mistake.  This is a glitch.  This was never supposed to happen.  This is not why cookies were created, to allow advertisers to track people.  Because the idea of a cookie is for you to have a relationship with the site you're visiting and allow it to maintain some state with you because you otherwise have a stateless relationship.  And it was when this concept of a third party hosting content on the first party's site, when that happened, the advertisers realized, oh, hey, we're having cookies happening here.



And then, when that central repository of ads began being hosted on all these sites on the Internet, then that glued people together.  It was that DoubleClick was a large advertiser who was providing third-party content across the Internet.  Suddenly they were getting back cookies from people that they've given them to on other sites in the future.  So that's where this whole concept of profiling users came from.  I mean, this is not what cookies were for.  And that's of course why browsers have allowed you to turn them off is it was recognized, wait a minute, there's a privacy concern here.  So...



LEO:  I don't think there's a privacy concern at all, but okay.  I think that that's kind of just the default, hey, it's a privacy issue.



STEVE:  I would argue that, if someone goes to a Philharmonic website because they're planning to be in New York the next week, and browses around, but clicks nothing, then gets a phone call from the Philharmonics telemarketing company saying, hi, we noticed you were just over on the website and wanted to make sure you knew of some special offers we have coming up, I would consider that a privacy concern.



LEO:  It is.  But the concern is not from cookies.  That didn't happen because of cookies.  That happened because he gave his phone number to somebody who then revealed it to a marketing company.  They were able to perhaps get that phone number from somebody other than the Philharmonic site.  That's not clear.  But the privacy issue is not the cookie.  The privacy issue is somebody gave that phone number to the marketer; right?



STEVE:  The privacy issue is aggregation.



LEO:  Yeah, but at some point he gave his phone number to somebody; yes?  Somebody he trusted.  They didn't get the phone number out of thin air.  They got it from somebody he gave it to.  Is that not right?



STEVE:  Correct, on some other website somewhere.



LEO:  That's the privacy violation.  Not the cookies.



STEVE:  So if he had third-party cookies disabled, they would not have been able to call him.  That's my point.



LEO:  Well, they wouldn't have known he went to the Philharmonic site perhaps, unless it was the Philharmonic that gave them the phone number, that he gave the phone number to the Philharmonic.  The issue is that he gave the phone number to somebody other than the Philharmonic, visits the Philharmonic site, and then the Philharmonic's able to call him because that other site gave the phone number up.  That's the privacy flaw.  Otherwise, the only thing that's passed around is he was at this site.



STEVE:  People don't want to be tracked on the Internet.  They don't.  They don't want to be tracked.



LEO:  Well, I think that they have to rethink that because they also want a lot of free stuff on the Internet.  And I think that there's a real risk here that what - I understand what they're saying.  I understand what you're saying.  But I also think you need to understand that you're getting - I think people don't make the connection to all the free stuff they're getting on the Internet and advertising.  That's how it's paid for.  



STEVE:  Right.  And I am 100...



LEO:  You are risking undercutting all the free content you get on the Internet.  You get a ton of it.  Most of it.



STEVE:  We don't know that, though.  I 100 percent agree with you about adblocking.  Adblocking says I want the page scraped of ads and see the content.  And I completely agree with you there.  But that's completely different from tracking, from knowing who I am on two different sites that I visit, and having a third-party be able to glue that together and establish a profile.



LEO:  Well, again, to me it seems like the profile only contains information that these other sites give up.  And if they're giving up your personal information, your quarrel is with those sites.  Yes?



STEVE:  Certainly that's not good, but that gets...



LEO:  Yeah.  So somebody - I gave my phone number to somebody, and somebody gave that phone number to DoubleClick, and then DoubleClick put the two together.  But I really need to be mad at the person who gave my phone number to DoubleClick.  Yes?



STEVE:  That's one part, Leo.  Part 2 is, if I'm somewhere else, I don't want to be known as that same person who lost his information somewhere else.



LEO:  You may or may not.  And I agree that...



STEVE:  The cross-domain tracking, that's...



LEO:  I agree that you should have the chance to turn that off.  I'm not saying you shouldn't have the option to turn that off.  However, I'm saying if it becomes a widespread option on the Internet, Do Not Track, it becomes the default option on the Internet, there may be surprising consequences.  You'll see a lot more paywalls, let me put it that way.



STEVE:  I think it's a little bit like what we experienced when I first discovered the first spyware and coined that term.  And that is, users were furious that this had been done without their knowledge...



LEO:  That I agree with.



STEVE:  ...and consent.  And this is consent-free tracking.  No one asks people if they want to consent to this.  And so that's certainly a factor here, too.



LEO:  Well, you go on the Internet.  Do you not believe that you are tracked on the Internet?  Do you not think that every site you go to keeps track of your IP address?  Do you not think your IP addresses and all the sites visited are preserved by the Internet service provider?  I mean, you're going on the Internet.  Of course you're being tracked.



STEVE:  Okay.



LEO:  And you're using free services.  I mean, I agree, I completely understand, and I agree that you should have the right to turn this off.  But I think that - and I think you have the right to use adblockers, by the way.  I don't think adblockers should be banned.  But I just think that you also should consider the fact that some of this is paying for the stuff that you enjoy so much on the Internet, including my content.



STEVE:  And it would be nice if...



LEO:  And I don't think people want me to start charging you for content.



STEVE:  It would be nice if we knew whether tracking mattered there, and/or to what degree.  We just don't know.



LEO:  Well, it doesn't matter if somebody doesn't give my phone number to DoubleClick.  It does matter a lot if they aggregate a lot, my credit cards and phone numbers, and then that information is shared all around.  That of course  matters.  But that to me is the flaw, not the tracking cookie.



STEVE:  What people - it's the gluing it together.  What people in the industry have said is that we would be stunned if we knew how much data was being collected about us.  And so it's like...



LEO:  All the time, by walking around, yes.  I agree.  Not just the Internet.  We know this.  That's how marketers work.  That's how Kmart - I'm sorry, Target.  You read that Target article.  That's how it works.



STEVE:  And all of the little supermarket...



LEO:  That's how they work.  It's like saying I want a supermarket card - and by the way, Dvorak does this - I want a supermarket card, I want the deals of the supermarket card, just don't track me.  It's a little bit more of an explicit relationship.  It's obvious, I think, when you buy a supermarket card, that you're giving them all that information, including your phone number, everything you put on that form, matched to the products.  That information is being shared with all the companies.  I think you know that; right?  But you do it because you get a deal on the food.  So that's a much more explicit transaction.  I just think we need to understand these implicit transactions that are happening on the web, that there is a reason for them.  It's not people trying to see what you're up to.  I mean, it really isn't.  They don't care what you're up to.



STEVE:  Well, the theory is that, if you are profiled, then the advertisers can deliver more relevant ads, and that therefore the impressions are more valuable to you and to the advertiser.



LEO:  Right.  That's right.  We don't disagree on this.  And believe it or not, I think people don't completely - there's this kneejerk reaction, cookies are bad.  You have to admit there's this kneejerk reaction, cookies are bad, and third-party cookies are worse.  And I know lots of people delete their cookies routinely.  And I think it's because they don't really understand what's going on here.



STEVE:  Well, and Firefox has an option of flush third-party cookies on termination.



LEO:  Every browser does.  Anyway, I don't care.  Go ahead.  It's much longer of a conversation about this than it deserved.  It apologize.



STEVE:  Okay.  So there's another controversy.  And that is that Google, Microsoft, and Netflix are attempting to add DRM to HTML5.  And the Mozilla people who are looking at this evolving HTML5 spec have been quoted as saying they think this is unethical.  And Ars Technica reported on it, and the W3C has a spec and the working notes.  And one of the things that they have asked is can an open source browser do DRM?  To which the Netflix representative said, well, it's been the case in the past that open source software has included closed source modules, and/or maybe some hardware somewhere would actually be doing the decryption.



I was curious about where this thing went because, I mean, we know it's impossible.  I mean, we absolutely know you cannot actually protect content.  But Netflix's - Netflix - yeah, I said that right, Netflix's position is they would like - their content providers require them to protect the content that they're offering.  And so traditionally they've used third-party tools or Flash or Silverlight or something that did offer that kind of protection.



Well, as we're seeing Flash ebbing from the 'Net, and HTML5 is now becoming the solution, that and JavaScript, to glue together the capabilities, they're saying, hey, we'd like to be able to deliver protected content just to the browser without needing a third-party plug-in in order to provide that protection.  So standing back from it, as we often said, if you're going to display unencrypted video on a person's screen, it can't be protected.  I mean, the technology doesn't exist.  It has to be decrypted in order to show it.



I have less of a kneejerk to this after really looking into it than the Mozilla people do, and I think they're sort of taking the ivory tower position because, in fact, what Microsoft, Google, and Netflix are asking for are just some hooks.  They're asking to expand the media-handling API, the media-handling features, to provide the hooks that would allow JavaScript to request decryption keys and provide those to a decryption module.  And those things are just sort of black boxes, not defined.  They just want to get that into the spec.



And so my sense is, well, yeah, I can understand this.  As a person who sort of really doesn't like having big, bloated plug-ins added to my browser, and loves the idea of things being kept simple, I like the idea of, if I want to watch something from Netflix, that I don't have to have a plug-in in order to do it, to provide the DRM as an add-on, but the browser can be enhanced with that at some point in the future.  So what do you think?



LEO:  Yeah.  Oh, yeah.  I mean, look.  You're not going to get movies without DRM.



STEVE:  Right.



LEO:  So good luck.  One of the reasons Netflix wasn't on Android for a long time is because they didn't feel they could protect the movies.



STEVE:  Right.



LEO:  We could argue about whether DRM's necessary.  I don't think it is.  But it's just the fact of the matter, if you don't support DRM, you're not going to get movies.



STEVE:  Right.  So big news from the Eleventh Circuit Court of Appeals.  And happy news for us.  I want to read just the beginning of the appeal and then the decision because it actually refers to TrueCrypt.  And I think exactly what was said and how it was said will be of great interest to our listeners.  The document reads - this is an appeal of a judgment of civil contempt.  "On April 7, 2011, John Doe was served with a subpoena duces tecum" - some legal term, a subpoena - "requiring him to appear before a Northern District of Florida grand jury and produce the unencrypted contents located on the hard drives of Doe's laptop computers and five external hard drives.  Doe informed the United States attorney for the Northern District of Florida that, when he appeared before the grand jury, he would invoke his Fifth Amendment privilege against self-incrimination and refuse to comply with the subpoena.



"Because the government considered Doe's compliance with the subpoena necessary to the public interest, the attorney general exercised his authority under Title 18 USC, authorized the U.S. attorney to the apply to the district court, pursuant to Title 18, for an order that would grant Doe immunity and require him to respond to the subpoena.  On April 19, the U.S. attorney and Doe appeared before the district court.  The U.S. attorney requested that the court grant Doe immunity limited to 'the use of Doe's act of production of the encrypted contents of the hard drive.'  That is, Doe's immunity would not extend to the government's derivative use of contents of the drives as evidence against him in a criminal prosecution."



So basically what they were saying was we will give you immunity for unencrypting your drive, but then whatever we do with the contents is still ours to pursue independently.  So again he refuses.  So this ends up being appealed, and the Eleventh Circuit just found that the Fifth Amendment right against self-incrimination does protect us against being forced to decrypt hard drive contents.  They wrote:  



"We hold that the act of Doe's decryption and production of the contents of the hard drives would sufficiently implicate the Fifth Amendment privilege.  We reach this holding by concluding that (1) Doe's decryption and production of the contents of the drives would be testimonial, not merely a physical act; and (2) the explicit and implicit factual communications associated with the decryption and production are not foregone conclusions.



"First, the decryption and production of the hard drives would require the use of the contents of Doe's mind...." This is what you and I were talking about before a couple weeks ago when this was still circulating around, and we weren't sure how it was going to come out, Leo.  So it would "use the contents of Doe's mind and could not be fairly characterized as a physical act that would be nontestimonial in nature.  We conclude that the decryption and production would be tantamount to testimony by Doe of his knowledge of the existence and location of potentially incriminating files; of his possession, control, and access to the encrypted portions of the drives; and of his capability to decrypt the files.



"We are unpersuaded by the Government's derivation of the key/combination [lock] analogy in arguing that Doe's production of the unencrypted files would be nothing more than a physical nontestimonial transfer."  Where in the past it's been argued that the government could have the combination to a safe, for example, or the keys.  "The Government attempts to avoid the analogy by arguing that it does not seek the combination or the key, but rather the contents.  This argument badly misses the mark."  And then they quote some case law.



And they finally talk about TrueCrypt:  "To be fair, the Government has shown that the combined storage space of the drives could contain files that number well into the millions.  And the Government has also shown that the drives are encrypted.  The Government has not shown, however, that the drives actually contain any files, nor has it shown which of the estimated twenty million files the drives are capable of holding may prove useful.  The Government has emphasized at every stage of the proceedings in this case that the forensic analysis showed random characters.  But random characters are not files; because the TrueCrypt program displays random characters if there are files and if there is empty space, we simply do not know what, if anything, was hidden based on the facts before us.  It is not enough for the Government to argue that the encrypted drives are capable of storing vast amounts of data, some of which may be incriminating.



"In short, the Government physically possesses the media devices, but it does not know what, if anything, is held on the encrypted drives.  Along the same lines, we are not persuaded by the suggestion that simply because the devices were encrypted necessarily means that Doe was trying to hide something.  Just as a vault is capable of storing mountains of incriminating documents, that alone does not mean that it does contain incriminating documents, or anything at all."



So that's the upshot of that, which is good news for people who want the right to keep their stuff private and have the Fifth Amendment protect them from self-incrimination.



LEO:  Yeah, we covered a little bit of this on This Week in Law, if people want to know more.  It's very interesting.



STEVE:  Oh, cool.



LEO:  And TWiT, as well, yeah.



STEVE:  So Yubico yesterday released a new form factor for their famous YubiKey, and it's very cool.  They call it the "Nano," and it is essentially just the USB plug portion that would go into and disappear into the USB slot with a little bit of an arced metal contact and a light that can be seen.  So the idea is that this is - it's sort of like a semi-portable Trusted Platform Module.  We've talked about...



LEO:  You're going to lose this, though.



STEVE:  Yeah.  Well, exactly.



LEO:  It's to be put in something else; right?



STEVE:  Well, yeah.  It's to be put into - the idea would be, everyone's running around with laptops now.  This would be a...



LEO:  Oh, just leave it in there.



STEVE:  Exactly.  You stick it in, and it just lives in the USB slot.  And people who have seen this have said, well, wait a minute, that's not really multifactor because...



LEO:  It's permanent.



STEVE:  It's permanent.  But it authenticates the device, which is really nice.  I mean, for example, I came up with that very fancy system using cookies, secure HTTPS-flagged cookies, in order to allow my employees to access the GRC data when they were roaming.  And the idea was they had to have their laptop at home with their home IP that GRC recognizes.  Then when they use the laptop to open a protected page on GRC, it says, hey, you don't have a permission cookie, do you want to get one?  So then I give them this permission cookie, which then identifies the laptop.  Then when they're subsequently roaming, and it sees a query come in carrying that encrypted protected cookie, then along with them identifying themselves using the Perfect Paper Password system - and in fact I think maybe that's why I designed the Perfect Paper Password system was for this purpose, because I wanted something like a one-time token, and I also wanted their access to be locked to their laptop so that they wouldn't be tempted to just log in from some friend's computer because there's just - I'm not convinced there's a safe way to do that.  So I wish there was some simple, clean way of authenticating that laptop.  And this provides that.



You would still have them provide - first of all, it'll identify itself.  And you of course touch the contact in order to send a one-time password for further identification.  And then for multifactor you'd still pop up and prompt them for a password.  And only if all of that works as a whole do you then say, oh, welcome, and give them what they want.



The other cool thing is that this is the v2.2 of the YubiKey technology, which has added a full FIPS standard/challenge response mode, which is to say it can have a secret which it never reveals.  And rather than merely sending out a one-time password every time you touch it, it can be challenged purely through software and generate a response.  So that, for example, you can use it to authenticate a submission.  You put together a bunch of information, and you press the Submit button.  Well, that information is run through the YubiKey.  It generates essentially a signature which it sends off with the information, and that's able to authenticate what was submitted.



And in fact the well-known free and open source Password Safe technology now supports the YubiKey, not just this little guy, but all of the v2.2 YubiKeys using this challenge/response system.  So you stick your YubiKey in your computer, and it now identifies itself while you're using Password Safe, which is over on SourceForge, a nice multiplatform solution.  And Password Safe is able essentially to ping the YubiKey whenever it wants to and as many times as it wants to to verify that it's there and that you are who you are saying you are.  And then you're also able to configure it so that you have to touch the little YubiKey contact if you want to set it up that way.



So anyway, I'm really happy.  They're moving forward on this authentication technology.  And I think the idea of being able to sneak one of these, just sort of slip it into a USB socket to provide some authentication for the laptop itself, is cool.  And I might still use a YubiKey in a different USB socket in order to authenticate me separate from that.  So, very neat.



And, boy, I hesitate to open this up again, but I did want to say that one of the solutions that I had always had and been thinking about for third-party cookies is just to associate the third-party cookies with the first-party site.  I had this in my notes, so I wanted to mention it, and that is...



LEO:  It's true.  If Google hadn't used DoubleClick as the originating site, but had instead used Google as the originating site, none of this would have happened.



STEVE:  Correct.  Correct.



LEO:  So it's that second originating site that confuses the issue.



STEVE:  Yes.  And my thought was, people have said, well, if you disable third-party cookies, some add-ins on sites no longer work.  And that is the case.  Facebook apps are running on your Facebook page.  They're inherently a third-party app, and they need a cookie in order to provide the same, not tracking, but the same sort of stateful connection to the user that the first-party cookie provides to websites.  Because I'm certainly with you, Leo, cookies are not themselves inherently evil.  Nothing works if you disable all cookies.  I mean, almost nothing anymore.



LEO:  Well, the only thing we disagree on is how dangerous third-party cookies are.



STEVE:  Correct, correct.  Yes.  And so one thought is that, if third-party cookies were tethered to the first-party site where you were when you got them, then everybody's happy.  Then you're able to accept third-party cookies.  Third parties are able to associate with you, yet they're not able to track you to follow you as you go to other sites on the Internet.  When you go to those sites, because your cookies would be in a jar essentially, and I coined the term "cookie jars" for this, then that other site would provide third-party content, and you'd have a third-party cookie for it.  But it would not be the same third-party cookie because you were on a different first-party site.  And that means that third parties are able to associate with you, no apps break, yet no one needs to worry about being tracked from site to site.  So sort of it's a nice compromise.



I also wanted to say, as I was going through the mailbag, so many people said, hey, Steve, you can solve the Perfect Posthumous Passwords problem, which we've talked about, what happens if I die, how can I give access to people I care about.  I was really impressed with how many people said LastPass, just use LastPass's one-time password.  It'll generate some.  You put them somewhere safe.  And if anyone else ever needs to access your LastPass logins, they're able to do that using your first-party cookies, so I just wanted to - or using your one-time password.  So I just wanted to shout out to everyone who also thought of that.



And a very brief Honor Harrington update.  I thought I was off the hook when I finished Book 11, Leo.



LEO:  Now, tell me the truth.  Did you breathe a sigh of relief?  Or were you sad?



STEVE:  Well...



LEO:  When you say "off the hook," it sounds like you were glad.



STEVE:  Oh, my god, 11 books.



LEO:  That's quite a commitment.



STEVE:  Yeah.  It really did bog down sort of like two thirds of the way through this first 11.  I mean, he's built a huge universe.  You learn all this about all these people.  David Weber, the author, clearly is interested in politics, so it's very much star system politics and bad actors and good actors.  So it's like, okay.  And, I mean, I was enjoying the battles that just seemed very clean and interesting and fun.  And there weren't a lot of battles there around two thirds through the series.  However, I have to say that Book 12 has started off, and I'm immediately gripped by it, and not a shot has been fired.  So I realize that I bought this series hook, line, and sinker.  It's a major investment, as you say, in time.  I'm ready to be done, but now I have to find out what's going to happen.



LEO:  Now you know why I didn't start.  Okay.



STEVE:  Ah, yes.



LEO:  Now 12, a dozen.  But more to come, you think?  I mean, is this it?



STEVE:  Yes, yes, there's 13 and 14.  13 is supposed to be tomorrow, well, tomorrow's month, supposed to be in March sometime is No. 13.  And then I think there are a couple more in the arc.  And we are going to get movies, so people who just don't have any interest can just wait.  It's going to be a few years, I'm sure.  But you can see the movie.



LEO:  So long as it's not Angelina Jolie's leg, I don't mind.



STEVE:  That was quite a leg.



LEO:  Starring as Honor Harrington.



STEVE:  Oh, yeah.  So Al sent me, from the U.K., just a short note reporting his success with SpinRite, which allowed his external hard drive to be imaged.  He said, "Steve, thanks for the useful podcast that you do with Leo.  I really love the show and methodical detail for each topic, right down into the ones and zeroes of computers and security.  This is just my simple SpinRite story.  I purchased it so that, if anything did go wrong, I'd have it to save me.  I've experienced the gut-wrenching feeling of having a drive which is broken, and at least with SpinRite nearby I can feel calm that it can often fix the situation.



"I like using MS Flight Simulator to fly different planes and have it installed on an external USB Iomega hard drive.  After a few minutes of playing, the drive becomes pretty hot, and I know that heat is not too good for a drive.  Nevertheless, it seemed to keep working many times, so I thought that probably the heat may not be so bad.  I don't know what the max temp is to run the drives so that they have a long life.  Then one day I thought that I should make a backup image [audio dropout] because I have so [audio dropout] and in case the drive failed.  I used Acronis TI, or Acronis, I guess, TI...



LEO:  Acronis, yeah.



STEVE:  Acronis, to do this.  But it told me it could not make the backup because there was a problem with the drive.  I guessed that it might be damaged sectors, so I ran SpinRite over it, and it fixed one sector, and then the drive worked completely perfectly again.  I tried using a fan blowing air over the external drive while I played the sim, and it seems to keep it much cooler.  Maybe that will give it a longer life.  Thanks very much for your great product."  So thank you, Al, for our report.



LEO:  I just have this vision of him with his computer open and a big fan blowing on it.



STEVE:  And I have to say, Leo, in my own experience with hard drives, it's very surprising how much cooler drives will run with air.



LEO:  Oh, yeah.  Keep them cool.



STEVE:  It's not only keep them cool.  But, I mean, I just had - just like sometimes I'll put a heat sink on the drive, like a heat sink with fins, and then blow the air across the fins.  The drive almost feels like it's below room temperature, I mean like cold cold, cold to the touch.  So by all means, I endorse the idea of air flow across drives.  That just makes them happy.



LEO:  Well, and a well-designed case will do that.  It's a little tougher in a laptop, of course.



STEVE:  Well, and many external cases, I think, really don't...



LEO:  Yeah, they're tight.



STEVE:  Yup.  They want to make them small.  And if they're small, you can't get much air through there.



LEO:  Are you ready now, my friend, for some questions and answers?



STEVE:  Absolutely.  We've got some good ones.



LEO:  You've got the answers; I've got the questions, starting with Jean-Matthieu Bourgeot in Tarare, France, who also loves coffee, apparently:  In the last episode of Security Now! you mentioned you and Leo had been speaking about coffee for 30 minutes before the show.  Has this discussion been recorded anywhere?  I would be greatly interested to listen to it.  We've got to do a coffee podcast.  The demand.  I'm sure many other listeners would love to hear it, as well.  Along those lines, why not do a special episode about the health benefits of drinking coffee, as you did for Vitamin D.  Over the years you have been and continue to be a great inspiration to me in my work and a real plus in continuing my tech education.  Thanks so much, Jean-Matthieu.  Thank you, Jean, for listening.



STEVE:  So this caught my eye because I was very - I won't say I was surprised.  But Leo, well, I asked you before we began recording, was our discussion somewhere captured?  Because if it could just be stuck on YouTube somewhere, I know that it will get a chunk of our listenership interested in what it was you and I were talking about.  So if anyone can find it, or if they have it or something, that would be great.



LEO:  Well, that's a good question.  If you go to Justin.tv, anytime we don't record a show, Justin.tv does.  That's, by the way, a very handy thing, as it turns out, whenever I forget.  Now I'm getting - look at that, I'm getting ads.  How dare they.  So if you go to Justin.tv and search for TWiT, we have a - you can watch our live broadcast, obviously.  But what happens with Justin.tv is they record everything as it happens, and I think they do it in chunks.  I'm not sure.  How big are the chunks?  They used to be two hours.  I think they're longer.  So you can go back to last week and get - I think we talked from 11:00 to 11:30 Pacific.  So you should be able to on here, I'm told, I've never done this, but go back to our recording of seven days ago and catch it.  Let me just, you know, let's - I don't know.  I don't see it here.  It should be here.  They're days in length now?  Ah, that's what they changed.  They used to do it in chunks.



STEVE:  Wow.



LEO:  But now they do it in bigger lengths.  So one of our chatters has posted this link.  Oh, boy. 



STEVE:  Big link?



LEO:  Let me click this.  Well...



STEVE:  We need to bit.ly it.



LEO:  It's Justin.tv/twit/b/309424801, if that helps in any way.  And I guess they said if you go into this 38 minutes in - is that what they said?  Something like that - you will find our conversation.  So let's jump ahead.  Yeah.  No, wait a minute, that's the Tech Guy Show.  So I don't know if this is - one of the things Google Analytics will tell you - I don't know.  As you can see, everything is recorded.  Everything is recorded that we do on this network.  And I don't know, this looks like Saturday.  So I'll have to go to a different link.  I'll leave it to you.



STEVE:  So it's there somewhere.  Maybe someone will find it and sort it out.



LEO:  If you're in the chatroom, you've got it.  66:28 in, they said.  All right, let me look.  I'm clicking the link, and I'm going to go 66:28 in.  66:28 in.  Let's see.  Let's see if it worked.  Oh, yeah, look.



[Begin clip]



STEVE:  ...focus point of the Internet.  I mean, we all need DNS in order to resolve...



[End clip]



LEO:  That sounds like the regular Security Now!.  No, it's in there.  No, they're wrong.  I don't know why they said that, but that's wrong.  So what you need to find is the raw - is not a repeat.  Anyway, I leave it as an exercise to the viewer.  And I apologize, but this is a security show, and we just really didn't think that you all wanted a show that was half an hour of coffee.



STEVE:  Well, actually you and I, we establish our Skype connection and then sort of chat a little as you're pushing buttons and getting monitors and cameras and things arranged.



LEO:  Somebody needs to watch live, if you care about that stuff.



STEVE:  And we just sort of stumbled into a discussion, since I had invested all this recent time and energy in coming up with the perfect cup of coffee.



LEO:  I can guarantee you, had we put that in the show, we would have gotten far more emails saying how dare you, it's a security show, stop talking about coffee.



STEVE:  Among the people who really expressed an interest, there was one grumbly person who said...



LEO:  There's no reason to grumble.



STEVE:  ...oh, my god, don't.  Don't, don't, don't.



LEO:  We didn't put it in the show.



STEVE:  Okay.



LEO:  And I'm not doing a special just for a half-hour of pre-show.  My advice to everyone is watch live.  That's all I'm going to say.  We are working on it.  I think this will be soon because I understand that one of the arguments against watching live is if you're not in a U.S. time zone, it's ridiculous.  You can't watch live, you're from Australia, one of our viewers, and he's fast asleep when we're doing the show.  But here's what we're going to do in response to that because this is going to kill a couple of birds with one stone.  We are - I don't know why it's taking so long, but we're working on a way of just recording the whole day, from the moment I start to the moment the last show ends, and then flipping it, and the reruns are that day again and again.  So you can watch, in your time zone, you just start watching whenever you want, you watch for eight hours, you'll get all new stuff, and then you can go to bed again.  How's that sound?  Right now we don't do reruns - we do reruns of the edited shows.  So you would have never seen that coffee stuff in the rerun.



STEVE:  So you'll take the eight hours and then duplicate it eight hours and eight hours to fill up a full 24.



LEO:  Yes, exactly.



STEVE:  That's brilliant.  That's wonderful.



LEO:  That way, yeah, I thought about that a while ago, and it's just hard to implement.  I guess we're having difficulty finding something that can record eight hours nonstop.  I think we have something, but my engineers won't let me use it.  They say the world will end.



Keith Rollin in Sunnyvale, California wonders, what's wrong with 2048 bits?  Steve, on Security Now! 340 listener Craig indicated he thought that 1024-bit public keys should be secure enough.  Perhaps I imagined this, but it seemed like he didn't like the idea of soon being moved over to 2048.  Well, so what?  What's wrong with 2048-bit keys?  Why not use them, given they're more secure?  Ever since I read "Cryptonomicon" I've used 4096-bit keys whenever I could.  Am I doing myself a disservice by doing so?  Should I strive for some balance between more security and fewer bits?



Thanks for a great podcast.  I commute 15 seconds - this is not a typo - 15 seconds every day from my bed to my computer, and I couldn't do it without listening to Security Now!.  It takes him a year to listen to one show, but - that's very funny.  Thank you, Keith.  It's a good point.  Why not just use all the bits you can?



STEVE:  Yes.  It's because they do not come without some cost, Leo.  When we double the length from 1024 to 2048, we much more than double the computation required.  It's a minimum of five and as much as 30 times more computationally burdensome to have 2048-bit asymmetric keys than 1024.  So one of the things that's been sort of holding people back is already, as we know, people have been leery about the processing overhead of dealing with setting up SSL connections.  It's historically the reason that websites bounced people into an HTTPS session only while they were logging in, and then bounced them back to a nonsecure session, the belief being that it was only during that period of time when they were actually providing their credentials that there was any need to protect their communications.



Now we know, of course, that the token that they were given went to create a session when they were logging on.  Then that's going to be available in the clear.  And that's what things like Firesheep were able to grab in order to impersonate people.  So we know that we're moving more towards HTTPS all the time, SSL everywhere.  I mean, that seems to be the future because it's going to solve these problems.  But what's been making people in big data centers nervous is that means every single TCP connection is going to have to do this SSL negotiation.  Google's been looking at it because they see this as slowing things down.



The good news is that SSL, as it's been more robustly implemented, allows the credential that is once negotiated to be reused.  And so that goes a long way towards solving the problem.  And next week I'm finally going to catch up with my commitments about shows that we're going to do and discuss the SPDY, the so-called "speedy" protocol.  I keep getting people asking me, both through Twitter and in the mailbag, hey, Steve, when are you going to tell us about SPDY, which is Google's tweak to HTTP, specifically to address these sorts of issues.  So we did the show on TCP and why TCP connections are expensive due to the need to throttle bandwidth, and that was sort of a preamble for being able to discuss SPDY and what Google has done in order to further improve the performance of the web.  And I'm really happy with this R&D arm that Google has that's making this stuff go better.



But bottom line is 2048-bit keys are much more computationally intensive.  On the other hand, the computing power in our machines is still going up exponentially.  Now we're in multicores and multichip multicores and huge on-chip caches.  So I don't think it's really going to be a problem.  And it's certainly good to have the security.



LEO:  Indeed.  Let's see, next question.  Question 4, is that right?  Did I skip 3?  Where's 3?  Where did 3 go?  Here's 3.  David Jones.  Oh, by the way, sad moment.  Davy Jones passed away, the lead singer of the Monkees, at 66 today.  He had a heart attack.



STEVE:  Wow, too young.



LEO:  Too young.  Way too young.  But another David Jones, this one in Aurora, Illinois, and presumably still with us, says:  Anonymous brings DNS down?  So what?  Steve, let's say someone does figure out a way to actually bring the root DNS servers down, as we talked about - this was last week's episode.  I can't imagine that the major search engine databases don't have the IP of the sites they have indexed in their respective entries.  Couldn't Google and Bing simply tweak a line of code to put the IP addresses in the links in the results page, instead of the domain name?  Oh, that's interesting.



So if you can't remember where a site is, just search for it.  And then click the link, and it would go to the IP address.  Back in the old WebCrawler days there were lots of sites that didn't even have domain names.  Then all you would need to know is Google's IP address.  You would need that, wouldn't you.  And you could still get to all of your favorite sites, as long as those sites don't change their IPs during the outage.  Which I would think would be a pretty low priority project if there's a major attack on DNS going on.  Let's not change the IP address today.



Non-web-based Internet services such as email or other apps might not have a way around these theoretical problems.  I don't know enough about the guts of those services to know.  Couldn't the rest of the planet's DNS servers just change a quick setting to ignore all DNS entry expirations until it's over?  Am I missing something?  That's one our most popular phrases, in almost all the email you get.  "Am I missing something?"  Thank you so much for the podcast.  Loving them since Episode 1.  Have a great day.  Longtime listener and SpinRite evangelist, David Jones, Aurora, Illinois, the City of Lights.  P.S.:  How's the Vitamin D working for you?  Any updates?



STEVE:  Okay.  So technically David's right.  But WebCrawler days?  Come on.  Yeah.



LEO:  We've come a long way, baby.



STEVE:  Now, the problem is that a web page doesn't look like it used to look in the WebCrawler days, where it was just Times Roman text pouring down.



LEO:  Static, right.



STEVE:  Exactly.  We know that contemporary web pages are full of other URLs with domain names going back out and causing our browser to load all those resources.  For example, many sites now just don't run without JavaScript, as we know.  And the page, each individual web page, at the top of the web page typically, sometimes at the bottom, calls out the JavaScript that it needs from the server, or from a server, maybe even a different server.  In fact, many times it is.  You'll see JavaScript libraries being pulled, for example, from Google or other locations.



LEO:  Oh, yeah.  Oh, yeah, all the time.



STEVE:  A jQuery, for example.



LEO:  Right.



STEVE:  Some people don't keep their own local copy, they just always go get the latest one.  So the problem is you might put the IP address of the main site you're going to into your browser and bring up some skeleton of a page.  But, boy, you wouldn't be using the Internet in that case.



LEO:  Images are often from a different server.  I think you do that, don't you, on your page, have a separate image server?



STEVE:  For a time I did, yes.



LEO:  We have a separate MySQL server.  So, I mean, in many cases, yeah, your page would break.



STEVE:  And media stuff is coming - I have media.grc.com is where all of the podcast audio is stored, and video stuff.



LEO:  I suppose you could, in your bookmarks, you could, instead of having a URL in your bookmark, you could put an IP address.  If you thought this was going to happen.  Was it March 31st was the day? 



STEVE:  March 31st, the day before April Fools Day, is when the claim was, although it's been disavowed by Anonymous folks, the claim that this was going to happen.  And, I mean, also to David's point, there is no mechanism for suddenly making all DNS servers stop expiring their records.  But that would work, too.  But the problem is we have to have some assumptions, and we have to have some foundation.  And the founding assumption is we have DNS.  And the DNS system is diverse and spread across the globe and well wired up, and we're increasing the security of it all the time.  Everyone takes the need for DNS very seriously.  And it seems to me that focusing on keeping DNS up makes more sense than lots of little tricks to deal with what happens if it goes down.



So it certainly would be the case that an individual who was worried about this could start, could build their own DNS cache, start statically recording the IPs of all the DNS lookups their system does, and if there was ever a problem with all external DNS servers, just switch over to his own private cache of DNS names and IPs.  That would work.  Sort of like a big hosts file, which is exactly what that was used for once upon a time.  So that's sort of a way of - on the other hand, you'd be sort of lonely on the Internet because you'd probably be there all by yourself.



LEO:  Just be you.



STEVE:  Oh, and Vitamin D.  I haven't been sick for the last several years, and I get email from people from time to time pointing out articles on Vitamin D.  It's by some weird coincidence that, if I had to have picked one thing to recommend to our listeners, even today, although my research has continued and is continuing for many years since, if I had to choose one supplement, I would choose Vitamin D over everything else.



LEO:  I'm getting mine out right now.  I forgot to take it today.



STEVE:  And all of the research says - I will mention one thing, though, and that is that I finally saw a paper which showed the measured blood level of Vitamin D correlated with the amount of international units of Vitamin D taken by people per day.  And so it was a scatter chart that had a series of vertical lines where the horizontal axis was the amount of Vitamin D being taken.  So the reason these lines were vertical is that Vitamin D was being taken in increments, like 1,000 IU, 2,000 IU, 5,000 IU, 15,000, 20,000, so forth.  So thus they were vertical lines.



But what really stood out in my mind was the degree of scatter of measured blood levels at any given daily dosage of Vitamin D.  Some people really don't need any.  Some people really need a lot.  And it is a potent hormone.  If you were to take 100,000 IU every day for a few months, that would damage you.  You do not want to do that.  But on the other hand, apparently if you drink endlessly water every day, that would damage you, too.  So, I mean, anything in high excess will hurt you.



But the point is the only way to know where you are is, next time you get your routine physical, just ask your doctor to have your Vitamin D levels checked.  The good news is, since we did the podcast, not in any way because of the podcast, but the world seems to be waking up to the importance of Vitamin D.  So your asking your doctor is not going to have him go, "Huh?"



LEO:  No, I was very pleased because after that thing that you did, I did ask my doctor, and he said, "Yes, of course."  It was a simple, easy thing to do, and I was getting blood work done anyway.  And he said, oh, yeah, yeah, we'll add that to the test.  He didn't mind.  It can't be a very expensive test.  I mean, it's...



STEVE:  Not expensive.  And what I learned was I was really, really low, even though my health has historically been very good.  But, I mean, Leo, just except that I got bad food once, or actually twice in a restaurant in the last two years, I haven't been sick a day.  And we did hear after the winter following that podcast from many of our listeners who said, wow, this is the first rainy winter season I ever went through that I didn't get sick.  So it has strong immune benefits, and I can't recommend it enough.  But you really need to test because I need to take a lot of it in order for my blood to be where I want it to be.  Other people may not need any, or much less.



LEO:  I got this test done March of last year.  I should get another one done because, as you can see, I was at 29 where the standard range is 30 to 100.  In other words, at the very low end of normal.  And so I have been taking D since.  And I agree with you, and it's purely anecdotal, but I have been much healthier since I took it.  And when I forget for more than a few - I think you build up a level.  But after a few weeks I start getting sick again.  So, in fact, I just - I haven't taken it in a couple weeks, so I'm taking some now.  Gotta take it.  So, yeah, I mean, I was glad that you did that bit.  And so consult your physician, of course.  We're not doctors.



STEVE:  Yes, exactly.



LEO:  We just play them on the radio.  Question No. 4, Dax Mars, visiting Earth via Second Life.  He says he never updates his computer:  Mr. Steve, I've been listening and watching Security Now! since the start.  Always good info, but I have a question.  I never update Windows on my PC.  Well, the one I use only for programming.  I write shareware, you see.  It's a Pentium 3 running XP Pro SP2.  It's probably been four years since I did the updates as of that install.  Yeah.  I think there's a SP3 you're missing.  It is on my wired LAN, but it is never used to go online except to allow the CD ripping software to get CD info once in a rare while.  So should I be updating it?



My reason for not updating is to keep it stable as a programming PC without things changing all the time.  It only has a 10GB drive, by the way.  Of course that's more than enough space to code on.  Of course, I'm not completely crazy, and my two main PCs are 100 percent up to date, run Avast!, SeaMonkey with noscript and adblocking, behind a Linksys WRT54G with DD-WRT firmware and one of your killer long random passwords on the WiFi.  So should I update the Pentium 3 or let her be?



STEVE:  You know, I'd let her be.  I think that it's been four years, you've never had a problem, you only go on the Internet in order to let your CD ripping software go and grab from the CD database, album name and track names.  As long as you're not promiscuously web surfing - and also, by the way, you have SeaMonkey with script blocking.  So you certainly want to treat that machine carefully because there's a lot of stuff we know is on the Internet somewhere that could get it if you clicked on a link.  On the other hand, if you behave yourself, you have your other machines for that kind of work, I'd say, eh, I mean, I can understand the notion of leaving it alone.



One of the things that really annoys me about Windows is that every single one of these little updates, and they're often not so little, has the ability to be rolled back.  Well, that requires that Windows stores all of this state of the machine before it applies each one.  And although the directory is hidden under the main Windows directory, oh, my lord, after a few years, it is so full of stuff.  And Microsoft just sort of, I mean, I don't know what they're going to do about it.  I wish they would expire the older things after a while.



But it does annoy me the degree to which all of this just junk builds up in Windows, and it never goes anywhere.  You have the ability, of course, to roll all the way back.  But I don't think that is ever going to work for anybody because there are just so many dependencies and interdependencies among things.  So it's one of the reasons setting up Windows from scratch is a good idea.  I would say, as you suggest, Leo, just jumping to SP3 isn't going to destabilize anything, and you'd get a bunch of fixes there at once.



LEO:  It's on the LAN, and other computers on the LAN are on the network.  So is it really fair to say it's not on the network, just because he never points that computer's browser to a web page?  It is on the Internet isn't it?  It's behind a router, but it's on the Internet.



STEVE:  Oh, yeah, it is.  And so he definitely has to behave himself.  But it's a little bit like you and me, who both don't use third-party AV stuff.  We're just very careful about where we go and what we do and, knock on wood, have gotten away with it so far.



LEO:  I think it's different, Steve.  I hate to...



STEVE:  Really.



LEO:  ...argue with you twice in one episode.



STEVE:  No.



LEO:  Because, all right, let's presume there's an unpatched exploit on XP.  And that exploit can be - now, if course it would have to get through the router; right?  So...



STEVE:  It would be him going to a web page.



LEO:  There's nothing just kind of floating around that would go float through the router to his machine or could be on another...



STEVE:  Now, that's what's so nice.  That's what's so nice about being behind a router and...



LEO:  So the router's going to protect it.



STEVE:  And SP2 has its firewall turned on by default, too.



LEO:  Right, right.  So he would have to explicitly open himself to an exploit using a browser or some sort of surfing.



STEVE:  Correct.



LEO:  All right.  So, yeah, that makes sense.  I don't disagree with you.  I don't.  I agree.  It is a little different than AV because an antivirus doesn't protect - if you have an exploit on your system, it doesn't protect you against necessarily an exploit being taken advantage of.



STEVE:  Right.  It tries to be watching your email come in and finding...



LEO:  In other words, we'd be nuts not to patch it.



STEVE:  Correct.



LEO:  It's one thing not to use an antivirus.  It's another thing entirely not to patch your system if you are going online; right?



STEVE:  Right, right.



LEO:  Omri Amirav-Drory was present at the Solve for X event that we've been talking so much about.  In fact, Omri has been here in the studio, and we're going to have him at some point on one of our shows.



STEVE:  Oh, no kidding.  Genetic compiling.



LEO:  Yes.  He's one of the speakers at the first-ever Google Solve for X event.  His talk is online at YouTube.  In fact, if you just search for "Solve for X" and "Omri," you'll find it.  He met, he says, with the spray-on nano-particle antenna guy, Anthony Sutera, and his fiance during that event.  He seems to be a very genuine geek.  He brought samples of his material to demonstrate and showed several interesting electrical properties of the material to anyone interested.  And, yes, he actually did have it in that spray can.



I am no chemist, so I can't verify his claims.  But it's one hell of a complicated hoax if it is one.  I'm a big fan of you and Leo, thought you and your listeners might appreciate another first-hand report since it's easy to wonder about something so new and surprising.  Omri Amirav-Drory is a Ph.D. and founder and CEO of the Genome Compiler Corp., which is, interestingly, GCC is the acronym.  He is going to join us on a triangulation to talk about genomics.  It's fascinating what he's doing.



STEVE:  I'm glad he's going to because he did indicate in his note that he was available.



LEO:  Yeah, we've been in touch, yeah.



STEVE:  Very good, very good.  And I just wanted to say thank you.  I appreciate having a report from someone who was there and who met Anthony and had a chance to spray an antenna on himself and so forth.  So we'll just sort of see what happens with that.  I don't have any stake in it one way or the other.  I thought it was interesting, made a great presentation, certainly.  And we'll just keep our eyes open, as we are for other things like supercapacitors.



LEO:  I'm still waiting for that to happen.  Jim Hartz, New Brunswick, New Jersey says he had his life made easier:  I'm a huge fan of Security Now! and a SpinRite owner.  I just wanted to thank you for something not related to either.  I recently was doing a web search for how to disable UPnP on a Windows XP box, and the second result was for none other than GRC.com.  Hey, nice SEO, Steve.  Knowing the site, of course I clicked that link.  Your freeware UnPlug n' Pray was quick and easy.  Thank you for making my life a little easier and for all you do for your followers.  Keep up the excellent work.  That's a free program you offer.  Does it work for all versions of Windows, Unplug n' Pray?



STEVE:  The ones that need it.  The reason I pulled this, what caught my attention, was that I realized how long it has been since I've had to solve one of Microsoft's screw-ups.



LEO:  That's true.  Things have changed, haven't they.



STEVE:  That's my point, exactly, that I wanted to discuss a little bit, is the world really has changed.  It's not like we don't have problems anymore, but they're different problems.  And they've sort of moved.  What I was doing for quite a while with DCOMbobulator, Unplug n' Pray, and, I mean, patchwork, one thing after another, was Microsoft would have some problem, and I'd quickly do a nice little lightweight piece of freeware written in assembly language, that no one could believe how small it was.  It would just come up, they'd click the button, it would solve their problem.  It would just fix that, whatever it was.  And, I mean, that's one of the reasons I was on your early Screen Savers shows so many times.  And this was happening all the time as I was producing these things.  And that's stopped.  I mean, that really has stopped.  And I think it was them finally turning the firewall on in XP with SP2.



LEO:  XP SP2, yeah.



STEVE:  And the fact that routers have become ubiquitous.  I mean, once upon a time people actually plugged, I mean, I just shudder to think of actually plugging a computer directly into my cable modem, or into an ADSL connection.  I mean, the idea of there not being this little separate island firewall appliance, which is essentially what a router gives us, as the first thing that's going to stop any unsolicited inbound traffic.  And we do know that, even today, if you took an XP machine, like just XP the original "gold" build, and stuck it on the raw Internet, it just gets taken over by Code Red and Nimda and MSBlast and everything.



LEO:  Is that still the case, I wonder?



STEVE:  It's still out there on the Internet, yeah.  It just immediately becomes taken over because there was no firewall, and there was no protection, and there was all, I mean, and DCOM things, there was like - Microsoft was running services that people didn't need, like Universal Plug & Play, which were vulnerable.  There were mistakes in those services.  And when you went on the Internet,, they were just wide open and exposed to exploitation, which is what made it such the days of the Wild West back then.  But anyway, Jim's comment made me realize, huh, I'm not doing that anymore.  I'm doing other cool things that I'm quite happy with.  So, but yeah, I thought it was worth just sort of noting that the world has changed.  That's behind us, thank goodness.



LEO:  Such good news, yeah.



STEVE:  Yeah.



LEO:  That's one of the reasons we can talk so much about privacy nowadays, frankly.  Ed Zucker, in Long Beach, California - remember we used to talk about spam a lot, too.  That's kind of gone away.



STEVE:  Yeah.



LEO:  Ed Zucker - or not gone away, we've just found ways to deal with it, let's put it that way.



STEVE:  Right.



LEO:  Ed Zucker in Long Beach, California, demonstrates that Chrome side tabs are well missed.  We talked to you last week about the fact that Google had removed them.  It was an experiment they turned off:  Steve, you're not alone in your love for open web pages and tabs.  The "bug" of the missing side tabs exploded in the chromium bugs management.  And after 108 individual postings by people who were desperate to get side tabs back, Google was forced to close the topic to further posting.  They didn't put the tab back, but they at least said you can't talk about it anymore.



STEVE:  We're not going to talk about it anymore.



LEO:  We're done.



STEVE:  Yeah.  I have a link there to this so-called "bug" report for Chromium.



LEO:  It's not a bug, obviously, it's a complaint about a feature.



STEVE:  Yeah.  It's like, hey, Chrome updated and my tabs are gone, my side tabs are gone.  I want them back.  And this thing goes on and on and on, 108 individual people saying, c'mon, figure this out, give them back to me.  Now, the good news is the 109th posting was from a Chromium person.  And what he said was that, sorry, they're not coming back, so we're going to shut down this complaint log because there's no point in continuing.  But he referred to a technology that they were looking at which would enhance Chrome such that it no longer had a rigidly fixed Chrome, for lack of a better term.  Remember that "Chrome" is the insider web designer/web browser jargon for the window dressing, all the so-called "chrome" of the browser is all of the stuff that's not the web page, the various buttons and menus and so forth.



And so what they're talking about is extending the extension, Chrome's extension API to allow customization by add-ons that would be powerful enough to allow tabs, side tabs.  And that's the kind of thing we've seen in other browsers that have more permissive APIs that do allow more customization of the browser real estate.  So that would be cool.  That would mean that users who weren't tab addicts, as I and so many other people are, people who didn't need those wouldn't be burdened by having Chrome lugging that technology around.  But those of us who absolutely organize our lives around having 57 open tabs would be able to add that to Chrome and then tab ourselves to death.



LEO:  The developer post says this really - "The bug tracker is where the engineering team discusses bugs.  This really isn't the appropriate place.  We suggest you go to the chromium-discuss mailing list, a much more appropriate forum."  And I have to say I think that that's probably the right way to handle that.  And we should point out that, while Google releases Chrome, that Chromium is in fact not a Google project, it's an open source project that Chrome is based on.  So this guy Pete Kasting, who posted this, and the people who made this decision, may or may not work for Google.  It's not known.  And I think having - it's a simple way to add it.  Just add detachable surfaces or something like it.



STEVE:  Yeah.  Isn't that great?



LEO:  Then you can do it.



STEVE:  Yeah.



LEO:  I mean, 108 sounds like a lot.  But I'm sure there are close to 100 million users, so it's not - it's a small percent.  Brian Voeller in Medford, Oregon, wonders about factors and prime collisions:  Today I have a question on factors and an unrelated thought on prime number collisions, something we were talking about a couple of weeks back.  You mentioned in Episode 340 that 512-bit and 768-bit numbers have been factored.  So we're always going to move to larger numbers to stay ahead.  That's why we're at much larger numbers.



When you say that they've been "factored," does this mean that someone has decrypted an early test message after many months and years of brute-force computation, thus proving the math is correct?  Or has someone computed all the products of all primes in the given keyspace and arranged them in something like a rainbow table?  It seems that the former is not all that serious since all that brute-force work is completely useless against any other encrypted message, even if the time required will steadily decrease as computation power increases.



The real problem would be the latter, as decrypting any message would then be as easy as retrieving hashed passwords from an unsalted database with rainbow tables.  The only catch I could see with this is that the tables would be so large that only a fraction could be stored in all the hard drives in existence.  So just brute-forcing would be faster, perhaps, than searching.  Can you explain a bit more about what you mean by saying they've "been factored"?



STEVE:  So it's really interesting.  When RSA, the security company whose conference is ongoing right now, and the source of a lot of our crypto technology from its inventors, when they proposed an asymmetric crypto system based on the difficulty of factoring large numbers, which were composed of primes, they said, okay, we want to make sure these are as hard as we think.  So they formally created a challenge which they hosted and gave, I think it was a $10,000 cash award for factoring the so-called "modulus," which is the composite of the two primes, breaking it back down into its primes.  And the contest went on for quite a number of years.  And it had a long list of increasingly long products of primes.  And on their site, which is still available at the RSA Labs section of RSA.com, I think if you Googled something like "prime factorization challenge" you can probably get right to it.



And what happened was the shorter ones got factored, and the largest composite of two primes that was ever factored was the 768-bit composite.  And I have the text from the discussion of that particular solution, to give people a sense for this.  So this is 768 bits.  "A six-institution research team has successfully factored the RSA-768 challenge number.  While the RSA factoring challenge is no longer active, the factoring of RSA-768 represents a major milestone for the community.  The factors were found on December 12, 2009 and reported shortly thereafter.  The academic paper describing the work can be found at" - and then there's a link to a PDF.  "The factors are" - and then it lists these two big, long, three lines of decimal digits is the two prime numbers.  And it says, "The effort took almost 2,000 2.2GHz Opteron CPU years, according to the submitters, just short of three years of calendar time."



LEO:  Oh, boy.



STEVE:  So in '09 it took three years for this six-institution team to crack a single 768-bit composite, a "modulus," as it's called, the composite of these two primes.  No one has ever done it for 1024.  And it's not like a quarter harder because 1024 is a quarter longer.  It's exponentially harder as these numbers get larger.  And so put that into perspective with 2048.  I mean, it's just not happening.  Which is why what we talked about a couple weeks ago, the discovery that the primes being used were not as random as we assumed they were, why that's a big deal.  Because essentially the 2048-bit - in fact, this was mostly done with 1024.  Even 1024-bit numbers are so hard to factor, nobody has ever - nobody has ever factored one, ever.  But the idea that there's this shortcut where you don't have to factor them because you can use a Euclidean algorithm, if you happen to have two of these moduluses that have a common prime, it'll tell you almost immediately that that's the case.  That's like, whoops, that's not a good thing.  So that was a real backdoor behind this.



But anyway, the idea was RSA had this challenge.  Moduluses up to 768 were factored.  No one has ever been able to factor anything bigger, which gives us a sense for the security.  And that 768-bit one, it used all the cleverness these guys could come up with.  The paper just makes your eyes cross, it's so detailed, and the technology that they used.  And even so, 2,000 2.2GHz Opteron CPU years were required, and it took them three calendar years to crack one.  And that was 768 bits.  So no one's using that anymore.  We're all at 1024.  And we're headed to 2048.  In fact, all of my new DigiCert keys are 2048 because that's the minimum length that you must use if you want to get an extended validation, an EV cert.  You have to have 2048 as the minimum, which everyone expects is going to keep us safe for a long time.



LEO:  So it's really being prudent.  I mean, it would take three years for a 768-bit key.



STEVE:  Yes.



LEO:  So it's just being prudent.



STEVE:  Yes, 2009 wasn't that long ago.  We haven't gotten things that much faster.  We still haven't had any breakthroughs in factoring.  I mean, this is a problem that really smart people have scratched their heads about for a long time.



LEO:  Question 9, Jacco Flenter in Holland wonders about salts and hashes stored in databases:  Steve, I've been listening to Security Now! for quite a while, and I've got a question.  I'm curious about hashes and salts.  I'm looking to help a project which stores salts in the database together with the hash of the password.  Now, is that a security issue?  I understand that this would leak some information about how to generate the hash from the plaintext, should the hacker know what method was used, and I assume that that's a bad thing.  But exactly how good or bad is this practice?  Unique salts give also a bit more strength to the hashes stored in the database, since one rainbow table matching a salt does not corrupt the whole database of passwords.  Thanks for Security Now!.  Regards, Jacco.  So he's saying there's a single salt, and it's stored with the database.  Is that a mistake?



STEVE:  Well, yeah.  He's saying that apparently they generate a random salt for each account.  And so they're storing the salt and the hash of the account password.



LEO:  I get it, together.



STEVE:  Together.  And so, okay.  What we know is that a salt is some typically binary data which is appended or prepended to the password, which are then together run through the hash to produce the result which is stored in the database.  The normal way, the reason one's concerned about this, is the brute force, that is, you are guessing - if you had access to the database, that would give you the salt and the hash.  If you knew what the hashing algorithm was, you would then start putting guessed passwords through the process, trying to get the hash to come out.  If you could do that, then you would - you don't know that you have the password because hashes can have collisions, as they're called.  But you would know that you had a password which, when combined with a salt and hashed, gave you the result.  And that would allow you to impersonate that user, to log in as them into that system.



If the salt was not available, what's significant is that the salt is binary, yet the passwords you're guessing are ASCII.  And if the salt were not available, if it was stored somewhere else, or if it was encrypted or somehow better protected than stored right next to the hash, then it's very likely that no ASCII, no password characters could be put in that would create a collision with the hash, that it would give you the same hash because you would very likely have to put some binary in, in order to have it salted with the binary which is the salt in order to get the result.



Maybe I've made that little too confusing.  I don't think I described it very well.  But the idea being, having the salt is critically important for being able to perform a brute force.  Without the salt, it's very likely no password on earth could create a collision because you just may not be able to - because the salt would be binary, and the password is ASCII.  So it's a much smaller character set in terms of the bytes.  ASCII is a much smaller range, very likely that you could never create a collision.  So I would say, I mean, it's not crucial.  But if you could put the salt somewhere else, that would be a good thing.



LEO:  We have two more.  Are you ready?



STEVE:  Yeah.



LEO:  Question 10, Keith Rollin in Sunnyvale, California wondering how is overwritten disk data recovered?  This is another one of those tinfoil hat things:  In order to securely wipe a hard drive, operating systems and third-party utilities offer facilities for overwriting data multiple times.  I've seen options for overwriting three, seven, 11, even 35 times.  The implication here is that someone can still recover previously written data from a disk even if it's only been overwritten a few times.  My question is, how is this done?  If there are multiple images of a block in a particular physical location on the disk, how does the standard driver know which bits are the current ones?  How does a recovery program know which bits are from one generation back as opposed to two generations back?  How prevalent is the technology for reading old disk contents, and how many times should we overwrite a block to obliterate old data?



STEVE:  And I agree with you, Leo.  I would now, more and more, I would classify this as an urban legend.  That is, the idea that it is possible to go back multiple generations.  This 35 times is the result of one famous paper on the Internet where someone analyzed very old generation drives, meaning MFM or RLL drives, where we knew how the data we were putting in was turned into flux reversals, because it's the reversals of flux on the drive which stores the data.  With contemporary drives, it's amazing how many different stages, they go through at least three stages of data manipulation before, that is, the user data is transformed in three very different ways before the final flux reversal pattern is generated.  Meaning that the user has diminishingly little control, based on the data they write, over what's finally written on the drive.



An earlier version of SpinRite, several generations ago, actually it's SpinRite 3.1 and 4, I think, did something where I reverse-engineered what were called the endecs, the encoder decoders of all the popular hard drives.  I found them all, I reverse-engineered them, I knew how they related data to flux reversals.  And I came up with this - it was called the "flux synthesizer," actually, which synthesized patterns based on the drive's make and model to do the best job of finding defects.  And that sucker really worked.  The problem is, you just can't do that anymore.  In the same way that you cannot deliberately write data to create flux patterns on the disk, that's just - it's gone from all of our contemporary drives.  Similarly, there's no way to do, like, worst-case data patterns.  They existed once.  They don't exist anymore.  And error correction is so prevalent that it's not clear that that really matters, either, because error correction is always there, always in use, and it's solving problems like allowing us to skip over little defects and correct for them.  My feeling is that two passes of pseudorandom data such that there's no record of what was written is all you absolutely would ever need.  I would argue that one pass could be reverse-engineered, but not two.  And even then it would take, I think, as you said at the top of this, Leo, it's another tinfoil hat issue.



LEO:  It all came from a guy named Peter Gutmann who gave a speech in 1996.



STEVE:  That was Peter.



LEO:  Yeah, asserting that this was possible, never demonstrating, never explaining, never showing any real evidence.  And even then, what work they did required a scanning tunneling microscope per bit.  It's just not - it's not - it doesn't - no.



STEVE:  No.



LEO:  And it takes a lot of time.  But it's become - there's so many things that are become revealed truths in technology because we don't understand it very well, and so we just all kind of accept it.  And that's one of the revealed truths, that you must overwrite 35 times, or somebody somewhere could figure it out.



STEVE:  Yeah.  The next major revision of SpinRite, which is a ways off because I'm going to do a minor one first, but it will incorporate the what I call "beyond recall" technology, and it will have an extremely good pseudorandom number generator, because I know how to write those now, having done all this crypto work, and it will very quickly do a secure wipe of the drive, and also do what it can about the safe area, the protected area, and the relocated sectors, a ways of getting into there, too.  So that'll happen.



LEO:  Our last question, ladies and gentlemen, is the Revelation of the Millennium.  I need a gong or something.  Ed in Cleveland says:  I've solved all of the world's problems without even trying.  Steve, I believe I've come up with a way to solve all the world's problems.  I'm contacting you because I know you will be able to confirm if my theory is valid.



I will start with the simplest example:  The recipe for tacos, when stored as a text file on a computer, is just a string of digits.  If you randomly generated digits, you would eventually produce a set of digits that is identical.  You'd also produce a lot of noise, along with many variations of the taco recipe.  If you never stopped, you would produce every recipe in every language that has ever existed.  In fact, I'll point this out, you would produce everything ever, including all of Shakespeare.  But let's go on.



You could eventually do the same with music.  Start producing a random set of digits, and you eventually end up with "Hey Jude" by the Beatles.  The process will produce the entire Beatles catalog, along with the most beautiful Beatles songs that John and Paul ever dreamed of making.  These random sets of digits will even contain a recording of "Yellow Submarine" with the fifth Beatle, Steve Gibson, on lead vocals.



STEVE:  Now, there's a scary thought.



LEO:  Ha ha.  It's true, though.



STEVE:  Yeah, it is.



LEO:  The problem is the word "eventually."  But anyway, we'll get on.  Among the text documents, sound recordings, and videos that could be produced by randomly generating digits is the cure for cancer, the end of war, the source of unlimited free energy, and everything you can and cannot imagine.  I think Douglas Adams wrote about the Infinite Improbability Drive.



STEVE:  Ah, love that, yes.



LEO:  This process could even produce a documentary video of future events; a video of the highlights of my life including the last breath I take, absolutely accurately and perfect in every detail.  My point is, although it may not be practical, it is possible to produce a digital version of everything that has ever happened in the past and will happen in the future, and also to produce things that would never have been invented by man.  Do you agree that this is possible?



I point you to, Steve, a very famous and infinite number of monkeys typing on an infinite number of typewriters, which was conceived of long before digital technology.



STEVE:  Ah, yes, the lure of digits, Leo.



LEO:  It's no different 'cause it's digital.



STEVE:  Yes.  I just got a kick out of this posting.  And what it tells us, as listeners of this podcast who are interested in things like bit lengths and in crypto and in probabilities, all of which we work to understand and deal with, is that Ed, of course, is correct.  And here we are looking at the impossibility of finding the 128-bit symmetric key used to encrypt communications because, for example, that's what protects SSL.  Yes, there's all of the fancy public key, private key, all of that.  But that just negotiates, remember, the symmetric key, which is much shorter.  And we can't try all of those combinations.  There are too many in only 128 bits.  And if we look at how few characters that is, then we get some idea of the number of bits required to represent one of the Beatles songs.  And that, sure, you could change a few of the bits here and there, and the song wouldn't be drastically different.



But when you start doing the math and looking at how many combinations of bits there are, it's true that everything that has ever existed is in some pattern of bits.  The problem is that so is everything that will never exist, and there's a lot more of that than there is - there's a lot more of the junk than there is of the good stuff.



LEO:  The real problem is this term "infinity," which somehow implies that it's a number, that it is in the same category as one, two, three, four, and five.  That if you kept counting long enough you'd get to infinity.



STEVE:  Well, and it's because we deal, we humans...



LEO:  We don't get it.



STEVE:  Yeah, exactly.  We operate in a world of how far can we throw this stone, and when will my car run out of gas, and physical, conceivable, real-world sizes and numbers.  And what I like about this...



LEO:  Infinity ain't one of them, by the way.



STEVE:  Right, exactly.  What I liked about this is that it reminds us that combinations of bits are incredibly powerful.



LEO:  Right.



STEVE:  I mean, he's right; Ed is right.  All of those things exist as a combination of bits.  The other thing this says to me is a little bit about entropy, which is we are highly ordered in our combinations of bits.  Computers and the technology we're using, the fact that you and I are communicating in real time, 500 miles from each other, and audio is going back and forth, I mean, this is this incredibly supreme accomplishment against entropy, where think of all the things that could go wrong, all of the ways that these bits could be different, and nothing would work.  Yet here it is, and we're talking to each other.  It's fascinating.  But, yes, the world is big; the universe is big.  And as you said, Leo, infinity is a very large number.



LEO:  It's a bigger number than one really thinks of.



STEVE:  It's a lot further than you can throw that stone.



LEO:  And then, for further research, Zeno's Paradox, infinitely small numbers.  And there's some who say in string theory that perhaps that thing that he was talking about is actually occurring, and that we are existing on one of the many strings of infinite possibilities, and we just happen to occupy one of them.  I hope you're enjoying yourself.



Steve Gibson is at GRC.com.  That's where you can find 16Kb versions of this show, which are mostly but not entirely random.  And also, of course, you can get the transcript.  You can get lots of free stuff.  And the most important thing, SpinRite, the world's finest hard drive maintenance and recovery utility.  You gots to have it.  If you've got a hard drive, you need SpinRite.  Steve will be back, not Wednesday, but Tuesday.  I should tell everybody.



STEVE:  Yes.



LEO:  We talked about this.  March 7, next Wednesday, is Apple's iPad 3 announcement day.  So we'll be doing MacBreak Weekly that day.  We'll start our live coverage at 9:30 a.m. Pacific, 12:30 Eastern.



STEVE:  Be still my heart.



LEO:  Yeah.  So we're going to flip-flop you and put you in MacBreak Weekly's time, 11:00 a.m. Pacific, 2:00 p.m. Eastern.



STEVE:  Tuesday.



LEO:  1900 UTC on Tuesday, March 6.  So...



STEVE:  And we will discuss SPDY, S-P-D-Y, finally, what Google has been doing to propose improvements to the most-used protocol on the Internet, which is HTTP, which all of our web browsers use - how to make it go more speedy.



LEO:  Awesome.  Steverino, thank you so much.



STEVE:  Thanks, Leo.



LEO:  Have a great week.  We'll see you next time on Security Now!.



STEVE:  Bye bye.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

	

SERIES:		Security Now!

EPISODE:	#343

DATE:		March 6, 2012

TITLE:		HTTP & SPDY

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-343.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  This week, after catching up with the week's security and privacy news, Steve and Leo take a detailed look at the World Wide Web's current HTTP protocol and examine the significant work that's been done by the Chromium Project on "SPDY," a next-generation web protocol for dramatically decreasing page load times and latency and improving performance and interactivity.



SHOW TEASE:  Time for Security Now!.  Steve Gibson joins us for security news, of course, and updates.  And then we'll talk about a new initiative from the Chromium project to speed up the Internet by, like, a factor of three:  SPDY.  Next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 343, recorded Tuesday, March 6, 2012:  HTTP & SPDY.



It's time for Security Now!, the show that protects your security and privacy online.  And boy, I've learned a lesson:  That's something people care about.  Steve Gibson is here - the man, the myth, the legend.  Oh, no, I'm supposed to call you the Explainer in Chief.  And you are going to explain today.



STEVE GIBSON:  Ah, there we go.



LEO:  You're going to explain spidey sense.



STEVE:  Oh, yes, it's something that, the more I've looked at it, the more I hope this thing gets traction because it's a project that the Chromium group - actually one main guy within the Chromium group - have been working on to figure out a way to improve the user's experience surfing the 'Net.  And I'll give you a benchmark which I also cover at the end of this explanation:  They've got it running so that the average of the top 25 websites load in one-third the time.  So, I mean, that's a huge...



LEO:  Wow.  That's not the websites making a change.  That's the browser.



STEVE:  Well, it's looking at the inefficiencies which no one really worried about 10 years ago.  Today's Internet is not our grandfathers' Internet.



LEO:  No, no, no, no.



STEVE:  And pages are much more sophisticated, much more complex.  They're pulling stuff from all over the place.  It's not just a page of text.  And so what Google has done is they've carefully looked at how time is spent.  There have been other efforts, also.  What we'll talk about is a solution to a problem that's been understood for at least a decade.  There is an RFC that was written in 2002, so 10 years ago, talking about a next-generation sort of multiplex streaming protocol to replace TCP.  The problem is we can't replace TCP.  It's just too ubiquitous.  All of our little NAT routers would break in our homes, to say nothing of the Internet's routers.



So what Google has done is they've figured out how to stick a shim in between TCP and HTTP so that nothing really has to change, but if you have a SPDY - SPDY is sort of their acronym, like HTTP, this is SPDY.  If you have a server that is able to serve HTTP for non-SPDY-aware browsers, but also able to support the SPDY enhancement, then if you're using a browser that also understands this next-generation protocol, your pages come up in one - your pages finish loading in one-third the time. 



LEO:  Wow.



STEVE:  I mean, that's a huge, huge improvement.  And so we're going to talk about what HTTP does, what it doesn't do right, look briefly at what's come before, and then plow into how to make it faster, what the Chromium guys have done.  And they've built a server.  They've got a server running; they've got a version of Chrome running.  All of this works.  And I just hope it gets some traction because it would be great to have.  And at no cost.  Basically it much better utilizes Internet connections than we are doing now.  And we'll talk about how.



LEO:  Neat.  Yeah.



STEVE:  So not a ton of news.  I did want to just mention something that was in the news, I think it was sort of toward the end of maybe middle or late last week about this Bodog.com site that got - it's a Canadian-based gambling site....



LEO:  Oh, yeah, yeah, yeah.



STEVE:  ...that is based in Vancouver.  Their domain, Bodog.com, is registered with a registrar, Canadian registrar DomainClip.  And there's no strong affiliation of any sort with the U.S.  It's not in the U.S.  The registrar's not in the U.S.  But despite that fact, the state of Maryland, prosecutors in the state of Maryland were able to obtain a warrant ordering VeriSign - which is a U.S.-based company, we understand, VeriSign, which manages the dot-com domain name registry, that is, it runs the dot-com top-level domain, and so the other registrars feed their stuff through VeriSign to the master dot-com server records - the state of Maryland ordered VeriSign to redirect the Bodog.com website to a warning page advising that it has been seized by the U.S. Department of Homeland Security.



And so there was a lot of coverage about this.  One blogger, Michael Geist wrote, he said, "The message from the case is clear:  all dot-com, dot-net, and dot-org domain names are subject to U.S. jurisdiction regardless of where they operate or where they were registered.  This grants the U.S. a form of 'super-jurisdiction' over Internet activities since most other countries are limited to jurisdiction with a real and substantial connection.  For the U.S., the location of the domain name registry is good enough."  And dot-com, dot-net, and dot-org are located here in the U.S.



So he goes on and says, "The aggressive assertion of Internet jurisdiction was one of the key concerns with the Stop Online Privacy Act (SOPA), the [controversial] bill that died following a massive online protest in January.  It simply defined any domain name with a registrar or registry in the U.S. as 'domestic' for U.S. law purposes.  The Bodog.com case suggests that the provision was not changing the law as much as restating it, since U.S. prosecutors and courts follow much the same approach."



And so he finishes, saying, "In an era when governments are becoming increasingly active in regulating online activities, the Bodog.com case provides a warning that by using popular dot-com domain names, companies and registrants are effectively opting-in to U.S. law and courts as part of the package."  And I did see, in reaction to this, a number of people talking about, well, that means we just can't - we can't be under dot-com, dot-org, and dot-net because it's subject to being confiscated.



LEO:  Well, and that was the whole point of SOPA was to add these other domains to the ICE takedown capability; right?



STEVE:  Right, right.  It was foreign domains.



LEO:  It wasn't for dot-coms, yeah, yeah.



STEVE:  Correct, correct, correct.  Well, and the other big news, I mean, this is hot news from this morning, it turns out that a guy named Hector Xavier Monsegur, who lived in New York's Lower East Side in a housing project, was the head of LulzSec.



LEO:  What?



STEVE:  Yes.



LEO:  They caught him?



STEVE:  Yes.



LEO:  Oh, boy.



STEVE:  They actually caught him last June, and they kept it secret.



LEO:  Whoa.  No wonder it's been so quiet lately.  Anonymous has done everything.



STEVE:  He pleaded guilty - uh-huh.  He pleaded guilty to the charges, 12 hacking-related charges on August 15th of last year, then turned state's evidence.



LEO:  Oh, boy.



STEVE:  And he turned in the other five top-ranking members of LulzSec, who were arrested en masse in a synchronized raid across the globe this morning.  Ryan Ackroyd, aka "Kayla," was one of them; Jake Davis, aka "Topiary," both in London.  Darren Martyn, whose handle is "pwnsauce," and Donncha O'Cearrbhail, whose handle is "palladium," both in Ireland.  And, finally, Jeremy Hammond, who went by "Anarchaos," in Chicago.  And Ryan Ackroyd, who I mentioned, is believed to be the No. 2 guy, that is, Monsegur's top deputy.  And Jeremy Hammond, the guy in Chicago, is believed to be - and there's a separate indictment for him because he's the person believed to be behind the WikiLeaks email breach, who hacked the U.S. security company, Stratfor, got all of those emails, and sent them off to Assange and company.  So this was a big deal this morning.



LEO:  Wow.



STEVE:  It turns out Hector, who they caught in June and who pleaded guilty two months later in August, he goes by Sabu, Xavier DeLeon, and just Leon.  He's an unemployed 28-year-old father of two, living in a public housing project in New York's Lower East Side.  And he became a "cooperating witness," as they termed it, in June.  I put up a - oh, no I didn't.  It's for a different story.  Gizmodo has - it's just Gizmodo.com/5890886.  So that's pretty easy to get in:  Gizmodo.com/5890886.  On that page is all the legal documentation, all of the collective and individual indictments which are hosted over on Scribd, but you're able to download them.



LEO:  Good-looking guy.  Oh, boy.



STEVE:  Yeah, so that's LulzSec.  And they have, of course, ties to Anonymous.  There was some over-reporting done, talking about, oh, well, this ends all of Anonymous.  It's like, well, no.  This is six guys who were at the top of LulzSec, and certainly very active in hacking.  But this doesn't end the careers of Anonymous.



LEO:  I have heard, and I get the sense that the truth about these groups, though, are there are a few, a small number of elite or talented hackers, and the rest are script kiddies or people running the low earth...



STEVE:  Ion cannon.



LEO:  ...orbit cannon, yeah.



STEVE:  Yeah.  And in fact, even in reading some of the stories and looking at some of these depositions, or rather indictments, they describe the roles these people played.  And in many cases they say, well, this guy was a kernel hacker who found the exploits and then turned them over to somebody else.



LEO:  Yeah, yeah.  That makes sense. These people are fairly skilled.  Fairly?  Significantly skilled, I think.



STEVE:  Yeah.



LEO:  Wow.  So it's interesting, though, that he turned state's evidence because there's no honor among hackers.



STEVE:  Yeah, I was going to say...



LEO:  And they kept this secret for so long.  That net must have extended to a pretty broad number of people.  Are we going to see more indictments?  I would guess we will.



STEVE:  Well, those five people arrested this morning, following up on Hector's arrest back in June.  So now you can imagine they will be squeezed.



LEO:  There'll be more, yeah.



STEVE:  And, yeah.  Wow.  So I ran across an interesting page that I thought our listeners would find interesting.  Under the topic of Privacy Watch, this is a page you can go to.  I created for this one a Security Now! bit.ly shortcut, that is to say, this is Security Now! Episode 343.  So if you put in bit.ly/SN343, that will redirect you to Tom Anthony's page, where he's able to tell which social networks you're logged into.



LEO:  Oh, boy.  I'm logged into everything.  Except Twitter.  I use a Twitter client, so I am on Twitter in fact, but it only shows what you're logged into via your browser.  I mean, I've got Twitter running right here, but...



STEVE:  You can see you're logged into Facebook and Google and Google Plus.



LEO:  Isn't that interesting, wow.



STEVE:  Yup.  It turns out that - and he says, "This is a demonstration of how a website can detect which social networks a user is logged into when they visit.  In my tests," he says, "it seems to work in all the major browsers:  Firefox, Chrome, IE7 and on, Safari, and Opera."  So what that means is that using this technology, which he explains and is essentially publishing, any website that someone goes to is able to detect whether they are currently logged into Facebook, Twitter, Google, and Google Plus, individually.  And so this little page, this bit.ly/SN343, will take you over to Tom's page, where you can see for yourself.  So it's like, whoops, just something to be aware of.  I mean, it's not a big deal.  But it's like, well, it's not a secret.



A couple weeks ago, might have been last week, when we did a Q&A, Leo, I read a question that had some fun math in it.  And this was a guy who decided to see how long it would take to crack 256-bit symmetric encryption.  And reading from the transcript of the podcast, we said, "So let's say the tricky government" - and this is reading his question.  His question was, paraphrasing, so let's say the tricky government has a secret algorithm that somehow allows them to weaken the strength of brute-forcing a 256-bit symmetric encryption key to one-trillionth of the original strength.  So we're just going to imagine that there's some way that the government has to do that.  And let's say they had a computer that can try one hundred trillion guesses per second.  And let's say this computer was one cubic millimeter in size.  And let's say they build a cracking complex the size of the entire Earth, made out of these one cubic millimeter crypto-cracking computers.



And he says, in his question, he said, "If I did my math right, it would still take 34 trillion years to crack."  And he says, "I like that."  And so I think that might have been you, Leo, reading the question, saying "I like that."  I responded, "I like that, too."  And then Leo, you said, "Did you check his math?"  Well, I didn't.  But Jason Bache, who has a website, JasonBache.com, did the math.  He tweeted me.  He's @NerdsLimited, and it's also NerdsLimited.com is his site.  He sat down with a copy of MatLab, did the math.  And get this, Leo:  33.8802 trillion years.



LEO:  That's right on.



STEVE:  So our original questioner was right, 34 trillion years.  But if we want to get a little more precise, 33.8802 trillion years.



LEO:  It's a rounding error.



STEVE:  But again, that really helps to put into perspective that, I mean, we've made a series of assumptions which are worst, worst, worst, worst, worst case, that there's a way of doing it in a trillionth of the original.  We just threw away that many bits, essentially, from the key.  And that it's going to do a hundred trillion guesses per second, which would be really impressive; and that it's a millimeter cube in size; and that we have an Earth-size worth of them.  Given all that - and I don't know how we'd power it or cool it, of course, those little details.  But still, 34 trillion years to crack.  So 256-bit symmetric encryption looks like it's good to go, given that the only attack we know on it is brute force.



Again, an interesting piece of feedback about SpinRite that I thought was very clever from a listener of ours named Mike Whalen, sent it to me on the 18th of February.  He said, "Hi, Steve.  I've been a SpinRite user for many years.  It has served me well, and I consider it an indispensible tool in my IT arsenal.  Having said that, I haven't had that much occasion to use it.  I happen to work for a company and with a colleague who's very focused on backups.  We do a combination of local and cloud backups with a service called eFolder, which we resell.  We manage anywhere from 200 to 250 desktops, and we do see dead drives.  But since we have backups all over the place, we rarely see a need to fix a dead drive.  We just toss it out and restore.



"Nevertheless, I like to play with SpinRite and have run it on a number of dead drives that we encounter.  I've been using it fairly simply.  I'd run it as Level 2 or higher, and if it worked, yay.  If it didn't, well, as I said, we have lots of backups.  On a recent Security Now! you mentioned Level 1 and how it can force a drive to recognize bad spots on the drive.  That gave me an idea."  And actually I was talking about how that is the case, but also that's a use case for running SpinRite on thumb drives, that is, on flash drives, because they're using error correction a lot.  Their cells are soft, especially as they keep cranking the density up.  These multilevel cells have problems and rely on error correction, very much in the same way that bits are soft in the magnetic storage of a hard drive.  So algorithms are used to sort of forgive the fact that we don't have exactly what we wrote, but it's close enough that we can figure out what we meant, which is what the error correction technology in the drive does.



So anyway, continuing, he says, "That gave me an idea.  I recently took possession of a Western Digital MyBook external USB drive that was throwing itself offline.  When Windows or anything accessed a certain area of the disk, the drive would become unresponsive.  You'd hear the drive spin down.  It would spin back up and repeat that problem whenever the same area was touched.  I replaced the drive with a NAS.  We were due to add one at the site anyway.  Meanwhile, I took the disk back to my office to see what SpinRite could do.



"I disassembled the MyBook and connected the SATA drive inside to a desktop machine.  The results were not good.  Basically, in levels 2 or above, SpinRite would start processing the disk, and the drive would spin itself offline, just like when it was in the case.  SpinRite would freeze and couldn't continue.  I never got through one successful run at levels 2 through 5.  I even tried Level 2 a couple of times, thinking maybe I'd made progress with each run, but no go.



"Your statement about Level 1, though, got me to thinking.  Could I run the drive at Level 1 and force the drive to make a decision on those possible bad spots?  I did that.  I ran SpinRite on the drive at Level 1.  Success.  SpinRite was able to process the entire drive.  I then ran Level 2, which had already failed multiple times before, and success again.  I then ran Level 3 for good measure.



"The end result, the drive is completely repaired and working perfectly, all data on it fully recovered.  I've used this method on two drives that would not get through levels 2 through 5:  Level 1 first, then run subsequent levels.  I'm a terrible documentation reader.  Maybe SpinRite's documentation points out this in bold HTML blink tag red.  Well, I didn't see it.  Thank you..."



LEO:  He knows you too well.



STEVE:  "Thank you for mentioning Level 1.  Perhaps you could suggest Level 1 as a way to ease a problem drive that won't get through 2 through 5."  Well, that's brilliant, and it's not written down anywhere, except now it'll be in the transcript.  And all of our listeners just got a new tip for running SpinRite, if you have a drive which, like this - the problem is that all of the other levels are writing something.  Level 1 is a read-only pass.  And that's why it's safe to run on thumb drives, because it doesn't write anything, absolutely nothing.  It only reads.



But the beauty of that is that, as we were saying before, the act of reading shows the drive it has a problem.  And clearly this, whatever was going wacky with this and a couple other drives that Mike found, writing gave the drive fits, but reading was okay.  So reading was sort of eased into it more gently and allowed the drive to fix the problems so that then writing to them was writing to different areas because the bad spots had been relocated to good areas on the drive.  So that's a great tip.  It'll definitely make it into our notes for the future.  So thank you, Mike.



LEO:  Blinking red tag.  Red blinking...



STEVE:  Danger, Will Robinson.



LEO:  Danger, danger, danger.  All right.  Let's talk - now, I have a couple questions.  First of all, is Chromium the same as Google?



STEVE:  Well, Chromium...



LEO:  Are these guys Google employees?



STEVE:  The guy who's doing it I think works for Google.  And it's all open source.  And the spec is available.  And it's still - they're working it out.  I checked to see the project began a couple years ago.  And it was last touched in January, I think.



LEO:  You're talking about SPDY.



STEVE:  SPDY, yes.



LEO:  Chromium is always updated, but SPDY, got it, yeah, yeah.



STEVE:  Yeah.  So in order to...



LEO:  And it should be, by the way, "Spidey," for Spidey sense.  Okay, go ahead.



STEVE:  Don't listen to him, kids.  Okay.  So because I wanted to talk about this protocol, we discussed before TCP.  And I explained when I wanted to do a podcast on TCP that I needed to do that so you could understand some of the problems which the SPDY protocol fixed, and which the HTTP protocol has because it runs atop TCP.  And so just to refresh briefly, we'll remember that when we're connecting to a remote machine, we're doing that over this Internet, this packet-switched network.  And in the old days, when we literally had a modem with tones that was connecting to the other end, the bandwidth was fixed and known, as was the roundtrip time.  It was truly a connection between those two endpoints.



What we have today is known as a "virtual connection" because it's essentially the agreement between the endpoints that they're connected, and then the data, rather than being a physical wire, as we know, are individual autonomous packets which are addressed and sort of aimed at each end by the other, and they hop from one router to the next until they get to their destination.



So one of the problems that the designers of the TCP protocol recognized was there was no way for them to know what the bandwidth was, that is, how often can we send packets?  How much can we send?  What is the roundtrip delay?  How long will it take to get acknowledgments back from the other end that they received the packet, so that we know whether to send it again if it got lost or not, and how do we deal with this.



So there's something called the "TCP slow start."  And the idea is that TCP starts off cautiously.  When you initiate a connection, neither end knows anything about the nature of the speed of the connection it has to the other.  So it's built so that it starts off cautiously.  And as it continues to succeed, as its packets that it's sending are being correctly acknowledged by the other end, that acknowledgment that comes back encourages it to go faster and faster and faster, and it literally goes as fast as it can until it starts having problems.  Then it backs off a little bit and then comes up again and backs off a little bit.  And so it's always sort of bumping its head against the ceiling of how fast it's able to run.  But this all means that there's the so-called "slow start."  There's a ramp-up.



Well, now, think in terms of our web browsers and what that means because the way the web browser works is we put in a URL and hit Enter.  And the browser looks up the IP address for the domain name in the URL that we entered.  Then it establishes a TCP connection to that IP address and sends its request.  The other end, the server, receives the request.  It also has this brand new connection.  So it starts to send a page.  But it can't send it fast because that's not the way TCP works.  TCP has to be cautious.  It has to sort of seek out the ceiling of where, anywhere between the two endpoints, is there a spot of congestion.



See, because that's the cool thing is, the way the system works, you could have a very fast client connection to the Internet, a very fast server connection to the Internet, but there could be some problem somewhere in between.  Could be a flaky router or an overloaded router.  And these packets have to get through there.  So TCP works very cleverly to just do the best job it can.  But it means it has to start slow.  So that means that that page is not going to come as fast to us as it technically could if this were on a mature TCP connection that had already learned how fast it was able to go.



Now the problem gets even worse because that page comes to the browser.  And as we know, pages are composed of a whole plethora of additional assets, pictures, I mean, especially contemporary websites full of little social networking buttons and icons.  And so all of this comes in on the main page, that'll then have tons of URLs for other stuff.  It'll have script resources back to the same server.  It'll basically spray queries out all over the 'Net to all the other services, advertising services that we've been talking about recently, anything that provides content for that page.  And it's just bewildering now how much that is.  Well, every single one of those is a new TCP connection that has to start out slow and ramp itself up.  So that slows things down.



And there was some work, when we went from HTTP/1.0 to HTTP/1.1.  The problem was that originally a browser would make a connection for a single query.  It would send the URL, for example, to the server, get the response, and by mutual agreement they would both terminate the connection.  Then, if the browser saw, oh, look, I've got 26 things, I've got seven different JavaScript files, and I've got a bunch of icons and navigation stuff and menu resources, all this stuff I need from that same server.  It would, for every single one of those resources, initiate a TCP connection, as for that thing, wait till it got it, break the connection.  And in TCP there is no memory from one connection to the next.  Neither is there memory, even simultaneous connections to the same server, there's no interconnection sharing in the protocol.



So what engineers realized - and this is 10 years ago.  We've had the web for a while now.  They were realizing this is just not very efficient.  TCP is a fantastic solution for end-to-end communication, but it's just not good for short-lived requests.  It doesn't make much sense.  In fact, that's one of the reasons that DNS, for example, uses UDP, is that there is no setup and speeding and timing and sizing everything.  A DNS query is a single query packet that goes out, and a single one that comes back, and you're done.



So they kept, in DNS, they kept the overhead low, but they don't have any of the benefits in the UDP protocol that we get with TCP, which is all of this work being done for us.  If we send a big file over, it's possible because of the packet routing that the packets are going to arrive in a different order than they were sent.  So they're all, as we know from talking about TCP in the past, they're all serialized, and the receiver is able to sort of check them in on the way in.  And if it sees one that it's missing, it's able to wait for that to catch up, and then it drops it in the right place.



So the TCP protocol does all this great stuff.  But there are some costs to it.  And one is it's just not great for short-lived connections.  It just barely gets going, and the connection gets dropped.  So when they went to HTTP/1.1 they introduced - the designers of HTTP evolved the protocol to introduce the notion of a persistent connection where there would be a header - actually there was a "keep-alive header," it was called, in HTTP/1.0, but wasn't widely supported.  They did a better job in HTTP/1.1.  And the idea would be that the browser and server would agree not to drop the connection, that they would hold the connection up so there would be a query and then a response, and then a query over the same connection and then a response, and so forth.  And for a while browsers were constrained to only having two connections per domain.



The idea was we didn't want to flood a server with 20 connections between two points because, if you think about it, it's really not efficient.  It's not efficient in terms of the resources to manage the connections, both at the client's machine and the server, because you have 20 sets of data, all these individual connections.  It's inefficient because of TCP's slow start problem.  You don't want to launch 20 connections.  They're all going to start slow.  So, and you ultimately have some fixed amount of bandwidth between these two points.  So if you've got 20 connections, all going at once, you're not going to actually end up finishing any sooner.  You've going to end up finishing later because you've got 20 slow starts and some sort of bandwidth limitation between there.



So it makes much more sense to bring up a limited number of connections, and for quite a while it was two, and then let TCP learn what the bandwidth is and then send, instead of having 20 connections with one query each, just have two connections and send 10 queries each.  And those later queries and responses will be much faster because they're running over a more mature TCP connection.  So there was this two-connection-per-domain limit that browsers were enforcing.  The problem is, as web pages got just bigger and heavier, many browsers have now extended that to I've seen a number six is used often, just because you just want more resources from the remote server.  Still, it's not as efficient as being a little more patient.



So there was this notion introduced in HTTP/1.1 called "pipelining."  Pipelining, the concept there was instead of the client issuing a request and waiting for the reply, the client could - and "pipelining" is a term we've talked about back years ago when we were talking about how to speed up processors, the idea being that you can have multiple things in the pipeline at once.  So a browser could make a query, receive the page, holding the TCP connection up, and then look at the page, and then issue a series of requests in the connection to the server, and then get back a series of responses.



It turns out that there were too many proxies involved on the 'Net which were not bug-proof in the face of pipelining.  The proxies want to work on a single-transaction basis.  And as a consequence, pipelining, although it's technically in the HTTP/1.1 spec, it's disabled by default today in all major browsers.  They don't do it.  They wait for the response to come back, then they issue another query.  That's the only way to reliably get HTTP to work at this point.



Now, the problems with a limited number of connections, which we want to have in order to get performance, but one problem is that that inherently serializes everything.  It means that any resource that was, for example, stalled for some reason, it might be big and low priority, but the browser asked for it, and other, smaller resources that could be served more quickly, they're waiting behind the big one.  So there's a problem with the serialization, even when we've got a mature, statically held TCP connection to make these HTTP queries over.  So that's a problem.



That also means, because we're serializing everything, there's no ability to simultaneously render objects.  We've seen, for example, on web pages where JPGs fill in, and they fill in one, then the next, then this one, then that one, then that one.  And if your bandwidth is sufficiently low, you can actually see the picture sort of render in.  Well, it might be nice if we were able to do more things in parallel.  So that was one of the things that the Chromium guys looked at.



Now, we take it for granted that clients ask servers, that is, web clients ask web servers for everything they need.  But it's worth questioning why that is so. It's the way it's always been.  But think about it.  The server that is sending the client the page, it has the page before the client has it.  And that means, if it looked at the page, it knows what other things it has that the client is going to ask for, if they're not in the client's cache.  So one of the problems with HTTP, which we didn't regard as a problem in the beginning because it was always designed to be a query-and-reply-based protocol.  But there is no concept of what's called "Server Push," the idea of the server pushing things to the client on its own because it has reason to believe the client is going to be getting around to ask for it at some point.  So that would save the time of the page getting there, the client processing it,  figuring out what's there, and then issuing requests that have to go back out.



Essentially, the server is sitting around with its server-to-client bandwidth unused, sitting there just being wasted, time is being wasted, while the page is getting to the client so that the client can look at it and then begin sending requests back.  So if we really look at how the time is spent, we can see that there are ways, all kinds of clever things we can do to compress this whole transaction between the client and the server.



Now, another problem is that the payload itself, the thing that's being requested, a page of text, for example, can be compressed.  Compression, both a compression technology called "deflate" and also more popularly and better, gzip, are now supported by all browsers and servers, the idea being that the client is able to say, in its query to the server, hey, I know about compression, so feel free to save time and speed.  Compress this on the wire before you send it.  So even though the server may not have it stored in a compressed fashion, it can use the gzip protocol to do essentially a stream compression, to compress the stream so that it is much smaller.  Web pages have a huge amount of redundancy in them with all of the tags that they contain, let alone just often English compresses really well because of common words.  But web pages in general, just because they've got so much structure which is highly compressible, that's a win.



So payload can be compressed.  But there has never been any way to compress the query and the query headers or the response headers.  That is, the headers themselves have never been subject to compression.  That just wasn't part of the spec.  It turns out headers have been getting bigger.  Everybody, as we've been talking about, is going crazy with cookies.  Cookies are growing.  It turns out that the headers can vary from 200 to as much as 2K bytes, and they're typically between 7 and 800 bytes in size.  But that can be squeezed way down.



And in the case of, for example, an ADSL line, where you're highly asymmetric in bandwidth, you've got much lower bandwidth upbound than you have downstream, that kind of just the size of the query headers is slowing down every single query because there's no way to compress them.  The other thing that is slowing down every single query is a huge amount of redundancy.  There are headers that never change between a given transaction.  For example, the user-agent.  The user-agent identifies your browser.



Well, if you're sitting there, and the browser is sending off a whole bunch of queries to the same server, it's not changing.  So the user-agent data is never changing.  Yet every single query has a user-agent header which is highly redundant.  The host header is also not going to change, where it describes - it says www.google.com, that's going out.  Even though we have a connection to Google's IP, we're still declaring this is going to www.google.com, and again is highly redundant, as is the accept header that tells the server what formats the client is able to accept the responses in, very redundant and uncompressed.  So there's just a lot that can be done to fix the protocol.



Now, again, as I said, this has been known for about a decade.  There was some work done on a next-generation TCP.  It wouldn't replace TCP, but it was called SCTP, Stream Control Transmission Protocol.  And the idea would be that, if this had ever happened - and it died on the vine.  There's been no progress on it in 10 years, since 2002.  There's an introduction to SCTP which did make an RFC, it's RFC 3286, which describes what the original goals of the system were.  And the idea would be that, in the same way that UDP - I don't remember the number.  I think it's hex 11 and maybe decimal 17.  That would make - well, anyway.  UDP has a protocol number.  TCP has a protocol number.  One is 6.  Anyway, it's been a long time since I looked at these.  But the idea would be...



LEO:  That's what reference books are for.  You don't need to know that.



STEVE:  Yes.  They would decide - I'm annoyed that I don't remember, but, yeah, I have enough in my head.



LEO:  That's exactly right.



STEVE:  So this would be assigned a new protocol number.  And so the browser would send off, on top of the IP protocol, it would embed in the IP packet this SCTP packet, much as right now we embed a TCP packet within the IP packet, and it would define a new protocol.  And one of the things that this protocol would offer is the concept of multiplexed streams and stream-aware congestion control.  So the idea would be, you'd establish a connection from the endpoints.  And then the protocol itself would understand the idea of independent streams of data sharing that same connection.  We have nothing like that now in our protocols.  We've got - they're very simple - UDP and TCP.  And if somebody wanted to do that, they would either have to come up with a next-generation TCP or add something on top.  And that's what SPDY does.  We'll talk about it in some detail in a second.



But the problem, of course, with coming up with a brand new protocol is nobody else knows about it.  None of the routers know about it.  Now, you can argue that a router probably doesn't care.  It's routing IP packets and is largely agnostic to the contents of the IP packet.  So it could contain any - the IP packet could be the envelope containing any interior protocol.  But our home routers do care.  NAT routers are protocol-aware.  I mean, that's what they're doing.  They're needing to understand ports in order to handle the whole NAT routing job.  And IP packets have IP addresses, but they don't have ports.  Ports is an abstraction that lives inside that packet, if it's carrying a UDP or TCP or some other oriented protocol.  So it would hugely impact our existing infrastructure if someone tried to just float some brand new protocol because it would make browsers faster.  And thus this thing died, even 10 years ago.



Then there was some work done on how HTTP would run on top of this.  There was a different thing called SST, which is Structured Stream Transport.  It had some of the same problems.  And then there was something called MUX and SMUX, which they stopped working on that about in '07.  Nothing's really happened since then, as I recall.



So there has been an awareness that we need something better.  There is clearly pressure with the increasing size and complexity and, well, and just the fact that we'd like our Internet experience to be much more active, much more interactive.  We're sort of getting to the point where we're seeing storage in the cloud, services in the cloud, applications running in the cloud, applications also being spontaneously downloaded in script into our browsers.  But these are wanting to be very interactive.  So we really want the best utilization of the bandwidth between us and the servers that we're connecting to as possible.



So SPDY comes along.  SPDY has the goals of achieving a large reduction in page load time, that is, latency.  "Latency" is the word the guys on the team use because what they want is just, if you're using a browser, for example, that doesn't understand SPDY, with a server that does, they would like there to be a dramatic difference in experience with a SPDY-aware browser.  And frankly, if this can - they're going to make the server open source.  One can imagine maybe Apache will grab some of the code and upgrade themselves.  And then that'll get incorporated into some of the Unixes and Linuxes, and that'll put pressure on Microsoft to support the SPDY protocol on IIS over on the Windows-based servers.  And when that happens, Google will have Chrome.



Well, that means all the other browsers are going to immediately have to support SPDY because, given what I am about to tell you, this thing really does work.  And so imagine going to a website, you go to Facebook, and in one-third the time the page has snapped up, and it feels different.  It feels dramatically faster using a browser that knows SPDY.  Well, all the other browsers are going to have to support it in order to compete.  So the goal is a large reduction in page load time.  They wanted, in the design of this, to minimize deployment complexity, which is to say just run on top of TCP.  Don't reinvent TCP.  We can't at this point.  It would break all of our NAT routers.  It would break switches at the other end that are running the big server farms.  The routers in between don't care, but we still couldn't get our data back and forth.



So use TCP.  We have a huge investment in it.  It works.  I mean, and it works beautifully.  Once it gets started, it's very efficient.  It just isn't efficient to be used for little tiny requests and queries that are then dropped.  And they wanted no changes required from the website.  That is, they wanted to be able to introduce this protocol support in the server, and have a browser that was aware, and all the magic happens between the two of them and on the line in between.  But the same page ends up being rendered at the client.  The same content is sourced at the server.  Which is beautiful because, again, this really does ease adoption.



So, more specifically, they've come up with a protocol which allows concurrent HTTP requests to run across a single TCP connection.  And I'm going to explain how they've done that.  But so what SPDY gives us, and, I mean, this is working now and has been benchmarked, is concurrent requests across a single connection.  It absolutely always compresses headers, the so-called "metadata," the stuff that isn't actually [indiscernible] cookies and expires headers and the user-agent and the host headers and all that.  That's always compressed in SPDY protocol.  The redundant headers are not part of the protocol.  They don't appear.  They're eliminated.  And the unnecessary ones, also.  There are some headers which were needed for the non-SPDY protocol which SPDY's operation inherently eliminates.



And SSL is always going to be the underlying transport protocol.  So they're just assuming that - they recognize that we're headed to a world where we're going to have point-to-point security, so let's strongly enforce SSL connections so that we just know that if we've got a browser with a SPDY connection, it will automatically be using SSL.  And that's also important because, if you had some proxies that were trying to parse your traffic - remember, for example, that ISPs are often running caching proxies, the idea being that they're able to serve common website pieces to their own users more quickly so the query doesn't have to go out on the Internet, off to a remote server, if it's in the ISP's cache.  And that lowers their costs because they're able to use their internal bandwidth to satisfy their clients, not have to send stuff out on the Internet.  And that's bandwidth they pay for.



The point, though, is that that means that there is, even though we don't see them, we don't see their IP addresses, we're not aware of them, they're there, caching what we do.  That's, for example, the reason that I have ShieldsUP! initiate an SSL connection in order to bypass the proxy to get the user's IP address.  I don't want to test the security of the proxy.  I'm being asked to test the IP of the user.  So I do that specifically for proxy avoidance.  And SPDY will run over SSL similarly for proxy avoidance so that it blinds proxies that otherwise would sort of see something that looks like an HTTP query but not quite.  I mean, it would really foul things up.  So this is a good thing for them, too.



The other thing that SPDY does which is huge is it enables the server to initiate communications with the client, that is, to push data to the client whenever possible, not force the server to sit there, knowing what the client is going to get around to asking for as soon as the query gets back to it, but to be preemptive, which is a huge win because obviously the best response we're going to get is if we can get the TCP connection ramped up, keep it running at that speed, and keep it full because time that isn't being spent sending data is just time that we have to wait for the page to end up rendering.



So conceptually we understand how we have a layered set of protocols.  We've talked about just now how IP packets are envelopes containing TCP packets, and within the TCP protocol is SSL, which is an application protocol that runs on top of TCP.  Well, SPDY will run on top of SSL, and HTTP runs on top of SPDY.  So essentially what we've done is we've sort of - we've shimmed in between SSL and HTTP, we've shimmed another layer of protocol stack.  What that means is that nothing below needs to change, and nothing above needs to change, as long as the client and server are aware, they've come to an agreement that they both understand SPDY version whatever, and negotiated that, and then are able to take advantage of its features.



So specific features are it supports the multiplexing of streams.  The idea is that once a TCP connection is established, the protocol is frame-based.  So we're used to thinking in terms of packets.  We have to sort of disabuse ourselves of that.  Think in terms of TCP just being a stream.  Now, the fact that TCP breaks that stream into packets to get where it's going, we understand, but we're going to ignore that for the moment.  Now we're seeing at our end a TCP connection, and we're just feeding it data.  So we break that data into frames ourselves.



Every frame has an eight-byte header which describes the balance of that frame.  Frames can either be control frames or data frames.  In the case of a control frame, the very first bit is a one.  Data frames have their very first bit as a zero.  Then for a control frame there's a 15-bit version number, which ought to be enough, and then a 16-bit type which identifies the type of frame.  Then there's eight bits of flags in the second block of 32 bits, and 24 bits of length.  So that specifies the length of the payload, followed by the payload.  Data frames, as I said, have that first bit is a zero for data.  Then they have a 31-bit stream ID.  So that means we know that 32 bits is 4GB.  So 31 bits is 2GB.  So we have two billion possible streams which can be individually tagged and flow over the connection.



However, even streams always go from client to server, and odd streams always go from server to client.  And the stream IDs always increase monotonically in each direction.  So as the client is initiating new streams, it's numbering them 2, 4, 6, 8, 10, 12, and so forth.  As the server is creating streams, it's 1, 3, 5, 7, 9, and so forth, both in upwards directions with the proper evenness and oddness.  And so the concept is that we have a single TCP connection.  Now, it's freaky when you say, wait a minute, but wouldn't more connections give me more bandwidth?  But really that is not the case.  We're used to thinking that if we make more connections, we're going to get more bandwidth.  But if we make more connections to the same place, those connections absolutely are going to compete with each other.  So all you do is lose, if you make more connections. 



So this system is one connection between client and server.  But because it lays on top of TCP, it lays this frame abstraction, and frames have stream IDs, and so obviously the client is able, over this single TCP connection, it's no longer just sending queries directly on the wire.  Instead, it's packaging them in frames.  So a single query lives in a single frame.  By convention of SPDY, the query headers are always compressed, so that's going to be much smaller.  But think about it.  Now what that means is that it's able to create a whole batch of very small queries, stacking them in TCP, not thinking about packets.  We're not dealing with packets now.  These are frames which may well cross packet boundaries.  But it means that we're able to pack the TCP packets with much more.



So what we get is a much higher level of utilization of the bandwidth we have in both directions.  The server is similarly unconstrained.  If it receives a burst of queries, it's able simultaneously to answer them all, and it does.  It's able to pull them and as quickly as it can to begin multiplex feeding them back on the line, which means every single outgoing packet is going to be filled.  Even if these things are small, and normally you'd have short packets, and then you'd be waiting for acknowledgment and so forth, here, because this multiplexing is such a huge win, because we're able to essentially fill every single packet to the brim, TCP works much more efficiently that way, and the server is able to just send all this stuff at once.



Now, they solve the problem of some things being more important than the other by having two bits assigned for priority.  So the client is able to set a priority on its query:  0, 1, 2, or 3, 0 being the lowest priority, 3 being the highest.  It's not something that has to be honored by the server.  But it typically would be.  And the idea would be that, because now we have this multiplex, it might very well be that the client says, oh, I need the scripts for my page more importantly than I need pictures that are going to be loaded because we need the scripts in order to get things running, or I need other important pieces.



So the client is able to prioritize its queries, even while sending them all in a big burst along with the lower priority queries.  And the advantage of that is that it has to manually hold the lower priority queries back, knowing that it needs the higher priority ones first.  It's able to just dump them all in this multiplex connection, knowing that the server will receive them and will use the available bandwidth to send all the highest priority queries back, the responses to those queries back before it gets around to sending the lower priority ones.



So it's a relatively straightforward, simple addition to the existing TCP protocol.  It essentially does not hugely change HTTP at all.  It compresses the headers.  It eliminates some, makes some slight rearrangements so that a SPDY-aware browser knows how to issue these queries and of course knows how to use its one connection between it and the server in order to saturate.  And in the benchmarks which Google did, they took the content of the top 25 benchmarks and simulated a cable modem that had a 4Mb downstream bandwidth from the server to the client and a 1Mb bandwidth from the client upstream to the server.  The average load time of these 25 websites, the top 25 on the Internet, was 2.348 seconds over HTTP.  And if you think about it, that's like, okay, you go to a big page with that kind of bandwidth, less than 2.5 seconds, 2.348 seconds.  Switch to the SPDY protocol, 0.856.  So from 2.34, so that's like 2.4, to 0.8.  So it's about a factor of 3:1.  It takes, I mean, it's dramatically faster.  And you're getting maximum bang for your bandwidth, setting up a single connection and just being smarter about the way we use the packets in order to adapt it to the nature of today's pages.



So I've got all my fingers and toes crossed for this.  I hope that they get this thing nailed down.  I hope that their open source server, as soon as it's ready, gets adopted.  We need it somehow to start getting deployed.  I mean, I'm sure Google's servers will switch to it.  And suddenly browsers that are SPDY-aware will be able to run all Google services much faster.  And as soon as other sites see that, they'll say, well, we need servers that allow our site to be running three times faster, one-third the latency to bring the page up.  So, I mean, they've demonstrated it.  It works.  The protocol's here.  There's really no downside, no new hardware needed anywhere.  We just need to use SPDY-aware browsers.  And I'll bet you we've got SPDY in our future.



LEO:  SPDY in our future.  That's what we should have called this show.  So just to reiterate for people who tune in late, Chrome does this automatically.  Anything based on Chromium would, as well.  So if you're on Linux and use Chromium, I presume that would do it.



STEVE:  Well, when they incorporate it.  Right now it is still in test mode.



LEO:  Oh, okay.  So you're using SPDY 1, the earlier SPDY.  Or no.



STEVE:  SPDY has not been deployed yet.



LEO:  Oh, so we haven't seen this at all.



STEVE:  No, it's in the Chromium galaxy somewhere, down off in some project, but is not part of the main production code.



LEO:  Got it, got it.  And then somebody was saying in the chatroom that, if you have Firefox, you can enable SPDY.



STEVE:  What?



LEO:  But I think that must be wrong.



STEVE:  That would be wonderful, but I'm suspect.  I would think someone could come up with their own SPDY converter.  No, no, no.  The browser needs to be aware of the things it can do, that it can send - oh, and I forgot to mention, also, that - do I not have it in my notes?  Did I skip those notes?



LEO:  In Firefox 11 you can enable it in about:config, they say.



STEVE:  Oh, yay.



LEO:  It's not a full, maybe not a full implementation.  And of course, as you mentioned, the server has to support it.  It has to be at both ends, obviously.



STEVE:  Right.  So "Multiplexed Streams" we get.  "Request Prioritization" we get.  "Header Compression" we get.  We also get "Server Push" and "Server Hint."  The server is able to push whatever it wants to.  And there's a new header.  It's "X-Associated-Content."  So it tags the thing it's sending, without even being asked for it, as content associated with the following query.  So that allows the client that suddenly receives something it didn't ask for to know why it got it.  And then there's - so that's called "Server Push," where the server is able to just proactively, preemptively send something, which to me makes so much sense because the server does have the page.  It's waiting to be asked for all these other things.  Why not just go ahead and get going?



LEO:  Right.



STEVE:  And so this allows that.  And the other thing is, because there's some concern that maybe that's a little too aggressive, then there's a little sort of a softer version which is "Server Hint."  And so that uses a header called "X-Subresources."  And that enumerates all of the resources that the page is known to contain.  So the server is sort of - it's suggesting to the client that it should ask for the following resources in cases where the server believes that the client is going to need it.



LEO:  So I've entered this Chrome URL that they put in the chatroom, chrome://net-internals/#spdy.  And it says SPDY Enabled: true; Use Alternate Protocol: true; Force SPDY Always: false; Force SPDY Over SSL: true.  So this is kind of a temp - this is kind of an early release version of this.



STEVE:  So it's kind of in there.



LEO:  It's kind of in there.



STEVE:  But it's in a production Chrome browser.



LEO:  Yeah, this is in my regular Chrome.  Maybe you have to hit this to turn it on?  They say you could turn it on in Firefox 11.  It will be on by default in 13.  SPDY's coming.



STEVE:  Wow.



LEO:  Clearly.  And right now it looks like only Google, of course, is the only server supporting it.  But so you can actually view live SPDY sessions here like this in the browser.  This is in Chrome.  And so as you browse around in Chrome, you'll be able to see what else is using it, I guess.  Pretty cool.



STEVE:  Very cool.



LEO:  Yeah.



STEVE:  Well, that's our future.  And boy, it's fast.



LEO:  Yeah.  That's exciting.



STEVE:  Our future is speed.



LEO:  Our future is fast.  Yeah, you know, it's funny because Google has always said - this is their philosophy.  They said people - in fact, they did a study that came out last week that said people will only wait, like, 25 milliseconds before a site - a quarter of a second, 250 milliseconds, a quarter of a second before they go, nah, it's too slow.



STEVE:  To switch away.  I'm going to go somewhere else.



LEO:  So it really does become important.  And it's something we've been battling with on the new TWiT site is speeding it up a little bit like that.  Maybe we'll implement SPDY.  Steve Gibson is at GRC.com.  That's his website, not yet SPDY-fied, but it will soon.  Right?  No.



STEVE:  I don't know.  Would like to.



LEO:  You're using IIS; right?  You're still using IIS.



STEVE:  Yeah, I am.  It'll be when Microsoft - I've got such a huge investment in my own assembly language glue all over IIS.



LEO:  Right, right.  You can find him there, though.  At GRC.com is where SpinRite is, the world's finest hard drive maintenance and recovery utility; all those free utilities he gives out, as well.  And this podcast, 16Kb versions for the bandwidth-impaired; transcripts, as well.  GRC, Gibson Research Corporation, GRC.com.  His Twitter handle - if you follow him you will get good stuff, I promise you -  @SGgrc.  And you monitor people who are sending you stuff via the "@" sign.



STEVE:  Yeah.  If they mention @SGgrc, that's how I get all of these neat little tweets that are incoming, and that's how we found out about the guy that did the math in the 34 trillion years to crack 256.  Yeah.  I do keep an eye on that, so I'm accessible that way to our listeners.



LEO:  Yeah.  And then of course we have all of the audio and video versions except that 16Kb version and the transcript at TWiT.tv.  And you should watch live.  Now, people are tuning in, saying, well, wait a minute, wait a minute, this is Tuesday.  So normally we do this on Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1900 UTC, at TWiT.tv.  But because of some, I don't know, some shindig Apple's throwing tomorrow, we flip-flopped you.



STEVE:  Eh, what's up?



LEO:  Something going on tomorrow.  So tomorrow, in the normal Steve Gibson time, actually starting at 9:30 Pacific, 12:30 Eastern, we'll be doing coverage of the Apple iPad announcement.



STEVE:  Ooh, good to know.



LEO:  Yeah, 9:30 a.m.  Doors open and the speech begins at 10:00 a.m., so we thought we'd start a little bit early.  Tom Merritt, me, Sarah Lane of iPad Today, and Alex Lindsay from MacBreak Weekly will be there.  Andy Ihnatko will be on via Skype.  And then we do have a friend, I don't even want to say his name in case Apple uninvites him...



STEVE:  Don't.



LEO:  ...will be there.  I don't think they'll uninvite him.  He's the editor in chief of a major Macintosh magazine.  Anyway, he'll come out after and talk to us and maybe, if he can, get us into the demo room because they often have a demo room.  So all of that tomorrow instead of Security Now!.  Thank you, Steve.  I appreciate your letting us move.



STEVE:  My pleasure, Leo.  Always a pleasure.  And we'll be back to Wednesday next week for a Q&A, so GRC.com/feedback.  Send me your thoughts and comments, and we'll get to them next week.



LEO:  Absolutely.  Thank you, Steve Gibson.  Take care.



STEVE:  Thanks, Leo.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#344

DATE:		March 14, 2012

TITLE:		Listener Feedback #139

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-344.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  We've got a lot to talk about.  Not just coffee, not just Vitamin D, not just health, but even some security news, the new Microsoft updates for Patch Tuesday.  We'll talk a lot about SPDY and answer 13 questions from you, our listeners.  Security Now! is next.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 344, recorded March 14th, Pi Day, 2012:  Your questions, Steve's answers, #139.



It's time for Security Now!, to protect yourself online.  Mr. Steve Gibson is here, our Explainer in Chief.  This is Episode 344, and we thought we only really would have enough security news for about a dozen shows.



STEVE GIBSON:  Yup.



LEO:  Were we wrong.  Hey, Steve.



STEVE:  Hey, Leo.  It's great to be with you again, as always.  And you know, normally before we begin, I ask you if you're recording.  And I didn't ask you this time, but...



LEO:  I am recording, sir.  I haven't forgotten to record this show in ages.



STEVE:  And actually, except for the live viewers, everyone listening already knows the answer to that question, when you think about it.



LEO:  That's true.  That's true, because it's recorded.



STEVE:  Because they wouldn't be hearing it if the answer were not yes.



LEO:  But the good news is I am.  You know, it's funny you asked that because a couple of weeks ago we did forget to record Game On!, which is a very expensive, elaborate show with expensive hosts and expensive production values.  And the whole thing was not recorded.  Oh, boy.  My heart broke.



STEVE:  And you, when we connected initially here, you said "Happy Pi Day."



LEO:  Yeah.  And it's not just because I have a pecan pie in my hot little hands.  It is actually because this is 3.14 that we're recording on.  Actually, 3.1415 - in 2015 will be really the true Pi Day, won't it.



STEVE:  Ooh.



LEO:  Ooh.  This is only 3.1412.  But three years will be the real one.



STEVE:  And I guess way back in 3.14159 something...



LEO:  But did they even know about pi?



STEVE:  They probably weren't aware of the significance of that date.



LEO:  They didn't know.  They actually do celebrate Pi Day now in schools.  And before the show my daughter Abby, who's now 19, came in, and she - in fifth grade they had a contest, in fifth grade, so what was that, eight years ago, for who could memorize pi to the most places.  And she just ripped it off about, I don't know, it was about 25, 30 places.  She says, "I'm not sure about the last few places."  The one who won knew it to 50 places, five zero places.



STEVE:  Yeah, we had a guy in high school who would annoy us.



LEO:  It's annoying.  It's annoying.



STEVE:  The first time it's fascinating.  Second time it's like, okay, yeah, Rick, we have already heard you do that.



LEO:  Well, that's why we have Pi Day.  Once a year, on March 14th, you get to do it.  So Happy Pi Day.  And you know what the best part about Pi Day is, we all get to have pie.  And in fact there's a new pie shop around the corner, the All American Pie Company.



STEVE:  Before you eat that, Leo, before you eat that, you may want to listen to some of my news.



LEO:  Oh dear, oh dear, oh dear.  Well, we are having pie for lunch, and the entire Twit Brick House will have hundreds of pies.  But maybe you'd better tell us why.  Anyway, we've got news, and this is also a question-and-answer episode.  So we have questions for you from our audience.



STEVE:  We got a bunch.  I've got 13, which is more than usual because some are just little announcements and updates and things.  So some of them are going to go quick.  But I just kept running across interesting tidbits that I thought, oh, I have to share that.  Oh, I have to share that.  So we'll do a lot of sharing.



LEO:  Well, let's get started.  Let's get going.



STEVE:  Okay.



LEO:  Is there anything big happening in security this morning?



STEVE:  Is anyone sponsoring this show, by the way?



LEO:  Yes, Ford.  The Ford Motor Company.



STEVE:  We'll talk about them in a little bit?



LEO:  We've got time.  We've got time.



STEVE:  Okay.  So first of all, I got so carried away with the technology of SPDY that I failed to update myself on the deployment of SPDY.  And so of course I was deluged with tweets from people who said, "Hey, Steve, thanks for the info.  Now I know what it is that my Chrome browser has had since last April."



LEO:  Aha.



STEVE:  It's like, uh, oh, that's nice.



LEO:  Well, we talked a little bit about that, about enabling it and everything.



STEVE:  Well, yeah.  And during the show we saw that it was there.  But in fact it has been, and Google has deployed it throughout their entire server farm.  I saw something, but it was a bit dated, that talked about how maps might not yet be using SPDY.  But all the other regular Google services do.  There is a funky "chrome://" URL you can put in which will show your SPDY sessions.  And sure enough, if you go poke around Google anything for a while, and then go open a tab and put this SPDY sessions URL in [chrome://net-internals/#events&q=type:SPDY_SESSION%20is:active], you see an enumeration of all of the connections which were SPDY-enabled between your browser and Google.  And just last week Twitter added SPDY support to their site.



Also Firefox 11, has just been released, and it has SPDY in it, but it's not enabled by default.  So people who are staying current with Firefox - I'm famously not, I'm just staying where I am, back on 3.something.  But people who are getting 11, I'm sure somewhere in there - oh, in fact, I've got it in my notes a little bit later is where you go.  You've got to go into the about:config and find it.  But you can turn SPDY support on.  Let's see, what else do I have?  Oh, it will be enabled by default in Firefox 13.  So they're putting it in 11, but not turning it on, to sort of step into this gently.  The Kindle Silk browser in the Kindle Fire has been using SPDY all along.



LEO:  Was that the speed-up stuff in Silk?  Or was there other stuff?



STEVE:  There's other stuff, too.  They're explicitly doing their own stuff.  But when they were looking for performance, they thought, hey, let's use SPDY connections between the Amazon backend and our Kindle Fire.  So that's there.  Also there's a mod-spdy module for Apache that's been around since December of last year.  So only for about four months, but still it exists.



Now, it's worth noting, though, that to say you have SPDY and to actually be getting the advantages are two different things.  So I don't want people to get too excited, nor too disappointed if they turn it on and don't see things speed up, the point being that, if you think about what we learned last week, using SPDY, that is, leveraging SPDY requires much more than just changing the protocol and announcing at each end that, oh, we're going to use a SPDY connection.  And this is why I'm a little suspicious of, for example, the depth of implementation that Apache may have gone to.  I'm not meaning to cast any aspersions on Apache.  Maybe they really did reengineer their server around SPDY.



But my point is, that's what it kind of takes.  You need to add a whole bunch of server-side intelligence to back up the support of the protocol in order to, for example, provide - to look at the page you're sending out and then to provide client hints of the resources that the client is probably going to want, or to automatically be sending down to the client in advance using the server-push features the things you know the client is going to ask for.  So just saying that, oh, yes, we're SPDY-enabled, doesn't necessarily mean that you're going to get the same kind of performance that Google's testing did.  And you know on Google's benchmarking they would have taken advantage of all that the SPDY protocol had to offer because that's of course what they were trying to measure.



So my guess is that we're going to see - and first of all, I'm super happy that this is happening because this just represents the evolution of the web.  Also it's worth noting that Google's efforts at deploying this are succeeding.  I have seen people on the 'Net saying, wait a minute, we already have it, why aren't we hearing more about it?  So of course with this podcast we're beginning to help make that happen.  But the next version of the HTTP protocol - remember that we started off with /1.0.  Then we went to HTTP/1.1.  Well, 2.0 is in the works.  And it is probably going to incorporate SPDY as part of the protocol.  So that moves us into mainstream standardization, which is great.  I just don't see a downside to it at all.



LEO:  That's great.  That's great.



STEVE:  So I wanted to catch everybody up on that.



LEO:  There's the latest on SPDY.  You know, we probably should mention, before we go any farther...



STEVE:  Oh, yes, I meant to, yes, yes, yes.



LEO:  For the last 36 hours, should be gone by now, if you went to any site that had TWiT.tv in the domain name, you'd get this warning.  This is the Chrome warning, but there's also similar warnings from Firefox, Safari.  If you had antimalware software you might have gotten a similar warning from NOD32 and so forth.



STEVE:  Even a Google search turned up a warning link in your results.



LEO:  Google uses a service, there are actually a number of services that track websites.  I think Google does their own thing, but there are other bad software/malware databases.  The warning, for those of you listening, says "Something's not right here.  TWiT.tv contains malware.  Your computer might catch a virus if you visit this site.  Google has found malicious software may be installed on your computer if you proceed."  You can proceed, or you can go back.  They say, "We've already notified TWiT.tv we found malware on the site."  No.  The notification comes from about the eight millionth person who sees this and says - tweets me and emails me.  And by the way, I'm glad you do, thank you.



And we worked on this quite a bit.  This happens about once a month.  And at first I was about to blame code on our site or a problem, something badly done on our site, or our site wasn't fully secured.  And then I had a little - and I want to run this by you.  I had a little come to Jesus meeting with Bear, Mike Taylor, who's one of the best sysadmins in the world, a part-timer for us, although his part-time job is often full-time, as it was yesterday.  Bear and Chris Dieterle, who works with him, as well, immediately went in, they rooted out the malware, they modified the code that was the exploit.  Often what happens is you have to figure out, well, where did the exploit happen, and get an updated module.



STEVE:  How'd it get in.



LEO:  Yeah, how'd they get in.  So there's two things you need to find out:  how'd they get in, and what did they leave.



STEVE:  And what did it do.



LEO:  Yeah, exactly.  Now, in this case we were able to get rid of the malware very quickly.  It takes a little longer for Google to clear this.  They only update this warning every 24 hours.  But there is a window of opportunity.  If you fix it fast enough, you don't get in this.  But because - what happened is we found it, we fixed it, and then inadvertently we reenabled it, the malware.  And we thought we'd fixed it and there was a miscommunication, and somebody on my staff turned it back on.  And so it ran all yesterday, Monday, what is it, this is Wednesday, so it would have run all Monday night.



STEVE:  And then got picked up.



LEO:  And then Google put up a more serious warning that is harder to clear, takes 24 hours to clear.  So that's why the warning persisted for so long.  It is gone now.  But the malware was removed very quickly, and the exploit I believe has been patched.  So I asked Bear, I said, "Well, Bear, this is not acceptable.  Who do I fire?  Who do I blame for this?"  He said, "Leo, this happens all the time."  He said, "You and every other site is hacked constantly.  What usually happens is the minute we get word, usually from somebody saying, hey, there's a malware alert on your site, we'll go in, we'll fix it, problem solved, move on.  Because of the failure here, it lasted longer than it normally does, so you became aware of it."



He said, "But we're doing this at least monthly, and it's not just your site."  And Bear works on a lot of very well-known sites, has friends that work on other very well-known sites.  He said, "The bigger your site, the more often this happens.  And anytime a site is updated in any way, it's likely that you're going to get another exploit."  I said, "Well, what's the problem?"  He said, "PHP is the problem."  The nature of PHP, you remember in the good old days of CGI scripts you had a special directory that was specially permissioned that code could run out of, and nowhere else could it run.  It can only run from the web server.



PHP is designed to run and be executed from any directory, any time.  So if somebody can modify your file system, they can put a PHP script in an arbitrary folder and then point their browser to it and execute it.  That script can then install malware.  So that's very commonly how it gets exploited.  And it's in the nature of PHP.  And he said, "There's no one to fire here.  You can blame us all for not getting this cleared sooner, but we do this all the time."  I said, "What?"  He said, "Every site is being hacked all the time.  And there's not much you can do about it except be very proactive about scanning it on a regular basis."  He said, "Most big sites have at least one, if not more, full-time employees whose only job is to look for file system modifications, be checking the log, constantly vigilant against this.  It's the only way to prevent it."  Now, you are in a special case, Steve, because you've written all the code on your site.  I bet you it's CGI scripts.  It's all...



STEVE:  No, actually, it's all assembly language, and it's pre- and post-server filters and back ends.  So it's actually a single monolithic DLL so that I don't have the overhead of loading and unloading and stopping and starting CGI.



LEO:  So that's even more secure.  For somebody to be able to access your file system on your server, they'd have to find a hole in IIS, I would guess.



STEVE:  And there have been some.  But I have something - I have my own web filter which is upstream of IIS, and I scrutinize everything coming in through that, also.  So, yeah.



LEO:  Right. You're much more safe because you're not using off-the-shelf software that people know.  You wrote your own.



STEVE:  I was going to say, and I have a much less exciting site than you do.



LEO:  Well, and that's what Bear said.  Bear said the reason this is happening more is because you're more popular.  He said - I want to name names.  Well, I'll give you an example.  A friend of his - I don't know if I should say this, anyway, a very, very, very, very well-known site - does this for them.  And he said they're hacked daily.  And there's not - and even though that this site has ample resources, let's put it this way, the resources of the entire federal government, they still get hacked all the time.  It's kind of the nature of the beast.



I was ready - I said, "But no, wait a minute.  You can secure a site, can't you?"  He said, "No, all you can do is constantly monitor it."  So, and people are saying, well, is it because you've taunted Anonymous?  No, has nothing to do with it.  It's not, was not probably targeted at our site.  It was some scanner that's running all the time; right?  And there's many of them.  I'm sure there's thousands of scanners running on the Internet constantly that are looking for these kinds of exploits.  So the minute a modification is made to your site that opens a hole, you're going to get exploited, period.



So in any event, it's probably not something that was targeted at us.  It's just this is part of doing business on the Internet.  A public server is always going to be attacked all the time.  Our code is modified quite a bit, but it is in fact most of it commonly well-known code in PHP.  And so it's a full-time job just to secure it.  And in fact this happens all the time.  Now, the good news is, well, first of all, I think it's great that these browser alerts are happening because it prevents people from going into sites that have been compromised.  And all the browsers do that now.  You should, if you see it, as much as you might want to watch TWiT, you should absolutely back out.



STEVE:  Oh, I'll bet you that not a single one of our Security Now! listeners is going to say, oh, yeah, I don't care that there's an infection there.  I'm just going to go through anyway.



LEO:  Well, a number, yeah, a number of our - I have heard from a number of people who did.  The good news is the exploit was a very old Java exploit, and I'm sure that everybody who listens to any of our shows knows enough to keep their system up to date.  So it's highly unlikely that anybody had any malware executed on their system.  However, you should, as always, you should be proactive, scan it.  And really, seriously, I understand.  If you see this on any site, but I understand if you see it on our site, it's fine to email me, tweet me and let me know, and not go in.  Please, back out.  It will be cleared as soon as we've cleared the malware.  It does take, unfortunately, if you don't do it right away, it takes longer to get that cleared, 24 hours to get that cleared.  But it is cleared now.  If you're still getting it, just restart your browser, you shouldn't see it anymore.  And I apologize.  But apparently there's no one to blame.  It's just the way of the web.  Does that sound right to you, Steve?  Do you believe it's possible to fully secure a site?



STEVE:  Yes, I do.  It's just math.



LEO:  That's what I thought.



STEVE:  Yeah, it is possible.  It's probably not convenient.  If you restricted the execution rights of the directories for scripting, then you wouldn't be able to load things in default directories.  I mean, you wouldn't be able to be nearly as casual as it's convenient to be.



LEO:  Well, you secure your site, so we know it's possible.



STEVE:  Yeah.  And I would argue it is...



LEO:  Some of your security I would say is through obscurity because you're not using commonly well-known code.



STEVE:  Well, that's not obscure.  It's just smart.



LEO:  Well, but if your code were published on the 'Net, it'd be more likely to be a problem.  But the way you've structured it, of course, makes it much less likely.



STEVE:  Well, but I mean, in defense of your approach, you would never have the site you have if it were up to me.  So you would never be hacked, but you wouldn't have all the features you have.



LEO:  Right, right.



STEVE:  And it would take about three lifetimes for me to implement everything you have in a way that would make me happy.



LEO:  Well, we'd have to custom program everything, of course.



STEVE:  For example, you're pulling libraries, third-party libraries from their servers on the fly into the pages of the visitors, of the people who are visiting you.  Not you alone, I mean, that's common practice now.  I see this, and when I see it I just cringe because I see some site that is loading JavaScript on my pages from a URL of some other domain.  And I think, well, okay, yeah, it's convenient for them.  The theory is that, when that library is updated, they're automatically updated.  The problem of course is, when that library is compromised, everybody using that is compromised.  So, I mean, what's happened is we've gone for convenience over security.  And this show is all about how those two, there's a constant tension between convenience and security.  And the fact is, to do it right would end up meaning that it was never done at all.  And that wouldn't work for you either.



LEO:  So one of the questions I had is, well, why is it that we get this malware warning and nobody else does?  And he says, well, there's a number of reasons.  First of all, if you have a full-time person doing this, you can clear this before the malware alerts pop up.  Second of all, some big, most big sites have an inside line to Google and an inside line to the malware sites, the stop adware sites, and can - see, Google does not, despite what it says there, notify us.  The way we get notified is by the malware alert popping up, and then we act upon it.  Most other sites will get an internal - this is what I'm told - an internal notification, hey, you've got a problem.  They'll fix it.  And that's why you don't see these.



The truth is, and we knew this about banking, banks are hacked all the time.  It's bad business to talk about it.  Sites are hacked all the time.  It's bad business to talk about it.  In fact, it's probably a mistake for me to talk about it because it just attracts attention and more hacks.  The best thing to do, if you can, is act as if you're never hacked, you're a hundred percent secure, and just don't tell anybody.  But that's not, as you know, how I operate.



STEVE:  Well, and it doesn't work in our model, where we have such vigilant listeners and viewers, and they're tweeting, hey, what's happened here?



LEO:  Right.  So one of the things that we are going to do, and I think we should have done this, but we couldn't afford to, is we are actually hiring - I'm hoping it's going to be Bear.  We're going to extend him an offer.  But we're hiring a full-time sysadmin to monitor this at all times.  It's a fairly high cost. People like Bear are not cheap because they're really good.  But it costs us money.  We lost considerable audience yesterday.  People didn't watch live, and we lost considerable ad revenue, as a result.  So we can't afford to have these - not to mention it's embarrassing.



So there's the story.  I do feel like - Bear is in the chatroom, if people have questions for him or want to get more clarification on this.  But I do feel like this is something that's a little bit the dirty little secret of the Internet.  And I was, when Bear told me this yesterday, I was flabbergasted.  I thought that we were doing something wrong, that this was something we could fix.  And he said, well, it's just the cost of doing business on the 'Net.  Unless you're Steve Gibson.



STEVE:  Yeah, well, again, or unless you expend a phenomenal amount of resources in order to keep it from happening.  And unfortunately - for example, PHP, it's very nice and very convenient and horribly insecure when it's not very carefully deployed and managed.  So it's a powerful tool.  But with that power comes responsibility.  And, I mean, the whole model, I mean, we've talked about this.  The idea, for example, that someone can send through a forum an SQL backend database command which will be executed by the server when it delivers that page, I mean, that's insane.  It's insane that it was ever allowed to be done that way.  Why was it?  Because it was convenient for the people who were implementing it.



So there are major decisions which have been made which were absolutely wrong, by policy, not by mistake.  And this was, for the longest time, this was my argument with Microsoft was they had insecure policies that were causing their problems, like having services that were enabled and running that no one needed.  That was dumb.  And the consequence, we had all these worms for some period of time.  Finally they turned - they put a firewall in Windows and turned it on by default, and all of that problem just went away, bang, oh, it's a miracle.  No, they finally fixed their policy.



So the problem is we're still in a position where convenience is trumping security.  And the idea that your own database would execute commands that your website visitors gave it, that's just nuts.  But the architecture enforces, I mean, it encourages that almost.  And similarly, the idea that somebody could put a PHP script on your server, which your server would then execute, that's nuts.  I mean, that's just crazy to accept executable commands from a passerby.  But the fundamental architecture says, oh, look, here's PHP.  I'm supposed to run that because I recognize the extension on that file.  Just lunacy.  But that's the way these sites are built now.  And they're just not secure by design.  They're secure by constant vigilance, which is exactly what Bear is talking about.  And it's too bad that that's the state of the art, but that's where we are today.



LEO:  And people want to blame Drupal or our web designers, and blame PHP.  And certainly you already expressed the case.  But it is just the way it is.  I mean, it's not Drupal's fault.  It's not PHP's fault particularly.  I agree it was kind of a crazy way to do it.  I long for the days of locked-down CGI script folders.  But, oh, well.  And we are making somewhat of a mistake by talking about it because it does attract attention.  And that brings more attempts to hack you.  And it's funny, Bear...



STEVE:  Well, but also, to the degree that we have other webmasters listening who are thinking, hmm, maybe I need to give some better thought to the security side of this...



LEO:  My point exactly.



STEVE:  The problem, yeah, the problem is that people who are building these libraries, they're doing what they need to.  The problem is the systems are just not secure by default.



LEO:  Right.  And Bear tells me that every time we do this, we talk about these kinds of things, that the server logs show a real spike in attacks.  So there are absolutely people listening who see this as a challenge.  And Bear just said in the chatroom, he says, "I cringe every time you do this."  But he understands that that's what we do, and that's what we need to do.  And that's, I think, one of the reasons Bear likes working for us.  So we will, I'm sure, have a full-time security czar on the site as soon as we can do that.  Moving on.



STEVE:  So last week we moved the podcast from Wednesday to Tuesday to make room for Wednesday.  And I just wanted to touch briefly on the fact that my two first third-generation iPads are sitting in Ontario, California, at the FedEx depot, patiently waiting for Friday morning, when they'll be loaded on...



LEO:  Me, too.  Me, too.



STEVE:  They'll be loaded on a FedEx van and...



LEO:  Mine's right next to yours in Ontario.



STEVE:  Oh, no kidding.  Is that where it is?



LEO:  Yeah.



STEVE:  Oh, okay.



LEO:  I've heard from people who have them in Nashville, but that's the FedEx hub.  And Ontario, it's almost like the town was - you and I know, because we went there for Podcast Expo a few years ago.



STEVE:  Yes.



LEO:  It's the town that was built to be a hub.  It's nothing but big truck depots.



STEVE:  Well, yeah, and it's the Ontario Airport surrounded by huge warehousing from which everything spreads.  And Ontario Airport is a perfect place for freight planes to be coming and going because pretty much nobody else is coming and going there.



LEO:  Right, right, right, it's great, I love it.  So we'll get it on Friday.



STEVE:  And someone said, someone tweeted, "Steve, I didn't think you were a sheep," or something to that effect.  And as if I'd bought into this.  And I've been very clear from the beginning, first of all, I love the iPad.  I think it's - it's my portable platform of choice.  I've got a Fire.  I've played with it.  It just doesn't have nearly the fit and finish, but of course it's one third the price.  For me it's the screen.  That retina screen is all I want, 2048x1536, and I'm done.  I will be absolutely happy to have that.  So it's going to be my little portable pad with that screen.  One will live in the car, and one will live in the house.  And I'm just going to be a happy camper.  Do you know, Leo, by the way, I'm still grandfathered into the original unlimited AT&T data plan.  But I've wondered, as they move to 4G and LTE...



LEO:  Yeah, they'll find a way to get you off of that plan.  I am, too.



STEVE:  Yeah.



LEO:  And what they said, which is interesting, is that they are not throttling the iPad.  Because you know the way they're handling the, quote, "unlimited" data on the iPhone is if you go over 1.5 or 2GB, forget it.  You go down to edge speed.  But apparently they're not doing that on the iPad.  There is a reason to go with Verizon, though.  Verizon has more LTE.  I don't know about where you live, but all...



STEVE:  I'm a Verizon customer.  It was only the fact that the pad was only available on AT&T at the beginning.



LEO:  Well, that's I'm sure why AT&T keeps this unlimited thing grandfathered in.  They're hoping not to lose you because Verizon has a more compelling offer, and they're going to allow hotspotting.  Now, for a lot of people, having a hotspot on your iPad may not be an important selling point.  But the fact is AT&T is not going to allow it, so.



STEVE:  Right.



LEO:  Yeah, as far as I know, they're continuing to do it.  But I can only imagine there's a strategic strike force in the executive offices at AT&T, trying to figure out, how can we get people off this unlimited plan?



STEVE:  Now, you don't know when yours is arriving, so we don't know if there's going to be a TWiT unboxing live video.



LEO:  There will be.  So here's the deal.  Mine says, as yours does, "Before 3:00 p.m."



STEVE:  Okay.



LEO:  I hope they're not lying because I know that that sometimes does not happen.  We have scheduled - we moved iPad Today from Thursday to Friday at 4:00 p.m.  So with any luck - it's going to be very embarrassing if we're sitting there at iPad Today, and no iPads have arrived.  But we have a total, I think, of four or six ordered.  I'm hoping at least one of them will arrive by 4:00 p.m. Friday so we can have an unboxing on iPad Today.



STEVE:  And we have heard that the screen is unbelievable, haven't we?



LEO:  Yeah.  Ryan Block at Engadget was at the event, showed us the screen.  And even on Skype you could tell the difference.  When he zoomed in, you could tell the crispness.  There have been videos, there's a video from Vietnam that is almost certainly legitimate of an unboxing.  But again, I think, I don't - it's pure speculation because I haven't seen it.  But it's my sense that when you see this, you'll say, boy, it feels like you're looking at real objects.



STEVE:  Not pixels.



LEO:  Not pixels, yeah.  So but we'll see.  We'll find out.  Estimated delivery - ooh, look at this one.  That must be an error.  That has to be a mistake.  Estimated delivery March 15th.



STEVE:  What?



LEO:  They do this every time, okay?  I've just got to tell you, they do this every time, where then - so it says March 15th, that's tomorrow, by 3:00 p.m.  Then they will have a little thing that says "Held at request of shipper."  But they haven't said that yet on this one.  It is at Ontario, next to yours.  Got there this morning.  Wouldn't that be nice?



STEVE:  Oh.  Anyway, we'll have it, and I'm done then.  I am a happy camper.  I don't need anything else ever again.



LEO:  Oh, yeah, until the next time.



STEVE:  I don't know.



LEO:  I have a feeling this is - would you use this in lieu of a Kindle?



STEVE:  That will be the big question because I'm reading with my DX, my big Kindle, twice a day when I leave the house to grab a bite of food.  I mean, I love the big form factor.  I found a white one which they no longer make on eBay that had barely been used.  I gave it to Mom this last Christmas.  The prior Christmas I gave her the previous small one.  And so she called that her "little friend," and this is now her "big friend."



LEO:  "Say hello to my little friend."



STEVE:  And she, too, likes it.  I really like it.  And so...



LEO:  Is your mom a fan of "Scarface"?



STEVE:  Mom's been around.  So anyway, so I'll want to see whether the crispness of the text on this so-called "retina display" moves me from the convenience of the reflective Kindle display.  That's one of the things I want to see, is this what I switch to for all of my book reading?  So, don't know.



LEO:  Is the DX screen - how big is it?  That's eight inches; right?  Eight and a half inches, something like that?



STEVE:  No, it's actually - it's a little more.  It's longer than the pad is tall, and a little narrower.  So it's a little more non-square aspect ratio.  But I just - it's very nice having a big page of text.  And one of the restaurants I eat at sometimes turns the lights down too low, which is annoying because of course I need light for the Kindle.  So I used the pad the other day, and it was fine.  But it's just the Kindle is lighter and sort of just easier to - I prefer it for reading books.  But the pad is for everything else.  We'll see if that changes after I have this amazing, amazing screen.



So we're just past the second Tuesday of the month, and we had a very noisy Microsoft update cycle because Microsoft was running around flapping their arms, warning everyone about the problem that we've already talked about a couple weeks ago that I kind of yawned about.  Quoting from Microsoft's own blog post, they said:



"Hello.  Today we're releasing six security bulletins - one critical-class, four important and one moderate - addressing seven issues in Microsoft Windows, Visual Studio, and Expression Design.  We recommend that customers focus on MS12-020, our sole critical-class bulletin, as the March deployment priority.  Here's a little more MS12-020:



"This bulletin addresses one critical-class issue and one moderate-class issue in Remote Desktop Protocol (RDP).  Both issues were cooperatively disclosed to Microsoft, and we know of no active exploitation in the wild.  The critical-class issue applies to a fairly specific subset of systems, those running RDP" - the Remote Desktop - "and is less problematic for those systems with Network Level Authentication (NLA) enabled.  That said, we strongly recommend that customers examine and prepare to apply this bulletin as soon as possible.  The critical-class issue could allow a would-be attacker to achieve remote code execution on a machine running RDP," which they mention is a non-default configuration.  "If the machine does not have NLA enabled, the attacker would not require authentication for access."



And then, finally, elsewhere, Microsoft was quoted saying - or I'm quoting them saying:  "This issue is potentially reachable over the network by an attacker before authentication is required.  RDP is commonly allowed through firewalls due to its utility.  The service runs in kernel-mode as 'system' by default on nearly all platforms....  During our investigation, we determined that this vulnerability is directly exploitable for code execution.  Developing a working exploit will not be trivial.  We would be surprised to see one developed in the next few days.  However, we expect" - and this is why everyone's running around with their hair on fire.  Microsoft said, "We expect to see working exploit code developed within the next 30 days."



Okay.  So first of all, the reason I had already discounted this when we discussed this, this has been a known vulnerability for a while.  I said, okay, first of all, Remote Desktop is not enabled by default.  Remote Assistance is enabled, but that's not the same thing.  So this is not a problem with the Remote Assistance.  This is with Remote Desktop, which is not on by default.  Even if you turned it on you're still, well, let's see.  Probably it punches a hole through your Windows firewall because it knows that it needs to be able to receive incoming connections on port 3389.  So that's the default port for Remote Desktop is 3389.  But I can't imagine anybody doesn't have now a SOHO router, a small office/home office router.  And that's definitely going to protect you from any unsolicited incoming probes to port 3389.



That is to say, even if you've got all your machines at home with Remote Desktop enabled, it's only if an outbound connection is initiated on that port that incoming traffic would be allowed to come back through, which would not be the case because outbound connections actually would be initiated to that port on someone else's machine, not from your 3389 port.  So there just isn't a vulnerability unless you explicitly have your world set up because you roam around out in the world, and you want to be able to access your computer's Remote Desktop remotely.  That's the danger.



But this network-level awareness is an additional protocol which has been implemented since Vista.  It's not available in XP.  I think it can be turned on in Service Pack 3.  So in XP SP3, they added it, but it's not on.  There is on Microsoft's site a quick-fix button that allows you to turn that on for XP.  It's in the UI of Vista and Windows 7 and Windows 8.  So turning that on enforces a level of authentication prior to the exploit being able to function.  The problem we have now is that it's possible to exploit the vulnerability prior to authenticating with Remote Desktop, which is really bad.



So I don't - I'm glad Microsoft has fixed this now.  I don't expect it to be a huge problem. But for any people who know that they deliberately mapped port 3389 through their NAT router in order to get to their desktop when they're out roaming around, those are the people, if they don't have this NLA enabled, they're at risk.  But all you have to do is apply today's patches, bring your system up to current, and you're fine, too.



For corporate installations that cannot, for whatever reason, deploy a patch instantly, Microsoft does have a Fixit button which allows you to turn on NLA to temporarily bring up a barrier.  If you still need, if you desperately need to have access to Remote Desktop in the meantime, and are unable to apply the patch, turning on this network-level authentication, that solves the problem, too.  So as always, install your Windows patches promptly, and you'll be okay.



And no doubt in the next few weeks we'll have some - someone's going to try to do a worm or an attack or something.  A worm is potentially a concern because we know that the default port is 3389.  So you just scan the Internet for anything that accepts a connection on 3389.  That's more than likely going to be Windows Remote Desktop.  And once you figure out what Microsoft did and changed, you'll be able to figure out the exploit, which is no doubt what some hackers are working on right now, to find people who don't install patches, who aren't listening to this podcast, who for some reason do have Remote Desktop enabled, and they'd like to crawl into their computers.  Unfortunately, this gives them a way to do that.



We recently had the sixth annual CanSecWest's Pwn2Own contest.  We've had fun talking about this in years past.  And what was embarrassing was that Chrome was immediately brought to its knees.  It took minutes, and an exploit was developed that escaped the much-vaunted sandbox of Chrome.  So the fact that Chrome is sandboxed, we've said that's good, it makes things much more difficult to exploit, but we can't count on it perfectly.  And this was an example.  There was an exploit that was developed.  However, it's worth mentioning that it apparently used a vulnerability in Chrome's version of Flash.  So once again, Flash and the complexity of Flash was the underlying problem.



But the good news is, and I salute Google for this, they had it fixed within 24 hours.  The moment that they understood what the problem was, they were able to push out a patch and fix Chrome quickly.  So this is a little bit like the model we were just talking about with your website, Leo, and websites in general that are so complex that there are going to be ways to get in.  But if that's the case, the best thing you can do is watch them carefully and fix them quickly.  And that's really the on-the-fly patching model that Chrome from the beginning has adopted, and of course we're seeing other people, Mozilla is talking about being much better about that, as well.  Speaking of which, there was a Pwn2Own vulnerability found in Firefox 11, just before its deployment, which has just happened.  It turns out once they saw what it was, they already knew about it, they were in the process of fixing it, so it's fixed.  So it's there.



Oh, and I also have had a note that both - relative back to SPDY again, I think I touched on it, but there is something called SPDY Indicator, available both for Chrome and for Firefox, that is, Firefox 11 and on, which supports SPDY.  And it puts a little green bolt of lightning in your address bar, just to indicate, as pure information, when you're visiting a site that is supporting the SPDY protocol.  So for people who want to play with SPDY, you need to enable it, as I said, in Firefox 11.  It'll be on by default, the plan is, in 13.  But it is, it's a Firefox add-on, so go search for SPDY Indicator.  You can find an add-on for Firefox, and there exists also one for Chrome.



And following up on the disgrace of GoDaddy, this sort of came across my radar, and I thought it was interesting.  Michelle Paulson, who is legal counsel, blogged on March 9th, so just a few days ago, she said:  "After months of deliberation and a complicated transfer, the Wikimedia Foundation" - as in Wikipedia - "the Wikimedia Foundation domain portfolio has been successfully transferred [away] from GoDaddy....  The portfolio transfer was formally completed on Friday, March 9th, 2012. The transfers were done seamlessly, and our sites did not experience any interruption of service or other issues during the procedure. 



"As the provider of the fifth most visited web properties in the world, the Foundation" - that is, the Wikimedia Foundation - "cares deeply about who handles our domain names.  We had been deliberating a move [away] from GoDaddy for some time  our legal department felt the company was not the best fit for our domain needs  and we began actively seeking other domain management providers in December 2011.  GoDaddy's initial support for the Stop Online Piracy Act (SOPA), the controversial anti-piracy legislation in the U.S. House of Representatives, reaffirmed our decision to end the relationship."



LEO:  Yay.



STEVE:  Yay again, yes.



LEO:  That was just inappropriate.



STEVE:  Wikipedia.  And I think it's good that they saw that, and good that everybody else saw that.  It's like, learn from that.  So little quickies from the Twitterverse.  Clifford Williams tweeted as @thegdot, don't know what that is.  But he said, "@SGgrc, the Cherokee web server already has support for SPDY."  I meant to check out what the Cherokee web server was, what platforms it runs on and so forth, but didn't get around to it.  But if anyone knows what that is, there's news there.  And that was before I learned that not only that, but Apache has support of some kind.  And of course Google has it widely deployed across their site.



And, oh, @Guysmiley777, he tweeted, "Love my  AeroPress.  And you're right, a consistent burr grinder makes a HUGE difference."  He says, "I was shocked at the difference."  And so I did want to let people know, I created a shortcut for anyone who's curious.  I think we've noted before that our coffee discussion, which was pre...



LEO:  Huge, huge.



STEVE:  ...podcast recording a few weeks ago, has made it to YouTube.  You can just put in, I think, "Steve Gibson coffee," and you can find it.  But I put in also - I made a bit.ly shortcut that was explicit.  So it's bit.ly/SGcoffee.  So SGcoffee, a bit.ly shortcut, will take you directly to it.  And it's just a nice little - I think it's 18 minutes of you and me, Leo, talking about our passion for all things caffeine.



LEO:  And I blame you because I just bought the most ridiculous burr grinder in the history of mankind.



STEVE:  Yay.



LEO:  Well, I had one before.  I had a Krups.  And they're, like, 20 bucks at Costco.



STEVE:  Wait, burr grinder for 20 bucks?  I'm surprised, Leo.



LEO:  Well, I know.  So I went online, and I ordered the KitchenAid Pro Line series burr coffee mill.  This thing is - it's like a Briggs & Stratton engine attached to a burr grinder.



STEVE:  Wait, and that's not the one I got?  Because I did get a KitchenAid...



LEO:  Well, maybe it is the one you've got.



STEVE:  ...Pro Line.



LEO:  Yeah, well, this is it.



STEVE:  Does it have, like, a big black knob in the front?



LEO:  Yeah, it looks like a sausage grinder.  It's the same one you got.  And it's your fault, at 158 bucks.



STEVE:  That's the one, yep.



LEO:  I blame you, Steve.  But it's good coffee.  I had to have some this morning, and it's amazing.  And then the other thing I got is a coffee vault.  Because you buy a pound of beans, but you don't grind them.  And so as long as we're talking coffee, I bought this thing, it's called a...



STEVE:  We're doing it again, aren't we.



LEO:  ...a Friis coffee vault.  And it's sealed, but it has something interesting.  It has a CO2 exchanger in the lid that you change every month.  They say in the materials that, yes, you want to keep it in a cool, dry place.  You want to limit exposure to air.  But you also want to vent CO2 that's coming off the coffee.  So this thing has a CO2 vent.



STEVE:  It is true that Starbucks bean bags, when you buy pounds...



LEO:  They have a little vent.



STEVE:  There's a bellybutton on the bag, and that's what it's for, it's to vent the CO2.



LEO:  Yeah.  So this is a little canister that I can buy a pound at a time and seal it.  And then - it's your fault.  I blame you.



STEVE:  I'm happy to take responsibility for you having a burr grinder, Leo.



LEO:  Pretty damn good coffee.



STEVE:  I'm not feeling sorry for you.  Sorry about that.



LEO:  Pretty darn good, I'll tell you.  That thing...



STEVE:  How many iPad 3s did you buy?



LEO:  Yeah, you're right.  168 bucks for a burr grinder, big deal.  I mean, the funny thing is the plunger is like 20 bucks, the AeroPress.  So...



STEVE:  Right.  Oh, and you're right, nothing slows that grinder down.  Boy, you turn it on...



LEO:  [Mimicking an engine revving]



STEVE:  Okay, now, when the announcement happened on Wednesday, Apple's site came up, and their store was down.  And I knew that I wanted to get in instantly.  They put up that placeholding page that said "The Apple Store is offline.  We're making updates."  Well, everyone in the universe knew what they were doing.  They were getting ready to put the third-generation iPad on sale.  So I was clicking Refresh for a while.  But I'm thinking, how long am I going to be clicking Refresh?



So I thought, there's got to be a web page change detector.  Now, I had one that I had used for years.  It was a little standalone Windows app.  And I tried to use it, but it wasn't happy with Apple's page.  Whatever the technology was that the page was putting it through confused it.  So it didn't work.  So I thought, what about an add-on for Firefox, which is still my primary browser?  Well, I found something fantastic that I wanted to share with our users for anything like this in the future because I was notified the moment, actually within 30 seconds of Apple's site switching to the commerce site coming back online, this thing told me, and I was able to get my purchase in before everybody else figured out that Apple's site was back up.



It's called "Check4Changes," aka C4C.  Check4Changes, and actually the URL is addons.mozilla.org/en-US/firefox/addon/check4change.  So there it's not plural.  Maybe it is just Check4Change.  Anyway, so what I like, it's very nice.  It's a lightweight add-on for Firefox.  You mark some text on the page that you want it to be looking at, and then you right-click on the tab and say "Start checking."  You're able to choose any of five intervals, and those five are configurable in the options.  And I had it, it was defaulted for 30 seconds, and I thought, well, that's often enough.



And then what it does is it changes the little icon on the tab to a countdown clock, just so you can see, and it goes 29, 28, 27, 26, and when it hits zero, it reloads the page and then checks the marked text to see if it's changed.  And then you can have it play some alert sound if it detects a change.  So I liked it because it's integrated into the browser.  That's kind of where you want that kind of thing to be.  It had no trouble with Apple's page because, of course, it is a browser, and it knows how to read pages; whereas this much more simple-minded, simple HTTP query thing that I had before just was lost in oblivion.  It was probably getting 19 levels of indirection or something before it finally got to the, who knows, cookie exchanges and things before it was able to get there.  And so this worked really nicely and I wanted to let people know.



I have a request from Consumer Reports.  I did an interview with them last week, talking about Facebook privacy stuff.  And they had a couple questions that could only be answered really by a Facebook developer, which I am not.  So if we have in our audience anyone who knows how to develop for Facebook, who knows the ins and outs of the Facebook API for doing Facebook apps, I'm sure any such person would also be on Twitter, so please drop me a tweet at @SGgrc because I'd like to put you in touch with a producer at Consumer Reports who would like to put your name in lights and interview you.



LEO:  Cool.



STEVE:  And I wanted to mention that Elaine, it turns out, our illustrious transcriber, also proofreads, and at a very reasonable price.  Jenny, whom you've met, Leo, is a prolific writer, and she just finished a screenplay, and this is the second thing she's had Elaine proofread.  And I can't quote the price, I don't know what it is, but we didn't even identify Jenny as Jenny to Elaine when she quoted because I didn't want to take advantage of Elaine in any way.  And Jenny could not be happier with the results that she's had.  So I wanted just to let our listeners know that, if they need something professionally proofread, there's someone who can do it, and that's Elaine.  It's On-SiteMedia.com.  I think that's what it is.



Okay.  And lastly, well, not lastly.  I'm still going.  We're going to run out of time before we even get to the questions.  I am more than halfway through Book 13 of the unending, never-ending Honor Harrington series.  And I take back any frustration I ever had with it.  Oh, my goodness.  Twelve began to accelerate, and even though there was a sort of a quiet period, maybe like books six through nine or ten, oh, my goodness, David Weber - the good news is he's written nothing since, except there are ancillary books, but I'm not going to go into those because I have this other stuff I have to get to.



LEO:  There are limits, man.



STEVE:  Yeah. But oh, my goodness, it has been worth everything.  We have this incredibly well-defined, huge, mature, interesting galaxy, steeped in politics.  And I happen to like politics.  I like, I mean, these are - the people do realistic things.  And I'm just - I couldn't be more pleased with this investment that I've made.  So I did want to say that, boy, it's been worth the journey.  I am loving where this has been going.  And now that I'm all caught up, because he's been writing these things since 1984 or something, I mean, like forever, they go way back, it's been fun to see the terminology catch up with present time, too, because I've caught him using some terms that weren't in common use when the series began, so of course he couldn't use them back then.



LEO:  Like cell phone?  Fax machine?  Automobile?



STEVE:  Yeah, it's been interesting.  But anyway, oh, wow.  And for a while I was annoyed that we weren't seeing more of Honor Harrington because I fell I love with her at the beginning.  Now, I mean, and she stayed around, and other things have come in.  Oh, my goodness.  It's just fantastic.  And the one thing I'll - no, I can't say anything more because I can't do a spoiler.



LEO:  No spoilers.  No spoilers.



STEVE:  But, oh, it's just - I'm clapping.  That's me clapping.



LEO:  Yay, yay.



STEVE:  Yay.  It's really good.



LEO:  It's not much of spoiler if you have to read 13 novels to get to it.  But I think we should still...



STEVE:  Yeah, I'll wait a year.  A year from now I'll let people know what it was because I'll figure by then you've either read them, or you've given up, or you got burned out.



Okay.  So, Leo, I've mentioned to you a few times that I have been reading about carbohydrates.  And I warned you about that pie on Pi Day.



LEO:  Wait a minute.  You're not going to say anything that makes it undesirable to eat this fine pecan pie, are you?



STEVE:  Well, we all know that I do experiments on myself.  And I played with Vitamin D.  Actually there's a lot you haven't heard about that I've done that someday we'll get around to doing a series of health podcasts.  But I needed to share something with you.  The reason I'm excited about getting through with this Honor Harrington series is that I've got four books stacked up on the science of carbohydrate metabolism that I really want to get to.  But I read enough of them, you just can tell when something makes sense.  And they made sense.



So five weeks ago I made a dramatic and deliberate change in my diet.  I have eaten since then absolutely no manmade simple carbohydrates or starches, that is, no potatoes.  And I felt self-conscious.  For example, there's a vegetable soup that I like at this place that's got some potatoes in it.  Well, I've never done this in my life, but I sort of, when I encounter one on my spoon, I'll push it off, out of the bowl, onto the plate that is next to it.  And I feel like I'm being a picky eater.  But, I mean, I've decided, if I was doing an experiment, I would be rigid about it.



So what does this mean?  Well, this means beef, chicken, fish, shellfish, and salad, vegetables, essentially.  It's all I've eaten.  No bread, no grain, rice, no oat bran, no whole wheat, none of that.  Friday of last week I did another round of blood tests.  And I've done, I mean, they know me at the lab.



LEO:  They're used to you.  "Oh, what is it now, Steve?"



STEVE:  It's very funny because I show up early so that I'm the first person there on the earliest day that they open.



LEO:  Right, because it's going to take a while.



STEVE:  The doors are normally locked.  Anyway, I went up in the elevator with the phlebotomist, who once he finally turned to me, he said, "What's wrong with you?"



LEO:  Do you like getting your blood drawn?



STEVE:  Anyway, so Friday was testing day after five weeks avoiding carbs.  I mean, not avoiding, I mean absolutely, no exception, zero carbs.  My bad cholesterol, my LDL, dropped nearly in half.



LEO:  Wow.



STEVE:  It is at 54.5 percent of what it last was.  And I know why.  And I could go into the science, but this is not the podcast for that.  But for what it's worth, I wanted to share with our listeners.  There are people out there I would imagine in our community of listeners who feel that their cholesterol is too high.  Maybe they're on statins to bring it down, which is unfortunate because statins have a lot of negative consequences.  But for what it's worth, my own limited individualized personal experiment, I have never had my bad cholesterol, my LDL, this low.  And it did nothing to lower my HDL, the high-density lipoprotein good cholesterol.  It stayed exactly where it was.  But LDL, just it crashed it.  It just collapsed.  So...



LEO:  And I just want to give the usual disclaimer.  Steve's not a physician.  He's not making any recommendations.  Please don't follow his recommendations.  But it's funny because this conversation has been going on for over a year.  Paul Thurrott read the same book that you've read, the "Good Calories, Bad Calories" book.  But I have to say, the study came out, but did you see the Harvard study that came out this week?



STEVE:  Oh, financed by the wheat growers of America.



LEO:  No, no.  It was a long-term, longitudinal, 15-year study with over 100,000 men and women who were free of cardiovascular disease and cancer at baseline.  And what it concluded was that there is absolutely no safe amount of red meat, period.  That basically any red meat you eat increases your risk factors measurably.



STEVE:  And I can tell you why that study is nonsense.



LEO:  Okay.



STEVE:  But I can't tell you now.  No, I saw the study.  I read the report extensively.  And in fact the "Good Calories, Bad Calories" science writer, Gary Taubes, has a beautiful, clear explanation of the problems with that kind of study.  That was a dietary questionnaire study.  And the problem is those kinds of studies, you just have to take them with a grain of salt.



LEO:  That's what the Meat Institute said, too, by the way.  Just in case you're curious.  There is an American Meat Institute, and they said that "relying on notoriously unreliable self-reporting about what was eaten and obtuse methods to apply statistical analysis to the data" is classically an error.



STEVE:  Yeah.  There's a guy, a pseudo-scientist named Ancel Keys, who is responsible pretty much for this whole belief that saturated fat is bad for us.



LEO:  Now, you could, by the way, I presume, do a no-carb diet that didn't have red meat and bacon and salami and hot dogs in it.  You could eat other forms of protein.



STEVE:  Oh, and I'm not a big meat eater at all.



LEO:  So it might be, based on this, it might be - but anyway, we shouldn't get into it.



STEVE:  I really like fish, and so...



LEO:  Let's just point out that there are disagreements among people who do this for a living.



STEVE:  Here's what I would say, Leo, is because the other thing we are is all individual, it is vastly - one of the things I have learned in the seven years I've been studying nutrition as a background hobby, is the incredible variety that exists among people.  So there are people who have sensitivities to one thing or the other that others don't.



LEO:  Well, that's why a 15-year longitudinal study of 100,000 people is better than...



STEVE:  Tells you nothing about you.



LEO:  Okay.



STEVE:  That's the key.



LEO:  Right.



STEVE:  Nothing about you.  So, and that's my big problem with the fact that doctors diagnose based on these huge studies...



LEO:  Public health, yeah.



STEVE:  ...that are not about you.  The thing they do ask, which is good, is what's your family history because now they're beginning to zero in on who you are.  So the only thing I want to say is what happened to me was that.  And it's simple for someone to try.  It's just, I mean, I understand people have carbohydrate cravings.  Well, there's a reason for that, too.  But my...



LEO:  Gary Taubes also points out that cholesterol is not necessarily a valuable indicator.



STEVE:  I agree with that, as a matter of fact.



LEO:  But that's a long - now we're getting a really long story, so we won't go there.  But he predicted, he does in that book predict exactly what, well, actually you got a remarkable result.  But he does predict a surprising result, which is a lowering of cholesterol and lipid in blood tests.



STEVE:  Well, triglycerides.



LEO:  Triglycerides, yeah.



STEVE:  Yes, because your liver turns glucose into triglycerides, and that lowers the size of the lipoproteins.  And the tiny VLDL and LDL lipoproteins are much more prone to something called "glycation" and oxidation, both of which are bad things for your arteries.



LEO:  But we will talk more about that some other time because we've got 13 questions and half an hour.



STEVE:  We're never going to get it done.  I have to briefly say, somebody tweeted me, "Hey, Steve, I heard you talking about SpinRite 6.1.  Should I wait to order SpinRite?"  And, okay, well, the phrase "till the cows come home" may be generic or applies here.  First of all, all SpinRite 6 owners are going to get 6.1 for free whenever I get around to doing it.  There aren't any bugs that I know if in SpinRite.  I just want to catch it up with things that have happened since I finished it in 2004.



And there's been a lot of changes since then, much stronger use of SATA, serial ATA, over parallel ATA.  Much larger drives.  BIOSes are becoming increasingly buggy, so SpinRite's dependence on the BIOS is some thing I want to remove.  I want to build in Ultra DMA.  We got that Western Digital hybrid drive that uses some flash and some storage.  SpinRite already does the right thing, but it could do a better job with it.  We've got the big sector drives, or maybe it's the WD big sector drives that use 4K sectors.  Again, SpinRite works with those, but I could detect that and do a better job in terms of buffer sizing and to make it better.



So I'm going to update SpinRite.  But waiting to purchase it makes no sense because it works fine now.  I'm just going to make it work better.  And I'm not starting on it now.  There's only one of me, and right now I'm still finishing up this really interesting project on finding the longest repeating strings in files, which is part of the project of putting SpinRite testimonials on the site which I want to get done.  Then I've got to get finished with the Off The Grid, I've got to finish those pages up.  Then I want to finally get the cookie stuff published.  And then I'm done.  And then I'm going to start on SpinRite.  But I move slowly.  So if you think you need SpinRite, believe me, from a preventative maintenance standpoint, get it, and you'll still get 6.1 as soon as it's ready.  So I just wanted to make sure I didn't confuse people by saying, oh, something fantastic and new is coming along that I want to wait for.  It's like, well, you'll get it anyway.  And all it is is just sort of catching up with things that have happened in the last eight years.



LEO:  Steve, I've got questions.  Are you in the mood?



STEVE:  Well, I am.  I'm a little worried about the time, though.



LEO:  We'll go until we run out.



STEVE:  Yeah.  Because, I mean, yeah, okay, we've given our listeners quite a podcast so far.  Not quite the Q&A that we had planned, but go until you need to do the next podcast.



LEO:  Till we've got to go.  We've got This Week In Google at 1:00.  We've got time.



STEVE:  Yup, okay.



LEO:  Question 1, Stephen in North Yorkshire, U.K.  He wonders if his use of TrueCrypt is fully secure:  Steve, I have all my banking details for several accounts for myself and my wife in a single text file on a TrueCrypt-encrypted USB card, or chip.  Whilst I realize that is safe, as it has a 26-character passphrase employing your suggestions, et cetera, once I OPEN the text file in Word or any other editor, am I storing the data unencrypted in various cache files and log files on my PC?  If so, is there any way around this?  That's a good question.  Thanks to both you and Leo and his staff for the hard work you put into producing Security Now!.  Stephen in North Yorkshire, U.K. 



STEVE:  It's a great question.



LEO:  Yeah.



STEVE:  And I often notice, for example, when I open a Word document, that Word opens up a temp file right in that same directory that's got some variant of that document in it.  So there the document was written to the disk on the fly by the word processor.



LEO:  Unencrypted.



STEVE:  Yes, exactly, unencrypted.  So Stephen raises a great point.  Here you've got the file encrypted with TrueCrypt, but the act of viewing the contents is causing it to be written to your drive.  Now, what I would suggest is - first of all, the problem, of course, is we're not using secure operating systems.  These started off as a toy OS on the desktop and never really lost that flavor.  So there's nothing secure about the systems we're using.  We've added features here and there, trying to increase their security.  But fundamentally they're not secure.  So the one thing you could do would be to use a lightweight viewer, for example Notepad, which does only keep its contents in RAM.  And I know that, for example, Notepad is a RAM-based viewer.  It doesn't write anything to the disk.



The problem you still have, of course, is swapping because, if the RAM that Notepad was using happened to be swapped to your paging file, then that would go onto the hard disk for that reason.  But normally that's only going to happen if you're heavily using your system, like you're actively paging RAM in and out.  And probably, if you just use Notepad to open it up and copy, cut and paste or whatever you were doing, and closed it, the chances of Notepad being swapped out are minimal because that's the app that you're using, and then you're probably okay.  But it is definitely, I thought, a very good point.  There just isn't - there isn't a perfect solution that I know of.  But having a really secure viewer is an interesting feature for a product that I kind of have in mind for the future.  So I'll keep that in mind.



LEO:  Yeah, anytime it writes the file, even though Word deletes a temp file when it closes it, it crashes, it doesn't delete it.  And even...



STEVE:  It's still on your hard drive.



LEO:  ...if it deletes it, it's still on the hard drive.  In fact, you might even overwrite it, and then it'd be in slack space.  I mean, it still exists.  So as soon as it's written, you're in trouble.  That's one of the reasons PGP has a secure viewer.



STEVE:  Ah, do they.



LEO:  So, yeah.  So when you unencrypt a PGP email message, you can have it open in a secure viewer that is stored in RAM, never writes to disk.  And I think they overwrite the RAM.  That's the whole idea, is that - for this reason.  You can view it, but you view it securely.



Steve Coakley in Phoenix wonders about a site-to-site tracking blocker:  Steve, I've noticed that, if I search for an item on Amazon or Google, and then leave and go to different sites, that ads for the exact item I was searching for keep following me and showing up everywhere I go.  Horrors!  That seems pretty creepy.  Well, all right.  It's not exactly like a doll chasing you.  I wonder if there's a privacy setting to turn off that kind of tracking.  I'm not even sure where to start looking, though.  If I use an ad blocker, will the ads still be there but I just won't see them?  I want them to stop altogether, even if I can't see them, says Steve.



STEVE:  Well, of course we stepped into this with our recent dialogues about tracking.  I just wanted to make sure that Steve knew that probably just disabling third-party cookies will solve that problem, and definitely give it a try.  All web browsers give you the option of turning off third-party cookies.  And that probably solves the problem.  So this is a perfect example of what third-party cookies enable, and browsers all let you turn them off.  So that's all you have to do.



LEO:  Question 3, Adam Fourney in Waterloo, Canada adds a bit more salt to his hash:  Steve, I just heard your response regarding a question which discussed the issues with a database containing both hashes and salts, stored in the same database.  In this case, I'm guessing that the primary reason the admins chose to use unique salts for each user is to thwart pre-computation attacks, i.e., rainbow tables.  Each salt effectively gives a new hashing function.  With this threat model, storing salts and hashes in the same table is no big deal.  Generating a unique rainbow table for each user is at least as complex as a direct brute-force attack, says Adam Fourney, Ph.D. Candidate, Waterloo, Canada.



STEVE:  Right.  I wanted to - several people wrote in about this, the idea of putting the salt along with the hash.  And so I wanted to make sure that I didn't overly complicate this when I was talking about it before.  Having a salt is way better than not having one because, if you simply used a well-known hashing function, then exactly as Adam mentions, and as we've discussed many times, existing tables for, like, SHA-1 and MD5, exist.  And so it would be simple, if they could get a hold of the hash, to look up a matching password for that hash, for that hash function.  Adding a salt, exactly as Adam says, dramatically increases the security because essentially you're scrambling, individually scrambling each instance of the use of the hash function per user.  So that's a much better thing to do.



Now, storing them together is the question.  And, yes, storing them together is not as secure as storing them apart.  But so store them apart, if you can.  But if you can't, it's better to have a salt than not to have one.  So again, it's that traditional tradeoff between convenience and security.  It's less convenient to have the hash somewhere, to have the salt somewhere else.  You have to go get it and then use it to figure out if the password's correct or not.  And you want to keep that out of the hackers' hands.  Whereas, presumably, they could get to the hash.  Of course you want to keep everything out of the hackers' hands, if you can.  So anyway, I think that issue is settled.



LEO:  Question 4, Sunil Joshi in Chicago, Illinois.  He wonders about SSL keys bigger than 2048:  During the feedback Q&A last time you mentioned that the longest RSA public key that had been factored was 768 bits, and that we currently use 1024 or 2048 bits for higher security.  I understand that every one bit increases the complexity exponentially.  However, this is true only until very advanced computational devices are invented.  It is only with the current processing power that it will take an inhumanly long time to factor a 2048-bit key, or even a 1024-bit key.



But why not stop worrying about where the edge is in this cat-and-mouse game and generate SSL keys that are way bigger than 2048?  What about 4096 or 8192?  Isn't the key generation merely a computational process?  What's stopping us from making the keys as long as possible?  I am sure there is some concern or limitation I'm not aware of.  Could you throw some light on it?  And thanks for making the Security Now! show.  I cannot wait for it every week.  Sunil Joshi.



STEVE:  So, yeah, I wanted to make sure about this because I've seen this question also pop up a lot.  It's true that computing the public key using a pair of hopefully very randomly generated primes - and we understand now that that's more easily said than apparently done in our industry.  That's a one-time process, to create the public and private key pair.  And so, sure, you could do that to any arbitrary bit length.  The cost, though, is in every time it's used.  We mentioned a couple weeks ago that it's about five times more computationally expensive to use a 2048-bit key over a 1024-bit key.  And that approximate ratio continues.  So it would be about five times harder to use 4096, and five times harder than that to use 8192.  So you start multiplying those fives, two fives gives you 25, and another one gives you 125, so now it's 125 times harder to use an 8192-bit key than a 1024.



In certain applications, that's just going to be a deal breaker.  You've got a low-powered processor in a smartcard or a heavily loaded server that has now switched over to using SSL all the time.  Imposing 125 times the connection overhead for negotiating an SSL dialogue, a handshake, that becomes a problem.  And here's the point.  Yeah, it does mean we never have to worry about security ever again. But what we've got is massive overkill.  And it's massive overkill that we're paying for needlessly every single time we use it.  So the fact is, today, 1024 is plenty strong.  As far as we know, we haven't even come close to factoring that.  And even the 768-bit factorization was much easier than 1024, and we are moving to 2048, which is radically harder to factor.  So the point is we really, really have enough security, and there's just no reason to throw away all that computation time without getting any real security benefit in return.  Once you've got, I mean, really enough security, anything more is just wasted time.



LEO:  Moving along to Question 5 from Ron Kurr in New Hampshire.  He wonders about determining the physical location of an IP address:  Steve and Leo, on a recent Tech News Today they were discussing the lawsuit brought against the cloud-based TV service Aereo.  One of Aereo's legal positions is that their services are restricted to New York City customers only.  I'm a developer by trade and understand the basics of networking, and I don't ever recall any specification talking about embedding the physical location of the machine attached to an IP address.  I'm assuming that Aereo isn't lying to the public.  So my question is, how do they know that my IP comes from a computer in New York and not Tokyo?  I appreciate the work on the show.  Look forward to hearing your thoughts.  Thanks, Ron.



STEVE:  That's a really good point.  Okay.  We know what IP addresses are.  IP addresses are hierarchical in nature, that is, big ISPs get big chunks of IP space.  For example, Level 3 has all of the 4-dot space.  And HP had famously had, I think it was like 14-dot and 15-dot.  They were really greedy because they were involved in the Internet in the beginning and had much more space than they were ever going to use.  And the good people have been giving back IP space that they don't need.  Many universities also got huge chunks of IP space that they never used.  And they've been giving it back as our IP space is becoming more - as the IPv4 IP space is becoming more depleted.



So the point is that the IP is used for routing, and there have been attempts to geolocate based on IP.  So, for example, if you're a Cox cable user you can maybe do reverse DNS on the IP and see what the DNS says, and that can give you a clue.  Or there are just - there are forward indexes that say IPs in this range are in this region of Southern California.  IPs in this range are in this region of Northern California.  The point is they tend to be very inaccurate, at least the closer you try to get.  I know that the block I have here in Southern California is identified by these various services as being well away from me, up in Northern California.  So it's not very accurate.  Sometimes they are; sometimes they're not. 



LEO:  All they really know is who your Internet Service Provider is.



STEVE:  Yes, that they could definitely determine.  So if you had a regional ISP, then you could presume that all the IPs they own are going to be serviced within that region.



LEO:  That might be easier in New York City because the primary ISP, Cablevision, only works in Manhattan, Long Island.  It is a regional provider.



STEVE:  Right.



LEO:  So, but do they say that it's IP addresses?  I mean, I bet you they have credit card information, too, if these people are customers.



STEVE:  Well, and it is also the case, although Ron didn't ask, as I mentioned before, Reverse DNS often is a treasure trove.  You ask for the DNS of the IP, and it'll say, like for example, on my cable modem is oc.oc.cox.net.



LEO:  Oh, you're in Orange County.



STEVE:  Orange County, yeah, exactly.



LEO:  So it's an imperfect science, at best.



STEVE:  Yup.



LEO:  But more can be deduced than one might think.



STEVE:  That's true.



LEO:  Charles Hill in Washington, D.C. observes that IPs can't replace hostnames.  Dangit.  In a recent episode you discussed what happens if DNS were to go down or be attacked.  Some people suggest, well, just use the IP address to get somewhere.  But you might want to mention that, for the millions of shared-hosting sites, that will not work.



STEVE:  So on behalf of Charles and all the people...



LEO:  Everybody said that, huh?



STEVE:  ...our very astute listeners who said, uh, Steve, you can't.  Remember that what they're talking about, and they're all right, is that many, many hosting providers have many fewer IPs than they have domains that they host.  So when you look up, for example, MyOwnSite - I'm making that up - MyOwnSite.com, it may give you an IP that's the same as YourOwnSite.com.  So both of those domain names point to the same IP.  The way the server disambiguates - I love it when I can use that word - disambiguates those two is that in the individual request, the individual web browsers asking for those two different domains, all make a TCP connection to the same IP address.



But in the request headers, in part of the URL there's a host header.  And so one of the host headers will say MyOwnDomain.com, and the other one will say YourOwnDomain.com.  So that tells the server which directory, essentially, to serve that request from.  And the server's broken down into all the domains with different hostnames that share the same IP.  So clearly, if we weren't using DNS anymore, if we were using IPs, that whole model of using the hostname to disambiguate the individual websites that are in a shared environment would not work.



LEO:  But that's not - go ahead.



STEVE:  I was going to say, Charles and everybody else, tip of the hat to you.  You're exactly right.



LEO:  But that's not done through DNS.  That's done at the hosting server, which disambiguates.



STEVE:  Correct.



LEO:  So you could, I presume there would be a way to use the IP address and then a slash and then the hostname or something like that.  There must be some way to signal to the server that you're looking for a particular site.



STEVE:  Yes.  The only thing you could do, like on the spur of the moment, would be to edit your hosts file and basically make your own...



LEO:  Ah, because the hosts file would pass along the information.



STEVE:  Yes, make your own little private DNS.  Then you could put MyOwnDomain.com into your browser.  It would look up the IP, and so it would make the correct connection to the correct IP.  But it would think it was connecting to MyOwnDomain.com rather than an explicit IP.  So it would put a hosts header in that would allow the remote shared hosting service to give you the correct website.



LEO:  Clever.  Just modify your hosts file.



STEVE:  Yeah.



LEO:  Instead of entering the IP directly.  Although most of the big pirate sites are not shared hosting.



STEVE:  Correct.



LEO:  So it's still going to work.  And I think that was the context for that.  No, actually the context was March 31st taking down the Internet, that's right, yeah.



STEVE:  Right.



LEO:  Greg Williams in Brisbane, Australia offers a clarification about 2048-bit SSL:  Asymmetric keys are only used during the negotiation, but not for the lifetime of the connection.  That uses negotiated symmetric keys. Therefore, you only pay the performance penalty at the start, and the rest is not slowed down.  Obviously, if HTTP pipelining isn't used - unfortunately it's disabled by default on almost every browser - there'll be a penalty for the multitude of request establishments, but it won't slow down the data transfer.



STEVE:  Yeah, I just wanted to toss that in in case anyone was confused about that.  That is the case.  And in fact, I'll go a little bit further and say that, thanks to SSL caching, you only need to negotiate, you only need to go through the public key negotiation the first time you're connecting to a remote server, no matter how many connections you then subsequently make as you're browsing around on that server because they will verify that they still have this SSL credential valid, and there's no need to redo it.  So not only is your individual flow not slowed down, but subsequent connections are also not slowed down.  It's really not that big a problem.



LEO:  All right.  Moving on to another question, this is #8.  Bruce in Washington, D.C. says he's been thinking about SSL and WiFi tracking:  Love the show.  In all the recent discussion of third-party cookies, it occurred to me that your own public key would make a nice, nearly unique "cookie" for tracking purposes.  Right?  So isn't there a privacy tradeoff to HTTPS?  In other words, when I have a secure connection, I'm kind of identifying myself.  Also on the subject of tracking, we know that Google and others have mapped WiFi hotspots based upon their unique MAC addresses.



Can companies also do the reverse with us?  For instance, smartphones and laptops can automatically search for WiFi hotspots.  But when they do that, they share their MAC address; right?  So Starbucks, for example, could keep track of my visits, even if I paid cash, based on my phone just kind of saying, hey, I'm here.  They might even be able to track me as I walk around town, as I pass various Starbucks locations.  I haven't heard of companies doing this, but I don't see why they couldn't.  Thanks, Bruce.  Is that possible?



STEVE:  So the first part of his question is not possible because he's got this backwards.  It's the server that we connect to that provides its credentials to prove to us that it is the server we are intending to connect to.  In a one-sided authentication, which is what that is, where the server is authenticating, we're not providing our credentials.  It is possible for SSL to be used in a double-ended authentication, where the user would have a certificate that is being used to authenticate itself to the server.  But that's a special case, corporate environments, corporate networks and so forth.  That's not the normal model, where we're anonymously connecting to an authenticated server.  Part 2, he's absolutely right.  It is the case...



LEO:  Hmm, that's interesting.



STEVE:  Yeah.  It is the case that all of our devices, our WiFi devices, have unique MAC addresses, and they're known to the hotspots wherever they're within range.  So just as...



LEO:  So do I have to have logged into that hotspot ever?  Or do they just sense it?



STEVE:  They just sense it.  And that's, I mean, when...



LEO:  So that conversation is going on as I walk through town.  My MAC address is being announced by my phone everywhere it sees an open - or an access point.



STEVE:  Yes, exactly.



LEO:  Or is it just broadcasting it?



STEVE:  Yes.  Essentially, in the same way that if you had...



LEO:  But this is good.  This is juicy.  Wait a minute.  You're saying, as I'm walking down the street, my phone is saying - giving out my unique, and it is unique, MAC address constantly.



STEVE:  Yes.



LEO:  Well, now, why are people worried about third-party cookies?  So then his supposition that Starbucks or anybody who had many locations - maybe this is why Starbucks has so many locations.  I've often wondered why they'll have a Starbucks across the street.



STEVE:  Are they a front for the CIA.



LEO:  They must be tracking us all.  They've got a database to say, well, I can tell you who was downtown.  Wow. So if you turn off the WiFi, of course that won't happen.



STEVE:  Well, and let's step back a little bit.  Let's remember that our cell phones are identifying where we are all the time anyway.



LEO:  To the cell company.



STEVE:  With cell tower triangulation.



LEO:  Right.



STEVE:  That's the way some of these location services work is "You are here."  And it's like, oh, yes, I am.



LEO:  And we know that all the major carriers, wireless carriers, have database portals for law enforcement, where law enforcement can go, using, what is it called, a pen warrant.



STEVE:  Yeah, and how many movies is this now in, where we all know that your cell phone is tracking you, and they'll send their final message, and then they'll smash the cell phone down and stomp on it in order to keep it from tracking them any further.  Or toss it into the back of a garbage truck, and now they're going off and tracking the wrong car.



LEO:  I'd be more worried about that than anything else.



STEVE:  But it is the case that MAC address is unique, and that's certainly trackable, too.



LEO:  Bill in Michigan, who's a regular in our chatroom, we love him, shares some thoughts about the consequences of SPDY.  He says:  I'm getting bad vibes about SPDY.  Here's the way I see it.  The third-party nature of advertising sourcing and ad tracking, being sourced by third-party servers, keeps the main site and ad servers separated.  But when pages start SPDYing up - if that word gets coined, remember when you heard it here first - who will want to go to the slow sites which link to offsite ads?  The pressure will be on to source those ads from the host server's SPDY stream.  Wouldn't this dramatically change the way things are done?  First thing I thought was there would be no such thing as a third-party script, cookie or resources.  They'd cease to exist.  Everything is first party.



In the GRC newsgroups, Alan Cameron brilliantly came up with another loss, the old HOSTS file.  Its effect will be meaningless.  The problem is that "pressure is on" phenomenon to keep pages fast.  Some new inventions or protocols will be needed so main servers and ad servers get their content in sync, so they can be just as fast.  Perhaps this will be done with some sort of side-channel communication.  This has actually always been a worry, but the status quo has held it back.  Now SPDY's pressure may make it happen.  Do you see what I see?  That SPDY changes a lot more than web page speed?  Your thoughts, please!  Bill.



STEVE:  So what he's suggesting is something which has been discussed from time to time, and that is that here we're also worried about third-party things.  All that a website would have to do in order to not have third-party things blocked is essentially funnel them through itself.  That is, rather than providing a URL to a third-party asset, it would provide a URL in its own domain which, when the web browser turned around and asked for it, it would go and fetch that third-party resource and feed it back to the browser as if it was coming from that first-party domain.



So Bill's exactly right.  There is a way to collapse this whole third-party deal.  And Alan was right that right now people, for example, have DoubleClick.net blocked using their hosts file, but this would allow DoubleClick ads to sneak in as a first-party, as if the ad were being sourced and served by the server they were visiting.  So that's the bad news.



The good news is third-party cookies don't work, either.  That is, no one could track you if that was being done because your browser would just give back the first-party cookie.  It would give back the cookie for the domain you're on, not the domain for the advertiser.  And if we assume that advertisers desperately want to track us around the Internet, then they have to hold their third-party status in order to be able to provide us with a cookie unique to them, not unique to the site we're visiting.  That's their whole deal.  So I think that there's some back pressure on amalgamating everything through a single-party site.  Probably we're not going to see it happen.  And boy, what a pain it would be.  You think you've got problems now, Leo, with your server.  Wait till you start trying to pump other people's content through it and out to the browser.  Ugh.



LEO:  Such an exciting world we live in.



STEVE:  Ah, yes.



LEO:  Question 10, Richard Covington in Redondo Beach, California.  He used the subject "CURSE YOU, STEVE GIBSON!!!" to get your attention, and it worked:  Hey, Steve.  Well, now that I have your attention, I'd like to thank you for the work that you, Leo, and Elaine put in to such a great show.  Additionally, and the reason for the note, I'd like to thank you for your decision to have Elaine make transcriptions of each episode.  Having these transcriptions available has resulted in an invaluable resource, yet you have set the bar for all other netcasts extremely high.  That's true, because it's expensive, and Steve does that out of his own pocket.  Which we should talk about.



But anyway, unfortunately, none that I listen to have even come close to your exemplary transcriptions.  However, because of these high-quality transcriptions, I've come to expect that I can go to any show that I've listened to in the car to either - and by the way, none of our other shows, either - that I've listened to in the car and either pick up a link or check out a subject that was discussed.  To my immense displeasure, the information just isn't there.  CURSE YOU, STEVE GIBSON for setting the bar so high!  I'd like to extend my highest gratitude and "job well done," and look forward to future amazing netcasts.  I've been a listener since Episode 1 and a proud owner of SpinRite.  Even though I've been designing computers for over 30 years, I still find the information not only timely, but very interesting.  Richard Covington.



STEVE:  So I just wanted to remind our listeners - first of all, thank you, Richard.  I'm happy that we here have spoiled you from all other netcasts.  And I want to remind our listeners, because I often run across people sending questions or tweeting things that are discoverable instantly by going to GRC.com/sn, which is that Security Now! page, and we use Google-hosted search, and I pay Google annually for the privilege, and I'm paying them more because people are using it more.  But thanks to the transcripts, remember that everything is searchable.  The other day I didn't remember which episode it was where I explained - I did that little snippet on what SpinRite does.  And so I just put into my own search term, "What does SpinRite do?"  And bang, it was Episode 336.  And it's like, oh, thank you, Steve.  Now I've found it.



LEO:  He's thanking himself.



STEVE:  I'm thanking myself.  I'm recursive, Leo.



LEO:  No, it is, it's a very good point.  And it's one of the real advantages that the transcription gives you is that it makes everything in the show searchable.  It's really a disadvantage of audio and video media is they're just not searchable unless you do that.  And you know, it's expensive.  We probably should do it for all our shows.  You have set the bar.  We don't currently, but maybe we will.  We've looked at automated systems.  They don't work very well.



STEVE:  No.  And I would say, too, that this podcast probably more than others, we're laying down foundational, long-term stuff.  And my feeling was it was always an archive we were building from the get-go, as opposed to, for example, Tech News Today.  I'm not sure that the stuff you guys discuss, I mean, it would be nice to have it, but is it worth paying the price to have it.



LEO:  We have three more, and we're going to do them pretty quick here because we're running a little bit late, but that's fine.  Josh in Greenville, South Carolina says:  I don't have the iLuv Anti-Glare Screen Protector for my new iPad.  I'd like to get it.  I love it on iPad 2.  But they don't make it anymore.  Have you found a similar product?



STEVE:  I love it, too.  When people see my iPad, which has the antiglare screen, they just go, oh, that's so much better.  And my only real serious pet peeve with Jobs and Apple is that they just go for this high-gloss screen.  So I wanted to take the opportunity to remind our listeners that I have a separate Twitter feed, @SGpad.  And it will be - it has been active in the last week.  It will be active as I actually get the arrival of my pads.  And I'll be tweeting some stuff.  So anyone who's interested in following my pad stuff, I'm not going to clog my main @SGgrc stream with that, just over on @SGpad.  Follow me if you're interested.  And I will definitely find a replacement for the iLuv Anti-Glare Screen Protector.  And I'll be tweeting the things that I find over at @SGpad.



LEO:  It's odd that they stopped making that, actually.  Let's see, here.  Moving along to Question 12, our penultimate question.  Dean Murray, Sydney, Australia, gives us a Tip of the Week.  He says that you are very comprehensible when being played back at double speed, which you can do on many devices, including any iOS 5.1 device.  I've been doing it this way for the last 100 or so episodes, and it's made my binge-listening approach much more productive.  He said:  I cannot even begin to imagine doing that today with what we recently heard is 400-plus hours of content.  So he's got to speed it up.  By the way, Tom does sound a bit faster than Leo and Steve, plus I've been told by some Americans that Australians are fast talkers anyway.  It's actually well known cognitive science that faster speech is more intelligible.



STEVE:  Yup.



LEO:  So check on your device - iPhones, iPods, iPads all can play back podcasts at 1.5 or even 2x faster.  Audible also supports that in their apps.  Finally...



STEVE:  And if you are stuck in traffic, Leo, you can play it back slower in order to...



LEO:  If you've got more time.



STEVE:  So you don't run out of podcast before you get to where you're going.



LEO:  That's what I've found.  We debate how long shows should be.  We're an hour and 55 minutes into this show.  And I have found, I have learned that people don't care how long it is as long as it's not shorter than their commute.  They want it to cover the commute.  That's my supposition, anyway.



Jim Michael in St. Louis, Missouri with our last question:  Have you heard of buffer bloat?  He found a YouTube video talking about it.  He said he thought it was quite interesting.  We actually talked about it with Bram Cohen, the inventor of BitTorrent.  And it's a big issue for BitTorrent Live because buffer bloat really can up latency on real-time stuff, including Skype.  He says, I understand much of what the presenter says on the video.  There's some things I don't get, and I would love to have it "Gibsonized" for us mere mortals, or at least debunked if it's not real.  Anyway, I thought I'd bring it up here in the hope you could explain this information.  Thanks for the great podcasts.



STEVE:  And that's next week's topic.



LEO:  Yay.  Yay.



STEVE:  We're going to go into what buffer bloat is, where the problem came from, how well-intended designers didn't actually understand, unfortunately, the TCP protocol and the problems it is creating for us, why you can actually end up getting much less performance than your connection can provide right there at home.  That's next week on Security Now!.



LEO:  Yeah, I had no idea until Bram described it.  And Vint Cerf has weighed in against it.  I mean, it's a big issue.



STEVE:  Yup.  And what I love about it, Leo, is we've already paved all the foundation.  All of our How the Internet Works series discussing TCP performance and slow start and throttling, everything we need to know in order  to add this next bit of subtlety is in place.  So I think our listeners are going to get a good kick out of it next week.



LEO:  Good.  Oh, I can't wait.  Because I kind of understood the issue, and I'm wondering - unfortunately the stats about what buffer sizes are on most routers is not published.



STEVE:  No.



LEO:  So we need to cut through this.  Steve Gibson is at GRC.com.  That's where you'll find his great stuff, including SpinRite, the world's best hard drive maintenance and recovery utility, and of course all his free security programs.  And this show.  He has 16Kb versions available, as we mentioned; transcriptions, as well, a great search feature.  Go to GRC.com.  And if you've got a question for future episodes - we do Q&A every other episode - GRC.com/feedback has a form just for you.  That's the preferred way to communicate with Mr. G.



Follow him on Twitter, @SGgrc, and a little iPad activity there at @SGpad on Twitter.  And we'll be back next week to talk about many things, including buffer bloat.  We do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time at TWiT.tv.  You can watch live, but you can always download it.  16Kb versions from Steve in audio, but we have audio and video available in higher quality formats at TWiT.tv.  Well done, Steve.  Bravo.



STEVE:  Thank you, my friend.  On to the next podcast.



LEO:  Go eat some more meat, and I'll talk to you next week...



STEVE:  Bye-bye.



LEO:  ...on Security Now!.  Bye-bye.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#345

DATE:		March 21, 2012

TITLE:		Buffer Bloat

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-345.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's news, Steve and Leo examine the growing concern over, and performance problems created by, the Internet's "Buffer Bloat," which has been silently creeping into our networks as the cost of RAM memory used for buffers has been dropping.  It's easy to assume that more buffering is good, but that's not true for the Internet.



SHOW TEASE:  It's time for Security Now!.  Steve is going to blow the lid off the biggest scandal in router configuration ever.  It's called "buffer bloat," and you probably have it.  We'll find out how you can tell and what buffer bloat is, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 345, recorded March 21st, 2012:  Buffer Bloat.



It's time for Security Now!.  Get ready.  Fasten your seatbelts.  It's time to protect yourself and your privacy online with this guy right here, our Explainer in Chief, Mr. Steve Gibson.  For 345 episodes he's been protecting you.  Yes, sir.



STEVE GIBSON:  And we have an explainer episode this week that I think everyone is going to find very interesting.  This is something which has actually been at a low simmer for about a year and a half, when some of the serious guru designers of the Internet began to wonder why their home connections, for which they were paying a useful amount of money for "x" number of megabits, didn't seem to be performing as well as they expected.



LEO:  Hmmm.



STEVE:  And these are the guys who did all of this, and something seemed to be wrong.  It turned out that, over time, almost as you could expect, in the same way that we've had hard drives getting inexorably bigger and processors getting inexorably faster, RAM prices have been inexorably falling.  And manufacturers of routers just began putting more RAM in them.  In the same way that you cannot buy a small hard drive anymore, like hundreds of megs - you used to be able to, that used to be big - you can't even buy a few gig now.  Similarly, you can't buy a little bit of RAM.  You always get, well, a bloat load.



LEO:  A bloat load.



STEVE:  A bloat load.  So what's happened is our routers have large buffers.  And it turns out that's not good.  You would think, oh, that's good because then you won't drop packets.  But we're going to look in detail at why the Internet needs short buffers, how its entire design has been based on small buffers and load latency which small buffers deliver, and how this sort of silent bloating of buffering throughout the Internet is already causing problems.  We've got a cool way for people to determine whether they're bloated or not and to what degree.  And even some things that adventurous people can do.  So I think a great podcast.



LEO:  Wow.  Yeah, actually I first heard the phrase "buffer bloat" not so long ago on a triangulation.  We had Bram Cohen, the creator of BitTorrent, on.  And he, because he's doing BitTorrent Live, which we are on, we're part of their launch partnership, he learned a lot about streaming media and the problem of buffer bloat.  And then he pointed to an article by Vint Cerf which he said, well, they kind of got it wrong.  But he had a lot of empirical information about buffer bloat, and it was shocking.



STEVE:  Well, and one of the things that the torrent clients have recently started trying to do is to be better citizens on the Internet because their nature was to cause this bloat, which would, for example, collapse VoIP or regular web surfing, just there was no - this notion of fair treatment of different flows, where flows are like we've discussed connections before, unless you're very careful with that, it's difficult to guarantee that.  And what's really interesting is, even reading the most recent dialogues among these super bright people, they don't really have the answer.  So there's also an aspect of this which I find fascinating, which is there isn't a good answer to this problem.  It's really interesting.  I mean, the best minds have been scratching their heads, thinking, okay, what's a universal answer?



One of the problems is that we have such a incredibly heterogeneous environment, made up of all kinds of different stuff, many different link speeds, many different architectures.  The nature of the Internet is to just be glued together with these autonomous routers which bounce packets from one place to another.  So there's no way of knowing, for example, what the roundtrip delay will be between you and the place you're trying to connect to and back again.  It doesn't even have to be the same in each direction because, as we know, packets can travel different routes in different directions.  So this incredible freedom that we have, thanks to this cool design of the Internet, does create problems.  So we're going to cover that in detail this week.



LEO:  And I know you want to talk a little bit about your iPad.  But before you do, I do want a little bit of a coffee thing because yesterday we had a very well-known computer programmer on, Rich Siegel, who's at Bare Bones Software.  And he told me about the Black Blood of the Earth.  And I have ordered some, and I will give you a report on this.  You might be interested in this.  The Black Blood of the Earth is a coffee that is, well, it's kind of a coffee extract.  It's a cold extract using a vacuum.  Now, for $40 you get 750 milliliters of this stuff.



STEVE:  So it's concentrated.



LEO:  Highly.  He says that he recommends keeping it below 100 milliliters a day.  You've got about...



STEVE:  You mean your own consumption.



LEO:  Yes.  He says you've got about a month and a half worth of caffeine by Starbucks ventis in a single bottle.  So you could actually probably put yourself into fibrillation with this stuff.  But I have ordered it.  He says the reason he started doing it - the guy is a radiation specialist at Berkeley.  And he also spends a lot of time at Amundsen Station at the South Pole.  But he apparently needs coffee, but he's a diabetic, and he can't drink cream and sugar.  So he wanted to create a coffee brew that didn't have the acidity of regular coffee.  By cold extracting using a vacuum, apparently none of the acids are extracted, just the oils, the flavor, the caffeine.  And it's slightly sweet, he says, because there is a little bit of sweetness in the bean.  And when you don't have the acids...



STEVE:  Black Blood of the Earth.  Is that what you're telling me?



LEO:  It's at Funranium Labs.  I've ordered a sampler.  And a Stein of Science.  Black Blood of the Earth.



STEVE:  Oh, goodness.



LEO:  And this guy is pretty serious about it.  We will, as soon as it arrives, I will give you - because he does single bean extracts.  So he's really - there's a Guatemalan, a Colombian; there's a Rwandan.  There's one called Death Wish I didn't really want to try.  So stay tuned.



STEVE:  Wow.  I ran across a crazy inventor decades ago who - and I don't remember what the project was.  I was consulting for some company.  And so they found this inventor guy.  And he was, like, showing us his stuff.  And he had designed a camera which you mounted on the underbelly of a plane and flew into a hurricane.  And this thing somehow, it had spinning mirrors that could synchronize with the instantaneous wind velocity to take photographs of hailstones as they're being formed.



LEO:  Wow.



STEVE:  And he says, oh, and by the way, I have the best coffee in the world.  And so of course that caught my attention a little more even than hailstones.



LEO:  Always looking, always looking, yeah.



STEVE:  Exactly.  And his deal was the same thing.  He took - I don't remember the details now.  But it was cold, I remember, it was all about cold water, cold extraction.  And something like he took a whole Yuban canister like you buy at the supermarket, like the large tin, and he did something with it, like maybe he just poured cold water in it or something.  I don't remember now what the detail was.  But then let it sit.  And then he did, he definitely extracted this syrup from the result, and that was like his magic potion.  And then he would mix a tablespoon or two of that in a cup, add hot water, and it made like this amazingly zero-bitter coffee that he loved



LEO:  Right, right.  It also doesn't stain your teeth because the acid etches your teeth.



STEVE:  And it could melt hailstones like no one's business.



LEO:  There is a company, the chatroom's giving me a link to Toddy, a cold brew coffee system.  So I'll order that, too, and I'll let you...



STEVE:  Of course you will.



LEO:  Welcome, once again, to Coffee Talk, a subsidiary of the Gibson Research Corporation.



STEVE:  At least we're recording this time.  We started to record.  



LEO:  So as long as we're off on a tangent, I guess I have to ask you, so how many iPads did you get?



STEVE:  Two.  One 4G-LTE because I'm grandfathered in to the original AT&T unlimited bandwidth for $29.95.  And so one question I had was whether they were going to honor that, whether they would still honor unlimited 4G-LTE bandwidth that everybody is saying is faster than WiFi, if you get, like, standing under the tower and in the right circumstances.  When I went from the iPad 1 to the iPad 2, I moved the SIM card, and that's all that was necessary.  And the iPad 2 then thought it was on the same account as the old one.



Well, I tried to play the same game this time.  I did note that they were different colors and looked very different, the iPad 3 SIM card and the iPad 2.  Sure enough, I swapped them, and neither of the iPads were happy with their new SIM card.  So I put them back and then poked around.  And essentially moving the account was as easy as logging into that AT&T account through the control panel on the iPad 3, and it showed me my different plans, and the one that was chosen is one no one else can choose anymore, but that's the unlimited for $29.95.  And that one was selected, and it stayed selected, and it left me where I was.  So migrating was easy.



I've been a big fan of antiglare, as you know, antiglare film.  And so I've left one without the antiglare film and one with.  And so my overall take is that the iPad 2 is fine.  I mean, it does everything you want.  The iPad 3 is a constant surprise with how clear it is.  It's just, when I look at it, I'm like, wow, this is clear.  Now, I now that will fade because I had that original same sort of feeling with the first eInk, where it looked like it was just printed on the screen.  It didn't really look like it was real.  It looked like a store demo where you have to peel that film off before you actually can use it.  And that'll last for a couple months, where I look at it and just kind of marvel at this eInk technology.  Like, wow, this is neat.  It doesn't look like an LCD at all.



So now I have the same thing with the iPad 3.  I mean, it is really clear.  But people have said, well, I have an iPad 2, and I like it.  Do I need to upgrade?  And I would say, eh, no, probably not.  There has been some interesting controversy that you've probably heard, Leo.  We know that the batteries have been - somehow they squeezed substantially more watt hours into what is essentially the same size.  If I put them both, lay them both flat on the table, I don't see that the iPad 3 is really any thicker than the iPad 2.



LEO:  No, it's a millimeter.



STEVE:  It does feel heavier.



LEO:  Yeah.



STEVE:  Yeah, it feels heavier.  But the iPad 2 had 25 watt hours of total battery, whereas the iPad 3 has 43.8 watt hours.  So from 25 to 43, that's a substantial change in terms of energy density.  And the first thing that I thought when I saw the iFixit Teardown was, ooh, that's going to be slower to charge.  And sure enough, that's one of the things that we're seeing being noticed on the Internet is people who do run their iPad all the way down, it takes a long time to charge it back up because those little chargers are 2.5 watts and 2 amps.  And so, if you're charging a dead, an empty 43, to round it easily, watt hour battery with 2.5 watts, you do the math, and it's...



LEO:  Actually the iPad adapter is 10 watts.



STEVE:  Okay, but still 2 amps, I guess. 



LEO:  Yeah.



STEVE:  I think it's only 2 amps.  So it's going to take hours in order to charge it.



LEO:  It's slow, yeah, yeah.



STEVE:  And that's what we are seeing.  And then lastly, the last glitch that I just saw was the problem with some people's smart covers with the iPad 3 because the iPad 2 had magnet sensors that did not care about the polarity, the north-south polarity of the magnets.  And the problem was, people who folded their original iPad 2 covers back sometimes had their iPad think that the cover was closed over the front of it rather than being all the way opened over the back of it.  And so Apple fixed that little glitch by making the iPad 3's cover sensor magnets sensitive to north versus south so that it could tell whether the magnet was coming down from above or up from below.



But the problem is that some of the original covers and third-party covers that also take advantage of this, they had their magnets thrown in with no concern for their north-south orientation.  So what that means is that some will work and some won't.  It's just sort of luck of the draw.  And apparently Apple is now taking back covers that don't work and exchanging them for ones that do because, when Apple fixed this problem, they had to start orienting the magnets in their covers correctly.  So anyway, that's my iPad 3 trivia.



LEO:  Yeah, yeah.  I have noticed that on some of my covers.  Although Apple smart covers, of course, are correct polarity.



STEVE:  Yup.  In security news there's two things, both from one guy.  I've got sort of a past friend, current friend, and hacker named Jeremy Collake, who I'm sure I've mentioned in podcasts before.  He actually helped me with one part of the socket lock utility that I wrote.  He's adept with drivers, and so he was able to quickly produce one component of that little gizmo when we were locking raw sockets back in those days.



Anyway, he discovered something - actually, this sort of follows nicely on last week's discussion about server configuration and security.  He discovered that Apache servers by default have something called a "mod status module" installed and running.  And so, for example, if you go to www.washingtonpost.com/server-status, that's a pseudo page generated by this status module which gives you a real-time snapshot into the server.



Now, the problem is that these Apache servers are all over the place.  And you can see a list of the most recent URLs which have been served.  And as we know, URLs often contain sensitive data.  And these will be URLs, even if they were wrapped in SSL, this is once it gets to the server, after it's been decrypted, this server-status page will show you potentially confidential information.



And so anyway, Jeremy blogged about this.  His blog is thepileof.blogspot.com, if anyone is curious.  And, I mean, even Apache.org has their server-status page wide open.  And I don't want to go into any other organizations that do, but some very sensitive organizations with running Apache server, you can see the IP addresses of the people who have been visiting and what URLs they clicked on.  And just like, whoa.  And as far as I know, Jeremy is the only person who has noticed this and talked about it.  So he asked me if I would bring it to our listeners' attention.  Anybody who is an Apache server admin, unless you're explicitly serving that server-status page to the outside world for some reason, you may want to lock that down.  These things can happen, as we know.



And then the second point is many people have asked and been excited about the encrypted DNS service being offered by OpenDNS.  And until actually I guess even now, the client side, in order to use encrypted DNS, you need to be making encrypted queries of the OpenDNS server.  There wasn't a Windows client.  But Jeremy found the one that was currently available, I think over on Google Code, and checked it out and tried it, and it looks like it works great.  So his most recent blog entry, again at thepileof.blogspot.com, is how to use and configure the Windows client for issuing encrypted DNS.



And the reason this is of interest, I mean, I'm sure our listeners will understand this, we've all talked about the utility and growing need to encrypt our TCP connections.  But there is no encryption of DNS.  It's not available.  It's not offered.  It's not in the spec.  There's no equivalent of making an encrypted DNS query.  Which means anyone who's looking, for example, even at someone's encrypted traffic in an Open WiFi hotspot, will still see all their DNS queries, meaning that they know all the domains that they're looking up.  And while this is not a huge problem, it's an information disclosure problem.  And apparently there's enough interest that I've seen some people asking questions and tweeting me, asking me if I've seen and what I think about the OpenDNS encrypted DNS stuff.  So it is available on Linux, Mac, and UNIX, and there is the Windows client that Jeremy says works just great that's now available also for download.  So you can find out more about that at thepileof.blogspot.com.



And in just yesterday's news, actually I guess the last couple days, it came to light that the NSA - I don't know if you ran across this bit of news, Leo - is building a massive super-super-computer center in Utah with big cooling towers, huge water pumps to pump the water through the cooling towers to take the heat out of this place, its own energy generation system, all of the, I mean, this is going to be a top-secret NSA cyber-computation facility.  And the concern was, naturally, among people who listen to the podcast, uh-oh, does that mean that the NSA will be developing the technology to crack state-of-the-art encryption?



And so I thought, well, okay, I'm still not worried because 256-bit AES is so already overkill stronger than we need.  I mean, 64-bit is arguably strong.  128-bit, as we know, is not twice as strong with the bits being twice as long.  It's, well, 64 bits is going to be twice 32 bits.  So 32 bits we know is 4 billion.  That means that 64 bits is going to be 16 billion billion.  Which means that only 128 bits will be 256 billion billion billion billion.  That's just 128 bits.  And we keep going, multiplying for every one bit we add.



So I'm not worried about 256-bit AES encryption, which is now available.  I would say that's what I would recommend.  But what was really interesting is that the NSA has - apparently all kinds of different satellites, literally and figuratively, of the NSA are feeding into this center, and they have an amazing amount of storage.  And one of the things that one of the articles that I saw about this mentioned was that they're very interested in decrypting the encrypted foreign communications from years past which was still using less strong encryption.  So it's not so much that we have a concern today.



And what I loved about this was it brings up a really important lesson for us.  And that is that, while our current encrypted data may not be crackable today, it may be crackable a hundred years from now.  And the NSA has been storing encrypted communications globally for a long time and archiving it.  Even though they couldn't crack it, they figured one of these days maybe we will be able to.  So this facility that they're building is more designed at cracking the past than it is cracking now and the future because, frankly, now and the future is really, really strong.  We've got seriously strong technology.  But even a decade ago there was stuff they would dearly love to crack.  And a decade ago our encryption was not nearly as strong as it is today.



So that's an interesting lesson, that there are just these massive stockpilers and archivers of global communications that they don't know what they say yet.  But once this facility is in place and humming, probably literally, from miles away, and glowing at night, that's the project they're going to be on is bringing to bear insane computing power in order to peer back into encrypted data that is still opaque.  Which I think is kind of cool.



There was a story that I didn't have a chance to plow into, another one of these Wi-Fi Alliance things where somehow our cell phones are going to be authenticating to wireless hotspots.  And so it's not clear.  There's no technical information yet.  I did dig as deep as I could, and all it was was a press release saying that, due to the proliferation of wireless hotspots, and of course the cellular carrier preference for moving their customers to ground-based WiFi rather than competing for limited cellular bandwidth, you can sort of see that the cellular providers would like to somehow get their customers moved over.



For example, the iPad, mine is AT&T and WiFi.  And when I'm somewhere where there's a WiFi access point that I have acknowledged and logged into, the iPad will preferentially use that bandwidth over using cellular.  So there's some movement afoot to make this official.  And it's still premature.  I'll keep my eye out for it.  And if any of my Twitter followers see any more details, by all means give me a heads-up so that I can kind of look into it.  But one hopes that whatever it is they do, they do correctly.  And it would be neat, for example, if there were some sort of encrypted negotiation so that you were able to seamlessly encrypt your connection to a WiFi hotspot rather than, I don't know, join it in some fashion without the advantage of encryption.  So that would be nice because your cellular connection is always encrypted; whereas, as we know, any use of WiFi hotspots is just not at all.



And then there was another story that I was unable to track any more details down.  Maybe you ran across this, Leo.  The RIAA and the MPAA were at a conference two days ago and saying that by June, like June 1st was the date that was quoted, so just a few months from now, ISPs are going to be watching their users' behavior on behalf of copyright holders and, for the first time ever, are implementing infrastructure, which is what it takes on the ISP's side, to start sending notifications to their customers if they see them downloading copyrighted material.  First they get - they get a couple notices first, and a few strikes.  And then your bandwidth gets throttled.  And then ultimately you get disconnected.



So that's news, to have ISPs which to this point have just been blind bandwidth carriers of ours.  I mean, they've been doing some shaping.  We know that they've been caught trying to throttle things that they thought were using too much bandwidth.  But they weren't doing any looking at our traffic.  So this is a concern.  Now, the good news is SSL is our friend because they can't filter and look into any of our SSL connections.  And they can't proxy them unless they start making us accept a browser certificate, which will be the end of life as we know it.  So none of that is apparently happening.  But for people who are not using SSL, a few months from now the word is - and it's a whole lineup of, like, a bunch of the major ISPs are saying they're going to start being proactive.



LEO:  This is that "six strikes" rule.



STEVE:  That's the one, yes.



LEO:  AT&T, Verizon, Comcast, Cablevision, and Time Warner.  It's a voluntary agreement.  It's not a legal - it's not a law.  But...



STEVE:  But why?  I mean, like, we're their customer.  Why are they serving the interests of the RIAA and the MPAA, who are doing everything they can to mess things up?



LEO:  The article that I found is eight months old, so I don't know if this has changed.  But at this point the ISPs say, "We will forward copyright notices to subscribers, but we won't turn over information about subscribers without a court order."  It's a one-way street.



STEVE:  Yes.  As far as I know, that is still the case, based on what I saw that talked about what was just being said two days ago.  This would be ISP to their customer, not - and I didn't mean in any way to imply that data is going from the ISP back to the copyright holder.



LEO:  What happens after five or six alerts, which is quite a few, is the ISPs have agreed to institute mitigation based on the copyright holder's request, which could include temporary reduction of Internet speeds (throttling), redirection to a landing page until the subscriber contacts the ISP to discuss the matter or responds to some educational information about copyright or other measures the ISP may deem necessary to help resolve the matter.  This does not involve a disconnect at any point from Internet service.  But throttling can be a pretty serious penalty.



STEVE:  Yeah.  So now we come to the question, what constitutes copyrighted material?  How is that determination made?



LEO:  Well, it's a letter from the copyright holder.  And I have to say, this system is very broken in a number of ways.  For instance, YouTube, which has this DMCA takedown.  I am now getting a notice on almost every show we post that we contain content from - and it's people we definitely don't contain content from, often Brazilian broadcasters, just strange.  And I think what's happened is these people are gaming YouTube now so that they are saying, well, they're giving them something, and it sets up a - it's all automatic at YouTube's end.  And what it does is it allows these guys to put ads into my content because YouTube gives you a choice.  YouTube says, well, we'll take it down, or you could put an ad in, or you can offer to sell the content if it's a song or whatever.  And so what these Brazilian television stations are doing, I think they're doing this as a gaming thing, but I haven't really done much digging, is putting ads in our content.  So you're getting a false - I think they're getting a false copyright notice.



STEVE:  False, yeah.



LEO:  And then getting the right to put an ad in our content.  It's just appalling.  And so you could see how this kind of copyright notification system can be absolutely abused.



STEVE:  Well, exactly, and that was my point, was that the ISPs are adding automated systems.  So, for example, in order to send out notices and to count how many they've sent, and including to actually actively filter the queries that their customers are sending out to the Internet in order to retrieve what is believed to be copyrighted content, this is all new infrastructure.  This is some serious equipment that the ISPs are for some reason installing and sticking in the circuit of their customers in order to offer this service, such as it is.  But the question is, then, where is the list of what is copyrighted coming from?  Their filters have to be driven by a blacklist of...



LEO:  I don't think the ISPs are doing this.  Isn't it the copyright holders who are notifying the ISPs?



STEVE:  But, like, what, on every file on the Internet?  You see what I mean?



LEO:  Here's what it says:  "Copyright holders will scan the 'Net for infringement, grabbing suspect IP addresses from peer-to-peer filesharing networks."  BitTorrent, if you're not smart, for instance, you can see who's sharing it.  If you're smart, you just encrypt and that doesn't happen.  So if they see your IP address participating, they'll then contact that ISP.  By the way, this is better than the old procedure, which was they would ask the ISP for information, and the ISP might actually give it to them.  Now the ISPs say, no, we're not going to give you any information.  We'll notify them, and we'll do the six strikes thing.  So I think it's just a formalized agreement about what will happen.  But copyright holders have been doing this for ages.  This is the only way they can do that.



STEVE:  No, see, but this is different.  What you're talking about is what has been happening, where IPs were identified as being infringing, and then the ISPs could notify their customers.  Now the ISP has some sort of blacklist of content, not of customers, but of content.  So if one of their customers downloads that content, the ISP says, oh, that's copyrighted content.  And so my question is, where does that list come from?  That seems to be the real problem because the ISP has to be able to identify customer queries that are attempting to fetch copyrighted material from the Internet.  Not by customer, but by the name of the material in the URL.  And so there's got to be a list of that somehow that the ISP's filters trip on.



LEO:  I don't see that on the original article.  Here's an article from the Law & Disorder column a couple of days ago in Ars Technica, the "Copyright Alert System."  Everything I've seen says that it is still incumbent upon, not the ISPs, but the copyright holders to notify the ISPs.  So I'm trying to find that information.  So you're saying that the ISPs are now running some sort of filtering.



STEVE:  My understanding was of that.  Maybe that's not the case, though.  Maybe it's just that they're maintaining the six strike counter and being more proactive in what they do with their customers.  And there just isn't enough information yet about what this thing is.  I did want to bring it up because it popped onto my radar, and I knew that our listeners...



LEO:  Yeah, I don't blame you.  Here's probably the one you saw, which was from the panel.



STEVE:  Yes.



LEO:  "Each ISP has developed their infrastructure for automating the system.  Start date for traffic.... Major labels monitor BitTorrent and peer-to-peer networks for copyright infringement, then report that infringement to ISPs."  Oh, so it is the labels doing it.  I really think that this agreement is the ISPs trying to get out from under this.  They've set up a system, but it's so that they don't have to do anything more.



STEVE:  Well, and it does sound like it's a benefit to customers because the ISPs will not be turning over the customers' identities to then be brought up in these ridiculous lawsuits that we've covered.



LEO:  Unless there's a subpoena.  So these ridiculous lawsuits are all John Doe suits, which then the point is to get the court to go to the ISP, saying, okay, hand over that information.



STEVE:  And compel them.



LEO:  And compel them.  And I think that this is the ISPs saying, look, let's just do it this way, and let's not go to court.  And frankly, I think the record industry and the motion picture industry are looking for a way to save face and to back down on all these John Doe court cases.



STEVE:  You know, I think that's right, too, Leo, because I do remember reading something about, like, a pro forma letter that said individuals at the account associated with the IP address of your account have downloaded copyrighted materials.  So this probably represents an interface between the copyright holders who are still responsible for generating IP lists of misbehavior, and then those they turn over to the ISPs managing those IPs, and then the ISPs now are taking a new role in notifying the customers who have those IPs.



LEO:  Right, exactly.  And there is an appeal process.  This is, I think, a way to avoid a three strikes law.



STEVE:  Yeah, good.



LEO:  Which nobody wants except the copyright holders.



STEVE:  Right.  I did want to just mention that I finished Book 13 of the Honor Harrington series.  Actually there's probably one or two more coming.  I'm glad that I read them.  I have this - this whole new world that exists in me now, after 13 novels.



LEO:  The Honorverse; right?  Isn't that what they call it?



STEVE:  Yeah, the Honorverse.  And it wrapped up in a nice place.  I'm not chomping at the bit for 14 and 15.  David can - I mean, 13 just came out, like this month, earlier this month.  So it just happened.  So I imagine I'll wait a year or two for 14, and then I'll read that; and 15, and I'll read that.  There are other ancillary books, but I'm not going off and down those rat holes because I've had all I can handle with 13.  And as I mentioned last week, I'm excited now to start reading more about nutrition, which is my current reading focus.



LEO:  I got a very nice email from somebody who pointed me to Gary Taubes' blog post about that Harvard meat study, in which he blows it out of the water.  And I had forgotten - I had read "Good Calories, Bad Calories," which is the book I know that you're taking as gospel.  And he blows it out of the water there, too, these epidemiological studies...



STEVE:  Yes, that's the problem.



LEO:  ...that our entire nutrition system is based on now.



STEVE:  Yes.



LEO:  They've gained such currency.  And it's really very simple.  It's funny, I posed this question to my daughter, who has studied statistics.  And she's actually taking a course at her university called "Citizen Science," which is about educating non-scientists in scientific thought so that they can more intelligently judge things like this.



STEVE:  Nice, nice.



LEO:  And I said, "Abby, what's wrong with this study?  They took 100,000 physicians, and they followed them for 18 years, giving them the questionnaire about what they ate, and then checked their mortality.  And according to this study, they had a 20 percent higher chance of dying prematurely if they ate meat.  What's wrong with that study?"  And she cut through it right away.  I was really impressed.  She said, "Well, the problem is, for those past 18 years, we've been told that eating meat is bad for you.  So the core cohort of physicians who are eating less or no meat are probably also people who take better care of themselves in other ways.  So it's a self-fulfilling prophecy.  Since we've been told eating meat is bad..."



STEVE:  Yeah, very good, Abby.



LEO:  "...people who don't eat meat are going to be more likely to take good care of themselves.  Correlation does not prove causality."



STEVE:  Exactly.



LEO:  A-plus, Abby Laporte, you get a checkmark on your quiz.



STEVE:  Yep.  In fact, you and I may remember - you may remember that you and I, a long time ago, we were talking about the problem of tracking down causality.  And I think we used the analogy of an alien landing in New York and noticing that, when the rain came down, everyone opened their umbrellas.  And that unless you under...



LEO:  Umbrellas cause rain.



STEVE:  Exactly.  Unless you understood what the actual mechanism was, you could easily draw the wrong conclusion.



LEO:  And that's why we have scientific process.  That's why the scientific method exists.  As Taubes points this out, okay, now you have a theory.  That's all you have.  Now you actually have to test, and this is what's so difficult, well, does meat actually cause mortality?  We maybe have a theory based on this epidemiological study, but you have no information.  So now you create a scientific double-blind study, and then we'll know.  But of course nobody's doing double-blind studies with meat eaters.



STEVE:  Well, actually the problem is that dietary studies are notoriously difficult because you don't know about the level of compliance that the people actually have to the diet, and we're talking about problems that manifest over decades.  And that's, I mean, that's the real problem is...



LEO:  It's very difficult, yeah.



STEVE:  ...because we're really not good about anything that takes that period of time.



LEO:  He says, and he does quote in the book, both books, "Good Calories, Bad Calories" and his kind of more popularized...



STEVE:  "Why We Get Fat."



LEO:  ..."Why We Get Fat," he talks about a study that was done on all the popular diets and those who followed closely each diet and the prognosis for each.  And oddly enough, counterintuitively, Atkins won, against the Zone Diet, against the Pritikin Diet, Dean Ornish's diet.  And he says that's the only evidence we have.  So anyway, you were right.  I brought it up unthinking.  Fortunately my daughter has a better head than I do, and I read the blog post from Gary Taubes, which was just well done.



STEVE:  Well, and in fact at the end of the first part of "Good Calories, Bad Calories" - and I'm going to start that from the beginning because I took a break from Honor Harrington just because this sort of came on my radar, and it immediately captured my attention.  The book I'm reading currently is one on nutritional anthropology, which is really interesting.  But the point is, at the end of the first section where Gary talks about how it is that our society came to believe that fat is bad for us, that a low-fat, higher carb diet is heart smart or heart healthy, it turns out that there's one guy that's responsible for this, and he doctored his data.  Ancel Keys is his name, since no longer with us.  And at the end of that, in a beautiful, short paragraph, Gary explains the fundamental impossibility of using epidemiological processes to determine dietary outcomes.  And when I encounter that again I'll share it because it was very short, and it was just spot-on.



LEO:  Thank you.



STEVE:  So, interesting stuff.  My news is that I've moved to Firefox v11.



LEO:  Wow, Steven.



STEVE:  From 3 to 11.



LEO:  That's quite a jump.



STEVE:  They have solved the memory problems.  So I wanted to let everyone know that my big complaint was that 8 and 9 and 10 kept saying, oh, we're better about memory, we're better about memory.  It's solved now.  You close pages, and you get back the memory that those pages were taking, which is the first version of Firefox since they broke it a long time ago that that's been true for.  And really what was my final motivation was that I wanted to be able to turn on SPDY in Firefox, which is available in v11.  You need to go to, using v11, because it's not on by default, you go to about:config.  You put about:config in the URL.  That brings up a pseudo config page.  Then, in the search term up at the top, the search field, just type in "SPDY," and that'll find you that subset of configuration settings involving the SPDY, the so-called SPDY protocol, and it'll be turned off by default.  Just double-click it and flip it back on, or flip it on.  And you then have SPDY support in Firefox.  And there is an add-on which will show when you are using SPDY connections as you surf around the web.



But also, while you're in that about:config, if you type in "cookie," you'll be taken to a bunch of lines involving cookies.  And there's an interesting setting that I did some research on after I found it.  It's network.cookie.thirdparty.sessionOnly.  And you can turn that on.  And people who are concerned about tracking and would like more prevention of that, sort of just generically, this makes third-party cookies session-only, so that when you close the page for a website, the third-party cookies that may have been transacted and in some cases have to be in order to use things - like some Facebook apps require third-party cookies.  Someone told me that some Google services now won't function because Google is using their own third-party domains to glue their things together, so you have to have third-party cookies enabled.  So you can make them just session-only.  You close the page, and they're never written to disk, and they just go away.  So that's another nice little feature that's probably been in Firefox for a while.  But I just happened to put in "cookie."  I searched for that when I was searching for SPDY because I wanted to turn that on.



And lastly, just complete randomness, I wanted to find good wallpaper for my super high-density, high-definition screen on my iPad 3.  And I was reminded of one of my favorite websites, I became a lifelong member years ago, called DigitalBlasphemy.com.  And this is a guy who for a decade has been using a huge array of digital artwork creation tools to generate really beautiful scenes, scenes of nature, castles in the background with lakes and trees in front of them and snow in the distance, complete abstracts, neurons firing, and all of this is available at very high resolution, I mean, like full desktop, large monitor resolution.  He also has dual and triple monitor versions so that you can have your wallpaper stretch out over a three-monitor setup, rather than have it repeat, have it all be coherent.



So anyway, I just wanted to tip our listeners off to DigitalBlasphemy.com.  It's a great site.  There's stuff that's available for free.  You can join for a year.  I joined for life because I always wanted access to it, and it's been worthwhile.  He keeps generating new stuff every year.  So that lifetime subscription ended up being useful.  And I like to support someone who's doing that stuff.  I mean really beautiful, beautiful artwork.



LEO:  Yeah, he does great stuff, yeah.



STEVE:  And I heard from a listener, Ken Harthun, who wrote to me on the 19th of February:  "SpinRite saves a student's laptop."  He said, "Steve, I'm a loyal listener of Security Now!, having listened to every single episode.  That first episode was only 18 minutes and left me wanting more."  Well, we've taken care of that.



LEO:  Was it that short?  Wow.



STEVE:  Wow.  And that was your original concept, Leo, was just to do sort of a check-in on the week.  It's like, okay, well, that didn't last long.  And it's funny, too, because I remember Elaine quoting me for transcription, didn't sound like it was going to be very expensive, either.



LEO:  No, sorry about that.  Whoops.



STEVE:  Oh, it's been worthwhile, and I haven't looked back.



LEO:  Thank you.



STEVE:  So he said, "Today's episode was a little over two hours and still left me wanting more.  You are often the source and inspiration for my Security Corner blog posts over at IT Knowledge Exchange.  So a big geek thank you to you and Leo.  Please continue."  He says, "I first used SpinRite in 1999 - it was v5.0 - to recover a floppy disk that had been corrupted.  Since that day I've insisted that wherever I worked, the IT department agreed to make SpinRite available to me should the need arise, and too often it has.  In my private service world, I always insist that, if SpinRite recovers the drive for my client, that my client purchase a copy.  Needless to say, there have been a few sales as a result."



LEO:  That's good idea.  That's a good way to do it.



STEVE:  I have no problem with that, yeah.  He says, "I have my own copy, of course, and last summer I insisted that my new employer, Antonelli College, where I am the network administrator, purchase a site license.  Well, that's a good thing because last week it saved one of their students' laptops and all of her interior design coursework.  Windows was throwing all kinds of errors.  The wireless wouldn't connect.  She gave me a list of seemingly random errors that didn't seem to make a whole lot of sense.  But they pointed toward a hard drive failure.  I was about to attempt to backup the data and restore the system when it just completely locked up, and I had to force a shutdown with the power button.  On restart it just hung at the starting Windows screen and would go no further.  I could hear the drive thrashing about.  Not good.



"Enter SpinRite.  I booted up from my thumb drive and ran it at Level 2.  After a couple of hours SpinRite reported that it was finished, though no errors or bad sectors were found," which of course is a story we've heard many times.  And I've explained why that doesn't mean SpinRite didn't do anything.  He says, "On reboot, the system came right up, faster than ever, connected to the wireless, and immediately began downloading updates.  I completed the updates, ran a few tests, and pronounced the patient healthy.  Needless to say, the student was ecstatic.  And thanks to SpinRite, I did my part to provide a 'superior student experience.'"  He says, "Part of our vision statement for the campus."  He said, "Steve, SpinRite is absolutely the best hard drive maintenance and recovery utility on the planet, and maybe in the universe.  It's worth 10 times the price you charge for it.  Thanks for all you do.  Ken Harthun."



And he said, "P.S.:  I've never had a hard drive failure, and I attribute that to my using SpinRite on my own systems on a regular basis."  And of course we understand also why it is a good preventive maintenance utility.  Running it on a drive, even a quick Level 1, shows the drive where it's got problems developing that it's able to correct before they get critical.



LEO:  All right, Steve.  What is buffer bloat? 



STEVE:  Okay.  Our listeners who are live can start something up in the background while we're talking, so that when we get down to where we're talking about what this is, they may have some results.



LEO:  I've done it already, and I have my results.



STEVE:  Cool.  This is Episode 345 of Security Now!, so I have done what I've done before, which is create a bit.ly link with the episode number, bit.ly/sn345.



LEO:  Bit.ly/sn345.



STEVE:  Yup.  And I made it both uppercase "SN" and lowercase "sn" so that it didn't matter which people used this time.  That will take you to what's called the "Netalyzr," which has been put together by the ICSI at Berkeley.edu, at UC Berkeley, at the International Computer Science Institute.  It is a Java applet.  And I tweeted this link in preparation for the podcast earlier this morning and got some of our listeners who sent back, "Steve, that's Java.  What's happened to you?  You're running Java?"  It's like, yes, yes, we have no choice.  And a couple of people said, well, I'll install it just for this because it sounds really interesting, but then I'm uninstalling it."  It's like, okay, fine.  I mean, we're losing this battle against scripting.  So I'm accepting that, that scripting is the future.



The beauty of this application in Java, this is a stunning piece of work.  And when I'm looking at what they can do in Java, I'm thinking, ooh, I could do some amazing stuff, which has the benefit of being platform agnostic, which is really important, being able to do low-level, packet-level work, and writing it once, and being able to run it across platforms.  Of course it won't run on an iPad.  You need to have something that'll run Java, and the iPad won't, in the same way that it won't run Flash.  But you do get both Mac and PC.  So, yes.  This is a Java applet.  Let it run.  It takes a few minutes, maybe five minutes.  And there is one of the things it does is measure the size of your buffers, that is, under load, the latency that the buffering between you and them has.



LEO:  By the way, we have killed the site.  So people, go later, don't go - everybody went all at the same time.



STEVE:  Oh.  Oh, you mean we killed Berkeley?



LEO:  Oh, yeah.



STEVE:  Oh.



LEO:  Berkeley.edu is down, my friends.



STEVE:  Actually, when I tweeted it that happened.  And I even tweeted about OneID, like a week or two ago, and they went down.



LEO:  People don't build sites, you know this, they don't build sites for the peak.  They build them for the average.  It's too expensive.



STEVE:  You cannot afford to build them for the peak, yes.



LEO:  So when we send 1,000 or 2,000 or 5,000 people to a site, of course it's going to - most sites will go down.



STEVE:  Bye-bye.  Okay.  Let's step back.  We've in the past created a perfect foundation of knowledge about the way the Internet works for understanding the problem with buffering.  We understand that, instead of a modem connection, where you actually have the equivalent of wires from the sender to the receiver, and you know exactly what the bandwidth is because that's the baud rate of the modem or the bandwidth of your point-to-point hardwired connection, that's all gone now.  And I remember describing how, I mean, what a conceptual leap it was in the minds of the original designers, the concept that you could create virtual connections, not actual physical connections, but the equivalent of a virtual connection, with the agreement between endpoints that they were connected by maintaining some state information, some knowledge at each end about the condition and the history of their connection, and then having them just launch packets of data towards each other which the intervening Internet of routers would arrange to get to the other end.



And I've talked about router buffers before in this context, where you think of a router as like a star, like a hub with a bunch of connections coming out of it, going north, south, east, west, and other compass directions, and packets are coming in on various of those connections to interfaces on the router.  Then they go into the core, routing core of the router, which examines the IP address at the front of the packet and decides, using its routing table, which is the best interface to send the packet back out on.



So the timing of all of this is uncertain.  These packets are arriving on all these different wires coming into the router whenever they want to, asynchronously.  And it's having to sort of shuffle them around, look at them, and then send them back out.  But if by chance a bunch of packets came in on three lines that all wanted to go out on a fourth line, and assuming for a second that these lines were all the same speed, well, if three came in, or if a bunch of packets came in from three lines, they can't all go out at once.  They have to be lined up.



So interfaces in routers have buffers.  They have a staging area where packets can be placed to sort of deal with these little brief events, sort of just the need to deal with the fact, as a consequence of this autonomous routing, where we've just got packets flying all over in every direction, the consequence of that is we need some buffer.  We need to deal with the possibility that there'll be moments where a connection is saturated, and where it's not so saturated that we have to throw things away because, if we had no buffer, then we would be over-discarding packets.



But one of the other weird consequences of this multilink links between routers, we've got links, our WiFi from our laptop on the couch to our WiFi router.  Then there's a link to maybe our DSL modem or our cable modem.  Then there's the cable link to the ISP's network.  Then there's multiple routes through the ISP.  Then there's their link to the Internet.  Now we're on, finally, after all those links, we're on the core of the Internet.  So then we've got multiple major Tier 1 providers, like Level 3, for example, and others that are major carriers.  And they get the traffic over to another ISP where, through many links, it gets back to its destination.



So all of these links, probably almost without exception, they're running at different speeds.  There's big hefty multi-gig fiber links.  There's GigE Ethernet links.  There's 100Base-T links.  There's who knows what between the cable modem or what the cable modem is actually doing in terms of its connection.  Then there's a link between it and your WiFi router, and then there's your WiFi link.  And we know that WiFi, actual WiFi performance varies greatly, depending upon the signal strength and multipath interference and various things that the WiFi system is doing in order to make it work.  So, I mean, it's just when you stand back and you look at this, it's amazing, frankly, that any data gets anywhere at all.



But what's significant is that there is no way to know what the bandwidth is because of all of these links and routers.  That is, it's one thing to talk about buffering.  Think about buffering as sort of short-term overage handling, where just in an instant three packets can all want to go out one wire, and they've just got to line up a little bit.  But if over time many input feeds were saturated that all wanted to go to one output feed that was no faster than the inputs, then more data would be coming into that router than it was possible for it to send out.  And so it would have no choice but to drop packets.  Its buffer would fill, and then no more could get in.  And so it just wouldn't happen.  They keep coming in on the wire, but there's no where for it to put them.  It can't get rid of them fast enough, so it's got to just discard them.  And we're discussed this.  That's the way - that's the genius of the original designers was that they said, okay.



LEO:  Throw it out.



STEVE:  Not all packets have to get there.



LEO:  Right.



STEVE:  They made peace with that, which had to have given them some sleepless nights.  But they said, okay, we're just going to make, I mean, that's like - that's the tradeoff of a packet-switching network is we can't guarantee that you're going to be able to send as much as you want because other people could be competing with you on the same thoroughfare, and just you can't get there.  So you'll have to back off.  You'll have to throttle back.



And that is the genius of the TCP protocol.  Remember that we've talked about the way TCP works.  It starts off slowly, the so-called TCP slow start.  When you initiate a connection to a remote server, your computer doesn't know how much bandwidth you've got.  It doesn't know how fast it can send the data.  So it starts sending it and hopes for the best.  And as time goes by, it sends the data faster and faster and faster.  What it's trying to do, it's trying to sense when the link gets saturated.  And because of all these hops and all these links that may be running at different speeds and may have differing levels of congestion, we don't know where we're going to have a problem.  But at some point along the way, there will be a situation where packets are lost.  They may be lost due to a momentary surge, where there's competing traffic, or they could be lost at any point.



And this is a key concept.  At any point where the bandwidth drops, any point where you go from a high-bandwidth flow to a reduced bandwidth, you're going to have a problem because, up until then, you've been able to send packets at high speed.  As soon as you drop to lower bandwidth, as we've seen, there will probably be a buffer of some sort there.  It'll be some device which is doing the best job it can.  But you're just giving it more than it can send, so it has no choice but to discard something.  So the brilliance of TCP is that it senses the loss of packets when the packets it's sending are not being acknowledged.  When it fails to get acknowledgment, it assumes packet loss, so it backs off.  It slows down in order to sort of adjust to having hit the ceiling.



Now, it doesn't know whether that was a fixed bandwidth limit that it hit, and so that it should just stay where it is, or that it could have equally been a burst of congestion somewhere along the way that's gone now.  So it always creeps back up.  And so what TCP is always doing is sort of riding just under the ceiling of what it's able to establish.  It's always trying to push a little harder.  And when it gets the news back that, whoops, packets apparently have been dropped because it's not getting acknowledgments of their receipt from the far end, then it takes that as, oops, okay, I found the ceiling again, back off a little bit, and then it begins to creep forward.



So that's been the solution.  But what that depends upon is low latency, that is, that depends upon, by its nature, that soon after it's going too quickly, it receives notice that it's not.  And it was trying to think, Leo, of the best analogy, and I got a great one that everyone can relate to.  And we've all seen on newscasts how painful it is for two people to talk over a satellite delay which is substantial.



LEO:  Yeah.  You see it on CNN all the time, this long lag.



STEVE:  Yes.  Or, bless his heart, Chris Matthews cannot shut up.  And it's so...



LEO:  On MSNBC, yeah.  You have to just stop talking.  That's the only way to handle it.



STEVE:  Yes.  Well, and what he does is worse because - and I've watched this over and over and over.  He'll be talking to somebody in Iraq, and the person is sitting there, patiently waiting, because Chris loves the sound of his own voice.  And so Chris finally ends with a question.  And then, just as the other person hears the end of it, Chris thinks of a better question.



LEO:  Yeah.



STEVE:  And so asks him, he sort of, like, amends that question and goes on.  And so you see the other guy beginning to respond, and then he hears Chris change his mind about the question.  And it's just like, oh, my god.



LEO:  Painful, yeah, painful.



STEVE:  Anyway, so the point is, what is that?  That is two people, two entities, trying to interact in a real-time fashion in the face of delay, that latency.  And you just can't do it.  It creates a problem.  And so what has happened is, over time, all of the specifications have been laid out beautifully.  If you look at the RFCs, everything I've talked about is spelled out in detail.  Nowhere, nowhere does it talk about the size of the buffers.



LEO:  Yeah.  Unfortunately.



STEVE:  Never comes up.  Never did come up.  Now, it used to be that RAM was expensive.  So buffers were small because even Cisco making BigIron routers, they were trying to get as much profit margin as they could, and hardware was expensive 15 years ago, 20 years ago.  So the buffers were small.  And also these were the engineers who designed the Internet.  They knew that packets were supposed to be dropped.  And I've said it in our original tutorial series on How the Internet Works, that's the genius of packet routing is, oh, well, packet got dropped.  We couldn't get it there.  And all the protocols have been designed with that in mind.  TCP sets its speed assuming that, immediately after the bandwidth is hit, it will get a notification that lets it back off.



But now what happened?  Everything got cheap.  Chips get big.  RAM, huge amounts of RAM is built into the ARM processors, just because why not?  We keep making the die sizes larger, and the details we're able to imprint on the chips are becoming ever smaller.  We're able to increase the transistor count dramatically.  So being able to say, oh, this thing's got 256MB of RAM, well, it doesn't cost anything.  And so the router vendors, really, who are not the Internet engineers that founded Cisco and Jupiter and the major backbone providers of the Internet, they're thinking, hey, we can have larger buffers.  And then packets won't get dropped.  Won't that be wonderful?



Well, turns out the answer is no, that's really bad because what happens is, it is often at the client router, at the end-user router, that we have the biggest drop in bandwidth, that is, where we go from large bandwidth pipes to a restricted bandwidth.  And if this router has large buffers, and now we're talking, I mean, they could be, and in fact in some they are, megabytes because the RAM is there, it's free, it's on the chip.  And it would take a certain amount of self-control for the designer to say I'm only going to use 10K when he's got a meg, and when he thinks, oh, not understanding this, thinking that dropping packets is bad.  Turns out, no, dropping packets is really important.  That's the only way that TCP knows how fast it can go.  And if you allow TCP to keep going faster, it will fill this huge buffer.  And only when this huge buffer is full will packets start getting dropped.



The problem is that, remember that it's the acknowledgment of unreceived packets which is - I'm sorry.  It's the non-acknowledgment of packets that were not received that tells TCP to stop.  So what happens?  TCP keeps filling this buffer, which then goes into a - it drops in bandwidth, there's a constraint, before it gets to the endpoint.  Well, the endpoint is happy because it's still getting data from the buffer.  So it's continuing to acknowledge the correct receipt of the packets incoming, which continues to encourage the sender to, not only keep sending them, but to send them faster.  So this buffer continues to fill.  It starts even filling up faster now because, due to its depth, the recipient is still getting data from this big buffer and acknowledging, so the sender keeps cranking it forward.  So what ends up happening is we end up, as a consequence of this delay, we end up delaying the news to the sender that a long time ago we hit our bandwidth limit.



Well, what TCP does is it backs off by a percentage.  It assumes timely notification.  So if you put a big buffer there, it backs off by a percentage of what it was sending.  But the buffer has been so big that it has gone way beyond the recipient's actual ability to receive.  So even backing off a bit doesn't solve the problem.  It's still going too fast.  And then it backs off again, and it's still going too fast; and again, and it's still going too fast.  So you end up with this big problem caused by a buffer which is too deep.



Now, the other thing that happens is the phenomenon that people see at home.  And this is what got Jim Gettys, who is the person a year and a half ago who got onto this problem, he noticed that interactive gaming came to a standstill when he was downloading a file.  Or, no, I think he was uploading a file, actually.  So the idea was that he was uploading a file, and even the reverse direction had a problem.  Well, the reason that happens is notice that we've got data for TCP.  Acknowledgments have to go back also.  So if you've got a buffer, a large meg buffer, which is full to the brim, carrying one flow of traffic, then what's happened is you've introduced a delay.  You may not care if the movie you're downloading to watch later isn't - you don't care about the real-time performance of that.



But you care about the real-time performance of web surfing, where inherently you're getting a page.  That page comes in, and you're wanting to set up a whole bunch of new connections to all the other places that this page needs to be built from.  And so the web page is highly interactive.  But if you've got your router buffer, an overly large router which has been allowed to fill up with traffic from a download going on, suddenly now other traffic is stuck at the end of it, if it can even get in.  It may be discarded prematurely because this buffer is full with someone else's work.



And even if it wasn't, we require - the assumption on the Internet is a roundtrip time on the order of 100ms.  100ms is, out and back, is sort of - that was the target that these protocols were designed around.  And maybe it's 200, maybe it's 150, 156.  I'm looking at my own roundtrip, and I'm seeing, oh, it looks like about 60ms between here and GRC.  And I'm actually going up to Northern California before I jump onto Level 3 and come back to GRC's servers.  And I see a worse case of about 158ms.  And that's what ping shows you when you ping something.  So you could use the ping command to ping Google or ping Microsoft or ping Yahoo! and get a sense for what your roundtrip time is.  But it's relatively fast.



And web surfing, interactive use depends upon that kind of performance, that kind of speed.  So if we have a large buffer in our router, as long as it's empty, we're fine.  We'll get good interactive performance.  But as soon as it fills up, if it's ever allowed to fill up, that large buffer equals delay if it's full.  And then all, I mean, then, quote, "The Internet is slow" is what everyone else in the family starts saying, even if there's, like, ample bandwidth.  You could have a 100Mb down and 1Mb up, yet if you saturate that 1Mb up, sending a file out, for example, nothing can come back because the protocols have to have acknowledgments get back in a timely fashion, and even saturating your outbound buffer keeps your incoming data from being able to be acknowledged.



So this problem we got into unintentionally with router manufacturers just sort of thinking they were doing the right thing, turns out to be really more trouble than it's worth.  Notice that that big file you're sending cannot get to you any faster than the slowest bandwidth link.  It can't.  Nothing can squeeze it through.  So having that big buffer sitting there, trying to squeeze it through, doesn't get it there any faster.  If the buffer were only 10K, so that it's only eight or nine packets, then that doesn't mean it's going to go slower.  What that means is that little buffer will overflow immediately, and an acknowledgment will be sent back telling the sender back off a little bit.  And then the buffer will clear up.



But also that little buffer will allow all the other things going on in the household to stay interactive, even when a big file is being downloaded.  And that's the key.  These large buffers allow large download traffic to block interactivity.  And in many situations that's a deal killer.  You don't want that.  And it doesn't help the bigger traffic to go faster.  Due to this weirdness of the way packets are moved around the Internet, it's not going to go faster than it needs to through the slowest link you've got.  And you're much better served only buffering just enough to deal with transience.  And it doesn't make any sense to buffer larger than that because it breaks our signaling.



Okay.  So there is this Netalyzr.  I'm sure everyone listening is now wondering, oh, my god, what's the situation with my network?



LEO:  I've run it here and at home already.  It's very curious.  This is a neat thing.  I guess this is something they're doing at Berkeley as part of a large-scale study.  So not only is it a great service for us, but by using it you're helping them collect data about networks in general.



STEVE:  Yes, exactly.  They do some aggregate recordkeeping by IP, so they're able to see that these ISPs are doing this and those ISPs are doing that.  And they also collect, without IP, just overall general operation.  So I ran it on myself.  And remember that I've got a pair of T1 trunks.  They each go at 1.54Mb, and they're bonded together, so I get the sum of their bandwidth.  So sure enough, this thing said, for me, "Network Bandwidth:  Upload 2.9Mb/sec; Download 2.9Mb/sec."



LEO:  As you'd expect.



STEVE:  Exactly.  I mean, I am very impressed that they just nailed that.  And they said, "Your Uplink:  We measured your uplink's sending bandwidth at 2.9Mb/sec."  It says, "This level of bandwidth works well for many users.  During this test, the applet observed 1,551 reordered packets."  Now, that's actually a high number, but that's a consequence of the fact that I have two T1s.  So normally you wouldn't see that high a reordering count, but it's because my two T1s are - packets are going across either one, and they might be coming out in a different sequence.



Then they said, "Your download link:  We measured your download link's receiving bandwidth at 2.9Mb/sec.  This level of bandwidth works well for many users.  During this test the applet observed 696 reordered packets."  Now, network...



LEO:  That sounds like a lot.



STEVE:  Oh, it is, because of my two T1s.  But again...



LEO:  So this is why your Skype sucks, by the way.  Well, it may not be the only reason because - keep going.



STEVE:  Okay.  "Network buffer measurements:  Uplink 940ms."



LEO:  That's a lot.



STEVE:  Well, but remember, only if the buffer's full.  So, yes, uplink is almost a second, 940ms.  That is a large uplink buffer.  And then downlink 370ms.



LEO:  That's not so bad.



STEVE:  So they say, "We estimate your uplink as having 940ms of buffering.  This level can in some situations prove somewhat high, and you may experience degraded performance when performing interactive tasks such as web surfing while simultaneously conducting large uploads.  Real-time applications, such as games or audio chat, may also work poorly when conducting large uploads at the same time."



LEO:  So it's okay as long as you're not doing other things?



STEVE:  Exactly, yes.



LEO:  Okay.



STEVE:  It's only, see, the buffer only introduces a delay when it's full.  If the buffer is just cruising along, packets come in, one or two, and they immediately leave, then it's not introducing any delay.



LEO:  We do have some of the worst Skype from you, and it really should be the best.  And I do suspect, now, is that your router buffer, that delay?  Or is that a T1 artifact?



STEVE:  I don't know.



LEO:  Let me look at mine.  We have EFM, Ethernet to the First Mile, on this computer.  And it's showing network buffer uplink 110ms, very low.



STEVE:  Nice.



LEO:  And then it doesn't even - it says downlink is good.  It's not giving me any details on that.  I don't know why.  "We were not able to produce enough traffic to load the downlink buffer, or the downlink buffer is particularly small," which was what we would like; right?



STEVE:  Yeah.  Now, and that exactly speaks to my point.  The way they were able to determine my uplink bandwidth was by specifically generating enough traffic to overflow it.  And that's what it took was like figuring out how much traffic, generating enough traffic to overflow it.  Because lesser traffic than that won't - the buffering is not a problem.



LEO:  Now, at home I'm on Comcast.  This is my home computer.  And it's running an Apple router.  And it's considerably worse.  The speeds are better.  The upload is 5Mb, download 20Mb, greater than 20Mb.  But the uplink is 260ms, and the downlink is 98ms.



STEVE:  Well, it's still good compared to me.



LEO:  Yeah.  What router do you use?



STEVE:  I have a Cisco 3400.  I mean, I've got a BigIron router.  I mean, not a Cisco plastic box, a Cisco...



LEO:  No, no, no, the high-end one, yeah.



STEVE:  Yeah.



LEO:  Isn't that interesting.  But your numbers are - wouldn't you say they're less than optimal?



STEVE:  I'll do some poking around.  Well, I just ran this an hour ago.



LEO:  I think this is fascinating.



STEVE:  Yeah.



LEO:  So you look at the network access link properties; right?  That's the section that you want to look at.  Is that right?



STEVE:  Yes.  And it's network buffer measurements is what it says.



LEO:  And is that directly related to the router, or could there be other...



STEVE:  Well, see, yes, that's the problem.  And that's why I'm saying I don't know yet.  I haven't had a chance to research this.  Because this is buffering somewhere between me and them.



LEO:  Right.



STEVE:  So it doesn't - it's not necessarily my buffers.  It could be Cogent, my T1 provider could have their system misconfigured.  And, see, that's the other reason.  I don't know why these are different, why uplink and downlink are different because my router is doing nothing.  It's just sitting here directly sending stuff out my T1 lines.  I see no reason that there should be anything asymmetric.  Notice that my bandwidth was exactly 2.9 in each direction.  So it may not be me that's doing the buffering.  It could be Cogent that's doing the buffering.  And so it's not within my control.



Now, you can imagine, buffering is important enough that a lot of thought has gone into this.  The typical brain-dead buffer is a simple FIFO that we've talked about, a first-in, first-out.  And so the overflow behavior of a FIFO buffer is called "tail drop," meaning that it just drops the packet from the tail of the buffer.  It no more will fit in, so it discards it.  But because a lot of work has gone into this, engineers have said, okay, how can we - yes, losing packets, dropping packets is the nature of the Internet.  It's going to happen.  How can we make it smarter?  For example, how can we be more fair about competing traffic?  One high-bandwidth user should not be allowed to fill and saturate the buffer because then an interactive user who would like to have - doesn't need that much bandwidth, and if we could just sneak him in a little bit, then he could be happy with his low-bandwidth interactivity while the big transfer goes on in the background.



The problem is that requires extreme knowledge of the nature of the flows, and routers don't have that.  Routers just see packets coming in, and they go, okay, fine, and try and send it out the best direction it can.  But a technology was developed called Random Early Detection, RED.  What random early detection does is, as the buffer is beginning to fill, not once it's filled and we have to drop things off the tail, but as it fills, the router increases the statistical likelihood of discarding a packet, even that it has room for.  It just says, you know, the buffers are beginning to fill up.  Let's just toss this one out because tossing them out, as we know, is a healthy thing to do on the Internet.  And as the buffer continues to fill, it increases the likelihood of tossing packets out.



And what this means is that, if somebody was greedy with their particular flow, the likelihood of their packets being tossed out statistically is greater than the likelihood of somebody who's not using that many packets having theirs tossed out.  So it tends to throttle the people who have more packets in the buffer and not so much those that don't have that many packets in the buffer, the idea being that theoretically you never get to a point of actually saturating the entire buffer because you exponentially increase the probability of discarding packets as it continues to fill.  And the beauty of that is, for example, that allows TCP to get an early notice.



Ooh, and I forgot about one other horrible thing that happens.  If you've got - remember when I was talking about how a big buffer gets full, and then TCP keeps sending and increasing its speed because it doesn't know any better, because the receiver is still getting valid packets and acknowledging them from this big buffer, one other thing that happens is called TCP Global Synchronization.  If multiple TCP flows are going through, then what happens is all of their traffic begins to stall at the same time, but none of them get the notice.  They all get over-ramped.  Then finally they all shut down.



And what can happen is, as a consequence of this, is all of the TCP connections can essentially synchronize.  So you'd like them to be hitting their ceilings at different times so that they're backing off and sort or scaling and sort of cohabitating nicely.  But if you end up with a big buffer, the phenomenon of the way TCP backs off is they can end up falling into synch.  And this has been something that's been seen in routers on the Internet, where there's like this surge, and then stop, and surge, and then stop.  And you sort of get into this oscillating positive feedback phenomenon, which is really bad.  Because, I mean, it's just like - it starts to really break the Internet.



So the good news is that attention is being paid to this.  There isn't - this hasn't really - I don't think it's reached critical mass yet, where router manufacturers are acknowledging it.  But as you'd expect, the OpenWrt people are.  There is a site called BufferBloat.net where there's been a concentration of work.  There is a variant of the OpenWrt project called Cero, CeroWrt, which is now at Beta 2.  And they're only supporting one of the more popular, Netgear, I think it is, I want to say N600, but I'm not sure.  That's just from memory.  I didn't write that down.  But so we are beginning to see some firmware for OpenWrt-class routers, which they're using the latest Linux kernel, I think it's 3.3.  Typically routers, I think, are back on 2.6.something for their firmware.  This project is using the latest Linux kernel because Linux is experimenting with the buffer bloat problem.  And in the 3.3 kernel they've got something called BQL, which is a Byte Queue Limit.  They limit the number of bytes in the queue rather than the number of packets using a rather sophisticated strategy and something called SFQRED, which is Stochastic Fair...



LEO:  Stochastic.



STEVE:  Yes, Stochastic Fair Queuing Random Early Drop.



LEO:  Oh, that's an acronym.  Acronym.



STEVE:  Yes.  So anyway, that's where we stand.  I expect that, in the future, in the advanced configuration pages of the better SOHO routers, we will see configuration settings that allow smart homeowners to introduce smarter buffer management and probably manually reduce the buffer size.  I read an interesting dialogue among these engineers that were explaining that there's a problem, and that is that, if a router manufacturer deliberately used smaller buffers, then competitors with large buffers could claim that the better router was inferior because it dropped more packets and had smaller buffers.  And unwitting users would go, oh, well, that sounds like I don't want that router, when in fact it would give you much better performance...



LEO:  Right, right.



STEVE:  ...on your network.



LEO:  Well, I'm glad to know that it's software configurable, I mean, in other words you could use a custom firmware and fix it.  It's not that - even though the hardware has the RAM, you can reduce it.



STEVE:  Oh, yeah.  You just tell it don't use so much.  And in fact it turns out that there are even device drivers, this Linux 3.3 has improved device drivers because, again, RAM got so cheap, and there was so much RAM in our PCs, that our own network adapters have over - have too much buffers down in the kernel, down in the driver.



LEO:  Wow.  Geez Louise.



STEVE:  Because it's like, well, we got RAM, we don't want to throw these packets away, when in fact you'd like to.  And I did see one interesting comment in a dialogue where someone said, well, there's a problem with sending out lots of little bursts, which is what you have to do if you have small buffers, because for power conservation, having a large transmit queue allows the processor, like in a smartphone, to put a whole bunch of data into the queue and then sleep itself, shut itself down so that a lower power portion of the chip is able to go and send off that data, and the CPU is not consuming so much power.  Whereas, if you had much smaller buffers, it would have to be constantly waking up and shutting down much more rapidly.  And so as a percentage you end up being alive longer than if you were able to shut down for a long period of time.  So that's, I mean, there's a lot to be determined yet.  But that's the story of buffer bloat.  And...



LEO:  What is the optimal buffer size?  Can you say that?



STEVE:  And that's just it, there isn't one.  It's so confounding because it's a function of roundtrip time and bandwidth and speed and usage characteristics.  There just - there is no optimum.  But what's happened is we know that too big is really bad, and too small - you want enough to deal with transience, yet you still want the total roundtrip time - see, this is it.  If you just do a ping, a ping will give you your no-buffer-delay roundtrip time.



LEO:  Right, because it's such a small amount of data.



STEVE:  Yes.  So do this.  Ping Google and see what that is.  Then start downloading a podcast from TWiT.tv and ping again.  Oh, and you also have to wait a bit.  You have to wait for the buffer to fill.  So wait a while.  Or just go ahead and start pinging.  And what you will probably...



LEO:  Watch it go down, yeah, yeah.



STEVE:  Yes, exactly.  And so you will begin to see the roundtrip time increasing, not because you're getting further away from Google, but because the buffers are filling, and your ping is having to wait in line, wade through that buffer to get to the front before it can finally leave, and the same thing happens in reverse.  So it's not unfilled buffers that are the problem.  The buffers themselves are not the problem.  It's that they're allowed to get too deep, and that creates latency.  And the Internet was not designed - it was designed for on the order of 100ms of latency.  I mean, I've seen some reports of six-second buffers.



LEO:  That's not good.



STEVE:  Buffers that are six seconds deep.  You might as well just...



LEO:  Forget it.



STEVE:  ...hang up and go home, yes.



LEO:  By the way, this Netalyzr gives you a lot of other interesting information.



STEVE:  Oh, it's a fantastic application.  It's worth...



LEO:  I'm looking at certain TCP protocols are blocked in outbound traffic.  Not all DNS types are correctly processed.  I mean, there's a lot of diagnostic information in here.  



STEVE:  Yes. 



LEO:  This is my home router, which of course has something going on, probably Comcast.  It's blocking remote SMB servers.  Well, that's probably right.



STEVE:  Yeah, I'm sure it would be, yes.



LEO:  But I have to say Russell, our IT guy here, is so good that our router is well configured here at the studio for minimal - he's done a great job for minimal latency, great speed.  That's why we get such good results.  But Steve, I want you to look at your router.  You're getting too many packet reorderings, too much of that.  If you want to know more about this show - he's silent.  But we do, it's funny, given that you have such a rock-solid setup, it always puzzles me that we have occasional audio breakups with you, sometimes weird results with you.



STEVE:  Okay.  What I will do is, for our next podcast next week, I will shut down one of my T1s.  Because what did you see, by the way, for packet reordering?



LEO:  Zero.



STEVE:  Really.



LEO:  Yeah.



STEVE:  Interesting.  And you're right.  I don't know how Skype handles reordering.  If it sees them out of order at all, it might just drop anything that's not coming along.  Anyway, I'll shut down a T1, and we'll try a podcast next week with only one T1.  I can do it trivially, so it's not a problem at all.



LEO:  Yeah.  That might be - it's funny, but that's a perfect example.  Less sometimes is more.  More sometimes is less.  Actually, I'm sorry, I had 10 reordered packets.  Wait a minute.  Which - okay.  Now I have this...



STEVE:  Yeah, but I had 900.



LEO:  That was at home, 10 was at home.  Let me see on the...



STEVE:  I had 1551.



LEO:  Yeah, we had no reordering here in the studio, and I had 10 reorders at home.



STEVE:  Wow.



LEO:  Yeah.  So I'm thinking that that's the dual T1s.  Maybe just, yeah, let's disable it next time.  Because you have plenty, 1.4Mb up is plenty for Skype.



STEVE:  Yup.  I will shut one down, and we'll see how it does.



LEO:  Steve is the master, and you can find out more by going to his website, GRC.com.  That's where you'll get of course the fantastic SpinRite, world's finest hard drive maintenance and recovery utility.  You'll also get all his free doohickeys, his security stuff, and copies of the podcast, 16Kb audio and transcriptions.  Those are only available at GRC.com.  Next week a feedback episode, so while you're there, if you've got a question, just leave a question at GRC.com/feedback.  And otherwise, if you want the video or the high-quality audio or you just want to subscribe, you can do that at TWiT.tv.



We do this show live every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, that's 1800 UTC.  So stop by and watch live.  Always fun.  Then you can watch the chatroom as it does its tests and brings Netalyzr down.  It's fun.  It's fun.  And it's been fun watching.  There's such a wide variety.  We have somebody in Britain who's got amazing bandwidth, 25 pounds for BT Infinity.  And he's just got 45Mb up and down or something like that, it's incredible.



STEVE:  Wow.



LEO:  It's incredible.  But there is a wide variety of ping times.  We've got people with 1900ms ping times.



STEVE:  Ooh, there's - okay, that's two seconds.



LEO:  That's too much buffering.



STEVE:  Yup.  Wow.



LEO:  What a great subject.  And more to come, I'm sure, on this one.  Steve, thank you so much.



STEVE:  Thanks, Leo.



LEO:  We'll see you next week on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#346

DATE:		March 28, 2012

TITLE:		Listener Feedback #140

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-346.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here with 10 great questions and answers, more on buffer bloat, security news, and a whole lot more.  Yes, we'll even talk a little bit about coffee and the iPad.  But just a little bit.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 346, recorded Wednesday, March 28, 2012:  Your questions, Steve's answers, #140.



It's time for Security Now! - time to protect yourself, your friends, your loved ones online; protect your privacy, too.  And here he is, the Explainer in Chief, the man who makes it all happen, Mr. Steve "I've Got a Giant Mic and I'm Not Afraid to Use It" Gibson of GRC.com.  Good day to you.  How are you, Steve?



STEVE GIBSON:  Great.  Great to see you and talk to you and be connected to you.  And we've got all kinds of stuff to talk about.



LEO:  We sure do.  It's Q&A episode.



STEVE:  And some of it, some is even about the Internet and security and computers.  I'm sure we'll get to that.



LEO:  Well, we have one Carbonite ad.  We'll do that right after your SpinRite mention.  But let's dig right - and I know we have questions and answers, but let's dig right into the security news off the top here.



STEVE:  Okay, now, first of all we should let our listeners know that, as a consequence of our buffer bloat episode, where I ran the analyzer last week...



LEO:  Love that Netalyzr.



STEVE:  Oh, yeah, that's been a win for so many people.



LEO:  I got an email from them saying thank you.



STEVE:  No kidding?



LEO:  Yeah.



STEVE:  Oh, neat.



LEO:  They said we got more traffic from you guys than we've ever had before, and it's really helped us with our research, so thank you.



STEVE:  Oh, fantastic.  Well, as we know, we learned that my own connection had arguably a little more buffering than I wanted.  But more significant for the podcast is, because I have a pair of T1s, and packets can be routed down either one, they were coming out at the other end with much more out of sequence than is normal for a connection.  We've talked about this often.  There's nothing that guarantees packets will arrive in the same sequence they're sent.  TCP handles that by putting serial numbers in all of the TCP packets, and both ends do some buffering of their own.  This is not the evil router buffering that is subject to bloat.  This is after they arrive at the endpoint or until they are acknowledged having been sent, each endpoint keeps them, and that allows them to be reassembled in order.



Well, the problem is, for something that really needs to be real-time, like VoIP, you don't have time to hold things because that would introduce too much roundtrip delay.  It would be like you and I were on a satellite connection instead of a real-time connection.  So the decision is made, if packets come in out of sequence, if one appears to be missing, if we get one that comes along, we'll just send the audio in that packet and not worry about what's been missed.  Now, there are algorithms for trying to fill in gaps, to sort of continue the audio from the last one you got and sort of hopefully bridge into the next one.  And that's somewhat useful.



Anyway, the point is that, for this podcast, I have shut down one of the two T1s.  So we are now running over one T1, and we'll just sort of see as the podcast goes along, and maybe assess it at the end, whether we seem to have had an improvement.  And if so, I did get a tweet from someone who said that I could use Cisco access lists to route UDP over only one.



LEO:  Oh, of course, through only one.



STEVE:  Now, I knew that there was a mechanism where I could use more of a hashing approach so that the hash of the source and destination IPs and maybe even ports was used so that you would always choose a consistent T1.  The problem is that that would effectively cut my bandwidth down in half when, for example, I'm web surfing and things, because I really don't want TCP only to use one.  But I would love, I have no problem if UDP protocol only uses one because DNS uses UDP.  That's probably the only other thing I'm using UDP for other than VoIP with you and Skype, so that would be fine with me.  So I have to see if I can actually do that with a Cisco access because I didn't know that I was able to specify not to share them.  So we'll see how that works.  But so that's the connection that we're talking over.



LEO:  I guess the bottom line that may be counterintuitive is it just doesn't mean automatically more - and this is the buffer bloat problem, too.  More bandwidth does not automatically mean better results on a UDP product like Skype.  And simply having a strong consistent connection without dropped packets is more important than having the combined 3Mb that the two T1s provide you.



STEVE:  Yeah, you want low jitter.  Okay, and jitter is a variation on buffer bloat.  If packets are queuing with other packets in a buffer, then the receiving end perceives that as jitter.  It doesn't see the packets coming in at a uniform rate.  It doesn't know why.  But it knows that somewhere along the way the packets got slowed down so that they were no longer coming in uniformly.  And what VoIP wants is just as uniform packet timing as possible.  So you want low jitter.  And of course you certainly want low loss.  And as we may be learning, you also really want them to come in in proper sequence.  But I turned on - I went to TWiT Live this morning and happened to catch a replay of yesterday's MacBreak Weekly, where I heard you going off on Google is now evil.  And so I thought, okay, wait a minute.



LEO:  You have to understand, sometimes I get upset about things.  And I overstate them.



STEVE:  We love you.  We understand that.  But I just thought I would let our Security Now! listeners know what it is that Google did to trigger this.



LEO:  Well, it stemmed from - and I didn't quote these articles in our conversation on MacBreak Weekly, but I'll quote them now.  It started with an article by Mat Honan, who is a really great writer on Gizmodo, which is a less-than-great gadget blog, but Mat is good, so I'm going to give Mat credit:  "Google's Broken Promise:  The End of 'Don't Be Evil.'"  And in it he talks about where this "Don't Be Evil" mission statement came from.  It's an interesting story, actually.  Every company has a mission statement, and usually namby-pamby crap like...



STEVE:  We will serve our customers to the best of our ability.



LEO:  We'll do better at - yeah, exactly.  And Paul Buchheit - who was an early, I think Employee 23 or 24 at Google, later went on to write Gmail, and is now at Facebook, I think, but a brilliant guy, and he's a venture capitalist - was at one of these corporate meetings at Google early on, and they said we need a mission statement.  And he said, I want to do something that's not namby-pamby corporate.  How about just "Don't Be Evil"?  And they adopted it, and it was kind of famous that Google's kind of plan was not to be evil.  Now, when that...



STEVE:  I loved it in sort of a hacker T-shirt sort of way.  I mean, it's just like, it's a great ethic.



LEO:  But it doesn't mean much.  In fact, first of all, it's something not to do, not what do they do, but what they don't do.  But it makes sense.  And remember, you have to remember the context.  This was in a time when all the other search engines were selling paid results into the search results.  They were giving you search results that were tainted by advertising.  And so in that context I think it's very likely that that's what he meant was let's give people clean, good search results and not be so focused on the bottom line that we do things that are bad for the customers, but good for us.  Now, that's my own gloss on what he said.



So I think really for me where Google really has started to go wrong is not the privacy and tracking issue, although you might think that, and certainly that hasn't helped their reputation.  Doing things like putting an invisible form in iOS browsers in order to end-around the third-party cookie prohibition is clearly evil.  I mean, there's no question about that.  But I will continue to defend - I think the word "tracking" when it comes to tracking cookies is such an anthropomorphic term that it really scares people more than it ought to.  So I will defend the idea of targeted advertising and tracking cookies to that extent.  But that's not - so I don't think that's really what I'm talking about.



I think where Google started to go wrong was with Search Plus My World, where they truthfully did start to modify their search results to benefit Google's bottom line.  Now, they have lots of excuses for it.  But really what happens is Google Plus is highlighted in search results, as is Yahoo!, also a Google property.  And now if you go to Gmail or anywhere on Google, and you'll see your Google Bar, your black bar at the top of all Google pages now has a big ad for Google Play, which is essentially - here, I'll show you.  So they put this bar on all Google properties.  That's not necessarily evil.  But they're starting to use it for promotional value.



Now, Google Play is of complete no use to anybody who isn't using an Android phone or Google's music.  This is a service, a paid service that Google provides.  And the fact that they're highlighting this so high just bugs the heck out of me.  You know, the Google page used to be famous.  You'd go to Google.com and...



STEVE:  So clean.



LEO:  ...and it would just be Google.com, search box, and that's it.  And they've more and more I think subverted what used to be a very good business model, by the way, to promote their own vehicles.  And that to me - I don't think Google's more evil than Amazon, Apple, or any other company, or Facebook.  They're all doing this.  But I think this does, this runs counter to their original mission statement, "Don't Be Evil."  And it comes from this Mat - I recommend people read the Mat Honan article on Gizmodo because that's a much more eloquent and, I think, effective statement of what I'm talking about.



STEVE:  Well, there was some good discussion that you and Andy and the group had on this week's MacBreak Weekly.  So I just wanted to understand that.  And also, if our listeners are looking for another podcast that they're not already listening to, I can vouch for the fact that that was a fun dialogue that you guys had.



LEO:  Yeah, thank you.  I appreciate it.  Yeah, I think that's a good show.  More interesting to Mac and iOS owners, although nowadays I think there's nobody doesn't own something. Speaking of which...



STEVE:  Well, but you were also talking about Amazon and Google as...



LEO:  Right, I mean, they all do this; right?  I mean, this is not...



STEVE:  Or Apple, rather, Amazon and Apple.



LEO:  Yeah, yeah.  So, by the way, speaking of Apple, my Liquipeled phone came.  And I'll be doing a review on this later, probably on Before You Buy, our product review show.  But I had my iPhone dipped in an invisible clear shield.  This is in lieu of a case.  Wow, you can't even tell.  You can't even tell.



STEVE:  And do they do it for you, or...



LEO:  Oh, yeah, they have to.



STEVE:  ...do you attach a string to it and dip it in?



LEO:  No, no, no, no.  It says they don't recommend the device come in contact with any liquids.  However...



STEVE:  Should it happen...



LEO:  Should it happen, it applies a protective water repellant coating to your personal electronics.  Boy, you couldn't even tell that it's been done.  All right.  So I'll do a review.  I guess I'll have to dunk this in a bucket of water.



STEVE:  Well, I guess it was - was it at CES we saw them with phones underwater, and they were working.



LEO:  And it was because you and I talked about it, and others, that they've contacted us, said, well, give us something, we'll do it.  Okay.



STEVE:  And you hand over your phone.



LEO:  I gave them my phone.  I didn't even wipe the data.  That's how trusting I am.



STEVE:  Well, in security news...



LEO:  Yes.



STEVE:  We will cover coffee at the end of our catch-up.



LEO:  By the way, I don't know if this is in your - I haven't gone through your rundown yet, but did you see there's a YouTube video about how law enforcement can completely get around that four-digit passcode on your iPhone?



STEVE:  Yeah, I did.  And I don't have it in the notes here, although - we don't have enough information about what it is that they're doing.  And it's a commercial product, where they're selling it to law enforcement.  Just for the people who haven't seen it, they show running a piece of software, connecting the MAC that's running the software to an iPhone.  You power off the iPhone, then you power it on while holding down the Home button at the same time as it boots.  And...



LEO:  Well, now, that's a flaw that's been fixed, I think, in many phones, in many iPhones.



STEVE:  And so, yeah, so that's one of my questions.



LEO:  I thought that was fixed.



STEVE:  Is this still the case?  Has it been fixed?  They talk about on their site how they have all these engineers who are continually needing to find new holes in firmware of phones that are being updated.  So they're using some sort of a hack in this video to get around that.  And the question this raises is, if you had the "10 strikes and you're wiped" option turned on...



LEO:  Which I do, of course...



STEVE:  Absolutely.  I do, too, because we keep our devices backed up through iTunes on our machines, or even iCloud now.  So who cares if it gets wiped out?  I definitely want it wiped out if some guy's trying to hack into it.  So, and I don't use four digits, of course.  I have the full alpha keyboard turned on, so...



LEO:  Well, I use a pattern.  Is that better or worse?



STEVE:  Eh, just don't tell anybody that's what you do.  Oops, never mind.



LEO:  Dvorak - well, no, it shows - no, on the iPhone I use a number.  I use a pattern on Android.



STEVE:  I know.  You're able to look at the screen.



LEO:  Yeah, Dvorak's always looking at the smudges and saying, I think I can figure this out.



STEVE:  Oh, yeah, I think I know what your number is.  I've got your number.



LEO:  He's tricksy.



STEVE:  Yeah.  So anyway, it was an interesting video.  It's not clear that that means anything.  As you said, we remember that hold the Home button down problem, and that's apparently what they're doing.  Maybe they have a different means around that.  Or maybe this is just old.  I mean, for example, one of the stories for this week is from a year ago, essentially, and that's this - it just sort of resurfaced because the paper that is going to be published about it is soon to be published.  But this was work done on problems with single sign-on systems which Google and Facebook and others are using, where some researchers were able to, by reverse engineering the protocol that they could see passing through their browser, they were able to subvert the single sign-on system.



And we've talked, of course, we did a whole podcast on exactly how OpenID works.  And we'll remember that the way it operates, when you go to a site that gives you the option of signing onto that site using a different site that knows you - for example, sign on using Twitter, sign on using Facebook.  When you click the button, you are taken to a page on the site you're still visiting, which then gives your browser a redirection with a bunch of special headers to the site that is going to be the identity provider.  It sees this special request coming in, and it has all the required fancy crypto and authentication bells and whistles.  And again, we covered this in detail on a full podcast to that effect.  The identity provider then provides a response which your browser redirects back to the so-called "relying party," which is the one that is offering you the option of logging in through this identity provider.  It then receives that packet, which it verifies and authenticates and again does all the crypto things and says, okay, fine, I'll accept that credential from that identity provider site as yours.  And that's the way it works.



Well, it turns out, naturally, that we're in first-generation of these things.  And we're often using downloadable kits where it's just, oh, grab this Java-based solution and plug it in, and you'll be up and running with multifactor, single sign-on technology.  Well, there are bugs in these things.  And there are problems with implementations.  And in fact there are problems with implementers in some cases.  For example, what the researchers found was that it was possible to alter the data going by which the recipient of that data assumed was correct and had been signed but never checked the signature.  So they broke the crypto signature, but the recipient of that just said, oh, well, we'll take the data.  We're not going to verify it.  So...



LEO:  So that's an implementation error.



STEVE:  Precisely.  The problem is that, for example, Computerworld's headline was "Study finds major flaws in single sign-on systems."  And Ars Technica even said "Flawed sign-in services from Google and Facebook imperil user accounts."  So, quote, "The researchers also found weaknesses in OpenID, a popular open standard that the researchers said Google, PayPal and 9 million other sites use" - nine million other sites, that's great - "to grant access to more than 1 billion accounts.  The OpenID foundation has since addressed those bugs, as well."



So what I want our listeners to understand who saw this, and I got a bunch of tweets from people who wanted to make sure that I was aware of it, so thank you for those, is the protocols are solid.  Without exception, we understand how to do this well enough that that part we got right, exactly as you summed it up, Leo.  It was just some implementation mistakes.  It was first-generation kits and assumptions being made by the users of the kits.  Like, for example, they didn't have to make a call to verify the signature.  The kit would do it for them.  So in some cases it was just sort of a communications error in not understanding whose job it was to perform the verification stuff.



And, okay, and this was all last year, around this time, like April/May of 2011.  And all of this has been fixed a year ago.  It was fixed immediately because the researchers told everybody whose systems they had been able to hack what they had done, and they were fixed immediately.  So it's like, oh, okay, thanks very much.  So, I mean, and as far as everyone knows, no one has been exploited by this. So this was - this made the news because the paper will be presented in a couple of months, and but it's already been fixed.  And, more importantly, there's nothing wrong with the concept.  Certainly we have to implement it correctly.  But that's always the lesson that we're encountering with security stuff is that, yeah, not only can the theory be right, but the implementation has to be there, too.



LEO:  We're going to give you a new title, the Debunker in Chief.  Explainer and Debunker.



STEVE:  There was another story that made a lot of news.  And this was actually Ars Technica covered it initially on March 16th, and then it was updated with some additional information because what Ars reported really upset people.  And this was that iPhones and iPads were leaking their past MAC addresses.  A security researcher by the name of Mark Wuergler worked with Ars and an Ars reporter after some research he had done.  He has a penetration services company and has written some apps that are sort of very much sort of Firesheep resembling, where you can go to an open access point, and he gathers all this information over unsecured WiFi and presents it in a nice fashion.  So the best thing to do is just to read a little bit of this verbatim from Ars's page, just the top of the story, to give you a sense for what this is.  It sets it up perfectly:



"As a security professional who gets paid to hack into high-value networks, Mark Wuergler often gets a boost when his targets use smartphones, especially when the device happens to be an iPhone that regularly connects to WiFi networks.  That's because the iPhone" - and by the way, this is true, this is verified, so keep that in mind.  "That's because the iPhone is the only smartphone he knows of that transmits to anyone within range the unique identifiers of the past three wireless access points..."



LEO:  Past three?



STEVE:  The past three "the user has logged into."



LEO:  Criminy.



STEVE:  "He can then use off-the-shelf hardware to passively retrieve the routers' MAC ... addresses and look them up in databases such as Google's Location Services..."



LEO:  Wow, so use that to track you.



STEVE:  Uh-huh.  Well, okay, get this.  If you were at a Starbucks somewhere, and you were capturing the MAC addresses of the customers that walk in who have iPhones with their WiFi turned on, as most people would, and the phone is looking for an access point to access, and you were able to critically cross-reference those MAC addresses with their location, then you know they're here at Starbucks and not home, and you know where they live.



LEO:  Oh, wow.



STEVE:  So, yeah.



LEO:  You could say, hey, let's go.  This'd be a good time to go visit his house.



STEVE:  Precisely.



LEO:  He's going to be drinking coffee for a while.  Let's go surprise him.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  Not good.



LEO:  Not good.



STEVE:  So continuing, "By allowing him to pinpoint the precise location of the wireless network, iPhones give him a quick leg-up" - so to speak - "when performing reconnaissance on prospective marks.  'This is interesting on a security level because I'll know where you work, I'll know where you live, I'll know where you frequent,' Wuergler, who is a senior security researcher for Miami-based Immunity, Inc. told Ars."  Continuing the quote, "'If the last access point you connected to was your home, for example, I'll know right where to go to get to you later or to get to your data.'"  Or to visit while you're at Starbucks.



LEO:  You're kind of cute.  Maybe I should visit you at home later.  Geez Louise.



STEVE:  "'If I'm an attacker that wants'" - I know, and this is true.  "'If I'm an attacker that wants to break into your company, this becomes a disclosure that an attacker isn't going to pass up.'



"The exposure of MAC addresses extends not only to iPhones, but to all Apple devices with WiFi capabilities, he said. It means that whenever the wireless features are enabled and not connected to a network - for instance, during a brief encounter at a Starbucks - they broadcast the unique identifiers, and it's trivial for anyone nearby to record them.  Wuergler speculates the behavior is a feature designed to automate configuration for networks users regularly access."



LEO:  Wow.



STEVE:  Okay.  So this generated so much kerfuffle that Ars asked Robert Graham to verify.  Now, Robert Graham is a person we've spoken of often.  He was the main networking techie behind BlackICE.  And he's still involved.  Errata  Security is his firm.  So Robert knows what he's talking about 100 percent.  He fired up Wireshark, walked into Starbucks, turned on his iPad 3, and saw his home router MAC address sent off into the air and verified that this is in fact happening.



So our listeners probably know enough, having listened to us discuss how the Ethernet works in our networking fundamentals stuff, to even guess what's happening.  This is an ARP query.  This is the Apple products wanting to ease reconnection to a previously connected network.  So unlike standard Ethernet devices - and actually, Leo, this may be also a function of the fact that they sort of stay on all the time.  You know, they're not actually being shut down and rebooted, which may flush the ARP cache in the device.



But the fact that Android phones don't do it, BlackBerrys don't do it, so it may be something Apple is deliberately doing to make their users' experience more seamless because, for example, if you were to come into your house, what your phone is doing is it's querying the last several access points, WiFi points, that it has visited to see if it is again in the presence of one of those.  Unfortunately, in order to do that, it's divulging what access point it was connected to because this is a - ARP is a non-encrypted, pre-connection, low-level - it stands for Address Resolution Protocol, the way devices talk over Ethernet.  And as we know, WiFi is just a wireless version of the Ethernet.  So it's got all the same protocols.



So I don't know how Apple will respond to this because people are not happy, as you can imagine, that their devices are, when in the presence of a WiFi network and connecting up, trying to connect to access points they have connected to before using their MAC address.  And once upon a time that wouldn't have been a problem, except that Google has been roaming the streets of the world, literally, acquiring all the MAC addresses and noting where they are.



LEO:  Well, not just Google.  There's a company called Skyhook that also does this.



STEVE:  Yes, yes.



LEO:  And predates Google doing it.



STEVE:  Now, Google did increase the difficulty of making ad hoc queries by requiring you to provide two MAC addresses that are physically near each other.  You can't just say give me one.  You have to have two.  And that's a nice workaround.  It allows the fundamental underlying technology still to work, but you would have to actually be near one of those in order to have a MAC address of another access point nearby.  You ask them both of Google.  Google verifies that they are physically near each other, and so it's not that you've just been able to capture one at Starbucks.  So that raises the bar a little bit in a nice way.  And I think it's a clever solution to the problem.  But this is still, I mean, this is arguably a problem.  I imagine Apple...



LEO:  I would say inarguably a problem.  I think, Houston, we have a problem, yes.



STEVE:  I think Apple will probably have to back off and change their networking stack so that it no longer does this.  Users, until we get an update, can simply turn off WiFi and not have the benefit of seamless WiFi connectivity when they walk into Starbucks and other similar open access point locations.  And that might be a good idea, if this sort of thing upsets you, because it is true that the world probably knows exactly where your router is geographically, and it's certainly possible to get that information one way or another.  So probably not good.



LEO:  Unh-unh.  No, not good at all.



STEVE:  Microsoft in the news, this was just in the news today, is getting involved in the HTTP 2.0 effort.  A couple weeks ago we talked about SPDY and covered the way that protocol works in detail.  Microsoft - immediately when I saw this I sort of closed my eyes, I went, oh, no.  Here we go.



LEO:  Here we go again.



STEVE:  The standards wars.  Microsoft is saying that they're okay with SPDY.



LEO:  But...



STEVE:  That they think it's a nice effort.  But...



LEO:  They got something better.



STEVE:  They, well, they say they want things that are more oriented toward mobile devices.



LEO:  Well, that's true.



STEVE:  But they haven't said what that means.  And SPDY's developer at Google said, wait a minute, there's nothing un-mobile about SPDY.



LEO:  Right, it's any web browser; right?



STEVE:  What it does sound like maybe Microsoft wants, which I can see, is something a little bit more like the web sockets API which is in HTML5.  And that is to say, more application-level features.  What Google has done is they've sort of made a transparent improvement so that the browser still browses and the server still serves.  But behind the scenes it's doing that as our listeners know from that podcast in a much more efficient fashion in many ways.  But there really aren't any application-level features that web applications could use in order to leverage that.  And so Microsoft I think has a point, that the web sockets API does provide that sort of feature, although it's layered right now on top of HTTP, so it still has the underlying carrier technology, the transport layer of HTTP.  Integrating all that more tightly makes sense.



So the good news is we're moving towards a next-generation HTTP one way or the other which looks like it's going to incorporate the best of all of these efforts.  It'll probably be - it'll be slow and take a while.  Someone, it was Simon Zerafa, made a comment about Twitter no longer using SPDY.  I just saw his Tweet earlier today, and I haven't had a chance to verify it.  I do have - I've got my little SPDY gizmo displayer in Chrome.  Let me go to Twitter.com.



LEO:  Why would they - they must have found something better, if they're not using SPDY.  You know, what's interesting is that Twitter has a development toolkit which is now being widely adopted by people as a framework.  And if it had SPDY built into it, and I'm not sure it doesn't, that would be a really cool way to spread SPDY to websites easily.



STEVE:  Well, I am at Twitter.com over an HTTPS secured connection.  And my little indicator is off.



LEO:  Oh, man.



STEVE:  And it was on earlier.



LEO:  Oh, man.  Well...



STEVE:  Well, they may have found a problem, which they will get around to fixing.



LEO:  Certainly, if somebody would find a problem, it would be Twitter.  So, yeah, maybe there is a solution.  They have a framework called Bootstrap which a lot of people are using now to create sites.



STEVE:  Oh, cool.



LEO:  Yeah, in fact Gina Trapani just did a site with Bootstrap.  Let me just see if Bootstrap supports SPDY.  It's S-P-D-Y; right?



STEVE:  Yes.



LEO:  Responsive design tools, no, it doesn't look like it's built in.  That's too bad because that would be great.  It's CSS-focused.  I guess it's not.



STEVE:  Yeah, okay, so it's not low enough level to...



LEO:  Not low enough level, yeah.



STEVE:  So it would be compatible with it, but wouldn't require it.  Brian Krebs, our intrepid security reporter who spends a lot of time digging around down in the dark recesses of the Internet, warned recently that the latest Java flaw is being actively exploited, and successfully.  He reported that the Java flaw that was fixed middle of last month, which is v6 update 31, or v7 update 3, has been added now to the very popular exploit kits, which many of the latest exploits are being built on, and as a consequence has dramatically increased their penetration success rates, which says that many people, not our listeners I'm sure, do have Java installed and aren't paying attention to it and aren't keeping it current.



Now, I mention that, of course, because last week's tool for measuring network buffer bloat required Java.  And I have to say that I was looking favorably at it from a standpoint of, wow, if they can do all of that, I could definitely have some fun doing low-level network things in a way that was platform-independent.  Yes, it requires Java, but I'm afraid the future probably does.



LEO:  Well, the good news is all browsers now, by default, don't turn on Java.  I think; right?  I mean, I know Chrome says, do you want me to allow Java?



STEVE:  Right.



LEO:  Isn't that default now in most cases?



STEVE:  Well, you can definitely disable it.



LEO:  Yeah.  But that would be foolish.



STEVE:  I think you're right that you have to enable it.  What Brian suggested, I liked.  And that is, if you find yourself often needing Java, you could go the multibrowser approach.  For example, it's easy to disable in Firefox under add-ons.  You just say turn that off.  And then, for example, you might just run Java under Chrome and use Chrome when you need Java, but don't use it when you're just out cruising around the Internet, or vice versa, or any combination of those.



So I did want to remind people, you just go to Java.com, and then there's a link, "Do I Have Java?"  You can click that, and it will run a test to tell you if you have it and, if you do, if it's current.  And I just did mine this morning to make sure, although I was sure that I had done it a month ago.  And it said, yes, you've got v6, update 31.  So it's like, ah, okay, good.



LEO:  I always thought Java was sandboxed, and so it was less vulnerable, the applets were less - I know there are problems, but it seems to me that, if you combine the fact that by default it's opted out, it automatically updates, and it's more secure, say, than JavaScript, it seems like it's not a bad choice, let's put it that way.



STEVE:  Well, it's not a bad choice.  And what you're thinking of is that it has always been an interpreted byte token style language.  It was built, as we all remember, back in the day, what is it, Bill Joy, for set top boxes, and so meant to be platform independent, processor independent.  You have a Java runtime which interprets the byte code.  If the runtime were perfect, then you could argue nothing you could do in terms of giving code to the runtime could represent a problem.  So it has the potential of being very secure.



The problem is there's just this huge tendency to sacrifice security for speed.  Even Google, with the Chromium project, there is a move afoot to run native code in Chrome, not just JavaScript but actual Intel executable.  And Google says, oh, we have a way to corral it and make it safe.  And it's like, okay.  I mean, they really want that ultimate performance.  And it'd be great if we could have everything.



LEO:  I'll have to look because when Java - for a long time Java had this sandbox model where, if it was untrusted code, unless you had a certificate, and you explicitly trusted it, it couldn't access the file system, it couldn't access the networking, it couldn't access browser internals, it was very much protected.  And maybe over time - as you say, people want convenience - that's eroded.  But it was, for a long time, it was deemed mostly secure.  I mean, there are malicious applets.  But you have to trust them explicitly, I think.



STEVE:  So a little quick iPad follow-up.  The news came out this week that it may be the LED lighting that has been the source of heat.  And I can confirm from my own experience that, when I have turned the backlighting up all the way, that does really seem to increase the heat.  Nothing that I do on my iPad 3 is processor intensive.  So I'm not doing gaming with lots of animation or movement or anything.  But it was when I had the light turned up.  And in fact because of this next-generation, super-high-resolution screen, the lighting is 2.5 times brighter, that is, there is 2.5 times more backlighting, and that generates heat because it is pulling power from the battery.  So that could certainly be part of it.  Then there was just in the last day or two some controversy about the iPad charging, that it saying it was 100 percent charged, but it wasn't really, that some investigators discovered that...



LEO:  Yeah.  By the way?  Bogus.



STEVE:  I know.



LEO:  Apple's responded.  Completely fooled the "investigators."  Which is a shame because this is the guy from DisplayMate.  I mean, I've always trusted him in the past.  He just kind of got fooled.



STEVE:  Well, he...



LEO:  He noted some behavior.



STEVE:  Yeah.  He wasn't wrong...



LEO:  Right.



STEVE:  ...in what it was doing.  And frankly, I'm glad to know they're doing this because I have worried, for example, when I have a laptop that is charged up, but it's just sitting there on the adapter, I have wondered if the battery isn't over time just draining without any attention being given by the laptop.  And so sometimes I'll, like, disconnect it deliberately and reconnect it so that the laptop checks it again, and hey, sure enough, it'll go into charging mode and bring the battery back up because it had drifted away from a full charge over time.



LEO:  And as it turns out, that's exactly what Apple's doing mechanically.



STEVE:  Yes.  Apple is taking active responsibility for it.  And so it's bringing the battery down and then bringing it back up again, and bringing it down and bringing it back up, in order to keep it - to have knowledge that it's keeping it up at 100 percent.  And unfortunately, with our current technology, there's so much battery-charge monitoring on the cells themselves that there is some self-discharge of lithium ions.  So you do need to keep an eye on it, which is what Apple's doing.  So for anyone who was wondering.  And then I can now tell you, Leo, that I still prefer reading on my large Kindle.



LEO:  Ah, the DX, the eInk version.



STEVE:  Yes.  The eInk, even over the iPad 3.  The iPad 3 is amazingly gorgeous.  And I have one with no antiglare film and one with antiglare film.  And I can't decide what I want because the antiglare that I have does knock down that super-high retina resolution.  It sort of gives it sort of a twinkly sparkly effect, sort of a specular feeling, where when I compare it, and I've left the other pad with no antiglare so that I can do some A/B comparison, there's no question that that glossy screen is even more important when you've got this kind of pixel density, if you really want to see the quality and the clarity of the LCD.  On the other hand, it is a problem when there's light behind you, or you're outside, or you're in a restaurant with some bright lights above, and you've got them shining into your pad.  So I like them both sort of in a different way.  But more than either of them, just for reading, I still think a reflective display is a lot easier on the eyes.  I love my Kindle DX.



LEO:  Yeah, I don't think it's a resolution issue.  I think it's having backlit versus reflective.  I think that's the...



STEVE:  Oh, yeah, unfortunately I was confusing about nine different issues there in one.



LEO:  No, no.  And I know what you're talking about.  And that was really what people always said is, well, I don't care, the quality of the screen isn't the issue, it's that the screen itself is emissive.



STEVE:  Yes.



LEO:  And that's not as easy on my eyes as reflective.  And some of it's conditioning; right?  Because we grew up reading reflective materials.



STEVE:  Yeah, I don't know.  I'm able to be reconditioned.  Except when it comes to cold brew coffee.



LEO:  Oh.  How do you - okay.  So you bought it.  You bought the Toddy.



STEVE:  Of course I have all this stuff, Leo.  I'm going to find out what's going on.  So I tweeted earlier this week, I said "Bite Me!" because I like bite.



LEO:  Yeah.  There's no bite.



STEVE:  I like my coffee - there is no bite.



LEO:  It's real smooth.  There's no acid



STEVE:  It is bizarre.  Now, I also have the stomach of a billy goat.  I mean, I'm sure...



LEO:  Right.  Because a lot of us, especially as we get older, my stomach gets upset.  I just had a cup of acidic coffee, and I feel it.



STEVE:  Yeah.  I love it.



LEO:  So this comes from our discussion last week of FunraniumLabs.com, the Black Blood of the Earth, cold-brewed coffee.  And, now, the good news is that Toddy, that brewer that you got and I have here, too, is only $30.



STEVE:  Right.  It was an inexpensive experiment.  I lost a pound of Starbucks Espresso.



LEO:  You really don't like it.



STEVE:  No, I just - it's just - it doesn't taste like coffee.  It just sort of freaks me out.



LEO:  I should have warned you because the Funranium is just like that, that Black Blood of the Earth.  It's just too smooth.



STEVE:  Yeah, it is ultra smooth and - I don't know.  Now, so the good news is, if there are listeners who have a problem with acidity, this solves it, baby.  I mean, it is smooth.  But it just isn't coffee.  I want to be bitten.



LEO:  Well, you won't like this, then.  Don't watch.  Because I've purchased another device.  Let me show you real quickly.  This is - it's just pretty.  That's why I bought it.  It's a wooden rack...



STEVE:  I saw that.  I thought, oh, no, Steve.



LEO:  It's like a distiller.



STEVE:  Don't go there.



LEO:  Yeah, yeah.  It's a little pricey.  And but I thought it'd be kind of cool in my house to have this on the counter.  And [laughing], oh, lord.



STEVE:  It's gorgeous looking.



LEO:  It's, well, that's kind - it's more like it's just cool than anything else.  This is called - I'll give you the name so that those of you who want to find out more, it is on Amazon.



STEVE:  It looks like a coffee guillotine.



LEO:  Yeah.  It really looks like a device; right?  And it's tall.



STEVE:  Yeah, looks like a chem lab sort of...



LEO:  Yeah, it's called a Yama, Y-A-M-A, cold drip coffee and tea maker from Northwest Glass.  And let me see how tall it is.  It's two feet tall.  So the idea...



STEVE:  Oh, it looks like it's seven feet tall.



LEO:  I know.  It does look like it goes a long way.  It looks a little bit like a distillery.  It's got a lot of glass.  That's one of the reasons I got it because the Toddy - this is a little more expensive than the Toddy, it's 200 bucks - but the Toddy is plastic.  They say it's not - there's no BPA in it, and so it's safe, et cetera, et cetera.  But it is a plastic brewing device.  And it took all day, right, 12 hours.  So you put the coffee in here...



STEVE:  Oh, I gave mine 36.



LEO:  You let it just go.



STEVE:  I let it go for 36.  Mine said - I think I got a different version or a different brand.



LEO:  You strong-brewed it.



STEVE:  Mine was Filtron, I think, was the...



LEO:  Ah, okay.



STEVE:  Yeah.  And so you basically ground - I used the nice burr grinder that we have and ground the entire pound of Starbucks, dumped it into this thing, and then it drizzled the amount of water in slowly in the top, and it filled up over the course of about an hour.  And then I let it sit there for a day and a half, 36 hours...



LEO:  They say longer the better, or the longer the richer.



STEVE:  Yeah.  And then I drained it all.  In fact, this said that some people who want to stretch their coffee dollar will then use half the amount of water a second time to, like, run it through the grinds or grounds...



LEO:  We're not stretching our coffee dollar here.



STEVE:  I wasn't stretching.  And in my case the result is this syrup, this super-concentrated coffee syrup.



LEO:  It's got flavor, doesn't it?  I mean, it's not that it doesn't have flavor.  It just doesn't have that bite.



STEVE:  Yeah, you're right.  It definitely has flavor.  And I just thought, no.



LEO:  I'm with you.  It tastes - it feels watery.  Because it doesn't have that acidity, it feels like there's nothing going on.  It's just kind of tea.



STEVE:  Yeah, it's just - it's different.  It's very flat to me.  So...



LEO:  Anyway, we'll just have to see.



STEVE:  Anyway, so now I know.



LEO:  Hey, this Yama is, like, 200 bucks.  So I'm glad you didn't go that far.



STEVE:  No.



LEO:  But it will be - I will look like I am making meth in my house.  Oh, lordy.



STEVE:  Well, I have a short note, a very note, from a SpinRite listener who is anonymous.  He said, "I am a computer maintenance freak.  I had been experiencing a problem which turned out to be a software glitch.  However, I was at the time afraid my drives were going to go.  I learned about SpinRite while reading up on SmartComputing."  He has those capitalized, so maybe that's a site.  And he said, "Double-checked with my office computer guy, who highly recommended SpinRite.  Purchased and downloaded it today.  It took a few hours to run through my drives.  Seems like things are running better and faster than ever.  So thanks.  This was a great investment, and I will add SpinRite to my maintenance schedule."  So he's got the right idea.  Get it before your drives die, and they probably never will.



LEO:  Yeah, yeah.  All right.  Question #1, an anonymous listener dropped by to make a quick, however important, point, suggesting that doubling key size is security theater.  Remember we had a question two weeks ago, somebody says, well, why don't we just - we went from 1024 to 2048.  Why don't we just go to 5096 or something?  If your key is large enough, he says, or she says, to make a brute force attack infeasible, a longer key doesn't add security.  Beyond that point, a determined bad guy will try to exploit a weaker link, and there are plenty of those, like buggy software, spear phishing, social engineering to get a keylogger installed.  Bad guys know the old story:  If you're hiking in the woods, you don't need to outrun the bear as long as you can outrun the other hikers [laughing].



STEVE:  I thought this was a good point.



LEO:  I love that analogy.



STEVE:  So it's the weakest link.  And at some point we know - in fact, true crypto failure is almost unknown.  I'm trying to, I mean, almost, I want to say, because there have been, historically, there have been some flaws found in older technology.  We no longer use MD4.  But even RC4 that was the crypto used in the very first WiFi, the WEP WiFi, it wasn't the fault of the crypto, it was the fault of, again, the implementation wrapper that the crypto contained.  And so that we continue to see, just like we were talking about OpenID and other things.  It was like, hey, all of this is all super security and signed and keys and all that, but then they forgot to check, see if the signature was valid.



LEO:  Right.



STEVE:  Like, whoops.



LEO:  Whoo, yeah, all right.



STEVE:  So but the one thing I did want to remind us of, sort of that is a counterpoint to this notion that doubling key size is security theater, is the notion of future-proofing because that's something to keep in mind.  There's this spectre of quantum computers hovering out there that are sort of going to just instantaneously try all possible keys at once.  We're a long way from there.  And lord knows what happens when those exist because the end of the world as we know it.



But for now, it is significant, I think, that that NSA facility is not attempting to crack things today.  They're going back and going to crack things that they've been recording for the last 50 years, back when the underlying security technology was strong enough for then, but not for now.  So there is this notion of the future.  At the same time, 128 bits is plenty for connection-oriented things, like Carbonite, for example, is using 128 encryption.  That's a session key used on a point-to-point link which is regenerated and changed every time you reconnect.  And also sometimes on the fly you're able to renegotiate a key on a running basis on these connections.



So 256 bits is plenty for data at rest as opposed to data in motion.  So you want to choose key lengths properly.  But the anonymous listener who wrote this question is certainly correct that, once you are future-proof, then all you're doing is wasting space and time and processor cycles.  And heating up your iPad 3 needlessly.



LEO:  By the way, it is not that hot.  It's just nicely warm.



STEVE:  Yeah, it is.



LEO:  Think of it as a hand warmer, a sheet warmer.



STEVE:  I love it.  I don't regret the iPad 3 at all.



LEO:  Oh, man, I love it, yeah.  They're just...



STEVE:  It's a nice device.



LEO:  A lot of people saying, oh, it's just a mere incremental upgrade.  I don't know how they could say that when they look at the screen.  It is more than an incremental upgrade.  And the camera.



STEVE:  Amazing.



LEO:  Yeah, yeah.  Al Kraybill in Arlington Heights, Illinois, found some buffer bloat.  SN-345 equals fantastic.  I ran the test and got "Network buffer measurements" - he's talking about the Netalyzr test.  In fact, bit.ly/sn345 will take you to that Netalyzr test.  Don't all do it at once.  We broke it last time.  But like I said, they wrote, and they said thank you, we appreciate it, we're getting a lot of data for our - because it's a study they're doing.



STEVE:  Neat.



LEO:  And I gave it to Russell, our IT guy, said this is a great thing to have in your toolkit because we learned a lot.  So this guy had an uplink of - I guess an uplink latency of 490ms, downlink of 2,000ms.  Yikes.  That's what we call a bloated buffer.  So what can I do about it?  Is there any way to tell where the bloated buffer is?  My router, a D-Link DI-602, is about eight years old.  Could that have too much buffer?



STEVE:  And this is the problem, that I saw some amazing measurements from our listeners.  One guy was at 7.5, wait, not minutes, 7.5 seconds.  So, I mean, 7,500ms in one direction.  And the problem is that we're in that awkward place where something is getting a lot of attention, yet as the stickers say on the back of our televisions, there are no user-serviceable parts inside.  Once upon a time you had tubes, and you'd take the back off the TV set, and remember you'd not want to use one of those cheater cables that allowed you to keep the thing fired up with the back off because you wouldn't want to electrocute yourself.  And you'd pull the tubes out and take them down to the drug store and run them through the tube tester.  I'm sure you remember those days, Leo.



And now we've just got boxes that are closed.  And at the moment, while this issue is still so new, there just isn't anything for us to tune.  There is, like, the newer version, the newest version of Linux, 3.3, is beginning to address this.  Hopefully that will make it into some router firmware, like the Tomato or the DD-WRT stuff, where we'll begin to get this addressed.  At the moment, right now, I don't think there's much that anyone can do.  And, I mean, this is where I guess I'm glad that I'm as busy and backlogged as I am with existing projects because, I mean, I could just go off on this and never return.



LEO:  Yeah, it's fascinating.  It's fascinating.



STEVE:  Oh, I would love to do a utility that would tell you where in your link the problem was, and it's possible.  But no, don't worry, I'm not going to let myself get distracted by that.  So Al, I just, unfortunately, it's useful to know we have the problem.  There's not much we can do except to work to minimize the buffering, which is to say, if you know you've got a - when something is saturating your bandwidth, when you know that in addition to saturation you also have delay, then the only thing you can do, if you're unable to find the delay and remove it, is work on whatever it takes not to allow that buffer to get full.  Which, for example, means being careful not to be uploading a big file when other people in the household are trying to be interactive on their computers, do that some other time.  And so at least now we understand what's going on, which is a big step forward, although it also creates some frustration in people who want to fix it.



LEO:  Yeah, yeah.  Well, I'm sure, I think we'll see fixes in time.  I mean, we'll see something, I hope.  Steve Coakley in Phoenix, Arizona found router buffer excessive buffering.  Oh, really.  Another one.  I ran the Netalyzr utility you mentioned on Security Now! - again, bit.ly/sn345.  And besides excessive buffering, I got a lot of strange errors about DNS not working correctly.  It doesn't look like I can change the DNS server in my Qwest Actiontec Q1000 DSL modem/router.  It's set to - and he gives some...



STEVE:  IPs.



LEO:  ...IPs.  He changed it to the 4.2.2.2, which is Verizon, right?  Or is that Level 1?  Anyway...



STEVE:  Actually, it used to be Level 3.



LEO:  3, I mean, yeah.



STEVE:  And I'm not sure whose name is on it.  I think Level 3 still.



LEO:  And ran the test again.  This time all the odd DNS errors went away, and it only found two problems.  The first one, network packet buffering may be excessive.  We estimate your uplink as having 5,700ms of buffering.  Yeah.  5,700ms of buffering.  And we estimate your downlink as having 450ms of buffering.  Wow.  5.7 seconds is a long time.  Can anything be done about that?  Can I even tell where it's happening?  This is kind of like the previous question.  The second problem, DNS resolver properties lookup latency was 340ms.  That doesn't seem so bad.



STEVE:  Okay.  So I did want to mention that that test tests a lot of other things.  And many users found, just as Steve Coakley did, found other problems with their network that they were unaware of.  My sense is that 340ms is a little slow for DNS lookups.  I don't know why it would be so slow.  Maybe it's just the DSL connection that he's got.  I wanted to remind people that my own, GRC's DNS Benchmark, exists, and that that might be a good thing to use.  There may be some solid, publicly available DNS servers other than the Level 3 servers, although those generally do perform up near the top of the list.



But the DNS Benchmark from GRC, you just - in fact, I think you can just put "DNS Benchmark" into Google, and I pretty much claim that territory now because the Benchmark is a good one.  It is Windows-only, but it is friendly with Linux under WINE, and you can run it on MAC with WINE, as well.  And again, we've discovered huge buffers.  One of the other problems that we have is that it could be ISPs buffering in their routers, so those buffers are completely inaccessible.  And also we know that later model network adapters have large ring buffers in the kernel, so that's introducing delay.  And we may never have access to that.



So again, the best thing we can do is, like, ask everybody, make noise, jump up and down.  Hopefully this is a problem which just sort of, well, we know that it just sort of crept up on us.  Nobody was really paying attention to it.  Now a lot of attention is coming to it because people are downloading large content, not just being interactive.  This was never a problem when everything was just web surfing, clicking on links and being interactive.  This because a problem when some member of the family wants to watch TV over their Internet connection, which was crazy five years ago.



LEO:  Crazy.  Crazy talk.



STEVE:  Now it's what people do while other people want to...



LEO:  It is, it's what we do.



STEVE:  It is, it's just - it's amazing.



LEO:  In fact, often three or four people in the house are watching different channels on their iPad, their TV, their Netflix, their Roku.  I see that in our house all the time.  And then somebody wants to Skype, it's just - what a world.



STEVE:  It's amazing.  It's amazing it works.



LEO:  Bandwidth consumption is not going to go down anytime soon.  I think we've realized that.  I think Comcast realized it three years ago.  That's why they put caps on.  Magic Johnson - or, no, just Magic John in Colorado, USA, needed to comment about our server security conversation:  I listened with horror, Steve, as you agree with Leo's supposed expert.  You did not agree, by the way.  I want to make this clear.  You sat there and nodded, but you didn't necessarily agree.



I maintain websites with in excess of 14 million unique visitors a day.  We have never been compromised, yet we see hundreds of attempts per hour.  It's not PHP that is the problem.  It is the code that is written in PHP - well, okay, thank you, master of the obvious - and the willingness of a system administrator not to correctly set file and directory permissions.  And that one I might agree with.  Bad code can be written in any language, as can good code.  The difference is bad coders are tempted toward the use of toy languages such as PHP.  I don't think he understands what I was talking about.



There's no excuse for the injections that have happened and the placement of code on Leo's system.  I was especially horrified by your acquiescence, which again, you did not do, to my comments that in the good old days we had a cgi-bin directory.  We still have a cgi-bin if we want, he says.



STEVE:  Well, I wanted just to come back to this briefly because I had a nice exchange with Bear.



LEO:  Bear, who is a pretty good expert.



STEVE:  And what happened was...



LEO:  Runs systems for Mozilla, among others.  Okay.



STEVE:  There was some, yeah, similar sentiment that I tripped over in the GRC newsgroups.



LEO:  Oh, I more than tripped over it.  I got it nonstop.



STEVE:  And so I went over, and I said, you know, guys, I don't - we don't have all the facts.  We don't know what's going on.  I'm unwilling to pile on someone who I don't know, and it just doesn't seem fair to me.  And I said, so we just don't have enough information.  And Bear, someone must have said hey, you know, this is being talked about over at GRC.  So he, to his immense credit, came over and said, hey, it's me, I have a thick skin, so let's talk about this.



And I what I had posited was that TWiT was in transition, and this is from things that you had said, Leo.  I mean, you were quite literally a cottage industry for quite a while, just down the street.  And Bear commented in the newsgroup, for example, that he had found the problem and turned it off, but somebody else turned it back on, and that that was really the way that this came to notice and was the problem that it was.  And what that really said was that you guys are growing, and that there's a need for policy.



LEO:  But let's put that aside because of course that's a bad mistake.  But the larger question is, and this was the thing that I really would love to get to the bottom of, is that as long as a website is being changed in any way, you're going to have security flaws, and that breaches are not - this is my real question.  Are breaches uncommon or common?



STEVE:  And I'm not an expert.  I cannot say.



LEO:  Bear is of the opinion and knows - runs a very big site and knows others who run other well-known sites, and he's of the opinion that, as we have become more and more high-profile, we are certainly getting more attacks; and that it is very, very difficult, if nigh impossible, to prevent breaches of some kind.  The question is really how quickly you see them and modify them.  But on the other hand, people like our commentator here do raise the point, well, Magic John says you shouldn't allow file systems to be written to and shouldn't be able to do - but I think that that's the point of an exploit is that it somehow allows access, higher level.  I don't know.  I'm not an expert.  I don't know.



STEVE:  Well, and we don't know, none of us know except whoever is your, I mean, the gurus of your web server, for example...



LEO:  There's the guy, he's the guy who runs our server, so...



STEVE:  Are all of the directories read-only except, like, very carefully tuned so that the equivalent of cgi-bin, I mean, for example, at GRC there's only one location where anything can be run.  Every...



LEO:  And this was my problem with PHP.  PHP, unlike cgi-bin, can be put in any directory and run from any directory.  So, I mean, admittedly, all directories should be write-proof except that you have to have some directories that are going to be written to; right? 



STEVE:  Well, okay.  So what you have with PHP is similar to what you have with ASP, Microsoft's Active Server Pages, the idea being that it's - and our listeners are tired of hearing me talk about JavaScript.  JavaScript is scripting run by the browser.  So PHP...



LEO:  Right.  This is all server-side.



STEVE:  Exactly.  PHP, like Active Server Pages and other technologies, there is server-side JavaScript also.  Anyway, those are scripts being run by the server.  So there the server is not delivering static, prewritten HTML.  It's actually running the PHP code to create these pages on the fly.  And so that's, I mean, it is a powerful technology, but it's also one that you have to be far more careful in deploying.  So what I think we can definitively say is that it is, from everything we've seen, all the evidence, and it's not like TWiT is the only site on the planet being hacked, I mean, we're talking about hacks all the time.  I mean, like, RSA, the security company, is getting breached by exactly these sorts of things.



So what we can definitively say is it is really hard.  There are old curmudgeons out there who want to say, oh, no, this is really easy.  It's not easy.  I mean, my site is easy because I don't have any server-side scripting stuff like that.  I haven't had to deal with this.  I do have static HTML.  And then my own stuff generates dynamic pages like the ShieldsUP! page and so forth.  So that's why I really can't speak to the challenges, because I haven't faced them myself.  But we know that security is difficult.  And so I think, I would imagine, that the lesson that TWiT has learned is it's time to really focus on security.  I mean, there probably shouldn't be a situation where Bear could disable something which is now a known problem, and somebody else could turn it back on again.  So...



LEO:  Well, yeah.  And that was a miscommunication, and that certainly, you know, that's not going to happen again.



STEVE:  Yeah.  And so there needs to be a single point of responsibility, somebody who really has that job, and sort of like moving...



LEO:  Well, that's a problem because we have web developers that are working on the site.  Now, I think a big problem was, with this previous TWiT.tv development, we didn't have a production and a development site.  We were doing stuff - code went live live.  And that was a big mistake.  We're not going to do that anymore.



STEVE:  So also there's some live and learn.



LEO:  Yeah.  But I don't know.  I don't know.  I don't understand it.



STEVE:  It isn't easy.  I mean, we talk about it...



LEO:  I don't want to have to hire a full-time security sysadmin, and I can't afford it.  So I don't know what the answer is.  I don't know what the answer is.



STEVE:  Yeah, well, I mean, you're wanting to have a fancy, feature-rich site, and the truth is that's hard to do.  This technology is fundamentally flawed from a security standpoint.  This technology, as I've said before, if you have a system where you can upload an SQL command that the server will execute, I mean, that's just crazy.  It's easy to implement, but it's a disaster from a security standpoint.  And frankly, the idea of pages being PHP so that all of your server needs to be executable, that's horrifying, too.  I mean, it didn't have to be that way.  But, boy, is it simple.



LEO:  And I would say in my defense that Richard Clarke, who used to be the counterterrorism czar in the U.S. administration, said every major U.S company has already been hacked by the Chinese government.  So, I mean, if it were really easy - I don't know.  He says it's pretty clear the U.S. government did the Stuxnet attack.  I thought that was interesting.  I think there was some minor Israeli role in it.  So we wrote Stuxnet, according to Richard Clarke.  Israel might have provided a test bed, for example.  But I think that the U.S. government did the attack.  I think this is fascinating.  And we talked a lot about Stuxnet.  You of course immediately said, no, it's governmental.  It's just not clear which government.



And I think the attack proved what I was saying in the book, which came out before the attack was known, which is you can cause real devices, real hardware in the world, in real space, not cyberspace, to blow up.  He's talking about cyberwarfare.  He says the war's already begun, and we're losing.  China has basically hacked every single major company in the U.S., says Richard Clarke.  And a few small podcast networks.



STEVE:  I guess my - when we hear that, it's easy to think, oh, my god, unplug everything.  But the fact is you're getting far more benefit from your website than it costs you.



LEO:  Right.  And you're not - nobody's getting credit card numbers by hacking our website.  They're not getting anything, you know...



STEVE:  Right.



LEO:  They're getting our website.  They're getting us.  But they're not getting any credit card numbers or anything.  "'I'm contributing to FUD,' says Hogan."  I'm just quoting Richard Clarke, who seems like he has a dog in this hunt.  But I don't know.  See, I can't say anything.  I'm just going to shut up.



Question 5, G. Sveddin in Southern California about Spidey - or SPDY.  I call it "Spidey" because I'm a Spiderman fan.  With respect to SPDY, I'm surprised to hear your excitement about the server push mechanism.  Seems to me a server that can push content without a request will waste bandwidth on unwanted content.  For example, of NoScript is installed and functioning, why should I download the huge JavaScript framework libraries on many sites now?  Another example is turning off images when mobile browsing.  With such bandwidth caps and costs, I wouldn't want to download content I don't want.  And this actually is an interesting question.  I kind of..



STEVE:  Yeah.



LEO:  It came to me, too.  I understand why there's a scaled-down version of server push which hints to the client what they should be asking for next.  But that appears to hinder the speeding-up of the bandwidth as the client would still have individual requests.  I would think the parallelization of requests and content returns would have a better payoff.  Let the browser request all it wants, after filters like NoScript or image block, and fill the bandwidth with only desired content.  All in all, SPDY sounds good.  But from the little I've heard and read it seems focused on delivering all content, a business perspective, rather than just desired content, a user perspective.  I'd love to see a more middle-of-the-road perspective.  I hypothesize adoption would be much faster on both sides.  Thanks, G. Sveddin.  What do you think?  Is it anti-user and pro-business?



STEVE:  Well, it certainly changes the model from a client-side request to one which does offer some server push.  Now, in fairness, the server push side is regarded as an advanced feature.  It isn't part of the base SPDY spec.  Both of those things, the server hints and the server push, are sort of more on the experimental fringe.  It's like, well, this is in the spec.  We didn't want to, like, not design it in so that we wish we had it later because maybe it would be a good thing.  My sense is it isn't something which is being actively used and deployed at this point, probably for much the same reason.  And I really do, I mean, as a proponent of only getting what we ask for and of things like NoScript, he's right.  Some of these scripting libraries are just big blobs which someone gives you the URL to it, and your browser's going to suck it down and take all the time to do that, which is crazy if you've got scripting turned off.



So, no, I think his point is well taken.  For what it's worth, my sense is it isn't happening now.  And I would argue that the business perspective is giving the user the most responsive page possible, and that you could, for example, give them images.  Well, of course, here he was saying he wants to be able to turn images off.  So that's a problem.  Anyway, so I guess it's certainly a tradeoff, and I thought he raised a good point, which is why I wanted to include it.



LEO:  Brian M. in Edmonton, Canada wonders about SPDY and CDNs:  I've been catching up on the discussion about SPDY.  I saw a major problem.  Many websites, my own included, use Content Distribution Networks (CDNs) that serve static assets - images, JavaScript, et cetera - from geographically distributed servers.  Many CDNs use anycast, a topic you discussed a few weeks ago.  With SPDY, wouldn't all of my assets need to be pumped through the same servers that handle my main dynamic content?  That could be catastrophic for many sites.  It would slow down my app servers.  It would be more expensive because the price to serve static assets from app servers is quite a bit more costly for a few different reasons - processing, bandwidth, et cetera.  Or am I missing something?  Thanks for the great podcast.  Brian. 



STEVE:  Okay.  So what he's assuming is that this - we talked about the notion of a single connection being made between the browser and the server, and sort of had to get over the idea that that could be faster than multiple separate connections.  And as long as we've got a single connection highly used, a fully utilized single connection, which is what SPDY for the first time allows because we can overlap things, that single connection can be overall much more efficient than making separate connections.  But that absolutely doesn't keep you from establishing additional SPDY connections to entirely different domains.



So the idea would be you would have one connection per domain or per server from the browser out to that remote asset, and a different connection to the CDN.  So you're still going to get the benefit of SPDY.  In fact, the CDN might not support SPDY, so the browser would seamlessly use a non-SPDY connection to the CDN, yet a SPDY connection to the server in order to pull all of those assets from one place.  So there definitely is no assumption or presumption on the part of SPDY that it will only be making a single connection to a remote location.  It'll make a single connection per server.  But if you're pulling content from 36 different places, it'll set up 36 connections, and those that are SPDY can run faster than they would otherwise.



LEO:  So no problem.



STEVE:  Compatible with all of that, yeah.



LEO:  Jon in Kentucky wonders about the future readability of computer media.  Oh, don't we all.



STEVE:  Ohhhh.



LEO:  Anybody with a Zip drive knows, or is it disk, I should say.  If you have the drive, you're okay.  Mr. Gibson, sir.  My father's church is getting ready to celebrate its 100th anniversary pretty soon.  They plan on opening the time capsule under the cornerstone - that's neat - and adding a CD with photos on it.  It hasn't been opened since the '60s.  I was thinking about this.  What would be better for them to use, figuring the technology still exists to read them, a CD/DVD or a thumb drive?  Thanks for your time.  Jon.



STEVE:  You know, this is a great question.



LEO:  It is.



STEVE:  Because, for example, I have around here some MFM hard drives with data on them, yet no MFM controllers.  Or if I have an MFM controller, it's got an ISA, the original bus from the PC, and I have no motherboards with ISA buses anymore.  It is a really good point that we think in terms of the technology we have and are using, but this whole issue of will we be able to read it in the future, not just will the medium itself hold up its integrity, I mean, that's a question, will the writable CD be readable even if you had the technology?  I mean, well, if I had an eight-track tape from back in the day, I don't have any eight-track tape players.  Of course vinyl has come back into vogue, so there's an exception to the problem of needing a turntable to play the disks that you and I were listening to in college, Leo.



LEO:  Well, you know what you should do, you should print prints.  Because those will be good.



STEVE:  That's exactly right.



LEO:  And better yet, put it on papyrus.  It's the only thing we know lasts thousands of years.



STEVE:  Put it on acid-free paper.



LEO:  Yeah, exactly.



STEVE:  You want it on acid-free paper so it will not yellow.  All of my DEC manuals from the early 1970s are just...



LEO:  They're crispy, yeah.



STEVE:  ...incredibly yellow because they were not on acid-free paper.  I printed all of the "Passion for Technology" books that I published on art-grade, acid-free paper, not that I particularly thought they'd be in any time capsules for any reason, but I just thought, well, I want them to look the same way a hundred years from now.



LEO:  But music, if you're talking about music, a vinyl record is going to be very simple to reverse-engineer because you can look at it, and you say, oh, I see, these are wave forms.  I just need something to read these wave forms.  Maybe, it's possible a CD will be so easy to reverse-engineer.  Certainly there'll have been a lot of CDs around, and presumably any future archeologists a hundred years from now will certainly know how to read CDs.  Hard drives, a little more opaque, if you ask me.



STEVE:  Yeah, I was thinking maybe put the CD and a USB CD drive in.  That is...



LEO:  Ah.  A reader.  Put a reader in.



STEVE:  Put a reader in.  Now, the problem, of course, is the USB interface.  We're already moving...



LEO:  That's gone.



STEVE:  ...to USB III.  And so a hundred years from now we're not going to have, well, I don't know when they're going to open this again.  But 50 years from now we're not going to have USB.  We'll be onto some Twilight Zone technology.  I mean, Intel's already pushing stuff that's, like, can it even work, it is so fast.  It's like, okay.



LEO:  Make prints.  The human eye has not changed its interface in tens of thousands of years.



STEVE:  That really is the answer is print these things out.  Instead of doing a CD, print them out.  That's what you need.



LEO:  But this is actually a very big topic.  And what I find fascinating is it is now the province of librarians because librarians have become information specialists and archivists.  And they are at the forefront of this.  It's fascinating stuff.  It's something I talk about on the radio show a lot because this is something real people do want to think about and really don't know what to do about.



STEVE:  Well, especially photos that are sort of, by definition, for the future.



LEO:  Right.



STEVE:  But if the future can't look at them, then you've sort of defeated your purpose.



LEO:  Jared in Western Australia has been wondering about spare sectors.  That was not a good Australian accent.  That came out all wrong.  Listening to your discussions on the show about how SpinRite works and how it shows the drive's bad sectors and induces the drive to map out weakened sectors before they become terminal is all well and good.  But I've never heard you discuss what happens if the drive runs out of spare sectors and cannot map anymore bad sectors?  Oh, you're in trouble if that happens [laughing].  You said that sectors are mapped out as bad at the factory.  So when the drive is new, its capability to map out additional sectors would already be somewhat compromised.  Is there any way for us to know where the drive stands?  Can you run out of places to put stuff?



STEVE:  Oh, yeah.  You can.



LEO:  It's more the drive allocation table, I would guess, than, I mean, the drive you can find spare sectors.  It's the drive; right?



STEVE:  Well, what happens is that drives generally store extra sectors at the end of their track.  And I've talked about mapping sectors.  Well, the way that actually happens is they will move all of the sectors from the bad spot to the end of the track down by one.  They shift the whole, all of that block of data down so that the drive can continue to read at normal speed.  It just sort of reads past the bad sector and finds the one it was looking for, that it expected to see in the bad spot.  Now it finds it a little bit further down.  So they actually just shuffle the balance of the track downwards toward the end of the track.



Well, there is a limit to how far they can go.  And this is the one place that that SMART, S.M.A.R.T., the Self-Management Analysis And Reporting Technology, SMART is the acronym, and it will show you - there are different parameters that SMART has.  And one is relocated sectors.  And what you don't want is for that to get down to zero because essentially it doesn't - the problem with SMART is that manufacturers never wanted to tell us anything about what was going on inside the drive.  They wanted it to be a black box that we buy, and we're happy with.



But Compaq, back in the old days, said no, we insist - Compaq was like a major IBM clone manufacturer, for those who don't remember the name.  They insisted, and they had enough purchasing power to force drive manufacturers, the big ones at the time - Western Digital and Seagate, Micropolis and Maxtor - to force them to give them a means of asking the drive how it feels.  And Compaq actually famously used SpinRite on their dock where they were accepting drives.  They would over-order drives and use SpinRite to prequalify them before putting them into their machines, and would send back the drives that SpinRite said were weaker, less good, than the majority of the drives.  And manufacturers didn't like that they were doing that.



So they said, okay, fine, we'll - and that's where this whole SMART system came from.  It is a sadly weak specification.  It's not something that anyone should be proud of.  Manufacturers were compelled to do it, or they would lose a major vendor in the form of Compaq.  And so they added this.  The point is that it doesn't give you a lot of data.  It sort of gives you a happiness indication.  And when that runs to zero, then you're really in trouble.  So that's one of the things that SpinRite monitors while it's doing its work.  There's a screen there that monitors the SMART parameters on the fly and also is able to show you the rate at which error correction is occurring, which allows you to get some sense for the relative health of the drives.



So they are black boxes.  The manufacturers don't want us to see what's really going on.  There is no specification for asking a drive for its bad block tables, for how many spare sectors it has remaining, for which tracks are almost out of spares.  There's no interface like that, that is available to the outside world.  So we do the best we can.  And of course running SpinRite on the drive from time to time allows the drive to at least know what's going on with it, for what good that does.



LEO:  Next we got Bob Lindner in La Crosse, Wisconsin.  He found news of Astaro and, brace yourself, Stochastic Fair Queuing:  Guys, I thought it worth a mention, I've been playing with the Astaro product, the home ISO download.  Good for you.  I think this is a really great product.  A few weeks ago I enabled the QoS (Quality of Service) settings.  The Astaro Security Gateway (ASG) allows you to enable an Upload Optimizer and a Download Equalizer.  They are described as follows by Astaro:



The download equalizer:  If enabled, Stochastic Fairness Queuing (SFQ) - this is becoming the acronym winner of the week - and Random Early Detection (RED) queuing algorithms will avoid network congestion.  In case the configured downlink speed is reached, packets from the most downlink-consuming stream will be dropped.  That's the download equalizer.  The upload optimizer, if enabled, will automatically prioritize outgoing TCP connection establishments, that is, TCP packets with the SYN flag set;  acknowledgment packets of TCP connections, that's the ACK flag set and a packet length between 40 and 60 bytes; and DNS lookups, UDP packets on port 53.  I thought you might find this interesting.  Thanks for the great podcast.  Bob.  Talk about dumping this in your lap.  So there.  What is that?



STEVE:  What's really interesting, okay, we talked about the first part, the download equalizer that uses this Stochastic Fairness Queuing and Random Early Detection, the idea being that, as a buffer is filling, the router will begin discarding packets statistically more often to prevent the buffer from ever getting completely full.  And that means that, if a particular stream is hogging the bandwidth, the chances are its packets will get dropped, which will send its endpoints the message that they need to back off and slow down.  So that's this RED, Random Early Detection, is the most often used Active Queue Management - there's another acronym, AQM - which is what we're going to be dealing with now for the next decade, is smarter queue, active queue management.



But the upload optimizer is really interesting.  This is a move to the front algorithm.  It says, if enabled, this option will automatically prioritize outgoing TCP connection establishments, that is, TCP packets with a SYN flag, as in synchronized set; acknowledgment packets of TCP connections with the ACK flag set and short packets, that is, between 40 and 60 bytes; and DNS lookups.  So this is neat because it means that the little tiny packets which we need in order to keep our connections running move to the front of the queue.  They don't have to wait behind a long delay of blob that's being uploaded or downloaded.  The Astaro technology gets them out right away.  That doesn't delay the blob because these are necessarily very small packets.  They're going to be 40 bytes rather than 1,500 bytes.  So in terms of the packet delivery time, there isn't much cost, but they do allow the system to act as if there is no bloat in the buffer.  So bravo, Astaro.  They clearly gave this some thought, like before the rest of the industry had.



LEO:  Wow, that's pretty smart.



STEVE:  Yeah.



LEO:  Amazing.  Our last question, Mr. G., from Kyle D. in B.C. [laughing].  How did I do that?  He wonders about private email.  Steve, I have a question about private email.  I currently store way too much information on Google, and I'm trying to move some services away.  Do you know of any good email services with a better privacy policy than Gmail, Hotmail, or Yahoo!?  I normally use PGP for anything sensitive.  I would just like slightly better terms of service/privacy policies when dealing with email.  Thanks, great show.  Kyle D.



STEVE:  So that's really one for you, Leo.  I have my own servers at GRC, so I've never needed to think about the repository.  But for people who, like with Gmail, have all of their mail living somewhere, Kyle is becoming a little nervous about that.  And so I thought - I wondered if you had any suggestions for probably smaller solutions who maybe are a little more honorable.



LEO:  I do.  But I would say, first and foremost, that any service that you're going to use is - you're trusting them.  And maybe we've all lost trust in Google, Yahoo!, and AOL; maybe not.  But most services have similar access to your content and, if they provide antispam services, are doing similar scanning of the content.  So, I mean, that's just the nature of antispam.  They're looking at keywords in the same way that Google does.  Google does it for both antispam and for advertising, so maybe you don't like that.



Since he uses PGP, I'm going to recommend a Canadian company called HushMail, which is an encrypted service.  Now, I should point out that HushMail, if presented with, like anybody, I think, presented with a governmental subpoena from law enforcement, will disclose.  So the reason they can do that is because I guess they have the key.  Anyway, I do think Hushmail was created with exactly this point of view.  They have a privacy policy.  They do not do spam filtering because they don't look at your mail.  They talk about in their privacy policy web logs and cookies.  They do log IP addresses.  Cookies are not used for marketing purposes, however can be used to track your settings.  It is not possible for users to view and update their personal information, but this feature will be available in the near future.  Hush must be able to authenticate the user, and they do that.  They require a securely sent Hushmail message.  But that's the only information they have, basically.  Pretty much this is a good solution, and it is encrypted using PGP.  Phil Zimmerman worked with them.



Another solution that you might want to look into, I think I'm moving my email to them, is a U.S.-based company called Island Email.  I know about them because they support MailRoute, and so they have very good antispam filtering, but that means that MailRoute is scanning your email.  Your Internet service provider is probably similar to one of these services in the sense that they also may do some scanning of your mailbox.  Unless you host your own email server, I think that's the only way to for sure know that only you control that content.



Finally, I'll tell you what I am currently using for my IMAP.  They were recently purchased by Opera, so that may be a nonstarter.  It's called FastMail.  I like FastMail a lot because they are, I think, the most sophisticated IMAP server out there.  And Opera has not changed them in any way.  In fact, the only thing Opera has done, as far as I can tell, is give them more resources.



So if you're looking for hosted email, understand that hosted email is always going to have some of this problem.  I guess HushMail is probably the best choice in hosted email because of PGP encryption built in.  And they have a very aggressive privacy policy.



STEVE:  And they've been around for a long time.  And I know that a lot of people trust them.  So, yeah, I think HushMail is a great thought, Leo.



LEO:  Yeah.  "In some countries government-sponsored projects have been set up to collect" - this is on HushMail.  They have a good article, "How HushMail Can Protect You."  But there was a recent news story, you should probably read it, that says HushMail does give up some information.  "HushMail does not put you above the law.  We're committed to the privacy of our users and will absolutely not release user data without an order that's legally enforceable under the laws of British Columbia, Canada, which is the jurisdiction of our servers.  However, if we do receive an order, we're required to do everything in our power to comply with the law."



I think what they're saying here is, well, this is the next one.  I thought data was always encrypted.  "When one HushMail user sends an email to another HushMail user, the body and attachments of that email are kept on our server in encrypted form, and under normal circumstances we would have no access to that data.  We cannot pick an arbitrary encrypted email message off the server and read it.  However, since HushMail is a web-based service, the software that performs the encryption either resides on or is delivered by our servers.  That means that there is no guarantee that we will not be compelled under an order enforceable under the laws of British Columbia, Canada, to treat a user named in an order differently and compromise that user's privacy."



What they're saying is we could be forced to compromise our own encryption software so that law enforcement could read your email.  But I don't think you could do it after the fact.  I would suspect that that would mean in an ongoing conversation.  But anyway, read it.  And the other thing to do, which is not a bad idea, is to use PGP encryption on your email.  And I do that.



STEVE:  Yes.  If you use your own encryption, then you're just transferring a blob from one place to the other.  So you're doing end-to-end encryption, or as we have called it before, pre-Internet encryption, where you take responsibility for encrypting.  Then nobody can read it.



LEO:  Right.  Unless the law enforcement comes to your house, then says give us the keys.  And now the courts are going back and forth on this one.  The most recent court decision says they can demand keys if they have other evidence that there is illegal activity going on.  They can't do it as a fishing expedition.  So there you go.  I think HushMail is probably the best choice in all of that.



STEVE:  Yeah, great idea.



LEO:  But it's web-based, and he wanted - but he did want web-based. Steve, we're out of time.  But you know what, it's perfect.  In 30 seconds we'll begin This Week in Google.



STEVE:  Yay.



LEO:  You couldn't have done it better.



STEVE:  Nice podcast.  Lots of coverage of all kinds of interesting things.  So I think we did a good one.  I have no idea what's in store for next week, but I can promise something interesting.



LEO:  That's good.  Tune in every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC.  You can watch us live.  But if you miss it, we have audio and video available.  Video available from us exclusively at TWiT.tv.  Audio we have a variety of formats, but Steve's the one with the low-bandwidth one, the 16Kb version.  And you can get that directly from GRC.com.  That's where SpinRite lives, all his free stuff.



STEVE:  And I have even lower bandwidth versions in print.



LEO:  Yes.  You don't get to hear our voice, but you can see every single word we speak, thanks to Steve and Elaine, at GRC.com.  If you want to ask a question, GRC.com/feedback is the place.  And if you want SpinRite, the world's best hard drive maintenance utility, absolutely GRC is the place to go and get that.  Steve, thanks so much.  We'll see you next week



STEVE:  Thanks, Leo.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#347

DATE:		April 4, 2012

TITLE:		iOS Password Mis-Managers

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-347.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's news, Steve and Leo examine the inner workings of the most popular password managers for Apple's iOS devices to determine whether and to what degree they offer enhanced security for safe password storage.



SHOW TEASE:  Steve Gibson's here.  It's time for Security Now!, and he's got a great topic for anybody who uses an iPhone or an iPad.  Believe it or not, the password managers you're paying for may not be doing the job.  We'll talk about how to keep your iOS device secure, and all of the security news as well, including that big credit card breach, next on Security Now!.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 347, recorded April 4th, 2012:  iOS Password Mis-Managers.



It's time for Security Now!, the show that protects you, your loved ones, and everyone you might know against bad stuff on the Internet.  And the guy who does it is here, the Explainer in Chief.  What was the other phrase I came up with, Steve?



[Per SN-346, Steve is the Debunker in Chief.]



STEVE GIBSON:  No, that's the one, Explainer in Chief.  That's the one.



LEO:  Mr. Steve Gibson, of GRC.com, well-known, you know, I could - hacker, programmer, guy who creates the ultimate, SpinRite is the ultimate hard drive utility, I mean, just on and on and on.  He's really a great guy to know as a good friend, but also a real expert in these things.  And what I love about Steve is he's the Explainer in Chief.  He'll take something and make it accessible to us all.  Steve, good to see you again.



STEVE:  Great to be back.  Episode 347.  And I think all of our iOS Apple device listeners are going to be extra interested because we certainly have a profile of an audience that's interested in security.  A well-known forensics company, ElcomSoft, who sells cracking technology to law enforcement, have done an analysis of about 13 of the most popular password managers which are available.  There's tons of password managers for iOS devices, for iPhones and iPads.  And the question, of course, is what's going on inside these?  Do they actually provide some protection?  And the news is, uh, not so much.



LEO:  Uh-oh.



STEVE:  Not in every case, at least.  There are, I mean, it's almost comical what some of them do, some of the mistakes they make.  So rather than just using that broad a brush, we're going to, because we have the information, quickly poke into many of the most common password managers and look inside their technology.  We've laid down enough foundation to understand the terms, and we'll see how these things are being used and what protections - or non-protections - they provide.  So I gave the podcast the title "iOS Password Mis-Managers."



LEO:  Oh, boy.



STEVE:  Because some of it's a little frightening.  There'll be some people changing their password manager shortly after listening to this podcast, I think.



LEO:  Can I do a little coffee talk?



STEVE:  Oh, please.  Absolutely.



LEO:  So Steve and I have been going back and forth on various ways to make coffee.  And the latest discovery that I've been exploring is cold-brewed coffee.  Steve already has decided, after buying the, what was that thing that you bought, the Toddy, that you don't like - you liked a little bite in your coffee.  You like the acidity that hot-brewed coffee - and that's the main reason people do cold brew is the low acidity.  And it can be a little stronger because cold brew often you steep for 12 or more hours.  So I bought - this was kind of crazy.  This was kind of crazy.  I bought a $200 - you saw it, the tower, the Yama.



STEVE:  Yeah.



LEO:  And in fact I'll play a little video so you can see it at work.



STEVE:  Does it sit on the - like it sits on the countertop and is, like, several...



LEO:  Yeah.  It's two feet tall.



STEVE:  Two feet tall.



LEO:  And here it is.  Watch.  This is it.



CLIP:  Question:  How do you make eight cups of perfectly brewed acid-free coffee?  Answer:  The Yama.



LEO:  I'm being a little silly.  It is a tower.  It's furniture.



CLIP:  This is the first time I've used it.  We start with ice water, literally ice water, dripping, one drop per second...



LEO:  See how slow?



CLIP:  ...hits that filter to keep it from boring a hole in the...



LEO:  And there's a little round filter that's not really about filtering, but more about keeping it from a - distributing it through the grounds.



STEVE:  Right.



LEO:  And then the grounds slowly, through a ceramic filter, give up their liqueur into the decanter.  It took all night.  And highly disappointing.  Highly disappointing.  It is not only - it is no acidity, but it's also fairly weak.  And considering that it took me all night to make, you get eight cups.  And the idea of the Toddy is it's much stronger, so you can treat it as a concentrate.  This isn't a concentrate.  So that's basically two cups of coffee that took all night, and it's still weak.  So unless I'm doing it wrong - I might try some other techniques.  But I do like the Toddy.  I know you didn't like it because it wasn't acidic enough.  But I think I'm going to stick with the Toddy.



STEVE:  Yeah.  My reaction was that it just didn't taste like coffee.  I'm used to there being that bite.  And...



LEO:  That's why some people like it.  They like the bite.  Some people will like it if it doesn't have the bite.  And you know I like it both ways.  Today I had the most biting coffee you can make.  Oh, look at you.  Look at you sucking it down.  I had the most - which was that stovetop espresso machine that boils the water and then forces it through the grinds, and it's cooking it.  This thing is boiling and boiling and boiling.  So by the time you have it, it's like coffee syrup.  And that was good.  And very acidic.  So there you go.  But I would say to people, you don't need the Yama.  But the Toddy is only 30 bucks.  And if you're interested in cold brew, that actually did a good job, I thought.



STEVE:  Well, I would say, for anyone who is acid-sensitive, if it upsets their stomach - I have the stomach of a billy goat.  I just - I do.  I could eat anything.  Nothing affects me.  And so I don't have a problem with the coffee.  But it's a great solution for someone who wants a lower acid coffee.



LEO:  And I steeped my Toddy for 24 hours and as a result got a nice, rich brew.  And I didn't feel like I had to do eight ounces per cup of coffee.  I could just use a couple ounces, and it was delicious.



STEVE:  Yeah, and then you can control the strength by how much you dilute it down.



LEO:  Yeah.  So there is a story that I was very curious about.  We talked briefly on TWiT.  But I thought this is a story for Superman, aka Steve Gibson, and that's the Global Payments breach.



STEVE:  Yeah.  Now, there's a stage in credit processing, credit card processing, that I've been aware of for quite a while because I'm a direct user of a payment processor like this.  My eCommerce system at GRC connects to a backend payment processor that is nothing that any user ever sees.  It's not a retailer.  It's sort of like it's the inner works of how this all happens.  And there's maybe a dozen of them.  There are not that many of them in the United States, for example.  And they're sort of the central hub of the electronic funds transfer system.  They've got direct connections to Visa.  And so they're sort of the front end to the actual credit card issuers themselves, and they perform all these transactions.  So naturally they're a pot of gold for somebody who wants to perform bad acts to acquire credit card information.



Now, interestingly, our good friend Brian Krebs broke the story.  He picked up on it.  He was able to verify it.  He was tweeting gleefully last week about he had more site traffic for his blog than he had ever had in history.  And, like, the day afterwards - because these things are very peak-y in their response, there's always something else happening the day after - he tweeted, "Oh, only 190,000 views today."  Aw, sorry, Brian.  But, boy.  So he was on top of it.  He was in the center.  And quoting from his blog, which was the authoritative location for all this information, The Wall Street Journal picked up on it, the Gartner Group picked up on it, I mean, it was, as you said, it was a big story.



He said, "It's not clear how many cards were breached...."  I should mention that the reports were upwards of hundreds of thousands potentially had escaped.  So Brian said, "It's not clear how many cards were breached in the [credit] processor attack, but a sampling from one corner of the industry provides some perspective.  On Wednesday, PSCU - a provider of online financial services to credit unions - said it [had] alerted 482 credit unions that appear to have had cards impacted by the breach, and that a total of 56,455 member Visa and MasterCard accounts were compromised.  PSCU said fraudulent activity had been detected on a relatively small number of those 56,000+ cards - [specifically] 876 accounts - and that the activity was geographically dispersed."



So it makes sense, first of all, that bad guys who acquire this information - and this is everything required to process.  This is user's name, address, ZIP code, the CVV2 code, you know, the CSV, it's known by various names, the little three- or four-digit code on the back, all of that had to be provided to - and, like, street address and ZIP code, which are things that are matched.  All of that was provided to the credit processor.  And now we know that they are archiving that.  They're storing it statically.  And that escaped.  So naturally this is very time-sensitive.  These cards are being shut down.  They're being replaced.  There's certainly a lot of scurrying going on, which means that there's a rapidly closing window of opportunity for exploitation of the stolen data.  The good news is that this Global Payments company reacted responsibly.  Although we did hear that this was early in March.  So it's been four weeks.



LEO:  Now, I'm looking at the press release from Global Payments.  They're saying as many as a million and a half cards were "exported."



STEVE:  I did see that at one point.



LEO:  And Visa has dropped support for them.  It may be one of those things where it's maybe worse than we thought.  By the way, their stock price dropped four bucks, 10 percent.



STEVE:  Yeah, was it, I think, about 9 or 10 percent.



LEO:  Yeah.  I'm surprised it was that little.



STEVE:  Yeah.  So we, from this position of scrutinizing security, have seen things like this often, I mean, that's what the podcast is about is how this happens and why and what we could do to prevent it, both on an individual, personal level and on a major provider level like this.  I expect we'll have more news trickling out over time.  I imagine Brian will be staying on top of it, and I'll keep an eye on his blog to see if he mentions more.  Was this their fault?  Was this an employee mistake?  Was this miscommunication of their stuff?



I mean, that is a big breach.  For a million and a half cards to escape is, I mean, like all the information required to process that number of cards, that's big and bad.  My sense is it can happen to anyone, unfortunately.  It should happen to no one.  But we do see it happening.  So I wonder if this will be a permanent - if this is a suspension, or if Visa is saying no more.  I mean, certainly this hurts them because they've got to go out and replace all those cards.  And, boy, clean up any fraudulent activity across a huge swath of cards.



LEO:  Yeah, it's ugly.  Visa says we're done.



STEVE:  Wow.



LEO:  So but from the point of view of a user, even if your credit card's breached, the law says that you don't owe anything; right?  I mean, the credit card - you're not liable for fraudulent charges on your account.



STEVE:  And in Visa's own statements about this, because they were out there rapidly trying to calm people down and not cause anyone to have any worry, they reiterated exactly that, that the users of credit cards are completely indemnified against fraudulent use of their card.  I mean, I've had many fewer problems in the last few years.  But it used to be that when I would be flying up to Northern California to visit my family for the holidays, I'd contact my travel agent, and she'd say, "Steve, did your card get compromised again this year?"  And, you know, because she'd...



LEO:  Again this year?  Again?



STEVE:  And I'd say, "No, believe it or not, Judy, I've still got the same card.  It's a miracle."  Because, I mean, it used to be happening.  This is before I was able to funnel so much through PayPal, and that's been a real boon, or through Google's shopping service.  I work hard not to give the card away, the card number, not to disclose it, if possible.  But again, it's the case that not everyone is being careful with it.  But as you said, Leo, in no case have I ever had any problem just having those charges reversed.  Which of course is the argument that the credit card companies make for charging such high interest.  And they say, well, you know, we have to stay profitable, and we're indemnifying everybody, so...



LEO:  Yeah, and that's the point.  You may not feel like you lose any money.  But in fact we're all paying for it.



STEVE:  It's dribbling out every month you have balances.



LEO:  But I have to say, all the card companies are much more proactive about calling about fraudulent charges.  I've talked about this on TWiT.  I had an order with Shoes.com.  It was my first order.  I used a credit card and had it shipped to a different address than the billing address.  And Shoes.com called me.  And when they couldn't reach me, they cancelled the order.  And I think that more and more that's what you're going to see.  Shoes, because I ordered athletic shoes, those are apparently a red flag.  Dvorak says that you can get any credit card canceled by doing this:  In the same day, filling up two different tanks with gas and buying athletic shoes.  They will cancel your card.  He says they'll just cancel your card because that's such a pattern for somebody who has a stolen credit card.  He's going to fill himself up, and his friends, and then go out and buy some sneakers.  And they just - I don't know if that's true, but it's a great story.



STEVE:  Actually, I think that's very clever.  The multiple fill-ups with a single card.



LEO:  Right, that doesn't sound right, does it, yeah.



STEVE:  That's clever.  Well, I had one card, my main card, actually, I cannot buy gas with it.  Every time I did, then I'd be in a restaurant, and they'd say, I'm sorry, sir, your card is not - it's like, what?  And then I'd call them, and they'd go, well, you used it at a gas pump.  And I finally, after several times this happened, I said, look, can you just turn that part off of my fraud protection?  She said, no, sir, we're unable to do that.  And she explained that the advantage to a bad guy is that they're next to their car if they need to make a getaway.



LEO:  They can run.  They can run.



STEVE:  Yes.  And they're at an automated terminal where all it can do is say yay or nay.  And so it's a way for them to test the card to see if it still works.



LEO:  Wow.



STEVE:  Although increasingly, I mean, now I have to put my ZIP code in every time that I use the card.  And so they would have to have that to go along with it.



LEO:  We're seeing more - and that's exactly why.  We're seeing more and more fraud protection techniques.  And it shows you it's not that hard to do.



STEVE:  But two fill-ups, that's brilliant because who's going to do that?



LEO:  That's unusual; right?  Yeah.



STEVE:  Yeah.  So another piece of news just hit.  Ars Technica reported something that I kind of thought everyone assumed.  But I got so many tweets about it that I thought, well, maybe not.  And that is that Apple holds the master key to the iCloud.  And a careful reading of the iCloud Terms & Conditions says things like Apple can "pre-screen, move, refuse, modify and/or remove Content at any time" if the content is deemed "objectionable" or otherwise in violation of terms of service.  Furthermore, Apple can "access, use, preserve and/or disclose your Account information and Content to law enforcement authorities" whenever required or permitted by law.  Apple further says that it will review content reportedly in violation of copyright under our favorite DMCA.



LEO:  Violation of copyright?  Now, see, I could see on court order, a subpoena.  On violation of copyright?  Oh, that pisses me off.



STEVE:  Well, so, yeah.  The takeaway from this is that, if you use iCloud, it's super convenient, it's all synchronized in the cloud and all that.  But it's encrypted in transit, and then it's encrypted by Apple when it's at rest.  When your data is at rest, it's under Apple's encryption, not yours.  So they can poke in there, peek in there, do whatever they want to, whenever.



I want to talk about, and I'm going to, I think, tentatively in two weeks, if nothing else comes up, about an interesting sort of very security-conscious cloud-based service whose name escapes me at the moment.  I wrote it down, and it's been on my radar for a couple months, and I've been meaning to get to it.  And I thought, since this would make so much news, with people being upset by this idea, it's like, well, let's take a look because we've often talked about pre-Internet encryption.  If you encrypt something, a blob, then iCloud syncs it, well, that's fine because all they ever get is a blob of pseudorandom noise.  They have no visibility into it.  But if it's just being done by your devices, it's safe in transit, but then it's under Apple's lock and key once it's there.  So...



LEO:  No privacy.



STEVE:  Yeah.  I didn't assume anyone would think otherwise, but I thought it was worth pointing out that this is - you get the convenience, but you're not doing device-level encryption for - I don't know if some of the services they're offering might require them to have visibility; but in any event, they do.  And that's sort of part of what you get, I think, from using a big bulk public service like Apple.



LEO:  Well, and that's something I talk about with Carbonite, who's one of our sponsors, is that - in fact, I remember having a conversation with the CEO of Carbonite.  He says, "We get subpoenas all the time.  We just say, sorry, can't help you," because they do pre-Internet encryption.  They support encryption, and you keep the key.



STEVE:  Right.  And, of course, famously, Dropbox wasn't doing that.



LEO:  And Dropbox still doesn't.



STEVE:  Yup.



LEO:  And, I mean, yeah.  There you go.  It's one thing to say, look, we'll comply with a court order from law enforcement.  It's another thing entirely to say, oh, and by the way, if the record industry asks, we'll hand you over.



STEVE:  That's right.



LEO:  To me, that's another thing entirely.



STEVE:  So we were right in our pretty much tossing off without much thought that claim that we discussed last week about this XRY's company video.  Remember they showed a video which claimed to allow them to hack a password-protected or passcode-protected iPhone instantly, in a matter of seconds.  And we both talked about how - and it showed them holding the button down while they powered it on, and we realized that was about the phone being a RAM disk, and that Apple had fixed that some number of versions ago.  And there has since been a bunch of public debunking of that video, which they have removed from YouTube.



LEO:  Oh, man.



STEVE:  They've taken the video down.  Now, people that have looked at it closely confirmed what we believed.  But we'll be coming back to this later in the podcast.  But it's worth talking about what can be done and what cannot be done.  What has happened is that, as we mentioned, the iOS security and the device, the physical device security has been improved dramatically over time.  And as I've had to look at what iOS is doing and the devices are doing much more carefully for this podcast, I have to say I'm impressed with what Apple has done, that is, the very first iPhone offered just UI protection.  There was no encryption of the device.  It was just - the passcode you put in sort of just kept you from getting past the locked screen.  But there was nothing else going on.  And the forensic companies were having a field day with that because naturally a phone is a wealth of information for law enforcement.  They would love to have access to everything in someone's phone.



And so as the iPhone has become increasingly popular, as we've moved from v1 to 2 to 3 to 4, now we're at 5.0.1, I think is the latest, Apple has really taken measures to increase the strength.  There are, for example, they have added full file system encryption, although there are a couple little catches.  For example, if you never - if you are on iOS 3, and you never wiped the device and then reinstalled under iOS 4 or 5, if you simply updated iOS itself to 4 or 5, then you still don't have an encrypted file system, which some people may not be aware of.  It turns out that the encrypted file system is super important.  I mean, really it's what everyone should have and want because it's zero hassle, Apple manages it beautifully, and it really does protect users.



LEO:  I feel like I take a performance - you're talking about FileVault, their built-in FileVault.  Yes?



STEVE:  Yes.



LEO:  I feel like I take a performance hit with that.



STEVE:  Well, now, not FileVault, but the actual, I mean, the entire device.



LEO:  Oh, I see, okay.



STEVE:  Yeah, the whole...



LEO:  That kind of like Intel's TPM thing, where it's just built in.  Then it's done by the CPU automatically, using its own...



STEVE:  Yeah, there is hardware crypto now in the latest devices.  And the forensics companies are not happy.  The iPhone 4S and iPad 2, it's really been locked down.



LEO:  So it's automatic.  There's nothing I - it's not like Vault - okay.  I understand.  FileVault's on the desktop.



STEVE:  Correct.



LEO:  This is automatic on the iOS stuff.  There's nothing you can do about it.



STEVE:  Yup, exactly.



LEO:  I got it.  I got it.



STEVE:  Yeah.  And so, for example, one of the things that they're doing, we'll be talking about key strengthening because there's two places that users will get security.  And this is really where this XRY company was misleading people because, even if you have access to the device, what Apple has done is they've used very good key strengthening, or key stretching.  The acronym is a tongue twister.  It's PBKDF2, which stands for Password Based Key Derivation Function v2.  And I've seen people say, well, you can remember that by Peanut Butter Keeps Dogs Friendly, Too.  It's the same acronym.



So what they do is - and we've talked about this PBKDF2 before because, for example, WPA, the WPA2 encryption, the good, strong encryption, what it does is it takes the user's passphrase and the SSID and essentially hashes it with some salt 4096 times.  It does it 4096 times, essentially in a loop, taking the output from the first one, putting it into the second one, hashing that, putting that into the third one, hashing that, into the fourth one, hashing that, and so forth.  Because it just makes it computationally infeasible, I mean, it's like it slows down any guessing that you do by the factor of how long it takes to perform that operation.



So Apple does this 10,000 times on their iOS devices.  So even if you have some access to the phone, talking about this XRY video, for example, even if they had access to the phone, because of the fact that anything you put in has to run through 10,000 of these complex hashing functions, in order to get the key which you can then test to see if it will decrypt the phone, the best you can do - oh, and it has to be done on the phone.  This is not an offline attack.  So the phone itself, because it also uses some non-public key as part of this password strengthening, the phone itself has to do it.  So you can't use GPUs or anything else.  You have to do it on the particular device that you're trying to crack because the point is, if you put the same - say you just did a four-digit passcode.  You put the same four-digit passcode into a different phone, it comes out of this strengthening function with a completely different 256-bit key.



So because every phone is different because every phone has its own secret keys that it never publishes, I mean, I'm very impressed with the technology that Apple has.  They've done a good job.  The point is it takes about a quarter second, I mean, you could only do four four-digit passcodes per second.  Now, that's not super strong security because it means, if you just do the math, that it takes about 42 minutes to try 0000 to 9999.  So one of our takeaways from this analysis today is you really do want to use, if you're relying on this Apple security, you want to use a stronger passcode because 42 minutes is not very long to crack...



LEO:  Ah, but remember that you also have this feature that, if they try 10 times and fail, it erases everything.



STEVE:  No.  This is, well, I mean, yes, if you use the UI.



LEO:  Oh.



STEVE:  Not if you're attached to the phone forensics.



LEO:  Oh.  So it's not paying attention to the count forensic.



STEVE:  Correct.



LEO:  Oh, interesting, oh.



STEVE:  Correct.  But, so that's one takeaway.  So we'll come back to this a little bit later because what we're going to see is that many of these password managers provide virtually no additional protection.



LEO:  So you really want the OS protection to be tiptop.



STEVE:  Yes.  And when you talk about backup encryption also because docking our devices to our machines, it turns out that using a really strong backup password is equally important because that's another place where the entire phone set of data is sitting and is available for forensics.  And law enforcement might often have a good reason for getting it from bad guys.  But we want to control that ourselves.



I got a great tweet this morning from Andrew Mason, who's in London, tweeted from @amason, who told me about a site I hadn't seen, AreWeSlimYet.com.  And this is not about body weight.



LEO:  Okay, because I know the answer.  I don't really have to check a website for that.



STEVE:  Yeah, Leo, you stand on your keyboard and - no.  So AreWeSlimYet.com is Mozilla's self-monitoring of Firefox's memory consumption.



LEO:  Oh, how clever.



STEVE:  Over time.



LEO:  How clever.  Now, you have to be using Firefox.  Do you have to go to that site in Firefox?



STEVE:  I don't think so.  I did because I'm still very happy...



LEO:  I'm on Safari here, and I'm getting information, so...



STEVE:  Yeah, I don't think you need to use Firefox.  You have to have scripting because they're very script - it's like a whole bunch of - you can, like, zoom in on these charts and things by moving your mouse around and then clicking.  But here is this AreWeSlimYet.com shows over the history of Firefox versions how they're using memory and graphically demonstrates their determination to just fight that down.  And I love the tabs on the side, and my tools I have in Firefox.  Now that I'm at 11, and they really did solve the memory bloat problem, where sometimes I'd wake the machine up after it was on overnight, and it used up all my 3GB.  It's like, okay.



LEO:  Now, is this information from my machine or their own stuff?



STEVE:  This is their own forensics over time.



LEO:  Got it, got it.



STEVE:  So it's sort of static, just sort of...



LEO:  It's not my number, yeah.



STEVE:  Right, right.



LEO:  I get it.  I was saying, how do they know?  How do they know?  All right.  So they're getting slimmer, aren't they.



STEVE:  Yeah, they're doing it.  I'm impressed.



LEO:  Especially with tabs closed.



STEVE:  And now that we're not sure how much we love Google, I thought, well, that's good.  I'm happy I've got Firefox.  On April 1st, and I was conscious of the fact that it was April 1st, was the news that Ashton Kutcher - Kutcher?



LEO:  Kutcher.  Now I don't know.  I want to say Kutcher.  Kutcher.  Oh, forget it.  Who cares?  Who cares?



STEVE:  Anyway, well, we might care.  He's been chosen to play Steve Jobs.



LEO:  Yeah, but just in some indie flick.



STEVE:  Well, I know, but...



LEO:  There's a big biopic from Sony coming up.  Actually, this is better news than you think.



STEVE:  Okay.



LEO:  So he's been picked because he has a stringy beard and stringy hair, and he looks like a young Steve Jobs.



STEVE:  He actually does.  I had never really...



LEO:  Yeah, but anybody with a stringy beard and stringy hair would look that way.



STEVE:  Okay.



LEO:  And it's in an indie pic, which means he won't be able to play in the really big one based on the Isaacson biography when Sony does that.  Thank god.



STEVE:  Ahh.



LEO:  I'm not an Ashton Kutcher fan, as you might determine.



STEVE:  I think you just pronounced his name correctly.



LEO:  I think I did.  As soon as I was angry about it.  Are you excited that he's going to play it?  I mean, he does look like - he does look the part.  And he's a good actor.



STEVE:  Yeah.



LEO:  It's not that he's not a good actor.



STEVE:  Yeah.



LEO:  Yeah.  But...



STEVE:  I have no bias one way or the other.  I don't like him or dislike him.  I'm maybe a little jealous of him, but...



LEO:  I'm very jealous of him.  You know he's not dating Demi Moore anymore, though, so that's...



STEVE:  Oh, okay.  Well...



LEO:  So you don't have to be jealous about that.



STEVE:  He seems to be a good guy.  He and Bruce and Demi were all getting along.  Sort of strange.



LEO:  So the interesting thing, I don't know how we got in this Hollywood gossip thing, but the interesting thing, I talked - we did an interview with Dana Brunetti, who's an old friend.  He's a Hollywood producer.  He produced "The Social Network."  And they tried - Trigger Street, his production company with Kevin Spacey, they tried very hard to get the Walter Isaacson biography, but lost out to Sony.  But he in the process was spending a lot of time thinking about, well, who do you get to play Jobs?  And the real problem is the age range because Kutcher can play the young Jobs, but he can't play the older Jobs.



STEVE:  Good point.  Right.



LEO:  So it's actually a very tricky casting decision.  I'm sure that this pic will be mostly about the young Steve Jobs, the hip Steve Jobs.  Well, he was always hip.



STEVE:  You think so? Because, I mean, he was - it was the later Steve Jobs that changed the world.  I mean...



LEO:  Right.  Kutcher is - comparing him to a 23-year-old Steve Jobs.



STEVE:  Yeah.



LEO:  So how do you - somebody was suggesting Tom Cruise.  I don't know if that's a good pick, either, but...



STEVE:  Oh, please, no.



LEO:  Fortunately, it's not our decision.



STEVE:  Well, it'll be fun that we're going to get some movies.



LEO:  Oh, yeah, we're going to get lots of movies.  Are you kidding?  Absolutely.



STEVE:  Yeah, that's neat.



LEO:  Yeah.



STEVE:  So I did poke just briefly, to talk about health, I poked a little bit into this Dave Aguss, whose book "The End of Illness" you mentioned last week.



LEO:  Yeah, what did you think?



STEVE:  Well, I was a little put off because I went to his website, and he has a video on there where he's talking about how supplements are harmful.  And he quoted, he said, he quoted a very bad Vitamin E study.



LEO:  Oh, dear.



STEVE:  Well, first of all, yeah, anyone who just says "Vitamin E," immediately I'm worried because there isn't anything called Vitamin E.  There's eight Vitamin Es.  There's alpha, beta, gamma, and delta tocopherol, and alpha, beta, gamma, delta tocotrienol.  There's a family of eight.  And unfortunately, because early nutrition scientists saw that alpha tocopherol seemed to be what there was most of, that's what all the supplements have.



LEO:  Right.



STEVE:  And that's what you'll see if you look at your bottle on a multivitamin is alpha tocopherol.  Well, what was found was that in people taking huge amounts of alpha tocopherol, there seemed to be a correlation with an increase in prostate cancer.  Thus, unfortunately, David says "Supplements are harmful."  Now - and Vitamin E causes prostate cancer.  The fact is, ill-advised, uninformed use, over-consumption of one of the eight Vitamin Es does.  Gamma tocopherol turns out to be the one that we need.  And because the molecules are so similar, if you overload on alpha, it competes with the other tocopherols and tocotrienols and keeps them from having the effect that they should.  So what you want is a Vitamin E which is full spectrum, that contains all eight of the different types in the same ratio that they occur in nature.  And that's the E that I take and have been taking.  And if you do that, then you're fine.



And then of course the other problem is, arguably, almost everyone needs to supplement their Vitamin D.  It's been our own purely anecdotal experience with the podcast I did where I got flooded with people after the holiday season saying, hey, this is the first season I never got sick, probably thanks to Vitamin D.  I mean, and since then, it's been several years since we did that, there's just constant reports about the benefits of Vitamin D supplementation.  So anyway, the guy seemed like a little bit of a populist and like...



LEO:  Read the book because I think that what you see on the website is a summary.  He may not say don't take multivitamins.  He has some interesting - I think the larger story is still accurate, which is that we don't treat people as systems.  Because we've had such success using antibiotics to target a particular illness or antivirals to target a particular illness, we have changed our model of medicine from thinking of it as a systemic model to you've got an invader, aim a weapon at them.  And, now, he's an oncologist, a cancer doctor, and he says that that doesn't work because cancer is a systemic issue, and that many of the illnesses we see come from systemic issues, and that we've kind of gotten away from that in medicine because we've had such success with the magic bullets.



STEVE:  Yeah, I think that's true.



LEO:  And I think that's probably what he means when he's talking about supplements, that you can't treat them as a magic bullet.  You have to think systemically.  One of the things he does recommend is getting blood work on a regular basis, looking - he says everybody's individual.  You need to look at what these things are doing.  And so I think in that regard he probably does say supplement your Vitamin D if you need Vitamin D.  I think what he's against is just kind of take vitamins because it's good for you attitude.



STEVE:  Right.  So I do, however, have a book recommendation.



LEO:  Oh, good.



STEVE:  I'm at the end of this book.  I am so impressed by this book.  It's funny, too, because as I was reading it - and this is the one I've mentioned a couple times that was about nutritional anthropology, essentially - I was thinking, wow, I hate the title of this book because it's just not serious enough.  And I was telling people, in fact I may have mentioned it to you on the podcast, that I would imagine that, when this book was first written, the author, whose name is Geoff Bond - actually his middle name is James, so Geoff James Bond.  He is from the U.K., but it's  G-e-o-f-f Bond.  I could imagine that, when he submitted his galleys to the publisher, it was probably titled "Nutritional Anthropology" or "Applied Practical Nutritional Anthropology" or something, and the publisher said, uh-huh, yeah, well, we'll never sell it if that's what we call it.  What's funny is that this is his second book.  And I did find his first book, which is titled "Natural Eating," and then the subtitle is "Nutritional Anthropology:  Eating in Harmony with Our Genetic Programming."



LEO:  Oh, see, this is the new thing everybody's talking about.



STEVE:  Well, and frankly, I'm now self-conscious about ever having mentioned Gary Taubes because I ran across a quote from him about what he eats, and it's like, oh, boy, that's nothing that I'm able to endorse from all the research I've done.  Anyway, the book is unfortunately titled "Deadly Harvest."



LEO:  Oh, dear.



STEVE:  Which is, I know, which is meant to sell copies.



LEO:  Absolutely, yeah.



STEVE:  But it is a serious piece of work.  He and his wife have lived among aboriginal tribes and eaten what they eat.  It is massively referenced and researched.  The last third of the book is the references to everything he refers to through the book.  For people who haven't studied, as I have, things like evolutionary psychology, there's a whole chunk about, like, pressures that, like more than just eating, like societal and familial relationships and interpersonal relationships and how our past formed who we are today.  Anyway, it's been a fantastic read.  I recommend it without reservation for anyone who is curious about sort of where I've gone with my reading:  "Deadly Harvest" by Geoff Bond.



LEO:  I've ordered it, yeah.



STEVE:  It was all good.



LEO:  And I've been reading a similar book called "The New Evolution Diet" by this guy, Arthur De Vany, who's an economist, but similar nutritional anthropology.  I presume that all of this stuff is around the same idea, which is that we stopped evolving about 40,000 years ago, and we should eat as our - and exercise, in this case, he talks a lot about exercise - as our Paleolithic ancestors did.



STEVE:  Yeah, the way - I don't want to spend too much time on this.  But the way I would sum it up is that we evolved in a world of scarcity.  Meat was scarce.  It ran away, so it wasn't staying put for us to get it.  Sweet stuff was scarce.  Like the only real source of sweets was honey in African killer bee nests, and they tended to protect their honey, too.  And so we wanted things that were high calorie, but we couldn't get them.  They were scarce.  So we largely supported ourselves eating a lower calorie, which is to say plant-based and slow-moving animal, like crickets and locusts and slugs and snails and things, that was our diet.



Now, but we were built to want the higher calorie foods.  So what happened, of course, in summary, is we got very smart with agriculture and with industrialization and with farming.  And so today we have all this technology that lets us have anything we want.  And unfortunately we're still programmed as we once were to want high calorie things.  And now we can have all the meat we can imagine.  We can have all of the grain, which didn't exist back then, and all of the refined sugar.



"60 Minutes," as a matter of fact, did a piece that was really interesting just this last Sunday on raising the question, is sugar toxic?  And I'm convinced it is.  And what they weren't quite ready to go into yet is so is white bread, so is grain, because it converts immediately into sugar and has almost all of the same effects.  So those were things that we just weren't designed to handle.  Our bodies weren't designed to handle them.  And you look around at what's happening to us as a consequence.  So we're smart, and unfortunately we're able to now give ourselves anything we could imagine we want, and that's not necessarily good for us.  But something is good for us.



LEO:  Yes.



STEVE:  And that's SpinRite.



LEO:  Yes.  How did I know?



STEVE:  On March 30th I got a nice note from a Gregg Dille, I think that's how I pronounce his name, D-i-l-l-e.  The subject was "Process control site license/SpinRite."  And he said, "Steve, just wanted to let you know, I work at a major chemical plant refinery.  Check your recent purchases of four copies to match it up.  We bought a copy of SpinRite, one copy, a while back and had been using it quite successfully in our process control environment.  Shortly after purchase, I sent a note to our group stating that we should acquire a site license, but the powers that be did not take me seriously.  I've tried to advocate the use of SpinRite out here whenever I felt the situation warranted it, as we have some nodes that are really old, and there is no plan to replace them.  They're working, so why fix them?



"During this year's software license true-up" - which I thought was interesting, it must be like where they decided to get themselves current - "I brought it up again, and others have since realized the value of SpinRite.  So we just made the effort to purchase four copies so that we would have a site license.  Thanks for all you do.  Gregg."  And that's, you know, thank you, Gregg.  I really do appreciate that.



LEO:  Yay.



STEVE:  It's an honor system, but that's what keeps us going.



LEO:  All right.  Let's talk about iOS.  I use LastPass on iOS.  I hope that's still safe.



STEVE:  They've done a good job.  I did vet them extensively.  What seems to be the case is that I can't quite understand the thinking on the password manager developers' part of not making them as strong as they can.  It appears that in some cases they just don't care.  It's a free app, for example, many of them are free.  And they've just sort of said, well, some people are going to buy them.  People who don't know any better will buy them, and so it doesn't really matter.  It's like, okay.  I mean, certainly a takeaway, by the time I'm through enumerating the specifics, our listeners are going to know and understand clearly that it's not enough for the thing just to say, oh, you have to put a password in to get to your passwords, and we're going to protect them from you.  It's like, well, okay, we really do need to know the details.



Now, but this all starts from sort of the forensic attack angle, the idea being, of course, that somebody, presumably law enforcement, or a hacker who's got access to the same sorts of tools, is trying to get to your stuff.  This ElcomSoft is one of the leading suppliers of forensic tools.  On their page - it's ElcomSoft.com.  On their page they talk about, they say "Enhanced forensic access to iPhone/iPad/iPod devices running Apple iOS."  And then they say "Perform the complete forensic acquisition of user data stored in iPhone/iPad/iPod devices running any version of iOS.  ElcomSoft iOS Forensic Toolkit allows eligible customers acquiring bit-to-bit images of devices' file systems, extracting device secrets (passcodes, passwords, and encryption keys) and decrypting the file system image.  Access to most information is provided instantly."  And it goes on to enumerate features and benefits all in one complete solution; quick file system acquisition, 20 to 40 minutes for 32GB models; zero footprint operation leaves no traces or alterations; and so forth.  So this is something which is used to access the innards of these phones.



Now, they published a paper which explains sort of the background of the environment that they're trying to operate in.  And one of the things that they make very clear is that they look at iOS and BlackBerry.  There's no coverage here in their paper of Android devices.  I'll keep my eyes out for anything that gets published like that so we can talk about that when something exists.  But as I was mentioning it earlier, it is the case that Apple has gone to great lengths and, I think, very impressive lengths to provide security to their users.



Now, as we also mentioned in another context earlier, as soon as you synchronize with iCloud, that's out the window because Apple holds the encryption, and you don't.  But as long as you don't do that - we don't know for sure whether Apple holds the keys per phone.  Each iOS device - iPhone, iPad, iPod - has unique hardware encryption keys.  And those are used as part of the unlocking process to develop the - when you actually enter this little passcode to unlock your device, to us it seems like all it's doing is sliding the screen over.  It is in fact producing a very strong 256-bit symmetric cipher key.  And it is only that that allows the file system to be viewed.  The file system is stored, given that it is encrypted, as long as that's the case, as pseudorandom data.  It is completely unavailable unless you have that 256-bit key.  And the only way to get it is by running through this process.



Now, if you do it through the UI, as you mentioned, Leo, as long as you've got the wipe after 10 mistakes, you're probably safe.  If there is a way to get past that, if the phone, first of all, if the phone is jailbroken, all bets are off.  So you absolutely don't want to jailbreak any of these iOS devices because that breaks down the fundamental protections that keep people from getting in.  It may be the case that there are ways in, and that the forensics companies have a way in.  But even if they do, then they are prevented from trying any more than about four passcodes per second.  Them getting a way in bypasses that 10 mistakes file system wipe feature.  My advice would be always run with that.



The downside is, if a toddler grabbed your phone and was playing with it and made 10 mistakes, you'd wipe out your phone.  But then you've got your backup.  So hopefully you're docking with iTunes from time to time on a base-station computer, and it's kept synchronized.  Or you're using iCloud.  You're not that concerned about Apple's having access, so you're backed up very currently that way.  Certainly makes sense to turn that on.



But if there's a way to get to the device underneath this - in a jailbroken style, by somehow hacking to it, then anyone forensically analyzing it is still going to have to come up with this 256-bit key.  And Apple does a 10,000-round password strengthening which has to be done on the device, using the device's hardware, because it mixes in the device's individual hardware keys as part of that.  So that puts an absolute limit of about four tries per second when you have that kind of access.  So that says about an average of 20 minutes to guess a four-digit passcode.



Now, to me that says, if you really do want security, you can't settle for a four-digit passcode.  You need to go to the more complex, turn off the simple passcode, get yourself a full keyboard, and then do whatever you want.  This is really where there's a tradeoff between convenience and security because this is something you've got to be able to do every time you unblank your device or turn it on.  I mean, it's on all the time actually.  But go to use it, you need to say hi, it's me, and prove that's you.



But this is where something like Password Haystacks, the haystacks concept comes in because length here can really trump complexity.  Yes, you want, yes, I know, nothing's better than pure entropy.  But still, there's a tradeoff with what's easy and feasible to enter.  But the bad guy doesn't know anything about your strategy for having padded a password.  Use the haystacks approach.  So what you want is something long, but also something you won't go crazy having to type in all the time.



LEO:  Well, and that's kind of the issue on iOS.  It's one of the reasons people like those four digits is I'm doing this, on a phone anyway, with my thumb, and I want to do it quickly.



STEVE:  Yup.



LEO:  And so, yes, you can have a long password, but who wants to sit there every time you turn on the phone, type type type type type type type type.



STEVE:  Right.  So all I want to do here is explain what the tradeoff is, which is, if it's digits only, I mean, actually you can do the math.  You can go to GRC.com/haystack, and it'll do the math for you of using different alphabet complexities and different lengths.  And then you can figure that there will be four attempts per second.  Which, I mean, that is slow.  Apple's done a nice job of making it that slow because that's no stick it on a GPU and do a billion per second.  That's four per second, which is pretty slow.  And somebody has to have your phone for that length of time.  But if you just make it six digits and a bigger alphabet, then it goes quickly to years to crack it.  And I think there was, like, six digits with a full alphabet, I did some math, I think it was like 88 years.  It's like, okay, that's probably enough, on average, to crack something.  And six characters isn't that hard to type.  So that's where that tradeoff is.  But that's getting into the device.



Now, what it turns out is that, once in, many - well, first of all, some users might not be locking their phone at all, or their iPad.  They may just want to access it.  They figure, hey, there's nothing I'm storing here that I care about except my passwords.  And so the idea being that people want the convenience of turning the phone on and just having it right now, right now access.  But they go, hey, I've got a password manager that I have either free or purchased, because both types are available.  And that's where I'm going to put the responsibility for keeping the things that I really care about.  I'm going to lock them up under a password manager.  But otherwise, who cares about my contacts and my web browsing history and things?  I'm not doing anything on the phone that I don't mind if somebody looks at.



So the question is, how secure are the password managers?  Oh, I need to also mention the backup before I move on.  One access point that the forensics guys have is the physical phone.  The other is the backup.  Now, again, I was impressed when I learned that Apple encrypts the backup before it leaves the phone, using the phone's keys.  So the backup is not encrypted, I just assumed it was encrypted on the PC, the Mac or the PC, whatever you're synchronizing your phone to.  It's not the case.  It's encrypted by the phone, in the phone, and only the encrypted result is stored.  Except that the backup password complexity definitely matters because that can be attacked in an offline attack.  So again, Apple's done a good job of making it secure.



But if you use encrypted backups, and you absolutely definitely want to, I'll wrap this up with some bullet points of sort of a checklist of things Apple users, and to a lesser degree BlackBerry users, need to do.  They're pretty much the same.  But a really good - first of all, using backup encryption is important especially, as we'll see in a second, because the password managers, many of them are not providing much, if any protection.  And if you do encrypt your backup, you want to use a good strong complex password because there an offline attack is possible.



Okay.  So what are the password managers doing?  I've separated them into three categories:  brain dead, brain challenged, and useful.



LEO:  Oh, I'm getting a lot of people hoping they don't get in that first category.  Okay.



STEVE:  So under "brain dead," there's something that just - there's a free password manager called "Safe," Safe Password, and it's also known as Awesome Password Lite and also as Password Lock Lite.  And in this case, heavy on the "lite."  Nothing is encrypted.  All user data is stored in plaintext.



LEO:  For crying out loud.



STEVE:  The master password is limited to four digits, and it's stored in plaintext.  So password recovery, such as it is, is instantaneous.  Not that it matters much because everything's in the clear anyway.  Just couldn't be more ridiculous.  So nothing safe about Safe Password.



iSecure Lite Password Manager, also no encryption.  All user data stored in plaintext.  The master password in plaintext.  So that means, to be clear about what that means - or I'll finish one more.  Ultimate Password Manager, their free version.  No encryption.  This is the Ultimate Password Manager, Leo.  No encryption.  All user data stored in plaintext.  Master password stored in plaintext.  Okay.



So what those are doing is nothing.  You go to the app, and it says, "What's your password?"  You type it in, and it sees that it matches the plaintext copy that it has stored; and, if so, it lowers the drawbridge.  It lets you look at your passwords and data that you've stored in there, which are also stored all in plaintext.  So if somebody had access, got access to your phone and could get past its lock code, or if your phone is not locked, if you don't use that, then anybody can read out all your passwords if you're using any of those first three brain dead ones.  Or, if you're not encrypting your backup, and someone has access to your PC where you have backed up your machine, same story.  There's all your passwords just laying out there.  You'd print the file, and there would be all of your data from these password managers.



Now, there's also, under the brain dead category, the last one is Secret Folder Lite, which is the same author as Password Lock Lite, which I mentioned.  That was the first one I talked about, heavy on the "lite."  And it's just as lite.  It protects folders, the photo and video files, but the passwords are all in plaintext, and they can be instantly recovered.  So none of those offer any protection.



Now, stepping up a little bit, we come to the "brain challenged" two.  There's something called Keeper Password and Data Vault.  Now, this one uses encryption, AES-128.  Most of the things we'll talk about from here on out use encryption, and most of them use AES-128, sometimes 256.  We know that 128 is just fine for today.  It encrypts in CBC mode, Cipher Block Chaining, which is one of the standard modes for using AES encryption, so that's good.  The encryption key uses the first 16 bytes, which is 128 bits, of the SHA-1 hash of the master password.  So that's  pretty good.  You put in any length password you want.  It hashes that to 128.  It does it as an SHA-1.  Then it uses the first 128 bits of that as the key for the AES encryption.



But the master password is verified by comparing an MD5 hash of what you enter with the MD5 hash of the password when you set it.  So when you're setting this up, it says give us your master password, and you enter it.  And it says, oh, verify that.  And so you put it in a second time.  And it's like, oh, very good.  You put it in twice correctly, so we believe you're going to be able to do it in the future.  It then makes an MD5 hash of that, and that's what it stores.  So the crypto is good, but it stored an MD5 hash, without any salt, of your password.  Which means any rainbow table with MD5, which is one of the older hashes that has been rainbowed to death, can be used to look up your password.  So not so good.



All they had to do was salt it, just add some salt to the hash, and then rainbow tables wouldn't be - precomputed rainbow tables couldn't be used.  But they didn't do that.  So you just - so anyone who has access to the raw data would take the MD5 hash of your password, look it up in an online rainbow table, which would give them the password.  And then they put that in, which it then SHA-1 hashes to get the decryption key, and they can decrypt your data.  So it's better than nothing.  But they could have easily made it a little stronger.  And, I mean, any listener to this podcast knows 25 ways that these things could be made stronger.  But the authors of these programs apparently don't or didn't care.



Now, that one is free.  Everything we've talked about so far is free.  Also under brain challenged is, for $9.99, something you pay $10 for and think, oh, well, if it's 10 bucks it must be better, this one is called SplashID Safe, SplashID Safe for iPhone.  Now, this uses Blowfish rather than AES.  And it's one of several, only a few, that do use Blowfish.  Blowfish is interesting.  It was designed by our friend Bruce Schneier back in 1993.  So it's been around a long time, and it has withstood all attack.



The problem with Blowfish is that it uses, because it's so old, it uses a smaller block size.  It's a 64-bit symmetric cipher, meaning you put in 64 bits at a time and get out a different 64 bits.  That's significant because there aren't - there are, what, we know that there are four billion combinations of 32 bits.  That means there's 16 billion billion combinations of 64.  Once upon a time, back in '93 when Bruce did that, that was enough.  But that was - that's a long time ago in terms of computing power explosion.  So 64-bit block ciphers are really no longer considered secure enough for industrial work.



But what is significant about this is that it uses a highly complex key setup, which is to say, remember the way these ciphers work is there's something called a "key schedule" is the technical term, the idea being you take the key, and you do a bunch of stuff to it to create some raw data based on the key, which is then used, for example, by successive rounds of the key.  This is the way AES, for example, works, where it's like an 11-round process for, I think it's AES-128 uses 11 rounds.  Each of those 11 rounds uses different data from the key setup.



Well, normally a cipher wants a fast key setup, that is, it doesn't want much overhead associated with getting going.  Blowfish has a particularly onerous key setup that involves preprocessing of a block of about 4K.  So it's very slow to set up the key.  But that's a good thing when you're wanting to prevent guessing because any brute forcing is by its nature requiring you to try this key, which means you've got to go through all this, in this case with Blowfish, a lot of work to get this thing set up.



So all of this sounds really good.  In fact, I should mention that OpenBSD uses for some of its security Blowfish on purpose because it's so complex.  It's just burdensome to guess what the key is.  So all of this good stuff was used by SplashID Safe for iPhone for $10.  After they did all this, the master password is encrypted under Blowfish - you're giggling, Leo.



LEO:  I can just tell something bad's coming.



STEVE:  Something bad's coming.  Master password is encrypted under Blowfish using a fixed key.  Which is - I'll spare everyone saying upper and lower case.  So it's "g.;59?^/0n1X*{OQIRwy."  Now, clearly someone went to some serious trouble coming up with that.



LEO:  Nice random password.  But it's the same.



STEVE:  And it's always the same.



LEO:  On every - I can't believe it.



STEVE:  It's built - I know, I know.  It's built into the software.  That's the magic key.  So when someone sees that you're using SplashID Safe, for which you paid $10, and they have access to your raw data, they go, oh.  And they simply use Blowfish to decrypt the stored encrypted key using that secret magic phrase.  Then that gives them your actual Blowfish key, which allows them to decrypt all your data.  So it doesn't matter how long it takes Blowfish to get going and set up its key schedule because they only have to do it once because they can decrypt your key using the secret passphrase built into the application.  Not so good.



So now, under "useful security," the good news is the bulk of the password managers are there, under this category.  But unfortunately there are still some problems.  A free version called Password Safe - and it says "iPassSafe free version."  It uses AES-256, so nice big key.  And it uses encryption in CBC, Cipher Block Chaining.  The master key is randomly generated.  So it pseudorandomly generates a master key, then encrypts that using the user's password, the user's master password, and that's what it stores.  So that's nice.  But the master password is not hashed.  It is directly encrypted.  It's padded out to 32 bytes because we have AES-256, so that's 32 bytes used for the key.  But most users are not going to use a 32-character key.  They're going to use whatever, whatever they think is enough.  Who knows?  Say they used 10 characters, which is probably more than usual.  Well, that means that we actually need - we need 32, and the user gave us 10.  So it would be nice if they hashed it.  Then they'd come up with, instantly, 256 bits of garbage-looking stuff, like the output of a hash is just going to be debris, but it's going to be based on what you gave it.  No, these people just use it directly.  They pad it out with nothing, essentially zeroes, to the full 32 bytes.  And that's what they encrypt.



So the problem is, although you would have to be doing AES-256 decryptions, the idea would be you would guess the password with AES-256 and decrypt it.  The instant you see that the end is all zeroes, you know you guessed right.  So it gives you, you know, it's nice encryption.  It does require you to use AES-256.  You can, however, do this in an offline attack.  So if you got a hold of the data, you'd take this somewhere with GPUs that are set up for fast AES decryption.  And you can do this in parallel.  You start pounding on it.  And the instant you decrypt such that the whole end, the tail of this is all zeroes, you can be very sure that you've got a candidate, at least.  So it makes it very quick to crack this under testing, under brute force, if you wanted to.  Still, I mean, it's not bad, and it's free.  So it certainly beats the pants off any of the other free things that we've looked at so far.



There's My Eyes Only Secure Password Manager, stores the master password, the answer to the secret password recovery question, and it uses RSA.  And it's unique in that.  It's the only one that we looked at that uses both asymmetric encryption, uses RSA public and private keys, and it stores all those in the iOS keychain.  So iOS manages some of the data for this password manager, which provides some good security.  iOS keychain has different attributes that you can store things under.  This is stored under the attribute of "accessible when unlocked."  So when you unlock your phone using the normal procedure, then these things stored in the keychain are accessible to the password manager, which is reasonable, which means when it's not unlocked, then they're encrypted securely.  So it does mean, though, that if you had an unencrypted backup, then that would be a problem.



So the problem is the users, all of that same data, the master password, the secret recovery question, and the RSA public and private keys, are also all for some reason encrypted in the same database using RSA.  But it's only 512 bits.  And we were just talking recently about how 768 had been cracked, and it gets much easier to crack it as the RSA modulus shrinks.  So this is only 512-bit RSA, not really strong enough because factoring 512 bits is now feasible and is getting more so all the time.  So again, you've got some good security; but it's like, okay, why didn't they use 1024 or 2048?  Because it doesn't take that long to do it with contemporary devices.



Strip Lite Password Manager uses AES-256 encryption.  And these guys did a good job.  It's one of the first that is really pretty strong.  They compute the encryption key using password strengthening, that PBKDF2, 4,000 times, using the master password that the user provided and a per-database salt.  So again, they protect themselves from any precomputation attacks and do this 4,000-round password strengthening.  So that looks pretty good.



Safe Wallet Password Manager, for $4, uses AES-256 encryption also.  And they do also password strengthening 10 times, so not quite as strong as Strip Lite, but still pretty strong.



DataVault Password Manager uses AES-128 encryption in ECB - that's Electronic Code Book - mode where there isn't any block-to-block chaining.  You just use each block and encrypt it separately, which is probably fine for this kind of data.  They encrypt the key using the master password, pad it out to 16 bytes.  So that's a little bit of a concern because when we don't hash, and we just pad, then it is possible, as we saw earlier, to quickly determine whether we've hit the right password because we're going to end up with an obviously padded result and not just pseudorandom noise in our test decryption.  But they also use the iOS keychain to store everything, so they're pretty safe.



mSecure Password Manager, for $10, uses Blowfish encryption.  The encryption key is an SHA-256 hash of the master password, so that's pretty strong.  They do password verification by performing a trial decryption of a known verification value for comparison.  So when you enter your password, they hash it and then perform a trial decryption of something whose decrypted value they know.  And if it matches, then it's safe.  So that means, okay, you could perform an offline attack.  Password recovery would require one SHA-256 process and a Blowfish key setup.  And that's significant because that's very slow.  So I think mSecure looks like they did a good job.



And finally LastPass - which is as we know $1 per month for the premium, Last Pass Premium, but they use the same technology even for their free, uses AES-256 encryption, so nice strong key.  They use an SHA-256 hash of the username plus the password.  So that's got the advantage of probably being longer than if you were just using the password.  Essentially the username becomes the salt when you're entering the password every time, after you've set it up.  And they verify by decrypting the 256-hash of the encryption key.  So password recovery for LastPass requires two SHA-256 hashes and an AES-256 decryption.  So that's also pretty strong.



So what we see is there are some password utilities which have done a very good job.  There are some that have tried, but have made some simple mistakes that render them essentially useless because it's very easy to look up the password or decrypt their secret key because they encrypted it with something that was known, even though it was random gibberish.  It's like, okay, well, this is a reverse engineer's joy.  And there are many that perform no encryption at all.  Everything is stored in plaintext.  The password just is checked to see if it's the same as what you put in before.  And if it is, it lets you look at your data, you and anybody else who might have it.



So strength varies across the complete spectrum.  There's no way to know what you've got unless someone - unless they disclose to you exactly what algorithm they are using, which would be nice.  Most people don't.  They just say, oh, military-grade encryption, if they have any encryption.  Again, as we know, as we well know from the podcast, just saying that means nothing because you may be using military-grade encryption, but storing the unencrypted data in the file.  So...



LEO:  It just shows how tricky it is.



STEVE:  Yes.



LEO:  I mean, it's not - you can know a lot and still do it wrong.



STEVE:  Yes.  It is very - we see that all the time, people doing a good job with encryption and making a simple mistake that allows the bad guys to get around it.



LEO:  Did you look at 1Pass - I think it's called 1Password?  Because that's kind of the best known one.



STEVE:  Yeah.  1Password...



LEO:  1Password, that's it.



STEVE:  Yes, the numeral 1Password.



LEO:  Yeah, yeah.



STEVE:  And they're good people.  I did look at it.  I looked at several of their blog entries.  This report from ElcomSoft was a little harsh about them.



LEO:  Really.



STEVE:  Well, but...



LEO:  They're probably the No. 1 iOS password manager.



STEVE:  Well, yes.  And they are absolutely strong.  They're as strong as any of the good ones.



LEO:  Oh, okay.



STEVE:  And from looking at the blog postings, they're going to make it stronger.  They weren't, as I recall, they weren't doing any password strengthening, though all of their crypto was absolutely good and solid.  I can probably - I didn't have it in my notes, but I think I've got the - I've got it right here in front of me, the ElcomSoft deal, what they said about 1Password.  Yeah.



1Password Pro, it is $14.99.  And it actually uses a bunch of MD5 hashes with salt, so rainbow tables cannot be applied.  And it uses AES-128 encryption to generate database keys and strong validation.  And I do know from reading their blogs that, if they haven't already, they're just in the process of adding some good strengthening to bring it up to speed.  But I was impressed by everything that I saw on their website.  So I think 1Password Pro is - and it looks like it's the priciest one of the ones we've seen.  But they've done a good job.  So I would absolutely trust them.  There is no backdoor, no shortcut into passwords stored with them.



So takeaways are that many popular password storage apps provide little or no actual security.  They're just pure eyewash.  It just prevents you, the user, from...



LEO:  [Laughing] Eye wash.



STEVE:  ...from getting past the front door.  But anyone with access to an unencrypted backup or to the device itself, if it's not locked, or if there's a way that the lock can be bypassed, although we see that Apple has done a very good job of that on the later devices, many of them just won't prevent you from getting in at all.  We see that Apple's own protection is typically far superior to what certainly some of this password software provides.  But the better ones that we talked about really, I mean, it requires full-on brute-force crypto in order to crack them. So you want to use a good, strong password.  That advice still applies.



And so Apple users, and same thing for BlackBerry users, BlackBerry also does good - BlackBerry's been a crypto leader for a long time.  So they use actually twice the password strengthening that Apple does.  They use 20,000 iterations of the strengthening algorithm in order to generate their final key.  Not that it really matters because you just do that once.  And all you'd really see from a UI standpoint is a slight pause as it accepts your key, which is entirely acceptable because the bad guy is going to face that pause every single time they guess.  And so you want them to be slowed down.



So complex backup passwords.  Use the best strongest daily unlocking passcode you can.  And length matters, so do something easy to do but hard to guess, especially when the bad guy doesn't know what you've done.  And absolutely encrypt your backups.  And listen to this podcast...



LEO:  For more.



STEVE:  Yeah, well, use one of the better password managers.



LEO:  Yeah, yeah.  LastPass continues to impress.



STEVE:  Yup.  They understand crypto.  They've made no mistakes.



LEO:  And they're totally cross-platform, a buck a month for the pro, which you don't even have to pay for, but it's worth.



STEVE:  Yup.



LEO:  I think that's probably a good choice.



STEVE:  It's what I use.



LEO:  Yeah.  Thank you so much, Steve Gibson.  He is the man in charge at GRC.com, the Gibson Research Corporation.  That's where you'll find him.  You'll find him on Twitter, @SGgrc or @SGpad, and I presume you're putting some stuff up there because of your new iPad.



STEVE:  Yup, have been.



LEO:  Lots of thoughts there.  And don't forget SpinRite, please, the world's finest hard drive maintenance utility.  That's at GRC.com, the one thing he charges you for.  Everything else is free, lots of freebies including ShieldsUP!, which everybody knows, but lots of free security programs, utilities, information about things like Password Haystacks, which Steve referred to.  If you want to know more, that's there.  And don't forget that there are 16Kb versions of this show, for those of you with bandwidth caps or bandwidth impaired or on dialup, as well as full transcripts at GRC.com.  We have the audio and video at our site, TWiT.tv, and we do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern, if you'd like to watch live.  Next week Q&A.  And if you've got a question for Steve, go to GRC.com/feedback.  And I'm sure he's collecting them even as we speak.  Thanks, Steve.  We'll see you next week.



STEVE:  Thanks, Leo.



LEO:  On Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#348

DATE:		April 11, 2012

TITLE:		Listener Feedback #141

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-348.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is going to join us in just a moment.  We're going to get updates on, boy, some big security flaws, both Mac and Windows, a big Windows update, a big Macintosh update.  And then we'll answer some great questions from you, the audience.  In particular, buffer bloat will be one of the many topics we'll talk about.  Stay tuned.  Security Now! is now.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 348, recorded April 11th, 2012:  Your questions, Steve's answers, #141.



It's time, and there has never been a better time, for Security Now!, the show that covers keeping you safe online with our Explainer in Chief, Mr. Steven Gibson of the Gibson Research Corporation, the creator of SpinRite, the world's finest hard drive maintenance utility.  He's also the author of a great many free security programs.  And it's a Q&A time, isn't it Steve.  Hey, Steve.



STEVE GIBSON:  It is, Leo.  It's great to be with you again, as always.  Elaine, who apparently not only, as we know, transcribes these podcasts but actually listens to them, she immediately emailed me last week when you had referred to me as Explainer in Chief...



LEO:  Yes.



STEVE:  ...and were trying to remember...



LEO:  Right.  What was the other word I used?



STEVE:  It was Debunker in Chief.



LEO:  Ah ha ha.  You are.  You are the Debunker and Explainer.



STEVE:  We don't do that much debunking, but when there's something that needs it, we deliver.



LEO:  When debunking is needed, the man is here.



STEVE:  So we've got - this is a Q&A episode - a bunch of great feedback from our listeners, some thoughts and comments and questions.  But also, boy, has it been a busy week in security land.  We haven't actually had a busy week for a while.  But the big news over on the Mac side, of course, is that reportedly on the order of 1 percent, which is a big percentage, of all the Macs have been infected with this - it's variously known as either "Flashback" or "Flashfake."



LEO:  Both of which are misnomers because it no longer works that way.



STEVE:  Correct.  It started out back in September of last year, so September of 2011, with a fake Flash update prompt for users.  And they had to provide their administrator password on Macs - this was all Mac.  And so this used an exploit in order to get into their machine.  And it was installing a botnet.  Well, over the months it has evolved its capabilities and finally began using a Java exploit, that is, exploiting a Java vulnerability, which Oracle patched for everybody else back in February.  But because Apple kind of went their own way with Java, I'm sure this was some screaming fit that Steve Jobs had at one point where it's like, we're not going to ship somebody - we need the source.  We need to maintain this ourselves.



So Apple has their own Java build.  And I don't know what the mechanism is for them maintaining synchronization with Oracle.  But for whatever reason, Apple is running their own ship, Java-wise.  But of course we know now they're dropping it.  10.7 no longer ships with Java.  Users who need it have to go and install it themselves.  So what happened was, as a consequence of this known but unpatched vulnerability, a huge number of Mac systems have been infected with this Flashback/Flashfake botnet.  And the guy at Kaspersky Labs did something really cool.  They reverse-engineered the latest version.



And it uses something we have seen before, I think it might have been Confickr, where it's a date-based cryptographic algorithm to generate domain names.  So that the bots use the date and a sophisticated crypto algorithm to come up with a domain name which is predictable only if you had all of the information, so if you were a bot, or if you were a Kaspersky Labs reverse-engineering guru.  So they understood the algorithm.  They picked a date a few days in the future, determined that on that date, I think it was last Friday, in fact, the botnet would start looking for the domain, the dotcom domain krymbrjasnof.com.



LEO:  What's that?



STEVE:  That's the result of the crypto algorithm.  And so what Kaspersky did was they acquired that domain name and set up a honeypot.



LEO:  You mean that the other guys didn't have it?  I mean, isn't that where they control the botnet from?



STEVE:  Yeah, but they don't need it every day.  So that one they hadn't grabbed, probably because they're - and the bots are always straddling several.  So the bots are looking at existing domains that they have and also prospectively looking at new ones in order to be basically anti-shutdown tolerant.  So the bots began reporting in on schedule at this domain name that Kaspersky grabbed.  Thus they were able to exactly determine the count and location because of course they got the IP addresses of the queries coming in for these bots.  They found, during their period of looking, 670,000 Mac machines.  670,000 machines.



LEO:  That's going up.  I mean, it was 500,000 when Dr. Web reported it, then 600,000.  So it's still going up.



STEVE:  Yes.  So a little less than half are in the U.S.  They offer on their site a breakdown.  It's sort of interesting:  300,000 are in the U.S.; 94, 95 if I round it, thousand in Canada.  So Canada is second strongest with a little less than a third of what the U.S. has.  Again, half again fewer, about 47,000 in the U.K.  Then Australia has 41,000.  Then it drops quickly - France down at 7,800 or 7,900, and Italy at 6,500, and down from there.  So and it was funny because I'm looking at that:  U.S., Canada, U.K., Australia.  I thought, well, that's pretty much the demographics of TWiT.



LEO:  Well, it's the English language speaking populace.



STEVE:  Exactly.  When I saw that it dropped in France, I said, oh, of course, because this is going to be to a lesser degree an English-speaking attack.  Then they used, and they were careful to say, "PASSIVE OS fingerprinting," meaning they didn't inject anything back onto the Mac machines or do anything active on the Mac machines that were querying, but they did passive fingerprinting to verify that, of those incoming queries, they could confirm 98.41 percent were Mac OS X v10.something.  So that they confirmed.  Then they did something very cool, which is - and you ought to click that next link there, the second one down that says "Flashfake Removal Tool and online checking site," Leo, just if you want to show...



LEO:  Yeah, I got it, yeah.



STEVE:  ...our people.  What they've done is, every query - the reason they were able to get these counts and to know that they were unique is the queries to this funky domain by the bots contain the Mac's own UUID, its unique identifying string that is absolutely unique.  So Kaspersky built a database of these 670,000 Mac machines.  And any user who is interested can put their machine's UUID into this site and check whether it's logged as infected.  So it's a quick way of confirming it.



LEO:  That's interesting.  I mean, it's easy enough to determine it with some simple terminal commands.  People have written Apple scripts that execute those commands for you.  But this would be another way to do it, I guess.  Kind of a backend way of doing it.  But you could see if you were ever infected, I guess.



STEVE:  Yes.  FlashbackCheck.com is the domain.  So FlashbackCheck.com with no spaces or dashes or anything, if you're curious.  Now, they also have a removal tool.  Kaspersky has a removal tool, small little thing, 164K zip file, which Mac users could use.  There are, as you said, online instructions.  They're a little complex.  And so automating this with a single click is a nice thing to do.  And Apple has said that - of course obviously Apple has responded to this, as you can imagine.  They have patched the problem with Java, but only for OS X versions 10.6 and 10.7, not anything earlier.  And they don't apparently plan to do so.



So anybody - and in fact they said on their page, "For Macs running Mac OS X v10.5 or earlier, you can better protect yourself" - yeah, better - "you can better protect yourself from this malware by disabling Java in your web browser's preferences."  And of course listeners to this podcast know that we've been long recommending that everyone disable Java, or uninstall it if you really don't need it.  But if nothing else, turn it off.



So this is a, once again, it's a JavaScript which then invokes Java in order to make this happen.  So if you're also running with scripting disabled by default, you would have that first line of protection, and just doing that would have protected you.  But then...



LEO:  But of course Mac people don't assume that they're in any danger.  So they probably don't run with scripting off; right?



STEVE:  Which is a great segue because there have been a lot of articles in the last week saying, wait a minute, we thought...



LEO:  We didn't have to worry.



STEVE:  ...Macs didn't get, yeah, Macs didn't get infected.  And so I look around, and I guess as I've mentioned before it's because I am in a university town with UCI right next to me, at Starbucks all I see is Macs now.  I mean, there's been a huge shift, with Mac adoption obviously rising.  And clearly I'm looking at a skewed demographic with college students who get a Mac when they go off to school as opposed to a PC more so these days than before.  So there is a much larger target now for the bad guys.  And where there's a known exploit, and maybe arguably, as you said, Leo, Mac users assume they're safe, so they're not going to be running with JavaScript disabled.  Not like a large percentage of regular Windows users do that either.  I mean our audience certainly does, but in general Windows users aren't.



So, yeah, I think we're seeing the inevitable catch-up, for lack of a better term, of the Mac situation.  I mean, there is, unfortunately, there is nothing fundamentally more secure about the Mac.  It always was based on UNIX; whereas Windows, back in the days of 95, didn't have a secure OS security model.  And even though NT did, it wasn't really used strongly until XP came along and Microsoft decided, oh, boy, with that Service Pack 2 release of XP where they finally turned the firewall on, and they really began to get serious about security.



I did read that the Mac support of ASLR, Address Space Layout Randomization, was less robust than Windows, and that when it was first released, Apple said several years ago that they were going to improve it, but they haven't done so yet.  But I don't know that that's a huge issue.



But basically these are all PCs of one ilk or another.  And we're seeing things like plug-ins such as Java or exploits in JavaScript and browser exploits.  Those are now the low-hanging fruit.  It's no longer open ports, which you could argue would differentiate one OS more from another because they have completely different internal architectures, Windows versus the Mac.  Now it's the stuff running on the OS which is where our problems are coming from, and they're cross-platform.  Java runs on everything.  And clearly whatever it was that was wrong with Java was just as wrong under Windows as it was under the Mac.  Oracle fixed it in February.  Apple didn't get around to it.  And you can imagine they wished they had now because this is a bit of a black eye.



LEO:  It's embarrassing, yeah.  Now, what happens if you get infected by this?  It isn't a particularly destructive virus, is it?



STEVE:  No.  It doesn't want to hurt you.  It wants to use you.  It wants to set up camp in your machine, check in with these wacky domain names from time to time, and participate in spamming and DDoSing, the standard botnet stuff.  So it wants to commandeer your machine.  It wants to use...



LEO:  Although, because all of these servers that it's supposed to hook up to have all been kind of closed or taken, it's unlikely to do anything if you've got it.  It can't join those botnets.



STEVE:  Now that it has become as high-profile as it is, there's a huge effort now to shut this down.  Apple doesn't yet have, but has said they will have, a removal tool.  I imagine next week we'll be talking about that because I would think they would do it quickly since everybody else already has for users.  But there will be an official one from Apple.  And all it'll - it just removes the required files from the OS, and then you're fine.  So it's not some horrible pernicious rootkit-y kind of thing that you can't ever get rid of or you have to reformat your hard drive and reinstall your OS or anything.  It will leave peacefully.



So Microsoft, also, we have just passed our second Tuesday.  And, oh, another big one.  They did six bulletins, four of which were critical.  But one is super critical because of its pervasiveness through the Windows ecosystem.  There's something known as Common Controls, which have existed from the beginning of Windows.  We're familiar with how Windows has sort of always been modular, with so-called DLLs, Dynamic Link Libraries.  Windows itself has a kernel DLL and a GDI DLL and a user DLL.  So it's built from these modules, these dynamic link libraries.



Well, a library which has always existed in Windows is called Common Controls.  And those are the things that all Windows apps have and use, like the scroll bars on the side, horizontal and vertical, and the menu system itself, and the individual window control widgets, the dropdown list box and the spin dialogues, and even text fields which appear in a dialogue, all of that is common control.  That is to say, all of the chrome that embellishes a window is essentially the common control.  You have the window frame, and then all of that other stuff.  Buttons, obviously, are common controls also.



Anyway, all of that is in a library which, over the years, has been evolving.  And at one point they switched their technology from DLLs to so-called ActiveX controls, where then the extension changed from .dll to .ocx.  So what was found - and let me get the timing on this right.  Microsoft has known that there were some exploits of this for a while, but kept it quiet.  So it's being called a zero-day flaw, but I don't really know that that fits so much.



But the problem is that the incredibly highly used ListView and TreeView are two controls in the current common control library which can be exploited.  And so of course the TreeView is what everyone's used to in Windows where it's like that hierarchical view with the plus signs you click, and it opens up.  It's that outline-y kind of thing.  That's a common control in this library.  And then the ListView is anything that is like a list of things, like a spreadsheet is a list and uses that common control library.  So there's a problem in that in every version of Windows.



And it's worse than this, though, because developers want to make sure that their software running on some random Windows machine has the most recent common control, or the one that they want, because sometimes these things change, they've got bugs and so forth.  The developer designs an application, and even Microsoft does this, designs an application with a given version of the common control.  Well, they bundle it with their application because what Windows will do is it will look in the directory where the executable ran from for various things that it needs before it goes out and looks system-wide, in the Windows system directory and the Windows directory and so forth.  So if an application brings along with it the version of the common control library that it wants and expects, then it knows that's the one that will be loaded for it when it runs.



But what this means is that this isn't just Microsoft that needs to fix this problem.  This is everybody, all applications that have bundled this now known to be buggy common control are potentially vulnerable.  Now, we have to mitigate that somewhat because of course the bad guys would have to get this application to invoke the TreeView or the ListView somehow themselves.  And that's much less likely to happen.  The big targets of opportunity, of course, is IE, Internet Explorer.  It's using those common controls.  And Office is doing so, too.  And this can be either exploited by IE or, naturally, by clicking on a link in email that invokes this common control which is present.



So we're recording this on Wednesday the 11th.  This all happened, the updates, on the 10th.  There are mitigating measures.  For example, in Microsoft's own FAQ they said, under their FAQ for this, they ask themselves the question:  "I'm a third-party application developer, and I use the ActiveX control in my application.  Is my application vulnerable, and how do I update it?"  Microsoft's own answer is:  "Developers who redistribute the ActiveX control should ensure that they update the version of the ActiveX control installed with their application by downloading the update provided in this bulletin."



So this is Microsoft formally acknowledging that everybody who is sending this out on their own has to take some responsibility.  But again, it's not clear how the bad guys would get to that particular instance of the bad control.  For anyone who's curious, this is a file called mscomctl.ocx.  And I wouldn't be surprised, if you just searched your file system for it, if you find a bunch of them littered around because different applications will have brought them.  Under workarounds, Microsoft said:  "To prevent the vulnerable Active X controls from being run in Internet Explorer, you can disable attempts to instantiate the mscomctl TreeView, TreeView2, ListView, and ListView2 controls in Internet Explorer by setting the infamous kill bit for the controls in the registry."



And we've talked about the kill bit for years because this is an area where Microsoft is beginning to get better with their security, but everything used to just be enabled by default, so it's touchy to come back in and turn things off, even though now they wish they hadn't been as liberal with allowing everything to run.  The problem is, that is with doing this, is that some websites really do want to use, well, at least the ListView, if less commonly the TreeView control.  So that would break those sites that do that.



So bottom line is it has been fixed.  This is an important Patch Tuesday.  So don't wait too long to update this and restart your machine.  When I fired up my Win7 box in order to run Skype for the podcast, Leo, of course it immediately popped up and said, whoa, we've got important things to do.  And I said, yes, update yourself right now.  Get it done.



And not to be left out, Adobe, also yesterday, released new versions of Reader and Acrobat.  There's no end of - and I should mention, I didn't quite finish saying that this is being, this zero-day, if it's so-called zero-day, this common control problem is being actively exploited in the wild.  So this is important.  This is going to be jumped on by the bad guys.  So again, it's not theoretical.  I remembered to say that because the fixes that Adobe has just offered for Reader and Acrobat are like, yeah, update, but nothing horrible happening with them as far as we know.



Reader and Acrobat 10, versions 10.1.2 and earlier, need to be updated for Windows and Mac; v9.5 and earlier, also for Windows and Mac.  And then over on Linux, since there's no Acrobat there, it's just Reader v9.4.6 and earlier need to be updated on Linux.  So keep that in mind for Reader and Acrobat users.  I switched over to, I think it's Sumatra, as my plug-in, my PDF plug-in for Firefox.  And I like it very much.  I prefer it.  I have Acrobat installed on this system, and so Acrobat brought its own plug-in.  It doesn't use the Reader plug-in, it uses the Acrobat plug-in.  And it was, I don't know, always bothering me with things, trying to launch a separate window and doing strange things.  So finally I got tired of it, and I disabled it, and I looked around, and I used Sumatra on Firefox.  And I'm very happy with it.



Oh, and I did want to follow up that last week, when we were talking about iOS password managers - we've got some questions, not surprisingly, in the Q&A approaching.  I mentioned that 1Password, which you specifically asked about, Leo...



LEO:  It's I think the most popular Mac program, yeah.



STEVE:  Yes.  And I mentioned that they were just on the cusp, I had read, of increasing its security.  And they have.  On April 9th, which would make that Monday of this week, they released 3.6.5.  And the blog posting is "1Password iOS PBKDF2 Goodness."  And of course we know that PBKDF2 is the password-based password-strengthening algorithm.  And so under their list of things they have improved, they said, "Improved security.  Now using 10,000 PBKDF2 iterations to protect the encryption key.  Dropbox authentication tokens are now stored in the system keychain.  Better support for iPad retina display" - on iPad 3, of course - "and improved log-in filling and some bug fixes."  So 1Password, as you say, Leo, the most popular password manager over on the Mac side, just got better.



LEO:  Yay.



STEVE:  And I wanted to let our listeners know that.  Also many people have tweeted me about a recent Dropbox tech blog.  It's tech.dropbox.com/?p=165.  And you can probably also, by this time, Google.  They've used a sort of a funky pseudo password, tongue in cheek.  It's "zxcvbn: realistic password strength estimation."  Well, this is very interesting.  So many people have brought it to my attention, I just wanted to let everyone know I'm aware of it.  This is the Dropbox guys commenting that more and more they are seeing password strength meters wherever they've being asked to create a login on a website.



LEO:  Yes, yeah, you see it all the time, yeah.  And I'm never good enough.



STEVE:  Well, and what they've done is they have developed a very nice one and offered it.  It's like, here it is.  And so for next week I will have a complete analysis of it.  I thought I would have time today, but as I was scrolling down through it, it's like, whoa, I'm going to have to read this, I mean, really think about it because it looks like it's extremely comprehensive.  And it looks like they've done a great job.  I salute them because this helps other developers.  Down in the comments to the blog posting there's a lot of guys saying, whoa, thanks so much, I'm going to use it.



LEO:  I could use this, yeah.  As long as it's reliable.  As long as it's, you know, it reflects accurately the true strength of the password.



STEVE:  Correct.  And that's why I can't say anything about it today.  I'll have a complete, an Explainer in Chief evaluation of it for next week.  And, really briefly, I just wanted to mention something that might be of some interest to our listeners.  Leo, I know you, I had heard you on some other podcast talking about genetic testing.



LEO:  Yeah.  I did 23andMe, yeah.



STEVE:  But it's now $209.  Wasn't it a lot more?



LEO:  It's actually - is it really 200?  Because I thought it was closer to a hundred.  Anyway, yes, it's a lot cheaper.



STEVE:  Yeah, so...



LEO:  And it was worth doing.  Although I will say that it is not the full genome.  It's not as cool as one would hope.  But it's a start.



STEVE:  I had thought that it was more like a thousand dollars.



LEO:  It's $99 for the test.  And then they encourage you to subscribe for $10 a month because then they will notify you - and I think you have to do it, so you're right, it's $200 when you include the $9 a month subscription because then they notify you when they find out new stuff about any of the genes that you have.



STEVE:  Right.  So anyway, I didn't realize it was so inexpensive.  I immediately ordered it, and I'm waiting to get my saliva kit so I can spit in it and see what they can tell me.



LEO:  Yeah, it's really easy.  In fact, I should show you, for those who are interested, I'll give you an idea.  I'll show you my page.  One of the things that they do is they give you surveys because they want to match your phenotype with your genotype, so your history, your sexual orientation.  They have a cancer family history survey.  So they encourage you to take these.  But if you want to then look at your disease risk, for instance, based on genetics - and remember, we don't know exactly what the connection is between certain genetic markers.  My risk of coronary heart disease is 58.1 percent, but that's because I'm a white European male.  So men of European ethnicity...



STEVE:  Well, for example, it says nothing about your diet.  And so it's like, clearly...



LEO:  As we know, most disease is systemic, and it's a combination of genetics and environment.  But it's interesting.  It's great.  And there is some stuff that is great.  For instance, here's carrier status.  These are genetic markers that you might pass on to your kids, things like Tay-Sachs disease.  And then drug responsiveness, traits, whether I'm likely to become bald.  It's fascinating.  My alcohol flush reaction?  None.  I am unlikely to taste bitter perception.  I have wet earwax.  My eye color, likely brown?  Yes.  My hair curl, slightly curlier hair on average, absolutely.  Likely lactose tolerant, yup.  That's probably because I have some Nordic or Germanic heritage.  Malaria resistant, not resistant.  Male pattern baldness, typical odds.  Muscle performance, I'm a likely sprinter [laughing].  Sorry.  You could see how some of this stuff doesn't - is more environmental.



STEVE:  Yeah.  I just - I didn't realize it was so inexpensive.



LEO:  Yeah, and well worth doing, as long as you understand it's not 100 percent complete, it's not your full genome, it's a few markers.  But it's really - I think it's great.  It's well worth doing.  And if you get your family members to do it, get your mom to do it and stuff, then you get additional information.



STEVE:  Okay, Mom.  Spit in this vial.



LEO:  Yeah.  Why not?



STEVE:  Okay.  So two little goodies from the Twitterverse.  Kyle Skrinak, who's in Apex, North Carolina, and he's @skrinakcreative, he said:  "@SGgrc, the OpenDNS DNSCrypt uses 112MB of RAM on my Mac.  Does that sound resource-hungry to you?"  It's like, oh, 112MB.  Well, yeah.  I look at that as a fraction of a gig, and it's a large fraction of a gig.  It's, wow, 11 percent.  So it's like, yeah, that seems like a lot.  I don't know where it stands in its development release.  I guess was it in beta on Windows and released for the Mac?  I don't remember know where it is.  But wow, that's a lot of memory to give it.  So maybe they'll work on paring that down.



And then Mark Cipriano in Australia, he said:  "@SGgrc Question.  How can I store important docs, e.g., birth certificate, etc., online?  Encryption?  Dropbox?  Evernote?  Can this be done safely?"  And it caught my eye because next week we're going to talk about SpiderOak, and I can't think of the other one.  There's two of them.



LEO:  I use SpiderOak, and I really like it.  Perhaps Wuala?



STEVE:  Oh, BoxCryptor is the other one I wanted to...



LEO:  Box, okay, that's Box.net, yeah.



STEVE:  SpiderCrypt or...



LEO:  SpiderOak.



STEVE:  SpiderOak, yes.  SpiderOak looks very nice, and BoxCryptor.  So I'm going to do the full, tear it down, look at the technology.  I've established a dialogue with the SpiderOak people, so they're standing by to answer my techie questions, which I'm sure I'll have, and I've already got some, in fact.



LEO:  I have some.



STEVE:  So that's next week's topic.



LEO:  It's got a little bug.  I have a SpiderOak account.  I think I pay for 200GB.  I pay for a lot.  And for some reason, on one of my machines, even though it's on the same account, it doesn't recognize the other machines.  It's kind of weird.  Anyway, I'd be very interested.  SpiderOak is one of those that offers pre-ingress encryption.



STEVE:  Yes, that's what caught my attention.  And I like it very much, just from a philosophical standpoint.  They are rigorous and ruthless about individual security.  I mean, they bend over backwards making it absolutely clear that this, as you said, is pre-egress, or pre-Internet encryption, that they do not have your password.  They don't want it.  They're going to go to every length possible not to be able to ever decrypt what you provide.  So it is encryption, and it really looks like it is secure cloud storage.



LEO:  I've been pretty happy with it.



STEVE:  Yeah.  And then BoxCryptor is different somehow.  I don't know how, but I will next week.  So I'll have the full tune-up there.  And I did get a nice note from a William Lorman, and he said - his subject was "A classic SpinRite story with an iMac twist," which is nice.



He said, "Hi, Steve.  I'm a long-time follower of your work and customer since 2006."  And he sent this on April 2nd, so this is recent.  He said, "I just had a scenario I thought you and Mac users would appreciate.  One of my customers' iMacs would not boot, and I could not get it back with two well-known Mac tools that reported hardware problems.  This happened when the customer forgot to configure the new disk they attached for Time Machine, so they were two weeks since backup.  I took the Mac to the Apple Store for a warranty claim, and the 'genius' gave me a not-so-nice response when I asked for the bad drive back.  He said, if the Mac apps I used didn't work, nothing would.  I said, 'I want to try SpinRite.'  He had never heard of it and said there is no way a PC product could work on an Apple part or recover an Apple system."



LEO:  Oh, dear.  Not such a genius.



STEVE:  It is in quotes here.  "I put the drive in a PC, booted SpinRite, and I'm guessing you know what happened from there.  SpinRite Level 2 got the drive back.  I mounted it in an external enclosure, and the Mac's Migration Assistant program got the user's whole world right back where it was before it crashed."



LEO:  Wow.  So they did give him the drive, they just were skeptical.



STEVE:  Yes.  "The user was very pleased to become one of your customers" - of course I thank you, William, for encouraging that, since he did get the benefit from it - "and claims they will never forget to configure Time Machine again.  Sincerely, Wm. Lorman."  So, neat story, thank you.



LEO:  I love that.  That is a great story.  You don't look at the file system.  You don't look at the operating system.  You don't care if it's HFS+, NTFS, FAT32.  You're not looking at that level.



STEVE:  Or TiVo.



LEO:  Or TiVo, right.  Which I think uses the Linux file system.



STEVE:  It does, except some of them are byte swapped because they were PowerPC based, so they were big-endian.



LEO:  Whoa.  They're big-endian.



STEVE:  Yes, exactly.



LEO:  Wow.  That's interesting.  But so you don't care because you just look at sectors.



STEVE:  Don't care.



LEO:  You're asking the drive - the only thing, the reason you don't have a Mac version, I know, is because you use an interrupt that's only in the PC BIOS.  You haven't done the EFI version.



STEVE:  Right.  A lot of people want it.  And it's definitely in our future.



LEO:  Nontrivial, I think.



STEVE:  Nontrivial.



LEO:  You kind of have to write your own INT 13, I think, is what you have to do.



STEVE:  Oh, I can't wait.



LEO:  It's not hard.  I bet you INT 13 is just a few lines of code.  I mean, how complicated could it be?  Steve, for you, I have questions.



STEVE:  Yeah.  We got some great ones.



LEO:  Let's get right to them.  Oh, I closed them.  And that was a foolish thing to do.  Let's reopen them and take a look.  Security Now! Q&A 141.  Question 1 from Shane in Phoenix, Arizona.  Is secure deletion necessary when using full disk encryption?  Oh, you know what, that's a great question:  Steve and Leo, first off, I love listening to Security Now!.  It's great.  I have a quick question.  I use a MacBook running Lion.  I've enabled full-disk encryption with Apple's built-in FileVault feature.  Given all that information is stored as encrypted gobbledygook, is it necessary for me to use OS X's secure delete tool when erasing sensitive files?  Namely, if my encryption key were compromised, would it be feasible to recover encrypted data that has been erased?  My first impulse is it's not feasible, since any information on the drive is just noise.  But I defer to your expertise on this one.  Thank you.  Shane.



STEVE:  Well, it's interesting because - and it's an important question because the answer is yes, you still do need secure deletion.



LEO:  Oh.  That's not what I would have thought.



STEVE:  And the reason is, while all of the data is stored on the disk as scrambled bits, when viewed from inside the operating system, it just looks like a file system because the encryption occurs on the way out, and the decryption occurs on the way back in.  So if regular file deletion is what typical OSes do, that is, they just mark those regions unused now, they're undeletable.  So you can undelete files even if it's on a secured encrypted file system because, again, the files stored are gibberish.  But the operating system, which is on the inside, sees everything decrypted.  So what secure deletion does, of course, is it overwrites the file so that the data is actually gone.  And then you're fine.  But you definitely want to do that even with full-disk encryption.



So to be clear, Shane said "if my encryption key were compromised," meaning if the full-disk encryption was decrypted, do I wish I had been using secure deletion, and the answer is yes because any file that can be undeleted, or the disk scanned from inside the operating system to find debris from temp files and other things that were not securely deleted, those are still available if you're on the inside.  Which is where you'd be if your encryption key were compromised.  So, yeah, it's still worth doing that.



LEO:  Interesting.  Mark Martin, Lansing, Michigan, has a follow-up from last week:  I went looking for more information about the ElcomSoft presentation at Black Hat Europe that you mentioned on our last episode.  I found the slides at media.blackhat.com.  Actually, I've clicked this link, and I don't think they're there.  But anyway, in them they discuss the complexity of the master password validation.  And a table at the end summarizes this again, includes rates for master password validation, for all password managers, and the length of passcode that can be exhaustively tested in 24 hours.  I was surprised to see that LastPass had an "average" placement on the list.  Given that they determined that a 12.2-digit passcode could be tested in 24 hours, that would seem to indicate that we'd want a longer passcode to become more resistant to offline attacks.  Are their conclusions about LastPass accurate, and should I start memorizing my 12 characters of entropy and pad it out to about 32 to feel safe?



STEVE:  Well, there was a table in the original document which I used as my reference for last week's podcast.  And you're right, Leo, I tried that link, too, and it...



LEO:  It's dead.



STEVE:  ...doesn't look like it's there.  What's a little misleading is that they're talking about digits, meaning specifically zero through nine.  And even in Mark's own text here he says 12.2-digit passcode, then later he says 12 characters.  So as we know, the strength of a passphrase is a function of the size of the alphabet.  So, for example, if your passphrase only used digits zero and one, then each character position can only have two states, and so it's an alphabet size of two, so you'd need a really long passphrase in order to get enough possible states.



So most users are going to be using an alphanumeric passphrase, in which case you're about 10 times, you're roughly 10 times stronger because you go from an alphabet of 10 to an alphabet of not quite a hundred, but like 94 or something.  So then the number of digits, instead of, like, 10 to the power of how many characters, it's 100 to the power of how many characters, and vastly stronger.  So I didn't talk about it last week specifically because it was like, okay, well, that's not really relevant to most people.  Most people are going to use both a complex and a sufficiently long passcode.



LEO:  Right.  And I did find the link.  Actually somebody in our chatroom, who was probably the guy who wrote the email, just passed it along to me.  So I guess it was just a typo.  If you go to media.blackhat.com, they'll give you an XML - a link to an RSS feed that has everything, and you can just do that, and you'll be able to find the announcement or the slides, if you're that interested to read them.



STEVE:  Well, and for anybody - there was a lot of interest, you can imagine, in last week's topic.  And so there is great information there.  So I would encourage people who want more than they got on the podcast to go there.



LEO:  If you want more, we've got more.  Oops, I did it again.  I closed the PDF.  One more time.  Open her up.  Questions.  Here we go.  This is Question 3.  Steve C. in Rochester, New York says:  Do mobile devices have a built-in firewall?  Steve and Leo, thanks for the great podcast.  I've been listening for about four years, and I really enjoy the show.  I have a question about iOS and Android mobile devices.  Do any of these phones or tablets have a software firewall as Windows does?  I've been under the impression that, if I'm using an iOS mobile device to connect to the Internet over a public unsecured WiFi hotspot, that I'm safe as long as I do simple web browsing.  That is, I'm safe as long as I don't attempt to log into a secure website over such a connection.  Is there any way that an attacker can inject malware into my device if I'm logged into a public WiFi hotspot?  Thanks, Steve C., Rochester, New York.



STEVE:  Well, that's a kind of a complex question.



LEO:  Yeah.



STEVE:  One thing to remember is that I'm sure without exception any WiFi hotspot is also a NAT router.  So it will have one IP on the public Internet, and it'll be distributing private IPs, probably either 10.x.x.x or 192.168.something.something.  So you automatically get the benefit of the NAT router being a hardware firewall that prevents unsolicited incoming traffic.  But that shouldn't make anyone feel safe for two other reasons, which is that most exploits that we're seeing now are not our grandfather's Internet exploits, where there were open ports with bad services running which bad guys could send packets to and take over your computer.  Most of them are like what we were talking about at the top of the show, where there's something wrong with your particular software in your own mobile platform, and you click on a link that takes advantage of that.  So there you're going out to a site and essentially asking for trouble without knowing it.  So software firewalls, while present, aren't giving us any protection.



And then the last aspect of this is, in an unsecured WiFi environment, remember that everybody is on, essentially, that unencrypted Ethernet.  And so it's not just remote bad guys, but many of the things we've talked about, for example the infamous Firesheep, which allowed people to trivially find other people's Facebook logons and so forth, before Facebook and Twitter and Google began bringing up SSL all the time, which increasingly is being done, really thanks to Firesheep representing such a threat.



So the dangers are multiple and various, not only from someone outside, who probably can't get in, thanks to the fact that the WiFi hotspot is also a NAT router, but mostly it's from people right there sitting at the table next to you or across from you.  They have access to your network traffic.  If you're using login credentials with a nonsecured authentication cookie, then you are immediately  hijackable, unfortunately.  But more than that, it's things you do that are leveraging defects in your software which represents today the greatest danger.



LEO:  An anonymous listener - we have many of those.  In fact, you're all anonymous unless you tell us.  An anonymous listeners says, actually asks about iOS's built-in Password Safe.  Did you know?  Steve, a quick question about iOS and passwords.  Safari is always asking me if I want to remember my passwords for websites.  That's even on the iPad, the iPod Touch, the iPhone.  Sometimes this is the most convenient way.  Even as a LastPass user, typing my master password is bad enough on a PC, let alone a mobile device.  But how secure is it?  Should I say no?



From your last show it seems like Apple's doing almost all the right things to protect my data.  If both use secure encryption and good implementations, then the only real difference comes down to LastPass requiring your master password, which adds another layer of authentication.  But LastPass also lets you tell it to remember the master password, which pretty much just means you're now invested in never losing that device, or in being confident the device could never be hacked or broken into.



Considering all that, is having Safari remember my passwords any less secure than having LastPass on my iPad and having it remember my master password?



STEVE:  That's a great question.  And I came away from last week's analysis of the most recent iOS-based devices, that is, everything from the iPhone 3GS forward, where Apple implemented hardware-assisted AES encryption and built unavailable keys, the keys that are - and I've verified this since - unavailable to the software in any way.  You can use the encryption, but nothing on one of these more recent Apple platforms, meaning the iPad 2, iPhone 4 and 5, are able in any way - wait, is there an iPhone 5?  Is it iPhone 4?  It's 4.  Wait.  What's the latest iPhone?  I don't remember.  Anyway, none of these things are able to access the keys that are stored in the hardware, embedded into the hardware and unique for every device.



So I'm very impressed with this.  What this means is that my feeling is it's not clearly less secure as long as you understand that you don't want somebody to get a hold of your device, and you need a good code to protect access to the device's UI.  We now know that Apple ties that into the encrypted file system so that everything is being encrypted on the device, and it's tied to you entering that code correctly, and that they use good password strengthening to slow down cracking.  So maybe the right thing to do is to consider a compromise, consider that Safari's own password storage is secure, Apple has done a good job of encrypting it, it's in the encrypted keychain, I mean, it really is safe from somebody who doesn't have access to your device.



What you obviously need to do then is use the complex login, the complex entry screen, not just a four-digit passcode.  I still don't think that's safe.  I'd go for the full keyboard and do something that you can easily do every time, but it automatically means that an attacker is going to have a much worse time.  And assuming that they're doing it from the UI and don't have some sort of jailbreak or some way around it, the machine is going to wipe itself.



And that was the other reason that Apple implemented this, by the way, in hardware is that it means wiping is instantaneous.  Apple simply has to wipe the decryption key on the file system, which it can do instantly, rather than having to physically overwrite all of the flash memory in the device, which as these things become 64GB and bigger, can take a long time.  So I really think it is safe, with the caveat that you make sure that getting into the device is going to be difficult, that is, in terms of getting past that opening screen.  At that point, I've been very impressed with what Apple has done.  I think it's very safe.



LEO:  That's great.



STEVE:  Yeah.



LEO:  Because I would like to say yes when it asks.  That really is a convenience.



STEVE:  Yeah, it is.  And I'm very impressed with Apple, I mean, they've really taken this seriously.  So I wouldn't hesitate.



LEO:  Good.  Robert Berry, North Carolina, has a great tip and a note about Windows Defender Offline:  Not sure if you've mentioned this, Steve, but I thought it might be worth letting your listeners know that the Microsoft offline malware removal tool, which used to be called System Sweeper, is now out of beta.  However, it's been renamed Windows Defender Offline.  I had some difficulty finding it because of the name change, so I thought it might be a good idea to spread the word.  You mentioned it, I guess, some episodes ago, 303, last year.  So search for "Windows Defender Offline."



STEVE:  Yes.  And you will immediately find it.  I verified that.  And just to remind our listeners, it's a nice tool because it is bootable.



LEO:  Oh, so you can make a disk out of it.



STEVE:  Yes.  You can either USB install or a CD.  So you boot it, and it's a standalone, outside of Windows malware remover, which is great for rootkits because it's before the rootkit has a chance to get itself set up and hidden from the operating system.  So this is the offline, meaning outside of Windows, scanner from Microsoft.  And of course it's free.  So...



LEO:  Yeah, Paul and I talked about this, I remember now, in December.



STEVE:  Right.



LEO:  And he has an article about it on the SuperSite for Windows.  And it is, I guess, still in beta.  Let me go there and see.  Oh, it wants me to log in.  Never mind.  I'll leave that as an exercise for the listener.



STEVE:  Yeah, it is out of beta now.



LEO:  Oh, okay.



STEVE:  And thus the name change.



LEO:  Got it.



STEVE:  It was System Sweeper.  Now it's Windows Defender Offline.  They're keeping it with the Windows Defender name, which they've already established.  But offline, that's what they mean by "offline" is not running under Windows, running outside of Windows.  You boot it in order to scan your machine.



LEO:  And that's the best way to do it, obviously.



STEVE:  Absolutely.



LEO:  Adam Jenkins, Question 6, he wonders about legacy iOS file system encryption.  You've got a lot of iOS questions because of your piece, I guess, last week:  Steve, are you sure?  Are you sure that upgrading from iOS 3 to 4 to 5 would not have encrypted the device's file system?  I'm pretty sure upgrading between major iOS versions has always required a full wipe and restore of the contents, which would have allowed for that encryption to take place.  Only minor updates are ever done in place.



STEVE:  Well, Adam and everybody else, I'm not sure.  I went back and tried to find the reference, which I'm sure I encountered during my research for last week's podcast, where some security types had said that, if you didn't wipe and restore under the iOS 4 or 5, that is, if you were at iOS 3, which was not encrypting, that your file system would never be encrypted.  But I couldn't find the reference again because I wanted to see if I could learn anything more about it in order to answer Adam Jenkins's question more definitely.  So I've got to say I'm not sure.  What Adam says makes sense.  And in fact, if as he says, a major version update does require...



LEO:  I think that's the case, yeah.



STEVE:  ...a wipe - it certainly sounds right to me.  And it feels like that other would have been - what I said last week would have represented a loose end that Apple would not have allowed.  I mean, it's hard to understand why they would have done it, although there wasn't hardware encryption support until the 3GS phone and the later iPad.  So I wonder about encrypting the file system.  I guess they do, even if you don't have it, if you've got iOS 4 or 5 on older hardware.  But still, I've been unable to find anything definitive.  So I wanted to back away from what I had said and not scare people because I can't confirm that.



LEO:  It does stand to reason, I think, that if you wiped the disk during a major upgrade like that, that in the process of wiping the disk the encryption's going to be turned on when it restores; yes?



STEVE:  Yes.  That's what I would think, too, that when you are installing - both 4 and 5 support whole file system encryption.  And so you would think that that would - 4 or 5 would come alive; they would turn their things on.  And then when you restore from iTunes - and we know that the export would have been encrypted by the phone, so on import it would be sucking it in and storing it in that encrypted format, backup encryption being different from local file system encryption.  But so it would translate from the backup encryption to the local file system encryption, and there'd be a lot of encryption there.



LEO:  Yeah.



STEVE:  I think it sure seems like you'd be safe.  But I wasn't able to confirm that, so I didn't want to leave people with the idea that they might not be.



LEO:  Unknown.  Josh in Michigan comments about the security of the LAMP stack, the Linux Apache MySQL PHP stack.  That's how most web servers run, they run LAMP stacks, including ours.  Regarding PHP and MySQL being insecure by nature:  As a web developer myself, I profit more from finishing a project quickly, and therefore I am not inclined to salt and hash passwords, verify that file access scripts don't traverse file systems, parse uploaded data for cross-site scripting, check variables against respective types, determine if TLS and modify session cookies accordingly, use prepared SQL statements, and so forth.  But I do each of those, and many more, anyway.  The security of the code is simply a side effect of how much time a project environment-aware and security-conscious development team is allowed to design and focus on the project.  By thinking like a hacker, we work to prevent the successfully manipulation of PHP's environment.



While I'm at it, I'd like to mention that MySQL allows for prepared statements forcing all input parameters to explicitly behave as strictly data, even if the parameters contain MySQL injection code.  It's just more difficult, and it takes longer to write that way and test, so most people don't bother.  I thought I'd mention that at least the capability is there, even if it's rarely used, because it seemed to really trouble Steve that SQL statements can be modified by user input.  Thanks for another terrific Security Now!.



STEVE:  I'm glad that Josh is putting all that effort into the security of the sites that he creates.  As he enumerates all the things that he has to explicitly do, which he knows to do, it brings to mind the question, well, what about a web developer who is less security conscious, who doesn't know that all of those things have to happen because they all represent tried and true and previously exploited approaches or exploitable approaches to securing a site.  I've seen some comments from people yelling at me that PHP is no worse than anything else, and I completely agree.  It's not PHP, it's the environment that we've created.  And I liked Josh's question because it enumerates nicely how difficult it is, but how necessary it is to do all of that in order to lock down any website.  And he mentions, yes, it's a function of how much time we're given.  And so I would tell any managers of developers, please, give them as much time as they need to make it secure.



LEO:  Well, it's also - it may be necessary, but there also is the question, is it sufficient?  The presumption that he's making is, well, if I do all these things, we're secure.  And as we well know from history, it's not possible to be a hundred percent secure.  So it may be - he's actually sounding a little cocky to me, like, well, I do all these things, so I know my sites are safe.  Boy, that sounds like a very dangerous attitude to take.  It's necessary.  Is it sufficient?  I don't know.



STEVE:  Yeah.



LEO:  Nathan Long in Charlotte, North Carolina wonders: Doesn't coding in assembly limit SpinRite?  Hey.  Hey, Steve.  What are you doing?  I'm a programmer at the opposite end of the spectrum.  You work in assembler and mentioned that using JavaScript is really high-level for you.  I work in Ruby and have just started dipping my toes in C, which seems very low-level to me.  So it may be my question's a bit nave.



I'm wondering whether coding SpinRite in assembly placed constraints on what systems it can be used with.  Doesn't assembly refer to chip-level details?  Can SpinRite be used on any x86 system?  Can it work with RISC processors?  Putting myself in an assembly programmer's shoes, it seems like the ability to write C and compile for lots of different machines would be an amazing advance.  And it was seen that way in 1979.  I added that.  That was me editorializing.  Thanks for entertaining my question and giving any insight into your tools of choice.



STEVE:  Well, Nathan, let me tell you.  I'll put it this way.  When I heard that Mac was dropping the PowerPC for the Intel x86 platform, I was delighted.



LEO:  Yes.



STEVE:  Because it meant that SpinRite could move largely unchanged over to the Mac.  It didn't happen the next day.  Obviously it still hasn't.  But it means that it is entirely feasible.  I need to just deal with the program's interaction with its environment rather than the program itself.  So you're completely right.  I like coding in assembly language, and that is absolutely tied to the processor which the code runs on.  You have no processor independence, as it's called, which is really exactly why C was created.  And you're right, it is very low level.  The developers of C, Ritchie and...



LEO:  Kernighan.



STEVE:  Kernighan, yeah, Kernighan and Ritchie.  Those guys set out to create the smallest layer above assembly language because they had coded the first UNIX in assembly code.  I mean, it was written in assembler.  And they said, okay, wait a minute.  Now, if we do that, we're tied to the chip.  And they didn't want UNIX to be tied to the chip.  They wanted to be able to more easily move it around to other architectures.  So what's the smallest thing we can do to make us independent of the assembly language, the machine language underneath?  And that was C.  There was a predecessor, BCPL, which was the language before.  And so C came after B, and that's the one that stuck.



So SpinRite will never run, I think it's safe to say, on a non-x86 system.  The good news is, Intel won that battle.  The non-x86 platforms are the mobile portable devices that are running the ARM architecture.  And we talked about the Advanced RISC Machine, ARM architecture, many podcasts ago.  But they don't really have a need for SpinRite today.  So I'm glad that our desktop systems have ended up being x86 based, and SpinRite can run there.  Whew.



LEO:  Whooo!



STEVE:  Yeah.



LEO:  Well, it's kind of ironic because of course one of the reasons you work in assembler is so that you can work to the bare bones of the machine.  And it is CPU-dependent for that reason.  It's the double-edged sword of it.  But you, when you wrote SpinRite, actually created a dependency on code in BIOS, as we talked about earlier.  And that's - I'm sure that's what's holding you back because everything else...



STEVE:  Yes.



LEO:  It's a routine in BIOS that doesn't exist in EFI.  I guess.  I guess it doesn't exist.  Well, it must exist, it's just not interrupt-driven.  Right?



STEVE:  Yeah, it's just a different approach.  You ask it for entry vectors, and it gives them to you, and so you call them instead of having - it's sort of a different way of doing it.  And it makes it...



LEO:  The capabilities of INT 13 are still there.  INT 13 is the interrupt that accesses the drive.



STEVE:  Well, and actually SpinRite is still using some BIOS things just because they've always been there.



LEO:  They're there.



STEVE:  I'm already making very little use of INT 13.  And so what I'll be doing is I'll be eliminating my use of INT 13 completely, and that will then bring me up to - actually, more portability will be a side effect of that.



LEO:  Sure, exactly.  And the whole world's x86 now.  It's funny because Intel was moving away from x86.  Intel was going to abandon it with the Prescott and all of that.  I can't remember what they called the new stuff.  But they were going to get rid of it.  And then they realized that was a terrible idea.



STEVE:  Was there Itanium?  Was that that...



LEO:  Itanium, yeah.  And I can't remember what it was called, the replacement.  But IA64, that's what it was called.



STEVE:  Yeah, I've been coding a lot in the last few, well, I've been coding...



LEO:  Have you.



STEVE:  ...all year, this longest repeated string thing that we'll be talking about here before long.  And I just - it's such a pleasure coding in Intel assembly language.  I just breathe it.  So...



LEO:  Yeah, you know it. It's your native tongue.



STEVE:  It is my native tongue.



LEO:  Yeah.  It's actually a crappy assembly language compared to something like 68000, which was...



STEVE:  Oh, god, do I wish they had not won.  Oh.  Oh.



LEO:  I know.  With the segmented - you still have to deal with that, right, the segmented memory?



STEVE:  No, that's gone.



LEO:  Oh, thank god.  You have a flat...



STEVE:  You're dealing with a legacy of few registers.  And it's an evolved architecture, and evolution never generates as elegant a solution as starting from scratch and designing something beautiful.  The Motorola 68000, National Semiconductor had a 32000 instruction set that is, oh, it's just...



LEO:  Gorgeous.



STEVE:  ...sublime.  And Intel...



LEO:  That's what I - I coded in assembler in 68000 because I was writing for the early Macs.  And I looked at x86.  Actually it was i386 or something.  Or was 8086, actually, that's what it was.  And I went, ahhh.  I played with it because at that time you couldn't access all of memory.  It was a segmented memory architecture because the registers were too small.



STEVE:  Yeah.



LEO:  And so you had to load a page, and then load an address within that.  It was crazy.



STEVE:  Yup.



LEO:  And I look at people like you, and I just go, whoa.



STEVE:  Well, and the biggest annoyance is there's a notion in an instruction set of something called orthogonality.  If you have an orthogonal instruction set, then the idea is that, for example, all the registers can be used with all the opcodes.  That is, it doesn't care.  But the Intel architecture is anything but orthogonal.  You have A, B, C, and D registers, and then something called ESI or ES and DS, and then BP and SP, the stack pointer.  But all of them have different characteristics, like these can be combined in this way, and those can't.  CX is an auto increment.  Only BX, ESI, and EDI could be used for this.  And so it was like, oh, it's just - and that really creates inefficient compiler code because the compiler has to know all of that.  It's much easier to write a compiler for an orthogonal instruction set because it's able to freely juggle registers around and not have to be as, like, understand all of the minutiae of the instruction set.



Obviously this problem has been solved because lots of compilers exist for the x86.  But boy, it's just - it's really sad that Intel won this war.  But I'm sure glad only one person did because I only have to have one assembly language.



LEO:  Yeah.  That's true, too.  And you know what?  The new Intel stuff's great.  No complaints.



STEVE:  Boy, and we have a lot of power.



LEO:  So much power.  More than we need now.  I mean, it's just done.  That whole thing is done.  Tyler Larson in Scottsdale, Arizona offers an opinion on buffer bloat, why fixing your router usually won't help:  You mentioned how a DD-WRT variant attempts to solve the buffer bloat problem by limiting queue lengths and protocol adaptations such as RED.  Actually, it won't help.  The reason is your home router isn't the choke point in your network.  The cable modem or DSL modem is.  Your router has 100Mb or 1Gb on both ends, both in and out.  Your cable modem takes in 100Mb or 1Gb from your LAN, but can only put out 1Mb, 10Mb, 50Mb, et cetera, to the WAN, depending on how fast your Internet service provider is.  So the buffers that get filled aren't in the router, they're in the modem.  The router's buffers are consistently empty.  Same story for your computer.  Changing your OS buffering behavior won't help, either.



The only thing you can really do to affect your buffering behavior is artificially limiting your bandwidth at your router.  If your modem has 1Mb upstream bandwidth, you need to limit the bandwidth from your router to something like 800Kb, below the megabit, to keep from overloading the modem.  This obviously decreases your overall speed, but can improve your latency under load.  It's not perfect, but there you go.



And I'm going to give you a side question that we were debating in the chatroom last week.  Does more bandwidth overcome buffer bloat?  In other words, if you have tons of bandwidth, do you have to worry about buffer bloat?  So these are kind of related, I think.



STEVE:  Okay, yes.



LEO:  He says the cable modem or the DSL modem is where the buffer bloat is happening.  That's not what others have told me, but is he right?



STEVE:  Well, and that's a question because he's right if the modems have buffers, that is, big buffers.  It's not clear to me, because a modem is not a router...



LEO:  Yeah, some modems come with a router.  So maybe that's what he means.



STEVE:  Some are hybridized, right.  But I don't know that the modem itself has a problem.  We ought to go right into Question 10.



LEO:  We'll do this all together.



STEVE:  Yeah, tie 9 and 10 together because Steve came up with a solution.



LEO:  Steve "Snuffy" Sims in Hedley, Texas solved his buffer bloat problem:  Steve, a very belated thank you for the many years of assistance you have given me from the early days of Windows 98 NETBIOS problems to now.  I have followed you and Leo since the days of Screen Savers.  I thought I might give a possible Band-Aid for the buffer bloat problem:



I ran the ICSI Netalyzr - which is such a great tool, such a great tool - with a download time of 200ms, but with an upload buffer of 2200ms.  In other words, giant buffer, 2.2 seconds.  Then I ran my own test, per your suggestion, of a large FTP upload on one computer while running Ping Plotter on another computer on the same network.  Ping time to a totally different server went from 57ms to over 500ms due to the saturation.  I am running a D-Link 825 router and went into the QoS settings - Quality of Service settings.  My actual upload speed is 650Kb. I have a place there to limit upload speed and set it back to 600Kb, which apparently was enough to prevent the buffer from filling up.  With this setting, the Ping Plotter ping time only increased from 57 to 80ms while the large upload was in progress on another computer.  This didn't help Netalyzr results, but made a big difference in actual real world use.  Once again, a very hearty thank you to you and Leo. Snuffy.  So he's saying by constraining the upload bandwidth, he kept from saturating his network.  But we've known about that for a long time.



STEVE:  Well, yes.  In fact, that is, well, that is the effect of the buffer bloat.  If he sees that pushing too much bandwidth delays the data in getting out of his system, that is, there is a buffer somewhere, and we don't know if it's in his router or in his modem or where, but somewhere he's able to induce 2.2 seconds of delay, that is, the buffer's that big, that if he just pumps as much data out as he can, then he'll fill that up.  And that means that other traffic that's not part of this huge upload, for example, that he's doing, it's waiting its turn in the buffer also.



LEO:  But that was always a problem because, if you saturate your upstream, and somebody else is surfing, the ACKs and the SYNs aren't going to come out, and so your upstream - what he's done, I don't know if it has to do with buffer bloat.  He's just saying I won't let one computer saturate upstream, and that way my other computer will continue to have some access.  But that has not - that's not buffer bloat, that's just how networks work.  If you saturate your upstream with one computer, of course nothing else is going to work very well.



STEVE:  Except that all the computers on the network have equal access to the bandwidth.  That is, they're all able to put packets onto the network that'll go out through the router at the same time.  So...



LEO:  I see.  So they have - so he can't saturate it.  He can only take his turn.



STEVE:  Correct.  Exactly.  There is no - there's really no notion of saturation.  We've come to think of it that way because of buffer bloat.



LEO:  Ah.  I get it.



STEVE:  Yeah.  So what he's done is, by recognizing that he cannot push, in his case, in Steve's case, more than 650Kb out, he's deliberately limiting himself at his router to 600Kb.  And now he notices that he's never getting that long delay.  So what that means is that he can do big uploads, and everybody else in the family can stay interactive because he's not letting that buffer get too deep, which would be delaying everybody else who's also trying to use the system.  So that is exactly what you want to do.



So that really does, that ties in with our prior question, Tyler, who was saying he believes the buffer is in the modem.  Well, we don't really care where it is.  But the recognized solution, even from the original videos that were demonstrating buffer bloat a couple months ago, was throttle your upstream yourself, and that keeps everybody else interactive.  It prevents one person, see, it's not that one person's hogging the bandwidth, it's one person is forcing the buffer to be filled, which then hurts everybody.  So one guy can really slow down the whole family.



LEO:  So he fixed it by saying - by limiting his upstream to something below his capability.



STEVE:  Correct.  And it doesn't have to be much below.  Just enough below...



LEO:  50Kb, yeah.



STEVE:  Yeah, because if you're just a little bit below, then you'll have zero buffering.  Really, think about it, if it can leave just a little faster than it's coming in,  it'll never fill.  If it's a little bit above, then it'll slowly build up because it won't be able to get out as fast as it's coming in.  And you really lose nothing because you're either going to have a - the buffer's going to fill up, and it's going to be really bad for everybody, or if you limit yourself to just a little bit less than your upstream bandwidth, you really don't lose any speed.  You prevent this buffering.  But what we really wish is that there weren't huge buffers, that the buffers were only 15 packets deep, and they were just getting thrown away.  Then  all of our TCP systems would throttle themselves, and again everything would work.  And this is the point is that buffers are not a good thing to have in a packet-routed network.  They're just not good.



LEO:  Right.  So what about my contention that having more bandwidth doesn't necessarily fix buffer bloat?



STEVE:  Well, having more bandwidth means that it's harder to fill the buffer.



LEO:  Okay, so it does.



STEVE:  Yes.  So you're right, Leo.  The idea is that, if more bandwidth means that the buffer is being emptied out the other end more quickly, so you have to really - you have to work harder.  You have to run ahead of the bandwidth in order to fill the buffer.  So if you've got more bandwidth, it's harder to run ahead of it.



LEO:  Right.  Okay.  So it does help.



STEVE:  Yes.



LEO:  I was wrong.  We're going to go to Question 11, Steve Coakley in Phoenix with more Netalyzr test results:  After looking into the long times given for DNS resolver lookup latency last time, it seems to be due to running the test in the evening when I had long ping times.  I have 20Mb DSL service that's fast in the daytime but starting to slow down a lot in the evening when everyone is watching Netflix.  This seems to be true for everybody.  Normally I get about 42ms ping times to 4.2.2.2, but during the evening pings go up to 200ms.



Anyway, I found this list of fast DNS servers at TheOS.in and tried testing them all.  Now, of course you have a product that does this, as well, Steve.  They all gave me fast ping times and pretty low lookup latency of around 110 to 150ms, except for Google.  It returned 229ms.  However, they all had lots of DNS problems like returning names that don't exist, except for Google and Verizon which didn't have any problems. So  it looks like GTEI/Verizon is still the best to use, 4.2.2.1, 4.2.2.2, et cetera.



STEVE:  This was a really good observation that I wanted to bring up.  I don't think I've ever mentioned it before.  First of all, these wacky IPs that you and I are familiar with, for anyone who isn't, those are - there's a set of six DNS servers, 4.2.2.1 through 4.2.2.6, which I've been with Level 3 for - actually I was with Verio in the old days, and those used to be Verio's servers.



LEO:  Right, right, they were Verio, that's right.



STEVE:  Yeah.  And they've always - I don't know where they are or what the story is with them.  But, boy, I mean, they're, within the sort of the intelligentsia of Internetness, those are what people use.  Now, I of course wrote a DNS Benchmark that I finished late last year.



LEO:  Which is excellent.  Highly recommend.



STEVE:  Which works great.  And I do have, when I looked at that link that Steve provided, that TheOS.in, I remembered going there and making sure that I had all of those DNS servers in my master list also.  So the Benchmark knows about those.  The point was that time of day really does matter.  We saw that vividly during all of the beta testing and pre-release testing of the DNS Benchmark.  And I say in some of the web pages, don't just try this once.  Try it and make a note of what the results are, but try it deliberately at different times of day because a DNS server that may be lickety-split when you try it is just really dragging.  So the point is that DNS servers themselves come under varying degrees of load, and they are very load-dependent.  So you really want to find the best one, you do need to try it in the morning, in the afternoon, in the evening, late at night, and make sure that your choices - and there's no way that my Benchmark can take the responsibility for that.  It's got to be the user who does that.



LEO:  You've got to do it by hand, yeah, yeah.



STEVE:  Yeah.  And so it's just like, okay, try it at different times to make sure you don't, by mistake, choose one that's really fast the one time you tried it, but is painfully slow when you actually want to rely on it.



LEO:  Finally, our last question of the day, Mr. G., comes from...



STEVE:  Right on time.



LEO:  ...James Lorenzen in Joplin, Missouri, and he wonders about the difference between 128-bit SSL and 2048-bit server keys.  Quick question:  You've been talking a lot lately about the number of bits we should use when creating server keys and certificates, or the fact that 768 bits has been compromised, and that 1024 bits should be good enough, but the recommended standard currently is 2048 bits.  My question is, when visiting sites that use SSL, they say, hey, safe and secure, we're using 128-bit SSL.  What's the difference?



STEVE:  So the short answer to this, I realized I have seen other questions...



LEO:  We've talked about this before, but...



STEVE:  Yeah.  But I think maybe I get too complicated or detailed or wander off the track.  But so here's the short answer:  SSL uses both.  There's two types of encryption or crypto in an SSL connection.  There is the server keys, where we end up with these big numbers, the 1024 and 2048, and someday we'll be talking about 4096.  And then there's the connection keys, which is where the 128-bit SSL comes in.  So it would be more proper for websites to advertise both, that is, the size of their asymmetric public keys - which we'd hope would be 2048, but if they're 1024 that's okay, too - and also their 128-bit SSL, but everybody has that.  When you have SSL, you're going to have that level of security.



So again, the short answer is there are, because there's two different types of cryptography, there's public key and private key, or also known as asymmetric key, where you have different keys for encrypting and decrypting, and symmetric key, where you have the same, the asymmetric or public keys are much bigger because they need to be much bigger to provide an equal level of security due to the way their technology works, which is different than symmetric keys, which can be much shorter to provide an equivalent amount of strength.  So that's why.  It's like the websites aren't really telling you the whole story.  They're sort of using what everybody else says.  All connections use both types, one long one and one short one, and that gives us the security that we need.



LEO:  It's just that simple.  So in other words, don't worry.  It's okay.  It's meant to be that way.



STEVE:  It's good.  It's all good.



LEO:  Steve Gibson is the man in charge at GRC.com.  That means you can go to GRC.com for lots of things, including of course the world's best hard drive maintenance and recovery utility, SpinRite.  Now, Steve, if you make a big change and make it Mac compatible, how much is that upgrade going to cost?  You going to charge people for upgrading?  Do you know?



STEVE:  Don't know.  I've got a bunch of things that I've got to get done.  And then I want to then, as I have mentioned, I mean, it's not even on the horizon yet, but I know what I want to do for what I'm calling 6.1, and it is to free it from the BIOS. 



LEO:  Free it.  Free at last.



STEVE:  Free it from the BIOS.  And I want to update it for a number of things that have happened.  Western Digital has 4K sector drives.  They're these hybrid drives that use both some EEPROM and some hard drive storage.  There's secure erase capability.  I want to give it stronger Serial ATA support.  It works now, but sometimes users have to go in and reconfigure things in the BIOS for SpinRite to see it.  I just want to make things easier and better.  That's my short-term goal.  And then the longer term goal is to take a look at Mac and the EFI and all of that.  But so it's not happening...



LEO:  It's not going to happen tomorrow.



STEVE:  It's not going to happen tomorrow.  And but we will absolutely, as I always have, protect people who purchase, and then there'll never be any regrets.  We still allow people to upgrade SpinRite 1.0 from 20-plus years ago and get a discount on SpinRite 6.  So 6.1 will definitely be free, so there's no reason not to get it now.  When we do 6.1, that'll just be transparent.  Everyone will be able to upgrade, for sure, no charge.



LEO:  So go to GRC.com, get SpinRite, get it now, with confidence.  You should also, while you're there, there's lots of free stuff.  And browse around.  You'll be amazed.  You won't believe the variety there, including this show.  He's got show notes there.  He's got transcriptions, text, as well as 16Kb versions.  On our site, TWiT.tv, we've got the high-quality audio, the video and that.  And of course you can watch the show live, it's always fun.  We usually have some pre-show conversation about coffee, food, vitamins, the stuff that we try to keep out of the podcast.  So if you like that stuff, tune in a little early, 11:00 a.m. Pacific, 2:00 p.m. Eastern at TWiT.tv, that's 1800 UTC, every Wednesday unless we move them around.  But you can always find the calendar - by the way, I don't know if we say this enough - on TWiT.tv.  That's where you'll find out where all our shows are.  I posted on Google+ the schedule for today.  We have, like, I mean, we do a ton of shows.



STEVE:  We may not have you next week; right?



LEO:  Next week, I'm not sure.  Eileen just - I don't know.  I'm in Vegas.  We do our NAB coverage.  Here comes Eileen, running, running, running.  We're going to do this show on Friday, Steve.  So expect an email.  We're moving it to Friday at 9:00 a.m.



STEVE:  Ooh, I love it.



LEO:  Aren't I lucky.  I picked it, apparently.  But we didn't tell Steve.  So now he knows.  So next week it'll be Friday, 9:00 a.m. Pacific, 12:00 noon Eastern time, and we'll do the show then.



STEVE:  Perfect.



LEO:  Thanks, Steve.



STEVE:  I'll be ready.



LEO:  Consider that your notice.  He's also on Twitter, @SGgrc, and of course - where else?  Oh, if you have questions for Steve - I knew there was something else - and you want to be on the next feedback episode, which is in two weeks, GRC.com/feedback.  There you go.  There you go.  Somebody's saying, "Which Friday?  What are you talking about?"  That would be April 20th.  So instead of April 18th, we'll be on April 20th because our coverage, wall-to-wall coverage of the National Association of Broadcasters show starts Monday, goes through Thursday of next week.  We're all going down to Vegas.



STEVE:  Perfect.



LEO:  Thank you, Steve.



STEVE:  Thanks, Leo.



LEO:  Thanks for being here, and we'll see you all next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#349

DATE:		April 19, 2012

TITLE:		Cloud Solutions

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-349.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's news, Steve and Leo examine ALL of the various cloud-based synchronizing, storage and backup solutions they could find.  Steve surveys each one in turn, and Leo chimes in with his own personal experience with many of the offerings.  They conclude that SpiderOak looks like the winner, though Jungle Disk is still in the running.



SHOW TEASE:  It's time for Security Now!.  And Steve Gibson's doing something I'm so excited about.  Have you seen all the different cloud storage solutions?  There's SugarSync and Dropbox.  There's Carbonite.  There's Jungle Disk.  It goes on and on.  He's taken a goodly number of them, looked at the security ramifications of each, the price, and more.  And he's got his review of something like a dozen cloud storage services coming up in just a little bit.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 349, recorded April 19th, 2012:  Cloud Storage Solutions.



It's time for Security Now!, the show that protects you, your loved ones online; your privacy, too.  And here's the guy in charge, our Explainer in Chief, Mr. Steve Gibson.



STEVE GIBSON:  Oh, Leo.



LEO:  Uh-oh.



STEVE:  I really went down the rat hole this week.



LEO:  You were going to do - when you talked last week, you said we were going to cover something that I actually like a lot called SpiderOak.  You and I have been looking at a lot of cloud storage solutions like Dropbox, Wuala, SpiderOak, Crash - I mean, there's a lot of them.  And I'm really looking forward to it because I just kind of empirically - maybe not even empirically, maybe a little less scientifically - chose SpiderOak, and I've liked it a lot.  But so I'm very curious what you think.



STEVE:  Well, so what happened was I started to look at it.  I contacted them, and they know us and were standing by in case I had any questions.  But when I mentioned last week that SpiderOak was going to be the topic of this week, I started getting all of this Twitter feedback from people saying...



LEO:  But what about...



STEVE:  ...well, what about BoxCryptor?  What about CrashPlan?  What about blah blah blah?  And I was just like, oh.  And some guy said, well, hey, I thought you liked Jungle Disk?  What about Jungle Disk?  And so I started to look at some of these others, and one thing led to another.  And so I ended up putting together notes for Bitcasa, BoxCryptor, Box.net, Carbonite, CompletelyPrivateFiles, CrashPlan, Cubby, DigitalBucket, Dropbox, Google Drive, Jungle Disk, HiDrive, Livedrive, Porticor, SecretSync, SkyDrive, SpiderOak, SugarSync, Tarsnap, and ZeroBin.



LEO:  [Laughing] I think there are a few you left out, Steve.



STEVE:  I know.  That's the problem.  Like Wuala.  When you just mentioned it, I thought, ooh, that's not on my list.



LEO:  Oh, one more.  No, no, no, no, stop, stop, stop.  Stop the madness.  Because I think this is a fair sampling of the choices out there.



STEVE:  Well, yes.  And just as I was putting this together, then the rumor, which has been circulating for some time, as you mentioned before we began recording, is that next week, maybe on Wednesday, Google is going to drop Google Drive on the world, and with 5GB of free starter storage and who knows what features?  So then I thought, well, ooh.  What if that's really a good thing, and I've spent all this time digging deep?



Now, I have to say, among all of those that I just enumerated, there are a bunch that are just sort of like, okay, this is not the right solution.  For example, Dropbox still in their terms of service explains that they're able to decrypt their users' data if the government issues them a warrant requiring them to do so.  And interestingly, there are some add-on gizmos.  A couple of things I read are encryption add-ons.  I think SecretSync is that, or maybe it's SugarSync.  I can't remember.  Anyway, I've got it.  We will be covering it here in a minute in order to, like, solve those problems.  Other companies, they're sort of like enterprise-style, big-iron, don't even care about your privacy.  I mean, it's collaborative stuff where other people can be editing your documents.  It's like, okay, well, if that's the case, then that's not probably providing us the security that our listeners want.



However, I found some new things, to me, that are really worthwhile.  So that's our topic for today is not just SpiderOak, but pretty much everybody that I could find.



LEO:  [Laughing] All right.  Well, as usual, we're going to start with security news.  Then we'll get to the cloud storage services.



STEVE:  Yes.  Several people tweeted me the note that Google had abandoned their plans for improving SSL latency.  Remember that we talked about this months ago.  Google had a pilot project, I think it was running for about a year and a half, where they were fudging the SSL spec as part of their overall "let's make the web go faster for everybody" plan, of which SPDY, for example, that we covered in detail several weeks ago, is a part.  Well, SPDY, of course, runs on an existing connection.  And one of the things it does is it's very good about helping you minimize the number of connections that you need.  And we've seen benchmark results that are very impressive when we have SPDY.  And SPDY seems to be gaining traction rapidly.



But what Google also wanted to do was to try to minimize that initial connection between the client and the server.  And so they were sort of fudging the way SSL works to get more done per back-and-forth transaction.  And they, pretty quickly - being Google, of course, they can have spiders roaming the web, and do, while they're doing searching stuff.  They found some servers that were incompatible with this trick of theirs.  And they went so far as to special-case those relatively few domains in Chrome so that Chrome would normally do the tricky SSL handshake maneuver when you were just using it unless you were connecting to any of those that Google had independently determined were going to have a problem with Chrome doing that, in which case it would back off to regular SSL.



So what the news was last week, and this came actually, I think, the first time, I have a note here, a Steve Styffe, he sent me the first awareness that Google had abandoned their attempt to make SSL faster.  And I looked at Google's blog posting about this, and basically it explained that it was always sort of a grey area.  They acknowledged that it was beta.  They just felt that - they were working with the environments which were incompatible, trying to kind of boost them into compatibility.  But it looked like the equipment manufacturers that were using SSL accelerators were the problem, and they just weren't able to make any headway there.  SSL accelerators are, for example, appliances with crypto hardware to do the SSL public key stuff, which we know is time-consuming in hardware, to accelerate that handshake.  And just because they're locked down in hardware, Google was never able to make any progress in getting that fixed.



So they decided, rather than sort of having what even they admitted was a flaky solution of Chrome needing to know who it was going to have a failed handshake with preemptively, which just is not very practical because new companies are going to be setting up SSL accelerators, and Chrome won't know about it, and things won't work for them.  So that's not good.  So they canceled that.



However, part of the SPDY protocol does allow the specification from the server that it supports this advanced handshake.  So there is still a way to sort of keep it alive within SPDY, but not just in general.  So I thought it's neat that they tried this.  I'm really very bullish on these efforts Google is making to lay down this technology and set standards.  We need someone to do it, and no one better than them.



Also, shortly after, might have been the day after, maybe the hour after we recorded last week's podcast, where we were talking about the Java exploit that was affecting Mac OS X to such a degree, and that Apple had released a patch for it, but we were expecting them to follow it up with a remover.  But at that point we didn't know when that was going to happen.  Well, it happened probably as the podcast was going public.  What's really interesting is what more Apple did.



I tweeted the fact that people - I tweeted to my Twitter followers that Mac users should check for updates again because Apple had just issued a second one to work with this.  And Apple, from their own page, said, "This Java security update removes the most common variants of the Flashback malware."  So in addition to fixing the Java exploit, it's a remover.  "This update also configures the Java web plug-in to disable the automatic execution of Java applets," which is to say they are disabling the Java plug-in as part of this.  "Users may reenable automatic execution of Java applets using the Java preferences application.  If the Java web plug-in detects that no applets have been run for an extended period of time" - and they don't tell us how long that is - "it will again disable Java applets."  So...



LEO:  Wow.  That's probably good; right?



STEVE:  Oh, it's fantastic.  But it's also huge news.  I mean, this is Apple saying, I mean, we already know they're moving away from Java.  They're not going to be bundling it with future versions of the OS.  So in their testing that's probably been working out well for them.  So they've gone, I mean, really another big step of, first of all, disabling it by default.  And even if you turn it back on in order to use some Java something on the 'Net, if you're not a frequent user of it, it will shut itself down again.



LEO:  So that's the key is that, if you do get somewhere where you need Java, you have a kind of a checkmark or a box that says, yeah, turn it back on.  I presume that that's how they'll do it.



STEVE:  Right.  It'll say you need Java installed in order to use this.  And you go, oh, I've got it here somewhere.  And then you go turn it on.  But if you leave it on, then it'll shut itself off again, which is just great.  I mean, I have to say I'm a little sorry for it because I'm, I mean, I can really see the benefit of Java.  I mean, look at this fantastic network analyzing tool...



LEO:  Netalyzr, yeah.



STEVE:  ...that we talked about for buffer bloat.



LEO:  And one of the most popular games out there right now, Minecraft, is Java.  So there are people, still quite a few, millions for Minecraft alone, who use Java.



STEVE:  Yeah.  And, I mean, it caught my attention, the fact that you could do that kind of network work in Java, and you get platform independence, it's like, ooh, boy, that might be something I'd like to learn for offering who knows what.  Like I need any other projects.  But anyway.  So I was just - a tip of the hat to Apple.  I'm impressed because, unfortunately, nice as it is to have it, I mean, what you'd really like is on-demand.  You'd like to go to a website that needs it.  You enable it for that site.  Maybe much like NoScript gives us that kind of control now over Java, for example, over in Firefox, either enable it for that site, or enable it and have it, like, disable when I shut down the browser, like enable only while I'm using the computer because, as we know, the smaller your window of opportunity is, the less chance you're going to get hit.  And Java had this problem that Apple didn't jump on as quickly as they should have, and they got bitten by it.



I did promise everyone last week that I would make time to analyze the Dropbox tech blog where they were proposing and put out all the code for what they were saying was a realistic password strength estimator.  And I just forgot, actually.  Well, by the time I saw it in my notes, it was like, oh, crap, I forgot.



LEO:  You've got plenty of other stuff to do.  I think we can live with that.



STEVE:  Yeah.  So I bumped it to next week, and I will try to make time to give it a long going over.  Lots has been happening with me during my non-podcast life, Leo.  I actually have invented something.



LEO:  What?  Really?



STEVE:  New in computer science.  I've had it for about a month.  And I described it to a couple of the people in our newsgroup who are the high-end coder-capable people, and they're like, wow, that is - and this is what I've been talking about.  It's the thing I've been working on all year so far, which I am excited to share with our listeners because it's just a real interesting piece.  But it looks like it's a really clever algorithm, which as far as I can tell is completely new, and it solves a problem no one has ever been able to solve before.



LEO:  Cool.



STEVE:  So anyway, I will be sharing that before long.  I did get a tweet from Robert D. Walker, who is a listener, who said, "OS X 10.7 did significantly improve ASLR [Address Space Layout Randomization] and 10.8 will be improving it even further.  You misstated that on Security Now!."  So I said, "Whoops," and went to look.  And sure enough - because I had said that Apple had added ASLR, Address Space Layout Randomization, a long time ago, promised to fix it, but hadn't.  And that was correct, except that I didn't realize it did get fixed just recently in .7, and apparently, so says Wikipedia, it's even going to get better in .8.  So I did want to - I wanted to correct that.



And, oh, Simon Zerafa, who tweets often and is a listener and a participant in the newsgroup, informed me of an interesting site, IsJavaExploitable.com, which is a nice way to go and see whether your Java, which we were just talking about relative to Apple, is current.  So I had to tell NoScript to let it run, and then the site said, oh, yes, congratulations, you're using the latest Java.



LEO:  Oh, that's good, that's good.



STEVE:  Yeah.  So it's a nice place.  If anyone's worried, IsJavaExploitable.com will tell you very quickly.  And he also tweeted, just I thought this was sort of fun, things that we've said before, but he put it together.  He said - this is Simon again.  "If you didn't go looking for it, don't install it.  If you installed it, keep it updated.  If you don't need it, uninstall it."  Which...



LEO:  That's good.  Very simple.



STEVE:  ...is just exactly right.  Oh, and one last tweet from Eneko Bilbao in Australia.  He said, "Re iOS encryption, took your advice, upgraded to alphanumeric PIN.  When changed, does it reencrypt the file system?  If so, it was very fast."  And so I thought I would just take this moment to explain that no, the file system is not encrypted using the PIN; but rather there is a pseudorandom long key which is your file system encryption key, and that is encrypted using your PIN.  And so that allows you to - so the only thing that is stored in nonvolatile memory, where it could be captured, is the encrypted version of that key for your file system.  And so when you correctly put your PIN in, then that allows that encrypted token to be decrypted, allowing your file system then to be accessed.  So, and that's the way most of these things work.  For example, if you have an encryption password on a hard drive, same thing happens.  You're actually encrypted the encryption key, rather than what you're providing actually being the encryption key.  It's a second sort of a one stage of - programmers would call it "indirection," one stage of indirection, but gives you the same level of protection.



And lastly, I just had a fun note that was shared, reminding us that SpinRite can be used on strange things.  Ben Stool wrote, he said, "It works great on TiVos.  Just a note" - and this just came in on the 16th of April.  "Just a note to tell you that SpinRite works great on TiVos.  I read about it on your website and heard Steve mention it on Security Now!.  Our eight-year-old DirecTV TiVos were starting to act funny.  So I pulled both 80GB Western Digital drives from them, connected them one at a time to a Windows XP Service Pack 3 desktop, and ran SpinRite at Level 5.



"Interestingly, both drives reported no errors and finished in a little over four hours each.  However, when I put them back into the TiVos (after blowing an embarrassing amount of dust out of them), the TiVos are back to normal.  These are first-generation DirecTV TiVos, but we like them and do not want to pay the high premium to go to the new HD DirecTV TiVos that were recently released.  SpinRite has let us keep our old friends going.  Ben Stool, Dallas, Texas."  So thanks very much, Ben.  You can use it on anything.



LEO:  Steve Gibson has done a lot of research and is now going to give you a brain dump.  Stand back.



STEVE:  So I didn't know what order to put these in, so I just thought, well, let's go alphabetical.  Now, Bitcasa we have talked about in the past.  And I did not have a chance - it was on my list, and I just ran out of time before I was able to do a deep dig into it.  This is the one people may remember which is unlimited file storage because they're doing a duplication elimination, so multiple people are sharing the same files.  It was sort of controversial.  And I have a link which I didn't follow, which is "The biggest problem, Bitcasa is not safe."  And it's like, okay, well, I don't know what that means.  So I just don't - it's on my list here, and I didn't want to skip it; but I don't have anything new to add to the prior information that we had about it.



I did get several people who tweeted, what about BoxCryptor?  It's sort of an interesting solution.  It's primarily a Windows solution, but they also have Android and iOS clients, so it has a mobile side, too.  There's a file system known as an Encrypted Filesystem - EncFS, sort of harkening from the way Linux labels its file systems.  This encrypted file system was designed relatively recently.  It's open source.  And whereas a system like TrueCrypt that we've been talking about encrypts at the block level so that all of the individual sectors are individually encrypted, this EncFS, this Encrypted Filesystem encrypts at the file level.



What that means is that it's more friendly for a cloud-based solution than something that encrypted at the block level.  In fact, it's not clear how you could do encryption of a file system at the block level and then remote it to the clouds.  In their pros and cons, they talk about that, since they're not encrypting blocks, there is a little bit of metadata leakage, "metadata" meaning the file organization stuff.  For example, if somebody looked at your encrypted file system, they could see how many files you had because, sort of like the directory tree itself they could see, the file names are encrypted; but they're rounded up to the block size of the encryption, which, for example, if it's 128 bits, that's, what, 16 bytes.  So they could sort of guess the filename lengths within - with an accuracy of within 16 bytes.  So it's that sort of leakage.



They do support, as I said, primarily Windows.  And Mac and Linux are able to mount - Mac and Linux already support natively this, well, or as an add-on, I should say, this encrypted file system, which allows you then to mount this BoxCryptor thing on your system.  They have a license - essentially, if you're a Windows user, you download their gizmo, and you select the source directory, which will store the encrypted data.  And then you assign that a drive letter.  So what you see is a drive letter in Windows into which you can store anything you want.  And when you put things in that drive, sort of that pseudo-drive, then it's actually performing on-the-fly encryption and storing, and sort of dynamically creating a file system in the directory where you've told it to.  And this is friendly, then, with being uploaded and shared.



So they have a free version - and this is sort of a problem I have with these guys is they sort of put some arbitrary limits on it.  It's not clear why they did.  But I guess they want to make some money from this.  There are other free solutions, I think, which are maybe superior.  So for free you can get up to 2GB of storage and a single drive  mapping.  For $40, unlimited personal, I mean, unlimited storage and any number of drives.  And then just if you're a business user they want $100.  Now, that is a one-time fee, so you're buying the license to the utility.  You can put it on any number of machines.  And if you then have some way of synchronizing folders, then this will provide the encryption side.  So it's sort of an interesting solution.  I'm not super gung-ho on it.



There's an Android version, and they want $6 for unlimited personal use and $9 for unlimited business.  And their iOS version doesn't look very impressive at all, actually.  I think it was like - you're limited to, like, three uploads or something, then it locks, and so you have to do an in-app purchase to unlock it for about the same amount of money as for Android.  So it's an interesting solution.  It's sort of like I'm not sure that it really, I mean, if you had some means of synchronizing folders, then adding this to that can give you strong encryption.  As far as I know, the encryption is based on a well-designed encrypted file system, and so it would qualify for Trust No One (TNO), which we'll be hearing that acronym a lot here in the next 45 minutes or so because many systems do explicitly support Trust No One, and many others don't.



Also when I was looking at this, there's a company called Box.net.  And it's funny because their domain is Box.com, but Box.net is what they call themselves.



LEO:  They were Box.net for a long time, and then they bought and were able to acquire Box.com.



STEVE:  Okay.



LEO:  So I still think of it as Box.net, but Box.com works.  It's very confusing.  I don't blame you for being confused.  But they've been around.  They may be one of the oldest that's still around.



STEVE:  Yes.  And they sort of look like it, too.  It's like, okay, well, I mean, it felt to me like maybe they weren't up with the times.  I couldn't see any clear support for mobile stuff.  You get, for their free version, single user, is a limit on file size of 25MB, and 5GB of storage.  And that's - so you get 5GB of storage, but with a per file size limit of 25MB.



LEO:  And that's kind of killing.  That's a terrible limit.



STEVE:  Isn't that random?  Yeah.  It's like, what?  Okay.  But if you pay them $10 a month, then you can get 25GB and 1GB per file, so that's certainly useful.  And at twice that amount, $20 per month, you can get 50GB and 1GB maximum file size.  Except that, as we'll see, those are on the high side, pricewise.  For example, just for comparison, something that still is in the running is Amazon's S3 service or Rackspace's service with Jungle Disk because they're $0.15 per GB per month.  So that would be...



LEO:  They also charge for bandwidth, so you've got to include that.



STEVE:  Well, Rackspace doesn't.



LEO:  Rackspace doesn't.  Jungle Disk with Amazon does.



STEVE:  Correct.



LEO:  So with Rackspace there's no bandwidth charge.  Oh, I didn't know that.  That's good.



STEVE:  Yeah.  And so, for example, at 25GB, these Box.net - and this is, again, we'll be talking about price because I know people are interested.  Box.net is $10 a month, but Rackspace or Amazon for the actual 25GB of storage, are $3.75.  And that's one of the other things, too.  Everybody wants to put you in this plan.  And I hate plans.  It's like the whole cellular phone business where you buy this many minutes.  Well, okay.  But if I don't use that many, then I've overbought.  One of the things that I really like about Rackspace and Amazon is you're paying $0.15 per GB rather than committing to some size of plan, and then you pay more than you're actually using unless you use right up to what that limit is.  So anyway, just something to keep in mind.  And I will say that Box.net does have a business plan, instead of these personal plans, which gives you 15 - I wrote $15 per month and a terabyte, but that's less expensive than the $20...



LEO:  That can't be right.  Nobody gives you a terabyte.  Nobody gives you...



STEVE:  No, that's something - something wrong with that.  So anyway, if anyone's interested, check it out.  Now, in my perusal I did, of course, run across one of our sponsors, Carbonite.



LEO:  Which does not position - I want to be clear upfront - does not position itself as cloud storage.  It's a backup solution.



STEVE:  Correct.



LEO:  But you do get cloud storage.



STEVE:  Well, and as we'll see, there are a number of sort of services that are becoming sort of generic.  There's the idea of synchronizing multiple machines.  And several of these services that we'll be talking about offer free synchronization where, for example, you can install this on as many things as you want, and they'll keep them synchronized, but that's different than storing in the cloud, the idea being that they all share a folder on their own hard drive, and then this thing keeps them synchronized.  And Dropbox, I guess, operates that way.  But then you can also do storage in the cloud.  And then most of these services now have a mobile component, allowing people to access these files, sometimes stream music, look at pictures and so forth, from iOS or Android devices.  So there's, like, different...



LEO:  That's how they're distinguishing themselves, I think, because you can't just do raw storage.  It's like, well, what do you add to the raw storage?  What is your unique point of view?



STEVE:  Right.  Now, I like, I mean, having looked at all of these, I have to stay Carbonite is still in the running, in my opinion.  They're $59 per year per computer, and unlimited storage, which is just a nice thing to have.  One of these companies that we'll get to does something really interesting, which is, to get you bootstrapped to them, they'll send you a hard drive, which you use locally to back up your machine, and then send it back to them.



LEO:  Oh, that's neat.



STEVE:  That solves the problem...



LEO:  That's interesting.



STEVE:  ...yeah, of, like, a multi-hundred gig through the cloud to get yourself set up the first time.  And then of course they install - they dump that hard drive into their own servers and then catch up any changes that have been made since then and then continue.  And they'll reverse the process.  If you crash, and you've got hundreds of gigs in their cloud, you can say, oh, my god, I need my data now, and they will send you...



LEO:  Here's your hard drive.



STEVE:  ...all of your data on a hard drive.



LEO:  Wow.



STEVE:  But anyway, so back to Carbonite.  We'll catch up with that...



LEO:  Now, just to be complete, it is unlimited.  But they do tell you they throttle after 200GB.



STEVE:  Right.



LEO:  So I just want to make sure that people don't get a false impression of that.



STEVE:  So $59 per year per computer, which is, what is it - and I have, I wrote down here $5 per month, so I guess that's...



LEO:  Yeah, it's roughly five bucks a month, yeah.



STEVE:  And support for Win, Mac, iOS, Android, and BlackBerry.  Although they've got some advanced features which are currently still only the Windows platform only.



LEO:  Right.



STEVE:  And then under PIE - Pre-Internet Encryption - where are they on Trust No One?  Reading from their own disclosure, they said in their FAQ, "Can Carbonite employees see my backed-up files?"  And they wrote, "Access to your backed-up files is protected by your encryption key which is kept strictly confidential.  Unless you choose to manage your own encryption key (see below), a limited number of Carbonite employees are able to access backed-up files in order to assist with data recovery if needed.  However, they will do so only after obtaining your consent."



And then they said, "If you are" - oh, and I loved this.  This is something I learned, actually.  "If you are subject to industry regulations that require no one outside your organization to have access to your backed-up files (e.g., HIPAA regulations)...."  So it turns out that being HIPAA-compliant requires TNO-level security, which is great because that's going to strongly encourage companies to go in that direction.  So they said, "If you are subject to industry regulations [blah blah blah] Carbonite provides you with the option to manage the sole copy of your encryption key.  If you choose this option, features such as Anytime Anywhere Access" - which is their web-based viewer, and I think your mobile also is the same way, those will be unavailable to you.



"Also note that, if you lose the sole copy of your encryption key, there will be no way for Carbonite to restore your backed-up files.  For these reasons, Carbonite recommends, and the majority of our customers choose, to have Carbonite manage their encryption keys."  But it is significant that, if you decide to, you're able to have them do the job for you.  I mean, you're able to accept responsibility, and they will not have your key.



Then I mentioned add-ons to non-encrypted solutions, and there is a company, or an offering, called CompletelyPrivateFiles, which offers encryption for Box.net.  So that's an example of that kind of add-on.  Again, Box.net's pricing didn't seem particularly compelling.  And then this CompletelyPrivateFiles company wants to charge you additionally for that.  Zero dollars for up to 5MB file size, $30 per year for up to 15MB files, $50 per year for up to 25MB files, and $80 per year for up to 50MB files.  So they're charging you for the size of file that you can use them to encrypt to get stored on Box.net.  So [buzzer sound], I don't think they make it.



Okay.  CrashPlan is the company I was just mentioning.  And every time I say "CrashPlan," I think, boy, couldn't you have chosen a more optimistic name for your company?  I mean, I don't know.  It's catchy, I guess, and that's what it's for.  It is multiplatform:  Windows, Mac, Linux, and Solaris; iOS and Android and Windows Phone mobile.  And the mobile apps are free.  Some of these people do charge, as we saw before, a few dollars for the mobile version of their gizmo.  And this is just at CrashPlan.com.



And they say on their site, "How is CrashPlan different from other online backup services?"  They say, "Unlike ordinary online backup, CrashPlan lets you back up to other destinations in addition to online.  You can back up to your other computers, external hard drives, and to computers that belong to friends and family for free.  If you want to back up online, too, purchase a CrashPlan+ subscription for home use.  To back up your business data to the cloud, check out CrashPlan PRO or CrashPlan PROe.



So, pricing-wise, their free plan gives you no storage, but you're able to use this multiplatform set of clients - again, Windows, Mac, Linux, Solaris, iOS, Android, Mobile Phone - to do intermachine backups.  So that you're essentially using storage that you, presumably on a different machine and/or different location or friends and family have, to do your backup.  So they're not offering any cloud storage; but they're offering, for no money, the technology for synching all this stuff together.



Their CrashPlan+ is $2.50 per month, which is for 10GB.  But then they have a one-year, two-year, three-year, four-year commitment discounting you all the way down to a dollar and a half per month if you commit to four years.  And you're able to then back up 10GB and a single computer for that price.  Then the CrashPlan+ Unlimited is unlimited amount of storage for $5 per month, which runs down, if you make a four-year commitment, down to $3 per month.  Now, that's getting to be pretty good.  Think about that.  $3 per month, well, of course you've got to commit to four years.  So $5 a month, one computer, unlimited.



Then they have Family Unlimited, which is two to 10 computers at $12 per month.  So this is scaling pretty nicely.  $12 a month - and if you commit to four years, it's half that, $6 a month - unlimited amount of storage, two to 10 computers.  And then this is the company that I mentioned that has what they call "seeded backup."  They ship a drive, and for a one-time fee of $125, so it's not cheap, but the idea is it will back up your entire machine.  You use their client to back up your entire machine to this drive, which you then return to them.  They dump into their cloud, and that short-circuits - or as they call it, "seeds" - their backup so that you're not spending lord knows how long transferring how many hundreds of gigs up to their cloud.  And for the same price they'll reverse the process, if you need to get your data back.



And I thought it was sort of funny because they change the security encryption strength depending upon whether you're free or not.  The free plan uses 128-bit Blowfish, and all the other plans are 448-bit Blowfish, which is great security.  We know that Bruce Schneier designed it.  And it's got a slow key schedule setup, which is good for security because it makes it much more difficult to try to brute force it.  And they do offer full, although optional, TNO-level security.  So you can set it up with what they call a private password, which is used to decrypt the encrypted encryption key, and with all the standard caveats.  If you lose that, they can't help you.



But so this is some interesting packages that may fit people because, at a reasonable price, it's widely cross-platform, two to 10 computers, unlimited storage for as little as $6 a month, covering all of that, if you go with them for four years.  And again, I have no experience with it.  This is just pulling all the data together and drilling down to figure out how they work.



Next up is something that looks like it's sort of a Dropbox clone called Cubby, as in a cupboard.  They support Windows.  They have a Mac desktop app, Android, and iOS.  And they distinguish themselves from Dropbox because, whereas Dropbox has, like, the Dropbox folder that you get on your machine when you install the Dropbox client, these guys allow you to share any of the folders that you already have on your machine by dragging and dropping those folders onto their app.  And then that folder becomes shared with this Cubby.  So this allows computer or cross-computer sharing, unlimited peer-to-peer cross-computer synching of the shared folders.



They say that it keeps unlimited versions of friend-shared files.  So I guess, as I understand it, if you share files with friends, and there's a means to do that, and they alter the files, then this is keeping versions of those.  And then you also get a free 5GB.  We're going to see a lot of this.  It makes Dropbox's free 2GB look a little stingy now.  Everyone pretty much seems to have gone to 5GB for their free offering.  And I should mention this is from the company LogMeIn are the people that produce Cubby.



However, nowhere, anywhere that I could find, was any mention of security, encryption, and privacy.  That is, that just is missing from their site.  It's all very nice and polished looking.  But they don't tell us anywhere about what they're doing for us from a security standpoint.  So it's like, okay, until I knew that, of course, if that was a concern for people.  And I love the idea that HIPAA regulations require this.  So maybe they'll be addressing that in the future.



I ran across something called DigitalBucket which I didn't spend much time at.  There's no Trust No One option.  They use Amazon S3 cloud storage as their backend cloud provider.  And they're expensive.  An individual plan is $99 per year for 50GB.  Their professional plan is $30 per month for 100GB plus three subaccounts.  And their small business plan is $125 a month, that's a lot of money, for 500GB and 10 subaccounts.  So it's like, okay, well, I was following some links and thought, well, what's DigitalBucket?  And it's like, well, doesn't sound like it's for us.



LEO:  It's a terrible name, too.



STEVE:  I know.  I thought exactly the same thing.



LEO:  Spell it carefully.



STEVE:  So proceeding alphabetically, after DigitalBucket we come to Dropbox.  We know that they're free.  They give you 2GB, which as I mentioned seems a little stingy these days.  $10 a month or $100 per year, and we'll see that many people we're going to encounter offer you essentially two free months if you sign up for a year, is what everyone seems to be doing, probably cloning off of Dropbox's policy.



LEO:  And they do an affiliate - you get a link that you can ask others to use, and then you get extra storage.



STEVE:  Oh, boy, strong social networking on these sites.



LEO:  Very viral, yeah.



STEVE:  Oh, boy.  Yeah, I had to keep clicking through all that.  It's like, yes, yes, I know.  It's like, you're three clicks away from an extra 250MB.  It's like, oh...



LEO:  I find that very annoying.



STEVE:  I do, too.  It's like, okay.  If it's good, I'll recommend it, but I'm not doing it because I need an extra quarter gig.  So for $10 a month or $100 a year, you get 50GB in the cloud.  Or for twice that, you get twice that much storage.  And it's interesting because, for example, $20 a month is, if you stored all - if you filled up 100GB at $20 a month, then if we compare that to Rackspace or Amazon, that same 100GB only cost you $15 per month, and that's only if you use it all.  Again, it's like, the idea of signing up for such a huge amount of storage and having to pay a fixed amount of money sort of rubs me the wrong way, relative to Amazon or Rackspace, where you're really only ever paying for what you use.  I'm an S3 user.  I'm still using Jungle Disk with Amazon.  And I get a little ping in the email every month saying, oh, we just charged you $3.15.  It's like, okay.  I like that.  Because I have a ton of stuff up there, all Pre-Internet Encryption, from Jungle Disk, that we'll get to here in a minute.



And so also from Dropbox, under security, under their "Compliance with Laws and Law Enforcement" section, they said, "As set forth in our privacy policy, and in compliance with United States law, Dropbox cooperates with United States law enforcement when it receives valid legal process, which may require Dropbox to provide the contents of your private Dropbox.  In these cases, Dropbox will remove Dropbox's encryption from the files before providing them to law enforcement."  So I salute them for being clear, but it's clearly not providing anyone protection who wants that kind of protection.



Consequently, we will run across a couple solutions.  It's one of those "Sync" things, either SecretSync or SugarSync.  I think it might be SecretSync.  In fact, I'm sure it's SecretSync because SugarSync I was very impressed with, and SecretSync is just sort of encryption for Dropbox to solve this problem.  Alphabetically proceeding, we hit Google Drive.



LEO:  But one thing I want to say about Dropbox, one of the reasons I use it, I know it's a bad deal, because every app, for instance, on the iPad and the iPhone has an interface for it.



STEVE:  Yes.



LEO:  And so it's convenient, even though - I guess that's what I'm paying for is the convenience; right?



STEVE:  Yeah.  And it is very popular.  I didn't want to leave it out.



LEO:  Popularity is why it wins.



STEVE:  Yes, yes.  And I did not want to leave - well, in fact, you and I were using it for quite a while.



LEO:  I still use it.  I wish I didn't have to because I know I'm paying a lot more than - I love Amazon, or Amazon S3 using Jungle Disk, which you turned me on to.  And I'm going to have to use Rackspace now because that's even better.



STEVE:  Yes, because no transit cost.  What I like about - I ought to just take this moment to say what I like about S3, Amazon, is the apps we use to talk to it are decoupled from it.  I'm buying the storage and transit, which in my case isn't much.  Mostly I'm using it for archival stuff.  But I'm not dependent on some company that I don't know about and don't know if they're going to be here tomorrow.  Essentially, I don't know, it seems more granular to me.  I like that I'm only paying for what I'm using.  And, for example, there are many S3 frontends.  There's a beautiful frontend for Firefox that I really like where I can just open this - it runs in the browser.  I open my Firefox and I'm looking at this really nice S3 Explorer app add-on for Firefox.  So I like the idea that I'm not being insulated from my files by sort of an all-encompassing Big Brother, don't worry, we'll take care of you sort of thing.



And so Google Drive.  We don't know what it's going to be.  We've heard the rumors that it's going to be 5GB, which would be keeping with the current what you get for free these days.  Drive.google.com now resolves, but doesn't have anything on it yet.  And the rumors are that we'll see an announcement next week.  So we'll see what they're going to offer and what it'll be.  I'll update, obviously, everybody with that news when we know.



And again, it was a tweet that reminded me about Jungle Disk, the thing that I use.  Good multiplatform support - Windows, Mac, Linux, iOS, and USB.  And Leo, do you know, were they purchased by Rackspace?



LEO:  Who?



STEVE:  Jungle Disk.



LEO:  Oh, yeah.  That's why they - yes, that's the whole point.  They got bought by Rackspace.  And they continue to offer their S3, but obviously Rackspace gives you a better deal.  And it's otherwise the same, I would guess.



STEVE:  Yeah, well, they've moved forward.



LEO:  I thought, when they bought them, I was a little nervous, to be honest.  I thought, oh, boy.



STEVE:  Yes, yes.  And back in the day, when we first encountered Jungle Disk, I purchased the lifetime something or other for $20, and they're still honoring that.  They do have something else, I think it might be the web access, which they don't bundle in if you were grandfathered into the original deal.  But for Rackspace you pay only for storage.  And as I said, it's $0.15 per gig per month, with free transit and free requests.  I say that because Amazon actually charges you by request.  It's not much, but it's not nothing.  So Amazon is the same storage price, but there is a transit fee for moving data back and forth.  I think it might be $0.15 per gig and $0.15 per request.  So it's really not meant to be a CDN.  Amazon has other offerings that are much more content delivery network oriented.



For me, I like it because Jungle Disk we absolutely know is Pre-Internet Encryption.  You put the password in, Jungle Disk encrypts it locally, and it goes nowhere else.  And their USB version is cross-platform, that is, it's Win, Mac, and Linux all bundled into a single thing which you then - you can put it on a USB drive, and you stick it in whatever computer you're at, no matter who made it, essentially, Windows, Mac, or Linux.  And Jungle Disk figures that out and runs, which is neat.



Now, they offer web access to cloud files, but I don't know how that works with Pre-Internet Encryption.  We know that it's possible that the decryption could occur in your browser, if you provided that key.  But might be that web access is only available if you don't encrypt with your own key.  And that is an option.  You have the ability to do that or not, as you choose.  But if you do, it's full TNO security.



And, let's see.  Oh, they also offer public sharing of specific files.  So of the stuff that you've got stored up there in your Jungle Drive, you can get a web URL and set a date of expiration, which you can then share with other people.  So you can email this URL to someone and say, hey, here's a file I want you to grab, go get it at this link.  They do put a maximum of 5GB on file size and 50 downloads per file, saying that it's not their intention that this be a free content delivery network.  But that gives you some security.



Anyway, so I'm still a Jungle Disk user, more from inertia than anything else and also because, as I've said, something feels right to me about the use of Amazon and only paying for the storage I'm actually using and because I'm not a big - I'm not using it to constantly back up my system, so there's not lots of transit that I'm paying for.  I think, if that were the case, I would opt for Rackspace as my storage provider, and then we get free transit, which makes a lot of sense.



I ran across HiDrive, which is from a company called Strato, and they're not U.S.-based.  I remember - I didn't write down where they were, but I noted, because prices weren't coming up in dollars, that I had to convert to dollars.  Nothing really jumped out about them for me.  They're iOS, Android, and Win Mobile 7 for their mobile side.  5GB for free, as many people are now doing.  $13 for three months, which seemed odd, and they call it a "three-month commitment," and that gets you 100GB; or $39 for three months gets you 500GB.  And on the security side I'm not impressed.  They mention, probably because they're European, ISO 27001 certification.  That is, they're compliant with that.  But who knows what that means?  That didn't - I even...



LEO:  Only somebody in Germany knows what that means.



STEVE:  Yeah.  I looked it up, and it's like a long Wikipedia page of gobbledy-gook.  And it's like, okay, well, I don't think anyone's going to be jumping on these guys anyway.



So Livedrive.  Good multiplatform support - Windows, Mac, iOS, and Android.  Although I kind of got kind of a creepy-crawly feeling from these guys.  On their homepage they say, "Resellers, sell online backup and more.  Sell our full range of online backup, storage and sync products to your customers.  Custom brand everything, manage it all from the web.  Sell unlimited backup accounts from just $59.95 per month, instant setup."  And it's like, okay.  That's - okay.



LEO:  That always makes me nervous, too.  That's, yeah.



STEVE:  Yeah, it just sort of seems a little slimy somehow.  So they have their offerings.  $8 a month is backup with no storage limit for one computer, and additional computers $1.45 per month.  $16 per month is their so-called "Briefcase" plan, where you get 2TB and Windows and Mac synchronization, and you can also share it with friends and family, specific files.  So that's cloud storage with ability to access it.  $25 per month is their "Pro Suite," which brings you up to 5TB.  And they store 30 previous versions of files.  They can restore deleted files and stream music.  And for $8 you can add NAS backup.  So they will back up your own local network-attached storage to the cloud.



And they're, as many people, purchase for one year and get two months free.  But again, it's like, okay, I think they're, I mean, obviously this is a huge and exploding market segment with cloud storage being the buzzword these days.  And so there are a lot of companies that are there, and it's not really clear to me what they have to offer.



I ran across, speaking of that, a company called Porticor that seems very enterprise-oriented because $162 per month.  It's like, ooh, okay.  I'm not sure...



LEO:  [Whistling] Wow.



STEVE:  ...who they're appealing to.  But you can register for a free evaluation, Leo, if you'll give them your email address.  And so I said, uh, I don't think so.  Yeah.  And when you do that, you get three virtual disks at 2GB per disk, and then they start sending you email.  So, uh, no, thank you.



Okay.  SecretSync is what I referred to before.  What they're doing is they're an add-on for Dropbox that puts another folder on your desktop, and anything you drop in there, they pre-Internet encrypt before dropping it in the Dropbox for you.  So it uses the Dropbox API, probably.  But it's not free.  You get up to 2GB of encryption in that encrypted folder for free.  But it's $40 per year to expand that to 20GB of encryption, or $60 per year for a terabyte.  So of course that's their own metering of the encryption.  Then you have to pay Dropbox's fees for the actual storage.  So it's like, okay, well, they're there.



LEO:  That's why I rejected that one.  I didn't want to pay twice.



STEVE:  Exactly.  And of course, going alphabetically, we've got Microsoft SkyDrive, which, eh.  It doesn't seem to have any strong Mac support, not surprisingly, although there is an SDK available for apps, although only apparently running Windows, iOS, and Android.  Now, Microsoft does give you more free storage than anybody, 25GB, I didn't see anybody that was at 25GB, with a 2GB per file limit.  They do support - SkyDrive supports Windows, iOS, Windows Phone, and Windows 8 Metro-style.  But again, no real clear focus on security.  No explanation about how keys are handled or crypto and so forth.  And I wouldn't be at all surprised if they also can and would respond to someone telling them that they need to hand over your data.  Do you know anything more about SkyDrive that's beyond...



LEO:  Well, I think it's going to expand.  The thing is you're working with Microsoft.  So at some point they're going to add to it.  It's probably enterprise-focused.  It does support the mesh synching, but only 5GB of that can be dedicated to Live Mesh synching.



STEVE:  And it does have a nice web interface, too.



LEO:  And Mac.  So, yeah, I mean, I think it's something.  It doesn't seem to play at the same level as some of these other solutions, however.



STEVE:  No.  And the 25GB is kind of compelling, except, like, well...



LEO:  You can't really do much with it.  There's no, for instance, there's no interface; right?  There's no - you want to be able to mount it, for instance, as you do Dropbox.  That would be cool.  You can't do that.



STEVE:  Exactly.  Exactly.  So, SpiderOak.  I'm impressed.  Good platform support - Windows, Mac, Linux, iOS, Android.  They are really upfront.  I mean, these guys, what hooked me immediately was they have what they call their "Zero-Knowledge Privacy" policy.  They don't want anything to do with your key.  You don't have an option to give them your key.  You can't misconfigure this so that they have your key.  They never get it.  So, I mean, and that's just like a big deal for them.  And of course we know for certainly a segment of our listeners, that's a big deal.  Certainly is for me.  I'm not sending my data off to the cloud without it being encrypted.  That just isn't what's going to happen.  My company's accounting data, and backups of images of my main machine which is up there, that's going to be encrypted.



I'm probably going to spend some time looking more closely at them because they are saying they offer things which seem really interesting.  So you get 2GB for free.  That seems, again, five seems to be the norm now, but for these guys 2GB.  But if you want 100GB, that's $10 a month, and they also do the two free months per year, so $100 a year if you did it for a year with them.  That buys you 100GB.  And as soon as you cross 66GB, that's the breakeven with Amazon and Rackspace.  So if you're storing less than 66GB on the 100GB plan, Amazon or Rackspace are cheaper for storage.  But if you're doing more than 66GB, then SpiderOak is cheaper.



So under their list of features they say backup, sync, share, access, and storage; multiplatform support we know, Mac, Linux, and Windows; they're 100 percent zero-knowledge privacy, so they're just storing pseudorandom data.  They're storing noise for us.  Any number of computers at no additional cost, so you're just paying for storage, and there's no transit cost.  They say "storage and time-saving de-duplication."  This is one of the things that I'm interested in.  It's like, okay, how are they doing de-duplication if they're doing pre-Internet encryption?  So that's something I'd like to understand.



They said "perpetual deleted file and historical version storage."  So they're also doing some versioning of some sort.  And they're saying they're saving deleted files forever.  So you can go all the way back to the beginning of when you started using them.  And then, this is interesting, 10 to 15 times faster than traditional backup solutions.  So it's like, what?  Okay.  And I've got the name of the techie there who I can have a conversation with because I'm interested in what they're doing.  And they make a big point of being wholly fault tolerant.  So the idea is not only is it in the cloud, but they've really looked at being fault tolerant.



Now, I noticed also in perusing that they say they securely synchronize folders across multiple computers and operating systems using their free online sync.  So you pay for, as I said, $10 a month or $100 a year for 100GB.  But then synchronization is free.  So, and on any number of machines you're able to use SpiderOak for performing synchronization.  And they say "discreetly share selected folders with friends, family, colleagues, and clients."  So, now, this is interesting because they must be doing it and maintaining TNO.  So I want to find out how that works because presumably, I don't know if you have to install their client in your friend's, family's, or colleague's machine, or if that's a web-based interface.  And I think it's web-based because they have something called "Share Rooms" where you can share folders instantly over the web in share rooms, and then you can also subscribe to an RSS feed to be notified of modifications in there.



And under "Efficient Versioning" they said, "SpiderOak keeps historical versions of every file.  This is an extremely important safety feature in a backup application.  Consider this scenario:  You accidentally save over your thesis paper with a different document.  The easy solution is just to go back to your backup software and retrieve the old version, except what if you don't notice for a few days?  If your backup software doesn't keep historical versions, it will save the new wrong version of your thesis into your next backup, making recovery impossible.  SpiderOak's historical versions are space efficient.  Even though your historical versions are encrypted and only stored on the server, SpiderOak detects the similarity between those historical versions and your new versions, only saving the parts that actually changed."



Now, somebody tweeted something that's kind of ringing a bell here.  There was some mention of not wanting to store data redundantly on your own machine.



LEO:  Ah.



STEVE:  Yes.  So maybe...



LEO:  That's how they do it.



STEVE:  Yes.  So maybe what they're doing is they're creating an archive region on your hard disk.  They're seeing the differences and maintaining that and then encrypting and only sending, for example, the deltas after encryption up to them so that there's a way to piece this all back together.  I mean, that, as I'm reading this, the thing that I remembered someone saying is they didn't like the idea of, like, this blob of space being taken up on their hard disk.  That may be what SpiderOak is doing.



I should mention, though, and actually this came from another tweet, apparently they've got work to do over on iOS because their iTunes store reviews for the iOS client are, like, horrifying.



LEO:  Really, really, huh.



STEVE:  It's one star, and people just shuddering at how bad it is.  You have to, like, remove it and then reinstall it, and then it kind of works.  And I just think that they - I don't know what the - I'm sure they'll explain to me, if I pursue this, what's happening over there.  But that's not the client, apparently.  People are trying to use it to read PDFs, and it's doing horrible things to them.  So...



LEO:  I think - I'm looking at a SpiderOak interface.  And it says here, there's a checkbox that says "Keep my own copy of all archive data blocks."  So you don't - looks like you don't have to.



STEVE:  Ah.  Okay.



LEO:  "Enabling this option will cause SpiderOak to send a copy of all new encrypted data blocks to the location you've chosen.  SpiderOak will then check this location first when restoring data.  This can increase the speed of larger stores."  Oh, maybe this is just - I don't know if this is where the versioning - maybe not.  Maybe this is just for bandwidth-limited folk.  It has, I mean, a slew of features.  I mean, this thing is amazing.  So I've been using it for some time.  I haven't had to restore from it at all.  But I'd be very - so you're going to do some more conversations with them.



STEVE:  Yes, yeah.  Because of all the offerings, I feel the same way.  This is one that, like, survived this whole process of looking closely into the corners.  And we're down to three left.  Actually, really only one because the other two don't qualify.  In fact, I'll do them first.  I'll go to "Z."  ZeroBin, I ran across it, somebody mentioned it, I figured out what it was.  It's an encrypted Pastebin.  So we're familiar with Pastebin, which is sort of just random catch-all.  Anybody can put stuff up there.  Of course the malware/script kiddie kind of folks and hackers use it as a rallying point, essentially.  But everything normally is in the clear.



And ZeroBin is browser, that is to say, client-side encrypted Pastebin.  So you could upload a file, protecting it with a password, and then get that password to someone else somehow.  I was going to say email, but you want to do it over a secure channel somehow.  And then they're able to get and decrypt it, to download it into their browser and then decrypt it.  So it's sort of a means of having 'Net-shared files which are cryptographically secure because they use AES-256 encryption in the browser.  So in case that was useful to anyone, I just wanted to note that it exists, called ZeroBin.



Then the other one that sort of didn't - I didn't spend much time on is Tarsnap.  I'd run across it before.



LEO:  I like the name.



STEVE:  Tarsnap.  No Windows support except through Cygwin, which is the library for sort of limping along with Linux or UNIX support under Windows.  They do support BSD UNIX, Linux, OS X, and Solaris.  And they provide storage at twice the price of Amazon for storage and transit.  So I'm not sure what they have to say for themselves.  But that's as far as I went with those guys. 



The last one is a company called SugarSync.  And, boy, they've got the widest platform support I've seen.  Win, Mac, iOS, BlackBerry - you don't see BlackBerry except, what was it, I think Dropbox offered BlackBerry also.  So that's uncommon.  Android, Symbian, Kindle Fire, a web interface, and an Outlook plug-in that gives you access.  They have a comparison chart with comparing themselves to lots of other people.  Of course it's their comparison chart.  So every one of the things that they compare against has a green dot on them, and various of the other guys are missing dots in various places.



And it's, until you get up to the really big storage, it's not even compatible with Amazon or Rackspace.  You get 5GB free, as most people do; 30GB at $5 per month or $50 per year, so that's also the two free months deal.  60GB for $10 a month; 100GB for $15 a month; 250GB for $25 a month, or 250 a year, for example; 500GB at $40 per month.  So it wasn't until you got to 500GB at $40 per month that pricing was better than Rackspace or Amazon.  Otherwise, on all those other ones, you were paying more than Amazon or Rackspace and, if you weren't using all of that storage, then paying a lot more than those guys.  It does allow you to back up any folder.  So it's a little bit like Secret - no, not SecretSync.



LEO:  [Laughing] You're losing track now, aren't you.



STEVE:  I'm losing track.  One of those that I talked about.  But it does not look like they support TNO-level security at all.  So not at all clear what they're, I mean, everybody, of course, supports secure transit, just even using just SSL.  But I saw nothing that convinced me that these guys were really good from a long-term storage security standpoint.  Their storage is expensive.  Huge cross-platform support.  But again, it's not clear how secure our stuff is.  So of all of those things, Leo, I think you chose wisely, SpiderOak.



LEO:  Interesting.  Because I did not get as comprehensive as you did.



STEVE:  Yeah.  I don't know, what was it, Wuala, now that I'm...



LEO:  Yeah, Wuala has an unusual idea, which is that you contribute some of your hard drive space to the Wuala...



STEVE:  Ugh.  Okay.  I'm out of that.



LEO:  I knew that would give you - and if you want more, it runs in Java, just in case you wanted another reason not to do it.  So I don't think you have to worry about Wuala.



STEVE:  Okay.  I don't know who I forgot.  I'm sure Twitter will let me know.  But of everything we just looked at, I mean, I am still using Jungle Disk for now.  I like it.  I like the incremental, pay for what I use.  Although I am on S3, so I'm paying for transit.  If I were doing a lot of stuff, SpiderOak is no charge for transit, cross-platform.  As you said, it's got features coming out of every pore.  And, boy, are these guys security conscious.  So I want to find out how they do what they say they do.  I imagine we will have the podcast I thought we were going to have this week, which is really, really drilling down deep into SpiderOak to figure out how they work.  And maybe we'll figure out what's wrong with iOS because I don't think they quite have that figured out yet.  But other than that, I like everything I see.



LEO:  Apparently Wuala got rid of the space-sharing feature, so maybe others had the same reaction that you had to that.  That's actually why I did it, because I wanted to get - because it's free if you donate 100GB or whatever.



STEVE:  Right.  And so, like, they're encrypting somebody else's data on your drive.



LEO:  Yeah, exactly.  Maybe pieces thereof.  Pieces thereof.



STEVE:  There are some interesting ways, using state-of-the-art block-level error correction, where you can sort of spread your data out among some - it's almost like a RAID, where you spread your data out among some number of nodes.



LEO:  Right, exactly.



STEVE:  And you don't need every one of those nodes to be alive in order to...



LEO:  I believe that's what they're doing, exactly.



STEVE:  ...reassemble and essentially do ECC on the data to algorithmically work around what's missing.



LEO:  Right.  I should say that's what they were doing because they don't do it anymore.  According to the chatroom, anyway.  Yeah, good.  Well, this has been really, really valuable.  And you see there's nothing perfect out there.



STEVE:  Yeah.  And, well, and what I wanted to do was, when I realized how many choices there were, I thought, okay, wait a minute, let's step back and get an overview, like what's going on out there?  And our sponsor, Carbonite, if, for example...



LEO:  I'm pleased to hear that they're good.



STEVE:  I set Jenny up with Carbonite because she doesn't need all these kinds of features.  She just needs her laptop protected.  And that's a good price for unlimited storage of a laptop, of a single machine.  It makes, I think, lots of sense.



LEO:  There is a Wikipedia article called "Comparison of File Hosting Services" that has a very large chart with checkboxes and things that might make it a quick way to kind of get a survey of features in many, many, many, many more.  I don't know how many they're doing.



STEVE:  I'm glad somebody else did that.



LEO:  Yeah.  And we're going to do - we have a new show we're launching, Iyaz Akhtar and I are going to launch a show, a how-to show.  And one of our first episodes, I think it is our first episode, how to roll your own cloud services, using things like Pogoplug.  So that might be the best way to do it.  If you've got a couple of - you need, of course, in order for it to work, you need a couple of premises so that you aren't all in one spot.  But I think it's possible to do your own, as well.  Certainly a lot cheaper.  Depends what you need.  And yes, I don't know how accurate the Wikipedia article is or whether vendors go in and modify it and all of that.  It's really not a review.  It's more like a list of features.



STEVE:  Oh, and that's super useful.  I mean, the one thing that I liked, although I didn't like SecretSync because they didn't talk about security, and they were pricey, but it was interesting to see their - well, and of course it is their comparison chart.  But it was interesting to, like, sort of see them lined up next to a bunch of these other guys because all the other players are there, too.



LEO:  This does not seem to have any information about pre-Internet encryption, which is unfortunate because that's, for us, the thing we care most about.



STEVE:  Oh, Leo.  If our data is going to go up to the cloud, it's got to be safe.



LEO:  Yeah, yeah.



STEVE:  I mean, it just has to be.  So, yes.  From all of this, as I said, I'm using Jungle Disk, but I'm going to be looking closely at SpiderOak.  And they were really responsive to saying, hey, we'll tell you anything you need to know.  So I expect I'll start using it a little bit, see if it, like, passes just the usability test.  But you are using it and have been for, what, a year?



LEO:  Yeah, a year, yeah.



STEVE:  Oh, okay.  Cool.



LEO:  Yeah, yeah.  I use it, mostly I use it to sync the computers, my documents folders across a bunch of computers.



STEVE:  Nice.



LEO:  And of course, as a side effect, you get a backup, as well.



STEVE:  Yeah, and that's free.  The cross-machine synching is just thrown in.



LEO:  Right, right.



STEVE:  Cool.



LEO:  All right, Steve.  Steve Gibson lives at GRC.com.  That's where his Gibson Research Corporation is hosted.  You can get SpinRite there, of course, the world's best hard drive maintenance utility.  You must have it, if you have a hard drive.  But he also has lots of free stuff which I highly encourage you to check out, GRC.com.  Next week a questions episode, so post your questions there, GRC.com/feedback.  There's also a users group there, a forum for people to share their security tips.  Oh, there's so much stuff.  And of course this show.  And he offers 16Kb versions and transcriptions, which we do not offer at TWiT.tv.  So if you need a small file, or you want the transcription, GRC.com.  We do this show normally Thursdays, so - go ahead, I'm sorry.



STEVE:  I was going to say we don't have - I was just about to say we don't have you next week; right?



LEO:  Yes.



STEVE:  You're off in Norway or something.



LEO:  I'm going to Norway.  We do this show Thursdays at 11:00 a.m. Pacific.



STEVE:  Wednesdays, Wednesdays.



LEO:  I'm sorry, Wednesdays at 11:00 a.m. Pacific.  We're doing it Thursday because I was out of town for NAB, and we had already done iPad Today.  Those of you tuning in for iPad Today, I'm sorry to have disappointed you.  However, we've already done it, and it'll be on the feeds any minute now.  And we're going to replay at, I think, 11:00 - I'm sorry, 1:00 p.m. Pacific tomorrow, if you want to watch live-ish.



STEVE:  So I'll be here regular time.



LEO:  11:00 a.m. Pacific Wednesday.



STEVE:  Wednesday.  But not with you.



LEO:  With Iyaz Akhtar, I think.  But I'm not sure.  Might be Tom Merritt.



STEVE:  Yes, yes.



LEO:  All right.



STEVE:  Iyaz is what Eileen and I talked about.



LEO:  Good.  Then that's who it'll be.



STEVE:  Cool.



LEO:  All right.  Hey, thanks, Steve.



STEVE:  Thanks, Leo.



LEO:  Thanks, everybody, for joining us.  We'll see you next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#350

DATE:		April 25, 2012

TITLE:		Q&A #142 / Cloud Security

SPEAKERS:	Steve Gibson & Iyaz Akhtar

SOURCE FILE:	http://media.GRC.com/sn/SN-350.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  During this special Q&A episode, Steve and Iyaz host an entirely Twitter-driven Q&A episode, caused by the flurry of interest created by last week's focus upon Cloud Storage Solutions.  After catching up with the week's security-related events, they zip through 21 tweets, then focus upon and examine the security architecture of one controversial and popular cloud storage provider:  Backblaze.



SHOW TEASE:  Coming up is Security Now!.  Leo is out, but I'm here.  But Steve, thankfully, will answer all your questions via Twitter.  He'll cover the latest security news.  And he's going to answer the question:  Is Backblaze really secure?  No, is it really, really secure?  Steve knows, and he's going to tell you.



IYAZ AKHTAR:  This is Security Now! with Steve Gibson, Episode 350, recorded April 25th, 2012:  Q&A #142 / Cloud Storage.



It's time for Security Now!, the show that keeps you safe online.  Now, obviously I'm not Leo Laporte.  He's off in Norway.  I hear he's hanging out with some fjords or something, taking some photos of them.  If you're following him on path, you probably are seeing this, or on Twitter.  But I'm Iyaz Akhtar.  I'm filling in.  But thankfully, of course, we have the star of this show.  We have Steve Gibson, you know, from GRC and SpinRite, pretty much, has pretty much saved you so many hassles because, if you listen to him, and you watch this show like I do, you know that you get so much smarter just listening to Steve.  So, Steve, thanks for being here, and hopefully you can guide me through this episode because I'm new to hosting Security Now!



STEVE GIBSON:  Well, as Tom has demonstrated, there's really nothing to it.  So I'm sure this will work very well.  We have - our normal protocol is to alternate every other week with a Q&A.  And this is nominally - and so this would be a Q&A week, following up on last week's topic, which was Cloud Storage.  But the cloud storage topic in general is just so big and so hot right now.  And of course just in the last day or two Google did finally unveil their long-anticipated Google Drive.  Almost in synch with that, Microsoft upped their SkyDrive storage to 25GB free for anybody who'd been using it before as some sort of loyalty bonus or something.



And naturally security is a huge, I mean, maybe the huge question surrounding cloud storage because it's one thing for us to have our own local hard drives and be, like, trying to keep our machines free of viruses.  It's another scale of security concern to be sending files that we may have varying degrees of concerns of privacy about out into the cloud.



So the good news is we absolutely know that we have the technology to do this safely.  Crypto provides us absolute - the acronym that we've developed here on this podcast is TNO, Trust No One, meaning that we're able to send off blobs of noise, pseudorandom noise, which no force on Earth, as far as we know, can reasonably decrypt, and put that out there for storage, and then get it back.  And so last week we talked about a number of these things.



Well, the topic and the issue of security generated a huge response on my Twitter feed.  And so I began noting these.  And I normally have a, like sort of a "From the Twitterverse" section of the podcast every week where I grab a few of the most significant, or tweets that I think would be interesting to our audience, and share them.  Well, this time it just dominated the topic, the issue of cloud storage.  And many people brought up very good points.  So this Q&A is the first one we've ever had which was 100 percent driven by Twitter, rather than the normal Security Now! slash feedback, or I guess it's GRC.com/feedback, feedback page.  I didn't even get to the mailbag.



But then something else happened, which is several people who are our listeners are using a cloud storage service called Backblaze.  And it's not one that we covered last week of the dozen or so that we did.  And when I went to - and so they tweeted, saying, hey, I've got more than, like, a terabyte.  Like I think one guy's got 1.2TB up at Backblaze and is very happy with it.  And I went to the site and dug around, and it did not look to me as if they had done their security right.  I mean, not really wrong, but their pages were very confusing.  Pretty pictures, but it just didn't look right to me.



And so I tweeted a few tweets that I'll read toward the end of the show which generated even more furor.  And the CEO and cofounder of Backblaze sent me a tweet saying, hey, Steve, I'd like to understand what your concerns are.  So because this is an important issue, I wrote him a note outlining what my problems were, and he responded with a detailed reply, and I responded.



So I want to catch up on the news, we've got some news this week, and run through these 21 tweets of comments pretty quickly.  And then I want to look closely at Backblaze because they look like they're a great company.  There's no reason to mistrust them.  Their security is as good as many other cloud storage solutions.  So, I mean, it's not like this is horrible and everyone should go running away from them.  But they say that they're offering something that they're not.  And that's the key.  This is, unfortunately, this is a perfect example of people using powerful crypto tools, but not in the right way.



And so it's sort of a great little case study.  Again, I'm not suggesting people run from them.  I'm just suggesting that, unfortunately, their documentation is so poor that people believe they're getting security that they're not.  And that often happens.  I mean, I don't mean to be singling these guys out.  But that was the question that I got asked by Twitter followers.  And for everybody, I think what they're doing and the way they're doing it is just a perfect little case study.  So that's what we're going to do this week.



IYAZ:  So we're going to go through all these tweets first, or...



STEVE:  Well, let's catch up on news.  There is, just in the last day or two, Microsoft Security Essentials came out with v4.0.  Mary Jo Foley reported in ZDNet that what she had had was 2.something.  And she wasn't sure whether they skipped over 3, or maybe she hadn't updated to 3 or what.  But 4.0 is now available.  It is showing as "important," an important update in the regular Windows Update deal.  So you don't have to go get it.  But if you Google just MSE, just the acronym, Microsoft Security Essentials, it's the first link that comes up.



And so you can manually download it, or you can go check with Microsoft Update or Windows Update, depending on what it's called on your machine.  You'll find it listed, currently, not for immediate self-download and install, but you can check it, and then it'll download.  It's about 12MB.  I think it's 10 for the x86 version, 12 for the 64-bit version.  And Microsoft says it's better, so that's what we should use.  When I fired up this machine to set up our Skype connection, I verified that in fact it was available.  I downloaded it.  Install did not make me restart the machine, so that was nice.



So I'm just letting everyone know.  And a tip of the hat to Simon Zerafa, who told me, gave me the heads-up that this thing was available.  So it's, as we've discussed this before, Security Essentials is Microsoft's antispyware, antimalware, antivirus tool, sort of for people who refuse to purchase one of the alternative commercially available ones.  This one is free.  Some head-to-head lineups show that it's not quite as discriminating as other tools.  It doesn't quite find as much as the commercial guys.  But I say it's a lot better than having nothing.



IYAZ:  Yeah.  Microsoft's big thing, I mean, Windows is so popular, it gets attacked all the time.  And when Microsoft went ahead and put in their defense stuff, I mean, that's important.  You really have to have [indiscernible].  And having something is better than nothing.  So even though people knock it, just have something.  I mean, that's always safe.



STEVE:  Yeah.  And I've got a good friend who someone else set up a Vista machine for her a couple years ago.  And there was a trial version of I don't know what, Trend Micro or something.  And it worked for however long the trial is, 90 days, six months, a year, who knows.  And then it began bothering her for money.  And so that's when I got the call saying, "Steve, this thing is telling me that my trial of Trend Micro has expired.  Do I have to pay them money?"  And my answer was, eh, no.  Remove that and install Microsoft Security Essentials, and you'll never be bothered for money again.  So for someone like that, who's not a hardcore security person, who otherwise would have nothing, this makes more sense, especially if paying something for it is more than they're willing to do.  So, yeah, I completely agree, Iyaz.



Also Firefox v12 has happened.  When I - I was at 11.0, and I have famously recently made the move from - I was way back.  I was staying back in 3 land until they finally fixed their memory problems, which they finally did, despite several claims to have done so but not, until they got to 11.  All I did was do - I went under Help and About.  That brought up the dialogue and immediately prompted it to start downloading No. 12.  So it's about a 7MB update.  There's a number of ongoing fixes, bleeding-edge features and protocols that they're adding.  They're heading toward what Google has done, which is the seamless, in-the-background update.



What's significant about 12 is that they have an architecture now using a service, a Windows service.  The service is not running all the time, but they're able to start it up when they need to.  It has the privileges of the system to allow it to update the files which you would normally have to pass through the User Account Control window to allow.  So this is their way, with v12, they've bypassed User Account Control.



Now, I get - I have a little bit of what we call on the podcast a "Gibsonian reaction" to that because one hopes that they've done this safely and securely because potentially this means that there is a service that Firefox users now have in their system which, if abused, could install anything on their system.  So I'm sure the Mozilla people know that and that they've - somehow they've created authentication and crypto and whatever they need to in order to do this securely.  It certainly is a convenience that Firefox is able to do this.  I did have to restart Firefox to go from 11 to 12.  As I understand it, their goal for the next major release, v13, is they'll get full seamless background updates and just be fixing Firefox for us, very much the way Chrome does, where it's just always, as you're using it, you're using the latest version.



IYAZ:  Steve, now, you installed Firefox 12.  Is there an option to turn off the automatic updates after you turn it on?  Because, I mean, if you have extensions and things, couldn't these things break over time because you're just automatically updating?  I mean, I was cleaning out one of my old computers, and I found Firefox 1.5.  And, like, I'm not letting it go.  I might need this later on, just in case.  But, I mean, can you turn off some of these, I guess, convenient features that could be a problem?



STEVE:  I'm sure it's configurable. When I brought up the Help > About box, it immediately started downloading it, although I did have to tell it to go ahead and do its thing and perform the update.  It then did run through all my add-ons and verify that they were compatible with this version.  So in this case, for me, going from 11 to 12 was painless.  But I'm sure - I remember when we were talking about this initially, that they were going to be doing this, that this background update, because some people would be uncomfortable with it, or maybe corporations are still saying we need - we're a Firefox house, but we still don't want this happening without IT first taking a good hard look at what's going on.  So that may very well have happened.  That is to say, I'm sure there is a way that you can disable that behavior.



IYAZ:  [Indiscernible] the automatic updates are just on the Windows version.  As far as I know, the Mac version doesn't allow that just yet.



STEVE:  Ah, okay.  Good to know that.  Now, a couple weeks ago we were talking about iOS password managers in some depth.  And one of the things that I ran across indicated that, depending upon your upgrade path from iOS v3 to 4 and to 5, it might be that you did not have the whole-device encryption actually running that iOS 4 and 5 have offered, due to the fact that it might not have been present, well, it wasn't present in 3, but it might not have gotten activated.  And somebody was kind enough to send me a tweet with the details.  Unfortunately, that got lost in my Twitter feed, so I can't give him credit.  But on TidBITS.com is an article where the author explains exactly how this can happen.



Now, the good news is it's easy - both things are easy.  It's easy to tell what your current state is, and it's easy to fix it if it's wrong right now.  So on the Passcode Lock settings screen of any iOS device, phone or pad, if you see the words at the bottom, "Data protection is enabled," then you're golden.  That means that you have whole-device encryption running, not just some parts of the OS being encrypted as Apple was sort of moving forward in how much of the device storage they were encrypting.  So the Passcode Lock settings screen, if down at the bottom says "Data protection is enabled," you're good.



If you go there, and you don't see that, then you don't have whole-device encryption.  The way that can happen is, if you had the passcode enabled at iOS 3, and then simply upgraded to 4, encryption would not have been applied.  So there are probably some technical reasons that Apple was unable to do that, as evidenced by the fact that, in order to get it on, if it's not, you have to first - and so here's the steps:



Assuming that you're now on probably iOS 5, you first disable and remove the passcode from the device, so shut that down first.  Then backup the device to iTunes.  And you can just Ctrl-Click on it and then choose Backup in iTunes.  So that'll copy all of the device onto your local iTunes-based drive.  Then restore the device by clicking the Restore button on the summary screens in iTunes.  And this article says that he's been told that Ctrl-Clicking and choosing Restore does not work.  So don't use the context menu for restoring.  Use the Restore button on the summary screens in iTunes.  And once you've done that, then on the device reenable your passcode, and you'll then be secure and fully encrypted and of course go back to the Passcode Lock settings screen - that's where you would have been anyway to reenable your passcode - and verify that it now says "Data protection is enabled," and you've got whole-drive encryption running.



In this article he mentioned that he was the presenter in some sort of a conference of security professionals, and he had everybody in the audience look, and a disturbingly high percentage did not have data protection enabled, although they had passcodes on their machines that were running iOS 4 or 5.  So that was a small sample, but these were security-aware people, and this had just caught people off guard.  So I would imagine some percentage of our listeners are going to be in that condition, too.  Now we've got the whole readout on that.



IYAZ:  So there's no way to automatically do this.  You've got to go through this five-step process.  Which the first step, again, is to turn off your passcode.  So it seems like, so, wait, to get more secure you have to be less secure for just a little bit.  So there's no automatic way to do this.  It's just simply you've got to do these steps.  Just double-check, and then your whole device will be encrypted.



STEVE:  Right.



IYAZ:  Okay.



STEVE:  Right.



IYAZ:  So now I've got to check on my old devices.  This is good.  This is good.



STEVE:  Yeah, I think a lot of people are going to be doing that.  The good news is it's easy to see.  If it had been tough to determine whether you were encrypted or not, or if you had to do this, like, preemptively, and not know one way or the other, that would have been a big pain.  But it's easy to see whether you've got it already encrypted or not, and not that big a problem to fix it.  I imagine everybody who is a podcast listener, like this podcast, cares.  And so this will let them fix it easily.



Also, on the Mozilla front, something that we have talked about and anticipated has happened.  I got a tweet from Ron Chung, who his tweet is @directorronc, that Mozilla had released - in fact, I think when I first saw it, it was at beta, and now it's released - their native PDF viewer.  As we know, Chrome, one of the nice things about Chrome is they've got a PDF viewer built in.  You're not using Adobe's rather rickety platform for viewing documents.



So it was good news that Firefox would be getting a native PDF viewer, too.  It does exist.  They're calling it PDF - the file is PDF.js.  And what it is, is a JavaScript and HTML5 - I consider it an amazing capability demonstration.  The fact that you can render PDF files with JavaScript and HTML5 is phenomenal.  The bad news is, it's still not very usable, and it's not clear to me it's going to be.  If you absolutely refuse to use Adobe's plug-in, the Adobe Reader plug-in, and in fact I had the Acrobat plug-in that was a nightmare because it was, like, bringing up dialogues and complaining and all kinds of things.  I was finally - I finally moved over to Sumatra PDF browser plug-in, which I really like.  But for the sake of the podcast, I thought, okay, well, and I was hoping that this native HTML, I'm sorry, PDF viewer for Mozilla would be a good thing.



So first time I tried it, it didn't appear to work.  Well, that was NoScript blocking me.  You have to - and I should have looked, but I didn't.  I just thought, okay, well, it doesn't work at all.  Then actually I sent a tweet back to Ron, and he said, well, it did for me.  So I poked it a little harder.  And you have to permit something called "moz-filedata:" under NoScript, and I gave it permanent rights, and then it does work.  But, ooh, is it slow.  And again, it's amazing that they can do it at all.



So I would consider it a phenomenal capability demonstration, but there's no way I could use it because, as you scroll down pages, you get blank pages with a little wait spinner clock, and then the page renders.  And it does a very nice job, once it gets there.  But it's just - I don't know that it's ever going to be practical to render something that is written in a language as complex as, well, it's Postscript is what underlies the PDF format.  So this is JavaScript interpreting - which is largely interpreted - interpreting Postscript in order to do very sophisticated rendering.



To me, it's - you're always - a native solution, like Sumatra or like Adobe, is just going to do a far faster and superior job.  And given that we have Sumatra browser plug-in, which is free, and if nothing else it doesn't have as big a target painted on it as Adobe does with PDF vulnerabilities, I'm very happy with Sumatra.  But they may be able to advance it in the future, make it go faster, who knows.  Or maybe they'll end up writing a native PDF viewer themselves, much as Google did with Chrome.  But it does exist, and it's cool that it can even be done.



IYAZ:  Any alternative to Acrobat is always pleasant.  I mean, I remember when I'd see links to PDFs, it used to say, "Warning:  PDF" because that means it's going to try to launch an application.  And you might see that splash screen that says it's loading, like, a thousand plug-ins, and you're like, why does it take this long?  When Chrome came along with its built-in reader, it was actually pretty easy, to the point where there was a little JavaScript bookmarklet that you could say open with Chrome's or Google's PDF reader.  And now that Mozilla's got it, I mean, it's going to make it a lot easier to accept PDFs instead of going, I don't want to open that.  That's just completely...



STEVE:  Yeah.  Well, and of course, as we know, Adobe was trying to promote all their formats.  So they've got Flash built into their PDF reader.  It's like, okay, wait, wait, wait.  When did a document ever need to have Flash in it?  And yet it's been a multi-opportunity vulnerability for malware and malware authors in the past.  It's just a bad place.  So of course the - well, and scripting, too, scripting in the PDF.  So best practice is disable Flash, disable scripting in your PDF viewer, of all things.  So it just makes much more sense to have a dumber PDF viewer because dumber in this case is going to be safer since it is a large attack surface for people who are messing around on the web.



So this was just tongue-in-cheek.  Actually I tweeted something about "Here's a hoot" yesterday.  And I learned that there are some script bots watching Twitter feeds.  And if you ever use the word "hoot" in a tweet, then these things pick them up and retweet them to everyone in the world.  So it's like, okay, well, it's the first time I had used that word.



Anyway, Sophos, the well-known and good reputation security firm, put out a press release just recently that announced that - and this is what I thought was so bizarre - one in every five Mac machines harbors Windows malware.  And they have a link where they show a breakdown.  They took, using their own assessment tool, which was resident in 100,000 Mac machines, so they had a 100,000 Mac sample, one out of five of those machines contained Windows malware.  And so it's not going to be effective on a Mac.  It's like the wrong DNA.  It can't infect a Mac because all of its tricks are for Windows.



But of course what this represents is that there's just so much of this Windows malware around, and that something that's trying to infect you, for example, using a Java exploit, which of course Windows has shared - I'm sorry, Mac and the Apple have until very recently shared with the rest of the Java-using, largely Windows community.  When your browser has that vulnerability, the thing trying to infect you either doesn't know or doesn't care who the host is.  Chances are still, due to the install base of Windows versus Macs, that it's going to be a Windows machine, all other things being equal.



So it's just sort of bizarre that 20 percent of Macs have Windows malware on them, just because it's out there, and they picked it up surfing and doing things that were unsafe or with some sorts of add-ons, like maybe a Java exploit that allowed the stuff to get in.  Once it got there, it looked around and said, oh, crap, I can't do any - can't get up to any mischief.  I can't install myself as a rootkit or do whatever I was going to do.  But it's still a file sitting there.



And after that tweet I got two responses:  Rene van Belzen, who's in Bergen op Zoom, Netherlands, he sent back:  "About those Macs with Windows malware being ineffective, they still form dormant, yet potent repositories for Windows malware."  And of course he has a point.  I mean, it is bad, and you don't want it jumping off onto Windows machines on the same network or through any sort of vector.  So even though it's unable to get your Mac machine, it's still sort of latent evilness that's sitting there on your machine.  So if you find it, by all means, remove it.



And then William Ricker in Boston, he said:  "Unscanned Macs in mixed environments serve as carriers for Win malware if they have email or USB."  Which is sort of a variant on what Rene said.  So certainly good points.  Even though it is the wrong machine that's infected, it's still not something that you want around.



IYAZ:  Yeah.  When I first heard this story, the first word that came to mind was "carrier."  It's just like, okay, it's got this little disease.  And people who have Windows already were a little bit not so happy with usually OS X counterparts.  But now they have even more reason to be very suspicious when they're like, where's that USB key been?  What files are on this thing?  Because you try to open everything, you might find out that it's infected.  I mean, it's almost because OS X users have been lulled with the security, like, hey, look, nobody goes after us.  But they're downloading files like crazy from who knows where.  They can do sillier practices.  But they are downloading some infected files that, if passed around, could lead to disaster.



STEVE:  Yeah.  Another little tidbit coming back to something that we discussed years ago.  It came to light that the Firewire interface, the IEEE 1394 interface, which is pretty much fading into the background now that we have USB II and especially USB III, and what is that, is it Thunderbolt or something, whatever Intel's insanely fast next-generation serial interface is.



Anyway, what we learned, and we have discussed in the past, is that the Firewire interface is actually a serial bus connection to the machine it's installed on, and you have things like Direct Memory Access, so-called DMA.  And again, Simon Zerafa brought this to my notice, and so I want to thank him for it.  The abuse of Firewire is pretty much now going mainstream.  Over at BreaknEnter.org, under their projects directory is something called Inception.  And quoting from them, from their page, they said:  "Inception is a Firewire physical memory manipulation and hacking tool exploiting IEEE 1394 SBP-2 DMA."  SBP is just the acronym for Serial Bus Protocol, which is all Firewire.



Then going on it says:  "Inception was originally coded as a GPL replacement for winlockpwn, the Windows Firewire unlock tool made available by Adam Bolieu, a.k.a. Metlstorm.  Winlockpwn was quite stable against older Windows XP targets, but did not perform well against more modern operating systems like Windows 7, and it is not maintained anymore.  As of Linux kernel 2.6.22, Linux Distros ships with the new Juju Firewire stack, making winlockpwn obsolete.  Thus Inception was born.



"Inception aims to provide a stable and easy way of performing intrusive and nonintrusive memory hacks on live computers using Firewire.  It is primarily intended to do its magic against computers that utilize full disk encryption such as BitLocker, FileVault, TrueCrypt, or Pointsec.  There are plenty of other and better ways to hack a machine that doesn't pack encryption."



So to briefly refresh, the idea is that one of the forensics tricks that law enforcement will use or bad guys can use is to gain access to your machine while BitLocker is running, while TrueCrypt is running, while FileVault is running.  The point being that the cryptographic keys are available, they have to be available in real-time in order to be shuttling encrypted and decrypted data back and forth between your system and the hard drive.  And there is now rather well-developed technology that knows immediately where to look.  And if you give something access to your RAM, these keys are in RAM in the clear and can be immediately snarfed.



So the takeaway from all of this is - and we've said it before.  This reminded me to say it again.  Since Firewire is probably no longer an interface that you're using, if that's the case, just remove its drivers.  Maybe in the BIOS, if you can turn off the IEEE 1394 interface, disable it there.  Or remove the drivers, or disable it in the OS.  You just don't want it on.  It is a port into your system's RAM.  And standard security best practice, of course, is to disable and turn off things you aren't using and don't need.  This is near the top of the list for machines that have a Firewire port.  I mean, again, it's not like it's huge danger.  The hackers can't reach over from the Ukraine and access your machine's Firewire port.  But for physical access to the machine, if you really do have sensitive stuff there, this gets right in.



IYAZ:  So for users who don't have a Firewire port, should they be worried that somebody can just put in a PCIE card and put Firewire into their computer and then be able to access stuff?  Or is that like a crazy scenario?



STEVE:  Well, no.  In fact, I don't think that is such a crazy scenario.  Some of the Macs, for example, have the Firewire adapters for the PCIE cards that you're able to slip in.  And that probably gives you the same sort of access.  That is on the system bus.  So best to just disable those things, if you don't need them.



IYAZ:  Start putting hot glue into all the ports and PCIE slots.  You're like, forget it, nobody's getting in here.  Physical access always is trouble.



STEVE:  Yeah, it is.  I mean, and we've talked, for example, in the past about that whole freezing the RAM and taking it out of the laptop and then putting it into a different machine, like keeping it alive by bringing the temperature down.  It's like, okay, well, there's a physical access hack if ever there was one.



Once again I have to punt on that Dropbox tech blog entry where they talk about the realistic password strength estimator.  As you'll see, when you see what's in this podcast, I just did not have time to get to it and had no time during the week.  So I'm not forgetting it.  I'm pushing it into next week.  And I will keep it alive until I finally get to it.



Okay.  So, quickly, 21 Tweets from the Twitterverse.  Ahto Jussila, he says:  "Tarsnap is the only cloud tool I feel comfortable installing on server.  Client source is available.  There are bug bounties and a well-known author."  And so my reaction is that's 100 percent understandable.  Tarsnap is - it's Linux-y or UNIX-y.  So, I mean, and it's only for those platforms.  And I agree.  I like the idea of the visibility of an open source tool.  And so I just sort of wanted to acknowledge that posting.  Tarsnap was down near the end of the list because we did it alphabetically last week.  And I just sort of shrugged it off as, well, this isn't really for anybody.



But I stand corrected.  I think it is for UNIX and Linux admin-scale people who like the idea of a clean and simple and sort of knowable tool, rather than just assuming that they're linking this to something in the cloud, and it's going to be good.  It uses Amazon S3 and EC2 as its backend.  And of course I'm a big Amazon S3 user.  They do double the price, which puts it at - Amazon is about $0.15/GB/month, and actually Amazon seems to have dropped their price.  I think it's now $0.125/GB/month.  Tarsnap doesn't give you an interface to your own Amazon account, but it charges you for your use.  So they charge $0.30/GB/month, and they front for Amazon.  So they're using Amazon themselves, but you don't have direct access to it, for example, as you do if you were using Jungle Disk or one of the other S3 frontends.



And they also charge $0.30/GB/month for transit, for bandwidth, apparently in both directions.  Now, what's significant there is that Amazon and Rack- that Jungle Disk and Rackspace - no, I do mean Amazon and Rackspace as cloud providers are now both providing free upload transit.  Last week I thought that only Rackspace was.  But I checked, and Amazon has since dropped their upload fees.  Now, to me that's significant because, for example, one of the modes I operate in, and I'm thinking of this from the standpoint of a server, is in the wee hours of the morning I have something that wakes up on my server and takes a static image snapshot of my entire GRC server hard drive.  It's actually surprisingly small.  It compresses it.  Then it's encrypted, and it's sent up to Amazon.  So the idea is it's a win for me that I'm not seeing any upload fees.  I maintain a number of past images from prior days, and I have sort of a staggered backup policy that is implemented, so I've got a bunch of them there.



But so the point is that I am, every day, I'm sending a blob up.  I'm never bringing it back.  So all I'm being charged for is the storage, which is from my standpoint quite affordable.  And Amazon is, like, rock solid in terms of availability of the data.  They can have, the way their redundancy is set up, they can have two entire of their datacenters go down, and you still have real-time access to everything.  So I'm quite bullish on Amazon.  They're just so big that you get the advantage of that.  And if you do your encryption on your end, then - believe me, there's no way I would be sending this stuff anywhere unless I was encrypting it first, and I was the only one who ever had the keys.  But the idea of free upload really works in this sort of scenario where you're highly weighted in the direction of sending stuff to the cloud, only needing to get it on the occasion that you're needing to recover from some calamity or for some reason to get a backed copy.



Moving on, Greg Bell, who tweets as @ferrix, he said - oh, also about Tarsnap.  He said, oh, yeah, he actually - I'm confused now.  Oh, sorry.  He tweeted about Tarsnap.  He said:  "Only charges transfer and storage, no monthly or yearly fee."  Okay, well, that's a little confusing because they're charging for storage on a monthly/yearly fee.  But I guess so he's saying that there's, oh, yeah, he's saying that there's no other charge like a static charge just for the privilege of their service.  And he says:  "I think that accounts for the price.  Great for my UNIX backups."



And then the reason I was confused is Colin Percival, who saw that Greg had commented in my feed, so he wrote to both of us, and he said:  "To the point where the median Tarsnap customer is only paying about $0.10 per month."  Well, okay, I don't know how Colin has that data.  Maybe he has some inside information about the amount of storage that Tarsnap users are storing.  But that would be, given $0.30/GB/month, someone paying $0.10 per month would have a third of a GB backed up.  So I suppose it's certainly possible to only be paying $0.10 a month and nothing more.



Carl Wilson said:  "FYI, SpiderOak's synch requires data to be backed up online already."  Then he said:  "Sharerooms can be password protected.  SugarSync has no PIE," meaning pre-Internet encryption.  And so I'm not sure what he means when he says SpiderOak's synch requires data to be backed up online already.  I'm going to find out because one of the things that has happened as, again, a result of my continuing focus on this whole topic of cloud storage, is that SpiderOak remains a contender for a very nice-looking, very feature-rich cloud storage solution.  So I'm still - maybe next week.  I just - it's a function of what time permits and how much time I have to dig down into it.  But the SpiderOak guys are there.  I've heard from somebody else since at SpiderOak who's standing by to give me any technical details that I need.  So it's certainly something that I'm going to get to as soon as I can.



Faiz Imam said:  "I have 1.2TB backed up on Backblaze for $5.00 a month, mostly photos.  Took me months to get it up there, but it rocks."  And so I think that this was one of the tweets that sort of began my saying, okay, what is Backblaze?  And that drove me into taking a close look at them.  And at the time that I made this note, I said, "So far as I can tell, it's not TNO."  And that's 100 percent confirmed now.  It's not.  Which is not to say that's a huge problem.  I don't want to overblow this.  And lots of other providers aren't.  For example, none of the big ones are.  SkyDrive and Google Drive and Dropbox, of course, these big ones that offer lots of services, the notion of the services they offer are incompatible with them having no visibility into your data.  You can't have it both ways.



So that's something that we'll cover later on in the podcast because I think what we're going to be seeing sort of evolving out of all of this is maybe sort of a hybrid solution where the user has control of some of the things which are absolutely black out on the cloud.  Nobody can possibly get to them.  And then other things, which they know are less secure, but that's the tradeoff they make because they want to be able to share links to them with their friends, or they want simultaneous document editing and all these other things that we're going to be seeing, cloud-based services in the future.  Obviously, for those things, it just can't be an opaque block that the provider has no visibility into.



Thilo in Switzerland says:  "If you review SpiderOak for Security Now!, you should also check Wuala, as they also do pre-Internet encryption with great platform support."  So we talked briefly about Wuala last week.  Leo had once been using it and then dropped it.  At one point they were apparently putting their, essentially, their cloud storage was other people's hard drives.  And I don't know definitively whether they are still doing that or not.  What I think Leo said was that, if you gave them a chunk of your hard drive voluntarily, then you got better terms with them.  They definitely have a technology which uses an ECC-like redundancy, which I did briefly mention last week, the idea being that, in very much like a RAID, where you can have a RAID drive die, and you can still reconstruct the data from the remaining drives, this is similar to that.  And there are other technologies like that where they build in redundancy into this distributed spray of data so that, as long as there's some critical mass of that still available, they're able to reconstruct the whole.



The problem is, for me, it's written in Java.  Now, whether it puts our data onto other people's machines, I just sort of don't like that.  Again, that's a tradeoff a user could make.  If it gives you a much better price, then maybe that's a tradeoff you want to make.  But Java is - I just don't understand that.  I could see Java things being useful, like free toys and so forth.  But these people are charging for this service, and Java, as we'll encounter a little bit later, has some problems.  Several of the providers are Java-based, of these cloud providers are Java-based.



And my point is, why, if you're making money on this service, then why not just do a native client?  Write a client for Windows.  Write a client for the Mac.  And then you're not having to deal with the whole Java-esque problem.  And part of this is sort of the nature of where this came from.  It was a project of the Swiss, a security group in Switzerland.  And it just sort of evolved into a commercial thing.  Anyway, I don't think I can get around the fact that it's written in Java.



Oh, and then he said in a second tweet:  Don't catch why you trashed Wuala in your latest Security Now! podcast.  They don't do space sharing and seem to be on a par with SpiderOak.  So it does look like they've done security right.  But my comment to that was, yeah, but Java?  It's like, rather not have that.  And there's alternatives that don't.



Josh Mandell said:  "I don't think I heard clearly if CrashPlan has pre-Internet encryption.  But their FAQ states how they do it and even has a link to Security Now! #230 on Blowfish."  Which I kind of got a kick out of, the CrashPlan people linked to this podcast where we described how Blowfish works because they do.  And as I remember, they give you one level of Blowfish, like 128-bit key Blowfish for free.  And then if you switch up to their paid version, they give you 4048-bit keys, which is the largest key size that Bruce Schneier's Blowfish cipher is able to handle.  But it's also written in Java.



And then I quote, "How to use CrashPlan but keep" - oh.  This was on a site.  This is what I knew I had here somewhere.  This was on a site that noticed the amazing, actually "ridiculous" is the word he used, amounts of memory.  He says, "How to use CrashPlan but keep the Java process from constantly using ridiculous amounts of RAM."  And he says, "I use CrashPlan on my online backup, and it's great - reasonably priced, secure, easy to use.  But there's one problem.  For better or worse, CrashPlan is a Java app.  And one of the problems with Java apps is they are greedy pigs when it comes to RAM usage.  I've often noticed that Java was using close to 400MB of RAM, even when nothing is happening.  To be precise, when CrashPlan is just hanging out and not actually backing anything up."



So once again, for me, that's a deal killer.  If I'm going to have something in my machine which is going to essentially be part of my machine, running all the time in the background, keeping things synchronized, I'm not willing to give it just shy of half a GB of RAM for that, not when native clients can be written and have been written that are way more lean.



Mike Dennis tweets:  "I have a four-year family unlimited plan with CrashPlan and been pretty happy with it.  I have over 1TB backed up to them today across my PCs."  And so I wanted to balance the prior one with this.  Mike is happy that he's got his four-year family plan and tons of data up there which is affordable.



I got a tweet from someone who didn't give me his name, but his handle is @Engrpiman.  He's in Boise, Idaho.  He said:  "Jungle Disk web interface allows for Trust No One.  You must enter your username and password.  Then it asks you for your second, which is the optional password, and then you have files."  And so my reaction is, well, I have not looked at Jungle Disk.  I will probably send off a note to Dave, who's known as Jungle Dave in the forums, and ask him.  The question is, where Jungle Disk is configured for TNO operation, you give it an optional password which then performs all local encryption of blocks that are sent off to either S3 or Rackspace.  So that means that the data that they are storing, as is required for TNO, they have no visibility into.  They have no keys, never get them, never will.  All they can do is give you back the same blob that you gave them.



So the question is, in order to do a web-based interface, they would need to do what LastPass does for us in their implementation, which is that last decryption phase would have to happen in the browser, that is, client-side, not server-side.  From just that description, you type these things into the browser.  Well, off they go.  Who knows where they go?  Dave may say, well, of course, Steve, I did it the right way.  You enter your password into the browser.  You're entering it into a local JavaScript app.  All of the decryption is performed locally.  Nothing unencrypted ever goes over the wire, and that password never leaves your machine.  I imagine that's what he will say, but I don't know that.



So we can't assume that this is TNO until we understand the technology, I mean, the details of the technology.  And this actually segues perfectly into where we'll be headed later in this podcast when we talk about Backblaze and the way they use their crypto because the devil is in the details.



Thomas Scrace in London said:  "Have you looked at Arq" -  it's HaystackSoftware, all run together, HaystackSoftware.com/arq - "for backup?  One-time purchase, and it backs up to S3."  So I had not looked at it.  I like it.  If you're a Mac person, it's Mac only, but it looks very nice.  It looks very similar to Jungle Disk.  It does local AES-256-bit encryption.  It looks like it's 100 percent TNO.  It uses S3 as the backend, which, as you've just heard me saying, I like a lot, meaning you can send stuff up there till the cows come home and not get charged for it except the amount of static storage there.  They have an open documented file format, which is - and an open source command line arq_restore command utility which is hosted over on GitHub.  So that's there and in the clear.  You can see how that works.



They have a one-time license of $29.  And I should say this I think is the model that we're headed for, one-time license for this kind of stuff.  I mean, there are going to be some very good solutions that you just pay some amount of money once for, and then - of course that's in the model, then, where you use somebody else's storage, like Amazon S3.  So you are paying monthly for the actual storage and maybe the transit of the data.  But it just feels wrong to me that we're stacking up all of these monthly charges on top of each other, somebody charging for the privilege to use somebody else's storage that you're also being charged for the privilege to use.  Because we don't have to pay all that.  Something like this looks very nice.



So again, this is HaystackSoftware.com/arq.  They also do versioning.  Under Versioning they called it a "Wayback machine."  They said:  "Arq keeps multiple versions of your files, a backup history.  Following the initial backup, Arq automatically makes incremental backups every hour, every day, uploading just the files that have changed since your last backup.  Arq keeps hourly backups for the past 24 hours, daily backups for the past month, and weekly backups for everything older than a month."



Under Features they wrote:  "No limits.  Arq backs up everything you tell it to back up."  And here he's clearly responding to limits of the other services, limitations.  For example, he says, under "Arq backs up everything you tell it to back up," it doesn't skip videos or ignore certain file types.  It backs up files of any size - 4GB, 40GB, it doesn't matter.  It backs up your external drives and your network drives.  Several of the other services won't do either of those.  It doesn't delete backups of your external drives just because you haven't plugged them in lately.  And there are a couple services that actually do that.  It doesn't forcibly delete backups older than four weeks.



And then my note is, I noted it will even throttle upstream transfer rates, which means that famous buffer bloat doesn't bite you.  While it's working, it will not saturate your outgoing bandwidth.  So, as we know from our buffer bloat episodes, it won't screw up your downstream interactive use of your network connection while this is happening.



Anyway, it looks very nice.  I'm really - I thank Thomas for bringing it to my attention.  And for Mac people, check it out.  It's certainly, if you like the idea, as I do, of where it makes sense, sort of more of a DIY sort of scenario, where you've got a relationship with a storage provider, and you kind of want to manage that yourself.  You're firm about wanting TNO.  You're sure you're not going to lose your key because, of course, if you do, you have no access to that.  But that's the whole point of trusting no one.  You have to trust yourself.  And it's not a monthly plan that you've got to get onboard with.  Anyway, for a certain class of our listeners, I'll bet this is a great solution.  So check it out.



Brandon Furtwangler says:  "Wow, SkyDrive just gave me 25GB free as a loyalty offer.  Can you find out more about the security model?  Could be my new fav."  Well, I looked.  And I looked, and I looked, and I looked.  There's absolutely nothing available - this of course is Microsoft's SkyDrive - nothing available that I could find about their technology.  No sign of any Trust No One.  And as I mentioned before, it's highly unlikely, given the services that they're offering.  The features that they're offering are far beyond here's a blob of opaque noise.  Keep it for me.  And if I ever need it, then I'm glad to have it back.  And everything of vital importance is in there, so I can't risk anybody else getting it.  So that's very different than these highly service-oriented cloud services, which is really where Microsoft is with SkyDrive and Google is with Google Drive.



We're going to encounter, and I think we'll be seeing a lot of the ideas of layering security on top of these services and creating sort of a hybrid where you've got a file which is a virtual drive hosted by one of these non-TNO services.  You're providing, though, the layer of encryption, so you get the best of both.  You're able to, with confidence, put files in there, knowing that they're encrypted before they leave.  Yet at the same time, it's SkyDrive or Google Drive, and wow, 25GB is pretty nice for free.  And then you have all of the features with none of the downside, except of course you don't get the features for those files that you have locked up in your own TNO sort of sub-vault on the service.  So I'll bet that's where we end up, with a solution that makes that sort of thing work, and easy.



Terry Reck in Greenville, South Carolina said - oh, and in his little Twitter profile he said:  "Mac support specialist by day, jazz musician by night."  And he said, oh, he sent me a link to one of the things we're going to start seeing.  This was on MacWorld.  It was "Automatically encrypt files for your Google Drive."  And this, frankly, isn't - it's free, but it's kind of kludgey.  It uses the Mac's scripting-based Automator scripts.  And when I went to go check that out, the script itself has the description:  "Creates a disk image filled with files and folders from the previous action.  Options include compression and encryption."



So this looks sort of like something where you manually collect a bunch of things and then drop it on this script, which compresses them, encrypts them, and then probably copies them to your Google Drive.  So it's a way of encrypting stuff before they go off to Google, but it's not a seamless client that actually allows you to mount something from Google Drive and look at it like a folder on your machine, where you could easily and freely move things in and out.



Oyvind Stokke in Bergen, Norway said:  "Enjoyed SN-349.  By the way, TrueCrypt plus Dropbox is a great combo.  Uploads diffs only.  Slow the first time with large volumes, but fast after that."  Okay, now, this is a very interesting idea because I confirmed that Dropbox hashes 4MB blocks of large files.  So the idea being that, if you had a large file, and only some piece of it changed, the Dropbox client running on your system is smart enough to realize that only that piece of a larger file changed, and just upload that.



Well, what's very cool about that model with TrueCrypt is, if you create a large TrueCrypt file into which you create a TrueCrypt drive, then as we know, when you TrueCrypt this large container file, it will fill it with noise.  Absolute, you know, it encrypts it, pseudorandom noise.  That, then, you synchronize with Dropbox.  And this is the part that takes a long time, if you create a terabyte volume or who knows what you're going to do.  But you get it synched.



Okay, now, remember that this file, this container, internally it's mapped just like a physical drive, meaning that in the front are directories.  And then there are the equivalent of file allocation tables.  And the actual physical space in the file represents the physical span of a drive.  So reading and writing files in and out of it would only be changing those sectors, the sector equivalents, in the file.  Which would mean that things you do would only change pieces, which would then be rounded up to 4MB.  And those 4MB chunks would get synchronized through Dropbox.  So this is interesting.



Now, one glitch, maybe, is that I did encounter a reference to needing to unmount the volume for Dropbox to synch it, which of course breaks the whole coolness transparency of it.  So I haven't tried this.  Maybe some listeners will and let me know what the limitations are.  But if you are a person who likes TrueCrypt - now, the downside is, and there are other solutions that don't have this problem, obviously, the downside is the whole concept is you create a fixed-size container, which means you're creating a fixed-size virtual drive.  That is, it is not inherently elastic.  It isn't expanding and contracting.



Things based on the encrypted file system, which we talked about last week and we'll touch on this week, they do encrypt files and the directory system metadata.  So there you get an expanding/contracting sort of environment.  But TrueCrypt is TrueCrypt, and there's a lot of good things to be said about that.  And so depending upon this need to unmount it or not, that may or may not be the problem.  And it may very well be that other of these less-secure-than-we-wish services, but who otherwise provide good features, like many people really like Dropbox, can have a TrueCrypt container file hosted on them and then really get TNO security.



Matthew Figur said:  "@SGgrc, you can use SecretSync with Google Drive as it functions just the same as Dropbox for some security."  And so we covered so many of these options, these cloud providers last week, I had to go back and remind myself what the heck was SecretSync.  I remember it seemed kind of good.  And so it is doing pre-Internet encryption and apparently is TNO.  But it's one of these that has recurring charges.  No charge up to 2GB, and if your needs were modest, then it's free forever at 2GB.  But if you go beyond that, it jumps to $40 per year for up to 20GB of encrypted storage, and then beyond that it's $60 a year for a terabyte.  So it's like, okay, maybe that makes sense.



I liked the way it looked.  We'd have to really vet it to make sure that it was TNO, and I haven't.  But it is one of those where you're paying them for the encryption privilege, and you're paying somebody else for the storage privilege.  So it's not clear to me that that makes as much sense as a solution which is free.  And my sense is we're going to be going there.  There will be alternatives that are free before long.



Toby Dawson says:  "Might be worth a look regarding online storage solutions, includes drive."  Oh, this was interesting.  Very interesting, actually.  This was - The Verge hosted a huge, wonderful grid.  In fact, I tweeted this recently, so you can find the link in my recent Twitter feed.  It's not very deep at this point.  Just @SGgrc.  But I also made it this week's bit.ly link.  But it's not sn-250.  Something, someone probably getting up to some mischief, or maybe not, but already used that.  So this week's bit.ly link is /sn-clouds, all lowercase, sn-clouds.  This is a very nice feature-oriented comparison of all these things:  Google Drive, Dropbox, SkyDrive, SugarSync, clouds, I mean, all these guys.  And it goes through them one by one.



But if you scroll way down, about halfway down, they pull it all together in one huge grid.  Again, it doesn't talk about security because of course that's a little harder to figure out in many of these cases.  But it's definitely got a nice feature comparison of all these guys.  So once again, bit.ly/sn-clouds, all lowercase, and you can find it.  Or I just did recently tweet it, so you can find the link there, too.



Tyler McHenry, a software engineer with Google in Sunnyvale, California, tweeted.  He said:  "Gdrive" - obviously his drive, Google Drive - "could be TNO if used with encfs," meaning the encrypted file system.  He said, "But the web UI would be useless, of course."  So Tyler is saying the same thing I've been saying, and I'll bet you we end up with a solution like that, sort of a hybrid where we come up with something that's using the encrypted file system, and then it looks like a drive or a file which is growing and shrinking and gives us all the benefit of full TNO security, yet at the same time all the features of Google Drive.



Justin Gerace said:  "Take another look at Box.  You sort of glazed over them in your discussion on Security Now!.  They have a big presence in the mobile space."  Well, I looked at them again, and they are neither pre-Internet encryption nor Trust No One.  And the storage costs are extremely high, about three times what Amazon and Rackspace costs.  So I just don't see that there's much, I mean, yes, they were there.  They've been there for a long time.  They've got a lot of inertia.  They've got a big following.  My feeling is the future is uncertain because they're going to be undercut by - now that the big boys are getting into the game.  And, boy, we've got so many options for much better security.  If you need the features they have, and you don't need pre-Internet encryption, or you can use something to layer that on top, then it might make sense.  But still pretty expensive.



Grahame Todd in Dublin, Belfast said, oh, he asked:  "Would you be interested in SafeBoxApp.com?"  He said: "It's pre-egress encryption for Dropbox, Google Drive, Windows Live SkyDrive, SugarSync, ZumoDrive, Carbonite, F-Secure, et cetera."  And I checked it out, SafeBoxApp.com.  It's not clear what they're going to have.  They're coming soon.  They offer it for Mac and Windows.  You can sign up for notification.  So there's just one more opportunity.  And since we are running long, I think I will take your advice, Iyaz, and skip these last guys because there's nothing really crucial in those.



I did note that SpiderOak has a promo code of "Spring."  So for anyone, I don't know what that means, I don't know what it gets you yet, but I just wanted to pass it along.  I don't think it's super top secret.  They didn't tell it to me, someone else did.  So the promo code is "Spring" for SpiderOak.



I wanted to note that TweetDeck is now available for the web, a just general browser interface.  I was very impressed:  web.tweetdeck.com.  I tried it under Firefox and Chrome, and it's beautiful.  It comes up, and it's like full running Twitter TweetDeck in real-time on those browsers.  So that's just way cool.



Okay.  So I did have a note that I wanted to share about SpinRite from a Todd Bertels, who is a listener.  He said, "Steve, good morning.  I'd like to share with you some of my successes with your SpinRite app.  After listening every week to you and Leo for the past year, I've decided to share some of these with you.  I've used SpinRite on several laptop, desktop, and server hard drives, and found that as long as the system recognizes the drive, and there are no scraping sounds coming from the drive, it will most likely work.  Most of these are unremarkable stories, with the exception of two.



"First, my server hard drive failed approximately three weeks after I installed a network-attached security camera.  The camera was configured to push a still image to the server via FTP once a second and overwrite the file existing there.  This file" - I'm sorry.  "These images are the same size, so it wore a pothole in the drive, and the drive failed completely.  After running SpinRite, everything came back except for the one camera image file.  Truly amazing.



"And secondly, my wife handed me her iPod Mini when we were at the gym.  It was very sluggish and would hang for three or four minutes at a time before playing again for a few more minutes.  We tried synching it with the computer, but that would fail after a few attempts.  It had 'failed hard drive' written all over it.  So I dissected the little gadget and removed the Hitachi microdrive from inside.  I went to Fry's and got a CF/IDE adapter and ran it against  SpinRite.  After 45 minutes the drive was running as good as new.  Steve, your product is truly amazing.  I've tried many other data recovery products and services over the years, and they just don't work.  Usually you get data back, just enough to make you kick yourself for not having better backups.  Cheers and thanks, Todd Bertels."  So Todd, thank you very much.  



IYAZ:  Okay.  So, yeah, I tried that TweetDeck for the web, by the way, just going back real fast.  I don't like it.  I think Twitter screwed up TweetDeck huge.  I don't know.  Did you like it?



STEVE:  I just fired it up on both browsers, and it worked.  And in fact I'm a TweetDeck user.  That's where I'm watching all this stuff happening all the time.  So...



IYAZ:  I guess I'm an old man.  I like the old Adobe Air version of it, when it had, like, 15 columns.  But that's just...



STEVE:  Well, I've got, like, eight.  Is there a column limitation?



IYAZ:  Well, when Twitter bought it, they kind of changed - they basically threw out all my old columns, for some reason.  It was like, start over.  And so then they lost me entirely.



STEVE:  Ah, okay.



IYAZ:  Cloud storage solution.  Backblaze was a cloud storage solution that you looked into extensively because apparently it has some things that need to be explained; right, Steve?



STEVE:  Yeah.  So what happened was, in response to our listeners - we heard from some of them who were tweeting, but there were many more actually.  They were saying, hey, what about Backblaze, which I had not covered last week.  So I took a look at it, and it took some wading through.  They've got some nice diagrams.  But what you want in a diagram that explains cloud storage is you want it to clearly show you where the Internet is in the diagram.  Which is to say, what is encrypted on your side of the Internet connection; what's going on on the other side of the Internet connection.



So they had some flow diagrams that talked about 248-bit public keys, and we randomly generate a 128-bit AES symmetric encryption key.  Then we use the public key to encrypt it, and then that goes off.  And actually I'll explain what they're doing in a minute.  But the point was that, unfortunately, it wasn't clear what was being done where.  They sort of had a flowchart, but not "You are here, and the Internet pipe is here," and "Nothing that shouldn't go through the Internet pipe is doing so."



So I had to dig deeper.  And I ended up finding what they call their Security Question Roundup page.  And so under, for example, "How good is the encryption?  What do you use?"  Because it's clear that many people, I mean, if these are real questions being asked, and certainly our listeners are caring because they were tweeting like crazy, saying what's the story, a question is "How good is the encryption?  What do you use?"  And so their answer is, "We use 2048-bit public/private keys to secure a symmetric AES 128-bit key that changes for every backup session on your computer.  Usually this is once per hour.  You can read about our approach here," and then they link to a "How to make strong encryption" page.



And then they say "We copied the design of Microsoft's Encrypted File System designed by a group of much smarter people than ourselves.  We didn't invent any of this.  It's all off-the-shelf OpenSSL library stuff."  It's like, okay.  And then later on on this page it says, "My place or yours?  Is a separate AES" - and again, this is like people still trying to understand what's going on because it's just not made clear.  "Is a separate AES encryption done on my computer before the data is sent to your server?  If not, how does the key generation work?"  So the answer is, "At a higher level, Backblaze uses OpenSSL.  So the answer to most of your questions is found by reading up on that technology.  Luckily this is the widest known encryption library and technology on Earth.  At Backblaze we aren't encryption experts.  We just specialize in making what is normally only for rocket scientists usable by Mom and Pop consumer."  Then we have a smiley face.



Then a little bit lower down, still answering the same question, trying to, I don't know, put someone's mind at ease, they said, "The private key stored in your account in the Backblaze datacenter is also a PEM file," which is just a standardized format for securing or for storing binary data - "stored ... in the ... datacenter is also a PEM file.  And by default it is secured (encrypted) by our well-known passphrase, which means technically, if a Backblaze employee was malicious enough and knew enough and spent enough time to target one of our million-ish customers, then we could have access to your file's contents."  Then it says, "(a firing offense at Backblaze, and we guard the access to a very exclusive list of Backblaze employees)."  Well, that tears it.  I mean, what that says is that, if an employee goes rogue and decrypts their customers' data, they'll get fired.  But it also says it's possible.  And we know that it should not be possible.  



So here's what they do.  When you install the Backblaze client on your machine, they generate a 2048-bit public key pair.  And we know how that works from many times we've discussed it.  In asymmetric encryption, one of them is used to encrypt, the other is used to decrypt.  Then for a - oh, okay.  So they generate the key pair.  And as part of your account setup, the private key is sent to them.  And they make a big point elsewhere of saying it is never written to your disk and never stored on your computer.  It's like, okay.  But so you send it to them.



Then to do a backup, a pseudorandom, 128-bit AES symmetric key is generated just for that backup.  The backup blob is encrypted with that key.  Then that key that you used for that backup is encrypted with your public key that is uniquely yours and for which they have the private key.  Then the encrypted blob and the encrypted key for it, that was encrypted with your public key, is all sent to Backblaze.  And again, on their site they make a point of, and that key is never written, that temporary symmetric key is never written to your drive.  It's only in RAM, and it's immediately deleted.



Okay.  So what that means is that at this point they are the only people who can decrypt it.  You can't.  I mean, it's your data, but you can't decrypt it.  So it's on their server.  And when you want it back, even if, I mean - but I have no reason to mistrust them.  I mean, really none.  I think they're a good company, nice people, well intentioned.  But they've just got a messed-up crypto model.  So, I mean, if they're trying to offer really good security.  And the idea now is that, if you want it back, you can't get it back because you don't have the key.  You ask them to decrypt with your private key, which they have, the key that was used to encrypt the data.  They decrypt it for you and send it back.  So you see my problem.



IYAZ:  Is there anything, I guess, after going through the FAQ here, or the Security Question Roundup, that is, is there anything positive about Backblaze after reading all this?  Because it sounds like it's kind of a mess.



STEVE:  Yeah, it's a mess.  And I wish it weren't a mess.  But, I mean, there isn't another way to explain it.  And also, frankly, I mean, there is this sort of sense - well, okay.  What I should do now, because I - let me share with you my communication to Gleb Budman, who is the CEO and cofounder, Gleb Budman, who reached out, contacted me, wanted to know what my concerns were.  I said:



"Hi, Gleb.  First off, let me explain that my tweets today were triggered because so many people were asking me why I wasn't recommending Backblaze, or what I thought of Backblaze.  My Security Now! podcast of last week focused upon many cloud storage providers, but Backblaze was not among them.  So I simply had not looked.



"Secondly, as my most recent tweet tried to explain, I'm talking about some strict techie details, not about how and whether Backblaze is trustworthy.  I have no reason whatsoever to suspect Backblaze is anything other than totally trustworthy.



"But the problem is your security model REQUIRES that your users trust you.  That's not in itself a bad thing.  But during the seven and a half years of the podcast we have covered cryptography and cryptographic systems extensively, and we have developed the acronym 'TNO,' which is short for 'Trust No One.'



"It is possible for cloud storage solutions to implement a cryptographic model where at no time and in no way could the storage provider possibly decrypt their users' or clients' data.  And a number of Internet remote storage providers do just that.  But from my careful reading of your online documentation, it seems very clear that that is not a security architecture that your organization has adopted.  Thus you are not TNO safe.  You can, if you choose to or were compelled to, decrypt your users' stored data."



So I then quote some of his own pages, which I won't go over again.  And I said - oh, and I should mention that one of the additional complications is that they offer an enhanced level of security, which is really where this problem comes in because they give their users the option to provide a password which, if they ever forget it, they're out of luck.  Unfortunately, they do this wrong.  The password that the user can optionally enable encrypts their private key, which is still stored at Backblaze.  So what they've done is they've layered sort of an attempt to increase the security on top of an already broken model.  But that doesn't unbreak it.



So now what happens is the user who wants access to their data has to provide the password to them, which then they use to decrypt the private key, which is then used to decrypt the key that was used to encrypt the backup.  So once again, the decryption is occurring at Backblaze.  Only they have the key.  And so they can and have made the argument that, well, but we don't - we can't decrypt it all the time.  We have to wait for the customer to ask for the data.  Then we can decrypt it.  It's like, okay, that's still broken.  I mean, all they have to do is change their model.  Don't do this "we're holding the only key in the universe that can decrypt our customers' data, but we promise not to look at it."  Okay.  Anyway.  So continuing with my note to Gleb, I said:



"From studying those pages, I understand that, one, when the Backblaze client is installed, a 2048-bit asymmetric key-pair are created.  The user's client computer retains the public key, and the private key is sent to Backblaze.  For every backup session, a one-time 128-bit pseudorandom symmetric AES key is generated.  That symmetric key is used to encrypt the user's data, and that key is encrypted with the user's public key.  The symmetrically encrypted backup data and the asymmetrically encrypted encryption key are then all sent to Backblaze."



So just to stop for a second, I mean, yes, this is confusing.  And you could understand why people who just want to know is this TNO or not can't figure it out.  I mean, and the diagrams aren't clear.  And it's sort of, unfortunately, this is all kind of a little glib on their site.  It's just not science.  It's, oh, well, we'll fire them if they do that.  I said:



"So this is unbelievably broken.  Even the user cannot decrypt their own data.  Only Backblaze, who maintains the user's matching private key, has the ability now, at will, to decrypt the encryption key used to encrypt the data, then decrypt the data.  And presumably that's precisely what you do whenever the user wants to browse or retrieve their files.  However, you could also do it anytime you desired.



"Now, I know that you provide a mechanism for allowing the user to encrypt their private key on your servers so that even you can't decrypt their backup encryption keys.  But it's never possible to layer more bad security onto a fundamentally broken security model to fix it.  In this case, if you were under court order to provide a user's data, you would merely need to wait until that user did wish to access their storage and thus provide you with their secret key to decrypt their private key.  And you would then have access to all of that user's stored backup data."



Anyway, that's their situation.  So Gleb slept on it overnight and sent me a note in the wee hours of the morning saying that he would respond when he'd had some sleep.  And he said:



"Steve, thanks for the detailed email.  I believe you are largely accurate" - oh, and I have his permission to share his response to me with our audience on the podcast.  "I believe you are largely accurate in your understanding of how the system works, but are largely wrong in your resulting conclusions, with one exception which is a fair concern, and I'll address.  Let me explain.



"First, Backblaze has two models for security:  Trust Backblaze.  In this default option we have the ability to decrypt your data.  This model exists for one reason, so that users can recover their password.  The point of backup is to protect people from data loss.  For the majority of users, the biggest risk is that they will forget their password and never be able to recover their data.  To be clear, even in this model all data is stored encrypted, and only a very few people in our entire company are trusted with the keys.  So while it is 'Trust Backblaze,' the encryption still serves a valid purpose."



Now, let me pause for a minute.  It's like, I completely agree with that.  We all get it that Trust No One means no one but yourself.  That is, if you are the sole key holder to data stored in the cloud, you can't lose those keys.  I guess my argument is how hard is that to prevent?  How many things do we have, tools do we have that help us remember our passwords?  And there's also good old paper and pencil, if something is really crucial.  Anyway, going on, he continues:



"Trust No One.  In this option a user can choose to encrypt their private key with a private passphrase.  In this model, neither Backblaze nor anyone else except the user can ever decrypt users' data unless the user gives them the passphrase."  Well, as I said, unfortunately, the user does give them the passphrase any time they need visibility into their data.  And at that point Backblaze decrypts the private key and has access.  So, broken.  Anyway, I don't want to criticize his response too much because he may - I want to allow him to have his say.



"While 90 percent of our customers choose the first option, and I firmly believe that for the majority of users this is the right decision because their biggest risk is not a government subpoena but losing their password.  However, for the purpose of our discussion I will focus on the second option since it would be the one you and some of your listeners are probably most interested in.



"You say that our security model for storing the private key encrypted by the user's private passphrase is inherently flawed.  However, this is the model that Microsoft Encrypted File System is based on."  Okay.  "I believe this is the same way your sponsor Carbonite does their encryption."  Okay.



"If you believe us storing a private key encrypted with a passphrase is not secure, this would imply encryption inherently is unsafe, in which case it does not matter who has the private key, since all of these systems inherently rely on encryption."  Okay, well, that's not correct.  I mean, the problem is, as we understand now, the user gives them the private key to decrypt their - the user gives the private passphrase to Backblaze, which then allows Backblaze to decrypt the asymmetric private key and then decrypt the backup.  So there's nothing wrong with encryption.  It's that their model is broken.  Where things are and where they're done is not Trust No One because - okay, well.  He says:



"When the user picks a private passphrase, Backblaze can never decrypt the data, regardless of any government subpoena."  Well, that's not true either.  The model requires that they decrypt the data.  Okay.  So he says:



"The one exception, which I want to be fair to you about, is that when the user does a restore" - oh, here it comes - "Backblaze needs to provide the user with their decrypted data."  Mm-hmm.  In this model, unfortunately that's true.  "Thus we ask the user for their private passphrase at that moment.  There is a moment of risk here, but very short."  Yeah.  On the other hand, computers are very fast.  "The system is automated.  No employee ever sees the key.  The key is only stored in RAM and is never written to disk."



Okay.  So to be fair, I think these guys have done, like, the best job they can with their broken model.  It's still broken.  It's still wrong.  And there's no reason not to trust them.  But it's just, you know, it's not done right.  He says:



"Going further, I claim that, if you believe a real Trust No One policy, you cannot use Jungle Disk, Carbonite, or any other provider because to use them you have to trust them."  Then he has a number of points:  "They have code that runs on your system connected to the Internet.  They do not open source their code; and, even if they did, would you review every single line of their code every time they did a release?  They can say that they do all sorts of things, but they could simply put a keylogger on your computer and send all your data directly to the government.  In fact, if they're required by a subpoena to get your data, and they have an application running on your system, they could change their app just for you.  Thus, even if some expert reviewed the code, that will not guarantee that the code on your computer is doing what they publicly say.  Thus you are inherently trusting them to do what they say."



Okay.  Well, right.  All of those things are true for everybody, for all users of all of these things.  Yet there are solutions whose architecture, by design, keeps the encrypted data on the local machine and only ever ships out decrypted data and never discloses its keys.  And that's not what this does.  And he says:



"What we say:  We encrypt all of your data by default on your computer.  We send all that data over an encrypted connection and store it encrypted.  You can choose to have your data encrypted with a private passphrase of your choosing.  If you do, NO ONE" - he has in all caps - "can ever decrypt your data unless you provide your private passphrase."  That's true.



"If you do a restore and enter your private passphrase, the key is stored in RAM, not written to disk, not seen by anyone."  So he's saying, given their model, they're trying to be as responsible as they can.  They're doing the best job they can, which I completely accept.  He says:



"Furthermore, the moment after restoring your files, you can change your private passphrase.  Thus, again, it would be impossible for anyone to decrypt the data, even if we wrote new code to capture your key, which we don't have."  And of course understand that to decrypt your files, they are the ones who decrypt them, which is fundamentally the problem here.  Nothing can get around that.  Then:



"We never decrypt data without the user explicitly requesting it, or if a government subpoena required it."  Okay, well, that's comforting.  "And with your private passphrase, that is impossible.  In the five years of Backblaze, we've never been subpoenaed or decrypted any user's data without their permission."  And of course they have to say that because they're legally obligated not to disclose, under Patriot Act, if they've done so.  So he volunteered that, and I believe it, but that doesn't mean it won't happen tomorrow.  So he's finishing:



"Should you trust us as a company to do what we say?  We're very public about who we are and are accessible on email, Twitter, Facebook, Google+, both as a company and individually."  And they are.  "We've been in Silicon Valley building products and companies for over a decade."  And they have.  "Our last company was an email security company, where we protected some of the largest companies on the planet from spam, viruses, phishing, etc.



"Does that make sense?  I'm happy to chat, connect you with our CTO or VP of Engineering, share more details about our approach and systems, join you on your program, or anything else you would like."  So I thank him.  And I think everyone understands now.  This is a great example of an attempt at security.  I mean, there is lots of security here.  Data is encrypted.  It is always encrypted as it goes to them.  Unfortunately, their model, and I don't understand who designed this, I mean, they earlier, and they've said on their public pages, they're not cryptography experts.  And I'm fully going to agree with them on that, too.  This is just not correct.



And my argument, and I responded to his note, and I said, look, I'm not telling you what to do.  You can obviously do anything you want.  And I accept that you're good guys.  But there are people who care, and they believe something that is not true from reading your pages.  It takes really carefully understanding what you have said in your technical documentation to get it.  And the reason there's been some concern generated when I posted on Twitter that this is not a Trust No One architecture, is that people thought it was.  The pages are so confusing, I mean, I don't want to say deliberately so because they're sort of like, oh, well, you know, we're not rocket scientists, and neither are you, so - and besides, we used OpenSSL and we copied Microsoft, as if any of that means anything.



So I think these guys are fine.  I think they're trustworthy.  And it is true that, as long as things are static, if you employ their optional passphrase, then your copy of your private key is encrypted on their system, and they can't get your data.  It's not until you want to look at it or ask for it that you need to provide them the ability to decrypt your data and send it back to you.  But that's just not the way it should be, not if they really want to provide security.  And I did write this in my response to him.  I said, all you have to do is not send the private key over, just send back the encrypted data and let the user decrypt it himself.  So easy to fix this, but it's not the way the system works now.  So that's the story.  That's the story.



IYAZ:  Do you think they're going to implement your changes?  Since you just gave them free advice.



STEVE:  There was, well, and - who knows.  I saw someone tweeted something about a 2.0, but this wasn't coming from Backblaze.  And a response did indicate - I think he responded to my response, which thanked him for his clarifications on things.  But there was something about moving forward in the future we're going to make things better.  So, okay, that would be good.



IYAZ:  Well, hopefully they'll at least clarify their security questions, and at least there's documentation about it.  Because it does seem like they're just trying to give you some reasons.  You're hoping they can figure it  out.  But thanks to you, Steve, everyone knows now.  So it's a lot easier.  Wow, that's - because I read that.  I read that documentation, too.  And I was just like, yeah, it seems a little bit like they're being honest, but seems like they don't exactly know.



STEVE:  Well, yeah.  They seem like, I mean, I really get the sense these are good people.  But they're not crypto people.  Maybe they're email people.  I don't know.  But, I mean, it's just a dumb architecture.  It's like, I mean, it's really - you generate a random key to encrypt your data, and then you encrypt that with your public key, and the private key that matches was sent to them, and they make a point of telling you it's not on your computer, it's never been stored.  Which means you cannot decrypt it.  Your own data.  Only they can.  It's like, okay, who came up with this?  Just nutty.



So again, but they're offering way more security, for example, than SkyDrive and Google Drive because those guys aren't doing any client-side encryption.  And there are all kinds of, you know, their privacy statements say that the data is safe in the cloud, and it's encrypted, and blah blah blah.  But there is only - there's absolutely a simple test, and that is - for TNO.  And that is decrypted data never leaves the machine.  Only encrypted data ever exits the machine.  And keys for that never leave your control.  They also never leave.  And that's all there is to it.



If you have that - and, see, the beauty is, here they're, like, worrying about having to fire people and needing to lock down access to the key that could decrypt.  Remember that 90 percent of their users think they're being encrypted on their machine, and that that means it's, like, safe at the other end.  Except that they just said some employees have access to the key that can decrypt 90 percent of, right now, of their customers' data, all those people who didn't use the extra passphrase.  Which means that they've got all this responsibility.  Why have that responsibility?  If you architected with TNO, you don't have to worry about your own employees or government subpoenas.  You can make a much more simple declaration of your security, rather than these pages of gobbledy-gook that nobody really understands.  Just say no, no one can get it, period.  And it's true.  Unfortunately, it's not here.



IYAZ:  Well, thanks, Steve.  It's been an education.  And I hope I didn't get the show canceled.  But it's been just a lot of information in my head.  You can find all Steve's stuff at GRC.com.  ShieldsUP! is a fantastic program.  And if you want to know about the steps we talked about in this show, you could check out the show notes at TWiT.tv/sn.  And thank you so much, Steve.



STEVE:  Iyaz, it's been an absolute pleasure.  And now I've got two backups for Leo who are qualified to do the podcast with me.  So I'm glad to have you, thanks.



IYAZ:  I'm glad I survived the baptism there.  So thank you, Steve.



STEVE:  Bye-bye.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#351

DATE:		May 2, 2012

TITLE:		Three Hybrid Cloud Solutions

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-351.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's news and Twitter feedback, Steve and Leo closely examine three remote cloud storage solutions whose Crypto was done COMPLETELY right, Offering full TNO (Trust No One) security.  And one of them makes Steve wish he were a Mac user!



SHOW TEASE:  It's time for Security Now!.  Lots of security news from Steve Gibson; I'm back; and Steve has found yet another cloud storage solution that's so good, he says it makes him want to use the Mac.  Wow.  It's coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 351, recorded May 2, 2012:  Back to the Cloud.



It's time for Security Now!, the show that secures you, now.  And here he is, the Securer in Chief, our Explainer in Chief, the man with the plan, Mr. Steven Gibson.  Hey, Steve.



STEVE GIBSON:  With his feet on the ground and his head in the cloud.



LEO:  In the cloud.  I want to thank Iyaz for filling in last week, did a great job.  But I'm glad to be back.  I missed you.



STEVE:  Well, and we missed you.  And I'm so aware of how much I depend upon the continuity of our episodes because what you missed last week was really fun and interesting.  It was, first of all, it was nominally a Q&A, but it was the first Q&A where I didn't even have a chance to open the  mailbag.  So god help me next week.



LEO:  It was all tweets.  All tweets.



STEVE:  Yeah.  It was 21 tweets.



LEO:  Wow.



STEVE:  It was our first fully Twitter-driven episode of Security Now! because there was so much reaction to the episode before that you and I did...



LEO:  Right.



STEVE:  ...where we did this huge, quick survey of cloud storage solutions.  And...



LEO:  By the way, I got one complaint, and I'm just going to - I'm going to get you off the hook here about how I described Wuala.  And somebody said, oh, you don't understand, you guys don't understand at all.  And that was not you, Steve, at all.  Steve hadn't looked at Wuala.  It was me.  So any errors committed in that portion accrue to me, and me alone.



STEVE:  Well, at least you pronounce it correctly.  I have a problem pronouncing it.



LEO:  Wuala.



STEVE:  You got that part right.



LEO:  At least I got the name right.



STEVE:  So shortly after you and I recorded two weeks ago, a couple people responded, saying what about Backblaze?  And I looked at Backblaze, and it was a classic example of really good people with good intentions doing crypto wrong.  And they didn't apparently understand that they had done it wrong.  And so I opened up a dialogue with the cofounder and CEO and made sure that I understood that they had done it wrong.  And unfortunately I was right that they were wrong.  And then so last week was basically responding to all kinds of the feedback that we had from the episode you and I did, and then taking a deep dive into what it was that they did that was wrong.



And just so you're up to speed, they haven't - first of all, it looks like a very nice company, good people.  I have no reason to mistrust them at all.  But what I tweeted was, after I looked at it, was they were not TNO.  They were not Trust No One.  Yet their documentation made that very unclear.  They implied that users could add a password that would then encrypt their storage over at Backblaze.  But in fact, the way they were doing this was completely broken.



They create a public key pair, an asymmetric key pair.  You have the public key; they have the private key.  When you encrypt something, the encryption generates a random key, a symmetric key, to encrypt the file.  That's all good.  But then it encrypts that with your public key and deletes the record of it, then ships it to them, to Backblaze, for cloud storage.  At this point you can't decrypt it.  Only they can decrypt it.



LEO:  Whoops.



STEVE:  Oh, yeah, just nuts.  And so then they say, yeah, but if someone uses a password, then that's safe.  Except that you provide your password to them for them to use that to encrypt the private key.  And if you ever want to look at your stuff, you've got to provide it again so they can decrypt the private key.  So, I mean, the point is that it's all, like, wrong.  They are the only people who can decrypt your data once you ship it to them.  And even if briefly, they are decrypting it, and they have to decrypt it.  So we went into that in some detail.  And so it was, I think, a really interesting episode.



This week, one of the things that I said with you two weeks ago was that I could sort of see some pressure toward what I was calling a "hybrid cloud solution."  We've got, as you know, since you and I were last together two weeks ago, Google Drive has announced and messed up all of our Gmail.  Or Google Docs, rather.  And Microsoft upped their free SkyDrive to 25GB for people who were already using it as, like, a loyalty bump.  And so there are all these free services.  And of course Dropbox is very popular, but we know that Dropbox is not secure.  And in their privacy policy they explain that they'll make your data available to agencies that request it under court order and so forth.



So what I'm calling "hybrid solutions" are those where you want the features that these existing providers offer.  For example, in Microsoft's case, there's all kinds of things - and Google applies, too, certainly - all kinds of things, special things that they can do when they can see your data.  And many people want those features.  But at the same time, it'd be nice to have a cubbyhole in that service where you can also put things that are just black.  They're just black ops.  No one and nothing can see into those.  And so this week I want to look at crypto done right, as opposed to last week, where we saw how well-intentioned crypto could go wrong.  Three apps, one of which is so good for the Mac that it makes me want to switch from Windows.



LEO:  Wow, that good.  Wow.



STEVE:  It's really nice, yeah.  And we've got some neat Twitter feedback and news and so forth.



LEO:  Excellent.



STEVE:  So we'll get into it.  I wanted to note that v12 of Firefox is out.  And that happened, that was announced on Security Now! last week.  And what they did with v12, Leo, is they are - they've engineered around the user account control popup in Windows.  They've got a process that they're able to start.



LEO:  Really.



STEVE:  Yeah.



LEO:  That doesn't seem like a good idea.



STEVE:  Well, unfortunately, this is - they're trying to get - and I agree with you.  And I brought up that point last week because you'd hope that the bad guys can't somehow...



LEO:  If there's a way to do that, we don't really want to publicize that.



STEVE:  So, but the problem is what - and we've talked about this before, where we know Mozilla is trying to go where Google has gone with transparent updates so that it's just continually keeping itself current and fixing problems on the fly without requiring any user interaction.  So this, so v12, which is now out, is - it's not quite to automatic seamless updates.  But they have now avoided the user account control so that they, presumably with proper protection, are able to update without providing you - without putting that dialogue in your face.  And with 13, which is now in beta, they've finished that, or they will when it comes out of beta.  The cool thing is that 13 enables SPDY by default.



LEO:  Yes.



STEVE:  Yes.  So we now have Mozilla's Firefox and Google's Chrome both with SPDY present, debugged, working, and enabled, which is a good thing.  It'll put pressure on the remaining browsers because these guys - and of course it will provide additional incentive for the server side to bring up SPDY support, just to globally and in general support or improve cloud-based experiences.



Now, the other thing that I just saw is really interesting, also.  We talked last week about how - or maybe it was two weeks ago because I think I remember discussing with you how, with Apple's Java fixes to deal with the Flashback trojan problem, they're now disabling Java by default.  And if you reenable it because you need it, if you don't keep using it, it automatically re-disables itself.



LEO:  Good.  Re-disabled.



STEVE:  It goes to sleep again.



LEO:  Time out.



STEVE:  Yes, it's like, okay, well, we're going to go back into protection mode.  Now, what Firefox has done, and this has just happened, is they're proactively disabling back versions of Java.  So if you aren't updating your Java, you can't use it because, I mean, they've been concerned enough...



LEO:  Oh, that's interesting.  Wow.



STEVE:  Yeah.  Yeah.  They've been concerned enough about the exploits, when studies are done that show the people who are not updating Java constantly being infected due to Java vulnerabilities, they're saying, look, we know that it's obsolete.  Let's just - that it's a vulnerable version.  Let's just shut that down.  And if a user wants to use Java, you've got to update it.  And so these are - it's unfortunate that we have to be proactive this way, but it's the only way at this point in our evolution of personal computing on the web to handle this.  So I'm really glad for it.



And Kaspersky came out with the announcement a few days ago claiming that Apple is 10 years behind Microsoft on security.  And I thought, huh, okay.  And this was Eugene Kaspersky's log or blog.  And I looked at it, and I guess I know what they're saying, but I disagree.  Apple reaps a huge benefit from having the experience of Microsoft.  Certainly 10 years ago Microsoft was getting a lot of arrows in its back.  It was very slow to adopt the security practices that many people were asking of them.  And you'll remember, Leo, I mean, we've been doing the podcast, what, for seven and a half years.  How many times did I say, "Why do we have scripting in email?  Why do we have scripting in email?"  Because, I mean, it used to be so stupid that you could just - that you could receive email that would run code.  And it took a long time for that to get fixed.  And why is the firewall not turned on?  Well, it took a long time to get that turned on.  Well, it took a long time to get that turned on.



So what I think is, it is true that the whole ecosystem that Apple has is somewhere lagging behind.  But it's not 10 years.  And by the ecosystem, I include, for example, the users, who are going to have to understand that it's not the case that Macs can't get viruses.  I mean, we know the 600,000 instances of Flashback that infected Macs demonstrate that, well, yes, they can.  I mean, they're just computers.  In this case, of course, it was a Java exploit that was allowing this stuff to get into them.  So I don't think it's 10 years.  I don't even know if it's right to put a timeframe on it.



But the good news is I know, even though Apple - I guess anyone is not responding as quickly as we want.  We're not happy with Adobe, with anything Adobe does.  And we'd like Apple to be more proactive.  Flashback happened because they dragged their heels on updating their Java client for Safari, and for the Mac.  And they learned the lesson of what happens if you drag your heels.  And that was a huge black eye for them.  So they may have to learn the lesson a few more times.  But they have the substantial advantage of having seen Microsoft dance this same dance and learn from it.  So I think that's good.



There is, if you click the link, Leo, you want to show people on the video side this next link at Ars Technica, wonderful and interesting browser adoption graphs.



LEO:  Okay.



STEVE:  For our listeners, I also just tweeted this.  So if you go to Twitter.com/SGgrc, up near the top of the feed is some really interesting graphs that just demonstrate over time what's happening with competition among browsers and how the user share is changing, and also some cool charts lower down showing, for example, we've talked about how Firefox's major versions have gone from glacial to almost too quick.  And these really nice charts demonstrate and show over time just sort of the user population changes of the various browsers.  And I just sort of liked it, so I wanted to bring that to our listeners' attention.  I think everyone would get a kick out of just browsing through those and looking at the various percentages.



LEO:  Yeah, especially as they change, yeah.



STEVE:  Yeah.  Now, we know that one of the drivers, I guess the most reliable driver of investment in malicious conduct is cash.  For the longest time, hackers seemed to be delighting in viruses, just doing them because they could.  They didn't make any money.  And that was one of the conundrums.  People said, well, why are these viruses in our computer?  What do they do?  I mean, rarely were they really destructive, but they were just annoying.  Then we began to see, as of course the web ecosystem in general of money, with Google demonstrating that you could make money with ads and so forth, began to create an economic model.  There was a really interesting analysis by Symantec of the way the Mac Flashback trojan worked.  They analyzed the ad-clicking component of it to understand what it did.  And quoting from their blog, they said:



"The Flashback ad-clicking component is loaded into Chrome, Firefox, and Safari, where it can intercept all GET and POST requests made by the browser.  Flashback specifically targets search queries made on Google and, depending upon the search query, may redirect users to another page of the attacker's choosing, where they receive revenue from the click.  Google never receives the intended ad-revenue click.  The ad-click component parses out requests resulting from an ad-click on Google search and determines if it is on a whitelist.  If not, it forwards the request to the malicious server.  Intercepted requests show a revenue of $0.08 cents for the click."



Based on the virulence and the number of machines that were known to be affected, and we know what that number was because remember that you and I talked about this, the crypto used to generate the domain names was reverse-engineered.  And I think it was Kaspersky, I can't quite remember, somebody reverse-engineered the crypto, registered the domain name, and then for a while had all of the bots phoning in for directions and so was able to count them clearly.  The bottom line, when you multiply this all out, is that that botnet was generating $10,000 a day...



LEO:  Wow.



STEVE:  ...for the Flashback gang.



LEO:  Wow.  But it's not surprising.  And doing so for something like five years.



STEVE:  So, yeah.



LEO:  They made a lot of money.  It's a profit deal.



STEVE:  This is a problem.  This is a problem because...



LEO:  Well, they had four million, at one point they had four million machines corrupted.  So that's where - I'm sure that number comes from the maximum.



STEVE:  Yeah.  And if you do the math, I mean...



LEO:  It's not hard to figure out, yeah.



STEVE:  It's a lot of machines.  And so there is - now this goes from script kiddies saying, oh, isn't this fun, to organized crime hiring computer professionals or black hat professionals to make this stuff happen.  I mean, it really does - it changes it from a lark to a business model, if you can make $10,000 a day while it lasts.



And I did have a note here about all the controversy over Google Drive's Terms of Service.  CNET called it a "toxic brew."  And they said:  "Google isn't about to make your private files public, but that doesn't excuse its sloppy terms of service."  And I never got around to digging down and developing my own opinion over what I thought about that.



LEO:  I could talk about this, if you want.



STEVE:  Yes, do.



LEO:  You would think that Google would have learned because this happens every single time a service - even Firefox, Facebook.  What happens is the lawyers say, well, look, Google, you're going to maintain copies of this.  In order to share it, you have to maintain copies on your servers.  So they write very broad language that says - and this is what Rafe points out in his article on CNET - that is kind of in conflict with their initial statement, which is we are...



STEVE:  Are on your side.



LEO:  Yeah, we're on your side.  You always own your content.  We have no intention to publish it publicly.  And in fact there's no facility within Google Docs to publish it publicly.  However, in the language, the lawyers always take the broadest approach, which says we reserve the right to use this, copy this in any way, in any form, in any fashion.  And furthermore - and I think this is probably what most concerns people - we reserve the right to use it to improve our services.  And I think that people are always scared when they read this copy.  And Google should have known.  The point Rafe makes is they could have written it more narrowly.  The point he's making is not that Google intends some nefarious use for this, but merely that this was sloppily written.  But this is what always happens in all these agreements.  We saw it with Pinterest.  We see it again and again.



"When you upload or otherwise submit content to our Services, you give Google (and those we work with) a worldwide license to use, host, store, reproduce, modify, create derivative works (such as those resulting from translations, adaptations, or other changes we make so that your content works better with our Services), communicate, publish, publicly perform, publicly display and distribute such content."  That's boilerplate.  And they should have written that properly.



STEVE:  Yeah.  In other words, our attorneys tell us that there's no way you can possibly sue us, no matter what we do, based on what we've just said we might do.



LEO:  They do then say, "The rights you grant in this license are for limited purposes of operating, promoting, and improving our services and to develop new ones."  And they say at the very beginning, in a preamble, "You retain ownership of any intellectual property rights you hold in that content.  What belongs to you stays yours."  They try to address this.  But by now they ought to know the first thing that happens when a new Terms of Service comes out is that...



STEVE:  Everybody looks at it.



LEO:  Everybody looks at it, and the first thing they look for is that line that says, "We retain worldwide license to do whatever we want with your stuff."  And everybody says, well, that leaves Google a giant barn door opening to steal our stuff.  So while I don't think that's Google's intent, they really - by now you ought to know, guys, when you write one of these things, that somebody's going to look at it and complain.  It's always the same.  This is the same thing we hear every time because, remember, in order to put this - they have to - your content lives on many, many Google servers; right?  And if when you share a doc with me, they have to make a copy into my thing.  All of the things they're asking for the right to do allows them to do all that.  They should have been a little narrower and say, hey, but this is just for this purpose.  This purpose we won't expose it publicly, et cetera, et cetera.



STEVE:  Which actually that's a perfect segue into today's topic because today's topic is how to make something like Google Drive really safe.



LEO:  Ah.  That sounds good.



STEVE:  Yeah, because the idea is you want the services that Google can only offer, as you just said, by having some visibility into your data.  But for some stuff you'd like to also be able to drop documents there where it actually doesn't matter what they say because they can't do anything with it.  It just looks like pseudorandom noise to them.  They can scratch their head.  The only thing they could do is delete it.



LEO:  Right.



STEVE:  But presumably they'd have no reason to do that.  But they can't see into it.  They can't check the copyright.  They can't do anything.  So that is why I think we're going to see hybrid solutions like what we'll be talking about today, where crypto is done right and you get the best of both worlds.  You get all of the features that are only available if, for example, Google can index them, while you also have the option of creating a black box that they just can't see into.



LEO:  Very cool.  That's what we need.



STEVE:  So I have a new section that I'm just going to call "Notes from the Cloud" because I keep getting people tweeting me, hey, how about this one, and how about that one?  It's like, oh, my god, there's just an endless number.



LEO:  There really are.  This is a very popular category.



STEVE:  Yes.  And so my goal, just so that people aren't glazing over as they listen to yet a third episode on cloud storage, which is what we're going to do today, is first of all, obviously, we're not covering the same territory week after week.  We're taking different aspects of it.  My goal is partly to make me focus on this so that I'm able to develop a more mature understanding of what's there because our listeners want to know.  And I have to know in order to translate this into, okay, well, is this crypto right or not?  And also I'd like us all collectively to get some sense for the state of the art in what is clearly going to be a very important segment in the future and where, arguably, security is one of the most significant things, which just happens to be the topic, the overriding topic of the podcast.



So I got a note from Terry Holman, who tweeted - @terryholman - about something called Symform.com.  And what I know about it is only enough to just say - I just sort of wanted - these are just little bullets that, if something I say scratches somebody's interest, then they can go look because this thing is free for up to 200GB.  It's plain and simple storage sharing.  You get as much as you share.  So that's not for me.  I don't want that.



LEO:  That's the Wuala model.  Which, by the way, Wuala apparently has kind of turned its back on.



STEVE:  Backed away from, yes.  What was cool about Wuala was that, as we discussed briefly, is they did a sophisticated - they had a sophisticated system.  But it sort of came out of academia, too.



LEO:  Right, right.



STEVE:  I mean, it was sort of like, could this sort of thing work?  The idea being - I described it as like a RAID array where, in a RAID, you've got redundancy built into all the copies so that several of them could disappear, and you could still reassemble the whole.  So that was sort of a cool academic concept that somebody said, hey, let's sell this.  And that's what they're doing.



My argument with them is that they're Java-hosted, and they're making money.  And I just think, how hard is it to write a native client?  Write one for Windows and write one for Mac.  Now you're done.  Instead of, like, forcing everyone to have Java installed in order to run your cloud backup service.  I mean, if it was free, okay, maybe.  But you're making money.  So hire a programmer who knows Windows and hire a different one who knows the Mac.  Give us a real client.



LEO:  That's a good idea.  Yeah, yeah.



STEVE:  Anyway, so Symform.com.  If you like the idea of free storage or free backup for up to 200GB, you want 200GB remoted from your machine, you're willing to give as much as you get, then this looks like an interesting service.  I don't know anything about it beyond that.  So there.  And then, oh, my goodness.



And here's one from Craig Schappacher, who tweeted about SMEStorage.com.  This thing, my eyes just glazed over with its unbelievable range of options.  They say "Manage all your cloud files in a single unified view."  You can get, for example, Google's free storage, Microsoft's free storage, Dropbox's free storage, everybody's free storage, and then this thing will hook into all of them at once and aggregate them.  So you don't have to pay anybody for over what they offer you for free, yet you get redundancy.  It can copy between them in case those go down.  And it's able to sort of give you a merged result.  And they've got every platform, also.  Linux/Windows/Mac for desk drives and for synch, and iOS/Android/BlackBerry/Windows Phone 7.  So it's SMEStorage.com.  And just wanted to let people know about that, also.  But no deeper dive at this point.



And then a couple things from the Twitterverse.  Brian Hall, who is a - he's described himself as a husband, dad, geek, and IT professional, also the creator of WishyBox, WishyBox.com.  He described it as a "simple, free, universal wish list" of some sort.  I didn't go there to look what it was.  But he says, "Why is it so hard for online synching and backup services to enable client-side pre-Internet encryption?"  And he also tweeted, "If an online backup/synching service were to enable pre-Internet encryption, would that break synching between different machines?"



And I liked this because it highlighted where we're going to go today, which is, if you pre-Internet encrypt, then you are only giving the service completely opaque blocks of data.  They can't do anything with it.  If they have an intelligent client at your end, and you make changes, they could see that only parts of the blocks changed, and so not be re-uploading the whole thing.  If you were to compress it first, the problem there is that then small changes tend to propagate through the rest of the file, causing you to upload a lot of information redundantly.  But sometimes, if you've got the bandwidth, these things don't have - they're free for upload.  So it definitely is a tradeoff.



As for why it's so hard for them to do the encryption, I can only say that that's a bit of a mystery.  I think our audience is, by its nature, in the same way that our audience is over-concerned, for example, with Internet tracking, we're maybe over-concerned with Internet security.  Some people just want the backup.  They think, hey, no one cares about my photos and my docs.



LEO:  Yeah, that's kind of how I feel.



STEVE:  Yeah.



LEO:  And I don't put anything there that I don't want anybody to see.



STEVE:  Well, and, see, I'm willing to because, given that it's encrypted, I understand it really, really, really cannot be cracked.  And so, yeah, it's both ways.  We have all that Google, I mean, we have all these docs up on Google Docs.  It's super convenient that I can put them up there, you can grab them.  We don't care if anyone looks at that stuff.  It's just - it's public anyway.  So there's certainly applications for it being wide open and unencrypted.  Yet at the same time, people are considering, like, backing up their whole hard drive.  And there is stuff there that they would not like to have get out.



I think I'm going to skip some of these, wonderful and tasty as...



LEO:  They're all wonderful, but...



STEVE:  Yes.



LEO:  Yeah.



STEVE:  Oh, there is one thing I wanted to mention.  Because we're recording today, today, apparently May 2nd only, so people who get the podcast...



LEO:  I did it.  I did it.  I did it.



STEVE:  ...or are listening live, Amazon has reduced the price of the Kindle DX, $120 off today.



LEO:  Off?



STEVE:  Yes.



LEO:  Oh, wow.  Do I want one?  You have one.  I know you love yours.



STEVE:  I have one.  I got one off of eBay for Mom because I wanted her to have a white one that's no longer available.  She loves it.  I do all my reading on it, despite the fact that I have every other one they make or have ever made.  I just like the bigger screen.  I like having more text on there and paging less often.  It's not like I don't like to page, but I don't know, it just - it feels right to me.  And I got a couple tweets back.  I tweeted this, so anybody - there is a funky link that you've got to use to find it, so it's in my Twitter feed - again, Twitter.com/SGgrc - and you'll find it there.  It's May 2nd only.  They're calling it a Mother's Day, pre-Mother's Day offer, just for today.  And so it brings the price down, with their leather cover, to $299.  I mean, so it's still pricey compared to the $79 one.  But normally it's north of $400.  So anyway, I just wanted to let people know in case they're interested.



Also, for those who loved the Lost Fleet series, Robert Spivey tweeted:  "Hey Steve, you should mention for the sci-fi fans on Security Now! the latest 'Lost Fleet' book was released on 5/1:  'Beyond the Frontier:  Invincible.'"  And yes, my copy came yesterday.  So I do indeed know.  I don't know when I'm going to get to it, though, because I'm deep into health stuff at the moment.



LEO:  We should mention, and since you said the word...



STEVE:  Okay.



LEO:  ...that in order to protect the gentle ears of you, our listeners, we're not going to do any health stuff on this show.  But Steve is going to do a health special this week.



STEVE:  Yes.  Something since I last talked to you, Leo, two weeks ago, I have had some amazing stuff happen, completely unexpected, completely - I just didn't expect it.  I figured out what was going on.  I dropped the reading I was doing, switched to something else, have been deep into some new research.  I have stats and numbers and something really, really cool.  We'll be able to tell people what it was next week.  But you and I are going to do a special on Sunday for an hour at 2:00 p.m., between 2:00 and 3:00, from the end of your Tech Guy show and before the beginning of your Sunday TWiT program.



LEO:  Yes.



STEVE:  And anybody who's interested in health stuff, all I can say is you will not be disappointed.  This is - and Leo, we're going to have fun.



LEO:  Oh, I can't wait.



STEVE:  I would say it's - the reason I don't think it's necessary to preempt Security Now!, as I did once for the Vitamin D episode.  I felt better about that because all I was asking people to do was take a pill.  And anybody can do that.



LEO:  This is more serious now.



STEVE:  This, well, this requires you thinking about if you want to do this.  But I am never going back.  My life has been changed.  My life has been changed forever.  I'm not kidding you.  It's been changed forever.



LEO:  Wow.



STEVE:  And I think yours will be, too, because you're the kind of guy who'll be willing to try this.  I'm going to give you the motivation based on what I have learned and what has happened to me that I have measured and documented.  And I know we've got listeners who will, if nothing else, find this interesting.  And maybe it'll plant some seeds.  So we're going to do an hour-long special, the second special about my interest in and hobby in health.



LEO:  And we should, well, we'll have all the disclaimers at the beginning of the show on Sunday.



STEVE:  Of course.



LEO:  But tune in, 2:00 p.m. Pacific, 5:00 p.m. Eastern.  That is 2100 UTC on Sunday.  And Steve won't tell me anything else.  It's a surprise.



STEVE:  Okay.  I did want to reiterate something because several people have loved what I stumbled on.  I don't know if you know, Leo, that there is a really fantastic web interface for TweetDeck now, web.tweetdeck.com.  And it looks exactly, I mean, it's like - it's amazing.  And Iyaz just, well, he's no fan of TweetDeck.  I guess when they updated it or when Twitter bought it, he lost all of his column settings, and that pissed him off, and he abandoned it.  But a number of people agreed with me, saying it is really impressive.  I'm just - I look at it, and I'm amazed what we can now do with HTTP.  I mean, it runs on - I ran it on Firefox and on Chrome, just as my two browsers that I normally use most.  Oh, and IE.  It's TweetDeck on a web page, working perfectly.



LEO:  Yeah, it is amazing, isn't it.



STEVE:  So, wow, yeah, I'm just very impressed.  Okay.  Now, sci-fi update.  I tweeted, "Am I the last person to know about this?"  And...



LEO:  No, I am, actually.



STEVE:  I think, oh, my god, Leo, this thing looks unbelievable.  This is Ridley Scott, who gave us, of course famously, the first "Alien" movie that blew our minds, has done a prequel.  And if anybody is interested, it's called "Prometheus."  IMDB.com, Internet Movie Data Base, it's right on - it's on the home page of IMDB.com right now, the latest trailer, which is about 2.5 minutes long.  And careful, though, because, I mean, it is a spoiler for people - I tweeted this, and I got some people saying, wow, more than tidbits, there's a lot there.  But, oh, my god, it looked, oh, it's June 8th is the release.  So we don't have to wait forever.  So I'm almost glad that I'm the second to the last person to know because otherwise it'd be one of those, like, oh, yeah, in 2014.  It's like, oh, well, great.  It's soon.  And, oh, it is - oh, well, I've said enough.  IMDB.com.  It's called "Prometheus."  It's all over YouTube, lots of really good trailers.  And it just looks fantastic.  So I'm really pleased.



Oh, and "Chronicle" comes out for release on disk next week, which was the sci-fi movie I did not see in the theater because I assumed it would come out quickly.  That's where the three or four teenagers go walk, see a hole in the ground.



LEO:  Yeah, I want to see that.



STEVE:  And then they - something happens, and then they start acquiring superpowers.  But this is sort of like the dark side, like what would happen if Henry had superpowers, Leo.



LEO:  [Laughing] Noooooooo.  Okay, go ahead.  Henry's my son, for those of you who don't know.  And he does, he thinks he has superpowers, anyway.



STEVE:  You can imagine that might not turn out so well.



LEO:  No.



STEVE:  Yeah.  So, yeah.  If there was nothing to restrain him, if he actually could do anything he wanted, oh, all hell would break loose.



LEO:  Well, you know, he has been studying UFC kickboxing and mixed martial arts.  So I'm terrified of him anyway.  He practically does have superpowers.  I think he could kill me with a look, if he decided to.  But don't tell him that.



STEVE:  So I did want to say to people, I've had a number of people say, what was that book that Leo liked so much, that you recommended?  So I just wanted to - we're not going to spend any time on it, but it's "Deadly Harvest" by Geoff Bond.  I like it as much as I did.  I think it's the place to start for understanding, for acquiring a really solid view of an approach to diet.  And what we'll talk about, you and I, for an hour on Sunday, is some surprises that, I mean, that really, like I said, probably have changed my life forever.



LEO:  Wow.  But you're not eschewing what we have learned.



STEVE:  No no no no no no no.



LEO:  Okay.



STEVE:  No.  This is all - it was an interesting catalyst and...



LEO:  But you've gone beyond now.



STEVE:  I've really gone - I've gone where many people have gone before, but I'm staying here.



LEO:  Okay.  Good.  I need something, so whatever you say, I'm doing.



STEVE:  I think you and others will say, wow, that works?  I'm going to try it.  Speaking of what works, I got a note from John Newcomb, who said, "SpinRite Kudos.  Dear Steve, just wanted to tell you how much I appreciate you for all the great info I get from your podcast with Leo Laporte.  You have such a wonderful radio personality, and with Leo, you guys are a great team.



"I recently bought a copy of SpinRite that I have added to my bag of tricks.  I'm a computer tech and work for a company who serves the dental industry.  SpinRite has already saved me a lot of time.  I was in an office the other day working on a machine that would not fully boot Windows.  So I ran SpinRite, and it recovered several bad sectors, which then allowed me to image the drive, which I couldn't before, and install a new one.  Thanks for making my job so much easier.  Your software works so well.  In using it and observing all the little details, I think it's clear how much care you put into it.  Sincerely, John Newcomb, Oakland, California."  So, John, thank you for sharing that with me and our listeners.



LEO:  And as I remember, we're going to take a break for our Carbonite ad, and we'll get to your new three cloud solutions, including one that makes you want to go to the Mac.



STEVE:  Oh, Leo.  I think this is the one for you.



LEO:  I'm going to have to rethink.  I've got Google installed, a Google Drive installed now.  And I've got SpiderOak.  You're going to throw me a curve.  All right.  All right.  I'm ready.



STEVE:  Okay.  So I went off a little half-cocked about this one, okay, because I loved the cleverness of their crypto.  This is one called Cloudfogger from some guys in Germany.  Sort of a funky name, like foggy clouds, or the idea being that it obscures what's in the cloud.  It's Cloudfogger.com.  And I tweeted about it.  Bunch of people looked at it.  And then when I actually tried to use it, I was a little put off, only because it's very new.  And while the crypto is done right and cleverly, it just doesn't feel very mature yet.



For example, a Windows application has to be multithreaded so that there's a user interface thread which keeps the user interface alive while other threads are busy doing stuff in the background.  This appears not to have that.  So that what it, for example, it is an encryption utility - all three of these are encryption utilities where they allow you to create a virtual drive on your machine which maps to a folder somewhere else.  And that could be a folder in the cloud.  So, like, a folder in your Dropbox, or a folder in your SkyDrive, or a folder in your G Drive.  And the idea being you don't mess with that.  You mess with the virtual drive.  Anything you put into the virtual drive, it seamlessly encrypts and places in this folder, which then the cloud service says, oh, there's a new file in the folder, and then it separately sends that off to the cloud.



So they, for example, don't allow you to, as they're setting it up, tell it where you want to install.  Which really annoys me.  It just puts it under Program Files > Cloudfogger.  But I've got my hard drive organized differently, so my categories of subfolders under a different directory.  And so I like to be able to say, oh, this goes under "Cloud."  I have a new category, even, called "Cloud," for cloud stuff.  But I couldn't do that.  It also, by default, assumes that you want to map "X" as your drive, doesn't give you a choice.  But I already have "X" mapped for something, and "W" is a map I already have.  And so it worked its way back up to "V," which was the first one free.  But it took forever.



Meanwhile, this single thread in the user interface just locked the whole thing up.  It's like it - and I'm sure Windows users have seen where up in the title bar it'll say "not responding" because Windows at some point realized that users would be confused by this, by the fact that the app was not really well written for interaction.  And so Windows takes responsibility for posting that into the title bar if the app is no longer coming back and picking up events from the UI event queue.



So these things can be fixed, and I think they will be.  It's only Windows, currently, and actually I put "Windows (sort of)" in my notes, and "Android (sort of)."  But so they have those.  And it's going to get better.  And they're promising Mac OS X and iOS.  So that's hopefully going to come.



And for me, I let it sit there for a couple days and noticed that it used up a quarter gig of memory, and it was sort of silently creeping up.  So I posted an update in Twitter saying, whoops, this things seems to be burning up RAM.  And I got some people who said, well, I'm under Windows 7 x64, and it's not doing that for me.  And I did see other people say, yeah, me, too.  So there's some things that they need to deal with.



Also, I was thinking of, when you were talking about the end-user license agreement problems, they also had a little problem with their EULA.  There was a Paragraph 10 that everyone started tweeting about, actually after I brought this to everyone's attention, because it was one of those overly broad, everything that you have is ours statements, which they immediately fixed and backed out of and blogged, we're sorry, we didn't really mean it, we just weren't thinking, blah blah blah.  Same sort of thing.



But their crypto, their crypto is right, and the crypto is clever.  They've solved a couple problems in a way that no one else has, that I liked.  So let's get a little techie for a second.  This is file-by-file encryption, when you have them encrypt a file because you drop a file onto the virtual drive.  So what you're dropping is a file in the clear, so-called "plaintext" in crypto speak.  They use a pseudorandom number generator, and they're using a very popular crypto package.  It's [Crypto++], if memory serves me right.  I think it's [Cryptopp.com], in fact, is the site.  It's a well-vetted, nice, good choice for a crypto library.  So they use a pseudorandom generator to generate a 256-bit AES key.  So that's randomly generated.  And that's the key that they use to encrypt the file.  So now the file is unreadable, and we've got this key.  When you install the system, they generate a public and private key pair.  And the symmetric key which they just - this random symmetric key is then encrypted using your public key so that now the only thing that can decrypt it is your private key.  And that's yours to have and to hold.



Now, the cool addition is that you're able to share this with other users of Cloudfogger.  So you can set up a community - oh, and I forgot to mention, this is free, 100 percent free, currently.  What they say on their site, and I'm sure they'll honor this, is that, if you get it now, what it is and what it does will always be free for you.  And it's unlimited size, no random, arbitrary, we're going to make you pay if you're over 2GB or something.  So it's completely free.  It's one of the reasons I liked it so much was my sense is that, for this class of application, it ought to either be free, or it ought to be pay once.  I can't see somebody saying to just do this we want you to pay X amount of dollars per month.  That's just not enough.  It's like, what, and then also pay the cloud storage provider whose storage I'm using?  That doesn't make any sense.



So this is free forever.  Their plans are they're wanting to promote this and to establish themselves because they're very new.  And then they'll offer additional features.  We don't know what.  They're not saying what.  But that you may have to pay for, only if you want to.  What they are offering now, if you get it, you'll never have to pay.  So I think that's cool.  And I'm sure they'll mature this over time, get more platform support, fix their little Windows UI problems.  I mean, it works.  Many people played with it after I tweeted about it and had no trouble.



So what's clever is that, if you want to share this with people, then the symmetric key which is used to encrypt the file can also be encrypted with other people's public keys.  So, for example, if I want to share this with somebody else, I get their public key through the system, and I encrypt this 256-bit symmetric key with their public key.  Now they're the only people who can decrypt it.  But the file can have multiple of these public key encryptions in its header.  So essentially you very easily, very nicely, with full TNO, full Trust No One security, you can specify which of your group you want to be able to give access to.  And since they have the matching private key that allows them to decrypt this, and only they do, and we know how asymmetric encryption works, that is, public key encryption, you encrypt with one, you decrypt with the other, and that's the only way it works.  That gives you really nice access control, and the file is then stored in the cloud, wherever you want it to be.  And you could control who has access.  So I really like it.  It's simple, and it's done right.  Now, one very clever part is they solved the problem of password recovery.  The problem that, as we discussed last week, that - god, I'm blanking on the name.



LEO:  Backblaze?  Backblaze.



STEVE:  Backblaze.  Thank you, yes.  The problem that Backblaze had is, when we were discussing why they did this, the cofounder and CEO said, well, yes, Steve, it's very nice if you have TNO, but then the problem is password recovery.  Users who lose their password are, like, they're screwed.  There's nothing anyone can do to get it back.  And I said, well, yes.  There's some responsibility that comes with that.  And they said, well, we've decided that we'd rather make it possible to give them their password back.  Yeah, by asking for it.  Okay.



LEO:  Now, that's fine, and then you have the choice, that's all, if you want to do that or not.  Right?  If you're the kind of person who loses passwords, and you want Backblaze to have access to your password and files, then you choose that.



STEVE:  Yes.  And the problem is they - Backblaze tells you that you can password-protect it.  But the way that works is you give them your password, and they encrypt your private key on their server with your password.



LEO:  In their defense, this is a very common choice.  Lots of companies do this, including Dropbox, by the way.



STEVE:  Yes.  And I did say that their security is better than other people's.  It's just not TNO.  It doesn't survive the test of does plaintext ever exist outside of your system, systems under your control, and does any secret that is important ever exist outside of your control?  And unfortunately, both of those they fail.  So TNO says those will always be true.



What Cloudfogger does is clever.  If you want to enable password recovery, if you're worried that you might lose your password - and I just don't know how that's a problem.  But again, if Jenny were using this, maybe that would be a problem.  She'd say, oh, I forgot what I used.  It's like, okay, well, now we're in trouble.  What they do is they hash your password, and they have secure password hashing.  We've talked about doing that 10,000 times in order to make it a slow process.  They hash your password into a 256-bit hash.  They take half, they split it in half, and they take 128 bits of it.  And that they save.  You keep 128 bits on your system.



Now, remember, this is the after-hash password.  So you're entrusting them with 128 bits of the hash after the password is hashed, and then the other 128 bits is stored on your system.  Then if, at some future time, you can't remember what password you put in in order to generate all 256 bits, you scream for their help, and they say, okay, we will mail you our half to the email address registered on your account.  So they use an email loop to provide some security.  But they're only giving you half.



And remember, 256 bits today is overkill.  128 bits is just fine.  So they're only getting half.  But the beauty is you need both halves.  So when this comes in through email, that 128 bits is merged with the 128 bits you still have to have on your machine.  That generates the 256-bit result of hashing your password and gives you access to all your files, and then you can change your password.



So I thought that was very clever.  It's a means of they never have the whole thing.  You don't even, on your machine, have the whole thing because otherwise the danger would be somebody else could tinker around with your machine and get access to your files with no password.  But and clearly, if somebody has unfettered access and can do the email loop, then there is that problem.  So you don't have to do this.  But if you want to enable it, it's a clever compromise.  But still, in a way, for example, that Backblaze doesn't do correctly, these guys did because they can help you recover, but they still never have enough to decrypt your files.



So anyway, my sense is that it works, it runs under Windows, eh, not ready for primetime, but it's brand new.  And so I cut them some slack.  We'll keep an eye on them.  We'll see how they do.  They're going to develop for multiple platforms.  But their crypto is good.  They've got good, solid crypto.



LEO:  Again, that's Cloudfogger.



STEVE:  Cloudfogger.



LEO:  Cloudfogger.



STEVE:  No. 2, BoxCryptor.  I talked about it briefly two weeks ago, but just sort of glazed over it.  I have since looked at it.  And I am very impressed.  This is very mature feeling, very nice guided setup.  Oh, one thing about Cloudfogger that I wanted to also remind myself to tell you guys is, due to the way they're doing this, filenames are visible.  And that's a problem.  So, yeah.  So they put their own extension on the filename in order to disambiguate it from those that aren't their extension.  And a number of people tweeted back, hey, my filenames are visible.  Well, that's a fundamental limitation of their approach.  And I don't know if they're going to fix it, or if they can.  But leaking filenames is annoying.  So, and the reason I've just remembered is that BoxCryptor doesn't.



There is a project that somebody worked on over in the Linux world called the Encrypted Filesystem, EncFS.  Wikipedia has a page about the encrypted filesystem.  It's a nicely designed, generic, well-documented, cryptographically secure and cryptographically encrypted filesystem.  The clients are Windows today, and iOS and Android.  And they don't yet have their own clients.  But for Mac and Linux there are existing encrypted filesystem drivers.  So, for example, if you were a multiplatform person, you could arrange to mount the BoxCryptor encrypted filesystem so your Mac or Linux machine could see it.  But I would not advise it.  I would wait for the third solution that we'll be talking about next, if you're a Mac person, because it's the one...



LEO:  He's such a tease.



STEVE:  It's the one that makes me want to switch to Mac, it's so beautiful.  For Windows, this is really nice.  I've got it running now.  I'm impressed.  It feels smooth.  For free, you get to play with it and to create one virtual drive.  I don't think there's a limit on its size.  But it's got me wanting to pay.  And again, this fits my model for a hybrid solution.  You pay once.  It's not expensive.  I think it's $29.  Or I think there's two versions.  I think there's a personal and a commercial version.  So you pay once for Windows, and this allows you to create a virtual drive.  It walks you through the process.  They do have iOS and Android viewers, so you're able to use those clients in order to see into your encrypted drive for cross-filesharing.



So I like it very much.  There's an advanced mode where you can do some funky things.  For example, you can have different passwords for different sets of files in the same encrypted filesystem so that you could arrange to give other people access to parts of your data.  And it's all explained.  They've got good documentation, nice PDFs for their Windows, for their iOS, and their Android client.  And I like it.  So I did want to do it justice because I sort of just glazed over it last week.  We were doing the alphabetical order, and it's "B," for BoxCryptor, so I looked how far we had to go, and I thought, well, can't spend much time on this.  But I've now used it.  And I think they've done a great job.  So if Windows, iOS, and Android fits, take a look at it.  I see no downside.  And it does encrypt your filenames.



There's a little bit of leakage inasmuch as you can get a sense for the length of the filename because it has to be padded out to the block size of the encryption.  So, for example, I created an !.txt file, and it created a little blurch of pseudorandom characters that were, like, 9 or 10 long.  And if I went beyond that, then it jumped it up to 18 or 20, whatever it was.



And there was one other thing.  They're still working on support.  The encrypted filesystem uses the entire pathname of the file to initialize the encryption for the file and the filename.  Their current implementation - and that's called IV, initialization vector chaining.  Their implementation doesn't have that yet.  So the same filename in different subdirectories has the same cryptographic name, which is like a little annoying.  It'd be better if that were different because, I mean, it does tell you that it's the same named file, even if it's different contents.  But that's the kind of thing I think they will probably fix moving forward.



So I like it.  You can play with it for free and pay for it once.  And you've got very solid-looking - oh, and I forgot to mention.  When you pay for it, then you get to add drives.  So not just one mapping between a virtual drive and a remote folder, but multiples.  So if you were using Google Drive and Dropbox and SkyDrive, you could set up different drives and have things scattered all over the place and really confuse yourself.  And finally...



LEO:  I've been waiting.



STEVE:  The company is Haystack Software.  I think it's a guy or gal.  But, I mean, doesn't have a feel of a big organization.  And I don't care because he's nailed this.  The product is called Arq.  And I just tweeted about it so that our listeners, our Mac users could find it.  Actually it's funny because I said, "The deeper I dig into this, the more I'm impressed and the more I wish I was a Mac user."  And of course you can imagine what came back.  It's like, Steve, it's not hard to switch.  Steve, it's - just give it a try, Gibson.  And it's like, no, I mean, I'm a Windows developer, so I'm stuck here.



LEO:  You're stuck.  He always says, folks, until he retires, and then...



STEVE:  Yes.



LEO:  Then he can go Mac.



STEVE:  Oh, my god, I'm so impressed with the Mac.  I like it so much more.  And Leo, I'm...



LEO:  It'll be very different by the time you retire, I just want to say, Steve.  We don't know where it's headed.



STEVE:  Yeah.  Someone even warned me, someone said, Steve, you'd better switch now before OS - I think he said OS 9, but that couldn't be.



LEO:  He meant OS 11.  I think really it's the iOSification of the Mac that we're all worried about.



STEVE:  Ah, yeah, that's not good.  I just - I've come to a formal decision, also.



LEO:  Oh?



STEVE:  I'm never leaving XP.  Not even when my three years are up.



LEO:  7's nice.  You don't like 7?



STEVE:  Not even when my three years - no.  XP, it's like, it's still in my way.  I've tried to get used to it.  It's like, there's just nothing I need over there.  So...



LEO:  It's not supported at all, of course.



STEVE:  [Indiscernible] down, yeah.  Well, it is for three years.



LEO:  Yeah.  Then you're going to have to make a decision.



STEVE:  Yeah.  I've already made it.  I'm not moving.  I'm unplugging.  We'll set up a telegraph, Leo.  Okay.  So Arq for the Mac by Haystack Software, HaystackSoftware.com/arq.  One-time purchase of $29.  It is a beautiful frontend for Amazon's S3 service.  And of all of these providers, I just - I like S3.  I mean, Amazon is huge.  99.9999999 percent uptime.  Any two Amazon datacenters can completely evaporate.  They could just disappear, and nothing gets lost.  Amazon's doing a good job.  You pay Amazon.  So you have an S3 account.  You pay Amazon.



Amazon has dropped their price, by the way.  It used to be $0.15/GB/month.  Now it's $0.125/GB/month.  And they dropped their upload transit.  So there's no fee for uploading.  And I mentioned last week, probably the week before also, that I love that because it allows me to send stuff up, to be like continually updating images of my systems with no cost.  It's not until I need one that I pay anything.  So I just really like it.  The guy did a beautiful job of his Trust No One security.  He has the full crypto spec and documentation published on his site.  There's an iOS app called ArqView for the iPhone and iPad that gives you obviously shared access to it.  There's even a command line version which is open sourced and available.  So you can see how it works.



Now, one thing that gives you a sense for the thoroughness of this guy is there's a completely independent guy, Nathaniel Gray, who is N8Gray.org.  He's got a bunch of crazy stuff on his site.  One is called Backup Bouncer.  This is an independent test suite for Mac backup utilities to see if they get it right because there's - it's one thing to have the actual file contents.  And everybody is obviously going to get that right.  But the metadata is often equally important.  It's user access...



LEO:  It is on the Mac because the Mac relies so much on metadata.



STEVE:  Yes.  Permissions, ownership, timestamps, symbolic links, ownership of symbolic links, hard links, resource forks, finder flags, finder locks, finder creation data, BSD flags, extended attributes, access control lists, all of this stuff.  So this guy, he says on his site:  "Hey there, OS X user!  Do you back up your files?  Of course you do.  Right?  Right??  But do your backups work?  Really?  Are you sure?  Have you checked?  Backup Bouncer" - and it's free, of course - "is here to help keep the ugly backup tools out of the club.  It's a command line-based test suite that makes it easy to find out how bad (or good, if you're lucky) your backup software is.  It aims to be a comprehensive test for preservation of all OS X file metadata.  The initial release tests for preservation of" - and then he's got a list of stuff that I partially read just now.



And he says, "Backup Bouncer can do many things to make testing easier for you.  It can create test volumes; populate them with interesting files; run a test suite of popular and not-so-popular commandline copiers including cp, rsync, tar, ditto, pax, and xar; verify the results of a copy, either from its own test suite or your favorite command-line or graphical tool," blah blah blah.  Anyway, only two backup solutions pass:  Arq and Jungle Disk.



LEO:  And they both go to S3.  Actually, Jungle Disk, now Rackspace.



STEVE:  Right.



LEO:  This sounds like kind of the new Jungle Disk for the Mac.



STEVE:  I think it is.  I really like it.  One-time purchase, 30 bucks, actually 29.  And I like - I'm liking S3 on the backend just because nobody's bigger.  Nobody bigger is going to buy them.  I mean, this is what happened to Jungle Disk is they got bought by Rackspace.  And Dave left.  And so the developer's gone.  And it sort of feels a little bit like it's maybe wandered off course.  It hasn't been updated for a long time and so forth.  And there are people who are having problems with it and having a hard time getting the support.  So I really like this.  I think this is for - if S3 makes sense for you, that kind of storage pricing, where you only pay for what you use, and...



LEO:  You know, I'm impressed by this.  They have a - when you install it, it has a little S3 storage budget calculator.  So you could say, well, I want to spend $10 a month.  Well, that's 71.43GB.  Okay, well, I want to spend $5 a month.  Well, that's, oh, I have to go back.  That's 35.7GB.  So you can actually figure out - and it will delete older backups to keep your costs within that budget, which is something Jungle Disk never did.



STEVE:  Ooh, no.



LEO:  I really like that.  So you can say, well, I'm going to spend 20 bucks, so I'll get 142GB.



STEVE:  And then it'll automatically manage that for you.



LEO:  Yeah, it'll delete older stuff.  You can also - you're right, he knows the Mac.  He knows them.  He's paying attention.  And you can say "Backup my home folder except caches, logs, and trash," or manually add.  It has drag-and-drop, which is very nice.  Yeah, I agree with you.  This is quite nicely done for people who want to use it on the Mac.



STEVE:  Yes, who want a solution as a frontend for S3.  Yeah, and I like it that, I mean, you buy it from him.  Amazon's not going anywhere.  No one's going to buy them.  They are rock solid cloud storage.  And this makes it secure because, again, the crypto is done right.  Strong crypto, all performed on your own machine, on the client.  Nothing but pseudorandom noise goes up to Amazon.  Amazon doesn't know what you're doing.  It just knows, okay, I've got a bucket of bits that looks like scrambled noise.  Like it.



LEO:  Right.  This is nice.  And it's 30-day free trial, so try it.  Of course, it's not free.  The Amazon will start charging you immediately.  But...



STEVE:  Actually, apparently, Amazon's got 5GB free for a year.



LEO:  Ah.



STEVE:  Yeah, he mentions that on that page.  AWS from Amazon, free 5GB for a year.  So, although you have to have an Amazon account, and so that gets you over to Amazon.  But who doesn't?  I mean...



LEO:  And of course Amazon today, knowing that you were going to do this story, released an app for their Cloud Drive Solution, so for Macs and PC.  So...



STEVE:  Eh, it's Java-based, Leo.



LEO:  Is it?  Of course it is because it's cross-platform, yeah.



STEVE:  Yup, of course it is, yup.



LEO:  So obviously this is a category everybody wants to be in.



STEVE:  Yeah.  And again, we're not going to beat this thing to death.  But I wanted to spend this time to give people, like, an overview.  Certainly cloud security matters.  And I'm hoping, I mean, I know that we have some effect, at least on the little guys, that is, this podcast does, because I've gotten feedback from everybody.  I mean, it matters.  And I just want them to do the security right.  It's just not hard.  It's just - mostly it takes caring about it.  All the technology is there.



So I want to wrap up by talking about this compared to TrueCrypt because TrueCrypt is the granddaddy of filesystem encryption.  And there's been some confusion about how these types of solutions interface with TrueCrypt, and how TrueCrypt can be used in the cloud.  And TrueCrypt is fundamentally different because TrueCrypt, the way you would use TrueCrypt in the cloud is you would create a container file on your hard drive, and this would be a fixed size.  So you need to allocate 10GB, which once upon a time was insane, but now we all have terabytes.  So you create a container file to hold the filesystem.  Then you use TrueCrypt to encrypt the filesystem in that container file.  And then you put that container file in the cloud.



Now, once, initially, you're doing a 10GB upload, that is, the entire container that is a TrueCrypt filesystem goes off to the cloud, 10GB, there it goes.  Even if it's empty, 10GB because, when TrueCrypt encrypts it, it turns the entire thing into noise.  It all looks like it's got data in it.  So off it goes, 10GB.  Once it finally gets there, then, if we assume that your client, the client that's managing this cloud service for you, is intelligent, and lots of them are, they're only going to update tiny portions of this large file, if that's all that changed.  Almost all of them that have matured look at the file that they've got versus the file that you've got.  And when you make a few changes, they only send those up.



So the beauty of TrueCrypt is that, when you make some changes in your TrueCrypt volume, it's like sectors or clusters on the hard drive.  Only those clusters that are about the files you're changing and the metadata, like the directory system and timestamps and things, only those change.  So they're relatively small incremental changes to the whole 10GB, for example, TrueCrypt volume.  And those get shuttled up to the cloud, and then you're synchronized. 



Now, the problem with TrueCrypt is it really wasn't designed for this application.  We're sort of stretching it that way.  And I have heard, and I have said, and it's since been confirmed, that you cannot leave the TrueCrypt volume mounted.  That is, TrueCrypt acquires exclusive ownership of this volume file and won't share it with the cloud client.  So it's necessary after doing things to unmount, to dismount the volume from TrueCrypt.  Then the cloud storage thing can see that it is available and changed and make the updates.  So it's not as transparent.



The other problem is, even if you stored nothing in the 10GB TrueCrypt volume, you've still stored 10GB in the cloud because basically you're storing a whole drive in the cloud.  So you're paying for it, even if it's empty.  That's where these file-by-file systems have the advantage that basically you're storing encrypted versions of your file.  The downside of doing that is you can see that there are files, and there are directories.  They've got cryptographic names, but you can sort of - there is some leakage of this metadata, timestamps and structures of the file system.  Now, I don't know that that is a big concern.  But the beauty of TrueCrypt is there is nothing that anybody can tell from the outside of this blob.  They can't tell how many files, how big they are, what's going on.  They could detect that you changed something, if they were watching really closely.  But it's just random changes, literally random changes, of this big blob, so it doesn't really get them anywhere.



So, I mean, TrueCrypt is maybe the ultimate TNO.  There are people using it.  They are using it in the cloud.  They say, yes, you've got to unmount the volume for it to update.  But they like the fact that it is TrueCrypt.  And we've talked about it.  We've been discussing it in various contexts for years.  It's very solid.  On the other hand, there's nothing unsolid about these file-by-file systems.  And, frankly, that's the approach I take.  I'm doing the file-by-file approach rather than the big homogenous drive that TrueCrypt creates.



So I think we're done for now.  I'll keep my eye...



LEO:  "For now" being the operative...



STEVE:  Yes, for now.  I'll keep my eye out for other tweets, people bringing things to my attention.  We'll watch these various things evolve.  I think they're going to.  Now, I just said that, and I realized I never did yet talk about SpiderOak, which is already mature-seeming, mature-looking, and beautifully cross-platform.  I think maybe we'll take a break for a couple weeks, let people catch their breath from all of this.  And then, after I have some more experience with SpiderOak, be able to talk about it more knowledgeably.  I mean, it looks like a nice utility.  I just have not drilled down into it and figured out how they do the things that they do.



Oh, I think Arq is the one, also, Leo, he says on his page that he is doing versioning, and he keeps, like, every file per week for the last month and every file for the last month for the prior year or blah blah blah blah.  He's got some nice sort of a hierarchical versioning deal that's...



LEO:  Yeah, I'm looking at his folder structure on S3, and it doesn't duplicate my local folder structure.  So he's obviously doing some smart stuff.  And that's why that calculator makes sense.  It even says, you tell me what's your limit on spending, and I'll keep versions up to that point, but delete the oldest versions at that point.  So versioning is very handy.  I really like that.  And a lot of tools don't do such a good job with that.  So that is attractive.  And I like the idea of using S3.  But I'll be very interested to hear your comparison to SpiderOak because I use that currently.  And I don't know.  I'm running Arq right now.  I don't know.  How many backups can one person have?  Is there such a thing as too many?  I don't know.



STEVE:  Leo, if there is, you will find it and break it.



LEO:  And I have Google Drive and everything else.  I just don't - what I'm really looking for, the thing I'm most loathe to lose is my photos.  I've got my - documents are small; right?  Because that's not - it's just documents.  So that I've got backed up in a number of ways.  But the photos are large.  We're hundreds of gigabytes here.  And that's, in fact, close to a terabyte.  And that's where I'm a little concerned.  I use a service called SmugMug.  I don't want to add to your list here.  But SmugMug, which is a photo-sharing service for pros, does support S3.  So what happens is you can say, when I upload the originals, I want the originals stored on S3 at additional - I pay the S3 charges.  But that's nice because now I have the originals stored in S3, SmugMug has the JPEGs and albums that I can share and buy prints of.  And so that's kind of how I'm doing it.  Although a terabyte on S3 is not cheap.



STEVE:  Leo, I really want this for Windows.



LEO:  Arq.



STEVE:  That is to say, Arq.  He says, under "Wayback Machine," "Arq keeps multiple versions of your files."



LEO:  Love that.  Yeah, love that.



STEVE:  He says, "Following the initial backup, Arq automatically makes incremental backups, every hour, every day, uploading just the files that have changed since your last backup."



LEO:  Perfect.



STEVE:  "Arq keeps hourly backups for the past 24 hours, daily backups for the past month, and weekly backups for everything older than a month."



LEO:  Perfect.



STEVE:  So, yeah.  So it's like, a beautiful hierarchical staging backup system, allowing you to go back to prior versions of things.  No file size limits.  4GB or 40GB, doesn't matter.  Backs up your external drives and your network drives.  Doesn't delete backups of your external drives just because you haven't plugged them in lately.  Oh, there are a couple services that do that.  If they haven't seen an external drive for a while, they just remove it from your cloud.  It's like, ouch.  So anyway, very nice for Windows.  Oh, sorry, for Mac.  I wish it was for Windows.



LEO:  Well, there are other solutions, I'm sure.  And we'll find out about them because everybody's going to tweet them at you.  And you'll never - this is not done.  Remember...



STEVE:  Leo, I've opened a real can of worms with this.



LEO:  A special health-focused Steve Gibson - we're calling him "Steve Gibson, Lab Rat" - episode.  This is not a Security Now! episode.  We've segregated it for those of you who can't stand yet another discussion of diet and health.  But if you're interested, Sunday, 2:00 p.m. Pacific, 5:00 p.m. Eastern, right after The Tech Guy, right before TWiT.  That's 2100 UTC.  And we'll put it out as a special, not in the Security Now! feed, but in a TWiT Specials feed.



STEVE:  Right.  And next week, when you do know what it was we talked about...



LEO:  Then we'll talk about it.



STEVE:  Then we'll talk and convince those people who haven't yet listened that maybe they should.



LEO:  There you go.  That's a solution.  Steve is at GRC.com.  That's his site for SpinRite, the world's best hard drive maintenance and recovery utility.  One must have it, if one has hard drives.



STEVE:  It pays my bills.



LEO:  And it pays Steve's bills, so it's a good thing just to buy it anyway.  He also makes available freely, at his own expense, 16Kb versions of the audio of this show, for people with bandwidth limitations, and transcriptions, which he pays to have done each week from the wonderful Elaine.  Thank you, Elaine.  Thank you, Steve.  That's at GRC.com.  If you have a question for next week's feedback episode, I guess tweeting @SGgrc works.



STEVE:  It seems to.



LEO:  But I think this week we'll also take questions from GRC.com/feedback, since we didn't do that last week.



STEVE:  Yes.  Sometimes the question does need to be longer than 140 characters.



LEO:  You know, I like the short ones, though, I've got to admit.



STEVE:  I know.



LEO:  There's something to be said for them.  And you can find the full quality versions in video of this show, as always, at TWiT.tv/sn, going way back to Episode - I don't even know what it is.  One.



STEVE:  One.



LEO:  350 episodes ago.



STEVE:  Yeah.  We should have started with zero, but live and learn.



LEO:  Hey, Steve, thanks so much.  Have a great week.  And I will see you Sunday for that special edition.



STEVE:  Oh, I can't wait.  I'll make some notes and organize, and I'm going to blow your mind, Leo.



LEO:  I can't wait, either.  And we'll see you all next week on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#352

DATE:		May 9, 2012

TITLE:		Listener Feedback #143

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-352.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is back with security news and answers to 10 of your questions.  It's all next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 352, recorded May 9th, 2012:  Your questions, Steve's answers, #143.



All right.  Turn on your modem.  Tune in your router.  Fire up your browsers, ladies and gentlemen.  It's time...



STEVE GIBSON:  And get under your desk.



LEO:  ...for Security Now!.  Thanks to PWR for writing my intro today in our chatroom.  Steve Gibson, the one, the only, the man, the myth, the legend, the Explainer in Chief is here.  Hey, Steve.



STEVE:  We've got it all bundled together in one...



LEO:  Yeah, one giant expletive.



STEVE:  ...giant description, yes.



LEO:  Steve is a security wiz at GRC.com.  He writes SpinRite, the world's finest hard drive maintenance, and recovery utility.  And he is here to answer questions today.  This is Q&A #143.



STEVE:  Well, you dragged me over here to give our listeners some feedback.  Or they've given us some feedback, and we're going to...



LEO:  Feed it right back to them.



STEVE:  Exactly.



LEO:  Boy, there were some interesting articles this week about security.  Wired magazine had a wonderful article in their Threat Level blog, I don't know if you saw it, that said, basically, everybody's been hacked.  It's all over.  Get over it.



STEVE:  Actually, I saw that go by, and I just said, uh, okay, fluff.



LEO:  Well, it wasn't fluff.  It was basically, no, it was quite a good article, and it was basically the premise that, even though no one wants to admit it or say anything, the truth is pretty much anybody who is worth hacking has been hacked.  It's kind of some of the stuff we've talked about, which is it's impossible to write perfect code.



STEVE:  Yup.  Security is porous, inherently, I mean, it's really, really, really hard.  And the cost goes up exponentially as you increase security linearly.



LEO:  And what the point was, and I thought this was actually pretty accurate, was that there is conventional security wisdom.  And most people charged with keeping their servers or their business secure just do what's - it's kind of like, if you just do what everybody else does, then you have plausible deniability.  You say, well, I'm doing what everybody else does, so it's not my fault.  And the problem is that the conventional kind of wisdom is insufficient these days.



STEVE:  And remember, the old, in the early days of the computer industry, the phrase was "Nobody ever got fired for choosing IBM."



LEO:  It's exactly the same mindset.  Which is it's a little tough - this is Kim Zetter writing May 4th:  "Everyone Has Been Hacked.  Now What?"  It's a little tough, if you're in the IT business, to be really a security expert.  Just do what everybody else does, eh, you're off the hook.  Nobody can complain because you've done everything.  And so they talk about Oak Ridge Lab being spear-phished.  There's a picture of Dan Kaminsky, who said, "There's been a deep conservatism around."  This is Kaminsky, the guy who wins that Pwn2Own every time.  He says, "'Do whatever everyone else is doing, whether it works or not.'  It's not about surviving, it's about claiming you did due diligence.  That's good if you're trying to keep a job," but "it's bad if you're trying to solve a technical problem."  That sounds like almost something like you would say.



STEVE:  Yeah.  I agree with him completely.



LEO:  Yeah.  He says, "No one knows how to make a secure network right now.  There's no obvious answer that we're just not doing because we're lazy."



"Simply installing firewalls and intrusion detection systems and keeping antivirus signatures up to date won't cut it anymore since most companies never know they've been hit until someone outside the firm tells them."  So I guess the point of the article is, well, okay, so let's acknowledge this.  Now what do you do?



STEVE:  Yeah.



LEO:  What is the appropriate response?  And basically they say it's a constant battle, as we've said.  There's no magic bullet.  There's no ultimate security protection.  We've just got to constantly manage the risk, assess the risk, and do the best we can.



STEVE:  Yeah, there are too many potential ways in.  And those ways in are all, for the bad guys, are also being used for good purposes.  And so it's these ways in, like visiting a site that runs some script that you want to have run because you want the services that the script provides.  But in the process, there's a sneaky way, for example, to abuse subtle characteristics.  In fact, we're going to talk about the recent iOS update to 5.1.1, which Apple just released, which fixes a couple problems just like this.  And we've talked about them all in other contexts, like cross-site scripting, where you can - really clever people can figure out how to get their code to run with your browser believing it's the code of the site you're visiting, which it gives permission to, yet you're running malicious code in this other site's context.



And, I mean, these are difficult things.  It's really hard to get all this right.  I would say I'm really seeing progress.  I mean, I think, for example, gone are the days where most people think they can use their mother's maiden name as their password throughout the entire Internet.



LEO:  Yes, yes.



STEVE:  And that'll be enough.



LEO:  And yet, I mean, I don't know, it's not in your notes, so I don't know if you saw it, you probably did and just decided to forget it.  We just learned that there has been a flaw for three months in OS X Lion that allows anybody to execute a simple terminal command and change anybody's password, including the sysadmins.  That there's another flaw that's been around for a couple of months that logs your password in the clear.  There's holes in PHP.  We just learned about another hole in the CGI version of PHP.  It's just - it's never-ending.  And then somebody just released 55,000 Twitter passwords and login accounts today.  It just is never-ending.



STEVE:  Yup.  And again, it's the systems, the way we designed these, they are so complicated that it's why I shudder every time new code comes out.  And it's why I'm on, like, I hang back, like really back, because new is not better in security.  New is just a whole bunch of new opportunities for problems.  And we see it over and over and over is that it takes a long time to sort through and find the problems in new stuff.  You're just - you're going to have them.  So unless it's something you really need, I'd say, well, if what you've got is working, stay there because at least it's a known quantity.



LEO:  That's too bad because geeks like me, we just - we can't wait till the upgrade comes out.



STEVE:  And Leo, this show is all about helping you pull the arrows out of your back.



LEO:  I know what you mean.  All right, Steve.  We've got questions, I see, but let's dig into the security news before we go any further with that.



STEVE:  Yeah, well, we are on the other side of the second Tuesday of the month, so everyone knows what that means.  It means that it's time to update our machines with Microsoft's latest fixes to things that they have found.  This time we have 23 vulnerabilities which are fixed in web browsing, file sharing, and email.  Eight of those 23 were rated "critical," which as we know means that no user interaction is required for hacking to result from the exploitation of these vulnerabilities.  At least three of them have been circulated publicly before their release, so that's always sort of something to keep an eye on.



And, interestingly, the one that Microsoft considers most critical is their MS12-029, which updates the patch they did last year for the Duqu worm.  Remember that was regarded as maybe a relative to Stuxnet, which was the one that famously worked on the process control systems in Iran to mess up their centrifuges.  Duqu was believed to be derived from the same code, thus from the same authors.  Microsoft fixed the one patch that it was known to be using.  But then they realized, ooh, that the same problem exists in a bunch of our other stuff.  So this 029 patch fixes Windows Office, .NET, and Silverlight, all that shared the same vulnerability.  So anyway, this is one you'd want to update as you normally would all of these things from Microsoft.



Also, Shockwave moves forward, for those people who care.  I mean, I understand that sometimes it's necessary.  There is gaming that is done with the Shockwave Player on the web.  But our standard advice stands, which is get rid of it if you know you don't need it.  Or maybe if you even don't know that you need it.



LEO:  It's not the same as Flash.  It, like, predates Flash.



STEVE:  Correct.  Exactly.  Different from that.  I'll just quote briefly from Adobe's page.  They said, "Adobe released a security update for Adobe Shockwave Player 11.6.4.634 and earlier versions."  So if you're earlier than the .634, you want to update.  They said this is for Windows and Mac.  "This update addresses vulnerabilities that could allow an attacker who successfully exploits these vulnerabilities to run malicious code on the affected system."



So again, it's one of these remote takeover kind of things where you just go to a site, and if you've got Shockwave Player installed, and a site is malicious, this provides an entry that your browser doesn't provide by itself.  It's the add-on that creates a door that the bad guys can use.  So they recommend updating to .635, if you know that you've got Shockwave Player.  Don't install it if you don't have it.  But if you need it, you want to keep it up to date, which is standard advice for all of these browser add-ons.



Now, Apple did just release an update to iOS 5 across all their platforms.  It took me, over my two T1s with 3GB download, about an hour, a full hour to get this thing.  And what's annoying, I'm assuming this is going to be the same, is that you have to do a different one for your WiFi-only iPad versus your 3G or 4G or LTE iPad versus your Touch versus your Phone.  So if you're like me, and I'm sure like you, Leo, and we have all of these things, it's like every single one of them needs a whole blob to be downloaded and installed.  So you only get to save that if you have a couple of the same thing.  So it's a little bit annoying.  But it's important.



This fixes three - well, first of all, I got a kick out of it because when I did this on my Mac earlier today, up comes a window and talks about all the happy little things they're fixing.  It's, like, seven or eight little improvements.  And it sounds like, oh, that's all good.  What they don't tell you at all there is that there's an address bar spoofing problem in all iOS prior to 5.1.1, where Site X could redirect you to Site Y but make it look as though you'd gone to Site Z.  So essentially it's an address bar spoofing problem, and that's not good because a lot of us who are security aware and just sort of web aware, we're just looking to make sure we went where we intended to and where the indicator thought we were.  But there's a way for the address bar to be spoofed which is fixed in 5.1.1.



Another problem that we've discussed extensively in the past is only now fixed.  This particular one is a cross-site scripting problem, where you're visiting one site, and as I was mentioning earlier in the show, code sucked in from a different domain could execute in the so-called security context of the site you're visiting.  You want the site you're visiting's code to be able to do what it wants, but you don't want some other domain to do that.  That is cross-site scripting.



And, for example, that would mean that that other site could access your cookies for the site you're visiting, and things like if you're logged into a site, as we know the way login happens typically, is there's a token that authenticates you which is being sent back with every query.  Well, that's what Firesheep famously was able to grab before sites began running exclusively over SSL to lock that behavior down.  But this kind of cross-site scripting problem even penetrates that, so that the third-party site would be able to get the tokens that are tied into the first-party site, even if you're running over SSL.  So that's not good.



And then, finally, they fixed a remote code execution problem where a maliciously crafted web page could crash your browser in such a way that it ends up running program code that was embedded in the page.  Now, that's a less elegant hack of your system.  You'd like it to be more transparent and not crash your browser.  But still, actually, I'm sure all of us who have been using iPads from the beginning see our apps crash from time to time.



LEO:  Sure.



STEVE:  You're just doing something, and it blip, just kind of goes away.



LEO:  Kind of restarts, yeah.



STEVE:  And it's like, oh, yeah, exactly.  It's like, oh, okay, well, yeah.  So anyway, time to update iOS.  Plan for however your download speed is.  How long did it take you with massive pipes, Leo?



LEO:  Well, I do it differently than you did it.  You obviously used iTunes to do it.



STEVE:  Yes, I did.



LEO:  So you can now do over the air updates, and those are delta updates.  So if you do it, you want to plug in your phone or your iPad or your iPod and then just go to the Settings, and in the settings General Updates.  It will do it for you.  And it's much faster if you do it that way.



STEVE:  And WiFi and cellular both?  Or WiFi only?



LEO:  It'll do either, but I would suggest getting on the WiFi, unless you don't have anywhere close to the cap.  But I think it's considerably faster.  The problem is that for some reason iTunes doesn't do deltas, apparently.  It downloads the whole image, which is almost a gigabyte.  So, yeah, it would be a lot better just to download the changes.  And Apple recently implemented that.  But apparently it's only for the over-the-air downloads.



STEVE:  Yeah.  And I have, I did update for the last one, I updated that way.  And I just sort of, like, didn't occur to me...



[Talking simultaneously]



STEVE:  Yeah, so, good, I'm going to do the rest of them that way.  That makes a lot of sense.  The advent of DNSCrypt from OpenDNS has generated huge enthusiasm from our audience.  It was initially only available for the Mac.  And I am pleased to announce, thanks to Gavin Groom, who tweeted me from the UK a heads-up, that it is now available for Windows.  So OpenDNS users who like the idea of having their DNS encrypted, now can install it for Windows.  There was some hack when it was in beta which we talked about briefly.  Now it's official.



So the reason this is significant is that DNS is like a little privacy leakage that we really haven't focused on maybe enough because we keep talking about SSL and setting up crypto and having everything you're doing in a tunnel that is encrypted that no one can get into, and that's cool and important.  Except DNS, as we all know, is the way our browsers get the IP address for the domains that we're then going to go into this secret, lower the cone of silence over ourselves with, for those who remember "Get Smart" back in the old days, except the DNS has no encryption.



So even if you were using - if you were in a mode where you were in an open WiFi and smug that all of your services you were using were carefully forced to be over SSL or natively over SSL, one little glitch is that any time your browser looks up any domains, not just the primary domain you're visiting, but remember many domains now bring stuff in from all corners of the globe, all of those domain names are being sent out to the DNS server in the clear.  So there's a privacy leakage.  They're not seeing the data, but they are knowing that your machine is asking for the IP addresses of this whole set of domains and that, depending upon what you're doing in that setting, that may make you feel uncomfortable.



So to some fanfare, OpenDNS has uniquely, of all DNS services, created their own encrypted tunnel between your machine, when you install the matching client on your side, and their service, so that all queries get encrypted as they go, as they say, over the wire or through the air to grandmother's house, over to DNS and back.  So now for Windows.



Just yesterday the Wi-Fi Alliance, who brought us...



LEO:  The fabulous WEP.



STEVE:  Fabulous.



LEO:  The fabulous WPS.  The fab- what else have they ruined?



STEVE:  All these wonderfully secure technologies.  And I shudder at this.  I think, oh, goodness, have they not learned their lesson.  Anyway, they're all excited about their next drop of update called Passpoint.  We touched on this a few weeks ago.  Not much was known.  Yesterday they dropped the announcement that they will begin authenticating and verifying equipment to be Passpoint compliant.  Also there's something called Hotpoint, I think it's Hotpoint [Hotspot] 2.0 that this is part of, starting in the summer, July of this year, hoping for a 2013 rollout.



Now, what this promises is sort of a way of offloading cellular bandwidth to the ubiquitous hotspots, free hotspots in a way that is less hassle for users.  When you typically need to use a free WiFi hotspot, like Starbucks, for example, there's some sort of a login screen, and you've got to go yes, sort of agree to the terms and services there.  It's never very seamless.  I find that it's always in the way so that I just don't try.  I don't use WiFi at Starbucks.  I stay on cellular, and that's the point is that that hassle keeps people on cellular.  And of course the carriers, the cellular carriers, would much rather you switched over away from their bandwidth, over to landline bandwidth that is less expensive and less burdensome for them.



So the concept is that there'll be some sort of new authentication cycle where your phone's unique ID, be it SIM card or hardwired 25,000-character ID that these things have, would be included in an authentication loop.  And the spec for this is $200, so I haven't bit the bullet yet to buy it, as I did the WPS spec, because I had to tell everybody about exactly how it worked and how it was broken.  There's a whitepaper also that is free that I've not gone over yet because this hasn't happened yet.



Also, this is not going to be a small change.  It is not going to happen overnight.  The problem is we have a huge install base of hardware for hotspots which all need to get upgraded.  This is not a simple change.  This is probably, at the least, would be a firmware change.  And it's not clear whether this is authenticating you and encrypting your connection, that is, is it WPS or WPA2?  What is it?



LEO:  And they don't say.



STEVE:  It's just all, I mean, they even say "Mobile authentication could use your SIM card."  It's like, well, you know it's going to.  Why do you say "could"?  No, anyway, it's just - this Wi-Fi Alliance is the biggest example of committee design.



LEO:  I think it's also more marketers than technologists.



STEVE:  Oh, absolutely, yeah.



LEO:  Yeah.  It's about marketing.



STEVE:  I mean, why else would I be paying $200 to have a specification, which you want people to have in order to implement something good?  It's like, okay.  They have - the marketers have salaries that need to get paid.  So anyway, I just wanted to say that it's moving forward.  We'll certainly keep an eye on it.  It's going to be critical.  I mean, at some point in the future we'll be talking about it seriously.  But it's not going to happen overnight.  No rollout until next year sometime.  And even then, probably slowly.  So we'll, again, see how it goes.



Now, yesterday Firefox fixed another memory leak.  This is sort of a constant battle for them.  They've moved beyond their own code, though, and they're now looking at the behavior of sloppy add-ons.  The sandboxing technology that Firefox uses has the add-ons loading in what's called the "chrome privilege zone."  So chrome's own UI interface is written in JavaScript.  The add-ons run in there.  And then Chrome and the add-ons together sort of reach out into the other domain sandboxes for containment.



And the problem is that, if pages are shut down that had resources allocated to them, they weren't always being freed.  So on the Mozilla.org Bugzilla page, there's a bug 695480 which has just got resolved.  And from that, in the summary the guy who fixed this said, "Add-on authors probably don't need to bother changing anything."  Oh, I should mention they're very bullish about this.  They regard what they managed to do, essentially fixing the problem without the add-ons needing to fix, as a real step forward.



They said, "Add-on authors probably don't need to bother changing anything unless they see breakage [from what we've done].  Breakage should be pretty rare, and the huge upside of avoided leaks will be worth it.  It's a little early to be sure what effects this will have, but the amount of leaks we see on our test suite dropped by 80 percent.  I expect that this change will also fix a majority of the add-on leaks we see without any effort on the part of the add-on authors."



So this is still not in the release chain yet.  This is in the development chain.  But I'm sure this will get pushed out soon because I have heard, I think it's 15 is now - they're out there somewhere.  I think I'm on 13, if I remember right, because we moved - either I went from 11 to 12 or 12 to 13.  Anyway, there's sort of a string of these major versions that Mozilla is putting out now.  They're moving fast, and they really are updating it, which is a good thing.



I have major news about Buffer Bloat.  Jim Getty, who was the individual credited with coining the term and who produced that neat video that we referred to months ago when we did the episode on Buffer Bloat, he blogged about a paper that was just released by two network researchers.  There's a Dr. Kathie Nichols who submitted a paper which is going to be published this summer in the journal called the ACM Queue, Association for Computing Machinery.  Her co-author was none other than Van Jacobson, who is known as the designer of TCP, so he knows something about these problems.



So Jim Getty said that they published an article which was entitled "Controlling Queue Delay."  And essentially they have developed a new algorithm.  The name is CoDel, and it's pronounced "coddle," unfortunately.  But maybe not, maybe that works because you're "coddling" TCP to help it work.  CoDel is - the reason people are excited about it is, I mean, it's like the Holy Grail of queue management.  It's a novel no knobs, just works, handles variable bandwidth and roundtrip time, and simple adaptive queue management (AQM) algorithm.



To quote from the article that Kathie - it's Kathie, by the way, Kathie Nichols.  I think I said "Katie" before.  Kathie Nichols and Van Jacobson wrote, they said, "In the decade since, many researchers have made strides in adaptive queue management, but no one has produced an adaptive queue management algorithm that has the following characteristics," which theirs does:  "It is parameterless.  It has no knobs for operators, users, or implementers to adjust.  It treats good queue and bad queue differently, that is, it keeps the delays low while permitting bursts of traffic.  It controls delay, while insensitive to roundtrip delays, link rates [meaning wire speed], and traffic loads.  It adapts to dynamically changing link rates with no negative impact on utilization."



And that's significant because one of the problems people have seen at home is with WiFi connections where the link rate over the air is dynamically scaling as a function of your connection quality.  So that can confuse things a lot.  If you're doing things, and you move around a little bit, even just a few inches, or turn, if your connection quality drops, your link rate changes, and you've already trained up your TCP connections for one link rate.  Suddenly it changes.  They don't adapt well.  So this fixes that.



"It is simple and efficient.  It can easily span the spectrum low-end, Linux-based access points and home routers up to high-end commercial router silicon.  And CoDel's algorithm is not based on queue size, queue-size averages, queue-size thresholds, rate measurements, link utilization, drop rate or queue occupancy time."  So it's not like time in queue, which some recent approaches have had.



So, I mean, this is very exciting.  It sounds like they've solved the problem.  There is an implementation for the CeroWRT build, which is an offshoot from the OpenWRT.  Anyone who's interested can go to BufferBloat.net.  That's the site where this work is being focused on.  People are working with early releases of code to implement this.  I expect we'll see rapid progress.  And looking around at people who have had a chance to study this, I have not yet gone into detail.  The paper is available, probably linked from BufferBloat.net, but you can get it from the ACM site as a web page or PDF.  It's got pretty pictures and shows buffers and things.  Once I figure out what it is, I will simplify it and tell everybody.  But I'm excited because I'm seeing people saying this could solve the problem.  Like, okay...



LEO:  This is a modification to TCP, to the protocol?



STEVE:  No.  And that's what's so beautiful.  This is a modification to the buffering, that is...



LEO:  The buffering algorithm.



STEVE:  Yes, because we really can't change TCP.  I mean, if we wanted to, oh, boy, talk about rolling out new access points being slow.  TCP is in everything already.  So the beauty is this would be essentially a change to routers.  So firmware updates, or throw away your $49 blue plastic box and get another one, and suddenly your network will run a lot more robustly at home.



LEO:  So we'll start looking for CoDel on the box, or AQM, which is really what this is, is queue management.



STEVE:  Well, but there are other AQMs.  Like we talked about random early detection, where as the buffers began to get full, they would start throwing away, randomly, packets.  And so the chances were that the hogs would statistically have more of their packets discarded than the non-hogs.  And so, I mean, so much time has gone into this.  But it really sounds as though it wasn't until it really, like the pressure got cranked up, that some really smart people who really understand the history of all of this problem sat down and said, okay, we've got to figure this out.



And I think CoDel does.  From everything that they have written, they've got a solution.  So it's going to be very cool.  So, yeah, I would say we'll keep an eye on it, see what the marketers call this.  I mean, CoDel is, okay, well, I wish we could have had a really cool name.  But at least it's not awful.



LEO:  This is great.



STEVE:  Yeah.  I did want to mention that I have a new Twit handle, a new Twitter channel that I created in order to move my health stuff off of SGgrc.  There have been a lot of people that have been tweeting since you and I did the special on Sunday, some asking where is it, where can they go to get it.



LEO:  It's out now.



STEVE:  Yes.



LEO:  Yes.  And Part 2 is Sunday.



STEVE:  Yes.  We're going to do a second half.  Anyway, my new Twitter handle, for anybody who wants to follow that, is SGvlc.  Instead of GRC, it's VLC for Very Low Carb.  So SGvlc is where I will tweet stuff of interest to people who are interested in that so that I'm not clogging up my regular SGgrc with such traffic.



LEO:  And you haven't tweeted there yet.



STEVE:  Nope, I haven't.



LEO:  But you will.  But of course people can go to GRC.com/health.  There's a lot of information there.  And then the special that we did on Sunday is available in our Specials feed.  We didn't put in the Security Now! feed because it's not security.  It's a special.  So TWiT.tv/specials.  It's the most recent one, Episode 124, "The Sugar Hill."  And Part 2 - this one's going up the sugar hill, Part 2 going down the sugar hill - is next Sunday, 2:00 to 3:00 p.m. Pacific, 5:00 to 6:00 p.m. Eastern time, 2100 UTC on TWiT.tv, if you want to watch.



STEVE:  Yes.  We squeezed it in between your Tech Guy radio program and your recording of your Sunday TWiT show.  And so we'll do that again.  As you mentioned, there are now a bunch of health-related pages.  Well, I've already had, I've always had that Vitamin D page up, since the summer of '09 when we did the Vitamin D podcast.  I'm now adding a bunch more with the references to the books that you and I have read and like and a bunch of other resources.  So GRC.com/health, and everyone will be able to find those things there.



LEO:  And I've been skimming this "Rosedale Diet" book you recommended, which I ordered as soon as you recommended it.  It's fantastic.  I'm very excited.



STEVE:  Yes, it really is.  I did read it cover to cover, except I skipped the recipes because, although I looked...



LEO:  You eat out.  We're going to get you cooking, Steve.



STEVE:  Actually, I have sent a note to Jenny and said, you know, there may be a day when I'm cooking for us.  And she wrote back, "Ha ha ha."



LEO:  I think you should.  Some of the fun of this, frankly, for me, has always been doing the cooking.  And then you know what's in it.



STEVE:  Yes.



LEO:  Then you know what oils are used and everything, and you can really make - yeah.



STEVE:  Exactly.  Exactly.



LEO:  They even have a healthy version of granola in here.



STEVE:  Yeah, and this guy gets it.  He's been, I mean, what I like about Ron Rosedale's book is he's been involved in this for decades, and it's, like, applied.  It's a practical manual.  But I want all the science and all the biochemistry first.  And in fact I was waving this book in front of the camera before we began recording, my organic and biological chemistry textbook.  It's the only thing I could find that actually showed the actual chemical processes for doing some of the things that I was talking about last Sunday and will be going into more detail in next Sunday.



For me, I want to - I just don't want to take it for granted.  The scientific method is verification and multiple sourcing and really, not just third-person hearsay, but how exactly does this stuff work?  And I think that's, if I bring any value to these, that's what it is, it's that it's not the same thing you can find anywhere else.



LEO:  It's fascinating stuff.



STEVE:  I do have an interesting SpinRite story that I ran across.  We've never discussed this before.  And it ought to get everyone's attention because it's something unusual from a Bob England, who wrote on April 23rd.  He said, "Hi, Steve.  I'm a long-time listener to Security Now! and long-term OP," which he says stands for "Other People's SpinRite User."



"I have to admit I've often borrowed other people's copies of SpinRite to keep my own hard drives working well.  When I used to work as an IT support tech, I used to recommend SpinRite to all my clients.  Some purchased it; some did not."  Well, Bob, I'd say you've helped me out, so I appreciate that.  "Over the past couple of weeks I noticed that my PC was beginning to just not feel right.  I'm used to how my PC feels, during what part of certain actions I will notice hard drive activity and so on and so forth.  Windows started to take longer to boot up.  File transfers from one hard drive to another were getting slower, and apps were often not responding.



"Then, last Friday, Windows BSOD'd and refused to boot into anything other than recovery mode and could not find usable partitions.  I thought enough was enough, and I decided it was time I actually got around to purchasing my own copy of SpinRite, so I did.  I ran SpinRite and saw the estimated completion time was 1,028 hours!"  He said, "I know that SpinRite can take a long time, but instead of just leaving it, I looked at the other screens to see if there was something important that I should take note of.  Sure enough, in the stats screen I saw large numbers of cabling errors.  The SATA cables I was using were the ones that came with my motherboard, so I thought they should be okay.  I checked to make sure they were seated correctly, and they were.



"I purchased new SATA cables and reran SpinRite, and it did a complete scan of the drive in less than five hours.  I wish I could say that I rebooted and everything was fine, but many of the Windows files were corrupted beyond repair" - and I'll explain why when I finish reading this letter - "mostly due to the BSOD I am getting" - the Blue Screen of Death.  And it's actually not, but I'll explain.  "However, SpinRite did manage to recover the files and sectors from the data drives, where I store all the work I do for our charity, of the 5TB of files that I have, including accounts and other extremely important information.  But as SpinRite had fixed these drives, it meant I did not have to wait to redownload all my backups or copy over archives from DVDs.



"I'm now setting up a NAS with RAID to further protect the data.  I was wondering if you had experience of bad SATA cables, particularly those that come with original motherboards.  Also, does the length of the cable matter?  I ask this because I have some very short SATA cables and was wondering if the principles of signal propagation apply to these.  Also, one other question:  'Locus of control.'  Is that a typo, or does SpinRite have a personality?  I've only heard the term used in psychology.  I've always assumed it was supposed to be 'focus of control,' but now I'm not sure.  Anyway, great show, and thanks for giving us SpinRite and all those other utilities.  Bob England."



So this is interesting.  I show checksum transfer errors and label them, what did I call them, "cabling errors," because that's all they can be in SpinRite.  And it's uncommon, but you know me, I'm pretty thorough.  And when I was designing this, I thought, well, there is a chance that, because it's a simple checksum algorithm, that errors could be occurring and going undetected.  And that's what happened in this case.  There is, in the actual hardware between the controller on the motherboard and the drive, there is a checksum-generating process that verifies the transfer of data.  This is different than the ECC that the drive appends.  It's different than any external checksums that are being applied.  It's just essentially the cable.  Did the data that left the controller get to the drive correctly?



And so what happens is, after a packet of data arrives at the drive, it verifies the checksum and flags an error if it's wrong.  But sadly, nothing else in the world except SpinRite brings that to your attention.  So what was happening was the drive was - this was all slowing down because many of these checksum errors were causing a retransmission over bad cables.  Unfortunately, he had corruption because, again, it's a simple checksum.  It's not like a good hash.  That's just too much algorithmic overhead.  And this stuff all dates back to 20 years before.



So it is possible to have undetected transmission errors between your motherboard and your drive.  This is really bad because the drive thinks everything was fine and writes the wrong data onto your drive.  And the motherboard thinks everything is fine because the drive didn't say, whoa, I didn't get that correctly, send it to me again.



So to answer Bob's question about length, I'm always - it is the case that shorter cables are theoretically better.  Probably in this day and age of digitization of everything it's not as important.  I mean, it would take a huge amount of noise, like lightning strikes, in order to glitch these cables.  They're differential in nature where there's a plus and minus that are balanced.  They're typically twisted so that any electromagnetic interference is received equally by both sides, so the difference doesn't change.  That's what differential is all about.



What happened, doubtless, is just some noise in the actual physical connection.  The fingers are typically gold on gold because you don't want to generate resistance noise at that junction.  But these are not soldered.  They're not, like, screwed down tight.  They're a design which is meant to be a compromise between convenience and quality.  And in this case that convenience compromise bit Bob.  All he probably had to do was just wiggle the connectors, or pull them off and put them back on.  That's something that Greg tells people to do all the time, just pull the connections off, reseat them.  In the process that wipes the contacts across each other and removes the grit or dust or maybe a little bit of oxide that forms.  And that's why we use gold, because it is resistant to oxidation in oxygen.  So something we have never talked about before, but it's something that can bite you.  And it bit Bob.



LEO:  This is why you're the hard drive expert.  I love it.  Steve, questions, questions, questions.



STEVE:  Yeah, we've got some great stuff from our listeners.



LEO:  We have a questing audience.  They just want to know more, starting with Alan J. Doyle.  I think this is a Twitter because he's @AllenDoyle, from Eagan, Minnesota.  He says:  Steve, if your backed-up data gets a virus, won't your cloud backup also be infected?  Do the file-by-file cloud storage solutions have an advantage here?



STEVE:  You know, we've never talked about that question, which I think is a good one.



LEO:  Yeah.  Are you backing up the virus?  Backing up the infection?



STEVE:  Yeah.  When we've talked about it generically, we've talked about that, for example, if you have backups, and you're keeping track of them, then it's necessary, clearly, for example, if you're making images of your whole system, you want to go back to an image which is before your system got infected.  Hopefully, if you're backing up just your data, documents and so forth, those tend to be more benign.  But, I mean, it certainly raises a very good point, that if you are backing up contaminated files, or doing whole system backups, then Allen's point is right.  You're backing up indiscriminately all of your files, and that means you're saving viruses and malware along with everything else.



So again, I mean, the only thing you can do is keep your defenses up, be aware of the danger, and maybe be a little bit better with, I mean, compensate for this fundamental problem by not discarding older instances of your system when it was in a known good state.  The downside of restoring from something older is there'll be a lot more changes to your system since then.  So you're resetting the clock back to that point.  So the stuff you have done that you wish you could keep gets lost.



And it could end up being like sort of a hybrid, where you take a snapshot of your diseased system so that you at least have all the things that you've done, even though they include things you don't want to have, like malware.  Then you restore from the most recent known uninfected image, which puts you back in time.  Then you carefully bring the things from your infected image, file by file, back over, your documents and maybe your email, if you trust that, and so forth, in order to - but again, only the stuff you need.  I mean, doing this does give you an opportunity to do some spring cleaning, too.  I mean, every time I'm setting up a new system from scratch, and I'm sure you've had this, Leo, because you're as much of a "ooh, let me try and use that utility" as anyone.



LEO:  Oh, constantly, yeah.



STEVE:  Yeah.  And so setting up a new system is always a chance to say, okay, now I'm not going to install all that crazy stuff that I installed last time.  Of course we just end up with new crazy stuff.



LEO:  Yeah.  Yeah.  Well, I mean, in general, though, backups, if you're backing up data, data by - as we've said many times, you have to execute - a bad guy has to execute something.  And where data gets you in trouble is where you have Adobe Reader or some other, remember that JPEG metafile issue on Windows?  So the thing that reads the data file itself has a flaw, and then you could create - you can craft malware-laden data files that activate.  But that requires you to have an application that's also got a hole in it.  So data by itself is generally okay; right?



STEVE:  And that reminds me that, when you do restore from an older image...



LEO:  Get the latest versions of your apps.



STEVE:  Well, and the updates, security updates.



LEO:  Exactly.



STEVE:  You want to immediately bring your system current so that it's got its guard up to whatever degree possible.



LEO:  I frequently, on the radio show, will talk about this.  And I always say, use a genuine install disk.  Install Windows.  And the very first thing you do is run Windows Update until you can update no longer.



STEVE:  I know, over and over and over.



LEO:  Over and over till there's no more updating to be done.



STEVE:  Updates of the updates of the updates.



LEO:  And I also say don't install stuff if you don't know you need it because people always say, oh, I'm going to put all my 500 programs back on.  There's a real opportunity not to do that; right?



STEVE:  Yup.  Spring cleaning.



LEO:  Spring cleaning.  And things like Shockwave, every app potentially brings with it a problem.  So don't install it unless you know you need it.



STEVE:  Yes.



LEO:  Okay.  Continuing on.  Where did I put it?  I closed - oh, shoot.  I closed the questions.  Let me re-open those questions.  Thank goodness for open reset.  Here we go.  Question 2, Alvaro Stevenson in Monterrey, Mexico - I'm sure I'm butchering your name, and I apologize.  How to tell if your home router's buffer is too big?  The buffer bloat problem:  Steve, I've joined an online game server with a 60ms ping, then I transferred a big file between two computers in my home network, and my ping increased to 200ms.  After the transfer, back down to 60.  Does this mean my home router's buffer can add up to 140ms of latency?  Love the show, Alvaro Stevenson.  What do you say?



STEVE:  Well, I would say yes and no.  The real test that you need to use, and this test doesn't do that, is you need to use the buffer that you're sharing with what you want to test.  And a number of people have asked, so I thought this was a very good point.  When you're transferring between two machines on your home network, it's not going - that data you're transferring is not going out through - it may be passing through your router, but it's not going through the buffer out to the Internet.  And that's the key because it's - remember that the whole glitch here is where you have a change in bandwidth.  Nobody's upstream bandwidth is as high as their own Intranet's bandwidth.  We're all running 100Mb, probably, inside our own home networks, but substantially less than that.



So it's where you transition from the high bandwidth to the low bandwidth.  That creates a pinch point, and then the buffer is there in order to keep from just throwing away everything that won't be able to run at that lower speed.  So to do the test, it's necessary - what people are doing, and successfully, would be to, like, check the ping time, then download something big from the Internet, like one of our podcasts.  And while it's coming down, try to ping your game server.  There you're going to see the real effect of the buffer bloat.  And I'll bet it's way more than 140ms.



LEO:  Or run Netalyzr.



STEVE:  Yup.  That, too.



LEO:  I mean, that's basically what the Netalyzr is doing, right, is...



STEVE:  Yeah, although I like the idea of, like...



LEO:  You could test it, yeah.



STEVE:  I know that gamers are all hopped up about their ping time because they see that as the interactiveness of their online gaming.  They want to not get penalized for latency in the connection.  So this is a way of, like, doing a test that you're familiar with, which is game server ping time, and exacerbating that problem by simultaneously downloading something and seeing how bad it gets.  And looks like we're going to have a solution for that one of these days.



LEO:  Boy, I tell you, we've had great results.  I'm now getting all the hosts to run Netalyzr just to see what's going on in their network, and it's been really useful.



STEVE:  Neat.



LEO:  If you Google ICSI - it's at University of California at Berkeley's Computer Science Institute, ICSI - and Netalyzr is N-e-t-a-l-y-z-r.  So I wish people wouldn't use kind of unconventional spellings because...



STEVE:  I wonder if they had to fit it into eight characters because they're still using DOS or something.



LEO:  Ah, maybe that's why.  Because if you just spelled it right, then we wouldn't have to spell it all the time.  So Netalyzr.  ICSI and Netalyzr.



Let's go to Cuyahoga Falls, Ohio.  Susan Kennedy lives there, and she wants to know about TNO-level security password protection:  Steve and Leo, long-time fan, Leo from The Screen Savers and TechTV, Steve from much earlier on GRC.com.  So I was thrilled to find the Security Now! podcast.  I can't catch the live feed, but I never miss a show.  My question has to do with Trust No One, TNO-level password security.  What if the encryption key for my cloud data resided on a corrupted section of my storage provider's disk?  Would I lose all my data, even if I remembered my password correctly?  Thanks for a great show.  Susan.



STEVE:  Well, this is a nice question about maybe a bigger problem, which again we've never talked about.  We sort of assume that nothing can ever go wrong with our data after we've sent it off somewhere.



LEO:  Not so.  Oh, is that not so.



STEVE:  And remember, one of the funniest things from "Hitchhiker's Guide to the Galaxy" was when Arthur Dent and Zaphod and their little crew landed in the middle of a rugby match, I think it was, like landed their space ship right in the middle of a rugby field with a match ongoing, and Arthur was really upset.  He said, wait a minute, we just can't land here.  And Zaphod said sure we can.  And he said, we just turn on the SEP field.  And Arthur said, what?  And that's Somebody Else's Problem field, where...



LEO:  I don't remember that.  That's funny.



STEVE:  Oh, isn't that wonderful?  Oh.  And Arthur said, what are you talking about?  And Zaphod said, well, go try to look at the ship.  And Arthur explains it when he - his gaze just sort of slid off of it.  He wasn't able to really lock onto it.



LEO:  Someone else's problem.



STEVE:  And it's somebody else's problem.  Oh.



LEO:  That is funny.



STEVE:  So it was a field that just told your brain that, well, whatever that is, it's somebody else's problem.



LEO:  Somebody else's.



STEVE:  And the problem is that we would like to believe that when we send our precious data off to the cloud, now it's no longer our problem, it's somebody else's problem.  Problem is, they can drop the ball.  They can have corruption and so forth.  And I'm sure their license agreements and their stuff say we'll make best efforts.  But...



LEO:  You're trusting them.



STEVE:  All we can do is all we can do.  And one of the reasons I like the larger guys, like Amazon, is they've got the clout to do redundant storage across multiple datacenters so that any two can go down, in Amazon's case, and you still have your data.  Smaller guys are going to give you, again, the best job they can.  But it's still important.  So to answer Susan's question, yes, if there was corruption there, that's still a problem.



So my feeling is that that's part of your backup strategy, but you do not rely on it exclusively.  External drives, network-attached storage, these things have become inexpensive enough that they're still a good thing to use, even if, or even though, you're still trying to make your data backup somebody else's problem.  You're only safe if it's still a little bit your problem.



LEO:  You know what happened to Carbonite some years ago, they're one of our sponsors, we talk about them all the time, they bought some Promise hard drive controllers.  And of course they use RAID and redundancy and so forth.  But they were small at the time, and I don't think they had multiple datacenters.  And these controllers corrupted all the data.  And I think they actually sued them.  They sued Promise over this whole thing.  Most people, I think, were able to get their data back because they discovered the problem.  It was only people who didn't have - who had a crash in the period of time between when the problem happened and when they fixed it.



STEVE:  And you know what it was, Leo?  I do know what it was.  It was the very, very early days of SATA.  The very early SATA drives and controllers weren't quite synchronized in the way they talked.  And there were some early problems that came up.  I remember Promise was having a problem with their SATA controllers.



LEO:  It was very upsetting, I know, to David at Carbonite.  He's the guy, the founder.  And they have since made sure that that could never happen again.  So in some ways, the good thing about Carbonite is it did happen.  And that's always - it's the same thing with backup.  You don't really take it seriously till you lose it.



STEVE:  Fool me once.



LEO:  Yeah, exactly.  So it does happen.  We do trust them.  I think that is certainly something to be aware of.  I think it's a great question.



Tom Paladino in Commack, New York suggests some poor man's backup solutions:  Thanks for the great podcast, for all the various cloud backup solutions on Security Now! 349.  Want to point out there are a few services that can be used for free in what I call a "poor man's solution."  SugarSync, he uses that for all his documents.  And SugarSync, like a lot of these, offers the first few gigs free, in SugarSync's case 5GB.  He says that's more than enough for simple document data.  However, for most users a large portion of their data is comprised of music, images, and videos.  That's a lot more than 5GB.



Fortunately, Google has three services that can provide free online storage for all of these, Google Picasa, will let you synch images to the cloud and now has unlimited file storage for images.  I didn't know that.  I pay for extra storage on Picasa, so that's good to know.  Google Play, formerly Google Music, has a synch client that pushes all of your music to the cloud and allows you to download your entire library back to a local PC if you need to.  That's free for, I think, 25,000 titles.  And lastly, YouTube now allows HD video uploads longer than 15 minutes, allowing users to upload their important family videos online for free.  It's important to note that both Picasa and YouTube can be set to "private" if you don't want to share those, as you probably wouldn't if they're family videos.  Thanks for a great podcast.  Tom Paladino, Commack, New York.



STEVE:  So I thought this was very clever.  And it really does make sense.  And I wanted your own experience and opinions, if you had any, with those services because I don't.  But I like the idea of recognizing that, exactly as Tom said, the things that we create are documents and...



LEO:  Are small.



STEVE:  ...are small relative to this explosion that we've had in the size of media, which everyone's having fun with.  But, boy, is it big.  And so rather than trying to have one solution where one class of your backup media is essentially forcing you into expensive data plans, Tom's idea is a great one.  It's like, hey, if you've got free photo upload for Picasa, put them up there.  And, that is, segregate this a little bit.  It's a little more work.  It's not everything in one place.  But it makes a lot of sense.



LEO:  I agree completely.  I think you're making a mistake if you're backing up - you've talked about this - these large media files, like ripped DVDs, to a backup service.  That's nuts.  Don't do it.



STEVE:  Yeah, it's crazy.



LEO:  And as it turns out, when people say, oh, I have 500GB of backup, most of that is stuff you don't really need to make a copy of.  I can't believe that you have 500GB of financial records or any of those kinds of things.  There are a lot of services that offer free photo storage.  Google Drive now is 5GB for free, and it's very cheap to buy more.  I have 200GB on Google, and I use that for everything.



So, yeah, I think there are a lot of good solutions.  I don't think you have to - it's really more of a question of how complicated you want to make it and how automatic it is and that kind of thing.  Lots of good solutions.  I mean, the cloud is coming, big-time.  If you use Apple stuff, you might just use iCloud.  It's not cheap.  They seem to charge a lot.  In fact, it's 50 bucks for 25GB a year and 100 bucks for 50GB a year, which is a little much, if you ask me.



Gregory MacGregor - a nice Scottish name.  Guess where he is?  He's in Spain.  Gregory MacGregor wonders, why is ARM better than - no, wait a minute, that's not the right one.  Did I jump ahead?  Yes, it is.  Why is ARM better than x86/x64 for mobile devices?  Steve, it's not a security question, but since you're the geekiest person I know on Leo's network, I'd love to know if you could answer this.  Ever since non-x86 tablets started showing up in the past few years, I've wondered, what it is that makes the ARM architecture the one to consider for mobile products in the future?  I know they give great performance per watt, but I've never known if that's by design, or if it's just that x86 isn't efficient enough today.



Why am I asking this?  Well, Windows 8 is just around the corner, and I wonder if it makes any sense to invest in an ARM tablet given the legacy hardware and software I can use with an x86 tablet.  Is there a chance the x86/x64 architecture could eventually match ARM's mobile-friendly specs?  Or do we really have to chose between mobility and legacy support?  Tough choice.  Thanks for the show.  You rock.



STEVE:  So, okay.  First of all, I would point Gregory at a really fun series that we did - you'll remember, Leo - about designing computers from first principles, where we started from scratch and looked at how computers work.  And one of the things we talked about was CISC, that is, C-I-S-C, Complex Instruction Set Computers, versus RISC, Reduced Instruction Set Computers.  And ARM, which stands for Advanced RISC Machine, although it used to stand for Acorn - I like the new name better - it is a RISC architecture.



And essentially the designers in England who put this together were essentially like a mom-and-pop shop.  I mean, they were just some - they weren't, like, Intel or Fairchild or Texas Instruments or anything.  They were just some guys who said, gee, you know, we've been using the 6502, and it's cheaper than the 8088 or the 8080, rather, because it's got, like, so many fewer gates.  And so it's a smaller die, and it was easier to design.  And so they just sort of said - and they weren't able to get a chip they wanted, so they designed one.  And they designed a simple one.  And they decided we're going to make it simple, and then we'll put the complexity in the software rather than in the hardware.



Well, Intel's path was different.  Intel began with a complex sort of traditional mainframe instruction set in a small - with a small bit length, namely an 8-bit microprocessor, but with an inherently complex instruction set.  So it was very mainframe-ish.  And then they extended its size, and it got increasingly complex as they went.  And now they're to the point where they desperately wish that they could keep instruction set compatibility with a simpler design, but they can't.  And you can imagine that the engineering effort that they put into trying to compete with this ARM chip, which just whizzes by them in terms of performance and power consumption.



So the answer is, I've sort of summarized what we discussed in great and I think really interesting detail back in those computer architecture podcasts.  So Gregory and anybody else who hasn't heard those, I'd really recommend you go back and look at them.  They're all at GRC.com/sn, where you can find them.  There's a search there.  Thanks to Elaine's transcripts, you can put in, like, "computer architecture," probably, and you'll find them.  I don't remember what batch of weeks they were in that Leo and I did these.



But essentially what matters is transistor count.  Transistors burn power.  And due to the way ARM started and has, to their credit, remained, there are many fewer transistors needed to run their instructions than Intel needs to run theirs.  And so the ARM dies are smaller.  There are fewer transistors.  They run more efficiently.  Everything about it has just turned out, coincidentally, to be what made sense in a battery-powered device.  And Intel, I don't know how they could get around this, how they could - if they could, they would have.  And so I think that's just a fundamental legacy difference that Intel is stuck with.



LEO:  It isn't actually by accident because ARM - Apple put a huge investment into ARM because they were developing processors for the Newton.  And so it isn't actually by accident.  It's intentional.  ARMs were always intended for mobile devices, ARM processors.  Intel has tried to do these scale processors.  They're trying to do low-power processors.  They even have some.  They realize they're missing out on a huge growth area with mobile.



And interestingly, Windows, when they decided to put Windows 8 on tablets, they didn't make it x86.  They rewrote it for ARM.  It's Windows on ARM, or Windows RT.  And I think that the legacy issue comes from the fact that Microsoft just kind of unilaterally decided that, if you're going to write software for the tablets, that it's got to be Metro style.  And only Microsoft has its actual Office style stuff on tablets and desktop.  So I don't - we'll have to ask Paul about that.  My suspicion is in time you'll be able to do a lot of the legacy stuff.



STEVE:  It'll be interesting to see Windows on ARM.  That is, it'll help us to understand...



LEO:  Right, the difference.



STEVE:  Yes, exactly, what's the slow part?  Is it the x86/64?  Or is it the Windows-ness, which is like - does Android on an ARM tablet, how does its performance compare to Windows on the same hardware?  We'll be able to see it.



LEO:  Yeah.  I don't know what the status is of Intel's XScale solution.  I mean, they're really hoping, I'm sure, to get a mobile part out there.  Be interesting.  They're able to get the die sizes down so low now, with Ivy Bridge and so forth.  I wonder.



STEVE:  Yeah.  I don't think you can engineer around the architecture.  What they're doing is they're, like, stalling, they're stopping the processor and trying not to have it run...



LEO:  Right, speed step and all that, yeah.



STEVE:  Exactly.  And so, but when it does run, it says give me a larger straw because I need to suck more juice out of your battery.



LEO:  Actually, interesting, just looking up XScale, which is Intel's mobile part, it's based on the ARM architecture.  So never mind.  I think ARM won.  Wow, that's really interesting.  Who would have thought Intel would use ARM?



Moving along to Question 6, Bill Schwartz in Quincy, Mass.  A huge SpiderOak disadvantage:  I've confirmed with SpiderOak support, which was excellent, that they provide no means for maintaining privacy between different users, or different computers, on a single account.  All users and all machines must share an encryption password.  So if, say, two household members share a 100GB SpiderOak account, all privacy between them is annihilated for all files placed on the SpiderOak network.  Moreover, each household member then absolutely depends on all the others to keep the common encryption key safe and private.  One slip by one person compromises everyone's data.  This will be a big disadvantage for many people.  I don't think so, but - I mean, come on.  Really?



SpiderOak told me their forthcoming enterprise solution of course will offer such intra-account privacy, but at a higher cost.  They also told me this feature would be implemented on the non-enterprise side, as well, but not anytime soon.  For now, the only answer is for each household member to have his or her own account, which means multiplying costs.  And since most users will probably never need anywhere near the full 100GB on the minimum paid plan, this will be a very big price disadvantage for SpiderOak.  It's too bad.  Everything else about SpiderOak seems great to me so far. 



This is not a problem at all with Jungle Disk, my current cloud provider.  As an aside, I have been feeling that Jungle Disk has absolutely lost the magic it once had since Jungle Dave sold and then left the company.  I've had many problems, including massive overfilling for months and months that took forever for them to solve.  Their app is still not completely compatible with OS X Lion. I'd love to find an alternative to Jungle Disk.  Thanks for the great review.  Hope this helps.



I've been using ARQ, on your recommendation, Steve, and I think this is a good alternative.



STEVE:  Yeah, I do, too.  On the Mac side.



LEO:  Yeah, on the Mac side, yeah.



STEVE:  Oh, and it does sound like, because he's talking about OS X Lion, it sounds like he's also...



LEO:  I mean, ARQ is an excellent alternative to Jungle Disk if you're on OS X.



STEVE:  Yup.  Now, I'm with you, Leo.  I wanted to bring it up and, like, highlight the issue because that's a good one, maybe.  And our listeners' individual usage patterns...



LEO:  You'll have to be the judge, yeah.



STEVE:  Yeah.  If you had a crazy teenager who - like Henry - who is sharing your account and had to have all your keys, and you were really storing super-confidential stuff - you probably don't have that kind of data.  But I could imagine, if I was depending upon a service like this for encrypting the keys to my kingdom, frankly, I'd just spring for a separate account and let other people use a different account than mine as opposed to intending to share it.  But it's a good...



LEO:  Or use TrueCrypt or something.  Right?



STEVE:  Right, right.  Exactly.  Or use one of these, as we covered last week, use a hybrid solution where you separately encrypt your own stuff and drop it into the family shared folder, so you're safe in any event.  Yeah.



LEO:  Yeah.  And they do offer free accounts of, what is it, 2GB.  So maybe give your teenager the 2GB, and then you don't have to worry about it, get a 2GB account.



Moving right along here, which we will do as soon as I reopen - why do I keep closing this window?  Question #7, Rick in Rhode Island.  He thinks you're wrong, Steve.  You're wrong about Java.



STEVE:  I have been.



LEO:  I don't know the details of cloud software using Java, but your dismissal of Java so quickly seems misplaced.  There are plenty of standalone, not browser-embedded applications built using Java, and I don't think they're any less secure than native applications.  Well, that's true.  It would be good if you could elaborate on how these cloud apps run, browser vs. standalone.  One reason standalone apps are written in Java is portability, and it works very well in that respect.



STEVE:  So I completely agree with Rick that in that mode it makes sense.  I did have a couple tweets from people who said, yes, Steve, I guess I can understand your position on Java.  But I'm a Linux user, and we're not Windows or Mac, and so we're often the stepchild that doesn't get the attention that the big platforms do.  When they're written in Java, because Java creates cross-platform compatibility, we're able to use those solutions.  And I think that's a very good point.  I mean, as opposed to not being able to use them.



My complaint was different than that, though.  It was that I don't like the idea of requiring a user to install Java just to run a backup client.  If you're a commercial enterprise making money from people, selling them your client, sell them a native client for their platform.  These things are not hard to write or create, I mean, that's why there's a billion of them is that it's not like it's rocket science.  Everyone's creating them.  But my feeling is, wow, I'd like to have one written for Windows that doesn't force me to be running Java.  And we have seen problems with memory management in Java clients, taking up half a gig of memory.  Other people report that they don't have that problem.  But if you're writing - I guess my sense is, if you're creating a commercial application for a platform, it's just not difficult to develop for that platform.  If it's freeware, then you kind of get what you don't pay for.



LEO:  I would say the most widely used Java app out there right now is a game called Minecraft.  And it's written...



STEVE:  Whose shirt I apparently wear.



LEO:  You wear that shirt.  You have a diamond block shirt.  And Minecraft is run by millions and millions of people, and you have to have Java to run it.  Actually, come to think of it, the Citrix products also run in Java.  So, but his point is well taken, which is a Java application is no less or more, actually may be more secure than a standalone application because of some of the built-in sandboxing features of Java.



STEVE:  Yup.  And like I said, when I saw that Netalyzr...



LEO:  Netalyzr's in Java, baby.



STEVE:  ...is in Java, I thought, oh, if you can do that in Java, then I need to keep that on my radar because that could be very useful for solving my own lack of cross-platform software development.



LEO:  Java's awesome.  I think your point, and what you've always said is, if you don't need it, uninstall it.  There's no reason to have it.  Like Shockwave, if you don't need it, don't install it because of the security issues.



STEVE:  Right.  Because your browser will run Java things, and that's how 600,000 Mac people got infected.



LEO:  Right.  I think, I bet, I'm just going to - I'm pretty sure, I know you can say disable JavaScript.  I'm pretty sure that the browser will also let you disable Java.  So that would be the other thing, to go into...



STEVE:  Well, remember, the new update from Apple preemptively disables Java.



LEO:  Right.



STEVE:  It shuts it down and then, if you turn it on, and you don't keep using it, shuts it down again.



LEO:  I have on my Safari, on my OS X system, "Enable Java" unchecked.  So you can have Java on your system.  Just don't let the browser invoke it.



STEVE:  Right.



LEO:  That would be good, too; right?



STEVE:  Yup, really good.  And that's what Apple has done, is they are turning it off for you and keeping it off.



LEO:  Yeah.  And what Chrome does is they say each time, they ask you, do you want to allow this to run?



STEVE:  Right.



LEO:  I see that all the time because whenever I run - whenever I do GoToMeeting, one of the reasons GoToMeeting I think uses Java is because it's compact, and they download a new copy every single time to make sure you have the latest version.  And so I see that "allow" thing every time I run GoToMeeting, and it's fine.  Just say, yeah, yeah, I wanted to run GoToMeeting, no problem.



Charles Hill, Washington, DC:  A defense of Backblaze.   Steve, I'm listening to your retelling of your email discussion with the CEO of Backblaze.  I can't help but think you were missing a critical point he was trying to make.  I am referring to their "user-provided private key" method only.  You're saying that since the key is given to Backblaze, and they decrypt the user's data on their server, it isn't TNO because you have to trust Backblaze in that instance.  Well, I don't disagree with that.



But what the BB CEO, the Backblaze CEO is saying is also valid:  "There is no such thing as TNO with an integrated solution, so what's the issue?"  That is, when you say if they were to do the en- or decryption on the user PC, it would be TNO because only the user would have the key in plaintext.  His point - I think you might have missed it - is, if you're using software provided by the client, whether it's Backblaze, SpiderOak, or something else, you're trusting their client software is doing only what it claims to do.  In other words, not sending back the data secretly or storing it somehow.  All Backblaze is doing is shifting the point of trust from the client software to the server side.  The issue of trusting the third-party exists, regardless.



So your suggestion of changing their architecture to just decrypt on the client isn't a solution.  You still have to trust their client software.  The CEO of Backblaze's point was just that.  You're just kidding yourself with TNO with an integrated service, so why not just be honest about it and trust them?  The only real TNO solution that I've been able to come up with is to separate the encryption out from the storage.  Personally, I just have a cron job tar/gz up my new files every week, run it through GnuPG to encrypt it, then FTP it up to an Amazon S3 account.  Signatures are kept locally.  It's a bit geeky, but it works for me.  Or am I totally off base?



STEVE:  Well, I certainly see his point.  My concern, and I know the concern of listeners who want TNO, is that it's not TNO.  And their documentation makes it sound like it is, but it isn't.  And we do know, because it comes up all the time, that our government is able to subpoena records of companies.  In fact, I forgot to put it in the news this week, but I tweeted it, it was late last week, Leo, you may have seen it, the story about the FBI proposing legislation to force...



LEO:  Oh, yeah, CISPA, yeah.



STEVE:  Yes, force social networking and other websites to build in monitoring technology.  I mean, so this is not made up.  And Gleb Budman, whom I exchange email with, the  CEO and cofounder of Backblaze, who is a really nice guy, he said, "We've never been served with that kind of requirement."  Well...



LEO:  Boy, that's a shock.



STEVE:  If they were, they couldn't say.  I mean, he would have to deny it.  He would have to say that.  And I just - the point is the architecture could be secure.  Other people do it.  These people didn't.  And they really didn't say that.  I mean, they said the other.  And so that's my concern.  It's like, yeah, this works.  I'm sure it's fine.  But it's not Trust No One because they've got the keys.  And by definition, that just doesn't do it.



LEO:  But his point is well taken, that when you run somebody's client software on your system, that software could be malcrafted in such a way that...



STEVE:  Absolutely.



LEO:  ...it could be stealing data.  You don't know that.



STEVE:  And I actually do like, I mean, he made the distinction of an integrated solution.  Most people, 99.99 percent, want that.  But that's where I like the solution I'm using of using a grandfathered Jungle Disk account and S3.  Amazon is my storage provider.  Jungle Disk is my encryption provider.  They're not in cahoots any way.  They're separable actions.  And of course his, as he says, "geeky solution" is that to an extreme, where he's got a cron job that runs a script that tars and gzips and encrypts and FTPs, blah blah, but it works.  There's absolute security because he only has to trust himself.  He knows all these little pieces, there's no way that they can be collaborating.



LEO:  Moving along to Question 9 from Shawn.  Shawnt.  Shant H. in Glendale, California.  Does the government have a master encryption key?  Well, this fits right into that wiretap story.  How's it going, Steve?  I'm a computer science student, long-time listener to the show.  This week, in one of my classes, the professor announced to the class that all 128-bit encryption can be cracked by the U.S. government because they have a "master key."  Wow.



STEVE:  Oh, I know.



LEO:  What school is this?



STEVE:  I know.  Glendale.  It's not like it's out in the sticks somewhere.



LEO:  Hmm.  Now, being an avid listener to the show, I am 99.99999 percent sure that this is untrue.  As far as my understanding goes, the math only allows a single unique key to decrypt the message, therefore there can't be a master key to decrypt the message.  I think my argument in class will be weighted with your backing.  Thanks for the great show.  Shant.



STEVE:  Well, Shant, I don't want you to get in trouble with your professor by calling him an idiot.



LEO:  He's an idiot.



STEVE:  He's an idiot.  I mean...



LEO:  And I wouldn't trust anything else he says after this



STEVE:  Yeah, that's a real worry.  Okay.  So the reason Leo and I can be so sure, I mean, I love the fact that we can be so sure.  It's because all of this is open.  See, this is the beauty of the open development, open academic process that encryption always enjoys is we know exactly how AES works.  We've done a podcast on it.  We've looked at it.  It's been pounded on.  It's the result of a competition among a bunch of all really good strong crypto and for a number of reasons sort of a compromise between how much power it used and how complex it was and whether it was, you know, all these criteria that they used, it was chosen.  So I just - I love the certainty with which we're able to say no, there's no such, I mean, it's ridiculous, patently ridiculous because - and we're only able to say that because we absolutely know.  It has not always been this way.  You'll remember, Leo, the days of the Clipper chip, which was sort of a...



LEO:  Al Gore, baby.



STEVE:  ...government-sponsored, secret crypto that no one knew what was inside.  It was like, oh...



LEO:  And nobody used because there was a backdoor.



STEVE:  Exactly.  So maybe this professor is confused, although the Clipper chip was not 128-bit encryption because it was too long ago for 128-bit to be used commonly.  Probably 64, back in the DES era.



LEO:  Or 48 even, maybe.



STEVE:  Maybe, yeah.  But, I mean, oh, goodness, no.  The beauty is contemporary encryption is completely open.  It's what I love about it.  And that's why, when an encryption technology, an encryption company says we're doing this, this, this, this, and this.  Here's our diagram.  This is what we're doing.  I mean, we know what the blocks do.  We know when you connect them together following standard practices that you're going to get a strong, a provably secure result as far as anyone knows.  And we have to throw that caveat in because something could catch us out.  But as well as we know, this is what it's going to do and how it's going to work.  I love that aspect of crypto.



LEO:  Me, too.



STEVE:  It makes for great podcasts.



LEO:  Me, too.  And it's why I like open source and recommend open source crypto solutions above all others, because you can verify that it works, that it doesn't have any backdoors.



STEVE:  Yeah.  And I would say open algorithm, to take a step back...



LEO:  Open algorithm, I agree, yes.



STEVE:  Yes.  Because most people may not look at the bits.  And mistakes can be made in algorithms.  But again...



LEO:  As we know, with WEP.



STEVE:  Yes, exactly.



LEO:  I just hope this guy's a professor of philosophy, not computer science.  That's all I can say.



STEVE:  Yeah.



LEO:  I just hope he's not a computer science professor because that would be really depressing.



STEVE:  Yeah, well, so Shant...



LEO:  Clipper chip was 80-bit, says "Considerate" in the chatroom.



STEVE:  Ah.  Shant, tell your classmates the truth, but don't get in trouble.  I don't want to, you know...



LEO:  Yeah.  You could pass notes.  Last question, Tom Hartnett, St. Louis, MO, commenting about the forthcoming NSA facility in Utah.  Get ready for this:  I've heard you discuss before that there are no shortcuts possessed by the government for cracking encryption.  I agree.  However, I thought I'd pass along this article nonetheless.  A paragraph in it caught my eye:  "The $2 billion facility, slated to be complete by September 2013, is allegedly designed to be able to filter through yottabytes (that's 10^24 bytes) of data.  Put into perspective, that's greater than the estimated total of all human knowledge since the dawn of mankind.  If leaked information about the complex is correct, nothing will be safe from the facility's reach, from cell phone communications to emails to what you just bought with your credit card.  And encryption won't protect you - one of the facility's priorities is breaking even the most complex of codes."  Hmm.



STEVE:  Oh, Leo, that is my favorite voice you have ever done.  Oh.  Say goodbye to Australian.  That was...



LEO:  That's my Walter Cronkite.



STEVE:  Oh, my.  Oh, we're going to bring that out from time to time.  Oh.  I just - oh, goodness.  That's one for the record books.



LEO:  So what do you [laughing].  Thank you, Steve, thank you.  What do you say to this?



STEVE:  I just - I want to hear it again.



LEO:  "The $2 billion facility."



STEVE:  Okay.  I completely agree with the designed to be able to filter through yottabytes of data.  Absolutely.  We know that that's the main focus.  And the fact is, so much today is not encrypted that huge amounts of value can be found in the clear, in plaintext, in all these yottabytes.  They're going to have to have some amazing indexing and organization system to deal with all this.  But that's what they've got this big facility for.



The idea, though, that there's some magic secret to decryption, you know, it says, "And encryption won't protect you - one of the facility's priorities is breaking even the most complex codes."  Well, I agree that that's what its priority is.  I mean, it's...



LEO:  It doesn't mean they can do it.



STEVE:  No, it's the dream of the NSA and the FBI and the CIA to be able to cut through encryption like butter so that it doesn't impede their investigations.  And I don't...



LEO:  That's why they're asking for a backdoor, by the way, in Skype and everything else, because they can't.



STEVE:  Right.  Right.  We've talked about TrueCrypted drives being sent from South America up to the U.S. law enforcement to see if the FBI could crack it, and unfortunately they were - I mean, okay.  Whether it's unfortunate or not, I can't comment.  But they weren't able to crack it because the crypto holds.  The crypto is absolute at this point.  So, yes.  I mean, the only danger on the far horizon is potentially the myth of, the allure of quantum computing, where the theory is it simultaneously tries all keys at once, which just melts crypto.  It's just over.  But we're a long way away from that.  So I'm not worried.  And we ought not be.  I'm not worried about Utah.  I mean, basically they want to feed every possible communication channel that they can find through the equivalent of - remember the wonderful movie, "Colossus: The Forbin Project," which actually is being remade, by the way?



LEO:  I love that movie.



STEVE:  I've watched it many times.



LEO:  Oh, what a great movie.  I'm glad it's being remade.  It could stand to be a little updated.



STEVE:  Yeah, it really could.  So it'd be great...



LEO:  I'm not going to say anything.  But somebody I know very well was approached by the federal government to help write something that would go through data and find keywords.  And in fact we know pretty well that Echelon exists.  The U.S. government's never admitted to it, but the British have.  And all Echelon is, is exactly this.  And this is what the NSA does.  They monitor electronic transmissions.  Unencrypted electronic transmissions.  I'm sure they store encrypted transmissions, but I don't know if they can do anything with them.  If they're properly encrypted, they can't.



STEVE:  Oh, and the roof looks so cool, with all the...



LEO:  I haven't seen the roof.  Antennas?



STEVE:  Oh, with all those big dishes, with all those dish antennas pointing in every direction.  It's like, whoa.



LEO:  But if anything, this should argue for people using encryption, using strong encryption because, if you don't, then you know that everything you say and do electronically, including email, telephone, cell phone, everything is being monitored by the NSA.  And they do key - I don't know what the keywords are, but I'm sure if you said a few choice phrases about Uncle Sam and explosives, you'd probably get flagged.  And that's what they do.  That's what they're doing.  There's so much encrypted transmission now that they probably wouldn't even have time to decrypt it.



STEVE:  Well, and there've got to be taps on major backbones of the Internet.



LEO:  Oh, yes.



STEVE:  So in terms of communications, so like everything that crosses through anywhere that they're able to install a tap, they've got, I mean, I feel sorry for their yottabyte computers, all the garbage, I mean, all the nonsense.



LEO:  Think of all that crap they're getting.



STEVE:  All the tweets and the Facebook postings, and it's like, oh, you wrote on my wall, and oh, it's like, okay, well, good luck with that, NSA.



LEO:  This is a picture of the actual building in Utah.



STEVE:  Ooh, look at that lighting.  Nice lighting.



LEO:  The country's biggest spy center.  I can understand why people are nervous.  If you want to protect your privacy, what you should be doing is make sure that you let  your member of Congress know that the FBI, NSA, CIA request to put backdoors into things like Skype and Facebook be denied.



STEVE:  Yup.



LEO:  Because that's, really, that's what they're saying is, look, we can't decrypt Skype, so we would like you to put a backdoor in it so that we can wiretap it.



STEVE:  It's like the problem that RIM had.  We talked about RIM's problem over in the Far East often last year because there was such a brouhaha about the foreign governments demanding that their BlackBerry-using citizens could be spied on.



LEO:  Yeah.  By the way...



STEVE:  The technology just isn't there.



LEO:  ...the contractors building this building have to have top-secret security clearances.



STEVE:  Yeah, because they've got special tile.  Oh, good, goodness.



LEO:  Flowing through its servers, according to Wired's Threat Level blog, which we love, will be all forms of communication, including the complete contents of private emails, cell phone calls, Google searches, parking receipts, travel itineraries, bookstore purchases.



STEVE:  Yeah, just everything, basically.  We're all electronic now.  Everything's wired up.  And these suckers want to filter through all of that nonsense.  I say good.  I say let 'em have it.



LEO:  You may remember that this was something George Bush wanted.  It was called Total - actually, I think it was actually the Vice President.  He wanted, remember, Total - what was it called?  Total Information Awareness?  TIA?  In a fight against terrorism.  The problem is, when your federal government knows everything, why limit it to terrorism?  Let's go after people with unpaid parking tickets, everything else.



STEVE:  And unfortunately there is a history of that, too.  There is a history of this stuff being repurposed, people believe for the health of the country, but not everyone is in agreement about what that means.  And that's a problem.



LEO:  Now, let me read you this paragraph because I'm sure this is where this story comes from.  One senior intelligence official who until recently was involved with the program says that the "Bluffdale center will have another important and far more secret role."  It's critical, he says, "for breaking codes.  And code-breaking is crucial because much of the data that the center will handle - financial information, stock transactions, business deals, foreign military and diplomatic secrets, legal documents, confidential personal communications" - I guess not so confidential - "will be heavily encrypted.  According to another top official also involved with the program" - and this is what I think is bogus - "the NSA made an enormous breakthrough several years ago in its ability to cryptanalyze, or break, unfathomably complex encryption systems employed not only by governments around the world, but also many average computers in the U.S."



STEVE:  Well, I don't know.



LEO:  Do you think so?  Think it's credible?



STEVE:  We have no way of knowing.



LEO:  We can't know.



STEVE:  The one thing that I remember from the early reports was that they already have a huge amount of data encrypted using older, weaker codes - for example, 64-bit encryption - and now we have the technology to feasibly crack that.  So they've got communications from foreign powers encrypted in - I mean, old communications encrypted in the then strongest codes of the time.  So what we need to remember is, when storage is available, the encryption we use needs to be strong relative to our ability to decrypt into the future until a point where it no longer matters.  And so my best guess is that they've got way, I mean, 64-bit encryption is, you know, we pooh-pooh it, but it was strong then.  It's still strong now.  We're just staying way ahead of what's feasible by going to 128 and 256, which is, you know, 128 is already really, I mean, that's, like, plenty strong.



LEO:  Yeah.  In fact, he says, "a lot of foreign government stuff we've never been able to break is 128 or less.  Break all that and you'll find out a lot more of what you didn't know - stuff we've already stored...."



STEVE:  Exactly.  So my guess is they're rubbing their hands together about bringing this processing power to bear on stuff that's a decade or two old.  There can be really juicy tidbits that still matter in data that is only that old.



LEO:  Sure.  They've stored it.  They just couldn't crack it until now.



STEVE:  Right, right.  I think the stuff we're doing today is probably safe, given everything we know.



LEO:  And the guy who wrote this article [James Bamford] is the author of "The Shadow Factory:  The Ultra-Secret NSA from 9/11 to the Eavesdropping on America," if you want to read more.  He has a little bit of an ax to grind.  I mean, he wants everybody to get scared.  I think, though, if there's anything, this would argue for using encryption more, not less, because they are watching.



STEVE:  Yeah.  Exactly.  Not assuming privacy.  Unfortunately, we can no longer...



LEO:  We don't have it.



STEVE:  Yeah.



LEO:  Yeah, we don't have it.  If you don't mind if spooks in Utah are reading your mail, no big deal.  But if you do, I would say public key cryptography with long...



STEVE:  2048-bit public key and a 256-bit symmetric key.  That's going to be...



LEO:  That's going to be fine for a while.



STEVE:  It really is.



LEO:  I hope.



STEVE:  I guess...



LEO:  Unless you and I are being paid by the federal government to say that.



STEVE:  The only breakthrough I could see, Leo, would be if  they actually had a factoring breakthrough.



LEO:  Right.



STEVE:  That would be...



LEO:  It would be a mathematical - it would be a breakthrough in mathematical theory, I think.



STEVE:  Yeah, well, see, and the thing I like about our symmetric crypto is it is so simple.  I mean, we did a beautiful podcast on AES where I explained in detail what that algorithm is.  And it's just - it's like there's nowhere for bad guys to hide in that algorithm.  It's just so clear and clean.  And we all know what the vulnerability, such as it is, of current public key crypto is.  It's the factoring problem, which the smartest people in the country who are in the private sector have looked at, private and education, and have not been able to crack.  Now, maybe the NSA has cracked factoring.  And if they've cracked factoring, then, yeah, well, public key crypto, at least the standard RSA style, there are other types, but that's then gone.  But again, maybe.



LEO:  Maybe.  It's an interesting idea.



STEVE:  Yeah, I mean, that's the vulnerability.  Factoring is the vulnerability because that's what we all depend on right now.  I mean, that's the Achilles heel.  Not the symmetric crypto, but the asymmetric crypto.  And the reason those keys, the asymmetric crypto keys have to be 1024 or 2048 bits long is that the actual strength is not nearly as great as it is with symmetric crypto, where a 128-bit key is fine.  We need to have, like, 10 times that many bits to get the equivalent strength.  So that would be the Achilles heel.  And maybe somebody's with his headphones on, listening to us say this right now, Leo, going, oh, shoot.  Figured it out.



LEO:  Steve Gibson is at GRC.com.  That's where he sells SpinRite, the world's best hard drive maintenance and recovery utility.  Go there.  Buy SpinRite.  If you want to leave a question for the next feedback episode, GRC.com/feedback.  His health page is there, GRC.com/health.  His free stuff, all sorts of stuff.  Really, it's becoming a better, bigger resource all the time for great information.  Steve will be back on Sunday, 3:00 to 4:00 p.m. Pacific, 6:00 to 5:00 p.m.



STEVE:  Whoops, 2:00 to 3:00 p.m.



LEO:  2:00 to 3:00 p.m. Pacific 5:00 to 6:00 p.m. Eastern, Part 2 of our up and down the sugar hill, conquering the sugar hill series.  I'm looking forward to concluding that.  I hope we'll conclude.  Maybe not.  Maybe this is becoming an ongoing series.  I don't know.



STEVE:  Well, the people who like it really love it, but...



LEO:  People who hate it, don't.



STEVE:  Yeah.



LEO:  And there's some in each camp.  I'm loving it.  And  I have to say, now that I've got this book, the Rosedale book, I'm very excited.



STEVE:  Good.



LEO:  Steve, we'll talk to you Sunday.  And then, of course, again next week when we do a Security Now! every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC.  You can watch live.  If you can't see it live, don't worry, we make audio and video available always after the fact at TWiT.tv.  Steve has 16Kb versions available at GRC.com, as well as transcriptions.  So you can consume it in a variety of ways.  352 episodes now in the can.  Thank you, Steve Gibson.  We'll see you next time.



STEVE:  Thanks, Leo.



LEO:  On Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#353

DATE:		May 16, 2012

TITLE:		DMARC - eMail Security

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-353.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's news, Steve and Leo look at the state of the slow but sure and steady progress being made to tighten up the Internet's eMail security.  Since spoofing and phishing continue to be huge problems, these problems continue to command the attention of the Internet's largest commerce, financial, and social networking domains.  The good news is:  There's good reason for hope!!



SHOW TEASE:  It's time for Security Now!.  What if spam went away entirely?  Well, it seems to be a problem of authentication.  Steve's going to take a look at things we've tried so far and a new technology, DMARC, that promises to fix the spam problem.  That's next on Security Now!



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 353, recorded May 16th, 2012:  DMARC Email Security.



It's time for Security Now!, the show that covers and protects you everywhere you go online, thanks to this man here, our Explainer in Chief, Mr. Steve Gibson of GRC.com, the Gibson Research Corporation.  Steve is a security expert and also the author of a great utility called SpinRite that everybody needs for hard drive maintenance and recovery.  Hello, Steve Gibson.



STEVE GIBSON:  Hey, Leo.  Well, 353 podcasts as of today.



LEO:  Add two, though, because we did two off the books.



STEVE:  We did, indeed.  Anybody who is waiting for Part 2 of The Sugar Hill can find it over on the TWiT Specials page, which we did last Sunday.  And I'll just mention that the pages at GRC regarding health, which are under our main menu under Research, have matured a great deal.  I'm getting - and Leo, this is for you, too - some fantastic case histories which I am able to share with their authors' permission in every case.  I make sure that they don't mind.  And they're anonymous anyway.  But really interesting experiences that a lot of our listeners have had.  Many of the questions they've had have been answered by these two podcasts.  And in some cases they'd tried it and been discouraged, but now they're encouraged to give another shot, or they learned enough that they think maybe they've got a better grip on it now.  So anyway, I would commend anyone who's interested to go look at GRC.com/health and look at low-carb stuff.  And there's a bunch of pages, all of the book recommendations.  I have a Q&A page, a users' experiences page, and a bunch of resources there.



LEO:  It's very timely because you know HBO's doing a four-part special right now called "The Weight of the Nation."  It's all about how fat we are.  There is an obesity epidemic, I mean, a huge obesity epidemic that just occurred in the most recent couple of decades.  Now 37 percent of America is obese.  Not just overweight, but morbidly so.  So it's a very interesting thing.



And given the information that you've given us in the last two episodes - and, by the way, it's on TWiT Specials, TWiT.tv/specials, Episodes 124 and 125 of our TWiT Specials.  It's interesting to watch these shows because there's still a considerable amount of confusion.  I was talking to my physician about this today, actually.  And he pointed out that doctors, MDs, are not trained in nutrition.  They know scant information about it unless they've studied it themselves in some other way.  There's a lot of misinformation from epidemiological studies, which we've talked about before, which have the basic fundamental problem of matching causation to correlation, which of course, as we know, correlation is not causation because we're all scientific thinkers here.  And he said the real problem is you can't really do long-term, double-blind tests on nutrition.



STEVE:  Right.



LEO:  You need 10, 20 years to know if this - because it doesn't kill you, none of this kills you right away.



STEVE:  Exactly.  And not everyone responds identically.  You can feed two people the same diet, and they will get completely different responses.



LEO:  He said the same thing.  He said it's kind of you can't be sure of what the effect will be.  So you have to do what you're doing, which is do a lot of research and try to find something that does work for your body.  And you're doing this, I should say, under medical supervision.



STEVE:  Yes.  And I test weekly.  I've got weekly charts of all of my...



LEO:  You're taking this very seriously,  yeah.



STEVE:  ...yeah, of all my measurements.  It's interesting.  Currently the bottom testimonial, such as it is, or it's feedback, I got permission to post just this morning, so I put it up.  It's a really nicely written piece about how a guy went low-carb and reversed his diabetes and high blood sugar, brought his blood pressure down, his HDL (the good cholesterol) up, the LDL (the bad cholesterol) down, triglycerides way down, I mean, everything was perfect.  He goes to his doctor, and the doctor says, "My god, congratulations, this is fantastic.  You're going to live forever.  What are you doing?"  And he says, "Atkins."  And the doctor goes, "Aghhhh."



LEO:  Oh, yeah, right, that's terrible for you. Don't you know?



STEVE:  "It will ruin your liver.  You're going to ruin your kidneys."  And so the guy says, "Well, how do my liver enzymes look?"  And the doctor says, "Well, they look perfect, they're fantastic.  But you're going to ruin your liver, and you're going to ruin your kidneys.  And you're going against the USDA and the FDA," blah blah blah.  And then he says, "Well, how does my urinalysis look that would show what's going on with my kidneys?"  "Oh, it's perfect.  There's nothing wrong.  But you're going to ruin your liver.  You're going to ruin your kidneys."  And this, of course, is - it's the truth.  And so, you know, he was discouraged and thought, well, god, I mean, it worried him that somebody who he assumed was an authority would have this opinion.  And so my favorite set of books are those low-carb - "The Art and Science of Low Carb Living" and "Low Carb..."



LEO:  I ordered those.



STEVE:  Good, because these guys are double PhDs and MDs who have been studying this.  And if nothing else, they give you some objectivity that I don't think that we're finding right now.  And so anyway, it's interesting stuff, I think.  It's fascinating to me.



LEO:  You know what one of the conclusions of this "Weight of the Nation" is the government needs to regulate all this.  And I thought, you know what, the government has mishandled this from day one.



STEVE:  Yes.



LEO:  And that's part of the reason we're in this fix.  Maybe if we just - if people just studied and learned and thought and did what you do, which is do this under doctor supervision, I think that you can do it yourself.



STEVE:  Yeah, and experiment.  I think it might have been in the beginning of "Good Calories, Bad Calories" that Gary explains how political this process is to government.



LEO:  Yeah, alas, yeah.



STEVE:  That in fact it's not, I mean, the scientists are consulted and then ignored because the government and the political advisors don't like what the scientists say.  So this isn't science-based.  It's politically driven, in fact.



LEO:  Yes, as is most politics.  Most government is politically driven.  Anyway, enough of that.  Let's get into the security issues.  Today we're going to talk about what?  What is DMARC?



STEVE:  I want to talk about what's been going on quietly and in the background by the big players in the industry that are essentially the movers of this towards dealing with the problem of phishing and spam and email spoofing.  Everyone's just sort of given up at this point.  And we know that there's still a huge problem because, in the same way that I'm noticing sites are now saying you need to have JavaScript turned on, because I'm going there initially with it off, and because for safety, and then I turn it on when I need it, similarly - and I'm sure you're seeing this, too, Leo - there are more and more sites that, when you do something with them, and they need to send you a confirming email, they say, you know, warning, if you do not receive email from us within two minutes, please go look for it in your spam folder because we really have sent it, and we're really going to, and you need to receive it in order to verify your email address, and it may have trouble getting to you.



And so this represents a big problem for the Internet.  We've had problems with email from the beginning.  It is still the No. 1 means for these large site takeovers.  We know, for example, that that whole RSA fiasco with them losing the keys began with an employee clicking a link in spoofed email that then allowed an exploit to take hold that allowed the bad guys to gain entry into the RSA network.  So it is really important for Internet security.



Well, there have been some efforts made that have sort of sputtered along.  We're going to talk about what they are, and why they haven't been able to get the traction that they could, and how, despite the fact that we haven't been paying any attention, there is an effort ongoing which is moving forward that looks like it's going to give us, finally, some real relief.  And we're about at a tipping point.  I would imagine, as often is the case on this podcast, we'll be talking about it.  It comes across our radar early; and then, oh, maybe six months to a year from now, suddenly it's going to be...



LEO:  Everybody's talking about it, yeah.



STEVE:  ...oh, yeah, we already know about that.  We did that in Podcast #353 a year ago.



LEO:  It's funny how much people have stopped talking about spam, not because spam has gone away or is any better - in fact it's, as far as I know, worse - but our tools for fighting it have gotten better, and particularly filtering.  But this goes beyond filtering.  All right.  Before we get into DMARC, Mr. Gibson...



STEVE:  Yeah, we've got just a little bit.  I don't know, sometimes a week just gives us so many news topics to talk about that we barely get to the show.  And in fact sometimes grumpy people will send me a tweet saying, "It took 55 minutes before we actually got into the content."  It's like, hey, folks, news and security updates and conversation about the week's events was the original concept for this podcast, and we added all of that other content afterwards.  So, I mean, I spend as much time, well, not as much time, but lots of time wanting to make sure I keep everybody current with things that are going on.



LEO:  But see, that's why this show could be any length at all.  You get to choose the length because it expands to fit the needs.



STEVE:  Oh, and I also get tweets saying, "Love the podcast.  Could you do it daily?"



LEO:  [Laughing] No.



STEVE:  Just scrape me off the floor.



LEO:  I can tell you right now, no.  But weekly's good.  Weekly's good.  You should be - weekly's good.



STEVE:  It's just right.



LEO:  Yes.



STEVE:  So Chrome has moved itself to v19.  And in the blog yesterday, quoting from the blog, they said, "Say you've found an awesome recipe on your work computer while, ahem, working hard at the office.  But when you get back home, you can't quite remember if it was two teaspoons of baking soda or two teaspoons of baking powder."



LEO:  [Laughing] Big difference.



STEVE:  I'll take your word for that, Leo.  "Wouldn't it be cool..."



LEO:  Yeah, you're such a cook.



STEVE:  Yeah.  "Wouldn't it be cool if you could pull up the same recipe on your home computer with one click?  With today's stable release of Chrome, you can.  When you're signed in to Chrome" - and we'll explain what that is in a second - "your open tabs are synced across all your devices, so you can quickly access them from the Other Devices menu" - which is a new menu - "on the New Tab page.  If you've got Chrome for Android Beta, you can open the same recipe tab right on your phone when you run out to the store for more ingredients.  The back and forward buttons will even work, so you can pick up browsing right where you left off."  So that means they are even syncing the history of the tab that is now being bridged by these devices.



And so then I thought, well, okay, what does "signing into Chrome" mean?  And they said:  "Signing into Chrome brings your bookmarks, apps, history, and other settings to all your devices.  Anything you update on one device instantly updates everywhere else, and your Chrome stuff is safe in case anything happens to your computer.  It's your web.  Take it with you."  Of course, and Google, too.



LEO:  Very nice.



STEVE:  But, so, yeah.  I'm wishing that Chrome wasn't just becoming so neat-looking because...



LEO:  Ah-hah.  You're feeling bad now, huh?



STEVE:  Well, I'm feeling torn.  I'm feeling pressure because I'm so happy with Firefox.



LEO:  But you're a heavy tab user.



STEVE:  Oh, boy, I am.  And that's the problem is I've got 48 open right now.



LEO:  Oh, my god.



STEVE:  And side tabs were taken away, as we talked about before, because they decided, well, it was just experimental.  And people screamed so much they said, don't worry, we understand there were people who organized their lives with tabs.  As I do.  It's just my - it's my things to come back to later list.  But I still like the way Chrome manages memory.  When you close a tab, like I watch my memory, and it's like, bang, memory is returned to me because Chrome runs every single page in its own separate process as part of their inter-page security isolation, which is different, entirely different than what Mozilla does with Firefox.  There's just one Firefox.exe. But when you've got Chrome running, there's about seven Chrome EXEs with additional ones for more pages because of the way they've set up their architecture.  And then those, of course, communicate in a safe way.



So, yeah, I mean, Google, I love it that there's a strong commercial drive behind Google's wanting to keep making Chrome better and better, and that Google's doing it.  Microsoft just seems to have stalled in innovation land.  And so, like, they're not using...



LEO:  Oh, yeah, IE's not - I don't know where IE's going, yeah.



STEVE:  Yeah.  I got a tweet from an old friend of ours, Alex Neihaus.



LEO:  Oh.



STEVE:  Remember Alex?



LEO:  Yeah.



STEVE:  He was - was it Astaro?



LEO:  Yeah, he was at Astaro.



STEVE:  Yeah, in the early days.



LEO:  He was the guy, he was our first - got our first ads on the whole network, which was Astaro for Security Now!.



STEVE:  Yeah.  He tweeted, and I just wanted to share this to remind listeners.  He said:  "@SGgrc, web.tweetdeck.com now turns on both SSL and SPDY indicators in Chrome on my Mac.  It's beautiful and fast."  So that means that Twitter has it at their end, and TweetDeck has it at its end.  And I just want to remind people, I'm a TweetDeck diehard because I'm so - I just have it open on a monitor, watching with, like, six columns open, keeping an eye on things and often replying to people who tweet.



I do need to remind people that I only am willing to do a DM.  I can't, I don't want to clutter up my feed with lots of @ mentions.  So if somebody wants a reply from me, you've got to follow me.  And then if it's a tweet that I have time for and can and want to reply to, I'll do that with a direct message.  But I can't direct-message people who aren't following me.  And that's a good thing for keeping Twitter spam down.  But often I'll see something, I'll go, oh, and I'm excited to respond.  I do a direct message, and it says "Recipient not following."  It's like, okay, well.  So I can't reply when I otherwise would have.  Or, I mean, when I did, and it just got blocked.  So for anyone who wonders why they never heard back, that could be why.



And I just have, before we get into our content, another interesting SpinRite tip, different from what we've talked about before, from a Sam Fineberg in Palo Alto who wrote on April 26th, so just last month.  He said, "Two of the computers in our household, my son and wife's, were running really slow.  My son's computer was even overheating and shutting off occasionally, primarily when he played Minecraft.  The computers weren't that old, so I was contemplating reimaging them.  In preparation for that, I ran a fresh backup on my son's computer and decided to run SpinRite on the drive.



"As I was running SpinRite, I noticed the drive got very hot, and there were millions of seek and ECC-correctable errors.  Running on a similar computer that wasn't slow, there were very few seek errors, and the drive stayed much cooler.  So I did an image copy of his drive to a new one, installed it, and the new drive is working great, faster, and no overheating issues.  After seeing that, I ran SpinRite on my wife's computer.  It also had millions of seek errors.  Once again, I replaced the drive, and it solved that computer's problems, too.  So in this case, SpinRite wasn't needed to fix a problem, but it led me straight to the right solution."



And what was happening there is, this is, again, one of the things I mentioned last week.  I talked about how subtle problems with cabling could be inducing errors which SpinRite shows you when you're running it in that cabling errors count.  Similarly, unlike any other software on the planet, there's nothing else that I've ever seen that shows you the error corrections that are actually being done on the fly, which are hidden from you, and also problems that the drive has finding the sectors.  The reason there were all these overheating problems is that the heads were servoing a lot, and that's where you use up a lot of energy.



So, again, SpinRite, on its statistics page, it's actually on the SMART, the self-monitoring and advanced reporting technology page, where it's dynamically looking inside the drive and bringing this real-time data out.  And what Sam did was exactly right.  He looked at a similar machine with, like, the same make and model drive, and saw what it was doing.  And that gave him a baseline to compare the other drives, which were clearly misbehaving.  And so essentially they were at some point going to fail, and SpinRite was saying, look at what's going on here.  This is important.  And so he was able to swap them out for replacements that just don't have that problem.  So another aspect of SpinRite, really the preventative maintenance and monitoring side, which can really come in handy.



LEO:  Really neat.  Let's see, here.  I think we want to get to the matter at hand.



STEVE:  Yeah.



LEO:  And then I'll interrupt you in a few minutes.



STEVE:  Okay.



LEO:  Because I don't want to do another ad right away.



STEVE:  Perfect.  So DMARC is a somewhat awkward acronym.  I don't know how the military gets these amazingly cool acronyms, Leo.  But somehow they always just have these, like, okay, how did you get that?



LEO:  It's a retronym, where they start with the name, and then they make up what the letters do maybe, I don't know.



STEVE:  Yeah.  And this sort of feels that way, too, like demarcation, demarc, dmarc.  But this is kind of awkward:  Domain-based Message Authentication, Reporting, and Conformance.  It's like, eh, okay.



So, okay.  So here's what's going on.  There have been, for actually a decade, if you can believe it, a couple specifications that were supposed to solve the problem of spoofed email.  We've talked many times, in many different contexts, about email spoofing, that it's a big problem because the headers in email can be set by the sender, so it takes a real expert to examine the headers.  And few users are.  And in fact, if a piece of email bounces around a lot, each bounce appends headers onto the beginning.  So the order of the headers is in the reverse order of the path the email took.  And it ends up being complex.  And, boy, headers these days are just so full of gobbledygook, it makes your eyes cross to look at it.  It's not like our grandparents' headers.



So the effort has been to come up with a way of preventing spoofing.  So one approach was the so-called Sender Policy Framework, SPF, which is 10 years old, which surprised me, just didn't feel like it had been around that long.  But it's a clever solution for, again, leveraging DNS.  One of the things we're seeing is other new applications for the domain name system, where new record types, or repurposing of existing record types, which is what we do here because adding new record types to DNS requires multiyear standards, and old servers won't support the new types, and so that's going to be a huge drag for something not DNS-related.



But reusing existing record types, for example, the text record, which is what these systems use, that's easy.  You don't have to change anything because all DNS servers have long understood what a text record is.  It's just sort of a freeform text record.  You can have as many of them as you want.  And you could say, "Give me the text records for Google.com," and it sends them to you.  So this is another reason why layering security on DNS is a good thing because this domain name system is increasingly going to become the master lookup index, domain-based lookup of information for the 'Net.  Traditionally, all you could look up was IP addresses based on a domain name, or the reverse of that, domain names from an IP address.  But as the 'Net matures, we're seeing new applications for this same - the same system.



In fact, GRC uses it to distribute the version numbers of our software.  You're able to say application.dns or .version.grc.com, and the IP address that it returns is the latest major and minor version number of our software.  So I do that because it generally passes through firewalls.  It's super lightweight, just a UDP packet out and a UDP packet back.  And it's a nice little way of getting some information from GRC.



So there are increasing number of things that use DNS.  And so securing that translates into all kinds of benefits as we come up with additional uses for it.  So what SPF, the decade-old Sender Policy Framework does, is it's a way for the owner of the domain - and that's the other kind of key concept here is the notion of who controls the information.  The reason we can rely on DNS, for example, to get the correct IPs for Google, is that Google controls the Google.com domain.  And all of the enforcements are in place for that to happen.  I control my own DNS server, or servers, that then supply the data records to Level 3, that provides me with my connectivity.  And so people actually ask the Level 3 servers for GRC information, which they get behind the scenes from me.  But the point is that I can have that information say anything I want.



So when SPF came out, I immediately adopted it.  I added records because it took, like, five minutes, was easy to do.  The idea is the recipient of a piece of email - and I don't mean the end-user recipient, but the SMTP server that the end-user is using.  So, for example, if you were a Gmail user, then it would be the mail.google.com server.  It's the server that we connect to as clients to collect our mail, whether it's IMAP or POP protocol.  That server, when it's having a conversation, receiving email, the email says I'm from Google.com.



Well, the receiving server is able to, right then, do a DNS query for the text records for Google.com.  And among them will be an SPF record which specifies the range of valid IPs or an enumerated list of IPs.  There are a number of formats.  Or it can even give a domain name for referral, that is, the valid originators of this email.  And the idea being that then this receiving SMTP server can check the IP that this connection is from.  And we know that IPs cannot be spoofed, IP addresses, because they are point-to-point links.  And part of the TCP handshake is a multidirectional packet exchange, specifically for the purpose of verifying that packets can go between the two IPs.



So unlike UDP, that is one-directional with no verification, TCP has verification.  So the receiving server, the server receiving the email, absolutely knows the IP that it's connected to.  And if it receives that IP from that domain's SPF record, its declaration of what machine's IPs are valid senders, then it's able to verify that email on the spot because it knows it's connected there.  The person who controlled the domain has specified this IP is valid.  And so it cannot be spoofed from someone else.



Normally, without this kind of verification, there's nothing to prevent some random server anywhere else on the planet connecting up to Google.com and sending email absolutely as if - or, I'm sorry, connecting up to your SMTP server and sending email that looks exactly like the email coming from Google and declaring that it's from Google.com because most times email servers are not the same IP as, like, the main web domain server.  And there is a provision in DNS for having a mail server declared as mail.google.com.  But oftentimes there's big networks; there's load balancers.  All kinds of things make this more complex.  So this was the very simple concept behind the old Sender Policy Framework technology.



Now, the benefit of it was that it was trivial to implement.  All anybody had to do who wished to authenticate that email they were sending was add a simple text record to your DNS server.  And at the SPF site there was even a little helper where you could specific the parameters that you wanted to use, like if it doesn't match, do you want me to drop the mail?  Do you want me to call it spam?  How seriously to take a failure to match and so forth.  Like is it advisory-only, or is it serious?  There are a number of parameters.  So you were able to set those, press a button, and it would give you, it would build for you a little SPF record that you could just then drop into your DNS server records.



The problem with that is that, traditionally, and that's certainly more the case 10 years ago than now, email was a store-and-forward technology.  And that store-and-forwardness was a source of great abuse.  But that was the original concept of email, the idea being very similar to the way we have packet-switching on the Internet.  We've talked about that often, where you just drop a packet randomly onto the 'Net anywhere with an IP address, and the job of routers is to bounce it from one router to the next, always aiming it towards its destination.  Similarly, email, sort of operating - instead of operating at the link layer there, operating at the application layer, email was the same way.  You might have email bounce a couple times between SMTP servers.  There were servers that would accept email from anyone and then initiate a connection and try to forward it, a so-called "store-and-forward."



And what happened was there were many servers that were open servers, the "open relays" is what they were called.  And this whole notion of store-and-forward was like relaying email from one server to the next.  And in the old days, before spam was a problem, typically servers were all like this.  They would happily relay email on behalf of someone else because once upon a time we were all good guys, and there were no creepy bad people hanging out on the Internet.



So that became abused immediately.  One of the first tricks of the spammers is they would find a so-called "open relay," and they would dump their spam there.  If their own servers had been blacklisted by their IP address so that nobody would accept any email from them anymore, they said, okay, fine.  So they would just search around the Internet for so-called "open relays," and they would dump their email on that machine.  And then it, doing its job, would forward it to its destination, which was typically a spam recipient, who wasn't happy.  And of course you then, "you" the open relay, would end up getting blacklisted because now your IP was generating spam, even though you yourself weren't generating spam.



So over the years this got shut down.  It's very rare now, and it's considered an SMTP email server configuration failure if you have an open relay.  It's like, oh, my god.  I mean, and actually you find out about it pretty quickly because there are bots and things that are roaming around looking for them.  And you'll generally get, if you've got like an admin account on your email server or something, you'll get email saying, "Warning:  You are running an open relay."  And oftentimes you'll be getting spam complaints and all kinds of problems.  So that's been bolted down.



So the original problem with the Sender Policy Framework is, when you think about it, is it was completely incompatible with mail forwarding.  The recipient is verifying the connection IP address of the sender domain.  So that implies it has to be point to point, that is, it has to be from Google as the originator to your server, and for your server to look at the IP addresses that Google is advertising through its SPF record as valid and say, yes, we believe this is Google.  If there were a bounce in between, if there was any forwarding going on to some third-party SMTP server, well, the Sender Policy Framework, with filtering, would reject it because the connection IP would be other than what Google is advertising.



So 10 years ago this was a problem with SPF.  It's not a problem today because nobody's relaying email anymore.  We've got robust networks.  We've got super inexpensive hardware.  We've got load balancing and all these other solutions to the original problem of, like, someone's server being down, so you'd send the mail and park it somewhere until their email server came back up, and then you'd be able to get it over.  I mean, so the relaying is shut down, and suddenly SPF has a real chance to work.



Now, there was a second effort, which Google adopted early, which was called DKIM, which is an acronym stands for Domain Keys Identified Mail.  And it's a somewhat complex specification.  But what it is, is pretty simple.  Listeners to the podcast will understand it immediately.  It is simply using public key crypto to digitally sign all outgoing email.  So anything originating from a DKIM-signing SMTP server is signed using that server's private key.  So, and this is compatible with, like, other signing.  For example, you could be using GPG, PGP, whatever, to sign your own email.  But then that's been wrapped in an envelope with all the headers and delivery information.  Then that is signed, as the final phase, by the server sending the mail out, using the server's private key.  What that means is that the recipient of the email is able to verify.



What they do, once again using DNS, is they look up the apparent sending domain's DKIM public key.  So the public key is published in that domain's DNS record, once again in a text record, in a specified format.  And all these have well-established specifications.  And so the recipient is able to get the matching public key and use that to verify that domain's signing of the envelope of email.  And since the private key is never disclosed, there's no danger.  There's no way for any third party to falsify that signature.  It's full-on, state-of-the-art crypto strength and solid.



So those two different solutions have existed.  But they haven't gained traction, or they've been doing so very quietly and silently.  One of the problems was the so-called "YAP" problem, Yet Another Protocol, where it's like overworked administrators, they hear about this, it's like, oh, boy.  We have other things to worry about right now.  Also there was a problem of very complex infrastructures.  For example, these large ISPs have massive networks, huge blocks of IPs.  They may be adding blocks of IPs for other purposes.  They were worried about false-positive rejections where, if they changed some configuration so that mail, their own legitimate mail would now be routed somewhere else and come out of somewhere else, suddenly that was going to be published.  DNS would need to be refreshed over time.



So there was just sort of this sense of, wait a minute.  We're not sure that it's worth the trouble that it's getting us.  And also note that this system inherently requires that senders and receivers collaborate together, that is, the senders are saying, I'm attesting, in the case of SPF, I'm attesting that all valid email comes from this IP.  But if the receiver doesn't check, doesn't care, then this is, I mean, it's inexpensive to make that assertion in your DNS records, but you're not going to get any benefit from it unless somebody on the other end takes the trouble to check and does the right thing with the results.



Well, very quietly, five years ago, in 2007, PayPal did pioneer this approach.  They worked out a system with Yahoo! and later with Gmail to collaborate this way, and the results were extremely effective.  It led to a very significant decrease in suspected fraudulent email that was purporting to be from PayPal being accepted by those receivers.  So, I mean, the concept is golden.  It absolutely works.



And so five years ago PayPal was having this problem that their email domain was being actively spoofed, and Yahoo! Mail users and Gmail users were having a big problem.  PayPal was having a problem with those users.  Now, they were having a problem, of course, with lots of other users, too.  The reason that Yahoo! Mail and Gmail were singled out is they were aggregation points.  There were a ton of people using Yahoo! and a ton of people using Gmail.  So just by fixing those two recipients, by getting PayPal, I mean, by getting those two to agree to honor PayPal's assertions about sender policy and DKIM-signed email, all of the users of Yahoo! Mail and Gmail got fraud protection for the PayPal domain.  So it worked there because we had one person with a big problem was able to convince two recipients with huge email user bases to go along with them, and it worked.



The other problem that both SPF and DKIM have had is that there hasn't been any built-in feedback.  I've had SPF records at GRC for a decade.  And I don't know if it's done any good.  I don't know if they work.  I don't know if any email has been, like, filtered out or prevented.  I like the idea that, in theory, if somebody checked my SPF records and saw that only email coming from this IP was valid, then GRC.com could not be spoofed, email from me could not be spoofed.  So I thought, okay, that's a good thing.  But I don't know if it ever got used.  I have no idea.



So there's that problem, which, again, there's enough adoption resistance and inertia that, unless there's a clear benefit, it's just not going to happen.  And admins have enough emergency stuff to worry about.  They're not looking for more work to do.  They're just trying to stay ahead of what's going on right now.



So what is little known is that, because SPF and, to a lesser degree, DKIM are so easy to adopt - SPF just requires adding a couple records to DNS.  DKIM requires upgrading your SMTP server to digitally sign outgoing email.  And again, 10 years ago, as we know, public key crypto wasn't free.  So there was some expense in terms of computation overhead to sending out a piece of email that was digitally - that was signed with a public key.  Today that's just, you know, we've got so much computing power, how many cores does your chip have, that that's just not a problem.



So adoption has been growing.  And at this point a little bit more than 50 percent of all domains are actually supporting either SPF or DKIM.  So again, not near a hundred, but more than half.  And in terms of mail volume, 85 percent of email has either SPF records associated with its actual domain originator, or they're digitally signed.  And in fact just this morning I got some Facebook notification that someone who I know knows somebody else, I don't know what it is, but anyway - because I keep trying to turn this stuff off.



LEO:  Yeah, good luck.  They keep turning it on, yeah.



STEVE:  They do.  It's so annoying.  Anyway, so it's got, like, DKIM-signature, and then a whole bunch of gobbledygook in the header, which I now know is, for example, it says "a=rsa-sha256."  So that says it's RSA public key crypto with the SHA256, the Secure Hash Algorithm, 256-bit signed.  And then the valid domain, "d=facebookmail.com," and then a whole bunch of stuff.  So, I mean, it goes on and on and on.  There's, like, a block of gobbledygook.  But that's all the signing of this.  Oh, and I got a kick out of this.  It also says "x-facebook: from zuckmail."  It's like, yes, well, we know where they...



LEO:  Yeah, zuckmail, I like that.



STEVE:  Zuckmail.  So, okay.  So I sort of narrowed this down to four problems.  Many senders, as I've mentioned, have a complex email environment with many systems sending email, often including third-party service providers.  Some large domains sub out their email handling to somebody else.  So it's coming from their domain, but it's being routed through somebody else.  So ensuring that every message can be authenticated using SPF or DKIM is a complex task, particularly given that these environments are in a perpetual state of flux.  It's like, oh, let's switch over to this third-party company.  It's like, oh, well, wait a minute, our authentication is going to break if we do that.  I mean, so it's like, oh, is it worth risking that?



Also, if a domain owner sends a mix of messages, some of which can be authenticated and others that can't, then email receivers are forced to, that is, the receivers of the email are forced to discern between the legitimate messages that don't authenticate and the fraudulent messages that also don't authenticate.  By nature, spam algorithms are error-prone and need to constantly evolve to respond to the changing tactics of spammers.  The result is that some fraudulent messages will inevitably make their way to the end-user's inbox.  In other words, it's the typical soft filter, or heuristic filter.  Good messages are going to get rejected, and some bad messages aren't going to get rejected because we don't have absolute authentication today.  But it looks like we're headed for that quickly, or soon.



Senders get very - and this is key.  Senders get very poor feedback on their email authentication deployments, which is to say none.  Unless messages bounce back to the sender, there's no way to determine how many legitimate messages are being sent that cannot be authenticated - so how would I know if somebody was rejecting my email?  There's just no way to know - or even the scope of the fraudulent emails that are spoofed in the sender's domain.  So, for example, again, if people are sending random email as if from GRC.com, how would I ever know that?  There's no way to know.  So this makes troubleshooting mail authentication issues very difficult, particularly in mail environments which are increasingly complex.



And finally, even if a sender has buttoned down their mail authentication infrastructure, and all of their legitimate messages can be authenticated, email receivers are wary about rejecting unauthenticated messages because they can't be sure there is not some stream of legitimate messages that are going unsigned.  And so, again, the recipient is like, well, okay, some of these are coming in signed, but these look pretty good over here that are not signed.  Maybe they're coming from a new server that Facebook set up, and they don't have authentication in place yet.  So all of this just created enough uncertainty that it's just kept people from moving forward.



But the big guys - Google with Gmail, Facebook, LinkedIn, PayPal, Bank of America, American Greetings, Cloudmark, Comcast, Fidelity Investments, Microsoft with Hotmail, Return Path, and Yahoo! - are all on this now.  They're all part of this DMARC effort.  And they have determined this stuff is mature enough, the specs are there, they work, the technology has been moved into servers.  Remember that SPF really didn't require any on the sending end, but it certainly does require it on the receiving end.  The SMTP server receiving has to have new technology for going and getting the apparent sender's SPF records and checking the IPs and checking the connection.  So that's taken some time for those features to be added to standard email servers.  And the same is the case with DKIM on both ends.  The sending server has to digitally sign outgoing email, and the receiving server has to be able to verify the digital signature from the apparent recipient, I mean, from the apparent sender.



So we're to the point now where the software technology is in place.  It's now time to solve these lingering problems.  So for senders, adding this kind of robust authentication requires work, and the return on investment has been uncertain.  And for the receivers, just having some authentication doesn't help much.  I mean, what we need is to be able to say, okay, we believe that the domain in question is asserting that it's got control of its outgoing  mail, and we're absolutely going to take action on failure.  So the solution is that senders absolutely authenticate all outbound mail and assert that to receivers.



LEO:  Right.



STEVE:  So a bunch of smart guys - oh, yes.



LEO:  Let's pause.



STEVE:  Perfect.  Perfect place.



LEO:  As we explain how this solution might be implemented. How about that.  It's always, you know, it often comes down to authentication, but the devil's in the details.  How do we authenticate?  We were talking with Bill Harris, who is a former CEO of PayPal and runs a company called Personal Capital, and we were talking about micropayments and online payments and getting rid of money.  And it's really an authentication problem.  How do I know you're you, and how do you know I'm me?  Once we've authenticated - that's the problem with credit card fraud is weak authentication methods.



STEVE:  Well, and it's why I went nuts over Stina's YubiKey.



LEO:  Right.



STEVE:  It's just like, hey, here's something to replace passwords, which is such cooler authentication.



LEO:  So authentication's the solution.  But how do we achieve it?



STEVE:  Probably the biggest thing that DMARC brings is closing the loop, providing a means for allowing senders who wish to authenticate a means of verifying what's happening out in the world before they commit all the way.  So the DMARC spec, it solidifies and unifies the existing SPF and DKIM specifications and also provides some configuration guidelines because the specs were broad and gave a lot of latitude.  So DMARC is saying, look, we didn't know what we were going to need initially.  Turns out this is what people use, and this is enough.  So here's how we want you to configure SPF and DKIM.



So the beauty is all we're talking about is some additional technology added to our email systems, but basically built on these existing established standards.  There's a new DNS resource record.  And again, rather than inventing their own, which would again require all DNS servers everywhere to be updated, they're just going to add a new resource record of the TXT, a text resource record, which is just anything you want to have it say.  The text record specifies the sender's policies.  And they have this weird word, they use it, they call it "alignment" for some reason.  Alignment types is either strict or relaxed, so how strict you want the matching to be.



Then they have a disposition for the incoming - for any incoming problems, whether the sender wants the receiver to quarantine records that don't match, to reject them outright, or just to monitor.  And finally, this text record contains - and this is where the loop gets closed - the URIs, or URLs, for sending reports, both of failure and aggregate daily summaries.  And the DMARC spec then defines this aggregate reporting format where it's a daily sum in an XML, so machine-readable, machine-parsable format, which is deliberately redacted for the sake of privacy.  That is, they want to just accumulate statistics, not specifics about individual email.



And so the daily aggregate reports are per apparent "from sender" domain, but they do not contain delivery disposition and do not contain individual email addresses.  But the idea is that they, by sending domain, they feed back the authentication results for the DKIM signature verification and the SPF IP verification, along with the successes or failures of the matching, and specify the policy action which was requested and taken.  So what this means is that a company that was deciding, as all these big companies I just listed are - and we know that SPF and/or DKIM is now deployed in about 85 percent of the volume of emails on the Internet and about 50 percent of the domains on the Internet.



So the next step is to take the server technology a bit further with this DMARC spec, which, by the way, has been submitted.  It was finalized just this January, a few months ago.  It has been submitted to the IETF, the Internet Engineering Task Force, for ratification and publication as an Internet RFC.  So it's going to be a formal specification moving forward for email on the Internet.



And so the idea would be that a company that wanted to lock down their email would upgrade their email servers to support the DMARC spec and add the DMARC text record to their DNS, which is simple to do.  And, for example, initially they would say, well, monitor.  Don't reject, don't quarantine, don't block, don't do anything, but we want reports  So they would put their whole system in monitor mode.  And then all of the recipients who also supported DMARC at the other end - remember, this is inherently, for this to work, it's got to be sender and recipient.  Both have to be on the same page.  They both need to be supporting this.



And it's a fail soft solution, that is, if either one doesn't, you just don't get authentication.  But it's looking like email is a significant enough backbone of the Internet, and companies, especially as we're doing finance more and more with banking and PayPal and email and also social networking, and where link spoofing and phishing is a problem, if we can fix email, this is a huge step forward for Internet security.



So the problem with deployment gets fixed by creating an ongoing feedback system where initially the system's in monitor mode.  And again, on an individual by individual sender basis.  So if I were to deploy it, I'd upgrade my email server.  And in fact the next server that I choose, this will be a requirement for me is that it be able to support this protocol because this is clearly where we need to go.  Then I would say monitor.  And any email outbound from us that goes to a domain that also supports DMARC, they would be querying our DNS records, see that we support DMARC, determine what our policies are.



And, for example, initially I'd be saying just monitor and report.  And so I would get back to the domain and URI that I specify, I would receive a daily report from every one of the domains that we touched that day of what they thought about our proposed authentication.  And so for a huge environment like Facebook, where massive network, global, servers all over the place, they want, in order for them to confidently say "reject," before they get to that point they want to be able to monitor.  They want to see that everything's working.  And then, even when they are in reject mode,  where they're saying to people that we were monitoring for a while, we verified that everything's working, there is no mail coming out of us which is not authenticated, there's no way for mail to get out of us without authentication being added, now we want everybody to just drop any email that is being spoofed with our domain that doesn't authenticate.  But we still want reports.



And so suddenly we get something that we've never had before, which is an ongoing reporting of fraudulent email going to third-party servers which support DMARC.  The third-party server would get inbound email spoofed from Facebook, for example, check with Facebook's DNS - remember that DNS is caching also.  So in fact they may well - major domains like Google and Facebook and so forth, these servers would have those text records in their local caches, so no traffic overhead is being required at all.



So they would say, wait a minute, this isn't digitally signed.  Facebook has said reject it if it's not.  And they would aggregate the information.  They would log the connecting IP of the spamming, fraudulent, spoofing server and send that to Facebook.  So now Facebook begins getting daily records of the IPs that are originating spam spoofing them that they've never had before.



So this robustly authenticates email.  It safely allows the system to be deployed.  And again, because it's DNS, if there was ever a problem, the admins could switch back to monitoring mode instantly, essentially, or over the expiration time of the DNS records which are being used.  And so it's flexible.  It's under sender control.  And closing the loop, generating reports, is really valuable real-time information.



So potentially, once we get there and bring up authentication to a level that we have never had before, the people behind this are hoping that this will enable new forms of communication over email because it won't be something where you're looking at anything that comes in with a great deal of skepticism.  And you can imagine also that at some point servers could be, like, adding a tag, or email clients could say whether the email is authenticated or not.  And if it said it was, you could trust it because it would have been securely verified.  So that's where we are with this.  And I'm excited about it.



LEO:  Cool, yeah.  Very interesting.  Now, how widely adopted is this?  I mean, do we have to consider that?  Or is that not an issue?



STEVE:  Well, end-users really don't have to do anything except sit back and wait a while.  It is...



LEO:  But ultimately we're all users; right?



STEVE:  Yes.  Yes.  Well, the spec is in place.  It's been finalized.  And you can imagine, I mean, among these big players, anytime you see some weird word like "alignment types," it's like, what committee group chose that?  So it's like, okay.  So it's a significant accomplishment that all of these players, who are competitors with each other also, got together on the technical level and said, this is what we're all going to agree to.  We can't all, I mean, we already have DKIM and SPF, which are, like, competing standards.  Well, they said, instead of choosing either one or trying to amalgamate them, they said, look, everybody likes their own thing.  Let's just support them both because some of them are in place, and SPF is easy to do.  So we don't need to choose.  What we just need to do is we need some way of believing the authentication.



LEO:  And that's not just out of trust.  You actually need a technology to do this.



STEVE:  Yeah.  Exactly.  Yeah.  You need the technology, and you need to be able to say we're actually going to throw this away if it doesn't authenticate.  And before...



LEO:  And that's the key.  And that's the problem with SPF and everything else and all these other authentications is, yeah, if you were willing to throw away - it has to be 100 percent or very, very widely adopted.  But if my mom adopts it, I can use it.  Otherwise I won't get her email; right?



STEVE:  No, no, no.  It's your mom's ISP.



LEO:  ISP, okay.



STEVE:  Yes.  So it's SMTP server to SMTP server.



LEO:  Got it, of course.



STEVE:  And so it's point to point.



LEO:  So if all the big ISPs adopt it, then we're good.



STEVE:  Yeah.  And it's going to happen, Leo.  I mean, this is - if 85 percent of the valid email traffic on the 'Net now contains this, but no one is using it, we're just, it's like, okay, everybody is saying we're ready to go.  But it's time to commit now.  And I think we're just at that point.  I mean, this is a big change.  To be able to lock down email and require authentication, what's going to happen is the big guys are going to do it, and then that will put serious pressure on the rest of the industry because it'll be like, wait a minute, you're not sending authenticated email.  I'd rather use somebody who is because it'll become a value-add.



LEO:  Or you could have a folder that says "Unauthenticated."  It's like a spam folder, but maybe a step down from that.



STEVE:  Yes, yes.  It could be, well, yes.  You could have  a spam folder or, that is, an unauthenticated folder.  And the beauty of that is it's going to actually mean something.  The spam folder gets false positives, and then your normal inbox gets false negatives.



LEO:  Right.



STEVE:  And so the beauty of this is your normal inbox would never receive an unauthenticated email.  And so, again, having a sender who knew their email was going into people's unauthenticated folder is going to move heaven and earth to add authentication to their servers so that their email doesn't look second-class.  It's a little bit like the extended validation certificates.  GRC is now all EV.  And every time I fire up GRC in a browser, and it comes up with EV, I'm like, oh, yeah, cool, I have that now.



LEO:  I hope this works.  We'll see.



STEVE:  Yeah.  Well, I mean...



LEO:  It's the best shot yet.



STEVE:  And this just shows how much inertia there is.  I mean, the system isn't so badly broken that no one uses it.  It's just so badly broken that no one trusts it.



LEO:  Right.



STEVE:  And so many problems are caused by this.  I mean, so many - spoofing is causing so much problem.  So the idea of having, like, authenticated inbox, that's a big move forward.



LEO:  Huge, yeah.



STEVE:  Yeah.  And that can happen incrementally.  I mean, not everyone has to support it.  If I knew that authenticated email was being flagged by my server and routed into a different inbox, versus unauthenticated, that's valuable to me.  And we can have that today.



LEO:  Yeah.  Steve Gibson's at GRC.com.  That's where you can post a question for next week because we'll do a Q&A, and I'm sure we'll get some questions about DMARC.  We'll do a Q&A episode next week.  It's GRC.com/feedback for your questions; GRC.com/health if you want to read his health postings.



STEVE:  Oh, and there is a feedback page there, too.  And I would love to have people who - either positive or negative experiences with low-carb stuff, please send me your feedback.



LEO:  Very good.  And of course you go there to get SpinRite, the world's best hard drive...



STEVE:  Yay.



LEO:  ...maintenance and recovery utility, and all the 16Kb versions of this show and transcriptions of this show.  All 353 episodes, they're there.  His show notes.  We also make audio and video available on our website, TWiT.tv.  This show, we do this every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC on TWiT.tv.  Watch live.  We'd love it if you watch live.  But if you can't, don't worry.  That's where there's always a recording available in audio or video, depending on your choice.  And next week a Q&A.



STEVE:  Yup.



LEO:  Look forward to it.  Thanks, Steve.



STEVE:  Talk to you again, my friend.



LEO:  Take care.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#354

DATE:		May 23, 2012

TITLE:		Listener Feedback #144

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-354.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  He's going to take a look at Twitter's new Do Not Track policy and answer 10 questions from you, his listeners, all next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 354, recorded May 23rd, 2012:  Your questions, Steve's answers, #144.



It's time for Security Now!.  Here he is, the ketogenic Steve Gibson, our Explainer in Chief and security guru from GRC.com, the author of SpinRite, the world's best hard drive and maintenance utility, and many other great freebies.  And today's a Q&A; right, Steve?



STEVE GIBSON:  Yeah, we have our 144th, so that's 12 squared for those of you who are math people, our Q&A on Episode 354.  And a bunch of interesting news, great questions from our listeners, a little bit of errata, paraphernalia stuff.  So overall, I think we're going to have a really nice podcast.



LEO:  You know, it's people - maybe I just don't usually get the email.  But more and more I'm getting tweets and email from people saying, oh, I've got something for Steve, I've got something for Steve.  They really - and I see you have some of this, the LastPass Wallet and so forth.  People really are kind of, I think, really starting to know about the show, which we like.



STEVE:  Yes.  I don't know, maybe it's my participation in Twitter.



LEO:  I think so.



STEVE:  But I get a ton, I get a ton of stuff from people who are tweeting.  And I am noticing that I think my message about please follow me if you want a response - because, I mean, I read every single tweet that I get.  It's sitting here, like right in front of me, right now, this huge spread, in TweetDeck, of all these columns coming in.  So...



LEO:  You're crazy.



STEVE:  It is, yeah, it's a little much.  But...



LEO:  I think that might have something to do with it.  I really do.  I think the more you engage the social networks, the more they engage back.



STEVE:  Yeah, and I have to say, somebody did tweet to me, "Steve, you're really missing out not being in Google+."  And I'm kind of there, but I don't know what it is.  I mean, I kind of looked at it, and I didn't know what it was.  So...



LEO:  It's more of a long-form Twitter.  If you wanted to do longer posts and engage in conversations about that post, because it has threaded responses, then it's similar, same idea.  I like it.



STEVE:  I love the fact that I'm limited, and so are they, because it's like, well, we can't have a conversation, but here's a link.



LEO:  In that case, you may not like Google+ all that much.  All right, Steve.  I've got your notes.  I'm ready to kick things off, starting with Twitter, of all things.



STEVE:  Yep.  There was a nice explanation, which I want to share with our listeners actually sort of the meaty beginning of it, posted by someone from the Electronic Frontier Foundation, the EFF, that is our privacy watch guard nonprofit group that is doing so much good stuff, explaining exactly Twitter's recent announcement that they are going to support the Do Not Track header which is increasingly available in browsers.  Microsoft's IE has it in sort of a flavor.  It's not yet supported natively in Chrome, but there's an add-on that you can get for Chrome that will add the DNT header to Chrome queries.  And it is and has been supported in Firefox for some time.  So the EFF guy wrote, and there's some really interesting tech stuff here:



"Under a new policy announced recently, Twitter will be suggesting accounts for Twitter users to follow based on data collected from an individual's browsing habits on websites that have embedded Twitter buttons."  Okay.  Let's stop for a second.  What that means is, this is exactly the third-party cookie issue that we've talked about often.  That is to say, when you're a Twitter user, your browser will have a Twitter cookie associated with it.  Then when you go to non-Twitter sites that have the embedded Twitter button in the page, when your browser displays that page from that website and displays the Twitter button, it is sending a query back to the Twitter servers containing the Twitter cookie - which in this context, since you're actually on a different site, that's technically a third-party cookie.  But what that means is that Twitter is able to track you, your movements, around the 'Net.  This is...



LEO:  Oh, we're going to hear howls.



STEVE:  Yeah, I know.



LEO:  That is huge.



STEVE:  It is.  But what it then means is that, when you go back to Twitter, it knows where else you have been and is then able to recommend people for you to follow that are relevant to what they're determining about you.



LEO:  Now, that's only if you use the Twitter in the browser.



STEVE:  Yes, I think that, yes, it would...



LEO:  Because if you were using a Twitter app, especially one that Twitter didn't write, like you - well, you use TweetDeck, which is a Twitter company.  But I presume there's no way they would be able to track you.  Maybe they would.  I don't know.



STEVE:  They could certainly, I mean, there are cookies associated with your account.  And it might be that, like, the Twitter apps which are not browser clients are also transacting the same cookie.



LEO:  It might be part of the API, who knows.



STEVE:  Because you're logged in, and they know who you are.  And so they could certainly give that identity.  So EFF, continuing, says:  "While this is sure to garner scrutiny" - exactly as you said, Leo.



LEO:  Howls, yeah.



STEVE:  Uh-huh, "...from the press and public, Twitter is also taking a pioneering step toward respecting users' privacy choices.  It has committed to respecting Do Not Track, a simple browser setting users can turn on to tell websites they don't want to be tracked.  Often framed as a signal from users to behavioral advertisers, Do Not Track isn't actually about ads we see online.  It's about user control over tracking of our web usage that could be used to build an intimate portrait of our online lives.



"Twitter is showing an inventive way that websites other than behavioral advertisers can respect Do Not Track.  We're heartened" - this is the EFF, that isn't often heartened by anything.  "We're heartened to see this forward-thinking approach and hope other sites" - well, and of course we know what this is.  This is also Twitter recognizing the controversial nature of this and being preemptive about offering some choice to users who are concerned about this from a tracking and privacy standpoint.  "We're heartened to see this forward-thinking approach and hope other sites with embedded widgets will follow suit."  Because think about it.  All of these sites that have little embedded buttons that we're now seeing everywhere, they're all doing this, too, but perhaps being much less forthcoming than at this point Twitter is.



"If you haven't done so already, this is a great reminder to turn on Do Not Track.  Twitter has a tutorial for doing this on different browsers.  Here's how the suggested accounts will work under the new Twitter privacy policy:  When you browse around the Internet to pages with embedded Twitter share buttons, Twitter is able to collect a certain amount of information about you through a unique browser cookie."  And remember, it's not just that you were there; but, because it will contain the full referrer header, it's also how you got there.  So they know, for example, if you were searching for something and clicked on a search link, typically what the search query was.  I mean, there's a lot of information that these third parties get.  And so Twitter is setting themselves up by having these embedded Twitter buttons to collect all of this when people go anywhere to third-party sites.



"Twitter is able to collect a certain amount of information about you through a unique browser cookie.  When you sign up for or log onto Twitter, the site will be able to suggest that you follow the accounts of individuals who are popular among others who visited the same sites as you."  So now we're getting sort of the social networking thing.  It's, gee, people who also have the same sort of site-visiting profile are following these people.  Twitter can, of course, see who you're following.  So they're able to pull that information, not only from you, but from others, and cross-correlate it and say, hey, here's some people that are maybe relevant to you.



LEO:  Now, are these paid advertise- I mean, my question is, if it's just doing a better job of suggesting, okay.  But are they paid advertisements, would be my question.



STEVE:  No, it's just improving its suggestion technology.



LEO:  Well, I don't see anything - I'm not sure if I see anything wrong with that.  I mean...



STEVE:  No, I agree.



LEO:  You can ignore the suggestions.  And if it really does give you suggestions that are good, based on things you're interested in, like it just suggested Yoko Ono and Michelle Obama to me, and Jimmy Kimmel, and Nathan Fillion.  I mean, yeah, I would like to be following those people.  So I don't know if - is this implemented now?  Or is it going to be implemented?



STEVE:  No, it's in place now.



LEO:  Okay.



STEVE:  So Twitter calls this "tailoring," in quotes, your Twitter experience based on your web browsing history.



LEO:  Seems good.



STEVE:  I know.  I think it is.  "For example, many of those who visit BoingBoing.net likely follow the account of @doctorow, the digital-rights-loving BoingBoing founder Cory Doctorow.  If you sign up for Twitter, and you've got a browser cookie from Twitter showing that you recently" - and this is a key, too, we're about to talk about expiration - "that you recently visited BoingBoing, you might see @doctorow listed as a suggested user even before you've started interacting with Twitter."  So that is to say, it can know things even before you get going.



"Twitter will be relying on data collected from your browsing habits within the last 10 days.  After 10 days, they start discarding data.  When you start a Twitter account, you'll have the option to turn off the tailored suggestions.  Unchecking this box won't just stop the suggestions from appearing, it'll actually remove the unique cookie that Twitter uses to track your browsing habits and show you tailored user suggestions."



LEO:  That's good.



STEVE:  And that's, oh, they've really done it right.  And that's right in the UI.  It's a checkbox.  You can say I want this or not.  "Established Twitter users may find suggested users under the 'Who To Follow' sections of Home and Discover.  Just like new users, established users can uncheck the 'tailor' Twitter box in their account settings to stop the data collection about their web browsing.  Do Not Track makes this a lot simpler, no messing with account settings or unchecking any boxes to keep your privacy.  If you've already got Do Not Track selected in your browser settings, then Twitter assumes you just don't want them collecting details of your online browsing habits in an identifiable way.  Users who have turned on Do Not Track will find, upon signing up for Twitter, that the 'tailor Twitter' button is automatically unchecked by default."



LEO:  Wow, wow.



STEVE:  I mean, I know they've really done a nice job.  "Similarly, established users who had Do Not Track already enabled in the days before the new policy took effect will also find the account personalization turned off by default.  Users who enable Do Not Track must change their privacy settings manually if they want the 'tailored' Twitter experience to be reenabled."



Now, there is a textbook example of doing everything right.  I mean, just across the board.  And this is why, as our listeners know, I have been so bullish about this from the beginning, about the Do Not Track header.  Everyone argues, yeah, but it doesn't really do anything.  It doesn't block anything.  It just says.  It's like, yes, but this is the way we're going to get there.  Because maybe it'll get enacted through legislation, or maybe it'll get enacted through this kind of social pressure.  But, I mean, Twitter doing it right sets a template for how to do it.  And Twitter's not small.



So they're offering a real benefit, as you identified, Leo.  It's like, wow, this does provide Twitter with valuable insight.  Yet it gives the users absolute control.  And if we have taken the time to turn on Do Not Track, it respects that.  And if we want then to have the benefit of Twitter knowing more about us so that it can make better suggestions, and we're wanting to mature our follow lists, then we go and turn that on.  It's just - it's beautiful.  So I hope this is an example of the future because this is the way it should be done.  And it's all we need, if everybody does this.



LEO:  Can you think of any negative, I mean, of leaving it on?  I mean, there's I guess the presumptive privacy invasion.  But are there maybe hidden consequences we're not aware of?



STEVE:  Well, okay.  So the skeptics will say, oh, well, how do we know Twitter's not selling this information?  It's like, well, you've got their privacy policy.  They don't want to get sued.  Privacy is an increasingly large concern.  I mean, thanks to Facebook that keeps stumbling with privacy, everyone is learning people really are caring about this.  So I don't think a company is going to say one thing and do another.  That would just hurt them too much.  And then these things do get discovered.  Employees leaving or mistakes being made, it's like, wait a minute, you said you weren't collecting this.  Now some hacker just got a database of 500,000 records that has this.  So what gives?  Very much the way Google got caught flatfooted with collecting all of the unsecured WiFi information.  They really didn't intend to use it for anything, but they had it.



So my feeling is Do Not Track may become too powerful.  I mean, what I'm looking for now is the equivalent of NoScript for Do Not Track, where I can say - I can, like, have my default be not to track me; but some sites, like Twitter, I may want to track me.  So in the same way that I want some sites to run scripts on my browser, but I don't want them all by default to run it.  So I imagine we're going to see that evolve in time.  As people support Do Not Track, we're going to want to say, well, I can't keep turning it on and off all the time.  I need to selectively permit tracking.  But again, this is where we're headed.  This is the future.  So bravo to Twitter.  If we've got any Twitter people listening, they just really did it right.



Meanwhile, a trojan that we never covered, and I'm not sure why we didn't, I just probably had too many things to talk about that week, is the so-called DNSChanger trojan.  And it would have been a perfect topic for us, so we'll briefly cover it now.  It's something which has affected hundreds of thousands, if not maybe a million computers.  And it's rather clever.  And we have all the understanding, thanks to the podcast's history, to get a grip on what this thing does.  It's a piece of malware which can infect people's machines.  And its action is to change their system's default DNS servers to malicious DNS servers.  And our listeners know what that means.  That means all the lookups you do are subject to bad guys messing with the IPs that your browser receives in return.



So, I mean, we have talked about, like, DNS server hijacking, where the bad guys pollute the records of a given DNS server.  And that's bad because then everyone using that DNS server who looks up a specific domain gets pointed at the wrong IP for all kinds of mischief.  Well, this is, like, way worse.  This is your entire computer, and in some cases DNSChanger is able to go in using, unfortunately, default logins, and sometimes Universal Plug & Play that we've warned everyone to turn off, are able to get into your router and change your router's DNS, that then affects all the machines in your network.  So even though only one machine gets infected, your entire network is now receiving malicious DNS replies from these bad servers.



So this allowed people to do ad hijacking and get up to all kinds of mischief with people.  The bad guys were found back in November of 2011, so about, what, six or seven months ago, and they were located in Estonia.  They were arrested.  And the people who do BIND, the major DNS server on the Internet, ISC, were given control of this set of rogue DNS servers.



So here's the problem.  All of these machines, more than half a million, right now, today, more than 500,000 are still querying these malicious DNS servers.  The problem is that the judge that was involved with this originally set a March timeframe for the DNS servers to be taken down.  They're still up and running, although now they're under benign control, so they're not delivering malicious results.  But more than half a million people's networks and computers are using them.  So if they're shut off, everybody who's still using them loses all their Internet connectivity and has no idea why.



LEO:  You know, when I read about this, I meant to ask you about it.  It seemed like it was a terrible idea in the first place to replace them.  It was - so people were still hacked; right?  But instead of pointing to a malicious DNS server, it was an FBI-run DNS server.



STEVE:  Well, actually, as I understand it, they were the DNS servers that were just - they were the DNS servers taken over.  So they were once malicious, but they were reloaded with good records.  And so in order to de-pollute them...



LEO:  Well, I don't know if it was the same machine or not.  It's the same IP address.



STEVE:  Okay.  Well, yeah, exactly.



LEO:  Doesn't really matter.  But wouldn't it have been better just to turn them off and say, in other words, people have been hacked.  And you're kind of hiding the fact that they've been hacked.  And it bothered me that the FBI decided that this was the way to handle it.



STEVE:  I agree.  It's sort of a strange, like, I mean, this is unique, as far as I know, in terms of, like, the way we've dealt with and mitigated this problem.



LEO:  I thought it was appallingly stupid.  But...



STEVE:  So what Google has figured out is that their page, their servers are able, with very high accuracy and negligible false positives, to detect when anyone visiting their site currently has the malware installed and/or is pointing at the wrong DNS servers.  And they are going to, in fact, I think maybe they have now, begun notifying everyone who has got this problem who visits Google.



LEO:  That's at least - at least they'll be notified.  I mean, they've been sitting there for four months with - and the thing is, if you have DNSChanger, you probably have other malware on your system.  And what would have been better is just to turn it off, and suddenly the system stops working, and the person goes, oh, my, something's wrong, and gets it fixed.  Instead, they've been going along for four months with, I would be willing to guess, in 90 percent of the cases, malware-infested systems that seem to work all right.  Makes me mad.



STEVE:  Right.  And what happened was this March deadline was extended to July 9th, which is - so this is, where are we, we're May, June, July.  So it's coming up in another six weeks.  So it's been extended because too many people were still using them.  Now, ISPs were supposed to take responsibility.  But ISPs didn't, for whatever reason.  Clearly, ISPs could have put up intercept pages or noticed when their customers were making DNS queries to these specific IPs and sent them something in the mail.  I mean, there are many things that could have happened.  But it just didn't happen.



And so Google has said, okay, it's multilingual because only 50 percent of the affected users are English speakers.  The other 50, located all over the globe, are non-English speakers.  So Google has had to do this in a multilanguage solution.  Also, Google has said in their blog posting they would like to be doing helpful things like this all they can, except that they're not often enough, and not as often as they would like, able to be accurate enough in their determination of problems.  We've seen Google, for example, now warning people on links that are believed to be malicious.  It's like, wait, this looks like this site is hosting malicious content.  Are you sure you want to go there?  So you click it, you get an intercept page saying, oh, ooh, thanks for catching that.  In this case, they have developed a technology that will have a sufficiently, like, near-zero false positive.  And they've been testing it long enough to know that they'll be able to deliver more than half a million of these notices within one week.



LEO:  Wow.  Wouldn't it have been better if the FBI had just put up - changed the server in such a way that it redirected you to a single page that said, you have malware on your system.



STEVE:  That's exactly what I think.  I don't know why any query didn't bounce you to an FBI site specifically to present you with that notice.



LEO:  In effect, the FBI has perpetrated a man-in-the-middle attack on hundreds of thousands of machines for the last six months.  It drives me crazy.  I don't - it doesn't make any sense.  And by the way, if you go to the DNSChanger Working Group, which is an FBI front, they actually...



STEVE:  [Laughing]



LEO:  I'm a little pissed off.  They give you really loose, useless information and have buttons that say "Fix It."  It's just stupid.  First thing you ought to do is - they give you how to clean your PC against DNSChanger.  And I just - I feel like - now, actually this has gotten better than it was when they first announced this about a month ago.  It just seems suspicious to me that they didn't do that, that they decided to keep it running for a while.  We'll do your DNS for you, just, eh...



STEVE:  Trust us.



LEO:  As you were.



STEVE:  Speaking of "trust us," RSA's - I'm really tempted to put the syllable "in" in front of "SecurID," making it inSecureID.  Windows software tokens are deep in the doghouse.  Now, we've talked about the hardware tokens extensively, the little dongles.  We were pioneering the PayPal football and eBay logon, the famous football for providing third-party security.  I, of course, love what YubiKey has done with their little one-time USB token.  So RSA couldn't resist doing this in software.



Well, it turns out that we have another classic example of good crypto implemented poorly.  Not the crypto's fault.  The architectures are absolutely solid as could be.  But it turns out that their Windows - they have a Windows version of their SecurID token so that people who don't want the dongle can install this software.  Now, already we know, whoops, bad idea.  The whole point of the dongle is, well, one is portability, so you have cross-machine portability.  But the other is that it's not connected to anything.  I mean, it's not in your system.  The YubiKey is safe because it just emulates a keyboard.  It will not receive any commands to allow it to dump its information.  Even using the YubiKey UI technology you can't get that information. It will not give it up.  So those guys did it right.



RSA said, oh, well, let's sell people a software token.  Think of all the money we'll make.  Well, it turns out that a security researcher discovered that the serial number, the required token's secret serial number is simply determined by a combination of the machine's host name and the current user's Windows security identifier, which is stored in the computer.  So, busted, completely.  It means that, if any software is able to get into your machine, and you have one of these, it can instantly clone your SecurID and, at will, generate exactly the same sequence of supposedly cryptographically secure, but cryptographically generated now, but no longer secure, six-digit numbers that the SecurID software does.  So it's completely reverse-engineered, and we hoped it would be a secret serial number, turns out not to be.  It's derivable from information sitting right there in the machine.  So, whoops.  And there's only 40 million people using this.



LEO:  Oh, geez.  So this is - is this in Windows?  Is this - who's using this?



STEVE:  This is in Windows.



LEO:  How would you know if you're using it?



STEVE:  Oh, you would be a user who periodically calls this up.  And it comes up in a little - it's got its own little Windows UI with a little screen that shows you your current SecurID six-digit token.



LEO:  Ah, okay.  So it's like that Google - the Google Authenticator or the football that VeriSign provides.



STEVE:  Right.



LEO:  Same idea.



STEVE:  Same exact, I mean, it's the same algorithm, same everything.



LEO:  Just poorly implemented.



STEVE:  Well, written in software.  And, for example, they didn't use the Trusted Platform Module.  The TPM that's in most laptops is sitting there for this purpose.  But someone said, oh, well, most people don't have that turned on.



LEO:  Right, or don't have it.



STEVE:  Or most people aren't using it, or don't have it.  So we won't use it.  But what they could have done is arbitrarily created a non-derived pseudorandom number through some handshake.  I mean, again, it's difficult to see how you can protect this.  This is fundamentally a bad idea.



LEO:  Well, that's what makes me wonder, I mean, Google Authenticator software on my mobile device.  So I wonder if it has the same flaw.



STEVE:  Well, and I've got a VeriSign VIP token on my BlackBerry which is able to generate numbers for me to log in in Windows.  But those are separate platforms.  So, I mean, it's certainly the case that doing this in software on a shared software environment will not be as secure as any little piece of hardware that is just all it's going to do is give you numbers.  So, but the tradeoff is convenience.  But again, putting it in Windows and then using...



LEO:  For logging into Windows.  Right, right.



STEVE:  Or your corporate VPN.  I mean, you just - so the point is, this is a huge vulnerability for anyone who depends upon it for security.  It simply never was secure.  And now that the world knows how to hack it, and all the details have been posted, it's just blown.  It's just completely blown.  If your machine ever got infected, your Windows machine, the malware could grab that data trivially, send it off to wherever, and they now have the ability to generate the same secret token, the same token stream as you do.  And there went the security and the authentication, everything it purports to provide.  Dumb.  I mean, it's just a bad idea to offer that on a Windows platform.



LEO:  Yeah.



STEVE:  Now, in happy news, LastPass has released a free secure Wallet for iOS devices.



LEO:  I saw that.



STEVE:  Yeah, and it looks very nice.  It's built around the existing LastPass feature called Secure Notes which LastPass has always had.  LastPass for our browsers can store more than just userID and login.  You can have it store notes for you also.  In the case of Wallet, which is 100 percent free forever, it comes with a series of templates for credit cards, passports, driver's license, memberships, bank accounts, and a bunch of more things.  Current LastPass users, as so many of our listeners are, can login with their usual account information.  So this is sort of like a - it's a client for your existing LastPass account and entire database.  And any existing Secure Notes will automatically be synched to the Wallet, where they could be viewed, edited, and synched back through the cloud to all other locations.



LEO:  What does it mean when a baby toy goes off?



STEVE:  That's my phone.  I forgot to silence it.



LEO:  Your telephone is a squeak toy?



STEVE:  Yeah, it's a squeaky toy.



LEO:  Okay.



STEVE:  That's generic, unfiltered incoming email.  It just  makes me laugh.  And anyone who I'm, like, at lunch with or something will laugh.



LEO:  It is funny.  I'm laughing.



STEVE:  Yeah.  So audio clips, photos, and texts can be saved as an attachment to any note.  You can use the app itself to record voice clips and securely store pictures from your device's photo gallery.  And in a blog, in the announcement blog, our old friend Joe Siegrist, who gave me all the information back in the day when I was able to fully vet LastPass and adopt it for myself and recommend it without hesitation, he responded to somebody who was grumbling about why they didn't do it for Android first.



And he responded saying, "The reason Apple was first here is that Apple does not allow us to do a free trial.  So it appeared that the best way around that problem was simply to give away something free" - instead of, like, a trial period - "to give away something free that gives people a taste of what the full LastPass does on their Apple device.  When you tell your friends at a party that they should be using LastPass, Wallet is a good place to get started if you're an iOS user.  We really had nothing for that case before, for the Apple platform."



So that was Joe, the  main technologist guy there, explaining why.  And which makes a lot of sense to me.  I just a minute ago grabbed it.  I haven't begun to play with it yet.  But I've got it now added to my various iOS devices.  And I trust these guys.  I know they know how to do it right and the importance of getting it right.  And so I wanted to let everyone know that this looks like just a pure and simple win, especially if you're already a LastPass user, to have an iPhone interface or an iPad interface.



And in the Anonymous Mailbag, I found something coincidental that I thought I would share.  From a Richard S. in Burbank, the subject of what he sent me was "Elaine's transcripts extremely useful."  And he said, "Dear Steve, just an anecdote demonstrating how useful it is to have the transcripts that you have asked Elaine to produce.  I was sitting at a research retreat with a very computer-savvy MD who was typing his secure password into our institutional VPN.  I asked him whether he knew about LastPass.  He said no.  I explained it to him and showed him my one-click login to our VPN.  He was impressed and asked if it was secure, and I said yes, absolutely.  The computer-savvy MD sitting next to him said that LastPass had been breached.  I said no, but MD No. 1 starting Googling the issue and getting alarming hits.  So I Googled "LastPass breach Steve Gibson GRC," and immediately hit the transcript for Episode 301, which I forwarded to him.  He read it and downloaded LastPass.  An invaluable resource."



LEO:  Awesome.  Well, I'm so grateful that you pay for that, and that Elaine does it.  It's really, it is, it's a huge - if we had the money, we'd do it for every one of our shows.  It's a huge value.  Thank you.



STEVE:  Well, and not only is it, as we've just said, well, the primary motivation was that people like to read along, or just sometimes read and not listen.  So this gives them an option.  But the other obvious thing that's happening is it makes our otherwise audio podcasts or video podcasts searchable.  You can find them.  And so you could, yes, you could then download the transcript, or it finds the audio and/or video for you also.  So very cool.



LEO:  Excellent point.



STEVE:  An anonymous listener also said, "Steve, don't switch to Mac just for ARQ."  This is my Notes from the Cloud section.  I saw that, and that piqued my interest.  That was the subject line in the Mailbag, so I dug in.  Because it's funny, I tweeted that ARQ for the Mac was so good as a really nice frontend for Amazon's S3 that it  made me want to switch.



And so he said, "It was great to watch you zero in on the right architecture for cloud backup:  A, fault-tolerant pay-as-per-usage storage backend like S3; B, a trustworthy frontend with strong crypto implementation like ARQ.  But there is still hope for PC users, and Linux and Macs, too.  Check out www.duplicati.com.  Everything you talked about ARQ, and cross-platform, open-source, non-Java, native code, plus plug-ins to many multiple backends.  Would love to hear your analysis on any crypto and other weaknesses possible in Duplicati code and architecture."



LEO:  I love it that it's open source.



STEVE:  I do, too.  And so under Features they list:  "Duplicati uses AES-256 encryption or GNU Privacy Guard to secure all data before it is uploaded."  So it's pre-egress encryption, pre-Internet encryption.  "Duplicati uploads a full backup initially, then stores smaller, incremental updates afterwards to save bandwidth and storage space."  And on their pages they go into some detail about how this is done.



"A scheduler keeps backups up-to-date automatically.  Encrypted backup files are transferred to targets like FTP servers, Cloud Files, WebDAV, SSH through SFTP, Amazon S3, and others.  Duplicati allows backups of folders, document types, e.g., documents or images, or custom filter rules.  It's available as an application with an easy-to-use user interface and as a command-line tool."  Oh, 100 percent free, by the way, if I didn't mention that already.



LEO:  Well, you'll pay for the storage.



STEVE:  Yes, but not for the frontend.  "Duplicati can make proper backups of opened or locked files using the Volume Snapshot Service (VSS) under Windows or the Logical Volume Manager (LVM) under Linux.



LEO:  Interesting.



STEVE:  And then it gets better.  From their How-To:  "Duplicati is built using standard tools and formats.  Un-encrypted archives are simple .zip archives.  Encrypted archives are .zip archives that can be decrypted with AES Crypt.  So even without Duplicati," they said, "all your data belong to you."  And it supports 1&1 SmartDrive, Amazon S3, BACKUP.ACtion, Box.net, CloudSafe, DriveOnWeb, Google Drive, SkyDrive, Strato HiDrive, Tahoe-LAFS, whatever that is, and T-Online Mediencenter.



So I'm very impressed.  Their future plans, they're at v1.blah blah blah.  Their 2.0 will add running as a service so that the whole thing can run when you're not logged in, doesn't need to run as a user-launched app, and they're also going to reengineer the UI.  So everything about this thing looks right.  And so I wanted to let all of our listeners know that, thanks to an anonymous mailbox person, we now have knowledge of yet one more interesting multi-backend frontend.



LEO:  There's just an infinite number of these, it seems, as time goes by.



STEVE:  Yeah, well, it's just - yeah.  And here again, this is - this fits my model.  My feeling is this is not something that people should charge for, that is, the privilege of having a frontend to Amazon S3.  It ought to be free.  There's just not enough value added to make it something that you should pay for.



And I wanted to mention, in a GRC R&D update, I hit a milestone yesterday with my main project that I've been working on and have referred to a little bit through the year.  I started late last year and just fell down, I don't know what kind of hole it was.  And actually it turned into an amazing R&D adventure.  And as I had mentioned, I have solved a fundamental problem in computer science, which has never been solved before.  As far as I know, I mean, it is an invention.  It is completely unique.  It is dramatically more efficient than any other approach for solving this problem.



And I will be - I'm not going to patent it or claim any IP.  I'm going to get it documented, and we'll do a podcast on it.  And this is my solution for finding in really, really large corpuses, which is to say big blobs of text, the longest strings that repeat, anywhere in them, in these corpuses, without knowing what they are.  And there are well-established solutions, but they are only toy solutions.  You can only do them on small little data sets because they just completely collapse and break.  They do not scale.  And I've come up with a brand new solution that no one ever seems to have seen before - I haven't, and none of the other smart guys who have been following this have - for, like, really solving this problem.



Then I was trying to figure out how I could explain this because there's a lot to it.  And what I realized was I needed - I couldn't do it in one podcast.  I needed to establish some additional foundation that we've never had before, which is sort of back to our basics.  Our long-time listeners will remember that we did a series of how computers work, sort of from first principles up.  Starting at the beginning, we went through the entire evolution of the way computers function.  And I stopped at the instruction set as, like, okay, now we're there, like different types of instruction set.  We talked about CISC and RISC and so forth.



But the next layer above that, which is below solutions but above instructions, are data structures, that is, pointers, arrays, records, stacks, trees, and lists.  That is, these are the things that computer scientists have come up with which are implemented sort of universally on any computer, using any instruction set, to sort of create the first layer of abstraction above the instructions.  Yet they are universally applicable to all kinds of problems.  So, like, anyone who's gone through computer science has learned about pointers, arrays, records, stacks, trees, and lists.  These are - and you know all those words, Leo.  These are fundamental ways, like fundamental tools which you use for solving, for them solving problems using those.



And so we will first do a series of podcasts, not a long one, maybe two podcasts, I think, ought to be enough to cover those because I have used those, and I realize I can't bring all of that information along, and what my LRS (Longest Repeating String) technology does, at once.  So we've got a bunch of fun podcasts here in our near future.



LEO:  I see that it's a problem people want to solve.  But why?  What would you do with the longest repeating string, substring?



STEVE:  Well, I got...



LEO:  Why would you search for that?



STEVE:  I got into this because I've got completely disorganized SpinRite testimonials.  And when I share them with our listeners every week, I'll sometimes - I'll move them, like, into a big list I've been collecting.  But there's a bunch of them already on the website.  There's a ton that are still in email.  There's a bunch I've never found that are in the Security Now! mailbag.  And my concern is I want to pull them all together and then eliminate duplication.  I don't want to have any that in there twice.  And so, but sometimes, for example, before I read them, I'll fix some grammar, or I'll change the spelling of SpinRite if it was W-r-i-t-e, for example.  So I'm not going to get exact matching.  I needed soft matching of, like, phrases.



LEO:  And if you did shortest repeating string, you'd get a lot of periods, spaces, A, B, C, Ds, and Es.  So you want longest because that's the biggest match.



STEVE:  Correct, exactly, the longest matches.  But then  other people who have had insight said, wait a minute, Steve.  You can use this for DNA matching.



LEO:  Oh, for lots of things, yeah.



STEVE:  And, it turns out, for instantly decrypting texts in unknown dead languages.  If you dump a text into this, it'll instantly find all the words and all the phrases using repeating series of words.  I mean, it just organizes disorganized stuff instantly.  Well, not instantly.  But, like, in a practical speed.  And nothing like this exists as far as...



LEO:  Even in grep and things like that?  They don't do that, huh?



STEVE:  No, because you have to know what you're looking for.  Here you don't have to know.  It finds the patterns for you.



LEO:  I cannot wait.



STEVE:  It's very cool.  So speaking of SpinRite testimonials, I had a really fun story from a Christian Alexandrov in Sofia City, Bulgaria.  And he said, "Hi, Steve.  I want to share a SpinRite story with Security Now! listeners.  My cousin was traveling on her way home in her car when she hit a pothole" - apparently this was big pothole, maybe they have big potholes in Bulgaria - "and broke the suspension on her right front wheel.  The car lost control and spun off the road.  The good news first:  No human casualties.  Bad news second:  Her laptop took a pretty good hit.  The plastic body was full of cracks.  She came to me and said, 'I gave the laptop on a few PC repair services, but all said it is already dead.  I'm desperate.  See if you can bring it back from the dead.'"



He says, "I was looking at this broken laptop and gave up any hope on it.  Anyway, I tried to boot on battery.  No boot.  The battery was broken badly.  I disposed of it.  I tried to boot on its charger.  I got luck, but not much.  It gave me blank black screen and, a few minutes later, failed attempt to find OS.  So I used SpinRite on Level 2, but no luck.  I was about to tell her this corpse is dead beyond resurrection.



"Then it hit me like lightning.  I ran SpinRite on Level 1 to get the drive to know itself again and force it to take action on itself using the tip you had recently mentioned and suggested on Security Now!.  After Level 1 completed, I tried to boot, and at least now I was not waiting for a few minutes to try to boot.  It started to boot normally, and I saw the BSOD saying 'Unmountable boot volume.'



"I got upset, and I decided to go full force.  I ran SpinRite at Level 4.  It took 96 hours straight to finish the drive, reporting a lot of green 'R' icons and few red 'U' icons.  So many sectors recovered, and a few at least partially recovered.  I ran SpinRite again on Level 4, and now it only took a few hours to finish the entire drive.  I saw a lot of 'B' icons" - meaning that SpinRite had marked those sectors bad and relocated the data - "on all places where the 'R' and 'U' icons were before.  I grabbed the chance and quickly backed up the entire movies folder.  This was the only folder my cousin desperately needed saved.  So I saved this folder to my PC.  When I checked its contents, I was stunned when I saw what was in there:  the complete first three seasons of 'Farscape' on high-quality."



LEO:  Thank goodness we didn't lose it.



STEVE:  No, we didn't lose those grasshoppers or whatever they were on "Farscape."  They were strange creatures.  "Needless to say, I kept a copy for me to enjoy a fine sci-fi series.  I disposed of the hard drive of this laptop, bought and installed a new one, reinstalled Windows, and copied back the movie folder.  My cousin was as happy as she could be.  Thanks to you, Steve, I have the chance to enjoy a fine sci-fi series.  If we get to meet face to face, I promise I will buy you a bottle of red wine on my expense, the finest Cabernet I can find on Bulgarian market, regardless of the price.  Thank you, Steve, for this great piece of software, and thank you Steve and Leo for the great Security Now! podcast.  I wish best of luck to you, GRC.com, and TWiT.tv from a happy SpinRite user."



LEO:  Well, I just hope he turned the BitTorrent client back on when he restarted the machine, that's all.



STEVE:  So thanks for sharing that, Christian.



LEO:  That's pretty funny.  To the Q&A we go.  Starting with our first question from Michael Dombrowski.  He is a smart kid, a high school sophomore in Washington, D.C.  And we were talking about ARM versus x86.  And then he wants to know about Windows 7 and 8.  First of all, love the show and watch every week, as well as the past two weeks of the "Sugar Hill" series.  I wish I could get my high school student to watch that.  He loves his French fries.  And I hate - every time I see it, it, like, pains me.  I see him eating them, that pains me.



He says:  I've been thinking this through in my head for a while and wanted you to tell me if I'm right or wrong.  Or crazy.  I was thinking that because the Intel x86 architecture and ARM both have the same fundamentals - AND, OR, and NOR gates - would it not be possible to map all of the x86 functions into the reduced set that ARM offers?  In other words, get to CISC from RISC?  I remember you saying in the fundamentals of computing that x86 just kept building in calls for things like multiplication, for example, and that ARM had a limited number of these.  But because they both must run on the same kind of logic gates, then could someone not implement in hardware or software an X86-to-ARM translator?



From what I know, which is limited as far as hardware is concerned, this would be possible.  It may take a lot of work, but for someone like Microsoft, maybe no big deal.  Sorry for the length of this email.  I wanted you to understand my question and make it as clear as possible.  Thank you for all that you do.  I feel I'm getting a comp sci class even before I go to college.  Michael.



STEVE:  So that's very clever and has absolutely been done historically.  There are two things, two approaches that could be taken.  For example, you could literally perform a static translation, where you take a program written in one instruction set like x86 and, instruction by instruction,  convert each CISC (Complex Instruction Set) instruction into the equivalent series of RISC instructions, and essentially do a static translation from one instruction set language into another.  So that can be done.



But what has ended up being done is a variation on that, and that is an emulator.  And emulations exist all over the place because it's ended up being a powerful thing to do.  In fact, historically, you'll remember, Leo, back in the days of early Pascal with p-code, the Pascal compiler generated a pseudo-code, which is what the "p" stood for, p-s-e-u-d-o, pseudo-code, for an imaginary computer that didn't even exist.  And then somebody who wanted to run Pascal on a given host platform, on a given computer, they would write an interpreter in the native machine language of that processor, which interpreted the pseudo instructions that the Pascal compiler produced.



And the beauty was that you had a huge library of Pascal programs.  And in fact the actual environment for editing and compiling Pascal was written in itself, in Pascal.  So when you simply wrote this layer, this interpret to interpret p-code, as it was called, suddenly everything works.  You get all the programs, all the software, and a little operating system that's ready to go and does go.



So it's certainly the case, for example, that Windows could have been left in x86 architecture, but Microsoft could have implemented an x86 emulator which would run on the ARM architecture and emulate the x86 instructions one by one.  The problem with doing that is performance because you're not directly executing the native instructions.  There is that layer, that emulation or interpretation layer, and there's a big performance hit.  I mean, it varies depending upon how closely the architectures map into each other.  If the ARM, for example, had enough registers to simulate the x86 registers, then that would help.  But if the architecture didn't, then you'd have to simulate registers in memory.  So suddenly, you can see, that would be a lot slower than emulating registers that were in the actual hardware architecture.



So to the degree that there's mismatch between what the architectures do, that creates more friction, sort of, between them.  And since Windows is almost 100 percent, if not now 100 percent, written in high-level language - C, C++, or other abstractions of C and C++ - it's very easy, comparatively, just to recompile the existing high-level language implementation of Windows.  Rather than using an x86 compiler, you use the now very mature ARM compilers.  And you end up with Windows running directly, natively, on the ARM architecture.



So, Mike, yes, it absolutely can be done, has been done.  There's a history of it.  Java, that we talk about often, is a so-called "virtual machine," the Java Virtual Machine, the JVM.  The Java compiler produces, again, this so-called "bytecode," or a specific sort of virtual language.  And then you have different virtual machines, JVMs, one for the x86 on Windows, one for the x86 on Mac, one of the old PowerPC on Mac, and so forth.  And then when you implement that JVM, the virtual machine, all Java-ness runs on top of it.  So it makes porting and portability very nice at a cost of performance that you can't get around.  But sometimes that's a tradeoff that really does make sense.



LEO:  So you could cross-compile, which would be kind of a one-time-only translation.



STEVE:  You really could.



LEO:  Or what you're doing, which is kind of an on-the-fly, as-you-go, real-time translation.  The interpretation is a little slower, but it's a little more flexible, obviously.



STEVE:  Well, and I guess the way, yeah, the way to think about this is, if you were to cross-compile, then you're taking the...



LEO:  That's like a one-time translation.



STEVE:  Right.  But the way to think of it in terms of the result is you're taking Windows, that was written in C, that was compiled through a compiler to x86, and then compiling it again into a compiler that compiles x86 into ARM.



LEO:  Right.



STEVE:  So if you did not have access, for example, to the original Windows source code, then that would be really your only alternative.  But since Microsoft does have access to Windows source code, and there is a C compiler for the ARM, they don't have to go through, like, a two-stage inefficient compiling process.  They just go one stage.  They just recompile Windows in C directly to the ARM architecture.



LEO:  And then you have, as in all code, you have some tweaked stuff that's written in assembler, and you would just translate that by hand or...



STEVE:  Right.  In Windows it's the HAL, the so-called Hardware Abstraction Layer, is the layer which is intimately familiar with what Windows - with the platform that it runs on.  It knows about the way PCs deal with PCI and USB and timers and interrupts and all that.  That's like the real nitty-gritty interaction with the hardware.  And so you'd have to rewrite the HAL in ARM assembler.  But that's a small portion of what has become the behemoth that we know as Windows.



LEO:  And you'd probably do that by hand because it's a small amount of code.



STEVE:  You'd have good guys who do it, yeah.  You'd put your best talent there because everything runs through there and depends on it.



LEO:  Right, right.  Chris Waters, somewhere in the U.S., wonders:  How secure are aging Linksys wireless routers?  Greetings.  I don't believe you've addressed the following on your fine podcast.  If so, I apologize.  I have a Linksys WRT54G - a classic, ladies and gentlemen - v8.0.  It has the latest firmware, but it's from October 2009.  It's at least five years old or more.



Is there anything inherently insecure with continuing to use it?  The router seems to work well, locks up every few weeks, necessitating a reboot, cycling the power.  I preemptively reboot it every week.  Googling this problem indicates it's quite common.  Any ideas as to what is causing it and how to prevent it?  I've considered installing alternate firmware, DD-WRT - I think this is the classic router for DD-WRT - or Tomato.  I'm unsure how secure these alternatives are.  What do you think?



STEVE:  So my sense is that our wireless router technology is enough of a moving target that it really does make sense to stay current.  We've been talking about and will be talking about buffer bloat in the past and in the future.  Here you've got firmware that's, as you said, Leo, four or five years old.  And we're finding little edge case problems with, for example, the wireless easy config technology, which it would be nice to have Cisco update for their Linksys firmware.



But this is probably an abandoned piece of hardware, whereas it by no means has been abandoned by the DD-WRT people or the Tomato folks.  And Tomato is a beautiful, thriving, living community and state-of-the-art piece of software.  And when solutions to the buffer bloat problem occur, they will be implemented immediately in these third-party firmwares for those routers.  So I'd vote for making the jump.  I'd look into which one makes the most sense for you.  I don't really have an opinion between those, not being...



LEO:  I like Tomato.



STEVE:  And that's what I thought.  I thought you did, and that's what I was going to say.  And it's, I mean, that's everything good about Tomato.  And it will be kept current.  And if things evolve in the future which require change or updates - like the buffer bloat problem and the solution that we now have in test, essentially, and we'll be doing a podcast on that shortly - it'll be available in Tomato very quickly.  So I'd say make the move, Chris.



LEO:  And that's a classic router.  That's actually the router, if my memory serves, that they recommend for both DD-WRT and Tomato.  It's actually valuable because it's so easily hacked.  And it does have one advantage, Steve, that newer routers may not have - no WPS.  It doesn't have any of those kind of fancy built-in things.



STEVE:  Nice.



LEO:  And you're right, that might be an advantage.  Now, at some point I do want to talk about the new 802.11ac with you.  And if you want to do a show on that I would welcome it.  The new standard is out.  Buffalo and Netgear have both shipped "ac" routers.  I actually have the Buffalo router.  And it has some real advantages.  It's much faster.  It's very interesting.  Unfortunately, the Buffalo router also has WPS on it.



STEVE:  Hmm.



LEO:  [Frustrated buzzer sounds]  But at some point, if you'd like to talk about it, I'd love to hear it.



STEVE:  Cool.



LEO:  David, and I'm not sure how - it looks like his name is mangled a little bit here with the Unicode.  David Garcia-Abad in Basque Country of Spain wonders about encryption for the ultra-paranoid:  Steve, I've been a listener for about two years.  And although I will not go into detail about how fun it is for me to listen to - oh, please, David, go right ahead - I have to admit two things:  Leo and you have made my commute time much more enjoyable; and, if Leo ever decided to charge money for the podcast, I would pay for it.  Hmm.  I'm that hooked.  I just wanted to know your opinion about a very simple idea.



Say you have some very confidential data, and that you want to make as sure as possible that no one will ever be able to crack it, not even the Utah-based super-cracking mega-facility.  Oh, he does listen.  How would you proceed?  Being ultra-paranoid, this is the approach I would take, nothing fancy:  First, encrypt the plaintext with AES-256 using key one.  Then encrypt the resulting ciphertext with a 448-bit Blowfish, using key two.  Then encrypt the resulting ciphertext with a 256-bit Serpent cipher, using key three, and et cetera, et cetera, et cetera.  You get the idea.  Is that the end of it?  I can't tell.  Let me track this down.



It's kind of a Matryoshka doll approach to encryption, using different algorithms and different keys.  If one of the keys gets compromised or cracked, well, we still have the others.  If one of the algorithms is found to be weak over time, well, we still have the others.  I know this is not the most original or convenient thing in the world.  I just want to know your opinion about this possibility.  Thank you for the show.



STEVE:  So, okay.  This sort of is interesting because, from a strict crypto standpoint, it raises the question.  And one of the options in TrueCrypt, the whole drive and file encryption technology that we like so much, it's got options for serializing the encryption algorithms using more than just one, just for this purpose, for the concern that, not so much keys leaking, but that's certainly a valid point, too, but that at some point in the future there might be some vulnerability found in any of, like, in the one crypto algorithm you were using, the one cipher.  And that would then weaken your position.  But if you used two or three or four, then no one weakness would cause a problem.



So part of David's question is does daisy-chaining ciphers in series using completely different and unrelated keys, because that's certainly what you would have to do, too, does that scale your security?  And the answer is yes, absolutely, 100 percent, 200 percent, 300 percent, whatever.  I mean, it is absolutely the case that you end up with the multiplicative effect, really, not even additive, multiplicative, of one cipher, followed by another, followed by another, each using unrelated-to-each-other keys.  You essentially just keep summing up the key length, and you end up with a ridiculously long key, and you have a cipher strength equal to the total bit length of all these unrelated keys, implemented with taking chunks of that in different, completely unrelated ciphers, driven by that portion of the mega key, and then feeding it into the next.  So you've ended up with something insanely powerful, but at a performance cost.



And it's why, for example, when I set up TrueCrypt, I simply use AES-256.  TrueCrypt now uses Intel's instruction set support, so it's even faster than it was before.  And that instruction set support only works for AES-256, so that gets accelerated.  The other things don't.  And I've looked at and torn apart and we did a podcast on AES-256.  And, I mean, everything to me looks like it was nailed.  So while, yes, you can always scale your crypto beyond reason, to no end, I mean, without limit.  I guess I ask, why?  Once you have enough, then more is just more cumbersome and slower.  It's not clear that, if it's unbreakable, it can be more unbreakable.  If you've got infinity, then you can't do...



LEO:  Can't do plus.



STEVE:  ...infinity plus one.  Plus one, yes.



LEO:  Sam Cornn in Machesney Park poses two practical questions about the DMARC email security we talked about yesterday.  One, what, if anything, will Google Apps customers need to do to enable DMARC?  And, two, what would need to be done for PHP mail scripts?



STEVE:  Okay.  So we didn't talk about that, which is why I liked Sam's question.  Customers would need to do nothing because this is inherently a server-to-server technology, where servers which are accepting email from other servers will authenticate that sending server's identity in order to believe the email that they're receiving.  So customers at each end, that is to say clients, the clients of those servers, just - their clients don't need to change because they've established independently their authentication with their own home server.  You log into Gmail using your strong credentials to say I am me, or you log into your corporate email server with your email client, saying I am me.  Very often, if it's a corporate email server, it's inside the company's firewall.  And so no one else has access to it as a client except people there inside the firewall.  It's not like if you're using a POP protocol on port 110, that's not available from the outside.  So no non-local clients can even access it from a client standpoint.  And then that server connects to the destination email server in order to authenticate the transaction and send the mail.



Now, as for PHP mail scripts, mail scripts could operate two ways.  They could operate as a client, or they could operate as an SMTP server, receiving connections on port 25, which is SMTP's default port, or sending, connecting to other servers on port 25, in which case that PHP mail script is being a store-and-forward architecture.  It's not being a POP client where it's connecting to another hosting SMTP server as a client.  In that case, it itself would need to implement the DKIM and SPF architecture protocols that we talked about last week.  So either they exist now, or they will.



For as popular a language as PHP, if there is a need for it, all the crypto backbone is already in place for PHP.  You can get crypto libraries.  And so either a talented PHP programmer could implement those protocols using the libraries, and they're really not that difficult to do, or wait a while, and somebody else will do it, and you'll just be able to import the library and be a DMARC-compatible server, if that's really what you want to do in your own language.  So users get to ride for free.  And if programmers want to tackle it, the docs are solid and available.



LEO:  Cool.  Question 5, Dominic Black in England talking about those older security protocols, SPF and DKIM, does not - he says they don't prevent domain spoofing, but they help:  You said in last week's Security Now! that a folder saying "Authenticated Mail" would be great as you could trust it.  But I counter that, saying you can't anyway.  For instance, with PayPal.com, what is there stopping me from, say, buying paypai.com and then capitalizing the "I"?  It'd look like PayPal.com in most browsers and email clients.  I would set up all the SPF/DKIM settings on my paypai dot account, and my fake email would now appear in your authenticated mail folder.  It would point you at the fake site, which I would design to look exactly like the real one, apart from an EV certificate.  But then again, someone in theory could get an EV for a fake domain.



Because of your authenticated folder, now you are more likely to trust my email than you would have been.  It's authenticated, but authenticated to a spoofed address, I guess.  Further to this, could we simply not use high ASCII characters and Unicode characters, now that the domain name system supports it, and buy domains with characters which look incredibly close?  What can you do to prevent that, huh?



STEVE:  Yeah.  He's right.  I mean, this is not something - this is sort of the human factor side of this problem.  And I don't see a solution for it.  I know, for example, that PayPal has themselves proactively, I mean, just to use Dominic's example, proactively grabbed similar domains to prevent this problem to what degree they can.  But this is just Dominic's example.  It could be any domain where you're able to create something that looks deceptively similar.  And, I mean, and his logic is thorough.  I mean, this is the kind of logic we develop on this podcast over time, is that by creating authentication and then abusing the authentication, we end up making a claim which, if you misunderstand the claim, appears to be stronger than if you hadn't made it in the first place.



So it's a very good point.  It's not a problem that I can see any means of solving.  At some point the user is responsible for looking at what's going on and being careful.  But I did, I felt I had to bring this up.  It was mentioned some weeks ago by a good friend of mine, and Dominic is exactly right.



LEO:  It's merely authenticating the phony domain.



STEVE:  Right.



LEO:  Ghislain in Espeluche, France wonders, if SKIM and SPF, why all the spam?  I think he means DKIM.  On the DMARC podcast you said that 80 percent of the mail volume is currently using either SPF or DKIM.  But everyone agrees that 90 percent of the mail volume is spam.  So doesn't this mean that almost all of the spam is already SPF and DKIM compliant?  Therefore, this kind of authentication doesn't fix anything, and we're really making all this bother for no result at all.  Am I missing something in reading those stats?  Also, I can say that DKIM is a real pain to configure right.  Regards, Ghislain.



STEVE:  So I think I was probably not clear.  It's 80 percent of the valid email volume is currently either SPF or DKIM.  And the problem is that, even so, we're not trusting it yet.  This is the whole point of DMARC.  And Ghislain mentions that it's a real pain to configure right.  He is correct.  That's why I haven't done it yet.  I don't have a DKIM-compliant email server.  My next one will be, as I mentioned.  But I do have SPF configured.  However, I don't know if people are blocking spoofed email from GRC.com because there's no way for me to get reports.  And I don't know when I do configure DKIM, unless it were for DMARC support, I want that feedback that it is, you know, don't block this, but send me reports.



So it's really clear to me that DMARC is a step forward.  But it won't be until we have enough confidence in the system that we are then willing to block email that doesn't meet the requirements.  We know, for example, that PayPal, as I mentioned last week, has relationships with Yahoo! and Gmail where they said we want you to block anything.  We're going to take responsibility for authenticating anything, everything that comes from us, period, for the benefit of ruling out any similar spam.  But the rest of the industry has been, like, well, you know, we're not really sure about this.  It seems like a good thing, but how do we test it?



And DMARC brings testing and then will, I'm sure with time, bring, I mean, it will just - the email world will switch to a mode where everything is blocked, and things will be better.  Not perfect, again, as our prior questioner mentioned, but better.  And we don't want to let better be the enemy of perfect.  So being better is worthwhile, too.



LEO:  Question 7 from Bob Carneim in Oak Ridge, Tennessee, who says:  I'm going to belabor the point.  I've been wanting to bring this up for a while now, so I hope this may come to your attention.  When I heard Charles Hill's question in the last Q&A, I thought, okay, I'll get my answer.  Alas, just as Charles thought you missed the point that Gleb Budman - Gleb Budman.  Is that really his name, Gleb Budman?



STEVE:  I know, it is.



LEO:  Try to say that three times fast.



STEVE:  It's not easy.



LEO:  Just as you, Steve, missed the point that Gleb Budman, the Backblaze CEO was making, I think you're missing the point Charles was making, which is this:  Your Jungle Disk/S3 solution, which I also use, is not integrated, and there is no inherent TNO encryption in the S3 bucket.  So you are counting on the TNO encryption the Jungle Disk client application is assumed to provide.  This assumed TNO is provided by the optional encryption key you type into the Jungle Disk client settings.  But how do you know the client is not transmitting that key to the Jungle Disk HQ or Rackspace or Amazon or the National SA, Spy Administration?



I've been using this solution ever since you described it way back when, but it always bothered me.  I would think that the only way you could be sure your key isn't being transmitted off your box is to have a separate machine inline between your box and the Internet that is watching all the packets for your encryption key to fly by.  But even then, if they encrypt your key, the analyzing box wouldn't be able to recognize it.  So did you or could you disassemble and reverse-engineer the client app and analyze it to positively determine that it is not sending out your key in any form or fashion?  Thank you.  Bob.



STEVE:  So this, Leo, is why you love open source, because it makes the claims potentially provable.



LEO:  Uh-huh.  I agree.



STEVE:  Yeah.



LEO:  Crypto always should be open source.  Otherwise you don't know.



STEVE:  The TrueCrypt application that we love is open source.  People can look at it and have at it.  Now, I would argue that it's a function of tradeoffs.  Now, TrueCrypt was designed by a bunch of nice people who went to a huge amount of work to create a great solution.  And we thank them for it.  Maybe we donate money.  I've supported them several times because I want it to keep going and stay alive and be current.  And so maybe that's the model that allows this to work.



But if I were going to do a crypto solution and invest a substantial length of my time in it, it would be commercial, and it would be closed source.  I'd be happy to document the protocol and the technology and do everything I can to demonstrate the way I have designed it to work.  But it can't be open source if it's also going to be commercial because I want to sell these things.  So does that mean I don't do a really valuable crypto product?  No.  It means...



LEO:  No, but people trust you.



STEVE:  Exactly.  And so Bob is absolutely right.  I did not reverse-engineer Jungle Disk.  But I did speak to Jungle Dave.  I think we had him on the podcast, in fact, years ago.



LEO:  I think we did, yeah [Episode 123].



STEVE:  And I was completely convinced, enough that it's what I trust and use, to use his solution.  Now, we just talked about a different open source, that Duplicati.



LEO:  Right.



STEVE:  Which is open source, a frontend for S3, very cool-looking solution.  I don't know if it's going to move me from Jungle Disk.  I'll take a look at it.  But so we are seeing alternatives.  My feeling is, if it's open source, then you're still trusting that somebody else, presumably other than you, has looked at it and not found anything wrong with it.  But I guarantee you, if somebody wanted to bury something in there that was misbehaving, they could do such that your visual scrutiny of it couldn't locate it.  And also you're ultimately, knowing that it's open source, but you're using a precompiled EXE.



So the only way to really satisfy yourself is really to write it from scratch yourself, which is probably not practical, or really go over it yourself with a fine-tooth comb, and then you compile that source into an EXE which you use.  Anything short of that, then you're trusting people.  I mean, my point is there's always going to be some trust.  And of course we've got the operating system platform that everything runs on.  We assume Microsoft isn't playing games.



LEO:  That's a good point.  Even if you have open source software, the OS might be involved.



STEVE:  Yeah, it's ultimately also there.



LEO:  Or your Internet service provider.  No, I guess it's encrypted by the time it gets there.



STEVE:  Yeah, but the OS, you're calling APIs to do all this work for you, asking it for things like pseudorandom numbers.  Well, what if it generated special Microsoft pseudorandom numbers, and they knew what they were?  So again, at some point we have to trust.  Unless you go out into the beach and get some silicon in a bucket and bring it back to your garage and start smelting it and purifying it.



LEO:  Oh, come on.  We don't have to start all the way back.  Question 8 from Asher Silberman at Cal State Northridge in California, he's got a Layer 8 club:  Hey, Steve.  Long-time listener, first-time writer.  Started listening to Security Now! back when it started.  I was in middle school at the time and listened to it on my walks home.  Wow, Asher.  Because of you, I was explaining RSA encryption to my friends during gym class.  Nerd.  But in a good way.



Now I am a sophomore in college and have started a computer security club at my school.  We're calling it Layer 8.  So far we've entered into competitions and competed in the National Collegiate Cyber Defense Competition - that's cool.  I didn't know that existed.  That is really cool - and the National Cyber League, even without much practice, since the club just started.  So I'm wondering, do you have any tips on resources for learning about security?  Any ideas for activities we might do to teach our members over the coming school year?  Asher, I'm so blown away.  He says:  Thank you, your podcast is a great inspiration.  But Asher, YOU are a great inspiration.  Isn't that a nice email.



STEVE:  Well, and so I have a neat idea, Leo.



LEO:  All right.



STEVE:  And Asher, here's your project.  Something I've been intending to do, but have never gotten around to, is to take a look at all the things we've talked about and all the security technology over the years and come up with a single comprehensive best practices document.



LEO:  Oh, wouldn't that be useful.



STEVE:  And we'll have Asher and his club on the podcast to present it.



LEO:  Great assignment.  Great assignment.  I love it.  Best practices.



STEVE:  Yep, what should people do, how should they behave, what tools make the most sense, easy to use, most comprehensive and so forth.  The whole club will have to pull together and answer those questions, distill it down to what people need to do to be secure and what to use.  And Asher, I'll get an email back to you with a way to contact me.  And we will have you and/or your club, you guys can gather 'round a microphone or appoint a spokesperson, and we'll have you present your results on the podcast.



LEO:  And it would be for end-users.  You don't have to worry about enterprise or servers or that kind of thing.



STEVE:  Right.  Just for moms and...



LEO:  Just end-users running - moms and dads running Windows or Mac, best practices.



STEVE:  Yeah.



LEO:  Love it.



STEVE:  What to do to stay secure on the 'Net.



LEO:  That would be a very nice thing to have.  Very handy.  And I will publicize it on The Tech Guy, and we'll give you some space on the TWiT site, because I think that would be very useful.



STEVE:  Yup.



LEO:  Love it.  Great idea, Steve.  Thank you.  All right, Asher.  Your assignment, should you choose to accept it.



Walter Anthony, in Climax, North Carolina explains how he's cloud-synched tabs in Firefox, just like the cloud-synching of tabs now offered in Chrome v19:  I just wanted to let you know I've been using Firefox for a couple of years now in a manner that synchs my home and work PCs.  All of my bookmarks, history and tabs are synched between the two.  I just run portable Firefox from PortableApps.com in my Dropbox.  Oh, that's clever.



STEVE:  Mm-hmm.



LEO:  That's clever.  As a result - you know, because Dropbox copies that folder with everything in it - my tabs are always in synch, with history available for each tab.  What a great idea.



STEVE:  Yeah.



LEO:  I've also used the synch feature built into Firefox to synch tabs, history, preferences, et cetera, across machines.  This has the added feature of allowing my wife and me to both use individual versions of Firefox on the same Windows 7 computer login account.  Mine is the portable version; hers is the desktop install.  Walt Anthony, U.S. Navy, Retired.  That's a great idea.



STEVE:  Yeah.  I wanted to share that.  I thought that was really great.



LEO:  I love that.



STEVE:  Yeah.



LEO:  And that would work with GDrive and anything that allows you to synch a folder between multiple machines.



STEVE:  Yeah.  PortableApps is a great solution because it's modified the apps so that all of their tendrils are contained within a defined location, basically making the app behave really in a self-contained fashion.



LEO:  Great idea.



STEVE:  So a just beautiful solution.



LEO:  Finally, Troy, Asheville, North Carolina, with the Welcome Firefox Add-On Tip of the Week:  Steve, I've taken all of your advice since Security Now! #1 and now have moved from Firefox v3.6 to 12, but our beloved Permit Cookie add-on no longer works.  So I wanted to give you and your listeners a heads-up that the add-on Cookie Whitelist With Buttons works beautifully, and the same way that Permit Cookies did.  Just thought I'd let you know. Keep up the good work.  Thank you.  So it's called...



STEVE:  Many...



LEO:  Go ahead.



STEVE:  Yeah, it's called - believe me, that's the whole name, Cookie Whitelist With Buttons.



LEO:  Yay.



STEVE:  And they refer to themselves as CWWB on their page.  And I used to be using Permit Cookies.  Many of our listeners who were more cookie conscious were using it.  And we were all shedding tears and sending notes to each other.  It's like, oh, no, it's broken.  Permit Cookies no longer works.  And sure enough, it died with 11, or maybe before, but I wasn't switching before.  But when I finally did, it's like, oh, yeah, doesn't work.  And so the good news is Firefox has a cookie whitelist facility built-in, but it's very cumbersome to go and diddle around and poke and navigate through the multilayer UI to get there.



So what these guys have done is they've simply surfaced the things you want to do most with the existing Firefox cookie management onto a couple of toolbar buttons.  So just like Permit Cookies, you're able to say "blanket deny cookies," yet when you want cookies for this session only, you can click it.  Or if you want to add a site to the permanent cookie permissions whitelist, then you click a different button.  So I know that a huge number of listeners who are mourning the passing of Permit Cookies now have an alternative, the Cookie Whitelist With Buttons.



LEO:  Woohoo.  And that concludes all 10 questions and answers from Steve Gibson.  We do these Q&A episodes every other episode, so we'll be doing it again next in a couple of weeks.  So you can, if you have a question or a follow-up, go to GRC.com/feedback and ask a question there.  GRC is the place where Steve lives.  That means that's where you can get SpinRite, the world's best hard drive maintenance and recovery utility.  You can also get all of his great freebies, his little apps.  And the podcast is there.  He makes two special versions available, and they're available only at GRC.com.  One is the transcription version we talked about earlier, pure text, searchable.  And the other is a 16Kb version.  It doesn't sound great [actually it does], but it is small, has the virtue of being tiny.



Now, for the video and the other versions, we have those at our website, TWiT.tv/sn for Security Now!  We do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC, on TWiT.tv.  We always welcome the live viewers.  The chatroom's very helpful, and it's just nice to have people watching us live.  But as I said, we make it available after the fact in a variety of formats, so you can always get it afterwards, too.



STEVE:  It's hard not to get it.



LEO:  Well, no, it's hard to get.  But it's not as hard to get as it might be.  Or something.  Steve, always a pleasure.  Thank you so much for your inspiration and your knowledge and for your dietary inspiration, too.



STEVE:  And we'll be back next week with a next topic.  I think I want to talk about this interesting little security problem which surfaced, which is how some firewalls are actually doing a bad thing that allows connection hijacking without being a man in the middle, when they were intending to do a good thing.



LEO:  Ooh.



STEVE:  It's a very clever hack that some smart people have come up with that demonstrates that, once you've got something that's wrong with a protocol, it's really not possible to fix it.  And this is a problem with TCP and the fact that sequence numbers are only 32 bits.  We've had problems in the past with them only being 32 bits because they were guessable.  And some clever people have figured out how to use that fact in a new way to allow connections to be hijacked and intercepted.  So a great topic, which we will plow into next week.



LEO:  Fantastic.  You are fantastic.  I thank you, Steve  Gibson.  I thank everybody for joining us.  We'll see you next time, right here on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#355

DATE:		May 30, 2012

TITLE:		Poking Holes in TCP

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-355.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo tackle two new and interesting threats to Internet security.  First, the newly discovered "Flame" / "Flamer" / "Skywiper" malware dwarfs Stuxnet and Duqu in capability and complexity.  Then they examine the work of two University of Michigan researchers who have detailed a collection of new ways to attack the TCP protocol.  They inject malicious content into innocent web pages and add malicious links to online chats.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and we're going to talk about what he says is the most sophisticated malware ever written:  Flame.  That's next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 355, recorded May 30th, 2012:  Poking Holes in TCP.



It's time for Security Now!.  Time to protect yourself.  Batten down the security hatches, if you will, with this man right here, our Explainer in Chief, Mr. Steve Gibson of GRC.com.  And a good day to you, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back here with you again, as always.  And speaking of battening down the hatches, we've got two big stories.  In our news is the details which are known so far, and they're still a little scant because this has just happened, and that is the most sophisticated piece of malware or malware system ever found...



LEO:  Whoa.



STEVE:  ...was recently uncovered by Kaspersky.  When they were looking for something else, they stumbled over this thing.



LEO:  That's how penicillin was found.  And Post-it Notes.  So it's a longstanding tradition.



STEVE:  Not quite the glue we were looking for, but we think we can use this.



LEO:  So what makes it so sophisticated?  Now, remember, Stuxnet, and I presume Duqu, were written by governments; right?



STEVE:  Well, and they - yes.  And what makes this so sophisticated is the complexity and the power of it.  It uses heretofore unknown injection techniques.  I mean, basically it has a ton of new technology which has never been seen before.  It is believed that this has to have been generated by a nation state.  It may be more than five years old.  Pieces of it have turned up.  Now that they know what they're looking for, they can go back and realize that VirusTotal was seeing some instances of this.  And it renames itself at one point, and those names have been picked up in archives from 2007.



So, whereas Stuxnet and Duqu, well, Stuxnet specifically was extremely focused on, as we now know, on upsetting the centrifuges of Iran's nuclear enrichment program, this is a comprehensive, general purpose, high-power espionage tool.  Now, what we don't yet know is how widespread it is.  Apparently it is all over the Middle East.  Sort of anecdotally, that much we have.  But anyway, we're going to talk about that.



And then also, what I mentioned we would talk about last week is the main topic, and that is, I titled this "Poking Holes in TCP."  This came to my attention from a bunch of people who were tweeting it to me when it was in the news.  And this was two researchers at University of Michigan have found some new ways of injecting malicious code - or malicious content, to make it more generic, because it is - malicious content into TCP connections without needing a man-in-the-middle presence.



LEO:  Ooh.



STEVE:  So they can be standing to the side, essentially, and interfere with TCP.  So this is - that, of course, caught my attention.  Now, the good news is it's more limited than the title and the synopsis makes it sound.  So it's less of a concern.  But it's a perfect topic for us on a technical podcast like this because it gives us a chance to look more closely at TCP, which is the Internet's most-used protocol.  More data moves across TCP than everything else summed up.  Well, maybe streaming now with video and audio over UDP offsets that.  But all of our web pages, all of the connection-oriented traffic is TCP based.  And we've talked about, in podcasts past, the way TCP works.  We'll look at it a little more closely relative to the glitch that these guys have found, which is interesting and provides some lessons for us.  So I think a great podcast today.



LEO:  Oh, very interesting.



STEVE:  And a little bit of random miscellaneous news.



LEO:  And all of that, thanks to Mr. Steve Gibson.  Let's kick it - we don't have a commercial.  So just go, baby, go.



STEVE:  Let's get into Flamer, or Flame.



LEO:  Flame.  I don't know if I like "Flamer" quite so much.



STEVE:  It's been called "Flamer."  It's been called "Flame."  And in fact a Hungarian research group who I'll be talking about, Crysys, they named it - before they realized what it was internally named - they named it "Skywiper."  So various people were tweeting to me about Skywiper as if it was something new, but it's the same as this super-sophisticated malware that blows everything else that we've seen before away.



Kaspersky was interviewed.  They were the people who first discovered this, having been asked by, I think it was the ITU, the International Telecommunications Union, to look into this.  They were looking for something which was wiping the drives of machines throughout the Middle East.  And so, in looking at those machines, they found something else that was before this unknown to them, and that caught their attention.  The guys at Kaspersky are calling it the most sophisticated malware ever found, dwarfing Stuxnet and Duqu.  It is 20MB of code in total for the whole thing.  And get this, Leo.  It bundles SQLite as its database backend.



LEO:  So when you install it, you get SQLite?



STEVE:  You get an instance of SQLite running in your system because - I'll go through the means...



LEO:  That's hysterical.



STEVE:  ...of data gathering.



LEO:  They need a database?



STEVE:  It builds a comprehensive structured database of everything it collects on its espionage.



LEO:  No wonder it's 20MB.  Holy cow.



STEVE:  Yeah, it's like a little OS that has just set up residence inside of your main operating system.



LEO:  Geez.



STEVE:  So here we have 20MB, whereas Stuxnet was only a couple hundred K.  So it's 10 times the size of Stuxnet, one of the reasons being that, as we saw, it has a complete database architecture.  So, now, Iran got into it.  And their equivalent of CERT, their Internet security agency is called MAHER.  They have a posting that I'll quote from.  They said, "Having conducted multiple" - and one reason is it's apparently rampant within Iran.



So, "Having conducted multiple investigations during the last few months, the MAHER center, the Iranian CERTCC, following the continuous research on the targeted attacks of Stuxnet and Duqu since 2010, announces the latest detection of a new attack for the very first time.  The attack, codenamed 'Flame'" - and that's due to some names contained within the reverse-engineered code.  "The attack, codenamed 'Flame,' is launched by a new malware.  The name 'Flame' comes from one of the attack modules located at various places in the decrypted malware code.  In fact, this malware is a platform which is capable of receiving and installing various modules for different goals.  At the time of writing, none of the 43 tested antiviruses could detect any of the malicious components.  Nevertheless, a detector was created by MAHER center and delivered to selected organizations and companies in first days of May, and now a removal tool is ready to be delivered."



Okay.  So some features of the malware:  It can be distributed - and I should comment that, understand, this is compiled code.  There's no source for it.  They're dealing with 20MB.  And, I mean, that itself makes the task of reverse-engineering this behemoth very daunting because they've got to watch it operate in a controlled mode with their own spy tools running.  And these are the people at Crysys and Kaspersky and the various organizations that have received this are now, I mean, like right now, as we're recording this, they're working together, sharing their information, and working to understand it.  But this task of understanding it is a matter of both watching it to see what it does and, like, watch it hook things, watch it inject code into different modules, run rootkit checkers against it to see which low-level kernel hooks it has grabbed in order to hide itself, I mean, so there's the behavioral side.  Then they also have to reverse-engineer this.  They have to decompile, disassemble this code and then figure out what's in there whose behavior they haven't seen.  So we'll be - I imagine this will be peeling layers off of a very large onion for some time to come.  And we'll be touching back on this as we learn more.



So we do know that it can be distributed via removable networks and local area networks.  It's capable of sniffing the network, detecting network resources, and collecting lists of vulnerable passwords as they pass by in the clear.  It can scan disks of the infected system looking for specific file extensions and contents.  It is able to perform screen captures of the infected machine when specific processes or windows are active.  It's able to capture the contents of any fields filled out, even when obscured by asterisks or dots so that they're password fields.  It can turn on the system's attached microphone and record over a long period of time any sounds in the environment.



All of this data is saved in an SQLite database which it is then able to transfer en masse to control servers.  There are more than 10 domains that have been identified as the command-and-control, the C&C servers.  It establishes secure, encrypted connections with those servers through SSH and HTTPS protocols, so it's encrypting its traffic, as well, point to point.  It bypasses all known antivirus detection, antimalware and other security software.  It's able to infect XP...



LEO:  Wait a minute.  How could it do that?  I mean...



STEVE:  Well, first of all, it wasn't known.  So none of these things knew to look for it.



LEO:  Right.  But now that they know, won't they find it?



STEVE:  Well, oh, absolutely.  But what it was doing also is it uses five different encryption technologies and three different compression technologies.



LEO:  Code.  See, that's scary.  If a virus can bypass antivirus detection, that would be a scary technology to have available.



STEVE:  Well, and remember that many of these new AVs have a problem with false positives, specifically because they are looking for things, not behavior and not specific known signatures, but they're looking for suspicious code.  And, for example, every maybe half a year or so, someone will report that some random update of an AV package now thinks that one of my EXEs, one of GRC's freeware is suddenly viral.  And it's like, no, it's not.



LEO:  It's usually pretty crappy stuff that does that.



STEVE:  Well, but again, this is - it's difficult to do because you'd like to catch things you don't know about, but you don't want a false positive.  So what's significant is that neither, I mean, even behavioral analysis didn't catch this, apparently for five years.  Nothing saw this hooking DLLs.  For example, Stuxnet and Duqu have relatively straightforward code injection technology.  This is completely new.  This is using technology that we've never seen before.  So nothing knew how to look for it.  So it can infect XP, Vista, and Windows 7.  And it's apparently expert at infecting large-scale local networks.  Quoting from one of the reports, they said, "According to file naming conventions, propagation methods, complexity level, precise targeting and superb functionality, it seems that there is a" - oh, I'm sorry, this is still from Iran - "it seems that there is a close relation to the Stuxnet and Duqu targeted attacks."



Now, that actually turns out not to be the case.  Kaspersky and Crysys, who have looked at this independently, both think there's no connection.  Whatever this is, it was created by a different organization or group than Stuxnet and Duqu.  Whereas those were targeted for specific purposes, this is a hugely comprehensive general purpose espionage tool which has been out there doing its job in secret maybe for five years.  So they...



LEO:  Five years.  Well, maybe it does get around antivirus.  Holy cow.



STEVE:  Yeah.  Yeah, that's what I'm saying.  I mean, that's what has shocked people is they have found the...



LEO:  But if it's a spear-phishing attack that's going after Iranian government installations, it might not be detected because it's just not out in the wild.  Or is it?



STEVE:  Well, for example, I mean, scroll down to my notes, one of the files, the core file which is downloaded by the initial loader is called mssecmgr.ocx.  So that's an ActiveX control of Windows.  It renames itself, or rather that file is renamed by the installation component to wavesup3.drv.  That file has been observed, was observed in Europe on December 5th of 2007, so five years ago nearly; in the UAE on April 28th in 2008; and in Iran for the first time on March 1st of 2010.  So, and it did not raise alarm.  It didn't trip any alarm.  No behavior was seen.



LEO:  Geez Louise.



STEVE:  I know.  I mean, it sounds like science fiction that we're talking about.  And it's as real as any of these malware threats that we've seen recently.  So they said, "The research" - this is Iran continuing.  "The research on these samples implies that the recent incidence of mass data loss in Iran could be the outcome of some installed module of this threat."  Now, again, that's at this point hypothetical.  "A list of the major infection components of this malware is presented below.  These samples would be available for security software vendors."  And they list some, but that's no longer unique.



Then the Crysys guys - who are in Hungary, they're the Laboratory of Cryptography and System Security - they're maintaining a paper that is tracking this.  They're at Crysys.hu, and their paper is crysys.hu/skywiper/skywiper.pdf.  And that was just the name they assigned it randomly before they realized there was a name embedded in the code.  So they have a technical report that they've put together, noting that there's been deliberate obfuscation of dates.  For example, the EXEs themselves have dates set back to '97 for whatever reason, to make them look like they're not new.  But tearing these things apart, they have found instances that are much newer.  For example, the version of SQLite which is installed inside is v3.6.22 from January 5th of 2010.  So this is in fact much newer, although the date stamps are deliberately set back to make it look older.



So Crysys in their report says that they have found evidence of five different encryption methods.  And I happened to note one of them is as simple as XORing with FF, so that just flips, it just inverts all the bits of the byte.  So that's very fast, and it's simple.



LEO:  And it's effective.  Unless you're looking for it.  It's easy to decrypt; right?  But only if you're looking for it.



STEVE:  Yes, right.  Then but there is, for example, also RC4 encryption, which is strong when it's applied correctly.  It was what was encrypting WEP protocol originally, and in fact still encrypts TKIP when it's being used because there's nothing wrong with it when you use it correctly.  So five different methods of encryption.  Three different methods of compression.  Five different known file formats plus some proprietary formats.  And, for example, the SQLite database is one of the well-known formats, which it just uses unmodified.  It uses, as I mentioned before, completely new, previously unknown code injection technology.  It locally stores information which it gathers in a highly structured SQLite database.  Get this, Leo.  It uses the LUA scripting language.



LEO:  Oh, yeah, excellent choice.  LUA, I actually have studied LUA.  It's a really nice scripting language.  You know what's written in LUA is, well, a lot of games use LUA, yeah, exactly, for a command kind of code.  And then Lightroom, Adobe Lightroom is written in LUA.  It's a scripting language.  It's a good glue language.



STEVE:  That's true.  It's a nice language.  It's also free.  So it's nice to know...



LEO:  It's open.



STEVE:  ...that these people were not pirating.



LEO:  Use open resource, yeah.



STEVE:  Yes.  They were not...



LEO:  Wordsworth had an interesting hypothesis in the chatroom.  He says it sounds like it was engineered in small modules, deployed independently, to see whether they could be detected, prior to being integrated into a larger malware package.  Is that - does that - is that the feeling you're getting?  It's interesting, yeah.



STEVE:  Yeah, it's certainly feasible.  Apparently, like all of these late-model malware, there is a component that installs itself and hides itself and arranges to run.  So you've got to have that.



LEO:  A little stub program.  It's not very big, I'm sure.



STEVE:  Yes, exactly.  And then it knows how to go check in with headquarters.  And we've seen various types of command and control.  The most recent ones are those where it uses the time and date and a cryptographic algorithm to dynamically generate domain names on the fly.  So they're not built into it.  You can't just, like, look at a list of domain names.  But at a certain time and data, it dynamically generates a domain name, and the bad guys have preregistered that domain and arranged DNS so that it's able to look up where they now are.  So, I mean, this has gotten very sophisticated.  And unfortunately, the 'Net provides this kind of power.  It's the benefit of the Internet, but also a substantial liability.



LEO:  This is the weak point, the weak link, I guess, in these viruses is they need to contact a server for command and control.  And knowing that information lets you block the server.  So they're being very clever about delaying the activation of that server and obscuring.  But as soon as they connect, isn't it obvious?  I mean, don't we then know, ah, we got 'em?  Because they have to make an explicit connection.



STEVE:  Well, we know there are also - sometimes they use TOR.  Sometimes they bounce through relays a few times.  But yes, your point is it's very much the same way that our domestic FBI follow the money because the bad guys who are extorting have to somehow get paid.  That's their weak link.  And so it's possible, similarly, to track that and catch them, which is often what happens.



So information gathering by this master espionage program are keystrokes on the keyboard; screen captures which are grabbed and compressed and then stuck into the SQL database; the microphone, so audio being recorded; contents of the drive, and not just all of it, but specific searches and requests are fulfilled.  It's sniffing the network and collecting data from the network.  It knows about WiFi and is able to exploit that when available; it knows about Bluetooth, and, if Bluetooth radio is on, it will sit there and monitor the Bluetooth channel; and USB and system processes.  And it contains rootkit injection and hiding techniques, also new, never seen before.



So Crysys said, "The result of our technical analysis support the hypothesis that Skywiper," which is their name for the same thing, "was developed by a government agency of a nation state with significant budget and effort, and it may be related to cyberwarfare activities."  Yeah, you think?  Uh-huh?



LEO:  Mm-hmm, mm-hmm.



STEVE:  "Skywiper is certainly the most sophisticated malware we encountered during our practice.  Arguably, it is the most complex malware ever found."



And, finally, as I've mentioned before, it looks like it's been around for at least five years doing something, doing its thing.  And part of the modular nature of this is the fact that, once you get that kernel installed and propagated, you are able to evolve this over time.  So today's Flame, or as Crysys calls it, Skywiper, may not be what was there five years ago.  These capabilities can be added over time, and these things are able to evolve.



So as I mentioned, it's been found around the globe for many years.  The whole package is 20MB.  This one key, that mssecmgr.ocx file, is generally around a meg, but there have been different versions of it each time that it's been seen, sometimes a little larger than a megabyte, sometimes a little smaller than a megabyte.  And Crysys said, since they were heavily involved in the discovery and analysis of Duqu, their preliminary analysis suggests that Skywiper was NOT, they said in bold caps, made by the same development team as Stuxnet and Duqu.



LEO:  Interesting, wow.



STEVE:  Really, really interesting.  Now...



LEO:  There's a novel in here.  There's a nonfiction - I would love to see somebody like John Markoff really dig his teeth into this and figure out what happened and the whole story because, boy, that'd be a fascinating book.  Fascinating.



STEVE:  It's interesting, too, how with the archives of the past that we're now beginning to accumulate, just because we've got virtually limitless hard drive storage, that it is possible to turn back the clock and find things that once existed.



LEO:  Right.



STEVE:  So it's possible to look at the state of the Internet five years ago.



LEO:  Archeology.  Internet archeology.



STEVE:  Yeah.  And do true analysis, like not only reverse engineering of this, but reverse engineering of its history before it was known to exist.  So it really can be done.  So anyway, I will certainly be looking for people who tweet any new findings about this, and I'll track them down and figure out what they mean and report to people.



LEO:  Fascinating, fascinating.



STEVE:  And speaking of tweeting, I got a couple interesting little bits from the Twitterverse.  A couple tweets from people who do work at ISPs who have been working to remediate DNSChanger troubles.  We talked about this a week or two ago, and you remember you had strong feelings about the FBI having commandeered and given control over to the ISC.



LEO:  Yeah.  The FBI-in-the-middle attack, I call it.



STEVE:  Yes.  So I think there was a little bit of stubbed toes from ISPs feeling like, well, we were saying they weren't doing anything.  It turns out it's just a difficult thing to do.  So they are working to detect when their users have computers that are checking with these malicious DNS servers and somehow trying to notify them of that fact.  So that was good to know.



And I mentioned an alternative to Permit Cookies, a Firefox extension I have loved for years and used until it seemed, for me, to stop working.  But Todd Eddy in Ohio sent me a tweet noting that he is maintaining the abandoned Firefox Permit Cookies add-on, but only to repair critical bugs, and he continually updates the version compatibility tag.  I don't know what the problem was.  I did try to update mine to this one that he's maintaining, I think under Firefox 12, but it might have been 11.  But it no longer functioned, and so I abandoned it for that pushbutton cookie gizmo [Cookie Whitelist With Buttons] that basically replaces it that I told our listeners about last week.



And finally, I got a note from someone who's written before, Christian Alexandrov, who apparently suffered a 5.8 magnitude earthquake in Bulgaria, and many hard drives were damaged, not surprisingly, by that.  He said, "Hello, Steve.  I want to share a SpinRite story."  Oh, the subject was "When earthquake strikes, SpinRite strikes back."  He said, "I want to share a SpinRite story with Security Now! listeners.  Recently, a few days ago, earthquake struck our country.  Earthquake's magnitude was 5.8."  That's a big earthquake, Leo.



LEO:  Yeah.  I mean, well, I mean, okay.  Big for Bulgaria.  I mean, here in California, well, that's just a little temblor.



STEVE:  Yeah, we would just have our overpasses rocking a little bit.



LEO:  No, that's a big earthquake.  That's big, yeah.



STEVE:  "Bulgaria is in seismological calm area, and such earthquake..."



LEO:  That's why it's a big deal, see, because it's unfamiliar to them.  They're not prepared.



STEVE:  He says, "Such earthquakes are rare.  The last earthquake equal to this one was 167 years ago."



LEO:  Whoa.



STEVE:  Yeah.  I wonder how they know that because did we have the Richter Scale 167...



LEO:  Oh, yeah, yeah.  Well, something like it.



STEVE:  Yeah.  "The earthquake created a lot of work for me and for SpinRite.  I go all over Sofia City to help to revive hard disks that suffered damage caused by the earthquake."  So clearly, pedestal-based PCs fell over while they were spinning.



LEO:  Wow.  Wow.



STEVE:  And that's not good for a hard drive.



LEO:  That actually is quite a bit of shaking, if your PC fell over.



STEVE:  Yeah.



LEO:  Geez.



STEVE:  And so he said, "Within that entire range I maintain, only four PCs were not damaged at all, regardless of the fact the PCs were working during the earthquake."  And then I'm going to skip this paragraph where he talks about the four that weren't damaged.  He says, "However, many places I had to go with SpinRite as my tool of choice.  A lot of hard drives were damaged.  SpinRite gave a lot of drives that special care they needed to make them good for work again.  Some people called me to try and fix their hard drives before they asked for help from PC repair services, or sometimes they called me after."



Get this.  "Of all the range of PCs I maintain, I was the only one who used SpinRite and brought over 180 damaged hard drives back to life.  It was a wide variety of hard drives..."



LEO:  Holy cow.



STEVE:  "...from 20GB UATA/33 to 1TB SATA3 drives that were saved and brought back to life by SpinRite.  Needless to say, there were a lot of 'U' and 'R' red squares on all drives on the first Level 4 scan, and a lot of 'B' icons on second Level 4 scan, where the 'U' and 'R' icons were before.  And also needless to say, what large number of files were saved and a large number of systems now work fine.



"Suddenly, I become a PC hero for saving PCs and bringing hard disks back to life and saving files and OSes.  Work here is still in progress.  Many drives still to fix.  And many are taken care of by SpinRite.  I do somewhere between 10 and 15 drives at a time, and many computers have two or three physical hard drives in them.  Steve, once again, thank you for your great piece of software.  And once again, thank you, Steve and Leo, for the great Security Now! podcast.  I wish best of luck to both GRC.com and TWiT.tv.  A happy SpinRite user."



LEO:  Wow.  Well, there you go.  Now you have a new slogan:  "Built for earthquake country."  Geez.  That's fascinating.



STEVE:  Very cool.



LEO:  That is really interesting.  Let us continue on poking holes in TCP, shall we?



STEVE:  Speaking of poking holes.  In TCP.



LEO:  Yes.



STEVE:  So some researchers, two security researchers in Michigan - I have to warn everybody, if you did not have your propeller hats on...



LEO:  It's time?



STEVE:  ...maybe this is a good spot to pause and go refresh your coffee or open a new can of - I hope you're not opening a can of soda because that's not good for you.



LEO:  No.  Sardines.



STEVE:  Oh, that's - there you go.  A can of sardines.



LEO:  Yeah.  Go get a can of sardines.



STEVE:  Because this is going to get a little hairy, but it's good hairy.  I mean, it's important hairy.  And a perfect, perfect topic for this podcast that pushes the limits of what we're able to do over an audio channel.  We're going to do that today.



So a couple researchers were looking at the security of primarily cellular networks, that is, their platform focus was Android, and Android connected to the Internet via cellular was the scenario they set up.  What we'll talk about is broader than that, really, but they've only focused on that.  And it's broader because it's really about the transmission control protocol, TCP, which is the basis for the web and all kinds of apps which are now using TCP behind the scenes.  They may not look like a web browser, but they're actually setting up persistent connections back to a server in order to communicate.  For example, when I have TweetDeck up, it's got TCP connections open through which it's using the Twitter API to communicate.



So, okay.  So what they discovered was that there were what they called "middleware firewalls" installed in these mobile networks in - they detected them, I think they checked 147 mobile networks, and they found them in 31 percent of them, so about one third of them.  The firewalls were there to block unwanted traffic, just to sort of, like they just stuck a firewall sort of in the middle of their network and said, okay, at this point anything going in either direction that looks funky, let's get rid of it.



Well, these are stateful firewalls which connections have been made through them.  And that way they're very much like our NAT routers that we've talked about that are stateful routers, where incoming packets are just dropped because they don't correspond to a connection that was initiated from the inside out, which is what allows connections to come back, or packets of connections to come back in.  So these are firewalls which, when a SYN packet, a TCP synchronized packet encounters a firewall on its way to a destination on the other side of the firewall, the firewall makes note of it.  It looks at the source IP and port, the destination IP and port, and adds that to its "okay, a connection is being set up through me" table.  Then, when the answering SYN/ACK comes back to the firewall, it makes sure that that SYN/ACK is expected.  And, if so, it updates its tables and passes the SYN/ACK on towards its destination.  So it's sort of a - it's a blockade just sitting at an arbitrary middle point in a cellular provider's network because, if SYN packets are just, like, from a denial of service attack, if a SYN packet hits it that it isn't expecting, or an ACK packet or something bogus in one way or another, it just ignores it.



Well, one of the things that these firewalls do is they validate the traffic on an ongoing basis.  They watch the setup.  And people who have followed along with our talk about how TCP works will remember that the reason we call a SYN packet a "SYN" is SYN is short for synchronize.  And this is the connection initiator saying I'm going to number my packets starting at this number.  And there's a sequence, a 32-bit sequence counter in all TCP packets which numbers the first byte of the payload in that packet.  So, for example, if a sender were to send out packets of a thousand bytes, then successive packets would contain these sequence numbers that were a thousand larger each time.



Well, that's done because, as we well know, packets don't always arrive in order at the other end.  The route that packets take is not predetermined by either the sender or the receiver.  Those are determined just by routing tables among all the routers that link these two points.  So it's possible that one router could be busy.  An interface might be backed up, so it routes a packet somewhere else, so a later packet could get to its destination sooner.  So it's necessary to number the bytes in the packet so that they can be reassembled in the proper sequence when they arrive.



So TCP has been a target of attack in the past, and the sequence numbers are one of the weaknesses of TCP.  So if we were to step back for a minute and come up with a lesson that we're about to learn, it is that, if you have a fundamentally unsecure protocol, there isn't a way to add security later.  It was an argument that I made against Backblaze, where they sort of tried to add a user password in a hokey way to give people a greater sense of security, but it actually achieved nothing in terms of true security for the user, or it achieved very little.  That is, they had a broken model where they were doing the decryption at their server end, and that couldn't change, no matter what they added on top of it.



In the case of TCP, it was designed, as we know, literally decades ago, back when numbering packets with a 32-bit count seemed like more than enough.  It was that 32 bits gives us 4 billion.  And there's nothing wrong with these counters wrapping, that is, counting up to 4 billion and then wrapping around back to zero.  They do that all the time.  TCP understands that, if it has a high packet number, and then suddenly it's got one very near zero, that it didn't go back 4 billion, it just went ahead a few.  So it allows and handles gracefully that wraparound from the maximum back to the minimum, as all the binary bits, all 32 binary bits fill up with ones and then click back over to zero again.  So the designers thought, well, 4 billion.



Now, the reason we have sequence numbers is several.  One is, as I mentioned, we want to number the bytes that we're sending in each direction.  So a TCP packet has a sequence number for its data that it's carrying.  And it also has a sequence number which acknowledges the most recently in order, received in order packet that it has received.  So what normally is happening is, after the SYN goes, and then the SYN/ACK comes back, a final ACK is sent, an acknowledgement, acknowledging the SYN of the SYN/ACK packet.  From then on, all the packets going back and forth have their ACK bits set, each end acknowledging what they've received so far from the other end.  So the system works nicely.  32 bits to number the data.  So that's plenty.  It means that, if packets come in out of sequence, it's obvious how they should be arranged.



The other purpose for this, though, is because packets wander around the Internet, we know that they're clipped off by their TTL field, the Time To Live, which decrements, is decremented by every router which forwards the packet.  And any router which decrements it to zero will send back an expired notice to the sender of the packet, saying, well, I tried to send this, I wanted to, but TTL went to zero.  And if we didn't honor that, the Internet absolutely would crash because packets would never die.  They'd just roam around forever and fill up the Internet.  So the fact that they die is crucial.



But it still means that, if you have a very high bandwidth connection and a long delay between endpoints, it's difficult to see how you could have 4 billion bytes in flight at any time.  And the designers were very comfortable with the idea that 32 bits would never wrap around within the lifetime of a single packet on the 'Net.  And that's the key is that, because connections, TCP connections come up and down and up and down, they're often very short-lived connections.  They establish, send something, and then drop again.  And then the connection may be reinitiated between the same two endpoints. 



Connections are identified by the source IP and port and destination IP and port.  And so if you brought the connection up, sent some traffic, took it apart, and then brought it back up again and made another connection, what the designers of TCP wanted to guarantee against was the possibility that lost packets wandering around from the previous session, the previous connection, might be confused with packets from this session.  So the way they solve that problem is by advancing the sequence numbers forward, actually for the whole system.



They normally - they do it system-wide so that any connection that is created uses forward-moving sequence numbers so that all of the numbered traffic that is leaving it will never have the same numbers as older traffic.  And that's a little confusing because you would think that we're always counting from zero.  The idea is that that SYN packet, the sequence packet says we're going to count from this number.  So this number equals zero, and a thousand plus this number equals a thousand.  So the idea being that these sequence numbers move forward, and in what was once a uniform fashion.  



Well, the hackers figured out that they could take advantage of older operating systems' uniform sequencing.  That is, the idea was they figured out that, by talking to a server, for example a router, they could determine the router's current sequence number.  And, because they would initiate a connection to it, it would send back its SYN/ACK.  That would tell them the current state of the sequence number.  Then what these clever hackers did was they were able to spoof TCP traffic because they were able to guess what other connections that either later existed or preexisted, they could guess the probable sequence numbers of those connections.



So this was a huge problem for the Internet, and it resulted in the randomization of TCP sequence, these Initial Sequence Numbers, the ISNs, for communications.  So for a while there was a problem because the hackers figured out how to get the sequence numbers of probable connections.  The response was to randomize those.  And in fact what Linux does is, being 32 bits, that's 4 bytes.  Linux takes the highest, the most significant byte and increments it every five minutes.  Then, for the lower 24 bits, they just use a random number.  So it's jumping all around within one-256th of the total sequence number space, and that's moving forward, jumping forward every five minutes.  So that's still believed to be about the best tradeoff you can come up with between random and still meeting some of the goals of moving sequence numbers generally forward over time so that you don't have various types of replay attacks.



So what these guys in Michigan figured out is a new way of determining a connection's packet sequence numbering.  And that's bad because, when you think about it, there isn't any protection in TCP.  I mean, there really isn't.  It's only obscurity which protects TCP.  It's the fact that, unless you can see the traffic going back and forth, you don't know for sure what the originating port was.  You may know what the destination port, if it's a server, for example, HTTP, it's going to be port 80.  If it's going to be SSL, it's port 443.  If it's POP, it's port 110 and so forth, SMTP port 25.  We know those so-called well-known ports at the server end.



We also know the server's IP.  And we may know the originator's IP.  So now we have just the question of what port it generated its traffic from.  And unfortunately, most OSes still do that in a uniform, from the bottom up, fashion.  They just issue traffic sequentially.  So if you can get that client to talk to you, you know what its current outbound port enumeration is, and so that gives you lots of information from which you can spoof TCP traffic.  And that's what we're talking about here.  We're talking about a new way to insert traffic into TCP sessions that gets around this problem that the initial sequence numbers are now being randomized by all contemporary operating systems.



So what these guys do is they have a number of approaches that they take.  I'll describe one in more detail because it's representative, and it'll give you a sense for this.  Their main exploit is not completely standing off to the side and attacking.  It is possible to do that, and they outline how that can be done.  I explained how you can know what their IP is, what their source port is.  You know what the destination port and the destination IP is.  And so there are completely, like, third-party attacks which they have identified and verified.



But the one that works best is one which is also really interesting because it demonstrates an interesting failure in sandboxing.  They implemented this with Android-based phones from, shoot, it was HTC, Samsung, and Motorola, using Android v2.2 and 2.3.4 from those manufacturers.  And they installed an unprivileged piece of software, we'll call it malware because it's not doing what you want it to do.  It may be offering some service to you, but it's also doing more than that.  But this malware is unprivileged, meaning your phone does not need to be jailbroken.  It's not even breaking out of the sandbox because they discovered some very clever side-channel leakage about the TCP stack on any contemporary operating system.



And that is, if, for example in Windows, you open a console window and type "netstat," you get an enumeration of all the system-wide TCP connections.  And as of, I think, XP and on, you can add a command line switch that will tell you which processes are involved with those connections.  So you can see that IE has the following connections open here, and TweetDeck has them open there, and so forth.  Well, and in fact there's one other thing.  There's netstat -s, which shows you an array of counters which all Internet operating systems, starting with UNIX and since, have maintained.  These are things like the total number of packets sent, the total number of packets received, an array of error information which is also available.



Now, Linux has the same thing, which it implements differently.  There's something called the proc file system, procfs.  And it's sort of a clever way - it's not actually a file system of data that exists in any storage media.  It's just a nice, clean way for the operating system to publish real-time information about things going on with it.  And, for example, there's a path, /proc/net/snmp, which stands for simple network management protocol, and then InSegs, returns a count of the total number of TCP packets received.  The same thing, proc/net/netstat: InErrs is a count of the erroneous packets received, like packets that have been received with a broken checksum, where the checksum doesn't match.



And there's one called, also under netstat, PAWSEstab, that's a count of old timestamp packets.  PAWS is an acronym for Protect Against Wrapped Sequences.  And that's exactly what I was talking about, the concern of sequences wrapping.  The designers decided that they needed more than 32 bits, and they realized that the timestamp was a feature just never really took off and got used, so they could use that as an upward-compatible means of providing some disambiguation.  But it generates, it increments this count in the operating system if a packet is received with a bad timestamp.



The point of all this is that these guys in Michigan realized that, if they had some software running in an Android phone, it could detect, by using this common, globally available information - this is an unprivileged read.  Everybody, all apps in Linux have access to the proc file system.  It's readable.  Everybody can have it.  So what this provides is a so-called "side channel attack."  And we've talked about those in various contexts before, but never in this context, where something leaks information that can be used.



For example, classic crypto has side-channel attacks if it takes differing lengths of time to respond to, like, an encryption operation or a decryption operation, depending upon the data or the key.  Because if you then use precise timing measurements, you somehow induce a system to try to decrypt what you're giving it with an unknown key, and you look at the time it takes, if its time varies with the key, then it's leaking information in the time domain, which that's a perfect side-channel example.  It's not saying, I mean, it's not giving you your data back properly.  But it is leaking information that it didn't intend to.



One of the reasons that AES was adopted was it is inherently power and time stable.  It does not allow those kinds of side-channel attacks, which is one - in fact, I don't think any of the submissions do, or allow that, because it's now well understood that you just can't have crypto do that.  What has not until now been understood is that doing something as benign as allowing an app to look at counters from the system-wide TCP stack is all it takes to launch exploits against other applications on the same OS.  And that's what these guys have showed.



So what they did is they have this piece of malware installed in an Android phone.  Three different phones, two different versions of Android, from HTC, Samsung, and Motorola.  So it's widespread.  They used an undisclosed nationwide cellular carrier.  Their report doesn't want to point fingers at anybody.  And it's not just one carrier that is doing this.  They all do.  I do know that it was a GPRS-based technology because they referred to GPRS at one point, some data files at one point in their report.



So they have an attacking server located somewhere else that this malware is communicating with.  And understand, in a real-world scenario users would innocently think they had downloaded an Android version of Firesheep or a how-many-calories-have-I-eaten-today app or something that looks like it's absolutely benign.  And it never breaks out of the technical sandbox.  But it establishes a connection to a malicious server, and then it waits.  It waits for some activity on the phone that it wants to intercept.  It might be instant messaging.  It might be Twitter.  It might be web browsing, whatever it's designed to do.  It's able to look at the processes running; and it's also able, from netstat, to look at the processes that are communicating.  And it knows, because netstat shows it, both of the endpoints.  It knows the local IP and port and the remote IP and port.  What it doesn't know is the sequence numbering for that connection.



So as soon as it sees a connection coming up, it communicates with a server located remotely that it's time to get busy and try to get into this connection.  So the initial sequence packet, opening a connection, goes from the phone toward the true destination.  We'll say Google, just to pick an example.  And the attacking server now sends a flood of probes back into the network, aimed at the client.  Between this attacking server and the client is this firewall, which is intending to do the right thing.  It's going to block packets that don't have matching sequence numbers.  That is, whose sequence numbers are unexpected.  There's a window which moves along, that moves forward, of sequence numbers that will be accepted.  And anything outside the window are rejected.



So the idea is this thing, the attacking server, floods the connection back toward the client with guesses.  They've even figured out how to binary search the entire 4GB - 4 gigabit, sorry, the 32-bit sequence number.  They've figured out how they can do a binary search in order to narrow it down.  So the client is - what the client is doing, it cannot see that this - the malware running on the phone cannot see the traffic coming back.  But the malicious server is deliberately generating packets, using the timestamping option, which it knows are going to fail.  So this one counter in the TCP stack, this PAWSEstab, which is the count of old timestamp packets received, it's normally not used.  That counter normally sits at zero.  So the point is it's not noisy.  They're not have to disambiguate other reasons for it to be incremented than their own.



So what they've essentially done is they've managed to come up with a communications path through the side channel, off the TCP stack, that allows the malicious client in the phone to notify the server when its packets get through the firewall.  That tells it, then, that allows it to zero in on the sequence numbering of the connection and then verify that it knows where the connection sequence numbers are.  Then it's able to respond as the original server was.  It sends a reset packet to the original destination server, which resets the connection.  The reset packet just causes, for example, in this case, it would be Google, causes Google to ignore the connection.  And reset packets are honored by all servers.  And Google doesn't know why the user changed his mind about connecting to it, doesn't care, just simply drops the connection completely.  So Google no longer has any interest in the connection.



In order for the reset packet to be accepted, it has to fit within this window.  It has to be a valid sequence numbered reset packet.  But the attacking server has been able to determine what that is through this probe.  So Google is dropped off the connection.  Now the attacker is able to send data in lieu of what Google would send as the response to whatever query the user initiated.  Now, this is tricky because remember that the traffic is not going to the bad guy.  The traffic is going to Google's IP.  And it's always going to go there.  The traffic will continue going there.  But Google's own firewalls, or its operating systems, will simply drop the traffic.  That connection's been reset, so the traffic coming in is not part of a known connection, and it gets ignored.



So the acknowledgments from the original client application running on the mobile phone are ignored.  But when you think about it, there's nothing in TCP that actually requires that both ends receive the data that the other one is sending.  That is, the malicious guy has a valid sequence number for the data going to the client on the mobile phone.  He can assume the data gets there.  He can assume packet after packet after packet are being acknowledged.  The acknowledgments he never sees.  They go to Google, and they're ignored because the connection has been reset.  They're just dropped.



So we now have a situation where an app on a mobile phone initiated a TCP connection to some service - Facebook, Twitter, Google, whatever - or maybe has a longstanding connection open if the malware wants to go in and inject things into existing connections.  But in this scenario they open a connection.  As far as the app knows in the phone, everything's fine.  It sends its SYN off to open the connection, and the next thing it gets is a valid SYN/ACK with a sequence number, which it accepts because it's coming from the malicious server.  And Google accepts the reset packet because the bad guy figured out what the sequence number was in that direction because that was allowed to get through the blocking firewall in the middle.



Now the app running in the mobile phone receives data.  But it could be an HTTP redirect which bounces them to a clone website without them seeing it, and these researchers achieved that.  They also achieved installing JavaScript, injecting JavaScript into the connection and causing the JavaScript to run in the context of your relationship with Google, which means, if you were permanently logged into Google, then they're able to send all of the information that your browser would normally never share with anyone but Google, off in any direction that they want to.



So that's the gist of this.  It is, I mean, it sounds - it is complex.  To me, as I'm reading this, I'm thinking, okay, well, this doesn't sound like the kind of thing that everyone is going to get infected by.  But it's perfect for targeted attacks; or, with time, this kind of attack could mature to the point where apps are offered on Android stores, people download them, and the malware starts up in the background and gets up to its mischief.



Now, I guess I feel of two minds about this.  I mean, all the details are in this 14-page report that allows somebody as good as these guys are, and there are a lot of smart hackers in the world, to duplicate this.  That is, nothing is left unknown.  And the reason I'm of two minds about it is that it's not clear how we solve this.  I mean, I guess providing the side-channel information from the TCP stack only to root-based apps might make sense.  But who knows what you would break?  Who knows what apps are actually using that information for some purpose?  So, I mean, that fundamentally changes the way all of our UNIX and UNIX-derived and also Windows systems function.  So we have a new problem which has surfaced that, in the context of mobile phones, breaks the sandbox and allows malicious packets to get injected.



Now, the one thing that stops this cold is HTTPS because there's no way, if an HTTPS connection is being established, there's no way for the bad guy to have a valid certificate that the browser is going to require and verify.  So throughout their paper these guys mention that they did find in a secure connection with somebody, I think it was either Facebook or Twitter, there were two connections that still were not running over SSL.  But this, one thing this says to us is that, certainly in a mobile network scenario, where we're assuming that the encryption of the mobile provider is sufficient, is HTTP and unencrypted connections really are not sufficient.  We really need to use end-to-end authentication.  And that, and pretty much that alone, gives TCP the additional layer of authentication and privacy that it needs.  TCP by itself just doesn't do it.  It wasn't designed to do it.  It was designed to work.  And it really works well, but it's not very attack resistant, unfortunately.  Isn't that cool, Leo?



LEO:  One more reason why HTTPS Everywhere is a good idea.



STEVE:  Yes, exactly, yeah.  I mean, this is some seriously clever hacking, and an interesting way of using just a little bit of information leaking across the OS boundary, which is how many errors of a certain type have we seen, and then deliberately generating those kinds of errors on packets that may or may not get through a middleware firewall, and using that to probe the firewall which in turn releases information about the state of the TCP connection that would otherwise never be available, and then you exploit that in order to hijack the TCP connection.  Wow.



LEO:  Wow.  And is this in the wild?  Or is this just now merely an academic exercise?



STEVE:  Academic exercise.  I wouldn't be...



LEO:  Okay.  So we don't have to fear it.



STEVE:  There's nothing to fear except...



LEO:  Except that it's been documented now, and so...



STEVE:  Yes.  There's also nothing to do, really.  I mean, I would love to see Android lock this stuff down.  And I would be surprised if they don't.  I mean, everybody - I got so many tweets about this, people saying, "Okay, I don't know what these guys said, Steve.  Could you explain it to us?"  And so...



LEO:  What does it mean?  Well, now we know what it means.  I don't know if you...



STEVE:  This sounds bad; this looks bad.



LEO:  I don't know if we feel any better, but now we know what it means, anyway.



STEVE:  Yes.



LEO:  So this show, as with all of the previous 354 episodes, lives in several places.  You can, of course, watch us live every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern, 1800 UTC, right here on TWiT.tv.  But if you missed a show, or I think more likely you wanted to listen again or even read a transcription, Steve makes text transcriptions available, as well as 16Kb audio versions at his site, GRC.com.  We also have audio and video and higher quality versions at TWiT.tv.  And you can get it on a podcaster like iTunes or Downcast or any of those, as well.  In fact, that's the best way, subscribe to the version you like.  That way you'll never miss an episode.  And you'll own all 355 at absolutely no charge.



Steve also makes a lot of other great things available at GRC.com, including his bread-and-butter, SpinRite, world's best hard drive maintenance and recovery utility.  He also has a lot of freebies there, including the world-famous ShieldsUP! and lots of free security stuff, too.  GRC.com.  Now, when you're there, if you have a question about this or anything in the realm of security, privacy, Vitamin D or fish oil, you can - or ketogenic diets, you can leave those questions for us to talk about next week because every other episode we do a feedback episode, GRC.com/feedback.  Did I miss anything there?



STEVE:  I should mention that I've had a bunch of really neat feedback from our two Over the Sugar Hill episodes, over at GRC.com/health.



LEO:  Oh, wow, yeah.



STEVE:  And there is a feedback page there for health-related stuff.  Anybody who wants to share their experiences, I've got a user experiences page and an FAQ page that I will be updating shortly.  So, love to hear what people think.



LEO:  My dad just sent me an email saying, you know, "You ought to be taking Vitamin D."  I said, "Been there, done that, know all about it."  And I sent him a link to your health page.  I said we did a show about it.  And, yeah, in fact I've been talking to my doctor about the ketogenic diet.  He's really interested in that "Art and Science of Low Carbohydrate Living" that we're using as our bible. 



STEVE:  Oh, I forgot to say, I got email from Geoff Bond.



LEO:  Whoa.



STEVE:  The author of "Deadly Harvest."



LEO:  Whoa.



STEVE:  Apparently we spiked his sales, and he's now the No. 1 rated preventative health book on Amazon.



LEO:  Awesome.  The power of the Gibson.



STEVE:  And so he sent me a note saying, hey, thanks, Steve.  He got a kick out of the fact that I wasn't that enamored with the name of the book.  But I understood that it wouldn't sell as many copies if it was titled "Nutritional Anthropology That I Have Known."  So anyway, it was neat to hear from Geoff, yeah.



LEO:  It's interesting, too, because we get people in the studio all the time now who are on the ketogenic diet or have been doing it.  A guy was here last week, lost 80 pounds, looked great.  Another guy who had celiac disease, so he was compelled to because of his intolerance for wheat and glutens.  And he also said, you know - he looked great.  He said, "I've lost a lot of weight."  So every day almost, somebody comes in here and says, "That Steve."  Well, it started with Paul Thurrott, and now it's spread.



STEVE:  It did, yup.  Well, and in fact many people they started with Paul, and in some cases the carbs crept back in because it's just so difficult, I mean, there's so much...



LEO:  But it's everywhere.  We're inundated with it.



STEVE:  Yes.  We're a carb-based culture.  But then they said, when they heard my two podcasts and a lot of the biochemistry of it, they understood.  In fact, one person said that ketosis was the only way she'd ever been able to lose weight, but it always starved her to death.  Now she knew how she could do it...



LEO:  Now she knows why, yeah.



STEVE:  ...and not be hungry all the time and not have to starve.  So, yeah, cool stuff.



LEO:  Great stuff.  Thank you, Steve.  GRC.com.  It's all there.  Is it GRC.com/health, if people want to read more about that?



STEVE:  Yup, and also in the menu, if you go under Research, there's Health as a subtopic of the research tab.



LEO:  There's a ton of stuff there.  Thank you, Steve.  We will do this next week, right here.



STEVE:  Talk to you then, Leo.



LEO:  See you.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#356

DATE:		June 6, 2012

TITLE:		Listener Feedback #145

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-356.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  Time for Security Now!.  Steve Gibson is here.  We've got a lot of security updates, including news about LinkedIn, Flamer, Stuxnet, and your questions.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 356, recorded June 6th, 2012:  Your questions, Steve's answers, #145.



It's time for Security Now!.  Couldn't be a better day to cover security with Mr. Steve Gibson, our Explainer in Chief.  He's here today from GRC.com, and it's a Q&A episode, so we've got a dozen great questions from our audience.  Good day, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you again, as always.



LEO:  Oh, yes.



STEVE:  We've had an eventful week, not surprisingly.  I think it was Friday that I tweeted to my Twitter followers the news that an investigative journalist with The New York Times had uncovered a multiply sourced report that one of his first acts after being inaugurated in office was that our Barack Obama, President of the U.S., ordered a speedup in the waves of cyberattacks that the U.S. was waging against Iran.  So we have some news there.  Of course that comes on the heel of last week's first opening discussions of Flame, what's now being called a "super cyber weapon" by Kaspersky, who's been looking into it further.  We've got a bunch of information about that, new and interesting things.  I was tweeting a lot of links as I was setting up the notes for the podcast.  So anybody who wants links to these things just check my Twitter feed, @SGgrc, and you can get links to these various important things.  But we have a bit of sadness...



LEO  Yeah.



STEVE:  ...in the sci-fi arena.  Last night we got the word from his daughter that Ray Bradbury passed away at the age of 91.



LEO  91.  I mean, that's a ripe old age, you know?



STEVE:  Yeah.  He looked good for 91.  He, of course, was I think probably most famous for "Fahrenheit 451," which was just an amazing book at the time.



LEO:  "Martian Chronicles," too, I think, yeah.



STEVE:  Yes, and also he wrote "Something Wicked This Way Comes."



LEO:  Oh, what a great book that is.  Short stories.  Lot of short stories.



STEVE:  And he's credited with being more of a literary influence on the genre.  He disliked the term "sci-fi."  He considers he only really wrote sci-fi, he considered, was his "Fahrenheit 451" story.  The rest he considered more, you know, flights of fancy.



LEO:  Yeah.



STEVE:  But his writing was so good that he was trying to bring, again, more of a literary feel to science fiction.



LEO:  I think he's one of the great science fiction authors, and this is a great moment, an opportunity to go back and reread.  I know that a lot of geeks I'm following on Facebook and Twitter said, oh, I'm going to reread "The Martian Chronicles" or "Fahrenheit 451."  One of my favorites, and I refer to it a lot, is "The Veldt."  That's a great one.  In fact, they have a - I didn't see this, so I might have to download it - a dramatization of "The Veldt" on Audible.com.  "The Illustrated Man," what a - and you're right.



STEVE:  Oh, yeah.



LEO:  These are not really sci-fi.



STEVE:  Right.



LEO:  They're fantastical tales.



STEVE:  Right.



LEO:  "The Martian Chronicles" is; "Fahrenheit 451" is.  Both of those, just fantastic.  Boy.  He's a great storyteller, one of the best writers.  And I think one of the reasons he defies genre is because he's such a good writer and really goes well beyond what we're normally used to in science fiction.  A truly...



STEVE:  And sadly, now we need to use the past tense when referring to Ray.  But certainly not his work.  His work will live on forever.



LEO:  And a great supporter of science.  And I think Ray Bradbury, an inspiration to many scientists for their work.  I think that often we've found out that scientists look back to what they read, like "The Martian Chronicles" or "Dandelion Wine" or whatever and...



STEVE:  Were really influenced.



LEO:  ...said that inspired my work.



STEVE:  Yes, yeah.  This Friday is going to be June 8th, two days from now.



LEO:  Yes.



STEVE:  It's the release in the theaters of "Prometheus."



LEO:  Oh, I'll be in line.



STEVE:  Oh, goodness, yeah.



LEO:  I'll be in line.  This is the prequel - you know, it's funny, I know a number of people who didn't realize this - the prequel to "Alien."



STEVE:  Yes.  And brought to us also by Ridley Scott, as was "Alien."  HBO has a short, 15-minute presentation called "Prometheus:  First Look."  I've not seen it, but my TiVo sucked it in this morning at 9:00, or noon on the East Coast, and I know that it's, through HBO's schedule, it's scattered around.  So anybody who's interested may be able to find it coming up.  And I only - a buddy of mine told me about it.  And apparently, one of the takeaways he had was that the set of the new James Bond movie, which is in production, was like a postage stamp compared to the set of "Prometheus."



LEO:  You could tell it's a giant soundstage, yeah.



STEVE:  It is a huge, actually I think it is the largest set of soundstage environment ever made.  Or, I mean, there's something like that about it.  I didn't, I haven't, again, I haven't seen this.



LEO:  Just the trailer, when you see the trailer, you can tell they're in a very large space.



STEVE:  Yeah.



LEO:  Yeah.  Cannot wait.  Cannot wait.



STEVE:  Anyway, so I'm very excited.



LEO:  Yeah, this is going to be an exceptional movie.



STEVE:  And again, just anecdotally, the phenomenal scene that, you know, that branded everyone who saw it in Ridley Scott's first movie, "Alien," was the classic scene of this creature erupting from the person's chest.  You know, we'd never seen anything like that, ever.  And apparently this movie has something different, but even more so.  So...



LEO:  [Laughing] I don't know if I'm ready for it.  That was so terrifying.



STEVE:  It was just amazing.



LEO:  Now, of course, Sigourney Weaver, who was the star of the first two, will not be in this one, I'm sure.  Who is the - who are the stars of this?



STEVE:  Well, we have Charlize.



LEO:  Charlize Theron.  Oh, she's wonderful.



STEVE:  Yes, yeah.



LEO:  One of our best actors.  Boy, she's good.



STEVE:  And we have another android.  And in fact, over on the YouTube, collection of YouTube videos for this, they're linked from the IMDB article, there is a full-length commercial that Wayland, who is the corporate interest behind all of this - remember, they were the people that did terraforming on "Aliens."  Anyway, they have an ad for their android, where he's demonstrating himself and so forth.  So...



LEO:  Oh, wow.  They're smart.  I'll tell you, they've gotten very smart about marketing this stuff, haven't they. 



STEVE:  Yup, yup.



LEO:  They just - they've got a series of - this isn't - there isn't just one.  It turns out there are many ads from "Prometheus."  Wow.  This is interesting.  Look at ads for all of their products.



STEVE:  Wow.  I haven't...



LEO:  They're so smart about - they're so smart about doing this stuff now.  They put a lot of energy into these...



STEVE:  Well, apparently Ridley Scott decided he was going to try to outdo himself.  And from everything I've heard, this new one is going to be a contender.  So I think it may be the movie of the summer.



LEO:  Yup.  Well, there you go.  Good and bad news in sci-fi.



STEVE:  So, yes.  New York Times' David Sanger put together an article.  The title was "Obama Order Sped Up Wave of Cyberattacks Against Iran."  And I'm just going to read the first few paragraphs, which since this is well written - it's a long story.  It's five pages on their website.  But this was properly written, so all of the meat is at the front.  So he wrote:



"From his first months in office, President Obama secretly ordered increasingly sophisticated attacks on the computer systems that run Iran's main nuclear enrichment facilities, significantly expanding America's first sustained use of cyberweapons, according to participants in the program.  Mr. Obama decided to accelerate the attacks - begun in the Bush administration and code-named Olympic Games - even after an element of the program accidentally became public in the summer of 2010 because of a programming error that allowed it to escape Iran's Natanz plant and sent it around the world on the Internet."  Which is interesting.  This is stuff we did not know before.  Prior to that it was contained there, and it got loose.



So, "Computer security experts who began studying the worm, which had been developed by the United States and Israel, gave it a name:  Stuxnet.  At a tense meeting in the White House Situation Room within days of the worm's 'escape,' Mr. Obama, Vice President Joseph R. Biden, Jr., and the director of the Central Intelligence Agency at the time, Leon E. Panetta, considered whether America's most ambitious attempt to slow the progress of Iran's nuclear efforts had been fatally compromised.



"'Should we shut this thing down?' Mr. Obama asked, according to members of the president's national security team who were in the room [with him].  Told it was unclear how much the Iranians knew about the code, and offered evidence that it was still causing havoc, Mr. Obama decided that the cyberattacks should proceed.  In the following weeks, the Natanz plant was hit by a newer version of the computer worm, and then another one after that.  The last of that series of attacks, a few weeks after Stuxnet was detected around the world, temporarily took out nearly 1,000 of the 5,000 centrifuges Iran had spinning at the time to purify uranium."



And so that's the start of a five-page story.  Again, you can easily find it at The New York Times, or I tweeted it Friday of last week.



LEO:  Where do you stand on this?  We had a good debate on TWiT on Sunday.



STEVE:  Well, and actually one of our questions that we are going to come to was a listener who poses that.  So I thought we'd maybe hold off...



LEO:  Good.



STEVE:  ...discussing until we get to the question because I do, exactly with you, Leo, I wanted to discuss, I mean, the controversial nature of it.



LEO:  Right.



STEVE:  Okay.  So, Flame update.  I also tweeted early this week, shortly after Microsoft released it, there is a very important update which Microsoft produced in an emergency, out-of-cycle release.  It's small.  It's 91K.  At least it was in the case of my Win7 box, which I updated the moment I turned it on here to run Skype.  Because it turns out that the components of Flame were digitally signed by Microsoft certificates.



LEO:  [Laughing]  Faux certificates?  Phony certificates?  Real certificates?



STEVE:  No, real certificates.



LEO:  That's not a good way to hide your tracks.



STEVE:  Now, I mean, and when I first heard this, I was thinking, you know, I wonder if this wasn't arranged.  I mean, if this is now, if we're pretty much clear that this is U.S. cyber espionage, if the CIA or the NSA wouldn't have gone to Microsoft and said, you know, the world is using Windows.  Now, that's another real discussion point is the fact that, you know, the entire world is using, I mean, dependent upon operating system software from a company based in Seattle, United States.



LEO:  Right.  I mean, these machines, Stuxnet is a Windows virus.



STEVE:  Yes, exclusively.



LEO:  Yeah.



STEVE:  And here, here there are, you know, Macs are available worldwide.  Linux in all of its flavors.  It would be, I mean, way safer for all foreign governments not to use a U.S.-based, U.S.-created operating system, yet they all are.  There was a blurb I saw in a Kaspersky blog or a summary that said that - oh, no.  It was from the Iranian CERT, saying that high-level Iranian officials had been infected by Flame, which is a Windows-only worm.  So they're using Windows.  And I have to think, wow, okay, that's...



LEO:  Microsoft would never screw us.  Never.



STEVE:  Anyway, so what happened was some clever person, and we'll never know whom, discovered that certificates issued for Microsoft Terminal Server could be used to sign code.  And that should have never happened.



LEO:  So it wasn't Microsoft that signed the code.  Somebody who owned a licensed Terminal Server?  Is that what I'm hearing?



STEVE:  As I understand it, there was a class of enterprise terminal services, and Microsoft offered a service where you could get certificates from Microsoft and use them to secure Terminal Server.  And those certificates, and these are what are now blacklisted, they chained straight up to Microsoft's root authority certificate authority.  And there are three of them that are implicated in this.  And Microsoft, that's what this emergency out-of-cycle patch is.



LEO:  So this is a whole - and larger than just Stuxnet.  It means any bad guy who had a license for Terminal Services could write certificates.



STEVE:  Yes, yes.



LEO:  That would be trusted by your browser.



STEVE:  And what no one - yes.  And what no - well, no, trusted by Windows.



LEO:  By Windows.



STEVE:  So these are - because this would - get this, Leo.  They also arranged a man-in-the-middle - and this is something we've dreaded forever - a man-in-the-middle attack on Windows Update.  And this is one of the propagation mechanisms for Flame in LANs that we discussed last week.  There is a component that we actually first talked about as being insecure, you and I discussed it on October 19th of 2006.



LEO:  We can prove it.



STEVE:  Yeah, it's in the show notes.  It's the way I found it.  It's Web Proxy Auto Discovery protocol, WPAD.  And I talked about how, when you launched IE, there was sometimes a long delay before it started.  And I remember watching, I think it might have been Greg, my tech support guy, at GRC's offices at the time.  He launched IE, and it sat there stalled for a while.  And I said, "Oh, Greg, you've got to turn off auto configure and then IE will launch much faster."



Because what happens is IE sends out a query for WPAD dot and then the machine name dot and then the domain name, looking for a file which contains a script for proxying your communications from inside a corporation.  So Flame sets up a server that responds to these queries within a LAN, which then routes the machine's traffic through it, which allows it to get itself in the man-in-the-middle position.  And then it maliciously signs its own components and sets these up as Windows Auto Update entities and sends them to those machines as security patches from Microsoft.  This is as bad as it gets.



LEO:  Wow.  And this - how long, I mean, could somebody have been using this now?



STEVE:  Yeah.  Yeah, I mean, we know - we've discovered it only because - this was heretofore completely unknown.  And it's only by reverse-engineering Flame, which has...



LEO:  Which, by the way, has been around for years.  So...



STEVE:  Yes.  Yes.



LEO:  This hole has been around for a long time, I presume.



STEVE:  Well, yeah.  The hole's been around forever.



LEO:  Oh, boy.



STEVE:  What wasn't appreciated was that the Terminal Server certificates would be accepted as code-signing certificates.  And that...



LEO:  So to make this clear, this is not a - Microsoft was not helping with Flame.  The authors of Flame discovered...



STEVE:  Well, we don't...



LEO:  We don't know.



STEVE:  We don't know.



LEO:  Right.



STEVE:  Because what Microsoft certainly has, plausible deniability.  If someone, if a U.S. entity said to Microsoft, we need a way to sign code for national security reasons, and you need plausible deniability - because it will be found.  We know it's going to be found.  So when it is, we need to have a way that this wasn't you colluding with the U.S. government, which would of course destroy trust in Microsoft forever.  So this is, I mean, this is just one more mistake.  We've talked about Microsoft mistakes every week.  And so, oh, here, oops, sorry about that.  And so they immediately revoked those certificates that this code signing depends upon.  And that does now shut down the propagation of Flame.  Which is no big deal because, get this, Leo, within hours of the discovery of Flame, the entire command-and-control network shut down.



LEO:  Wow.  So they knew it was discovered.



STEVE:  Yes.



LEO:  That was a response to being discovered.



STEVE:  Yup.  Yup.



LEO:  Oh, wow.



STEVE:  Okay.  So that...



LEO:  So that response, was that a response to news stories?



STEVE:  It was, as I remember, it was Kaspersky's discovery after being asked by the ITU to look into this thing called "Wiper" which was wiping out hard drives.  And that still has not been found because of course now they're off pursuing something way more interesting, which is Flame.  But, yes, within hours of the announcement of this new thing that was even then still unknown, the 80 domains in a command-and-control network went dark.  So...



LEO:  [Laughing]



STEVE:  It just...



LEO:  Oh, man.  There's a movie here, I'll tell you.



STEVE:  Yes.



LEO:  I can see the call going out:  Shut 'er down.



STEVE:  So I did tweet two links earlier today with the details - I'm going to summarize some of them - from Kaspersky Lab that has been and is continuing to reverse-engineer this.  And as I said last week, and here's an example of it, information is going to be coming out incrementally.  We'll certainly be covering it because it's fascinating.  This is the most sophisticated super cyber weapon espionage tool that has ever been seen.  So Kaspersky wrote:



"In collaboration with GoDaddy and OpenDNS, Kaspersky Lab succeeded in sinkholing most of the malicious domains used by Flame's C&C infrastructure.  The following details summarize the results of the analysis.  First, the Flame C&C infrastructure, which had been operating for years, went offline immediately after Kaspersky Lab disclosed the discovery of the malware's existence last week.  Currently there are more than 80 known domains used by Flame for C&C [command-and-control] servers and its related domains, which have been registered between 2008 and 2012.  During the last four years, servers hosting the Flame C&C infrastructure moved between multiple locations, including Hong Kong, Turkey, Germany, Poland, Malaysia, Latvia, the United Kingdom, and Switzerland."



LEO:  Even Switzerland.  Huh.



STEVE:  Yeah.  "The Flame C&C domains were registered with an impressive list of fake [individuals'] identities and with a variety of registrars, going back as far as 2008.  According to Kaspersky Lab's sinkhole, infected users were registered" - so infected users, that is, people who are carrying the Flame virus - "were registered in multiple regions including the Middle East, Europe, North America and Asia Pacific.  The Flame attackers seem to have a high interest in PDF, Office, and AutoCAD drawings.  The data uploaded to the Flame C&C is encrypted using relatively simple algorithms.  Stolen documents are compressed using the open source Zlib and modified PPDM" - they wrote PPDM, but they meant PPMD, which is a partial match statistical compression technology.  And they said, "Windows 7 64-bit, which we previously recommended as a good solution against infections with other malware, seems to be effective against Flame."  So Flame...



LEO:  Really.  That's interesting.



STEVE:  So the 64-bit version of Windows 7, the malware...



LEO:  It's that kernel locking?



STEVE:  Well, it's the malware is targeted at 32-bit code.



LEO:  Ah.



STEVE:  And it's tightly written.



LEO:  It's nothing Microsoft did.



STEVE:  Right.



LEO:  Okay.  Interesting.



STEVE:  So elsewhere, under "Observations," they wrote, "When a computer is infected with Flame, it uses a default configuration which includes five C&C server domains.  Before contacting these servers, the malware validates its Internet connection by trying to access www.microsoft.com, windowsupdate.microsoft.com, and www.verisign.com over HTTPS.  If the connection is successful, it will proceed to talk to the C&C domains.  Some of the fake identities used to register domains include names such as:  Adrien Leroy, Arthur Vangen, George Wirtz..."



LEO:  Vandelay Industries.



STEVE:  Vandelay.



LEO:  These are made up, obviously.



STEVE:  Yeah.  "Ivan Blix, Jerard Ree, Karel Schmid, Maria Weber, Mark Ploder, Mike Bassett" and so on.  "Many of these forged identities have fake addresses in Germany and Austria, notably Vienna.  We do not know why," writes Kaspersky, "Vienna was such an attractive choice for the attackers."



LEO:  Because that's where the sausages come from, of course.



STEVE:  "The fake attackers used addresses of hotels, various shops and organizations, doctors' offices, or simply non-existent addresses."  But interestingly, in many cases, the domains were registered to, for example, valid hotel addresses in Germany and Austria.  So who knows why?  So really interesting stuff we're learning.



LEO:  This is like spy games.  This is good stuff.



STEVE:  And it's true.  I mean, it's real.  Yikes.  So, wow.  In other news, this was something that just surfaced last week after we recorded the podcast.  But, and I attempted to follow it up, but not assiduously.  So I don't have any more details.  But a number of people tweeted the news that IE v10 would have Do Not Track enabled by default.  Which is huge.



LEO:  No kidding.



STEVE:  Yeah.  And again, as we know, it doesn't proactively prohibit, but it proactively declares that its user does not wish to be tracked.  And we're beginning to see maturing behavior on the part of trackers to be responsible in various ways about their behavior relative to the Do Not Track header.  So this is just all good news.



Also Apple released an iOS security paper which I've not yet had the chance to go over, but I wanted to let people know that I was aware of it, and I will go over it, see what it says.  And if it looks like it's worth a podcast, then we'll give it one.  Otherwise I'm sure I'll at least summarize it because it looks like it had lots of interesting stuff.  And that touches on another story I'll be talking about in a second where iOS, due to it being the most secure platform available, is pulling the greatest dollar amount in the sale of exploits from hackers who find them to organizations that want them.



LEO:  Wow.



STEVE:  And government agencies have become the top bidder for these exploits.



LEO:  Great.



STEVE:  I know.  It just gets crazier.  In the news this morning was LinkedIn in the doghouse.  LinkedIn a couple days ago was caught somewhat controversially sending the calendar, all the calendar details of people's LinkedIn profiles to LinkedIn's servers.  LinkedIn defends themselves, saying, well, yes, because we offer the facility to, again, sort of the social networking model, we'll show you the LinkedIn profiles of everyone you're meeting with before you meet with them.  And so to do that we need to know what your meetings are going to be.  So it's like, okay, fine.  Well, in the meantime, six million...



LEO:  Yeah, but they didn't tell anybody they were going to do that.  They just did it.



STEVE:  No, they didn't, yes.



LEO:  Geez, you'd think companies would learn.



STEVE:  Yeah.  Well, here, speaking of learning, 6,458,020 unsalted SHA-1 hashed LinkedIn passwords were recently posted to the Internet.



LEO:  Oh, see, now, I didn't worry because I saw the SHA-1, that they were hashed.



STEVE:  They were not salted.  And they are being decrypted at a high rate.



LEO:  Oh.



STEVE:  Because it's not, yeah, every LinkedIn person listening to this, you should immediately change your password.



LEO:  I'm going to be a honeypot.  I just want to see what they do.



STEVE:  Okay.



LEO:  Because what can they do with my LinkedIn account?  Who cares?



STEVE:  Well, okay.  So consider what they can do if they can log into your account.  Are you using that password anywhere else?



LEO:  No.  I checked immediately to see if I had used a unique password, and I had.



STEVE:  Okay, good.



LEO:  So, I mean, it'd be interesting to see if I get hacked; right?  I mean...



STEVE:  Yeah.  Yeah.



LEO:  I don't really use LinkedIn.  In fact, I canceled it recently, and it for some reason did not cancel.



STEVE:  There's a needle in a haystack aspect because they do have 6.5 million people to work from.  So what's happened...



LEO:  Ah.  So it's only 1 percent.



STEVE:  Yes.  It's a small piece of the entire database.  And you are one in 6.5 million.  What's happened is people have been looking through the list.  And many people are finding the hash of their password in the list.  And passwords that are dumb, like "Facebook" or "linkedinsucks," for example, are examples from YCombinator.  I posted a link to this YCombinator page where there's a really interesting discussion for anyone who wants to pursue this and look into it [news.ycombinator.com/item?id=4073309].  Because it looks like, after the hackers find a match, they put five - they replace the beginning of the hash with five zeroes so that it will no longer match again, to essentially flag it as, okay, we've reversed this hash.  Remember, SHA-1 is among - it's not as bad as MD5.  That's worse.  But SHA-1 is the worst among the two worst hashes LinkedIn could have used without salting it because extremely high-speed hashing hardware exists.  I mean if the NSA in their new Utah facility are doing anything, it's building massive rainbow tables for SHA-1.



LEO:  So here's my question.  There's a site, LeakedIn.org.



STEVE:  Nice.



LEO:  That says "Provide your password (which we hash with JavaScript, use source to verify) or an SHA-1 hash of your password below, and we'll check to see if it's in the database."



STEVE:  Cool.



LEO:  So is this safe?  I mean, I'm going to give them my password.



STEVE:  Yes.  Yes.  I would say it's absolutely safe.



LEO:  I'm going to change it right away anyway, I guess.



STEVE:  Yes.  They're going to do it locally.  I would say change your password, then...



LEO:  Then do it.



STEVE:  ...give them your old password and see if it was there.  There were some posts that I saw where people had changed their password three weeks ago, just coincidentally, and their old password was in this list.  Meaning...



LEO:  Oh, so it's an older database.



STEVE:  Yes, meaning that it's at least three weeks old because in this one instance it had that person's prior - presumably he didn't use a password like "Facebook" that would have been in there anyway.  But they had their old one and not the new one.  Of course, it means nothing not to have the new one because, as you said, it's a small portion of the entire LinkedIn database.



LEO:  And all the hashes begin with four zeroes, or, I mean...



STEVE:  No.



LEO:  No.



STEVE:  No.  What appears to be happening is that...



LEO:  Oh, look.  Look at this.  "Your password was leaked but has not yet been cracked."  Okay, I guess.  Actually it was 10 percent, 6.5 million out of 64 million.  So I had a one in 10 chance.



STEVE:  Ah.



LEO:  Okay.



STEVE:  And yours was there.



LEO:  I'm in there, they say.



STEVE:  Wow.



LEO:  They found my hash.  There's my hash.



STEVE:  Yeah.  So what happens is, after it's been cracked, the crackers replace the first five characters with zeroes, which SHA-1 would have a very low probability of doing.



LEO:  Ah, I get it.  So that's how they know you've been cracked or not.



STEVE:  Yes, it's a simple flag that allows them to quickly do it.  So, wow, yours got reversed.  And was that one - was it complex?  Was it gobbledy-gook?  Or was it something that was like dictionary?



LEO:  No, it was gobbledy-gook.  It was a generated pass.



STEVE:  Wow.  And, see, that just demonstrates that SHA-1 is that insecure.  It is so fast...



LEO:  Well, wait a minute.  They said they hadn't been cracked yet.



STEVE:  Oh, hadn't.  Well, no, but many...



LEO:  Had not been cracked.



STEVE:  Oh, that's a very good point because things like "Facebook" and "linkedinsucks" and so forth...



LEO:  Those are easy to crack.



STEVE:  Have been cracked, yes.



LEO:  Mine was a completely random long password that has apparently not been cracked yet.



STEVE:  Which is as strong as you could get it against SHA-1.



LEO:  Right.



STEVE:  It would take a brute-force...



LEO:  So explain to me - you've explained this before - why salting is necessary, why SHA-1 isn't - SHA-1 is secure.  It's a secure hash.



STEVE:  It's, okay, it's secure.  The problem is that it's old, and it's well known.  And many organizations like, well, and once upon a time many operating systems were using it to hash passwords without salt.



LEO:  Right.



STEVE:  So the NSA could build a table where they manually put in every combination of, like, just start at A, B, C, D, E, standard brute-force password cracking, run it through SHA and record the output, and build a dictionary which they then index in the sequence of the output.  So that, when they have a hash, they can look that up in this index and immediately see what password generates the hash.  They wouldn't know that that was your password, but they would know that that password generates the same hash, which would then allow them to impersonate somebody using a password that generated that hash.  So that would allow them, for example, to log in.



So what salting does is it just - it's like it customizes SHA-1.  If you did a pseudorandom salt, meaning that for any password the user puts in, before hashing, you append your own gobbledy-gook to it, then that would generate a different SHA-1 hash than if somebody just put "Facebook" into SHA-1 and got Facebook's SHA-1 hash.  So if the bad guys knew what the gobbledy-gook was, they could still do forward attacks.  But it's much less likely that the bad guys would know what your salt was than just obtaining the database of passwords.  Which looks like...



LEO:  Now, if the salt was stored with the database, that would be bad.



STEVE:  That would be bad.  And again, further dumbness.  But hopefully somebody who had the smarts to do salting would understand the need to separate the salt from the database.  And in this case we know that it was not salted because you can put "Facebook" into SHA-1 and get the same hash as one sitting there in the LinkedIn database.



LEO:  So that's how this LeakedIn.org site works.  I gave it my password.  It ran an SHA-1 hash against it...



STEVE:  Right on your local browser.



LEO:  ...in JavaScript and then presented me with the hash, which then I said, okay, now search for the hash, and it said, yeah, the hash was in the database.



STEVE:  Exactly.



LEO:  And so if you could do it forward, you could presumably do it backward.  LeakedIn.org.



STEVE:  Yeah.



LEO:  That was fun.  I changed my password.  I decided not to be a honeypot.



STEVE:  That's good.  Because, I mean, if you - that's incremental.  Incremental loss of privacy is still a loss.  It's not that you can do it backwards, it's that you can do everything forwards.  So you keep putting things in...



LEO:  You keep trying stuff.  Got it.



STEVE:  Yes.  Try things in a forward direction and see what comes out.



LEO:  Which is why my truly random password is going to be very difficult because they would have to try stuff.  It would only be bad passwords that would be guessed.



STEVE:  Exactly.  And so the bad passwords are all being found fast because that's what they're trying first.



LEO:  So they'll use presumably a dictionary of some kind where they just try common passwords like "abc123" or "adasdf."



STEVE:  Yeah.  And apparently they did try "linkedinsucks" because it's one of the ones that has been cracked.



LEO:  I bet you a lot of people had that password.  So if you did as I did, and I've just done again, I used LastPass to randomly generate a password.  It seems highly unlikely that a good random password of sufficient length would be guessed.



STEVE:  Very, very unlikely.  And also consider this is not a high-value get anyway.



LEO:  Right, right.  There's no credit card in here.



STEVE:  I mean, you were almost - you were almost not caring if someone did get your password.  It's like, eh, let's see if I get hacked.  Because it's LinkedIn, who cares?



LEO:  Who cares, exactly.



STEVE:  So, yeah, exactly.  So if it were really high-value database, then first of all one would hope that the security would be better.  But then you really would want to change your password.  And there would be more motivation on the part of the attackers to crack people's hashes and figure out what their passwords were.  But in this case - and we're presuming the usernames were stolen, too.  They only posted the passwords.  The presumption is they have matching usernames.  Thus the reason they're going through all this trouble of tracking these things down.  So I think next week we will be saying, well, here's the damage that was done because lots of LinkedIn users are going to find their accounts were hacked.



LEO:  Yeah.  Wow.  It's kind of a double strike, as you said, because of this calendar stuff.  Maybe, I would guess, a few people would take the opportunity to cancel their LinkedIn account at this point.



STEVE:  Well, yes.



LEO:  That'd be another thing you could do.



STEVE:  And it is definitely a black eye.  It is way, we're way beyond the point where there is any excuse for this being the - I'll put "security" in quotes - the "security" architecture for LinkedIn, a substantial, out-in-the-front-of-the-pack, state-of-the-art, web-based system.  To be having unsalted SHA passwords, that's nuts.  I mean, it's just like - that's a decade ago technology.  All the OSes are off of that.  Everyone who's doing security, knows what they're doing, are off of that.  So this was just written by somebody in the beginning who didn't think it was going to amount to much, and it did.  Briefly.



LEO:  Actually LinkedIn can tweet on my behalf, so I am glad I did not let somebody use my account.



STEVE:  Ah, yup.



LEO:  That wouldn't be good.



STEVE:  That'd not be good.



LEO:  No.



STEVE:  So there was an article a couple weeks ago that I meant to talk about, and it just sort of fell through the cracks, but I saw it again, and I thought, okay, I just need to mention this.  And that was - and this is all in this domain that we're in today, talking about state-sponsored cyberwar.  And that was the question of Chinese putting backdoors in our chips.  There was a rather inflammatory claim made by a company that reverse-engineers chips by popping the lids off of them and looking at them and essentially figuring out what the schematic is of the integrated chip by peeling off the layers of metallization that glue these chips together.  And then they've got technology for automating this.  And they made the claim that chips being made in China and installed in U.S. networking equipment had backdoors.  Now, the good news...



LEO:  Well, then.  Hello there.



STEVE:  Yes.  Now...



LEO:  That's nice.



STEVE:  So here I am laughing that Iran's government agency people are using Windows that's made in Seattle at Microsoft.  At the same time, we obviously have an entire infrastructure in the United States of chips from China.



LEO:  Now, you'd need physical access to the backdoor; right?



STEVE:  Well, okay.  So it now looks like this was a false positive, that in fact the interface that this hardware reverse-engineering company found was - it was a known diagnostic portal into the chip.



LEO:  Oh.  Not malicious, in other words.



STEVE:  Exactly.  It was part of the original design, not something put in afterwards.  But yes, you would - no, you wouldn't need - presumably there was a crypto key that you could use for accessing this remotely.  So I'm not wanting to be too quick to laugh here at foreign governments using United States operating system because we're using chips which have all come from a substantial foreign government, and we don't know what has been done to them.  I mean, you'd have to open them up.  I mean, the problem is finding out.  You have to open them up and reverse-engineer every single chip that you're getting, and that's not feasible.



So what it really says is, just as it's crazy for a nation-state hostile to the United States, like Iran, to be using an operating system developed and sourced by an American company, it is every bit as crazy for the U.S. government and the critical infrastructure in the United States to be using networking hardware which comes from anywhere outside of our own borders.  So, yow.  I mean, these - I'm getting a real sense...



LEO:  Everything's made in China, by the way, we should say.



STEVE:  These chickens - I know.  



LEO:  Yeah, these are chips in your phone and everything.



STEVE:  Yup, yup.



LEO:  Although most of the Apple stuff...



STEVE:  It may have a domestic label on it.  It may say Cisco or Linksys or D-Link or Netgear.  But every component is of Chinese origin.



LEO:  Amazing.



STEVE:  Yeah.  So what is it, the phrase, "the chickens coming home to roost," Leo, I think is the - it's a little scary.



LEO:  [Clucking]



STEVE:  So Forbes, a couple days ago, Andy Greenberg sort of is their software malware exploits guy.  He did a really interesting article, "Shopping for Zero-Days:  A Price List for Hackers' Secret Software Exploits."  So this is Forbes.com, that's a real magazine.  And this is, again, investigative journalism.  ZDNet picked up on the story.  Their title of their take on this was "U.S. Government Pays $250,000 for iOS Exploit."  And their summary said, "Selling exploits to government agencies is becoming a more and more lucrative business.  Hackers get paid anywhere between $5,000 and $250,000 for a security vulnerability."



And Leo, if you'll click the link that I've got there, take a look at that chart because what the article explains is that there's a hierarchy of payment value where the more difficult the exploits are to get and to find and to create, the more valuable they are on this gray market.  And many hackers use third-party go-betweens to negotiate on their behalf with foreign governments.  Apparently, Chinese hackers pretty exclusively sell only to the Chinese government.  But other hackers are selling to various foreign powers.  [http://www.zdnet.com/blog/security/us-government-pays-250000-for-ios-exploit/11044]



LEO:  And it's big bucks.



STEVE:  And so this...



LEO:  Could be a quarter million dollars for a really juicy one in iOS.



STEVE:  Yes.  I mean, and they're - yes.  I mean, that's a quarter million dollars for finding something.  Now, some of the terms are really interesting.  For example, you would like to know that this bad guy is not selling, is not reselling this to many people.  So one of the ways this is set up is that only as long as the exploit is not uncovered do payments continue.  So essentially, until it goes public, the malware or the exploit discoverer receives periodic payments from the one-time license that they have made to a foreign government.  So clearly it's in their interest not to over-disclose it because it would get overused and then discovered and then all payments stop.  And so, for example, it turns out that the Russian mafia that has traditionally been a big buyer of these is no longer able to purchase them at the price they were because they tended to immediately use and abuse them, meaning that they had a very short payment life, and so they didn't generate nearly the revenue for the discoverers.  But, I mean, listen to what I'm saying.  This is crazy.  This says there is a mature...



LEO:  It's capitalism.



STEVE:  [Laughing] Oh.  It's a mature...



LEO:  It's really amazing.



STEVE:  ...functioning marketplace, a global marketplace for unknown defects in highly used operating system platforms which nation states are purchasing in order to launch and in order to build super cyber weapons for espionage.  I mean, Leo...



LEO:  Makes sense to me.



STEVE:  In the past this would have just been science fiction.



LEO:  Yeah.  Wow.



STEVE:  This is mind-boggling.



LEO:  Wow.



STEVE:  Yeah.  And Bruce Schneier weighed in very soberly four days ago.  Oh, no, I'm sorry, more than - on April 2.  He cites these articles.  He says, "This article talks about legitimate companies buying zero-day exploits, including the fact that 'an undisclosed U.S. government contractor recently paid $250,000 for an iOS exploit.'"  And then he quotes it, saying, "The price goes up if the hack is exclusive, works on the latest version of the software, and is unknown to the developer of that particular software."  Oh, by the way, Leo, I don't know if you noted that Adobe hacks are the least valuable.



LEO:  Easy to come by.



STEVE:  Uh-huh.



LEO:  It's directly related to how hard it is to hack, I think; right?



STEVE:  Exactly.



LEO:  Because iOS is the top.  Bonus.  Actually, this would be a - this is a valuable chart, yeah, because just above Adobe Reader, on the bottom, in a way, Mac OS X, then Android, then Flash or Java, Microsoft Word, Windows, Firefox or Safari, Chrome or Internet Explorer, then iOS.



STEVE:  Yup, going up in difficulty and platform size.



LEO:  This has to be a little tempting to those security researchers.  I mean...



STEVE:  Well, Leo, think about it.  A quarter million dollars.



LEO:  It's a lot of money.



STEVE:  Yeah.



LEO:  Please don't die.  Please, I beg of you.



STEVE:  You know.  And, I mean, it's our tax dollars hard at work, Leo.



LEO:  Yeah.  Well...



STEVE:  You and I are paying for it because it's a government contractor that's buying these in order to equip our country's cyber weapons.  I just - this just makes my eyes cross.  Anyway, just to finish this paragraph, "Also, more popular software results in a higher payout.  Sometimes the money is paid in installments, which keep coming as long as the hack does not get patched by the original software developer."



And so Bruce continues, "Yes, I know that vendors will pay bounties for exploits.  And I'm sure there are a lot of government agencies around the world who want zero-day exploits for both espionage and cyber weapons.  But I just don't see that much value in buying an exploit from random hackers around the world."  And there he has a point.  Except that the economics, as I explained earlier, really do inure to the benefit of a hacker behaving himself.  So I can see that, too.



He says, "These things only have value until they're patched, and a known exploit - even if it is just known by the seller - is much more likely to get patched.  I can much more easily see a criminal organization deciding that the exploit has significant value before that happens.  Government agencies are playing a much longer game.  And I would expect that most governments have their own hackers who are finding their own exploits.  One, cheaper.  And two, only known within that government."  So really, really interesting stuff.



LEO:  Really is.  Surprising.



STEVE:  And I've got email from Kevin Rose.



LEO:  Now, that can't be THE Kevin Rose.



STEVE:  And it wasn't.  I asked.  He said...



LEO:  I know Kevin uses SpinRite, but I just - I don't - yeah.



STEVE:  Yeah, he said, "A very fast SpinRite recovery," sent it on May 14th.  And he wrote, this Kevin Rose wrote, "While SpinRite has a history of going slow, it can also fix issues rather quickly.  On an older computer I had BSOD at boot-up, unmountable boot volume.  The first thing I did was boot it into my trusty copy of SpinRite and ran it on Level 2.  40 minutes later it was complete, with one unrecovered sector, though the report did say that most of the data had been recovered.  I was able to boot back into Windows and back up all the data from the 40GB hard drive, then run SpinRite again on Level 4.  The computer is now working normally as my VPN server."  So when I read that, I thought, huh, well, guy's got a VPN server.  That kind of sounds maybe like Kevin.



LEO:  Yeah.



STEVE:  So I said - I wrote back, I said, "Hey, Kevin.  I don't know whether this is THE Kevin Rose, but either way, thanks for sharing your success story.  I'm so very glad that SpinRite was able to help you."  And he replied, "Nope, this is not the more famous Kevin Rose.  I wonder if he," he says, "I wonder if he uses SpinRite."



LEO:  Oh, he does.  I know he does.



STEVE:  And you've confirmed that.



LEO:  Well, he used it on The Screensavers.  We used it all the time.



STEVE:  Ah, right.  And so he said, "This is one of the best" - this is the non-Kevin Rose Kevin Rose said, "This is one of the best programs I have ever used.  While it is not used as often as many other programs, when it is used, it is easily worth five times its price.  To date, SpinRite has saved a total of five hard drives for me:  two desktop hard drives, 40GB and a terabyte drive; one 320GB hard drive in my old laptop; and two external hard drives which, oddly enough, were the two drives I have that did not have a fan in the external enclosure.  Using eSATA to the drive shows that during normal use they were within 1 degree C of their overheating temperature."  So anyway, non-Kevin, thank you very much for your SpinRite story.  And thank you, Leo, for confirming that THE Kevin Rose is also a SpinRite user.



LEO:  Of course he is.



STEVE:  That's cool.



LEO:  All right, Steve.  I've got questions.



STEVE:  Cool.



LEO:  12 of them, starting with Scott Maser in Colorado Springs with a question about the "DynaStat" screen on SpinRite:  Steve, I'm running SpinRite on a drive that failed miserably.  It was a Western Digital Network Storage drive that had some data I am trying to recover.  Backups.  The SpinRite - see, this is - this probably was a backup drive.  It was his network storage drive.  And yet...



STEVE:  They go bad, too.



LEO:  They go bad, too.  One copy of anything, whatever drive it's on, is still not a backup.  The SpinRite screen is covered with a lot of "B's" - that means bad - and the time remaining counter keeps going up as it hits the "B" sectors.  I fully expect to let this run for a while just to see what I get.  And by the way, Scott, could be a while.  Could be a long time.  I've been trying to decipher the DynaStat screen.  I'm confused with the bit numbering.  I see bits 0 through 32.  Isn't that one too many bits if I'm looking at things using a 32-bit word?  Is there a reason there are 33 bits on the screen, Steve?  33 bits?



STEVE:  Okay.  There is a reason.  That's how many would fit.



LEO:  Oh [laughing].



STEVE:  Okay.  The DynaStat screen, it's mostly just eyewash.  I mean, it is showing you what's going on.  But mostly it's - "DynaStat" stands for Dynamic Statistics, and it's a technique that is unique to SpinRite, which allows SpinRite to often recover unreadable data where at no time is the sector readable, but SpinRite can figure out what it was when it was readable.  And because this takes some time, it can take up to 2,000 samples of the sector, I had to have SpinRite show you something while it was running and doing this.  And so the DynaStat...



LEO:  Are you saying it's eye candy?



STEVE:  Well, yeah.  I mean, it's true.  It's true eye candy.  But you shouldn't try to, like, figure out what it means.



LEO:  Right.



STEVE:  It's the, first of all, a sector that's 512 bytes is 4096 bits in a stream.  Bits are stored, not as, like, bytes at a time, like 8 bits abreast.  They are actually stored in a linear bit string that has no byte boundaries.  So that's why 33 bits is as good as 34 or 31 or 32.  It's just SpinRite is showing you where in the 4096-bit stream, the problem begins that SpinRite has located.  And it's able actually to zero in on the problem and start working on it.  And so what looks sort of like an oscilloscope diagram are the statistical probabilities of the bits from the first bad bit being zeros and ones.  So it's, I mean, what it's showing you is true.  It's sort of a - it's a viewport into the database, the statistical database that SpinRite is building over time as it analyzes that sector in order to try to recover its data.



So that's a little tutorial on the DynaStat screen.  It's, again, it's mostly something for you to look at.  Just like, be patient, SpinRite's going to recover this sector if there's any way possible.  And in fact it's able to even - SpinRite will give you the data out of those 4096 bits that it can, even if it can't get all of them, which is, again, another very unique thing about SpinRite that often allows recovery to occur even when the sector could never, ever be read correctly and corrected.  For example, if this was a chunk of a directory, well, you might get most of the files that were linked from that branch of the directory, and that's more valuable than getting none of them.  So, or like having the directory stop at that part of the file system.  So that's just a reason why SpinRite's able to so often pull off the miracles that it is.



LEO:  Question 2 from Jason Varner, Pennsylvania, USA.  Jason says, "I wanted to mention AES Crypt awesomeness.  Awesome.  Dear Steve, after hearing you discuss Duplicati on a recent episode of Security Now!, I decided to try it out.  It's another one of those cloud storage systems; right?



STEVE:  It's a frontend for S3 that is absolutely multiplatform, which is really nice.



LEO:  While I wasn't particularly impressed by the Linux (Ubuntu in my case) version of the GUI interface, looking into Duplicati did lead to the discovery of the awesome AES Crypt piece of software [aescrypt.com].  As a relatively recent Security Now! listener, I don't know if you've ever discussed AES Crypt before, but I wanted to make sure you were aware of this elegant, simple solution for AES 256-bit file encryption.  I'm assuming this encryption package provided is solid - Linux users ONLY have the option of downloading and compiling the source code - but wanted to ask for your feedback on AES Crypt.  As my need for a remote backup of my data is not so sensitive that daily or even weekly backups are necessary, I am now employing the following completely free and rather simple remote backup process (hopefully TNO compliant):   



1.  Make a ZIP file of directories to be remotely backed up, with the date of the snapshot included in the filename, e.g., BACKUP.20120529.zip.



2.  Encrypt that ZIP file using AES Crypt and a strong password, which gives you the same file with a .aes extension.



3.  Upload that file to the BACKUPS folder on Google Drive.



While this solution isn't the most accommodating to the need for frequent backups, i.e., the entire backup file has to be uploaded each time, and you have to think to do it and blah blah blah, it fits my needs.  I guess he could write a cron job to do this.



STEVE:  Yeah.



LEO:  Your feedback on the AES Crypt software and my process would be greatly appreciated.  Jason Varner.



STEVE:  So I wanted to make sure we pointed people to AES Crypt.  I use it.



LEO:  Oh.



STEVE:  And I like it.



LEO:  Better than TrueCrypt?



STEVE:  Well, it's entirely different.  It is a very simple, lightweight, bulletproof, AES cipher application, and cross platform:  Windows, Mac, it's available in Java, in C-sharp, also for Linux.  It's open source.  So what it is, I mean, we've talked a lot about what AES encryption is.  This is simply a utility to give end users access to AES 256-bit file encryption.  So it's just a - it's as simple as you use this in the same way that you use ZIP to zip up a bunch of files, you use this to encrypt a file.  It asks you for a password.  And that password is hashed and then used as the key for the encryption.  And no force on Earth, as far as we know, if you use a strong password, is able to decrypt it.  So it's absolutely bulletproof.  Under Windows, the app does a whole bunch of nice things with - it's got a nice UI.  And it also will put things in the context menu so you can right-click on a file and say "AES Crypt This," and it will encrypt it and decrypt it and so forth.



So it's such a great - I wanted to bring it up, thank Jason for mentioning it.  This came up in the context of Duplicati because our listeners will remember, if they looked into Duplicati further, that Duplicati bundles the file format into their backend, that is, the files that Duplicati uses to store at Amazon is AES Crypt compatibly encrypted because the other thing that AES Crypt has done is to publish their file format.  So the Duplicati people said, hey, rather than reinventing the wheel, let's use the AES Crypt file format and the cipher, which is as good as anything else.



And the cool advantage to that is, if anything, for any reason at all, you ever couldn't use Duplicati, you still have full access to those files because you could use the standalone AES Crypt to, after you bring them back from Amazon, to decrypt them.  So, and it's also just a really nice standalone encryption tool.  So I just - I thought I wanted to give everyone a pointer to that.



LEO:  Ranmadhu in Australia wonders:  How does Google know you're using DNSChanger?  That's the malware that Google is now detecting and announcing.  In Security Now! 354 you were talking about how Google has come up with a method to determine if someone's using the wrong DNS servers.  I'm completely at a loss as to how they can do this.  I wasn't aware that a remote server could tell which DNS server a client was using.  It would be great if you could elaborate.  Thanks, and keep up the great work with the show.



STEVE:  Well, so I have not looked specifically to see how Google does this.  But let's remember that Google is, if anyone in the world is, is running script on your browser.  I mean, Google's whole - the whole focus is turning your browser into a desktop surrogate, essentially.  So I was thinking, from my remembering JavaScript, and it's been a while since I've coded anything in JavaScript, I don't think you can get low level enough for JavaScript to see the IP address of a DNS entry that is looked up.  But, for example, Google could include some items on the page which are a domain that is resolved by the bad guys.



Now, if your DNS server, whatever DNS server you were using, resolved one of the bad IPs for one of those domains, then that would tell Google you were using DNSChanger DNS servers still.  But I don't know that it's possible for JavaScript to determine what the IP is.  Now, maybe they're playing some games beyond JavaScript.  Or all that would be necessary would be if Google found something that those servers returned differently, because of their maliciousness, than good servers.  And I don't know whether there is, like, something Google knows that we don't know.



But so my point is that, if Google's page asked for a resource on a domain which was like a different size or in any way different than what a valid non-DNSChanger, DNS server would return, then they could certainly detect - they could certainly tell from the nature of what was looked up by that DNS server, whether it was DNSChanger or not.  So essentially, when you're running - even though the Google server can't tell, you need to remember that when we're going to Google, we're running Google's script on our browser.  And then there's all kinds of things that they're able to do.



LEO:  It's all sorts of magic.



STEVE:  Yeah.



LEO:  So it would require that JavaScript would return this information.  Returns a lot of information.



STEVE:  It does.  I don't think, I mean, Java, the Java language definitely could do this.  I don't think...



LEO:  JavaScript is what they use.



STEVE:  ...a JavaScript allows you to look up the IP for a domain name.  But maybe it does, in which case it'd be even simpler to just see if it's among those, the IPs.  They might send it back to Google, and Google looks to see if it's among those.  But again, just something, any behavior that was different about those servers, and specifically like what they returned, that would be enough to tip off that you were using those malicious servers.



LEO:  Really interesting, isn't it.



STEVE:  Yeah.



LEO:  Very interesting.



STEVE:  Love the technology, Leo, love the tech.



LEO:  Yeah, yeah, yeah.  Quib.  Our next question is from Quib in Southern California, who says:  Greetings from the past!  Steve, I discovered your podcast a few weeks ago, absolutely love it.  Decided to take a casual sip from the fire hose of the episode archive.  Well, it is a fire hose.  There are, what, 356 total episodes.



STEVE:  Yeah.



LEO:  He says: I'm currently on 74, which is back in the Vista pre-release days.  Wow.



STEVE:  It is a bit of a Wayback Machine that he has.



LEO:  Yeah, I forgot we go back that far.  You sound so optimistic about how the new architecture will protect the OS from all sorts of nasty things.  I've only listened to a few new episodes, but I do know you're still doggedly hanging onto XP.  I never would have guessed that five years from where I am right now, you would be so against the new platform.  For the benefit of those who haven't yet listened to the other episodes, the remaining episodes, would you give the listeners a brief overview of what went wrong?  Did Microsoft get lax and start letting every passerby drop code into the kernel?  Did the creators of malware find a way to bust through the protection?  Or was it really an improvement for security, but other irritating issues kept you from making the switch?  Thanks for the show.  You are a great service to the Intertubes, says Quib.



STEVE:  So, okay.  Microsoft clearly improved security dramatically from XP to Vista, and fixed the things that they really didn't do that well, sort of maybe went overboard with Vista, in 7, making 7 more friendly.  Yet we don't see attacks which are only effective against XP.  All the attacks that we see are always effective against all of them.  So when you think about it, there isn't a differentiation.  I'm not seeing anything that gets 7 that doesn't also get XP.  Why?  Because it's still the same operating system.  Microsoft comes up with new layers of eye candy and new UI features, but nothing fundamentally changes.  I mean, yes, Address Space Layout Randomization gets better, and DEP is more strongly enforced, and a few things like that.  But they can't really change much without breaking all of the legacy stuff.  So they're limited in what they're able to do.  And you could argue that they're sort of running out of things to do at this point.  So first of all, looking back at all the patches we've discussed in the last year, nothing is XP only.  I can't think of anything that only affected XP.



LEO:  How interesting.



STEVE:  It's always all of them.  And so here I am using XP, not seeing any effective improvement.  I mean, these are, oh, look, we added a bunch of security features.  Everybody move.  It's like, okay, let's see.  Nothing showed up.



LEO:  Nothing.



STEVE:  Nothing seems to be actually more secure.  And I don't see anything that I want over on Windows, lord knows on Vista, but even on 7.  I mean, it looks different, but it's just in my way more.  So it isn't demonstrating better security.  Now, that will change in two years or three years, whenever it is that patches stop being offered for SP3.  So at that point I'll think, okay.  Either the bad guys will have moved off to Windows 8, and no one will even be bothering to attack XP anymore because it'll be more like Windows 98 is, for which none of these things are effective because it'll just have enough different DNA that it can't be infected.  Or maybe I'll switch.  I'm not sure.  But at the moment, XP is the same as 7 in every way I can tell.  Everything I want to do is compatible with XP still.  So there's no incompatibility problems.  And there's no demonstrated actual effective increase in security.  So why would I move?



LEO:  Let me...



STEVE:  By the way, these are all free for me.  I'm an MSDN subscriber.  I pay Microsoft...



LEO:  So you could move.  It's not like you're spending more money.



STEVE:  ...$2,700 a year to have access to all their OSes.  So, yeah, it's free.  Costs me nothing to move.  But except my time because I'm fighting with 7.  I mean, it just looks like a toy to me more and more.  So, I mean, I felt that way about XP compared to Windows 2000.  So I'm just a curmudgeon by nature.  But at this point I'm just digging my heels in.  It's like, unh-unh.  This thing works.



LEO:  Well, at some point you're going to have to.  I think there's only two years left in the update cycle.



STEVE:  Only.  Leo, come on.



LEO:  Hey, this is from five years ago this guy is writing, so two years is nothing.  It's like the blink of an eye.



STEVE:  Yup.



LEO:  Bob Harris in New England mentions that the TrueCrypt/Dropbox trick could corrupt users' data:  Steve, in Security Now! Episode 350 - we've got a bunch of oldsters here - you mentioned a TrueCrypt/Dropbox trick which could maybe result in some bad things.  The problem is if the folder sync utility manages to transfer an actively mounted container file system, then it would be possible for the user to mount the container file system on a different machine or machines concurrently with the original.  The danger here is there is no coordination between the systems.  The algorithms used to allocate new files and storage are going to be the same, when the systems are the same OS.  So if two or more systems try to use the mounted container file, creating new files or allocating storage, they are likely to choose the same blocks.  The last system to sync their changes wins - maybe.



It's more likely that the files will be lost, or only partially there, or have the mixed contents of several files in them.  It also is possible that the file system metadata could become corrupt such that even a chkdsk or fsck cannot repair the file system, losing all the users' data.  And even if the user promises they will never mount the container file system on more than one system concurrently, hey, accidents happen.  It might only take one "oops!" to corrupt the data.  This dangerous trick could be tried with any number of container file systems, e.g., an encrypted Mac OS X Sparse Bundle, some of which might just allow Dropbox or similar folder synching utilities to transfer data for an active mounted file system.  I'm not sure I understand this, Steve.  Maybe you'd better explain.



STEVE:  Yeah.  So this was so obvious to me that it made me shudder.  And it was definitely worth mentioning to people, although I think we're protected from it.  First of all, so what he's talking about is that - I know that some people are doing this.  But I believe that you cannot both have the file in Dropbox and mounted by TrueCrypt.  So what he's talking about is the danger of taking a file and making it a container file for TrueCrypt, which gives you, when mounted, a drive letter, and having it also sitting in Dropbox and visible to other machines.  Now - or copied to other machines, as I understand that's what Dropbox does is it clones it to your drives on other machines, where it's accessible.  It is a nasty hack, the idea of mounting a drive which is a file that's in a shared resource that was never really designed to be shared.  But Dropbox must have provision for handling desynchronized changes among files.  So this might be handled by TrueCrypt.  But, I mean, sorry, by Dropbox.  Or it may just not be possible to have TrueCrypt mount it when the file is, like, opened by somebody else, so that there's some sort of exclusivity.



LEO:  But Bob, there is some file locking.  I think so.



STEVE:  There must be file locking.  But Bob is correct.  Imagine the horror of this file, which is nothing but the sectors of a file system, being simultaneously available to different machines that each believe it is their file system.  That is, there's no notion that this is simultaneously - any other machine has access to its sectors.  Because that's what TrueCrypt is doing.  Its mounting the file system means that the blocks of data in the file are virtual sectors of a virtual hard disk.



So the reason I was made to shudder is that, I mean, it's like a classic, like cache coherency problem or cache access conflict.  Any file system is excruciatingly careful to only allow access through a given port so that all of the activities behind the scenes are synchronized through that one viewpoint.  And this would be like having multiple views into the raw data.  And if that were possible, nothing would prevent multiple operating systems from just going in and, like, allocating the same sectors for new files and just overwriting each other when they wrote those back.  Which would be horrific.



Now, the fact that this apparently isn't a problem and doesn't happen makes me think, as you said, Leo, there's - and I think for Dropbox to be effective they have to have somehow managed concurrent access to shared files.  So something resolves this for people.  But I just wanted to make sure, for anyone who is relying on this, that you maybe test this or make sure that you're safe in using this, what is otherwise kind of a cool hack.



LEO:  What Dropbox does for me, if there's a conflict, is it creates a new file that says - let's see if I can find one here, a conflict file.



STEVE:  Ah, so it branches off.



LEO:  It branches.  And it says there's a conflict.  



STEVE:  Okay.



LEO:  Which isn't that helpful because, you know. 



STEVE:  Yeah, then you...



LEO:  How do you merge the two?



STEVE:  Essentially you've forked your file system.



LEO:  Yeah, and that means you're forked.



STEVE:  Yeah.



LEO:  Yes.  Moving along.  Creighton in Arizona points us to a new CAPTCHA solution.  Steve, the following site may interest you.  A company is unveiling a series of drag-and-drop logic puzzles to prove you're human.  Now didn't I just read that CAPTCHA...



STEVE:  Yes.



LEO:  ...had been broken?



STEVE:  Yes.  Google has been having a real problem with their...



LEO:  reCAPTCHA.



STEVE:  Yeah, their reCAPTCHA solution.



LEO:  Which they got from Carnegie Mellon and I really like.



STEVE:  Yeah.  And it was great.  But, you know.  And we've discussed CAPTCHA a lot because the whole problem of bots getting increasingly clever is prevalent.  We talked about there was that one that was kind of like a waving flag one that I liked a lot.  This one is, again, another take.  It's AreYouAHuman.com, just demonstrates their technique.  I'm not that impressed with it.  I mean, what impressed me, Leo, is that it's so hard to tell.



LEO:  I don't know, I've got a stack of pancakes.



STEVE:  Okay.



LEO:  I've got some tools, including a daisy, a saw, butter, and maple syrup.  And I guess the presumption is, if you figure out the butter and the maple syrup work better than the saw and the daisy...



STEVE:  Yeah, I got a pizza when I tried it yesterday.  And I got pepperoni and cheese, I think, maybe tomato sauce, and a few non things.  And they're all kind of drifting around.



LEO:  That's kind of cool.



STEVE:  I mean, it is.  But again, I wonder, okay, how hard is that?



LEO:  Well, here's the way you break this stuff.  You use a human.



STEVE:  Yeah, that's a problem.



LEO:  You put up a porn site, or a fake porn site. 



STEVE:  You redirect to - yes, right.



LEO:  And you put this CAPTCHA on it as an iFrame.



STEVE:  Or you pay people in Russia...



LEO:  Or you just pay people.



STEVE:  There is a site where you can make money, it's a Russian site, you sit there and you solve these CAPTCHAs in real time, and you're only paid if you solve it quickly and if it's correct.  Then you get some money added to your account.  It's a little micropayment system.  And so it's - and these are people, this is quote, "a job," unquote.  And that's what they're doing.  And these are the human front-end for a bot network which is then using this to create accounts under - in fact it was Gmail you read about because Google Mail is generally not - has a lot of spam.  And so it's generally regarded as safe.  And unfortunately, they've been having problems with their CAPTCHAs.  You're right.  Ultimately there's no solution.



LEO:  CAPTCHA is stupid.  Stop using it.  Thank you.



STEVE:  And it's annoying.  Because, I mean, I'm often, I look, and I go what the heck is that?  I don't know what...



LEO:  If it's a high-value target, it's easy to break.  And  if it's not, stop bugging me.



STEVE:  Well, isn't this an interesting problem that we're having, that it isn't - well, but think about it.  It's also interesting that it is actually difficult to differentiate a human from a computer.



LEO:  Right.  It's called the Turing Test.  In reverse.



STEVE:  Yes, they could do so much.



LEO:  DarthNader in Minneapolis says Password Haystacks are too good of an idea:  Steve, remember when you were talking about passwords?  Well, it seems your idea was too good because, like, many good things, it's been foiled by those who could most benefit from it.  My national bank chain made me change my password today, and their rules now include one about how you cannot use the same character three or more times in a row, eliminating my ability to use a string of the same character as a haystack.  They also told me that I cannot change my password more than once in a 24-hour period, eliminating my ability to change my password until my desired password was out of the "recent passwords" list.  Well, that's good.  Well, I could still do it, but it would take over a week to do.  So I guess he's one of those guys who wants to reuse his old password?



STEVE:  Yeah.



LEO:  Next time you have a good idea, please don't take it to the mainstream media because, once the public knows about it, so does my bank.  I'd like to be able to use your good ideas.  Actually, well, all right, I'll let you answer this one.



STEVE:  Well, I was going to say, first of all, I doubt, I mean, it's flattering, but I doubt that...



LEO:  They're just trying to keep you from doing 1111111111.



STEVE:  Yes.  GRC and Password Haystacks probably isn't the reason the bank made this change.  And I would note that no one said you had to use dot dot dot dot dot dot dot dot...



LEO:  Right.



STEVE:  ...to pad.



LEO:  I don't use repeating characters.



STEVE:  Exactly.  And I don't either.  That was just an example of a way of padding.  So you can definitely pad with something a little more clever.  And I'm not going to offer any suggestions because anyone listening can figure out their own scheme, and I'd rather not put one out there that people go, oh, I'll use that one.  So, yeah.  Certainly there are ways around that.  And it sounds to me like the bank has got good security policies.  These are the sort of things we want them to do.



LEO:  Somebody in the chatroom just sent me a password policy from - I guess it's from the state of Texas.  Actually it looks like Texas State.  Or maybe, yeah, it's portal.computerscience.oag.state.texas.us.  Password has to be exactly eight characters long.  I'm not sure what that's all about.



STEVE:  Oh, my god.



LEO:  It must contain at least one letter, one number, and one special character.  But the only special characters allowed are @, #, and $.  A special character cannot be located in the first or last position.  Okay, that means two through seven.  Two of the same characters sitting next to each other are considered to be a set.  No sets are allowed.  Avoid using names such as your name, userID, or the name of your company or employer.  Other words that cannot be used are Texas, child, and the months of the year.  A new password cannot be too similar to the previous password.  A password can be changed voluntarily once in a 15-day period.  The previous eight passwords cannot be reused.  This is just brain-dead.



STEVE:  Oh, my god.



LEO:  Some good stuff, but mostly stupid.



STEVE:  Okay.  So let's wrap up with this next question, which is the one I referred to earlier.



LEO:  Okay.



STEVE:  Which is a good place for us to stop.



LEO:  Our last question.  Oh, you don't want to do the motorcycle question?  Which one did you refer to earlier?  Do you mean the question...



STEVE:  #8.



LEO:  #8, okay.  We'll get to the rest another time.



STEVE:  Yes.



LEO:  Mike in Thailand.  And this one is regarding Flamer, Skywiper, and Infrastructure Systems Security:  Steve, thank you and Leo for the very informative shows.  In the past you performed a very detailed analysis of Stuxnet, which I found more useful than many Industrial Control Systems analysis.  I work with ICS systems and see that much of the IT in use and thinking is five to 10 years behind the times.  I have found it very difficult and frustrating to get people to really understand the risks.  Working outside the U.S., I see things from a more global, interconnected perspective.  Australia sees all this as the start of cyber war.  Mikko Hypponen, chief research officer at F-Secure, sees a future of cyber race. 



My question is:  What is your thought on the big-picture direction of all this?  That's what we, your listeners, want to know.  What do you think it means for the future?  Thanks, and best of luck to you and Leo.  Are we in a cyber war?  So this gets to the question that we were talking about, whether...



STEVE:  Yes.



LEO:  ...President Obama did the right thing to aggressively pursue Olympic Games.



STEVE:  Yeah.  I would say to escalate what may have been going on.  And, I mean, it is, it's a real question, I think.  We know that, from stories that we've covered, that there appear to be incursions which have never been admitted by entities of some cloth in China who are poking at and probing and often breaking into our U.S. infrastructure.  The Chinese government always disavows any responsibility or affiliation and so forth, although these things generally seem to be coming from China, which has a lot of people and a lot of Internet connections.  And so statistically, maybe, even if they were random, that would be the case.  But it's a really good question.



My problem is that - I used the expression earlier, this notion of the chickens coming home to roost.  By that I mean our technology is incredibly porous.  Our security is really bad.  I mean, we launch platforms that are written quickly, that are generally late, we're behind schedule.  Management says is it secure?  The programmers say, well, yeah, we think so.  We'd like to have a few more weeks.  And they say no, no, ship it now, we'll fix it later.  I mean, there's that kind of approach to commercial entities that have the wrong motivations for publishing software which is too important, arguably, to be wrong.  I mean, when we hear that the drone control system is using Windows and got infected by a thumb drive...



LEO:  Oh, dear.



STEVE:  ...you think, okay, wait a minute.



LEO:  That can't be good.



STEVE:  You know?  And, I mean, I worry that Iran may be working to purify uranium for the purpose of building a bomb.  They say they only want it for domestic power production.



LEO:  Yeah, yeah, sure.



STEVE:  And so they're running centrifuges which we apparently are able to screw up.  Once again, remember, these were not even on the network, but it didn't matter because Stuxnet could jump from thumb drive to machine and back in order to infect the control systems.  Well, we're using these SCADA control systems for our dams and our nuclear reactors and huge mission-critical systems.  And they're connected to the Internet because, oh, it's convenient to be able to log in.  Anyway, so...



LEO:  Although these were air-gapped.  That's why they had to use thumb drives.



STEVE:  Yup.  And it didn't matter.  It got across the air gap.



LEO:  Didn't matter.  They were still using Windows.



STEVE:  Yup, exactly.  They were using Windows.  So, and, I mean, for a long time our listeners would send me pictures of the ATM machine with the dialogue box...



LEO:  The Blue Screen of Death, yeah.



STEVE:  Either a BSOD or, more often, a notice popped up with a button you had to click, but there was no mouse to click with.  And famously, the big, huge Vegas kiosks will have, like, a Windows message that is...



LEO:  Right, error, error, error.



STEVE:  ...come up on top of - oh, god, yeah.  So I don't know.  I mean, this is during the course of this podcast, which, what, we are now in our seventh year, or seven and a half year?  Are we on our eighth year?  I don't remember.  Anyway, during the course of this podcast...



LEO:  Way too many, yes.



STEVE:  ...this has gone from theoretical to way past real.  We are now in real with Flamer and before that with Stuxnet.  And, I mean, I remember - remember when Stuxnet first began to happen, I was initially skeptical.  It's like, eh, we need to wait for more data.  I don't want to jump to any conclusions here.  Well, now we know.  And there is no question that Flamer is beyond - the capabilities in Flamer are beyond an individual or a small group.  This is, when you've got repurposed valid Microsoft security certificates, and someone figured out or arranged that they could be used to code sign in order to allow Windows Update to be intercepted, I mean, how many times have we worried...



LEO:  That's wild, isn't it?  That is just wild.



STEVE:  Yeah, how many times have we worried that Windows Update might be vulnerable, and all of our Windows machines would be downloading malicious code?  Well, Flamer does that.



LEO:  I love it that they can use Windows Update to update themselves.  I mean, I don't love it, but I just think that's pretty amazing.



STEVE:  You, your system has an obsolete version of the malware.



LEO:  Of the malware.  Would you like to update?  Well, so, and the debate we had was really whether the feds - whether it was right for the U.S. to pursue this cyberwarfare strategy.



STEVE:  An undeclared aggression.



LEO:  And I think that, given the alternative - and this started in the Bush White House, where Vice President Cheney was urging bombing attacks on Iran, which would have really been destabilizing in the region, and I think they decided, well, instead of bombing these plants, let's try this.



STEVE:  We'll do something that won't hurt lots of people.



LEO:  Right.



STEVE:  It'll be more, a little bit more like a drone attack, if I might use a...



LEO:  There's some question to its efficacy.  I mean, they did get people - apparently it was efficient to the point that the Iranian scientists took all of the centrifuges offline because they couldn't figure out why they were failing.  But I don't know if it really slowed down the enrichment process in any significant way.  Certainly not as much as a bomb might have.



STEVE:  Yeah, estimates, optimistic estimates in that case were maybe it knocked them back 18 months at the most.



LEO:  Right.  So it's not a huge...



STEVE:  But it certainly didn't shut down the program.



LEO:  Right.  So, and we have said time and time again, oh, terrible, we shouldn't do it, nobody should do cyberwarfare, those darn Chinese are doing it, well, now we know everybody's doing it.



STEVE:  Yeah.



LEO:  And I guess my opinion is it's kind of the way it is.  Should we - it's not like poison gas, which we all agree, all civilized governments agree not to use.  It's...



STEVE:  And landmines are not...



LEO:  Or bio, bio weapons.



STEVE:  Yeah.



LEO:  It isn't like that, although I guess if you use a cyber attack on significant important infrastructure like the electrical grid, and you brought it down, it would have some deleterious effects.  I just think that this is the way war is - war is not a good thing, but you can't bury your head in the sand.



STEVE:  And we do have, for example, we have CIA agents that are operating covertly which are sort of the same sort of thing.



LEO:  It's just how it is.



STEVE:  Embassies, foreign embassies are known to be basically satellite spy centers...



LEO:  We've been doing that for ages.



STEVE:  ...of governments.



LEO:  Right.



STEVE:  I think maybe it's - what's a little unnerving, Leo, is it's moved into our territory.  I mean, it's moved into the purview of this podcast.



LEO:  Well, yeah.



STEVE:  Where it's become real.



LEO:  Secure yourself.  But I think that cyberwarfare is inevitable, and I think that it would be foolish of the U.S. government to ignore it and not to participate out of some moral high ground.  I just don't.



STEVE:  I don't think we need to worry about that.



LEO:  I think that that's a weapon we need.  It's a weapon we need.



STEVE:  We don't need to be - worry about any moral high ground.



LEO:  [Laughing] There's plenty of worse stuff.  And I think it's an appropriate weapon.  I do.



STEVE:  Yeah.



LEO:  So I guess, after chewing on it, I don't think it's inappropriate to use this weapon.  In fact, in some ways, not bad.



STEVE:  And it's not - this isn't...



LEO:  It's nonlethal in some cases.



STEVE:  Flamer was just espionage.  As far as we know, from what's known at this point, it looks like it was an information-gathering tool.  It was taking screen shots and capturing keystrokes and looking for AutoCAD DXF files.  And, now, what we don't know, and this could easily change our opinion or amplify our opinion, we don't know how much incredibly valuable intelligence it was gathering.  Somewhere there are probably really unhappy people who were involved in turning off the command-and-control network four hours after Kaspersky announced their discovery because something vital to presumably Western intelligence gathering was taken offline.  It went dark.  They lost what may well have been a fantastic source of intelligence.  So we're looking at it sort of from a, oh, what does it do and how does it work.  We know nothing about, in detail, what it actually gathered.  And in four years, boy, it may have just been a phenomenal success.



LEO:  Steve Gibson is at GRC.com.  That's his home.  That's where SpinRite lives, the world's best hard drive maintenance utility.  And of course a lot of freebies he gives away because he's just a nice guy.  As well as 16Kb versions of this show in audio and full transcriptions.  If you want the video or the - what is that you're showing there?  What is that?  What is that?  Is that next week?



STEVE:  No, that's the...



LEO:  What are you up to?



STEVE:  That's the little prototype for the ketone breathalyzer.



LEO:  [Laughing] You madman.  You've done it.  Does it work?



STEVE:  It's on its way.



LEO:  He's breadboarding a ketone analyzer.  Well, it's about time.



STEVE:  Yeah, exactly.



LEO:  Wow.



STEVE:  Because I don't have enough things on...



LEO:  What chip do you use to detect the presence of ketones?  Is there a sensor?



STEVE:  There are volatile gas sensors which will detect ethanol and also acetone.  The problem is that they all - they're very sensitive to temperature and humidity, and our breath is both hot and moist.  So the signal I'm looking for is minuscule compared to the noise, which is temperature and humidity.  So I have a second sensor which is exactly the same technology, but designed to detect methane instead.  And so the idea is that the common mode response will be humidity and temperature, and the differential response will be the content of gases that differ between the two sensors.  So anyway, I'm just at the beginning of...



LEO:  What a fun challenge.



STEVE:  ...of experimenting.  It may be that I cannot find - it may be that breath is just too hostile because of its temperature and humidity.  But I'm going to - I'm working to very quickly determine, one way or the other, because I am just so tired of - my hands are just raw from poking them in order to take blood several times a day, which I have been doing.



LEO:  Several times a day?



STEVE:  Oh, yeah, yeah, because I'm spending serious money on these $5 ketone blood tests in order to monitor my ketones and get a sense for where they are.  I would - I can't wait to be able to, you know, to blow into something.  And if it works, we'll, I mean, I'm not going to go into production.  People don't have to worry about me disappearing...



LEO:  I think you should open source this.  You should give this away, yeah.



STEVE:  I'm absolutely going to - I'm going to open design it, and we will probably do a, what's the site where these things are crowd-sourced?



LEO:  Something -dables, expendables...



STEVE:  No, I'm thinking, shoot, I'm drawing a blank.  I've said it to many people.  It's the - it's where everybody says, hey, I have an interest in this, and you put up a pledge against - Kickstarter.



LEO:  Oh, Kickstarter.



STEVE:  That's what I'm trying to say.



LEO:  Oh, you could Kickstart it.



STEVE:  So the idea would be, all of our listeners, given it's possible, it would be a battery-operated, handheld thing.



LEO:  I think you'd do quite well.



STEVE:  I call it the Ketoflute, since it would use audio.



LEO:  Ketoflute.



STEVE:  The Ketoflute.



LEO:  [Whistling]



STEVE:  And so, I mean, for anyone who's doing this - and I've got to say, Leo, it's good to put this at the end of the podcast, so anybody who doesn't care can hit stop.  They're done.



LEO:  They're already tuned out, yeah.



STEVE:  I'm getting so much feedback from our listeners who we have helped with these Over the Sugar Hill podcasts.  Several people have lost 35 pounds.  Their blood tests have normalized.  One guy from Scotland said, "I smell funny, thanks to you, Steve."



LEO:  Me, too.



STEVE:  But he just loves what his body is doing.



LEO:  Yeah, it's awesome.



STEVE:  So it was really a good thing.



LEO:  Yeah.  And you feel like the keto strips are not as accurate as you'd like them to be?  Is that the issue?



STEVE:  Well, they don't continue working.  There's an adaptation in your muscles that begin to burn the acetoacetate.



LEO:  Oh, that's what's happened.



STEVE:  Yes.  So you're still in...



LEO:  Okay.  That explains it.



STEVE:  Yes, you're still in ketosis, but the strips no longer register.  There are expendable, but unfortunately very expensive, they're $5 per test, they're like the glucose tests.



LEO:  That's why you do the blood tests, yeah, yeah.



STEVE:  That's why, yeah, those are the little deals.  And then I do a weekly urinalysis, and it freaks out that I've got ketones in my urine.  It's like, yes, I know, I can smell it.



LEO:  [Laughing]  The Sugar Hill, two specials that we did, if you want to know more on the TWiT Specials feed with Steve Gibson about the ketogenic diet.  And he has recommendations for reading there.  But you can also go to GRC.com/health for links.  And if you want audio of a higher quality, or video, we've got that at TWiT.tv/sn.  We do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, on TWiT.  Please watch live.  We'd love having you as a live audience.  But if you miss it, don't worry, you have plenty of ways to watch after the fact.  Do subscribe.  I think that's a great thing to do.



STEVE:  And don't forget that we do get questions from our listeners.  Every two weeks we go through a sampling of them, and those go to GRC.com/feedback.  So that's how to get stuff to me.  And of course I do keep an eye on my Twitter feed where I get a lot of great stuff, feedback from our listeners, too.



LEO:  @SG...



STEVE:  @SGgrc.



LEO:  ...grc.  Thank you, Steve.



STEVE:  Thanks, Leo.



LEO:  See you next week on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#357

DATE:		June 13, 2012

TITLE:		Flame On!

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-357.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, after catching up with a large amount of the week's news, Leo and Steve carefully examine two major new discoveries about the Windows Flame worm.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  Boy, he's got a lot of security news.  There was a big Microsoft update, a new Apple update of Java, and Oracle, too.  But the big story is Flame, two amazing revelations that might give us some idea about where Flame actually came from.  Steve Gibson, next, on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 357, recorded June 13th, 2012:  Flame On.



It's time for Security Now!, the show that protects you online.  And here's the Protector in Chief, Mr. Steve Gibson of GRC.com, the Gibson Research Corporation, creator of SpinRite, world's best hard drive maintenance and recovery utility.  It looks like you're wearing a plain black shirt, Steve.  Surely there's something written - "Born to Code."  I knew it.  I knew it.  Is that a Think Geek T-shirt?



STEVE GIBSON:  No, I had it custom made.



LEO:  "Born to Code."



STEVE:  Yeah, that one and the one that says "Future Centenarian," both of those.



LEO:  I do like that.



STEVE:  Yeah, I've got some great comments.  I was walking down in Laguna Beach about a couple of weeks ago with Jenny, and some guy said, "Oh, I love your T-shirt."



LEO:  "Future Centenarian?"



STEVE:  Most people just sort of stumble over it.  It's like, what the hell does that say?



LEO:  How old are you now?



STEVE:  Got a lot of syllables.



LEO:  "Future Centenarian."  I'm making one of them.  Can we sell that in our TWiT Store?  Or something like, "I'm Ketogenic, Are You?"  Something like that.



STEVE:  That'd be good.



LEO:  Got your ketones rising.



STEVE:  Do you have a TWiT store?



LEO:  We do.  We just opened one.



STEVE:  With the hoodies and the fezzes and the...



LEO:  Yeah, TWiT - not fezzes yet.  Unfortunately, some of the fine TWiT merchandise like this mug and the fezzes are made by third parties.



STEVE:  Fine TWiT merchandise.



LEO:  And so for fezzes you have to go to Fez-o-rama.  It'd be nice if we could get it.  But we have a Spreadshirt store, twit.spreadshirt.com, that you can get hoodies with the logo and the T-shirts and stuff.  We could have a couple of fun ones like "Born to Code," "Future Centenarian," "I'm in Ketosis."



STEVE:  "I'm in Ketosis, Why Aren't You?"



LEO:  Yeah, I like that.  We've got to spread the word.



STEVE:  Yeah, we've actually - I've had so much great feedback.  People, I mean, our listeners are losing multiple tens of pounds, I mean, decades.



LEO:  You know, we blew it.  If we'd been smart - but, see, we're not really marketing anything.  But if we'd been smart, we would have had, like, a page that says how many pounds, and a thermometer, and a giant scale with how much our audience has lost, things like that.  That would be awesome.  Or gained.  We could put a "gained."  I doubt anybody's gained, but we could put a "gained" just to be fair.  Today we have - the title of the show is "Flame On!"  In fact, I'm going to add an exclamation mark.



STEVE:  I've got one here, yeah.



LEO:  I think you're talking about Flamer.



STEVE:  We are.  Two major revelations have come out this week, as I was sure would happen.  And as I've said the last couple weeks, we will be learning more about this over time.  This just - it takes time to peel this apart, to reverse engineer it, for these guys to look inside.  They don't have source code.  They've got the executable code that they have captured.  And so there's just no substitute.  Somewhere, certainly with Kaspersky in Russia and scattered around the globe, there are engineers who are burning the midnight oil, figuring out what this thing does, how it works, and where it came from.  And we have two, as I was writing the notes for this, Leo, this morning, I was getting goose bumps because of some of what has been discovered this week.  It was also a huge week for security stuff, so we've got a whole bunch of stuff to talk about at the top of the show.  And then two major, bone-chilling...



LEO:  Oh, boy.



STEVE:  ...really interesting revelations about Flame.



LEO:  Holy cow.



STEVE:  Yeah.



LEO:  Well, it's a jam-packed episode today of Security Now!.  I'll tell you what.  Hey, I forgot to ask you, did you see "Prometheus"?



STEVE:  I did not, only because I want to wait a little bit longer for the theaters to cool off.  So I'm going to go Monday, and we can talk about it next Wednesday.



LEO:  Good.  I won't say anything.  I did see it.  There was not - it was not a crowd.  There was no crowd.



STEVE:  Interesting.



LEO:  Yeah, that surprised me.  I was ready.  I bought tickets two hours early and went 45 minutes early, sat in the front row.  The theater didn't even fill up.  On a Saturday night.



STEVE:  Whoa, on a Saturday night?



LEO:  I don't know if that's Petaluma or what.



STEVE:  Did not see it.  I'm looking forward to it.



LEO:  I know you were really excited about it.  So, Patch Tuesday.  Did you see that?  Playing in theaters worldwide.



STEVE:  I saw that coming.



LEO:  Yes.



STEVE:  So Microsoft Patch Tuesday was yesterday.  And the most-used operating system in Iran and the Middle East got patches for 26 known security flaws.



LEO:  Say again?  26?



STEVE:  26 known security flaws.  Brian Krebs refers to them as "patch bundles," which I like because the way Microsoft does them is there'll be, like, they'll fix one file, some DLL, and it had three problems in it.  So it's three vulnerabilities, but one patch.



LEO:  Got it.



STEVE:  So there were in this case seven patch bundles covering 26 known flaws.  Half of them, 13, were in IE.  So those were important.  Microsoft announced and fixed, all at once, a critical flaw in their RDP protocol, the Remote Desktop Protocol.  And also they've got a problem that they acknowledged which they have not fixed, but I just tweeted it because it's critical.  So, let's see.  I don't see a link in front of me.  Oh, yeah, there's an MS Fix it, one of the quick fix-it buttons, and that's support.microsoft.com/kb/2719615.



So the story here is - again, this is not fixed with yesterday's Patch Tuesday because Google found this being exploited in the wild, so it was a zero-day exploit.  It is under active exploitation now.  It involves Microsoft's XML Core Services, all versions, 3.0, 4.0, and 5.0, across all Windows platforms and Office 2003 and 2007.  Again, I love - actually I turned this into an acronym.  Brian Krebs refers to it as "Browse and Get Owned."  I thought, ooh, BAGO.



LEO:  BAGO.



STEVE:  Browse And Get Owned.



LEO:  Holy cow.



STEVE:  And this is worse, though, because Office is involved.  This is also being used in targeted attacks simply by mailing people Office documents.  So it's an uninitialized memory vulnerability.  Microsoft wrote:  "The vulnerability exists when MSXML attempts to access an object in memory that has not been initialized, which may corrupt memory in such a way that an attacker could execute arbitrary code in the context of the logged-on user."  Which is Microsoft's traditional backpedaling way of saying BAGO:  Browse And Get Owned.  It's not like it could and it might and if the moon is in the correct phase.  No, this happens.



LEO:  BAGO.



STEVE:  So BAGO.  You browse somewhere, and that's it.



LEO:  That's terrible.



STEVE:  It's very bad.  So thus I tweeted it.  You can go to just Twitter.com/SGgrc.  You'll see a link that I sent out this morning to this fix.  Everybody who's listening who's using Windows should do this because this will fix it.  In the meantime, I'm sure Microsoft will nail this by next month.  But this is not something you want hanging out there.  Google detected that it was being used and locked it down.



LEO:  That's interesting.



STEVE:  So now doubt they've got some - their web crawlers crawled some infected pages and said, what's this?  So it's important.  Also on Microsoft, Microsoft's been very busy because there's been a lot of upshot from what's happened with the Flame worm.  I mean, they got really caught off guard.  And last week I said, eh, it wasn't clear to me whether there might have been some sort of plausible deniability here.  It just sort of seemed, from what we knew at the time, a little suspicious to me that there could be this crossover of certificate signing.



Well, I no longer believe that, due to what I will be talking about later in this podcast today, because we now understand much more about how the fraudulent certificate was created that was used to sign this malicious Flame code.  And this is why I got chills.  So this wasn't Microsoft's sort of wink, wink, nod, nod, to the NSA.  Microsoft I'm sure is very unhappy.



So they have updated immediately a bunch of infrastructure things under Windows Vista and 7.  They are updating their OS's certificate update tool to automate the process that used to be manual-only of disallowing certificates, that is, putting certificates in the untrusted status list.  They said: "The new certificate update tool will rely on a 'Disallowed Certificate Trust List' maintained by Microsoft.  The tool will check the list daily, moving certificates found on the list into the 'untrusted' store.  In the past, moving certificates to untrusted status required manually updating them."



So this is Microsoft being proactive, saying we're going to have every Windows Vista and 7 box on the planet check in daily so that we're able to, if this ever happens again, we're able to be much more proactive...



LEO:  Interesting.



STEVE:  ...in instantly distrusting those certificates.  So that's a cool, nice step forward.  They also said that they are giving advance warning - and this is something I'm surprised but very pleased about - they're giving advance warning of an update to how Windows manages certificates that will blanket-invalidate certificates that don't have adequate security.  They said certificates with RSA encryption keys shorter than 1024 bits will automatically be marked invalid.  Once this key length update is released...



LEO:  Wow.



STEVE:  ...all such certificates will be treated as invalid, even if they are currently valid and signed by a trusted certificate authority.



LEO:  That's one way to do it.



STEVE:  So that's big.  There are 768 bits, it's not really strong, but it's pretty strong.  512, not so much.



LEO:  But this isn't so much about the strength of the bits as an opportunity to kind of invalidate a bunch of certificates.



STEVE:  Yeah.  And...



LEO:  Yeah?  Older ones.



STEVE:  Exactly.  So really, since certificates are always expiring, we know that they have a year or two or three life - although it's possible for individuals to create longer living certificates if they want.  I'm using certs for my VPN that I used really ridiculously long bit counts, but I gave them a long life, so I'm not, like, traveling and then having my cert expire on me, which would be a problem.  So this is a good thing that they're doing.



Still, it's surprising because this is the kind of thing that will catch some people unawares who aren't paying attention, and suddenly something will break that was working before they did this.  But it's all - this is the nature of staying ahead of the moving target of security, which we'll be talking about here later because this MD5, which is increasingly insecure as problems have been found with it, and it was MD5 that Microsoft only stopped using last year, and that was the vulnerability that allowed the certs to get made for Flame.



But also, still in reacting to Flame, Microsoft is updating Windows Update.  They said they have a hardened Windows Update infrastructure so that the Windows Update client, that is, that part running in our machines, will only now trust files signed by a new certificate that is used solely to protect updates to the Windows Update client, which, again, this is them reacting to the fact that the Windows Update client had been unnecessarily permissive.  As we know from what I said last week, it was essentially accepting code that was signed with a sort of a generic - it was in the trust chain with heredity from Microsoft Terminal Services.  And there was no reason for Windows Update client to be so permissive.



Well, they've locked that down.  They're saying, nope, we're just - there's no reason it was that way.  Essentially, this is Microsoft sort of maybe overly trusting the whole public key infrastructure, the PKI system, just saying, well, our root is going to be secure, so no one's going to get bad certificates.  Well, someone did.  And had this been in place before, this would have excluded the particular solution that was found that allowed Flame to get these certs.  Furthermore - get this, Leo.



LEO:  Oh, boy.



STEVE:  They are strengthening their communications channel.  No more proxying of SSL traffic.  They were allowing an enterprise or, for example, educational institutions we've talked about often that have their own SSL certs and proxy traffic on behalf of the Intranet, the idea being that a Windows client running inside a corporate environment or an educational institution would, in initiating an SSL or HTTPS connection, would have a cert from a proxy on the network border, which it would negotiate with.  That would then decrypt at that stage, and then that proxy would establish a connection, in this case to Windows Update.  Microsoft is saying we're not going to let that happen any longer.  We need to have a non-inspected passthrough.  So they're saying that they're going to no longer allow proxying of SSL traffic.  Enterprises and educational institutions who connect through a network proxy will need to create passthrough exceptions so that Windows Update traffic is tunneled without inspection.  And of course again they're doing this to strengthen it.  They're saying you're connecting with us, you don't get to look inside of our tunnel.  Like, okay.  Because of course the...



LEO:  What side effects is that going have?  What if people in business probably rely on that; right?



STEVE:  Yeah, although businesses are normally pulling their updates separately already.  That is, the clients are not directly connecting to Microsoft.  They're using an enterprise update facility so that IT is able to look at everything and make sure it doesn't break things within the enterprise.  And then an enterprise deploys these updates into their Intranet, inside of their border.  So but for, like, schools, schools are not doing that, and this will break Windows Update until the schools add this proxying exception.  So again, these are serious infrastructure changes.  But as I said, all this indicates to me, Microsoft is not happy.  They are not happy that their system got abused in this fashion.  One of the...



LEO:  Yeah, I wouldn't be.  I mean, that's really about as bad as you can get.



STEVE:  Yeah, one of the further indications that this was no wink and a nod.



LEO:  Right, right, they didn't agree to this one.



STEVE:  Unh-unh.



LEO:  And that makes sense.  That would be such a mistake to agree to that.



STEVE:  It would, it would.



LEO:  You can see the horror.



STEVE:  So we have an amazing flaw that came to light in MySQL, the My Sequel Server.  HD Moore, who's our famous originator of the Metasploit framework, explained in his posting, he said:  "On Saturday afternoon Sergei Golubchik posted to the oss-sec mailing list about a recently patched security flaw" - and it has a CVE number of 2012, of course this year, dash 2122 - "in the MySQL and MariaDB database servers.  This flaw was rooted in an" - this is a really interesting mistake, which I think our listeners are going to get a kick out of.  You will, too, Leo.  "This flaw was rooted in an assumption that the memcmp() function would always return a value within the range..."





LEO:  Oh, always a mistake.



STEVE:  Uh-huh.



LEO:  "Always" is a bad word.



STEVE:  Now, HD wrote "-127 to 127," and he says "signed character."  But actually assembly language programmers know it's -128 to 127.  You've got to be careful with those rounding errors.  But still, so what he's saying is that the mem compare function would always return a value within that range.  "On some platforms and with certain optimizations enabled, this routine can return values outside of this range, eventually causing the code that compares a hashed password to sometimes return true, even when the wrong password is specified."



LEO:  [Laughing]



STEVE:  Uh-huh.  "Since the authentication protocol generates a different hash each time this comparison is done, there is a one-in-256 chance that ANY," he has in all caps, "password would be accepted for authentication."



LEO:  Any all-caps password, regardless, would be accepted.  Geez Louise.



STEVE:  So, he says: "In short, if you try to authenticate to a MySQL server affected by this flaw, there is a chance it will accept your password even if the wrong one was supplied.  The following one-liner in bash" - and he has a little one-line bash script - "will provide access to an affected MySQL server as the root user account, without actually knowing the password."



LEO:  Wow.  That's not good.



STEVE:  "This evening Jonathan Cran, CTO of Pwn Express and Metasploit contributor" - yes, it's the Pwnie - actually, I'm sorry, it's Pwnie, P-w-n-i-e.  The "Pwnie Express and Metasploit contributor committed a threaded brute-force module that abuses the [they're calling it an] authentication bypass flaw to automatically dump the MySQL password database."  Okay, so get this.  It exploits the flaw to dump the database.



LEO:  Now you got everything.



STEVE:  "This ensures that, even after..."



LEO:  Oh, they can't fix it.



STEVE:  Right.  "Even after the authentication bypass vulnerability has been fixed, you should still be able to access the database remotely using the cracked password hashes obtained before the fix was applied.  Pulling from resources of a personal side project of mine," says HD, "I was able to derive some statistics about the real-world impact of this vulnerability.  This project managed to find and gather the initial handshake for approximately 1.74 million MySQL servers across the Internet at large."



LEO:  Oh, horrendous.



STEVE:  "This statistic only includes MySQL instances that were on hosts publicly exposed to the Internet and not bound to localhost."  So these are, I mean, again, the idea that any clown would have their SQL Server answering random queries from the Internet is like, okay, just lock them up now.



Anyway, so let's dig into this a little deeper because this is interesting.  The memcmp() function is a standard C function.  I just put "memcmp" into Google.  The first link was www.cplusplus.com/reference/clibrary/cstring/memcmp, which is the standard C string memory comparison function.  Under description it says:  "Compare two blocks of memory:  Compares the num bytes of the block of memory pointed to by ptr1 to the first num bytes pointed to by ptr2, returning zero if they all match or a value different from zero representing which is greater if they do not."  It takes three parameters:  ptr1, which is a pointer to the first block of memory; ptr2, pointer to the second block of memory; and num is the number of bytes to be compared.



And it says under return value:  "Returns an integral value indicating the relationship between the content of the memory blocks.  A zero value indicates that the contents of both memory blocks are equal.  A value greater than zero indicates that the first byte that does not match in both memory blocks has a greater value in ptr1 than in ptr2, as if evaluated as an unsigned char value," an unsigned character value.  "A value less than zero indicates the opposite."



Now, if you were to compare two blocks of memory - in this case we're comparing two hashes.  We're comparing the stored password hash to a hash made when the user entered their guess.  So we've got two blocks of memory.  The normal way this would operate is you would do a byte-by-byte march along both of these blocks of memory of length num, and essentially you'd subtract one byte from the other.  And if you get zero, that means they're identical.  So you go to the next pair of bytes, the next byte in each of these two memory blocks.  You subtract one from the other.  If you get zero, you continue.  So you keep going until either you don't get zero as a result of a subtraction of the two bytes, or you finish the num number of comparisons.



So what you'll always end up with is a one-byte value that is either zero, if you got all the way through, meaning all of the bytes in these two blocks were identical and the hashes match, or you'll end up with this one byte that won't be zero, and the direction in which it's not zero is which one or the other was greater.  So, and that would be useful, for example, if you were comparing alphabetic strings, and you wanted to do an alphabetic sort.  You'd like to know if the two strings are different and also which one is alphabetically larger or smaller than the other.



But when he said, depending upon what optimizations were applied, now, the byte-by-byte comparison I just suggested is robust and reliable.  But there would be a great tendency to speed it up.  And in the list of vulnerable OSes, the 64-bit OSes seem to be, like, disproportionally represented.  The great temptation would be to compare eight bytes at once.  That is, if num is greater than eight, then, for example, if it's nine, then you know - or if it's eight or greater.  So then the temptation would be to do a 64-bit, that is, an 8-byte comparison; instead of doing eight single-byte comparisons, do one 8-byte comparison.



The problem is that, if you do that, and notice that hashes are often multiples of eight bytes long, so they're going to finish, if you compare 64 bits at a time, they're going to finish at an even 64-bit boundary.  It would be very possible for seven of those bytes to be completely wrong, but the final bytes to be the same.  Which means the least significant byte of the subtraction could be zero, even though the rest of them are not.  So it is a classic coding error to not check the entire value's zero-ness, but to only check the least significant byte.  And because the function is cast to return a signed byte, all of the more significant data gets discarded.  And this thing just returns the last byte.  So the chances are one in 256 that you're going to end up with a zero final byte, even if the other seven bytes are non-zero, and you wouldn't know it.  The function would ignore those more significant bytes, only return the least significant one, and...



LEO:  Whoops.



STEVE:  Oops.  So what we have is...



LEO:  And this, by the way, this library routine is all over the place.  I mean, this is...



STEVE:  Oh, it's a fundamental...



LEO:  ...fundamental.



STEVE:  Exactly.  It's very, very key.  So here's an instance where a security vulnerability was found, but this probably represents a bad bug in code all over the place, which is using this optimization in order to jump through the buffers eight bytes at a time, if they're not looking at the entire size of the final 8-byte by 8-byte subtraction for comparison.



LEO:  And most people are going to use memcmp() because it's a library routine.  It's stood the test of time.



STEVE:  Uh-huh, and then it got broken.



LEO:  Whoops.



STEVE:  This is the way, I mean, this is why computers have bugs.  It's like little tiny things like this.



LEO:  You hate to see a bug in a library routine, especially a very commonly used library routine, because that means we don't know how widespread this could be.



STEVE:  And I should just say I'm just conjecturing.  I wanted to take our listeners through a how-this-could-have-happened.  I didn't look at the code.  I don't...



LEO:  Right, no, that makes sense, yup.  And this is in C++.  So anything that's written in C++ potentially...



STEVE:  Or just C.  I think has the C has the same...



LEO:  Actually, you're right.  I don't know if the same bug exists, though.  It's the C++ library; right?



STEVE:  Ah, good point.  Okay.  So we did talk last week about LinkedIn.  And the, what is it, 65 million, or, no, 6.5 million.



LEO:  Yeah, one tenth of their users.



STEVE:  Had passwords leaked.  I was very pleased that LastPass got themselves involved because I like LastPass so much.  They've done such a great job.  Our friend Joe Siegrist blogged, he said:  "LinkedIn was hacked, confirmed by LinkedIn on 6/6/2012.  LinkedIn has updated their blog, indicating that there was a breach, and several LastPass staff members who used unique passwords for LinkedIn only" - and you could imagine anyone working for LastPass is going to have one of those wacky LastPass-derived, fully pseudorandomized passwords.



They said: "Several LastPass staff members who used unique passwords for LinkedIn only, as well as numerous individuals not associated with LastPass, have confirmed that LinkedIn's database has indeed been hacked."  Meaning, as we talked about last week, they put in their password into a hash, hashed it, and found it in the database.  So Joe wrote:  "If you have a LinkedIn account, we strongly suggest that you immediately, A, change your LinkedIn password; and check if you have re-used your LinkedIn password on any other websites and, if so, change those passwords, too."



And the question was, "Was MY LinkedIn password hacked?"  So they created a page, very nice, simple page, LastPass.com/linkedin, where they offer the ability to check your password, your LinkedIn password against the master database that was leaked.  So they've made this simple to do.  And of course I trust LastPass not to do anything wrong.



Now, you don't have to trust them because the first thing you should do is change your LinkedIn password, then test your old one there.  But since we've talked, eHarmony also lost 1.5 million unsalted MD5 passwords.  So LastPass.com/eharmony will do the same thing there.  And Last.fm also updated their blog indicating there was a breach and have confirmed that they are forcing password changes because the entire password database has been floating around the Internet for years, it now turns out.



LEO:  Oh.  What?  Oh, geez.



STEVE:  So LastPass.com/lastfm.  So there's three pages at LastPass (linkedin, eharmony, and lastfm), any page at which you can submit the appropriate password, and LastPass will hash it on your browser - they're not getting anything but the hash - and then check it against each of those three leaked databases which they have collected and are maintaining for us.  So thank you, Joe and company, for that nice service.  And I wanted to let our listeners know there's somewhere trustworthy they can go to have their passwords checked.  But of course always change yours first and give your old one to the site, just for prudence sake.



And last week we were talking about, in the LinkedIn context, we were talking about the need for salt.  And I got a couple tweets that made me feel like people believed that I believed that salting was all that was necessary.  And although we've covered this before, I thought it's worth reminding people that that's really not all that's necessary for anyone implementing a password database.  There's now a very well-known, well-understood best practices.



We know we need to salt, but salting is not enough because hardware exists which, if the salt is known, it's still possible, even though you wouldn't have a rainbow table - a rainbow table is basically a precomputation table for a hash, which could be and has been, for the popular hashes MD5 and SHA-1, unsalted, has been created to allow a password to immediately be looked up from its hash.  So given a hash, you could find a password, not necessarily THE password, but it doesn't have to be THE password, just a password, that will hash to the same thing, which would allow a bad guy to log in and impersonate you.  If you salt, that doesn't work.  It immediately busts any precomputation table.



But the problem is precomputation tables are a decade old.  Now we've got walls of PlayStation 3s.  We've got field-programmable gate arrays.  We've got the NSA building secret facilities in Utah.  We've got all kinds of things happening that are specifically designed to crack hashes, whether they're salted or not.  And so, if the salt is known, then you can still apply - although you can't precompute, you can now compute on the fly because, sadly, these hashes were designed for efficiency.  MD5 and SHA-1 were designed back in the early '90s when computers were two decades slower than they are now, and so they were designed for speed when that was a priority.



So what that means is that they are parallelizable and pipelineable, meaning that they could be implemented to be extremely fast in hardware.  You can either have tens of thousands of them running in parallel at once, simultaneously testing 10,000 different passwords; or, if it's pipelineable, you could have 10,000 passwords moving through a pipeline coming out the other end to be tested.  So this makes them very fast.



So consequently, you want to use something that we talked about before, a PBKDF function, a Password-Based Key Derivation.  WPA, that was designed more recently and much more strongly, famously does use a Password-Based Key Derivation Function, the idea being that you use iterations of a salted hash where you take the output of it, you put it back in, you add the salt, you hash it again, take the output, add the salt, hash it again, and you do that some number of times.  WPA uses 4,096 iterations.  iOS 3 used 2,000 for its security, and iOS v4 increased that by a factor of five to 10,000.  So this is all part of what you need to do.



Now, I would say that best practice, we talked about not storing, in a best practice situation, not storing the salt with the database.  Well, what you really want to do to make the strongest system you can is you custom salt every account.  So when somebody is creating their password, you generate a pseudorandom salt for that user.  You also have what I would call a sequestered system-wide salt which is not stored with the database.  So the per user salt, which does need to be stored with the database, that makes each user's hash custom to them.  The sequestered system-wide salt, which is not stored with the database, means that if only your database is compromised, they still don't get that.



But then, once you've got these two salts, a per user salt and a per system salt, then you apply Password-Based Key Derivation, whatever, 10,000.  And the idea there is that you are slowing down the process of processing this hash in such a fashion that even guys with really fast GPUs and hardwares are slowed.  So that's best practice for hash storing today.



Now, the next generation, I was glad to see that Colin Percival is the guy behind Tarsnap.  And I've talked about Tarsnap.  This is the Linux-based cloud storage system that is extremely secure.  He's done some of the work on the so-called "memory hard functions."  The other problem with MD5 and SHA-1, in having been designed for speed, is that they don't require much memory.  And if you don't require much memory, you can make them much more parallelizable because essentially the number of these that the NSA can create is a function of the die size.  And so if you just build yourself an MD5 engine or an SHA-1 engine, the smaller it is, the more of them they can put on a chip, and the faster their overall processing is going to be.



So what you want is an extremely memory-hungry algorithm.  That is, an algorithm that cannot be run in parallel.  It's parallel hostile.  It cannot be pipelined.  It's pipeline hostile.  And it uses - it has to have a huge amount of memory.  What that means is that it would just be impractical to create chips.  The chip would have to be big because every single instance would have to have a big plot of land allocated to ROM or RAM just by its very nature, and probably RAM, and the algorithm is going to use it in such a fashion that the whole chunk of RAM is being churned in some fashion.  It's going to be very slow.  There's just no way to make that better.



So we're learning a lot from all of these attacks about how to create really robust anti-password-cracking technology.  Of course, it doesn't help when major sites just use an unsalted MD5 hash because that's just no longer secure against these kinds of attacks.  So we know how to do it well.  I'm glad that we're seeing high-profile breaches like this because it's got to bring management's attention to, like, asking the question of their programmers - hey, we're not using an unsalted MD5? - even if the guy in the suit doesn't know what that means.  The programmers can say, uh, we'll get back to you on that.  And then find out whether they are or not.



LEO:  Interesting.



STEVE:  I did talk last week with some excitement about how Microsoft's IE 10 was going to be getting the Do Not Track header enabled by default?



LEO:  They changed their mind.  No.



STEVE:  They didn't last a week, Leo.



LEO:  Actually, they didn't change their mind.  Their mind was changed for them.



STEVE:  Correct.  The industry, the advertising industry had a meltdown and laid it on Microsoft's doorstep.  It turns out, though, that, I mean, and this is - we need agreement from all the players.  So what the advertising industry reminded Microsoft of was the fact that the Do Not Track spec - which I really like because it's got some great guys behind it.  Peter Eckersley from the EFF, the Electronic Frontier Foundation; Tom Lowenthal from Mozilla, and Jonathan Mayer, who we've spoken of many times, at Stanford, are all privacy advocates.  And they're the editors of the W3C's working paper for the standardization of DNT.  This is going to get W3C standardization.



However, the way this has been written, and this is a compromise I can live with, explicit consent is required.  So in this W3C standard, it will say that an ordinary user agent, meaning a browser, must not send a tracking preference signal, that is, any tracking preference signal, without a user's explicit consent.  Example:  The user agent's privacy preferences pane includes controls for configuring the tracking preference signal.  Or, on first run, the user agent prompts the user to configure the tracking preference signal.  But that says it just can't be on by default.



And so essentially what was said was that, if Microsoft did have it on by default in IE 10, that would inherently violate the standard and free the advertisers from paying attention to it because it was a nonstandard header as Microsoft had implemented it.  So this gives you a sense for the games that are being played.  On the other hand, we're talking about having the FTC enforcing this once this becomes a W3C standard.  So this is all good news.  This is what we predicted when this first surfaced, probably more than a year ago.  I was saying yes, yes, yes, that's - this is a good thing.  And it has taken a long time.  These things do.  But we're making some progress.



And Leo, when you turned your Mac on before we began recording the show?



LEO:  Oh, I got a few little updates there.



STEVE:  Yup.  We did have, across the board, from Oracle and Apple, an update to Java.  I found mine this morning when I unblanked my screen.  I'm still using v6 of Java, so I received Update No. 33.  People who have moved to 7, both are parallel tracks at this point from Oracle.  Version 7, being newer, has its update No. 5.  So those are available.



And in Oracle's fixes, Brian Krebs noted that Oracle patched 14 security flaws, only 11 of which were patched by  Apple.  So he didn't know, and I don't know why.  Either Apple didn't think they were important, or Apple's implementation of Java.  They may have been a Windows-only thing, so they don't affect Apple at all.  Apple is deemphasizing Java, no longer ships it.  But for those systems that have it, and many do because many need it, they are maintaining their version, and they probably are stuck doing that pretty much forever.



And lastly, Mozilla is heading toward opt-in activation of browser plug-ins, which I think is just all good news.



LEO:  What is that?  Isn't it already?  I mean, don't you have to install them?



STEVE:  No.  Many of these things are in the browser, or they'll be - I'm sorry, I wasn't clear.  Per site, that is, site-specific permissions.



LEO:  Ah.



STEVE:  So essentially moving some of the technology that we have known and loved from NoScript into the native Mozilla platform.  It's in beta in v14 of Firefox, and they're targeting it for release in v16.  And what they're saying is that so many exploits are being caused by obsolete plug-ins, that they are, in very much the same way that Chrome is, they're becoming much more proactive about - they've got their browsers secured, largely.  And now they're saying, okay, well, we've got to secure the things that run in the browser.



So this would be - okay.  So these would be site-specific, enforced by the browser.  So you would tell it when you want to run plug-ins by site, and the browser, Firefox, would remember that.  I think that's just all good.  And as I'm reading this, I'm thinking, okay, I mean, this makes sense because there isn't just one type of person on the Internet.  I know that many people will be using IE, and IE will just run everything.  But there are many people who care more about security.  And I'm just comforted by having to enable scripting.  I'll go to a page, and it'll be blank.  And I'll think, okay, I do want to see what this page has.  So for me it's a quick right click.  And I often just enable it temporarily, unless it's something that I know I'm coming back to.  And then the page loads, and everything's fine.



So I like the control.  I, knock on wood, have never had anything crawl into my machine.  I don't surf promiscuously all over the Internet, so I'm not a typical target for this kind of stuff.  But still, I'm glad to have my guard up.  And I fully respect that not everyone is as cautious as I, and probably many of the podcast listeners are.  There are solutions for them, too.  So we're not just in a one-size-fits-all world anymore, relative to Internet security.



And lastly, this is only tangentially related to security.  I have it under my Miscellaneous category.  But I just thought I'd mention it, an interesting facility coming to Facebook, called Pipe, from a small German team.  This uses something that Adobe has in Adobe AIR called Adobe Real Time Media Flow Protocol.  And this is a very simple, encrypted, peer-to-peer file sharing for Facebook users.  And it's, like, feature sparse, which is actually why I like it.



If two people are, like, on the phone, or talking, or both on Facebook, it's a tiny app that you can add to Facebook, called Pipe, and it simply allows you to drop a file into the pipe, and it comes out the other end.  And that's all it does.  It doesn't use Pipe servers because it is truly peer-to-peer.  The Real Time Media Flow Protocol solves the NAT traversal stuff, and it's peer-to-peer in the same way that Skype is.  And it's powerfully encrypted.  I think it's AES-128, if I remember.  And it's not Dropbox.  It doesn't do storage in the cloud or synchronization among multiple machines.  It's just a pipe.  And so you can - and you don't need to friend other people to use it, as other systems do.  It's just a pipe.



So if in any situation someone's on Facebook and they want to - oh, and it's got a size of a gig limit because it uses the browser's cache.  So it's whatever you drop in is going - it's a browser-to-browser technology.  So you're limited.  You just can't send massive things.  But my goodness, a gig.  So, I mean, that's going to take a while to transfer anyway.  But as a super, super simple, clean means of moving files between Facebook users, I think it's going to be popular.  I love the fact that it's that simple to use.  You just drop it in, and it comes out the other end.  It's a pipe.



LEO:  Very nice.  Yahoo! has another product called Yahoo! Pipes.  But that's not the same.



STEVE:  Not Facebook.



LEO:  Oh, okay, this is Facebook Pipes.



STEVE:  Facebook, yes, it's just Facebook to Facebook users.  And so no client to install.  It's a little Facebook app, very small, very lightweight.  And it just allows, I mean, it's like your mom could use it because it's simple.



LEO:  Interesting.



STEVE:  And I got a nice note from someone named Ray, who maybe didn't give me his last name because he didn't pay for SpinRite, apparently, but it saved his life.  And he said maybe literally.  So I guess I'll say, Ray, maybe you'll buy SpinRite at some point.  In the meantime, I thank you for sharing the story, this lifesaving story.



He said, "So I decided to reinstall Windows on my computer for the sake of speeding it up."  Which is a good idea.  I do that every few years.  "But of course I had all kinds of things to be backed up.  So instead of just burning a few DVDs or borrowing an external hard drive, I decided to transfer it through my network onto my other computer, a computer I've had for about six years.  Everything transfers over, and I start my reinstall of Windows on the first machine.  When the time came to transfer it all back to my main computer, something went wrong.  All but about five files did not transfer over."  So, wow.  All but about five files did not transfer over.  The first time I read this, this morning, I thought he said...



LEO:  All but five.



STEVE:  Only five didn't transfer.  So, yikes.



LEO:  So he only got five.



STEVE:  Yeah.  "Just a bunch of unable-to-access-drive errors.  At this point I'm thinking, oh, great, I guess I'm going to lose some stuff."



LEO:  Yeah, guess so.



STEVE:  "So I tried to restart the computer."  And this must be the second computer that received this archive.  "And nothing at all.  The hard drive cannot be read to boot.  Right about this time is when my thought process went from, 'Oh, great' to 'Oh Lord, please protect me.  My wife is going to kill me.'  It had occurred to me that all of my wedding pictures were part of those files.



"So lucky me, I knew someone who owned SpinRite.  I called him immediately and got his copy and ran it.  The drive was in VERY" - he has in caps - "bad shape.  So it took approximately two weeks of chugging away, but SpinRite finally recovered EVERYTHING" - he has in all caps - "on the hard drive.  I lost some music that never successfully made the initial transfer, so that wasn't SpinRite's fault.  I'm going to appreciate SpinRite for the rest of my life because of this.  Also, the next day I purchased Carbonite so this can't happen again."



LEO:  Good man.



STEVE:  "Thank you, Steve, for creating the greatest product in the history of spinning disks."  And thank you, Ray.  I'm glad SpinRite worked for you.  Thank your friend who hopefully was an owner.  And maybe somebody you'll become one, too.  In the meantime, all of our listeners know that SpinRite can get the job done.



LEO:  Sure does.  That's nice.  We're going to talk about Flame.  Flame On!  Two big revelations.



STEVE:  Goose bump raising, yes.



LEO:  Oh, boy.  I love this stuff.  Somebody's going to write the novel about Flame.  I can't wait.  Flame.  Flame On.  So Flame, or Flamer - actually has a lot of different names, we'll call it Flame for the time being - is impressive.



STEVE:  That seems to be the - well, yes.  It's beyond impressive.  As we know from the last couple weeks that we've been discussing it, it is 20MB.  It's 10 times the size of Stuxnet and Duqu.  And what we believed last week, what I said from what we believed, turns out to be wrong.  We have some revelations...



LEO:  What?  Oh.



STEVE:  ...this week.  Aleks [Gostev] at Kaspersky blogged about a discovery which they have made since we last talked about it.  And he said:  "Back to Stuxnet:  The Missing Link."  He said...



LEO:  Ooh.  Now, we know Stuxnet was developed by the U.S. and Israel.



STEVE:  Exactly.  And so Aleks wrote:  "Two weeks ago, when we announced the discovery of the Flame malware, we said that we saw no strong similarity between its code and programming style with that of [what they're calling] the Tilded platform which Stuxnet and Duqu are based on."  So this Tilded platform is the common derivative from Stuxnet and Duqu.  "Flame and Tilded are completely different projects based on different architectures and each with their own distinct characteristics.  For instance, Flame never uses system drivers, while Stuxnet and Duqu's main method of loading modules for execution is via a kernel driver.



"But it turns out we were wrong.  Wrong, in that we believed Flame and Stuxnet were two unrelated projects.  But it turns out we were wrong.  Wrong, in that we believed Flame and Stuxnet were two unrelated projects.  Our research unearthed some previously unknown facts that completely transform the current view of how Stuxnet was created and its link with Flame."



So to go back a little bit, we covered this extensively when it was happening.  There were three main variants of Stuxnet.  There was one that was built, the first one, in June 2009.  And then there were two others in March and April of 2010.  And the middle one, the March 2010, evidenced the most penetrations, and it was because it was so prevalent, the one that was first detected in June of 2010.  Can you believe it's been two years, Leo?  That's bizarre.  Where did time go?



LEO:  Yeah.



STEVE:  Okay.  So Aleks says:  "Despite the fact that Stuxnet has been the subject of" - and this is so cool.  "Despite the fact that Stuxnet has been the subject of in-depth analysis by numerous companies and experts, and lots has been written about its structure, for some reason the mysterious 'resource 207' from 2009 went largely unnoticed."  So that's something called "resource 207" that was in Stuxnet from 2009, that is, the June 2009 Stuxnet, the first one.  "But it turns out that this is the missing link between Flame and Stuxnet, two otherwise seemingly completely unrelated projects.



"In October of 2010" - okay, so October of 2010, which was after the discovery of Stuxnet, so June 2010 was when the March 2010 version was discovered.  "In October of 2010 our automatic system received a sample from the wild."  That is, of something.  They didn't know what.  "It analyzed the file thoroughly and classified it as a new Stuxnet variant, Worm.Win32.Stuxnet.s.  With Stuxnet being such a big thing, we looked at the sample to see what it was.  Sadly, it didn't look like Stuxnet at all.  It was quite different. So we decided to rename it to Tocy.a and thought, 'Silly automatic systems.'"  It misclassified it.



"When Flame was discovered in 2012, we started looking for older samples [of Flame] that we might have received [and not recognized].  Between samples that looked almost identical to Flame, we found Tocy.a.  Going through the sample processing system logs," back from October 2010, "we noticed it was originally classified as Stuxnet.  We thought, how was it possible?  Why did the system think that this Flame sample," which we now knew was Flame, "was related to Stuxnet?  Checking the logs, we discovered that the Tocy.a," which they renamed, which their system originally identified as Stuxnet, "we discovered that the Tocy.a, an early module of Flame, was actually similar to 'resource 207' from Stuxnet.  It was actually so similar that it made our automatic system classify" that at the time unknown Flame worm "as Stuxnet.  As it turned out, Tocy.a was similar to Stuxnet alone and to no other sample from our collection.  This is how we discovered the incredible link between Flame and Stuxnet."



So this resource 207 is an encrypted DLL containing what they refer to as a "PE."  PE is the acronym for Portable Executable, which is the Windows format for executable files, which is 351K in size.  Resource 207 from Stuxnet is a Flame plug-in.  And they said actually a "proto-Flame plug-in."  So Stuxnet's resources actually contain a Flame platform component, meaning that a week ago we didn't think Flame and Stuxnet were from the same source, from the same people, from the same team, in any way related.  Now we know they are.



Once they believed that, and because they're were becoming increasingly familiar with Flame and already knew Stuxnet so well, they began looking for similarities which they hadn't been searching for, and they began to find them.  They refer to "mutex names."  A mutex is a sort of a fundamental - it's what's called a "synchronization object" in coding, stands for mutual exclusion.  The idea is that different threads running in either the same process, that is, the same program, or different processes may need to coordinate their access.  Say that they shared a database, and you'd need some way of them not both reading a record from the database, making different changes, and then writing them back because the last one to write it back would overwrite the changes the other one made.  So you use something like a mutex or a semaphore to synchronize the execution of these threads.



Well, when the threads are in the same process, they're able just to share the handle of the mutex because they would both be able to know it.  But when the threads are in separate processes, because you've got interprocess isolation, which is a key for the security of our systems, there's no way for two different threads to know the handle of something that they need to share unless you give it a name.  So what's done in Windows is that mutexes are named.  And essentially the first thread to create the mutex or open it uses the name.  And if it doesn't already exist, it's created in the system, and that thread is given a handle that it can use to access it.  And then later, if some other process creates the same mutex with the same name, it gets a return code saying, oh, that already exists.  Here's your handle to it.  And so it's a way, by using a common, a name that they both know, it's a way of synchronizing these things within the system that you wouldn't normally have access to due to process separation.  Well, both Flame and Stuxnet use improbably named mutexes:  TH_POOL_SHD_PQOMGMN_ and then a %d, so that's probably a short - a printf for...



LEO:  For date, yeah.



STEVE:  ...a date or a decimal number.  And then SYNCMTX, as an example.  Well, there's no way that's a coincidence that they both had that.  And then some similar things.  They both share the same string decryption algorithm which is unique to them.  They both mangle class names in the same way.  They both have similar naming conventions.  In Stuxnet there is a temp file created named dat3A.tmp, which is placed somewhere.  And when Stuxnet infects a system, it creates that file so that, when other instances of Stuxnet start up, they check to see if that file exists.  And, if so, they know Stuxnet is already here.



Well, Flame - okay, so that was, again, dat3A.tmp.  Flame uses dat3C.tmp.  So what they've found is by looking at closely at this code, they now understand they have common roots.  And they know that there was a source code level relationship between these groups or teams, or maybe it's just one group, because this secret resource 207 that just was part of Stuxnet, remember that it was there in the first release of Stuxnet that was found in June '09.



But the functionality of resource 207 that exists in Flame today, it was migrated into other modules of Stuxnet in the March and April 2010 versions.  To do that, you pretty much need the source code.  So you would take the source code, and you'd say, okay, we're not going to have it in resource 207.  We're going to move those functions around into other places.  So it's very clear now that there was - we don't know the details of common authorship.  But we believed a week ago there was no relationship.  Now we know there absolutely, unequivocally was.  Probably the same contractor.



LEO:  Same author.



STEVE:  The same author.  The same group.  In fact, there was some note in Aleks's blog where he - because I was thinking about myself and coding style.  They have the same coding style.  And that's something...



LEO:  Yea, yeah.  And that's very distinctive.  It really is unique.



STEVE:  Yes, I was thinking about that with myself.  I know, if I looked at my own assembly code, like a reverse, a disassembly of my binaries, I could just see this is me, this is the way I do things.  And for this kind of low-level stuff, it had to be written in assembler because the compiler would tend to fuzz that.  The compiler, things come out looking all kind of generic from a compiler.  So you could identifier the compiler that produced the code, but not the author who produced the code because that level of translation, it would sort of blur...



LEO:  It kind of obfuscates it, yeah.



STEVE:  Yeah, it blurs it.  But if I looked at my disassembly, it's like, oh, I wrote that.  And I know there's no question.  And so that's what they're seeing.  They're seeing a style of coding at the assembly level that at least parts of this had to be created in where it's like, oh, they used the same, just the same fingerprint, same coding style.  And there's an infinite number of those at that level.  So, yes, these are all the same group who put this together, which is amazing.  Now, there's more.



LEO:  There's more.



STEVE:  To pull off this signed certificate attack, what we now understand is this wasn't a matter of simply getting a certificate, like having it issued, because that wouldn't work.  What had to happen was something we talked about years ago.  We covered a brilliant cryptographer named Marc Stevens, who was involved - and you'll remember this, Leo, because I do - in creating a fraudulent certificate authority for the RapidSSL authority.  And you may remember they used 200 PlayStation 3s...



LEO:  Right, right.



STEVE:  ...a wall of these things.  And what they did was - the need was to create a new certificate, a different certificate with a different common name.  The common name is the thing that you're protecting, essentially, like GRC.com is the common name for our SSL certificates.  So I prove to VeriSign that I am GRC.com.  I provide them with my public key, which they sign to assert that they have verified that I'm GRC.com, and that's then my certificate.  So spoofing a certificate means changing the common name.  Well, these things are all fingerprinted, the certificates are fingerprinted using message digests, which is what MD of MD5 stands for.  And as we said earlier, Microsoft was using MD5 until last year, despite the fact that it's been chipped away at over the years.  I mean, I think it was in '07, so five years go, that you and I talked about, we did a podcast on cracking MD5.



LEO:  Right, I remember that.



STEVE:  Yeah, Marc's wall of 200 PS3s, all using their high-powered GPUs.  Now, the reason that was necessary was that we're talking about what's called a "chosen prefix attack" on a message digest, the idea being that, as the digest goes along processing a file that it's creating a fingerprint for, it's evolving a state.  It maintains a bunch of memory and has a bunch of static constants.  And you're taking new data from the file and munging it in a different way so that all of the history of the file is mixed in with the new data and the constants in sort of an evolving fashion.  So the idea is that, if you're incredibly clever, you can design some changes as a prefix such that parts that you don't control of the file will still end up giving you the result you want.



And so the idea is that you want to change part of the certificate in your way, yet still have it be signed by someone you trust, even though they never signed it, meaning that - and remember that, when I say the word "signature," a signing means that they have used their private key to encrypt the result of the hash, and so you verify it by using their public key.  Well, that means, since you never get their private key, that means you've got to make the hash come out the same.  So if the hash comes out the same, they signed the other hash for the valid certificate.  You've managed to create your own certificate with the same hash, so their signature still applies.



So the problem is that these certificates are serialized, and they're time stamped.  And so, if our listeners who remember this podcast will remember, the challenge was they had to submit a certificate request at a precise instant in order to get a preknown timestamp and a known serial number.  They probably did it in the wee hours of the morning in the time zone...



LEO:  When there's less traffic, yeah.



STEVE:  ...when there's less traffic.  So the serial numbers would be advancing less slowly.  So they said, okay, at this point in time the serial number is probably going to be this when the certificate is issued.  That'll be at exactly this instant.  They then used their PS3 wall to crunch ahead and figure out what prefix they needed in order to synthesize their certificate signing request, the CSR file, which they then submitted at the precise instant in order to get the authority to sign it.  So that was what Marc did in '07.  What Marc realized - and he was involved in this when it became clear that an MD5 collision attack was employed.  He said, hey, what did they do?  How was this used?



Okay.  So what Marc said of this is:  "Most interestingly, the results" - oh, and he used his own proprietary forensic tools to reverse-engineer the certificate that was used by Flame to authenticate its code.  And he said, "Most interestingly, the results [of our analysis] have shown that NOT our published chosen-prefix collision attack was used, but an entirely new and unknown variant.  This has led to our conclusion that the design of Flame is partly based on world-class cryptanalysis."



LEO:  Isn't that something.



STEVE:  "Further research will be conducted to reconstruct the entire chosen-prefix collision attack [which was newly] devised for Flame."  And Matthew Green, a professor specializing in cryptography in the computer science department of Johns Hopkins University, said:  "It's not a garden-variety" - he says, "It's not a garden-variety collision attack," as if there is such a thing.  I mean, what I just described is hardly garden variety.  But at this level, the world's preeminent cryptographers are saying this is "not a garden-variety collision attack or just an implementation of any previous MD5 collision papers, which would be difficult enough.  There were mathematicians doing new science to make Flame possible."



LEO:  Isn't that amazing.



STEVE:  [Laughing] Oh, Leo.



LEO:  Wow.  Wow.



STEVE:  Oh, yeah.



LEO:  That's just mind-boggling.



STEVE:  Yeah.



LEO:  I mean, so world-class mathematicians working on this thing.  Am I right?



STEVE:  This is NSA, yeah, this is NSA.  This is not some contractors.  This is not outside.  I mean, this is, I mean, maybe Israel.  But, I mean, this is...



LEO:  Sounds like the NSA.



STEVE:  It really does, yeah.



LEO:  Golly.



STEVE:  Oh, I got goose bumps again.



LEO:  That's pretty cool.



STEVE:  And based on their analysis, they're saying that this was probably $200,000 worth of just pure compute time, just computation time.  That's what it would cost to do the computation.  And the same sort of collision process would have been required.  They believe, due to reasons of the specifics, that the window would have been about a hundred times smaller for this versus what was done in '07.  So Marc was saying this was orders, two orders, two decimal orders of magnitude more difficult, which it would have increased the amount, the computational complexity associated with synthesizing this cert in order to make it happen.  I mean, these guys are just, like, they're stunned that this was done without them.  This was not done in the academic community.  This was done secretly in a cyberwar setting [laughing].



LEO:  Very interesting.



STEVE:  Yup.



LEO:  Well, Steve Gibson, you have once again blown my mind.  Flame flames on.  So it looks pretty much like it was, well, since Stuxnet was, I think we now can safely say for sure, an Israeli/U.S. joint effort.



STEVE:  Well, yeah.  Remember that...





LEO:  Part of Operation Olympic Games.



STEVE:  Yep, Olympic Games.  And I've been watching the political side.  And of course the White House is not happy that this information leaked.  On one hand, some people are saying, well, doesn't this make Barack look like he's tough on cyberwar?  And it's like, yeah, but it shouldn't have leaked.  And reportedly the President is not happy that this story got written.  But...



LEO:  Well, sorry.  I mean, come on.



STEVE:  It's true.



LEO:  People are paying a lot of attention to this.  And good luck keeping it a secret.



STEVE:  It is interesting, Leo, that there is a level, I mean, this kind of level, this goes way beyond script kiddies and Metasploit turnkey exploit packages.  This is world-class espionage.  And, boy, can you imagine the chagrin of the people who designed it when this got discovered?  It's like, oh.



LEO:  Well, the big mistake was that it leaked out.  It was only supposed to be used in constrained circumstances.  And it's leaked out.  And that's really the big mistake.  If you want to be upset about something, be upset about that.  But the truth is, I think that's a valuable lesson that every security researcher knows very well.  It's very hard to contain these things, much harder than a bio weapon.



STEVE:  Yeah.  It was used in a targeted fashion, thus the concentration of its being found to a much higher degree in Iran and in the Middle East than elsewhere.  So it wasn't just, I mean, Stuxnet was found in people's air conditioners in their homes.  So Flame was at least more tightly targeted than that.  So that's good.



LEO:  Steve Gibson is the best.  You can find his work online, GRC.com.  That's where SpinRite is, world's best hard drive maintenance utility - Dude, if you use it, buy it - and a lot of free stuff that you don't have to buy, and a lot of research and all sorts of things at GRC.com.  Not to mention show notes, 16Kb audio versions, and even transcriptions of each and every one of these programs, all 357 episodes at GRC.com.  Now, if you want the video or the higher quality audio, we've got that at TWiT.tv.  And you can always subscribe.  Is the 16Kb version a podcast?  Did we ever make it like a downloadable podcast?



STEVE:  No.



LEO:  Let me know if there's a demand for that, folks, and we can turn that into a subscribable show.  Never even thought about it.



STEVE:  I haven't even checked my stats for quite a while.  That's part of my revamping that I'm working on.  And do not forget, please, GRC.com/feedback.  Next week's episode is a Q&A, and I love to hear what questions our listeners have.  We'll address them.



LEO:  Good.  Steve's Twitter is @SGgrc.  And we do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern, so you can always watch live.  We like it when you do, and we can see the chatroom and all that.  That's 1800 UTC on TWiT.tv.  Thanks, Steve.  We'll see you next Wednesday.  Or, oh, programming note, three weeks from now is the Fourth of July.  So we will let you know when we're going to - we're not going to record on the Fourth of July.  The whole place is shut down for fireworks.  Except I think OMG Chat is going to do a Minecraft Marathon on the Fourth of July.  He's going to launch his new Minecraft show then.  So stay tuned for that.  But no Security Now!.  And we'll let you know what the new schedule is going to be.



STEVE:  Great.



LEO:  Thanks, Steve.



STEVE:  Thanks, Leo.



LEO:  Take care.  We'll see you next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#358

DATE:		June 20, 2012

TITLE:		Listener Feedback #146

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-358.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  He's got his review of "Prometheus"; some security news, of course; and we'll answer some questions from our audience, including a great tip for you LastPass users, something you might want to change.  It's all coming up next on Security Now!. 



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 358, recorded June 20th, 2012:  Your questions, Steve's answers, #146.



It's time for Security Now!, the show that protects yourself and your friends and your loved ones and your privacy online.  Here he is, our Explainer in Chief, our Chief Privacy Officer, Security Officer...



STEVE GIBSON:  CPO.



LEO:  Yeah, CPO Steve Gibson of GRC.com.  Hey, Steve.  Good to see you again.



STEVE:  Actually, speaking of CPO, we do have a question that we're going to cover, since this is our 146th Q&A episode this week, a question from a listener about career opportunities in security.  And I won't spoil my answer about that by talking about it any further, but...



LEO:  Stay tuned.



STEVE:  ...we will be discussing that.  I finally saw "Prometheus" on Monday, so we can talk about that a little bit.  And I wanted to also notify our listeners who aren't following me on Twitter that the second season of "Falling Skies" has begun.  But here I am, already starting, and I know that we've got a lot to cover.



LEO:  I'll tell you what, let's do an ad, how about that.  And we have questions and answers and all sorts of stuff.



STEVE:  And some errata.  There was a mistake...



LEO:  No.



STEVE:  ...that was conveyed last week I want to fix...



LEO:  Never.



STEVE:  ...about that MySQL authentication bypass and the memcmp() function in C.



LEO:  Oh.  We went on and on about the memcmp() function, turns out that wasn't it.  Okay, well...



STEVE:  No, it was.  Well, kind of.



LEO:  We'll explain.



STEVE:  We'll get there.  We'll get there.  I like to cram it all into one sentence.



LEO:  And I know it's probably not in your lineup, but I've really got to know what you think of the Microsoft Surface at some point.



STEVE:  Okay.  I know nothing about it.  I haven't even - it's not even on my radar yet.



LEO:  Oh, well, Microsoft made a big announcement about they're going to make a tablet called the "Surface."  And I know you're into tablet computing.  There'll be two form factors.  There'll be an ARM form factor that uses Windows RT, basically the iPad-like version of Windows.  And then there'll be one version that uses Windows, Windows 8, the professional version.  And it's an interesting product.  "Interesting" is the best I can say about it.



STEVE:  Yeah.  I have my iPad.  I think I'm done.



LEO:  Yeah, I think that's the problem is you're not alone.  Steve Gibson.  "Prometheus."  What did you think?



STEVE:  Yeah [sighing].



LEO:  Yeah, me, too.  That's exactly my reaction.  Yeah [sighing].



STEVE:  Yeah.  It could have been so much...



LEO:  It was beautiful, wasn't - it could have been so good.



STEVE:  Yes, it could have been so much more.



LEO:  No - now, we've got to say, we're not going to do any spoilers here, folks.



STEVE:  No, I'm not going to do any spoilers.



LEO:  Because you should see it.  Everybody should see it.



STEVE:  Yeah.  And I've ordered the disc, the Blu-ray, back on June 3rd...



LEO:  Yeah, it was gorgeous.



STEVE:  ...and I'm glad I have it because I will watch it multiple times in future years, as I have watched "Alien" and "Aliens" and "Alien vs. Predator" and both "Predator" movies.  I guess there's a third one now.



LEO:  First half is like "2001:  A Space Odyssey."  I'm thinking, this is going to be the greatest sci-fi movie ever.  And the second half is more like "Alien."



STEVE:  Well, in explaining it to a friend of mine, I said, you know, it felt muddled.  The beauty of the original "Alien" movie was that what it was about was crystal clear.  You absolutely knew what was happening.  And they just crammed too much random stuff into this.  I mean, it was exciting and visual and interesting and sci-fi.  I mean, it's got spaceships, and how can that be bad?  But annoying things, like they just happened to fly over the landing site when it could have been anywhere on the planet, and it wasn't emitting any radiation or any signal or anything, so what are the chances of that?  And then it just - anyway, I don't want to, as you said, we don't want to spoil it.  But it got a 7 out of 10 on IMDB.  I'll be glad to own it.  But, boy, it felt like a real opportunity was lost.



LEO:  There was such promise.



STEVE:  Huge.



LEO:  And the trailer made it look so good.



STEVE:  Huge amount of money got spent.



LEO:  Well, and it was gorgeous.  You can't deny it was gorgeous.  It was also gruesomely gory; so if you have any squeamishness about blood products, stay away.



STEVE:  And we had our new Sigourney.



LEO:  She's good, Noomi Rapace.  Is she not great?



STEVE:  She was wonderful.



LEO:  She is a superstar.  She was Salander, Lisbeth  Salander in the original Swedish versions of "The Girl With the Dragon Tattoo" of the Millennium Saga.



STEVE:  Oh.



LEO:  And she's, yeah, I didn't recognize her, I had to look her up, and I said, oh, her.  She was great in that Swedish version.  And she's a star.  There's no question, she's a star.



STEVE:  Yeah.  And also we were hoping for some clarification, and I think deliberately Scott added additional confusion, hoping that there will be a sequel.  But all the reports I've had is that the theaters are not full.  People are not rushing out to see this.  So I don't know if it's going to make enough money to pull a second one.



LEO:  I was shocked.  I planned.  I went opening night.  I planned ahead.  I bought tickets ahead.  I had planned to be in line.  No line.  I got there 45 minutes early, sat in the front, there was no one in the theater.  In fact, the kids in the theater kicked me out because they had to clean it.  I went, oh, no, I'm going to lose my great seat.  I went out, no problem, it was there when I came back.  It's too bad.  I really - I was ready for the science fiction adventure of a lifetime.



STEVE:  Well, we do have another "Spiderman" coming up, and we have a new Bond coming up, and we have another "Bourne" movie.



LEO:  You forgot another "Batman" coming up.  Sequel mania.



STEVE:  We'll have enough things this summer, I think.  And speaking of this summer, I tweeted a couple days in advance of Sunday's premiere of the - it's a two-hour premiere, but it was just two one-hour episodes back to back of the second season of "Falling Skies" on TNT.  And so I wanted to let people know that, if they missed it, it will be re-aired on this coming Sunday afternoon, June 24th, which ought to give our listeners time to listen to this podcast and queue it up.



"Falling Skies" is not to die for.  Its lead actor is Noah Wyle, who of course made himself in the "ER" series that ran forever.  It's okay.  The first season starts after Earth has already been invaded and the planet pretty much decimated.  And so we're the resistance humans fighting back against the aliens.  There's some good computer graphics.  It's interesting.  It tries to be character-driven.  Anyway, that gets a 6.9 out of 10 on IMDB, and I'll watch it.



The first two hours were good.  It looks like they've got more budget.  It did obviously get renewed for a second season, so that says something about it.  So I would say, if people like sci-fi, you definitely need to see the first season.  You can't really pick up here with Season 2 if you weren't watching it last year.  But if you were, you probably want to continue.  And I wanted to let everyone know that it has started again for the summer.  As of course has "True Blood," but I'm a little disappointed in that.  That seems to have lost its way.



LEO:  [Laughing] I think we're just bored.  It's fourth, fifth season, I guess, now.



STEVE:  It was so fresh and new and amazing...



LEO:  Right, exactly.



STEVE:  ...the first year or two.  Now it's like, okay, fine.



LEO:  Eh, more vampires.



STEVE:  Yeah.  So, errata.  We gave the impression last week that the problem with that MySQL, what was called the "MySQL Authentication Bypass" may have been an error in the memcmp() function.  My careful explanation made it very clear that that wasn't the case, but people came away feeling that we'd said that there was a bug there, not in MySQL.  The bug is in MySQL.  It's that the return value from the memcmp() function, the word in C is "coerced."  It's being coerced from its integer value to a byte-size value.  And that's why the...



LEO:  Ah.  So MySQL is ignoring the sign, not memcmp().



STEVE:  Well, it's ignoring the more significant bytes.  And that's the key.  The idea is, if you do a comparison, and you have a multi-byte comparison, you have to care about all of the bytes in the result, not just the least significant byte, because the other ones could be non-zero, and in fact while the least significant byte is zero, which will be the case one out of 256 of the times, which is what I explained.



But so anyway, what MySQL is doing is they're coercing the return value to a byte which discards the more significant bytes that are probably non-zero, if you don't have a password match.  And so one out of 256 times you're going to get authenticated when you shouldn't.  So I just wanted to correct the record to make sure people understood that it was not the memory compare function, which is just fine.  It was the coders who for some reason coerced its return value into a byte.



Also people picked up on this 64-bit vulnerability, which I got a lot of people writing in and tweeting about that.  First of all, it's already been fixed.  What this was, was an incredibly subtle difference between the way AMD implements some deep voodoo hardware 64-bit stuff in their chipset versus the way Intel did it.  Intel is where the vulnerability exists in the case that code was written to the AMD spec.  Whereas Intel is saying, well, we're not going to do anything about this.  Our chips are not buggy because our chips work the way our spec says.  Except that what happened is people assumed the two chipsets, AMD and Intel, were identical in this really subtle way where they're not.



So it caught everybody off guard, but it's a local privilege escalation vulnerability that requires - it's like a theoretical problem.  And all the OSes have already responded.  It was already in last Tuesday's patch of this month by Microsoft.  So I wanted to let everyone know.  I'm not going to go into any great detail because it's impossible to explain without really digging into details of the way ring transitions work in the OS, and it's just a subtle difference that has already been resolved.  So a tempest in a teapot at this point.  And as far as we know, nobody ever - it's not being exploited.  It never happened to anybody.  It was just like, whoops, here's something that was found, and it's been fixed.



Unlike the Microsoft XML Core Services exploit that I talked about last week and urged everyone to follow the Fix it link.  It is actively being exploited, and now its exploit code has been publicly released as a new module to the Metasploit exploit framework.  So that's going to really ramp up its exploitation.  If anyone didn't get around to going to the little Microsoft Fix it link, you can scroll back not very far in my Twitter stream because it'll still be up there near recent since I'm not tweeting a ton of stuff, and find it.  You definitely want to do that because this is exploitable, not only through visiting a web page, but also targeted exploits through the earlier Office products, I think 2003 and 2008, if I remember, across platforms [2007 for PC].  So definitely something that you want to fix.



Firefox updated to - we're at v13 now.  And we were at 13.0.  We moved to .1 because there was a subtle problem that the latest version of Adobe's Flash had with an obscure conflict with something called RealPlayer Browser Record, which some people had installed in Firefox, and lord help them because you know how we feel about RealPlayer.  I know Elaine, it's the only thing she can use for transcribing, so we understand, Elaine, you're still using it.



LEO:  You're the one who's still using it, yeah.



STEVE:  Who needs it, who needs it, probably.  Anyway, so Firefox.  Adobe said you can move back to a prior version of Flash, but Firefox stepped up and fixed it.  It was, again, a very subtle interaction with the sandboxing, the new Firefox sandboxing technology for Flash which is hoping to contain future Flash problems and prevent them from turning into exploits.  That interacted in some bizarre way with RealPlayer's Browser Record, and so Firefox has been updated to fix that.



I did just pick up a little note that I liked, and that was with the iOS 6 that was talked about and previewed in the recent Apple Developers Conference.  The developer preview release notes mention that, under iOS 6, which will be the next major update, the OS will request explicit user permission when an application attempts to access contacts, calendars, reminders, and photos.  Anyone who's using an iPhone now, or an iPad, any iOS-based device, has probably encountered the "can we have location" permission.



So at the moment it's only your location, your geographic location data, which Apple had been requiring you to specifically give applications permissions to have, yet we've talked about some of what people felt were privacy abuses where applications like, I think it was LinkedIn, was sending people's calendars off to the mothership.  And they were saying, well, yeah, of course, because we want to allow you to look up the profiles of people who you're going to be meeting in the future.  It's like, oh, okay.  Would have been nice if you'd asked.  So Apple is going to be enforcing that at the iOS level.  So that'll be more user interaction, but I think that it's good, that it'll give people more control over what apps are able to do.  So I think that's moving forward and is a good thing.



There was a bunch of news about the FBI making some noise, worrying about IPv6 because it sort of was as if they suddenly woke up to the fact...



LEO:  Hey, what?  You guys are what?



STEVE:  Well, now 4.3 billion IPs doesn't sound like many.  We've got multiple terabytes of hard drive space, so 4.3 billion IPs?  That's nothing.  Now, with IPv6, of course, we're going to have 340 undecillion IPs, which is what we get with 128-bit addresses.



LEO:  What's the problem?  The FBI can't count that high?  Oh, I'm going to be in trouble.  I didn't say that.  That was the Canadians.  That wasn't...



STEVE:  What happens in practice is that it's up to ISPs to keep the whois database for the regions of the Internet they control up to date.  So as ICANN and other disseminators of address space have been slowly and judiciously metering out the very limited IPv4 space, they've had the leverage to enforce ISPs to keep the "who are you giving these blocks that we're giving you to" records up to date.  And as far back as when I was working with Verio, maybe 10 years ago, so more than a decade ago, I had to fill out a "how am I going to use the IPs you've given me," it was like an IP justification form, they called it.



LEO:  Now they say, "Have all you want."



STEVE:  Well, that's the problem.  Yes.  If you've got 340 undecillion IPs, it's just, well, in fact, I am being offered, I was going to switch my...



LEO:  They give you like a Class C, don't they?



STEVE:  No, no, a full Class A.



LEO:  They give you the Class A.



STEVE:  Yeah.  I'll have a full 32 bits of my own.



LEO:  That's yours.  Oh, my.



STEVE:  And so the problem is, ISPs will only ever be needing to come back to the trough for more maybe every 15 years or so, rather than constantly.  And so now the FBI is saying, wait a minute, we have now realized that we depend upon being able to track back the owners of IPs because that's the traffic that we see.  That's the Internet's addressing is the IP, the Internet Protocol address.  And so it's going to be real problem if, with 128-bit IPs, they just sort of go off into a big block that isn't enumerated, which could very well happen because there really isn't anything other than existing protocol which has been inducing ISPs to do this, and the fact that they were, in order to get more IPs, they had to justify how they're being used now, and so that justification filtered down to the customer and then back up to the formal whois database.  



So politically this is going to be - the FBI is saying, unless this is being done voluntarily, we may need some legislation to enforce this because...



LEO:  Oh, no.



STEVE:  ...we need to know.



LEO:  Oh, they're going to legislate against IPv6.



STEVE:  That's been said, yes.



LEO:  See, people are so worried about, quote, "tracking" with cookies, tracking cookies.  This is real tracking.  This is law enforcement wanting to know exactly what you're doing, and they're upset that they can't.  Okay.  Enough said.



STEVE:  On the flipside, I understand, I mean, there are bad guys, and we would like the FBI to be able to go get the bad guys.  We're seeing, for example, botnet operators and people who are doing denial of service attacks.  They're being tracked down and caught.  And that's good for the Internet.



LEO:  But won't they know, if you get a Class C, or Class A, they'll know, I mean, they still have - you're in a range that you own, even if you're using - so they know who you are.  This is not thinking.



STEVE:  Well, okay, no.  But it's important to get this, that for my provider who is Level 3, or in the case of my T1s that I have here at home, Cogent, for Cogent to ask for more IPs, they need to say where the IPs they already received went.  And if they've got just so bloody many of them, then they're only going to need to ask every 15 years or so.  And so there just won't be - right now it's just protocol that induces ISPs to keep the whois database current because the providers of these very limited IPv4 IPs can say we need you to map out how you're using what you've already got before we're going to give you any more.  Prove to us you need more.  And so that's happening on a continual basis.  Thus there is some political pressure for the ISPs to ask their customers how they're using the IPs and sort of...



LEO:  This is the FBI saying we don't really want to have to go through really annoying court order subpoena process.  We'd just like to have a database of what everybody's doing so we could just follow you around.  This court order thing, it's just so slow.  It slows us down.  Who needs that?  Because they could get that information.  Right?



STEVE:  Yes.



LEO:  Yeah, okay.  It's just that they want to know ahead of time. 



STEVE:  Yeah.  They would have to generate a legal paperwork to induce the ISP to tell who they gave this block of IPs to.



LEO:  Do the legal paperwork.  Don't be lazy.



STEVE:  Many people picked up on the story of Fujitsu cracking 978-bit crypto.  Well, so everyone's like, okay, is this bad?  What does this mean?  And a lot of people picked up on the report.  It was supposed to take umpteen millions of years, and they did it in some 120-some hours.  So this isn't a problem.  Nothing about the crypto we're using today is affected.  This is a completely different crypto technology known as pairing-based crypto.  It is very much next-generation crypto.  There are cryptographic libraries that implement it.  It's still deep in academia.  It's a cool technology which potentially solves the certificate authority trust problem, so it's got everybody interested.  It offers something called "identity-based encryption," which allows you to use things about yourself as your key in a secure way.  It's incredibly complicated.  We'll talk about it someday, if it ever happens.



But there were theoretical beliefs about the strength of it.  And so what Fujitsu did, and this is very good for it, was they showed it wasn't as strong as people thought.  And a perfect analogy is the factorial problem.  The reason, and we're talked about this before, the reason we need 2048-bit keys for asymmetric encryption is the difficulty we believe there is in factoring an integer that large.  The reason we only need 256-bit or 128-bit symmetric keys is that it's an entirely different problem to crack it.



So cracking symmetric encryption is entirely different from cracking prime factor-based asymmetric encryption which requires factorization.  So similarly, this pairing-based crypto is yet again an entirely different means of encrypting, and so it's got unknown key length requirements.  We know what the key lengths are for symmetric.  We've settled on what they should be for traditional asymmetric that requires factorization in order to crack it.  Now we're looking at a third type.  And so it's still in academia.



So what happened is there were assumptions about how long it would take to crack a 978-bit key.  And that's a weird number all by itself.  And it turns out Fujitsu used, like, hundreds of cores, operators had 200-some, 248 cores cranking away.  And in what was a surprisingly short time for the academic researchers of this next-generation potential, next-generation technology, Fujitsu had a breakthrough.



So that's good.  That means, oops, 978 bits is not enough.  We'll just add some more.  So we're determining the required strength for this key of pairing-based crypto.  Interesting, but doesn't affect us in any way today.  Someday we'll be talking about it, and I'll explain more about how it works because it offers some really, really interesting, cool things.



And then in the wacky story of the week, we have the news that an Australian online retailer, Kogan.com, has begun taxing people who purchase from their retail website, Kogan.com.  They're putting an IE7 tax on their shoppers.



LEO:  [Laughing] I love it.  You  mean if you use IE7, you pay more?



STEVE:  Yes.  Yes.  So this is just one of - 6.8 percent tax, which is 0.1 percent for every month since IE7's launch.



LEO:  That is so wonderful.  I want Newegg to do that.  That's so great.



STEVE:  So the history of this is sort of fun.  Chief executive Rusian Kogan told the BBC that he wants to recoup the time and costs which were involved in rendering his website into an antique browser. 



LEO:  It's the steampunk cost, the steampunk tax.



STEVE:  He says IE7 was launched in '06, and since then Microsoft has released two major updates to the software.  And so the BBC reports that according to Mr. Kogan, the idea was born when the company started working on a major site relaunch.  Kogan said that even though only 3 percent of his customers use that old version of the browser, his IT team had become preoccupied with making specific adaptations to make the pages display properly under IE7.  And quoting him, he said, "I was constantly on the line to my web team.  The amount of work and effort involved in making our website look normal under IE7 equaled the combined time of designing for Chrome, Safari, and Firefox."



LEO:  Wow.  That's actually legitimate, if it really is that hard.  It should be a pre-IE8 tax because what of IE5.5 or 6?  What about them?



STEVE:  And we have covered the news that even Microsoft is trying to get people to let go of IE6, and people won't because they've got corporate ware...



LEO:  Right, Intranets, yeah.



STEVE:  ...that was written to it, and it won't work otherwise.  So Kogan said it was unlikely that anyone would actually pay the charges.  His goal is to encourage users to download a more up-to-date version of IE or use a different browser.  And they had a screenshot in the story of where it showed on the receipt, on the web page, an IE7 tax.  Whatever they sell, they're expensive stuff because it was a significant chunk of change if you insisted on using IE7 to do your purchase.  So I got a big kick out of that.



LEO:  Kind of amazing.



STEVE:  Yeah.



LEO:  Bold.  A bold, a new strategy.  We should all do it.



STEVE:  It got a lot of good coverage, too.  So this week and next week I'm going to amplify something that many people are reporting, and I'm pleased by it.  And that is that SpinRite is becoming very effective, well, I mean, has been, but is becoming known to be effective in recovering solid-state drive technology.  Cody reports from Lansing, Michigan.  He said, "Good evening, Steve.  I just wanted to share a quick note about" - oh, the subject was "SpinRite Saved My Raspberry Pi."  And that may sound odd to people.  We're not talking about something that comes out of the oven.



LEO:  Oh, I think our audience knows what Raspberry Pi is.



STEVE:  Yeah.  He said, "Good evening, Steve.  I just wanted to share a quick note about SpinRite that I found interesting.  After months of anticipation" - because as people may know, they immediately sold out of their first batch and had to get more.  "After months of anticipation I received my Raspberry Pi, a $35 ARM-based computer.  I rushed home after work and started tinkering.  I have had a 16GB Class 10 SD card for a while with this specific application in mind.  No matter how I wrote the image to the SD card, I was experiencing a wide range of issues when trying to boot my Pi.  I gave up on the card finally and dusted off a smaller 4GB one, and everything worked.  So I decided to see if SpinRite could even see the SD card."  And by that he means he hooked it to his computer and booted SpinRite to see if SpinRite would pick up the card's presence because it would if it was supported by the BIOS.  And in this case it was.



He said, "And it did.  So I decided to run a Level 2 scan."  And the only thing I would suggest, well, no, a Level 2 scan or a Level 1 scan, you want the quick read-only scan on solid-state memory.  He says, "It took a few hours.  Then I booted back into Windows, attempted to run the installer utility to write the image to the disk once again, which had continually failed.  To my surprise and great pleasure, I was then able to boot the Raspberry Pi into the Debian Linux distribution made for it.  I thought I would pass along this unlikely use of your product to help out any Pi owners who might be facing grief with their devices.  Thanks.  Cody, Lansing, Michigan."



So I just wanted to reinforce.  We've mentioned it a couple times.  But you don't want to use the Level 4 that performs a read/write, read/write exercise because that's needlessly fatiguing the limited write cycles on solid-state memory. But by all means, run a Level 2 because what that does is it forces the card's processor, whether it's an SD drive or a thumb drive or a SSD card of any sort, it forces the processor in there to verify that it's able to read the sectors, and it does so in a way which will induce the processor to either rewrite the sector if it's soft, or to relocate it if needs to move it.  So I'm seeing multiple reports now, after having mentioned it on the podcast, of people who probably wouldn't have thought that SpinRite would help solid-state devices, and we're seeing that it does.



LEO:  That's very interesting, yeah.



STEVE:  And I'll share another one next week.



LEO:  So don't run it on Level 4.  Run it on Level 2, is the tip.



STEVE:  Yeah, 1 or 2.



LEO:  All right, Steve.  Ready?  You feel good?



STEVE:  Let's go through 10 questions.



LEO:  You've got your special thinking cap on?  All right.  Here's Question #1.  I need a thinking cap to say this name right.  He's from Normal, Illinois, but his name is anything but.  I apologize.  I think I might get this right.  Thanesh Rajandran in Normal, Illinois says, how do you research a topic, Steve?  How do you do what you do so well?  Long-time Security Now! listener here.  Six months ago I was forced to pause my listening because it was my last semester as a grad student, and things were getting very hectic.  Now I'm playing catch-up.  I miss listening to your voice, in a good way, and the richness you share in every podcast.  I love it.



It's true.  Security Now!, one of our most popular shows, and there's a good reason.  It's all that thinking and smartness coming off of Steve.



The question I have is sort of off topic from security, but I think that, nonetheless, many may find it useful.  I know I would.  When you go about researching a topic, as you have done with the health topics, Vitamin D or ketosis, or with security topics like WPS, you always wind up being able to discuss the topics from the ground up, starting with the fundamentals.  It's really amazing.  So I'm curious.  Do you have a process?  When you begin the task of researching a topic, are there certain keywords you use when you Google search?  Are there default websites you visit initially and branch out from there?  I don't have a SpinRite story to share yet, but I have my hopes up since my seven-year-old laptop is starting to get a little cranky.  Hey, that's nothing to hope for.



STEVE:  I was just going to say.



LEO:  I hope I get to use it.



STEVE:  Okay, but I don't think that's a good thing.



LEO:  Thank you, Thanesh.



STEVE:  Yes.  Remember that it does - SpinRite is useful for prevention.



LEO:  Yeah, in fact, now's the time to use it.



STEVE:  Exactly.  Something's a little cranky, I'd run SpinRite, frankly, just to see, like to get some reading on what's going on.  But to answer your question, what is probably not maybe obvious is just the sheer number of hours that I spend on these things.



LEO:  Oh, here it comes.  He's going to want a raise now.  All right...



STEVE:  No, no.  But when you're talking about the Security Now! podcast being strong, you know, Leo...



LEO:  You work hard.



STEVE:  ...from just looking at the materials that I prepare...



LEO:  You work very hard, yeah.



STEVE:  Yeah, I mean, I really do invest in this podcast.  And similarly, I invest in the things - in my own passions.  And so before I surfaced with a podcast about, for example, the "Over the Sugar Hill" stuff, I'd read six texts, I mean, six books.  And I have a biochemistry text and a ton of research.  So I would say, first off, it's that this is not something I do for a few hours.  This is something I do, in the case of low-carb stuff, for six months before anyone else is really aware of it.  So it's where my life goes for a long time.  And I think the key for me to explaining these things is just understanding them. 



LEO:  Yes.



STEVE:  I'm never afraid to say "I don't know."  And one of the problems I think that techie people maybe have more than others, I'm just sort of aware of it, is because their identity might be a little caught up in being smart and being, oh, he's the computer guy in the family, it's often hard for people to say "I don't know."  Like they want to be the know-it-all, the wizard, that always has an answer.



LEO:  It's a good thing.  You can say that.



STEVE:  Yes, because the problem is, if you don't acknowledge you don't know, then you're less inclined to go find out.  And so I recognize when it's like, I read something, and it's like, okay, wait a minute, rather than on any level needing to believe that I understand it, if I really don't, I go find out.  And so I think that's the only thing I really have is a clarity of what I don't know, which then drives me to find out, and then I'm able to explain it in a way that I think is clear.



LEO:  Albert Einstein said, "If you can't explain something simply, you don't understand it well enough."



STEVE:  Yup.



LEO:  I'd also point out I just read some research that was fascinating, that smart people are oftentimes less logical and more prone to making errors and mistakes because they believe in their ability so much.



STEVE:  Yup.  I saw that, too.



LEO:  Wasn't that fascinating?  They don't second-guess themselves.  They don't think hard enough.  So that's a challenge that I'm sure people like you have to really constantly give yourself is, wait a minute, I think I understand this.  I probably should look into it.



STEVE:  Well, I had a neat techie employee who worked with me on the R&D side of SpinRite 20 years ago, back in the SpinRite 2 and 3 era.  And he was young.  And when there would be like a mystery, a bug, he would leap forward and guess.  He couldn't resist guessing.  And he was, he was GATES.  G-A-T-E-S is an acronym for some sort of, like, a young version of MENSA.



LEO:  Gifted and talented, yeah, those programs are all over the country, and they're really good programs, the GATE programs.  But...



STEVE:  Yeah, the problem was he - his name was Jim.  And I said, well, now, here's the problem, Jim, is you now have an ego stake in being right.  We don't know if your guess is correct, but now you want it to be.  And I said, I have no problems not guessing, saying I don't know what's wrong.  And I believe that makes me more open to seeing what is actually going on, rather than sort of trying to bias that result in my direction.  So I just - I don't want to have a stake.  It's why, for example, I've invested substantially already in the design of this ketosis measuring device.



LEO:  Ho ho ho, he's building it, ladies and gentlemen.



STEVE:  Yeah.



LEO:  You put that on your head?  What the hell?



STEVE:  You blow in there.



LEO:  For those listening, it is breadboarded.  Lots of - I see six, five pots on there.  I see a bunch of circuitry, wires.  And there is a little - there's a USB interface.  Oh, that's cool, so it's USB.  And a thing, I see a thing, I guess that you could buy that off the shelf, that you blow into.



STEVE:  Oh, no, that's a made-from-scratch...



LEO:  You made that, too.



STEVE:  It's a chamber that has the sensor located inside...



LEO:  Dude, you rock.



STEVE:  ...which is measuring - anyway.  So the point is...



LEO:  You're calling that the Ketoflute, right, as I remember.



STEVE:  The Ketoflute, yeah.  And I've invested heavily.  I've had friends blowing in it.  I mean, it's working.  But I still don't know...



LEO:  Hey, come here.  Can I get you to blow into this?



STEVE:  I still don't know if I'm going to have anything.



LEO:  Right, this is research.



STEVE:  Yeah, it's pure R&D.



LEO:  Steve, this is why we love you.  I'm getting tears in my eyes.  This is amazing.



STEVE:  I need to answer the question.  Maybe it'll work; maybe not.  But again, if I have to go, well, okay, now I know, at least I've satisfied my curiosity without needing it to be something it isn't.  So...



LEO:  You see? 



STEVE:  It's important to be a pure researcher.



LEO:  And everybody needs to have that.  If people could develop that mentality, it'd be so great.  If you don't know, investigate.  And you probably don't know.  That's the problem.  Smart people think they know.



STEVE:  Well, and that was the lesson from the Portable Dog Killer.  I just encourage people to go build something because, oh, the act of doing that teaches you so much.



LEO:  Right.  Question 2 from an anonymous listener:  Steve, with all the recent security breaches of super-popular, multiuser sites like LinkedIn, what steps should a company take when such a breach occurs?  Do they disable user logins and password changing till they verify that the original hole has been plugged?  Should they force users to change their password on first login?  Should the company randomize the passwords, send users an email with a new password?  I realize the security hole in that email, but given that the leaked password could be unhashed within hours, changing the passwords would essentially make the leak useless.  Thanks again for a great podcast.  What is the right response?



STEVE:  Well, I loved the question because it's the right one to ask.  And we can answer it by stepping back a little bit and asking what is it which has been lost, which such  a company needs to regain?  And what's been lost is their confidence in their ability to authenticate existing users.  So they learn with as much surprise as the rest of their customers or users that they've been breached, that somehow out posted on the Internet are all the hashes of their users' logins.  So certainly they definitely need to solve the problem of the breach.  Otherwise, anything they do can just get releaked.  So absolutely they need to, as quickly as they can, figure out what it is that happened, how it happened, how that data got loose.



So there's the forensic side they need.  They also have to, exactly as our anonymous listener suggests, then be, A, 100 percent skeptical of any subsequent login and even, depending upon the nature of their service, logins which could have occurred from the time of the breach until discovery.  That is, in the case of that, I want to say form.me.  I can't remember what the site was.  There was LinkedIn, eHarmony, and there was another one [Last.fm], where apparently their database had been floating around for years on the Internet.



LEO:  Oh, yeah, yeah.



STEVE:  So we have this issue of when did the breach occur, which is different from when we found out about it.  From the moment that it occurred, anything that had happened since then is suspect.  And so certainly the company needs to factor in what services they're offering, what kinds of things they do.  This is different if it's people posting random comments to random blogs versus PayPal or Visa and MasterCard, for example, where there could be dramatically more consequences to failure of their authentication mechanism.  So there's when did it happen, when did we find out, what are the consequences of authentication compromise then, then solving the problem so that any changes won't continue to leak out.



But then, and here's really where we come down to what action they should take, is how do they reestablish authentication?  And, sadly, the way the world is right now, it is the relatively insecure email loop, as we call it, is probably the only way to do this.  Now, the best practice is not to simply blindly mail updated links to everyone because that's just - you would, first of all, that creates a huge burden.  Suddenly your authentication ability goes to your entire user base.



What probably makes more sense is for the company to deny all subsequent logons with the existing compromise password, that is, set flags throughout everyone's account saying that you cannot log on right now.  When new visitors come, they get an explanation, which they should have had emailed to them.  So certainly the company wants to be responsible and immediately send out email explaining that there has been a breach that they're pursuing to figure out how bad this is, what the consequences are, so forth.



But then the idea is users who want to log on should request at that time that they be emailed updated credentials to the existing password.  They can't obviously use - I'm sorry, to the existing email account.  They obviously can't use a new email account.  Otherwise the bad guy could attempt to logon as them and immediately commandeer.  So it has to be the email account that was used, which they need to prove continuing ownership of.  That email contains a link which they click which then authenticates that they're the recipient of email that was sent on demand.  Then they're allowed to change their password under hopefully stronger hash and strong password management technology, and reauthenticate.



So it's a tricky situation.  And what you would hope is that state-of-the-art companies already had that in place, that is, that they're not scurrying around waiting for several weeks to be able to respond affirmatively.  It would be nice if, even though they never want their password databases to get compromised, if they had planned for it, and it was built in so that they were able to initiate this kind of process on demand.  And they probably have it in place for the instances already where, on an individual basis, this needs to be done.  So this is why in general it doesn't take forever to get this to happen is unfortunately they just have to do it on a mass basis rather than individual users saying, hey, I need to do password recovery.



LEO:  It was anonymous, and there's some speculation that maybe this was the CEO of LinkedIn that was asking, but I don't think that's probably the case.



STEVE:  No.  Hopefully he's got IT people.  Although, given that they used an unsalted MD5...



LEO:  Maybe he doesn't have any IT people anymore.



STEVE:  Yeah.  I'm happy to answer your question.



LEO:  Thank you, Reed.  Jared in Australia wonders about testing connection bandwidth:  When you use websites to test your connection speed, for instance Speedtest.net, and press "Begin Test," it finds the fastest server for testing geographically, but that's not always the closest.  However, after the test finishes and the results are shown, why in general is the upload speed always the same, even when the test is run multiple times for accuracy, whereas the download speed is often varying around?  For instance, on my DSL I get 9.4Mb download on average, but sometimes it's 9.35, sometimes it's higher, but it's usually between 9.35 and 9.40.  The difference in the upload speed is much smaller, 0.86 to 0.87Mb.  So why, Steve?  Can you explain this?



STEVE:  Okay.  So he wondered why there's the huge difference.



LEO:  Why the variation in download but not upload.



STEVE:  Yeah.  Now, actually there's less variation in download than upload when you look at it as a percentage rather than as an absolute, which is probably the proper way to look at it.  He sees between 9.4 and 9.35Mb download, but that's only a difference in half of the second significant digit, from 9.35 to 9.4, whereas he reports that in uploading it's 0.86 to 0.87, which is a difference of one whole second digit.  So even though it's counterintuitive, there's actually more percentage variation in what he's seeing in upload than in download.



But in general, I liked the question because everyone wants to know what their bandwidth is, typically, in downloading things.  And as we've looked at the Internet, we understand that it is based on a best effort packet delivery, where routers that are overloaded have official sanction to simply discard packets, which will stall the traffic and require them to be resent.  We also know that most downloads are over TCP, which requires that the packets come in, ultimately arrive in sequence.  So if one packet is lost and other packets are sent, then the lost one needs to get retransmitted, and that generally means retransmitting everything from the lost one back.



The point is that there will, just naturally, this is not like in the modem days where we had wires connecting the two points.  Instead, we're sort of spraying packets out into the ether, and they're wandering their way toward their destination.  So the proper means of measuring bandwidth is to simply use the largest number you can ever get.  That will be...



LEO:  That's your max.



STEVE:  ...your actual bandwidth.  Anything less is a consequence of some momentary loss along the way.  So run the test 10 times and see what the best is you can get.



LEO:  Don't average it, look at your peak.



STEVE:  Right, exactly.



LEO:  Yeah, that makes sense.



STEVE:  That's the best stable number.



LEO:  Question 4 from Ireland.  Bart B. in Maynooth, Ireland suggests a method for determining a user's DNS server without JavaScript.  Remember in 356 Steve talked about a few ways Google might be able to know what your DNS server is.  Google was warning people when they had DNSChanger that they had malware.  He says:  I think it would be easy to do in the following way, entirely server side, without any reliance on JavaScript.  What you need is for your web server - Google - to communicate with an authoritative DNS server under your control.  You set up a DNS zone for the purpose of testing DNS servers, and you run that DNS server.  You have that server log the IP requests to it for a given subdomain.  Logging to a database with rsyslog would do it for you without even needing to hack your DNS server.



Your web server inserts a request for a JPEG - this is very complicated.  I hope I'm following this, and I maybe reading this wrong.  But your web server inserts a request for a JPEG image - when I say "you," I mean Google, or whoever's trying to do this.  Google's web server inserts a request for a JPEG image on a one-time subdomain of their controlled test domain into the website it returns to the client.  This will cause the browser to resolve that domain using the visitor's DNS server.  Since the subdomain is a one-off, it can't be cached anywhere, so that DNS server will have to request the relevant A record from the authoritative server, in other words, that server we set up, the DNS server.  The web server can then check the DNS server's logs to see where the request for the one-time domain came from, hence telling the web server what the visitor's DNS server is.  This would work if you got one request a minute, maybe.



No JavaScript needed, and even a moderately skilled sysadmin could hack such a system together in a day.  If I had to do it, I'd send up a BIND DNS server on CentOS 6 logging into MySQL, using the default rsyslog syslog implementation that comes with RHEL (Red Hat Enterprise Level) CentOS.  I'd then create a simple CGI script running in Apache to query the MySQL server for the relevant logs.  Show off.



Thanks for the show and for SpinRite.  Keep up the great work.  There is now more than one episode of Security Now! for every day of the year - that's true - quite an achievement for a show where each episode is at least an hour long these days.  Hat's off to you guys.  Bart.



STEVE:  So I wanted to acknowledge Bart's note and the similar notes from many listeners.



LEO:  It's an interesting mindbender.  How would you do this?



STEVE:  Well, yes.  And I've done it because everyone will remember the spoofability test.  I wrote a pseudo DNS server, of course in my case in assembly language, which does just that.  When you use the spoofability test, it sends a bunch of uniquely named images to your browser, causing your browser to ask its DNS servers for the IP, which causes them to ask GRC's authoritative server for the IP, and as a consequence...



LEO:  Oh, clever.



STEVE:  ...I get the queries from the users' DNS servers that allows me to determine how spoofable they are.



LEO:  Don't you, I mean, isn't there an issue, though, with timing?  I mean, you have to say, well, I mean, if you were Google, and you had a million requests a second, this is going to be a very difficult thing to do. 



STEVE:  Yeah.  Exactly.  It can work.  I love the fact that so many of our listeners are on the ball to this degree that they've picked up on it.  I've implemented a system, as I said, just like it for the spoofability test, so it certainly does work.  And so I wanted to acknowledge everybody who said, hey, Steve, you could do it this way, too.



LEO:  Have to be a low-traffic site, though.  I mean, if you got 20 requests in a few seconds, it's going to be hard to say, well, that one came from here, and that one came from here; right?



STEVE:  Ah, no.  The way you do it, though, is, for example, you ask for zqrd7 blah blah blah dot...



LEO:  So you have a unique JPEG for each time.



STEVE:  Unique domain name, and you tie that to the user sessions, exactly.



LEO:  You're just generating unique domain names.  That makes sense.  So that way you can just say, well, what domain name asked - who asked for this domain?



STEVE:  To whom did we send this query.



LEO:  Right, that makes sense.



STEVE:  Yeah.



LEO:  So then you could handle it, I presume, millions of times a second.  I wonder how they do it now?  Do you think they do it that way?



STEVE:  I wouldn't be at all surprised.  I mean, that's a nice, solid, robust way of doing it.  And GRC does lots of spoofability tests.  I can handle huge numbers of people doing that, yeah.



LEO:  Okay.  Jessica Tallon, Lancaster, U.K., notes LastPass Password Iterations:  [Bad accent] Hello, Steve.  Sorry, Jessica, that's mean.  Hello,  hello, hello.  Mary Poppins.  I religiously listen to Security Now! and would first and foremost like to thank you on the fantastic job you and Leo do, not to mention the wonderful "Over the Sugar Hill" episodes.  I remember a while back you mentioning Last Pass would soon start offering password iterations.  You said they were in the implementation phase; however, I don't recall you following up on that.



I was poking around my LastPass settings today and noticed, when you log into your vault and check the Settings option along the left-hand side in the General first tab, you notice a new entry, Password Iterations.  By default, at least for existing users, it seems to be set to 1, which of course means no added security.  But it does recommend cranking it up to 500.  I cranked mine up to 1,000.  That's the highest it recommends.  I thought it should be something worth noting as it isn't automatic, and the user must take action to ensure they get this added security.  Thanks again, Jessica Tallon.



STEVE:  Yes, I wanted to pass that on.  It's a very good point.  Anyone signing up for new a LastPass account will have their default set to 500.



LEO:  Ah.



STEVE:  But any of us who have been using LastPass since I first did the careful comprehensive podcast about it, or anyone who knew of it before then, will have, as I do, or did, rather, it's still set to 1.  So it needs you, the LastPass user, to go there and crank it up.  They allow the setting up to some huge number, 100,000 rounds.  But the problem is, all devices that you use LastPass from would have to be fast enough to do that, and things like iPads or iPhones or something may not.  So they recommend not going - you could go to a thousand, if you wanted to.



But they're already using SHA-256, which is a deliberately slower hashing algorithm than SHA-1.  So the reason you do these multiple rounds is to slow down any brute-force attacks.  So they recommend 500.  Our listeners probably want to go a thousand.  And the only consequence is a slight delay when you're authenticating, just that one time that you're providing your password.  In your browser it's got to crank doing this crypto X number of iterations where you decide what X is.  Then it sends the final hash to LastPass.  So I just wanted to - I thought it was a great note to let everyone go look in your vault, click on Options or Settings, and right there you'll see, in red, they've got - it's highlighted for me.  It was in red because mine was still set to 1.



LEO:  Yeah, so was mine, yeah.



STEVE:  Of course, yeah, I cranked it up.



LEO:  Yeah, so...



STEVE:  So thank you very much, Jessica.



LEO:  Yeah.  And you think 500's adequate?



STEVE:  Yeah, I really do.  I'm sure those guys recognize - they used a slow algorithm and so forth.



LEO:  So this is to make your password, your login to LastPass password more secure.



STEVE:  More resistant to brute-force attack.



LEO:  It slows them down.



STEVE:  Exactly.  



LEO:  Okay, good.  I'm doing that right now.  And since it is both client and server side, as you said, you want to make sure that you don't set it too high because your iPhone could take a long time to log in.



STEVE:  Because, yeah, all of this, all of the hashing is done on the client.  So some clients are slow.



LEO:  Right, although I think an iPhone's pretty fast these days.



STEVE:  I think it probably is.



LEO:  Mike Calmus in Washington, D.C. wonders about Microsoft's "you're doing it wrong" attitude toward security:  Steve, I submitted the following problem report to Microsoft regarding Internet Explorer and got the subsequent response.  I wonder if you could comment on this attitude industry-wide and possibly help get Microsoft to do something about this issue.  Thanks for Security Now!.  Love the show.



My message to Microsoft:  "When client certificate authentication is used in a website in Internet Explorer, particularly with a Common Access Card (CAC), IE caches the certificate information such that the browser must be completely closed, all windows and tabs, for another user to use the system.  If the browser is not restarted, the original user's certificate will be presented to the website, and that user's information may be then disclosed. This occurs even after an Access Card has been removed from the system.  This occurs in all versions of Internet Explorer that we've tried." 



Their Response:  "Hello, Mike.  Thanks for your message.  Completely closing out all browsing sessions is considered a best practice for ensuring that any information present in the browsing session is completely removed, including authentication cookies and SessionIDs."  Then they point to a discussion on MSDN.  "Regards, Nate."



STEVE:  I'm no apologist, lord knows, for Microsoft.  But I think - I thought about this for a while.  And I don't disagree, frankly, with Microsoft's statement.  The problem is really that we're asking for something from our browsers that they're just not very good at.  I mean, this is similar to the advice to log out, manually log out of a website that you're persistently logged into.  Otherwise, as we all know, somebody else could come along, and the browser doesn't know it's not still you.  So the problem of the common access card not being pulled constantly is an efficiency and performance tradeoff.



I guess my feeling is, if you're needing to use your browser in a mode where you really need user authentication security, then perhaps enforcing the use of the private browsing option that all of our browsers now have where, where when you terminate private browsing, it expressly isn't saving anything persistently on the machine, I think that's probably something that the server serving the pages could and should detect and verify.  And unfortunately, it is the user's responsibility to revoke authentication because otherwise our browser-based authentication is sticky for the sake of convenience.  So it's one of those security versus convenience tradeoffs.



LEO:  Yeah.  All right.  So I think that that makes sense.  The choice they've made makes sense, is your point.  You could argue about it.  But I think it's not just for these  CAC certificates.  There's lots of reasons why you need to restart your session.  The problem is, in Windows, well, no, I guess Windows actually does it better than Mac.  On the Mac you can close all windows, and the app will still be running.  On Windows, when you close the last window, the app closes.  So presumably, if you've closed the last window, you now have restarted the browser; right?



STEVE:  Right.



LEO:  So actually that's another reason why what they do is probably the right thing to do.  There has to be a window still open for the browser to be running.



STEVE:  Yup.



LEO:  Jody in Florida wanted some clarification about there's two kinds of salt?  Well, yeah, you have your sea salt and - no, not that kind.  Steve, in your discussion about salted hashes in Episode 357, you grabbed my attention when you seemed to distinguish between a generic and a per-user salt.  I'm familiar with the situation where each user has their own unique, random salt value and assumed that's what's always done to implemented salted hashes.  Are you saying sometimes there's only one?  Are you saying, Steve, sometimes there's only one salt value system-wide, used to compute hashes for an entire user database?  If so, then your opinion that the salt should not be stored with the hash values makes a lot more sense.  In the case of per-user salt values, it always seemed to me storing the salt values on a separate server from the hashes isn't going to provide significantly more security because it's already one per user.  I hope I'm not the only one that could use some clarification on this.  Thanks, Jody.



STEVE:  So, Jody, yes.  One thing to remember is that many of these database exploits are obscure SQL database table traversals which we talked about years ago where you inject some cross-site scripting and explore what the table names are and end up dumping it out, like through the browser, actually, and acquire a database that was never expected or supposed to be exposed publicly through that channel.  But what that means is that the bad guys haven't actually penetrated your network.  They're not roaming around from machine to machine.  And it's not like you got infected by Flame or some serious spyware.  Certainly that can happen, and could.  But typically they've just gotten the sort of a shoehorn in that lets them get the database, which means they have no access, for example, to a system-wide hash which is not stored with the database.  If you stored the hash, the per-user hash along with the hash, and they get the database, then they get both of those things.



So that's why last week I explained why really best practice is to do both, have a system-wide hash not in the database but just sort of like in the code somewhere, which could escape, it could become known, but it also may not.  And if not, it just provides you with additional security.  And then also you want to do a per-user hash because that just makes it zero effort to implement, and you really do get better security.



LEO:  Bill Prast, Tampa Bay, Florida, wonders about a career - oh, this is the one you were talking about - wonders about a career in Internet security:  I love Security Now!, wake up listening, throughout the day and at night, and I listen still.  [Laughing]  Just to Security Now!, over and over and over again.  I'm an IT Security AS degree seeker, currently prepping for a CCNA security credential.  You and Leo give me an inspiration.  I'm a 27-year-old single dad and night-time student.  Good for you, Bill.  He's working hard.  I work in the IT field now.  It's great experience, not so much money.  What kind of career outlook do you think I'll see in a year in the IT security field?  What can I expect to face in the IT security field?  Bill Prast, IT technician at General Telecom LLC, studying for his security credential.  I think that's great.  Good on you, Bill.



STEVE:  And for what it's worth, many of our listeners are students and have been inspired by the podcast to focus on security.



LEO:  Oh, we're required listening in a lot of classrooms.



STEVE:  Yeah, we're assigned.  And I really do think there is a bright future.  I mean, I wish there weren't from the standpoint of, boy, isn't it too bad.  But increasingly in the future, security won't be something outsourced.  It won't be something that is an afterthought.  It won't be something where a company hires a security consultancy to, like, set things up and then wander off.  There will be an in-house security person.  And I just think - one of my theories of employment in the future is specificity.  The more specific your skills are, you can be found on the Internet, you are something that people understand.  And being security, I think, makes a lot of sense.  It is, unfortunately, a growth industry.



LEO:  Yeah, exactly.  Good business to be in today.



STEVE:  And Leo, you've got to go...



LEO:  No, I don't have to go.  No, no, no.  Let's keep going.  I'm having a good time.



STEVE:  Two more questions.



LEO:  Two more questions.  We can make it.  We're trying to keep the show a little shorter per request of many people on Twitter.  Not too short.  Don't worry.  It ain't gonna be a 10-minute show.  No way.



STEVE:  No, we're an hour and 20 minutes right now.



LEO:  Yeah, we're good.  I think an hour and a half is the right length for the show.  Ben Moore in Southaven, Mississippi, wonders what the heck is JavaFX?  I'm a longtime listener to Security Now!, proud owner of SpinRite.  I pretty much quit installing the Java Runtime Environment on new computers.  Still have a lot of older ones where it's installed.  Recently these older computers started upgrading to Java 7, but when they do they're also silently installing something called JavaFX.  What the heck is JavaFX, and why do I need it?  Maybe I should just uninstall Java everywhere.



STEVE:  [Sighing] Okay.  So this is more bad news.



LEO:  Oh, no.



STEVE:  Yeah.  This is Oracle deciding that they want a piece of the Flash/Adobe AIR/Silverlight market.  This is their special effects delivery platform.  It used to be a script that would run under Java, and they've now compiled it into byte code as a separate library, and they're now promoting it as essentially the same thing as Adobe AIR or Microsoft Silverlight, one of these content delivery platforms, to provide a library of helper effects for people who want to do this in Java.  And sadly, they're just sending it out, along with Java 7, which we know will have things that are exploitable.  There will be mistakes there.  People are getting it even if they don't use it, which means that websites, web browsers will display something, fall through some glitch in the code, and get their users in trouble.



LEO:  Great.



STEVE:  So I say, more than ever, if you don't know you need Java, get rid of it.  I love what Apple has done.  The notion of it disabling itself and requiring you to manually say, yes, turn Java on...



LEO:  That's how it should be.



STEVE:  Oh.  It is exactly the way...



LEO:  On a per-session basis, yeah.



STEVE:  Per instance, yes.



LEO:  So it doesn't just remember that.



STEVE:  And if you leave it on, it turns itself off again.  That's where we're headed...



LEO:  It's the right way to do it.



STEVE:  ...is that kind of security.



LEO:  And that would be good for everything.  You don't need to have it running always.



STEVE:  That's called NoScript, Leo.



LEO:  Yeah, oh, yeah, that.  Oh, yeah, that.  All right.  You're going to win eventually.  Charlie Guthrie in Richmond, Virginia - I'm sorry, Richmond, California, just down the road apiece - wonders about his voice as a password:  Steve, Vanguard, the mutual fund company, now offers the choice of using voice recognition as a password.  Not as a password for their website, only when you're interested in talking to them on the phone.  Before when you called they asked you several prearranged security questions.  Now you just have to repeat a set phrase, and if the voiceprint matches, they'll talk to you.  I don't think you've ever discussed this technique on your show.  I was wondering if you consider it to be secure, that is, secure assuming they do everything else right, like securely storing the voiceprint and so on.  That's interesting.  Voice calls are only 8-bit sound, so there's not a lot of information there.  Maybe it's enough.



STEVE:  Right.  Certainly the loss of fidelity over a phone is a big problem.  What's interesting is that I did a little research because I was fascinated back in my high school years with speech synthesis.  And in fact one of the things I did at Stanford's AI lab was program their DEC PDP-10 to sing the Eagles song "Desperado."



LEO:  [Laughing] "Desperado."  Was it good?



STEVE:  Actually it was.  There was something called a Votrax synthesizer which was a phoneme, something called a formant synthesizer.  The idea, the theory of speech is that you have what's called a buzz source, which is our vocal cords, and then the actual physical...



LEO:  The mouth shapes it, yeah.



STEVE:  Yeah, well, actually our throat and tongue, all of the aspects of our larynx physically shapes that.  And forensic studies that have been done by the FBI and other law enforcement have shown a remarkable specificity for recognizing specific voices.  That is, for example, in a courtroom, they have shown better than 0.3, lower than 0.3 percent error.  So extremely low error.  Now, this isn't - it's not just you speak and we will identify you from our entire user base.  No.  The way this works is, we have figured out who you are before.  In setting this up, you've identified yourself.  You're saying this is who you are.  We have your voice on record.  And so it's an AB comparison system where it verifies - it's very much like a thumbprint, where at the DMV you gave them your thumbprint, and then later on they say is this the same thumb that we saw before.



LEO:  The thumb's harder to record, though, than voice.  What if I have a recording of that person saying that sentence?



STEVE:  It is absolutely spoofable, yes.



LEO:  Very easily.



STEVE:  Yes.  So it's not super secure.  But over a phone line, I guess my point is that, if you know who you're expecting it to be, then you actually can rule them out or not.  And it is incredibly difficult for someone who has not recorded the authentic voice to spoof them because no two people have the same physical throat mechanics.  And so it's both physical throat sizes and also then - and that's sort of like static aspects, and then the dynamic aspects of the actual way they speak that specific phrase.  So I think we're going to see more of it.  Certainly it's been fodder for sci-fi for a long time.



LEO:  Cutting off people's thumbs has also been fodder for more than sci-fi.



STEVE:  Right.



LEO:  Great episode.  Great questions.  Thank you all for asking.  You of course can go to GRC.com/feedback to ask your questions.  That's Steve's site.  You can also follow Steve on Twitter.  He's @SGgrc.  He also has @SGpad and @SGvlc.  You didn't really follow the Microsoft Surface announcement, huh?



STEVE:  I didn't.



LEO:  I'm curious, well, at some point you'll - it's one of those things where they didn't announce availability, price or anything.  So it's going to be - they said when Windows 8 RTMs, but that's - who knows when that is?  September?  I don't know.



STEVE:  Well, and I'm just not a Win8 person, Leo.  I'm staying with XP till...



LEO:  I guess you're the wrong person to concern yourself about this yet.



STEVE:  Yeah, that whole pane look, or whatever the hell they call it, it just looks awful to me.



LEO:  Yeah, I can't really imagine you - it's like having a command line person use a GUI.  It's just a little too much.



STEVE:  Yeah, that was a painful transition, too.



LEO:  I'm sure that was very difficult for you.



STEVE:  I only launched Windows in order to use Micrografx Designer back in the early days, when I actually needed graphics.  Otherwise I was happily in my command prompt, writing SpinRite in assembly language.



LEO:  And I presume, because I know you have some Macs, but you don't use OS X day to day, so I presume you did not order one of those Retina Display MacBooks.



STEVE:  No, but I did salivate.  I just don't use it enough to justify a couple thousand dollars.



LEO:  Neither do I, but I did it anyway.



STEVE:  I know you did.



LEO:  And now I can't use anything else.  I have to use my iPad, my iPhone, and my Retina because everything else looks blurry.



STEVE:  It really is spectacular.



LEO:  It does make a difference.  You start to get used to it.  It's not a good thing, actually.  Don't get used to it.



STEVE:  I noticed that when I had my iPad 3 underneath my antiglare plastic for the one I carry around outside.  And the two that I have in the house are not antiglare.  And, oh, they look so nice because the antiglare filter does knock back some of the sharpness of the screen.



LEO:  They've done something, because I know you don't like these shiny screens, but they've done something in the new MacBook Retina that is much less glary.  I don't know, maybe there's micro scoring or something, because there's some glare, but it's blurry.  It's not the mirror image that you used to see.  So it is, it's much nicer in that regard.



STEVE:  Good.



LEO:  And I'm sure they'll put that on the iPad next time.  Steve Gibson is at GRC.com.  That's where you go to find SpinRite, the world's finest hard drive maintenance and recovery utility.



STEVE:  Don't be shy.



LEO:  Don't be shy.  Buy, buy, buy.  Come on down.  You should have, like, a sale someday.  10 percent off for the first 20 buyers.  Nope, nope, nope.  I said it, he didn't.  Don't get your hopes up.  You can also get a lot of free stuff.  See, that's the point.  Steve gives you everything except that one thing.  And maybe the Ketosis Flute.  Think we're going to have to charge for that.



STEVE:  Well, and what we do, I'll note that even somebody who bought SpinRite 20 years ago, we will still give you a discount on today.  So we are never going to leave anybody, any of our users high and dry. 



LEO:  Steve is conscientious, that's for sure.  He also spends a lot of his money on things like transcriptions of this show.  He makes 16Kb versions.  That's all available at GRC.com.  For the larger file size or the video, you can get that at TWiT.tv.  We do Security Now! Wednesdays, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, soon to be even more on time.  I'm working on it.  I'm going to get out of bed earlier so I could be here on time.  11:00 a.m. Pacific, or 1800 UTC, for those of you worldwide.  And I just wanted to mention that we've got a team of geeks.  I thought they were in a biker gang, but they say no, we're an IPTV gang in from Canada, actually Adam Erstelle, Kirk Fierback, Ken Delaney, Lyle Bryant - the handwriting's not mine - and Grant Backus [ph].  Thanks for you guys to come in.  And they all enjoy the show.  They were just on tenterhooks the whole time, Steve, seriously, the best audience is during this show because they're like the super nerds.



STEVE:  Glad to have them.



LEO:  It's like having five Sheldons.  No, I'm just kidding.  Thank you, Steve.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#359

DATE:		June 27, 2012

TITLE:		Coddling Our Buffers

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-359.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a few items of security and privacy news, Steve and Leo return to the Internet's "Buffer Bloat" problem to share the new solution "CoDel" (pronounced "coddle") that has been developed by several of the Internet's original and leading technologists and designers.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's going to debunk that whole RSA SecurID broken thing and then talk about buffering, how we can fix buffer bloat.  There's a technology, I kid you not, called CoDel.  Stay tuned.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 359, recorded June 27th, 2012:  Coddling Our Buffers.



It's time for Security Now!, ready to cover your privacy and security needs with this man right here, our Explainer in Chief, Mr. Steve Gibson of GRC.com.  Steve, good to see you again.  We're a little late today because we just finished our live coverage of Day 1 of the Google I/O Conference, the developers conference.



STEVE GIBSON:  Yeah.



LEO:  Do you go to developers conferences?  Microsoft has them; Apple has them; Google has them.



STEVE:  Back in the day, I used to.  I used to go up to Redmond and hang out with Google stuff, I mean with Microsoft back in the day.



LEO:  Yeah, I've been to a few of those.



STEVE:  And of course every COMDEX that there was I used to do breakfast with Philippe Kahn.  He would always invite me up.  And I'd go to parties and see Steve and Bill from Microsoft and hang out.  And I did go famously to the RSA Security Conference a few years ago, where I ran across Stina Ehrensvrd of Yubico and found the YubiKey.  But in general, my sense is I can look at the schedules of the conferences, I can pick up the keynotes, I can look at the PDFs, read the research at length - which is, for example, what I did for our podcast today.



Several months ago, when the term "buffer bloat" was in the news, we did a podcast about buffer bloat.  We'll review that briefly today because I want to explain the operation of the solution, which some fabulous Internet architects and designers have designed.  And it's like, okay, now we just need it deployed.  And that's the next step.  But essentially they've come up with a really, really nice solution, which is really interesting to have when we look at how hard it has been for the industry to have something.  This issue of how to deal with routing buffers on the Internet is as old as packet-switching because it's a problem that arises from that.  And it has fought every prior attempt to wrestle it to the ground until now.  We have a solution.



And then the big news of the week, we don't really have that much news, but the big news that got unfortunately picked up and completely blown out of proportion is - and I heard you mentioning it yesterday or Monday, I guess it must have been yesterday, about the scientists so-called cracking the RSA SecurID tokens.  Ars Technica picked up on it.  I got tweeted by everybody.



LEO:  I knew you'd cover it.  Yup.  Good.



STEVE:  Yeah.  So we have that to talk about, and just random tidbits and things.  I also have the not-yet-published next book by Mark Russinovich that we'll talk about, that I have just finished.



LEO:  Good.  I just got Daniel Suarez's new book.



STEVE:  Oh, cool.



LEO:  Yeah.  So we can compare notes.  All right, Steve.  What's the story with the RSA tokens?  I mean, that's a big deal, if they've been cracked.



STEVE:  Okay, yeah.  And they have not been.



LEO:  Oh.  But that's what the headlines said.



STEVE:  I know.  I know.  Even Ars Technica, that I respect a lot and who often gets things correct, said - their headline was "Scientists crack RSA SecurID 800 tokens, steal cryptographic keys," which is not at all true.



LEO:  In under 15 minutes.  No?



STEVE:  Yeah, okay.  So here's the deal.  Bruce Schneier's famous quote is fantastic.  It applies here.  He says:  "Attacks only get better, they never get worse."  Which reminds us that, over time, academic researchers chip away at security.  And we've talked about that in the seven and a half years of the podcast, over and over and over.  We highlight instances of that, things like, for example, the MD5 we were talking about recently, the Message Digest 5, the MD5 hash, where as researchers continued to look at it, they poked at it and began to find some soft spots.



Well, there are standards associated with public key technology, asymmetric and also symmetric key technology, which researchers have long known about.  The annoying thing about the paper that will be shown in August of 2012 at a major upcoming crypto conference is essentially an additional improvement on the efficiency of already known existing soft spots.  So this, for example, is another reason that it's now time for us to be moving to 2048-bit asymmetric public key technology, up from 1024, because the researchers are continuing to look at these problems and getting better at it.



Now, way back in '98, so quite a while ago, there was a very sharp researcher, looks like I'm probably going to mispronounce his name, I would say Bleichanbacher, came up with what was sort of commonly known as the "million probes" attack.  The idea is - this is the idea, both for the asymmetric public key attack and the symmetric attack, both of which were addressed in this paper that will be shown in a month and a half.  And that is, any crypto algorithm that is in common use, the normal public key technology and symmetric key, they normally encrypt blocks of a certain size.  For example, when we say "AES encryption," that's a 128-bit block that has various key lengths - 128, 192, or 256-bit keys.  But the block size is always 128.



Well, what that means is that, when we're encrypting data, it's going to be uncommon, or unlikely, it's actually one in 128, that the actual length of our data would exactly fall into a multiple of the block size.  So the question is, what do we do with the last block?  And the solution is, the cryptographers have come up with what's known as "padding," where we pad the data out to the size of the block.  So it turns out that the smart academics have figured out ways to get current state-of-the-art crypto systems to leak a little bit of information.  And we've talked about some ways that happens, the so-called "side channel" attacks.



For example, right now we understand the danger of a side channel, for example, if a crypto algorithm used a different amount of power, depending upon the key that it was encrypting with, or if it took a different amount of time, depending upon the key.  Well, those things that are like power or time, that are not about the data going in and out, they allow clever cryptographers and potentially bad guys, which is really the problem we're worried about, to glean some information.



So that's what happened in this case is back in '98 this million probes padding attack was demonstrated where the padding used for public key crypto could be used in order to probe for the key.  The way this happens is you take something which has been encrypted, and for example, if you give it back to this algorithm to decrypt, and you haven't altered it, it'll say, yeah, fine, here, I decrypted it for you.  But if you deliberately damage the encrypted data that you give it back to decrypt, once it believes it's decrypted, these algorithms check to make sure that the padding is correct, sort of as a form of checksum.  And  they will then respond, whoops, there seems to have been something wrong with what you just gave me.



Well, that bit of feedback turns out to be very, very weak, that is, the systems are so good that cryptographers have thought about this a lot and looked at it.  And it's like, okay, a million probes.  And then maybe there's a statistical chance that we can learn something, so forth and so on.  Okay.  Well, the efficiency of that was doubled in 2003 by a researcher, Kilma and his group, who were able to come up with an improvement.  And then these guys, the authors of this paper and the subject of these news stories, made that attack essentially five times again more efficient.



So that today, with the actual technology in use, RSA SecurID Model 800 tokens, the Estonia government-wide secure ID card that has been issued, and a number of currently-in-use technologies in, as you said, Leo, in what has now become a matter of minutes, well, RSA got hit because theirs was the fastest to crack.  I think it was 13 minutes.  Now, we're not talking 13 lazy minutes.  We're talking...



LEO:  Hard-working minutes.



STEVE:  Hard-working, high-speed computer, so forth and so on minutes.  Other of the systems are more like 90 minutes.  But I saw some 96 hours to do some things.  But still, I mean, we're no longer in millennia, which is where we would like to be with our crypto; but significantly, neither have the keys been stolen.  All of this is one particular instance of a key that was used and encrypted can be determined, that is, all of this is about a hardware device - and we've talked about HSMs.  Yubico has got one on the way, the Hardware Security Module.



The idea is, because we've given up trying to secure our computers, we just can't, we've decided, okay, we will move the sensitive stuff out of RAM into a little hardware box and plug it in by USB or Firewire or whatever.  And we'll ship the stuff out to it, have it do the work, and then it just kind of gives us the answer.  But so basically they're creating a black box.  So that's been the solution we've come up with because it's the only way we've figured out we can secure anything because we've, as I said, given up on securing the machines themselves.



So what these attacks do is they would, for example, as we have talked about, if you're encrypting a file, you generate a pseudorandom key, and that's fast for bulk encryption.  Then you encrypt the file with that.  But then you encrypt just that key using public key technology, which is inherently slow.  So you just encrypt the key that you used for encrypting the entire file.  And that way you're able to minimize the amount of processing, but you have essentially the strength and flexibility of public key crypto without having to go so slowly.  But this technology could allow them, in a distressingly short period of time, to figure out one key, that is, not crack the token, not get the sequence of numbers it's going to generate, not have it reveal its own secret private key, but just probe it and poke it to get sort of like one answer.



So what's most distressing is these problems have been known for a decade.  In sort of following this trail back, I found the so-called PKCS #1 standard - PKCS is Public Key Cryptography Standard - on the RSA website.  And what everybody is using now is PKCS #1 v1.5.  And this is...



LEO:  By the way, that's what the crack is against, not against particularly the SecurID token.



STEVE:  Correct.



LEO:  It's just that it uses PKCS.



STEVE:  Yes.  And everybody does.  It's a standards-based API that gives you inter-token interchangeability.



LEO:  The RSA folks were quick to point that out, saying that it's an academic exercise and not a useful attack.  Does that seem fair, to characterize it that way?



STEVE:  Okay.  One of my favorite cryptographers besides Bruce said - his name is Matthew Green.  And I loved his quote about this.  He said: "Never continue using a broken primitive only because the known attacks seem impractical today."



LEO:  Right, right, right.



STEVE:  And so here's the point.  PKCS v2.1 was published on June 14, 2002.  Okay?  We're at June 27, 2012.  The 2.1, actually 2.0 even, fixed this problem.  Nobody moved.  Nobody adopted it.  For 10 years, Leo, this thing has been solved.  But it's like, well, yeah, we know there's problems with 1.5, but for the sake of backward compatibility, that's what we're going to support.  And so, okay, a decade ago, maybe it made sense.  Here we are 10 years later, and nobody has moved off of 1.5.  These attacks are only effective against that standard, not the new one.  And all of this has been known.  But the industry has been sitting around, saying, well, exactly as you quoted RSA saying, there aren't any practical attacks; and, besides, we're selling lots of these.  So we're not going to worry about it.



So that's the story.  The good news is, this is, unfortunately, and we see this over and over and over, this is what is required to get people to get off the dime, to update themselves, to keep themselves current.  It's not until something bad like this happens, well, it's exactly like Microsoft, that last year finally stopped using the MD5 hash, only last year.  That was the weakness that has allowed Flame to get its foothold was that there was a newfound means of doing a chosen prefix attack on the MD5 hash.  Had Microsoft stopped using it back when all the cryptographers said stop using it, we no longer can trust MD5, that wouldn't have happened.  So we have exactly that scenario again.  Ten years old is the spec that completely shuts this down.  Nobody's using it.  So the good news is they're probably going to start now.



LEO:  And there's nothing to fear right now because it isn't in the wild exactly.  Maybe it is now, I guess.



STEVE:  I would say, if you were - and that's the other thing is that the press ran around in a froth, trying to figure out what this meant.  And it's, exactly as you said, a theoretical attack.  I would say you don't want to hand your RSA SecurID token to bad guys and let them pound away on it for a few weeks.  That would be an unwise thing to do.  Although it's not like they can get anything from it.  They have to have a specific target that they're using it to crack.  So it does mean you want to keep your tokens close to you because this stuff does go from theoretical to real.



You can imagine, the NSA is probably drooling in some lab somewhere.  It's like, oh, goody, now we have a way of hacking these things more quickly.  And who knows what access they may have or tokens they may have acquired over time that they haven't been able to crack.  Now this technology lets them do that.  So this is the kind of thing that certainly has real-world application, yet it represents more of a policy failure throughout the entire crypto industry than it does anything else.  It's just like, well, sure, the academics are poking away, but that's what they do.  Now, this surprised people by bringing the attacks down into the mere hundreds of thousands from the millions, making it orders of magnitude faster.  And suddenly it becomes real.



So anyway, that's what that was about.  And this is, I mean, this is what we see over and over and over.  This probably just needs to be regarded as the process.  This is the process that the crypto industry has, sort of that tension that exists between the academics that designed these things and then tear them down, and the commercial side that wants to profit from them and is never in a big hurry to need all the old tokens obsoleted.  They'd rather not have to replace them all.  So every so often they have to.



LEO:  I use Google Authenticator, which is a software-based  program, does the same thing.  And I'm trying to - maybe you would understand this.  I don't understand it.  But I'm trying to figure out what Google Authenticator uses.  It says one-time passcodes are generated using open standards developed by the initiative for open authentication...



STEVE:  OAuth.



LEO:  ...the HOTP, yeah, it's OAuth, using HMAC-based one-time password and time-based one-time password.  But then it points to an RFC.  So I can't tell if it's using...



STEVE:  Yeah, so this is very much the same thing that, for example, some of the YubiKey modes are.  And it's the dongle that we talked about early on, the little football that PayPal and eBay were using, and I still have mine and use mine constantly.  That technology is not the subject of this because this is more the so-called HSM, the Hardware Security Module.  One thing was really interesting was that all these academics attacked relatively lightweight crypto solutions like these tokens, not the actual industry-strength hardware security modules.  Why?  Because they couldn't afford any of those.  Those cost 10s and 20s of thousands of dollars.  So they're much pricier, but they probably have the same problem.



But the good news is our little one-time password systems are - they're almost too dumb to succumb to this problem.  You have to have a lot more of a crypto engine in there, somewhere where you're giving it work to do, and it's performing crypto functions in a black box mode and then telling you - and then giving you feedback.  In fact, in one case there's one company's product is still in debug mode, where it dumps a log of what happened. 



LEO:  No.  Oh.



STEVE:  [Laughing] I know.  So it's like, thank you very  much for the debugging log.



LEO:  Hmm, that makes it a lot easier.  Yeah, handy.



STEVE:  Made it much easier.



LEO:  So it doesn't look like this Google Authenticator does use that particular technology, the PKCS.



STEVE:  No.  All it's doing is it's either a counter or - all of these things, I've got the little VIP, the VeriSign identity system, in my...



LEO:  That's not vulnerable, either.



STEVE:  No.  Those just generate a nice little key.  In order for it to be vulnerable, you have to have a device where, I mean, it's much more industry strength.



LEO:  Got it.



STEVE:  You give it some work to do, it's got a crypto engine in it, and it actually performs the decryption for you and gives you a result.  All of our little authentication technologies are just pseudorandom number generators.  So again, not victims of this kind of problem.



LEO:  Excellent.  Good news.



STEVE:  I picked up an interesting tidbit that I actually forgot to add to my notes, but then I saw it again.  I went, ooh, I just wanted to mention this, just as an indication of things to come which I'm glad for, and that is the news yesterday that the FTC, the U.S. Federal Trade Commission, has hit the Wyndham Hotels chain with a lawsuit over three hacker breaches in the past two years.  And so the story reads, "Wyndham Hotel Group just took the fourth blow in a quadruple whammy:  First, it was hit with three digital breaches over two years that affected more than half a million customers.  Now, the Federal Trade Commission has filed a lawsuit against the firm for allegedly misrepresenting the security measures that ought to have prevented those hacker intrusions.



"In a press statement Tuesday, the FTC claimed Wyndham had subjected consumers' data to an 'unfair and deceptive' lack of protection that led to a series of breaches of Wyndham hotels and those of three subsidiaries.  The statement describes a series of three attacks on the hotel chain and its franchisees, beginning in 2008, that first compromised 500,000 credit card numbers stored by the firm, followed by attacks that breached another 50,000 and 69,000 accounts at other locations.



"The commission claims that those breaches are the result of Wyndham's failure to properly use complex passwords, a network setup that didn't properly separate corporate and hotel systems, and 'improper software configuration' that led to sensitive payment card information being stored without encryption.  The FTC contrasts that lack of protection with Wyndham's privacy policy statements that claim to 'recognize the importance of protecting the privacy of individual-specific (personally identifiable) information collected about guests, callers to our central reservation centers, visitors to our websites, and members participating in our Loyalty Programs,' and promise the use of strong encryption and firewalls."



So I saw that, and I thought, oh, good.  I mean, unfortunately, it's this kind of publicity that again, as I've often said, will end up being the motivation in the boardrooms of the CEO to say to the CIO or CTO, okay, tell us this cannot happen to us.  And they squirm around in their chair a little bit and say, oh, well, you know, we need more money or time or whatever.  So it's just good news that we have some oversight like this.  And it's weird that it's the Federal Trade Commission, but it's because Wyndham is not doing what they are saying that they're doing.



LEO:  It's interesting.  If they start suing people for this kind of stuff, that's very interesting.



STEVE:  Yes.  I wanted to mention also that I had just a fantastic experience generating an SSL certificate last night.  And you don't often hear someone saying that.



LEO:  Never hear that.



STEVE:  No.  And this is DigiCert once again.  I talked about them before when I switched GRC, when I dropped VeriSign, now owned by Symantec, like a hot rock and switched over to DigiCert and was able to get a multidomain EV certificate.  I went through the whole extended validation process once.  GRC has the advantage of having been around for 20-plus years, so D&B knows about us and so forth.  So it was easy to see we have established addresses and phone numbers and so forth.



But the certificate that I got had a couple extra slots in it because, unlike VeriSign, that was going to charge me something like $1,300 per, I was able to get a four-slot single certificate for $550 or something.  So, I mean, radically more affordable.  It's the thing that, I mean, I've wanted to have, of course, an EV cert for a long time.  I ought to have one.  And finally it was my switch to DigiCert that enabled that.



Well, as I'm moving more and more toward GRC being always HTTPS, I realized that the media server that we've got, where all of the archived podcasts, for example, are stored, as well as the videos that I serve on the site, the media server didn't have an SSL certificate.  So last night I thought, huh, I wonder if I can actually make this happen.  And so I went back to DigiCert, logged in.  They found my account, and it said, oh, you have two free empty slots.  And I said, oh, that is just too cool.  So I went over to the server, the media server, had it generate a so-called certificate signing request, a CSR, dropped that onto the website, pressed the button.  It took maybe about five minutes for them to verify everything, see that everything was current and correct.



And it was only because I was adding a subdomain to GRC that this was an automated process.  So, for example, I have www.grc.com and GRC.com.  Those were the two out of the four slots I had filled.  Now I have media.grc.com.  And in, like, five minutes I received email with the signed certificate that I dropped onto the server, and we now have SSL.  So I know this sounds like a commercial.  I'm getting of course nothing from them except I want to help them because they deserve it.  These guys rock, and I am so glad that I made the switch to them.  So that's DigiCert, and I just can't say enough good about them.



LEO:  Good.



STEVE:  And while I'm saying good things, Leo, I've just finished our friend Mark Russinovich's latest book.  His prior book was "Zero Day," which I read and liked and talked about.  Now, the bad news is no one can get this yet.  Mark said, when I finished yesterday and wrote to him and said, okay, this was really fun - and in fact, what I loved about this, I was thinking of our podcast listeners.  And, I mean, I was depressed and chilled because I would recommend this when it's available, and it won't be until September, and I will remind people when it is.  In fact, I'm going to see if we could get Mark to jump on and talk to us because...



LEO:  Oh, that'd be great.



STEVE:  ...this is absolutely true.  It's obviously a fictionalized account.  But this talks about Stuxnet and Duqu, and it's an adventure written around the same two central characters, Jeff and Daryl, who he introduced in his first book, "Zero Day."  So we continue following them.  They're ex-NSA and CIA, but computer people, sort of who should not be out in the field, but they end up going out anyway.



But as I'm reading this, I'm thinking, okay, anybody who we want to explain how bad, unfortunately bad things are with security, this is the book because it's very accessible, it's very readable, and Mark just lays out how really sad the current state of cyberwarfare is, I mean, the fact that the U.S. electrical grid may well already be infiltrated with malware.  I mean, here we're chuckling about apparently the U.S. in Iran with the Olympic Games project, having designed Stuxnet and managed to get it into the nuclear enrichment facilities in Iran.  And just last week or the week before I was saying, yes, well, the joke may be on us because we're getting our chips from China that's in all of our networking gear.  So we hope that those don't have any extra functions added to them.



Anyway, this book is "Trojan Horse," not available for a few months, but I will let our listeners know when it is and see if we can have Mark come on to talk to us about it because, again, it's a great book.  But oh, my goodness.  I think our listeners will find it fascinating as a fictionalized account by somebody who really knows this stuff, and an incredibly accurate portrayal of how sad things are right now.  I mean, you really just want to unplug.  It's scary.



LEO:  Mark Russinovich was originally with a company called Sysinternals.  Microsoft acquired them.



STEVE:  Founded.



LEO:  He's a programmer.  Founded it, yeah.



STEVE:  Founded, he and Bryce founded Sysinternals, which generated some of the best Windows utilities that have ever been created.  And now he's a technical fellow at Microsoft, which is their most revered slot.  And it turns out he can write, too.



LEO:  He's a technical fellow.



STEVE:  I promised a second sort of surprising SpinRite story last week about SpinRite's success in recovering solid-state media, which we're beginning to see more and more because I've mentioned it.  And so this is Bill Murray in Wilmington, North Carolina, said "Hi, Steve.  I'd like to share another SpinRite testimonial with you.  I recently took a 7,000-mile motorcycle trip."  How do you ride 7,000 miles?



LEO:  With a sore butt.



STEVE:  Without running into some ocean somewhere.



LEO:  Oh, yeah.  But he went across the country and back, I guess.



STEVE:  He went around in circles.  Yeah, says, "I recently took a 7,000-mile motorcycle trip from North Carolina," where he's based, "to visit Colorado, Utah, and Arizona."  Okay, so he kind of made a big loop.  "During the trip I was taking several hundred photos per day.  Some were JPEGs taken with a point-and-shoot camera while on the move, and others were RAW plus JPEGs from my Canon DSLR.  Each evening I was copying my camera cards to both my Netbook, equipped with a 96GB SSD drive, and to a 32GB USB thumb drive, since I was quickly filling up my camera cards.  Unfortunately, I soon ran out of space on both the Netbook and my largest USB thumb drive.



"To conserve space, since the SSD was almost full, I began using only the USB thumb drive.  After returning home, when I went to import the USB thumb drive photos into Adobe Lightroom, I discovered that three folders, three days' worth of photos, were corrupt and unrecoverable.  Remembering that you and Leo had previously discussed a testimonial during a previous Security Now! podcast where someone used SpinRite to recover some Flash media, I broke out my copy of SpinRite which I had previously purchased to pretest drives for my Windows home server.



"I proceeded to check the USB thumb drive.  After completing the scan, to my amazement, I found it had recovered my photos in the corrupted folders.  I had some recovery messages about not being able to relocate some files, since they were marked "system" and hidden.  But it had worked.  Like many others, I want to thank you for providing this outstanding product.  Also, a huge thank you for the time and effort you put into the weekly Security Now! podcasts with Leo Laporte.  Bill Murray, Wilmington, North Carolina."  Thank you, Bill.



LEO:  Thank you, Bill.  Yeah.  That's nice.



STEVE:  Yeah.  So I've been sort of, for a while, thinking, well, I wonder whether SpinRite's life is coming to an end as our media stops spinning.  But although the name will be a little antiquated...



LEO:  Call it FlashRite.



STEVE:  It sure does, well, and I actually understand why.  Because all of this technology, they have controllers, and they have error correction.  And that's SpinRite's forte is dealing with that problem with error-prone media.  And in the same way that we have a problem with magnetic storage because basically they're always pushing the limit, trying to cram as much possible data into as small a space as possible, always making it just reliable enough.  Similarly, they're putting, for example, in the case of MLC, or Multi Level Cell storage, they're putting analog voltages into individual capacitors in these memories.  And as those voltages drift, the bits they read back are not going to be the same, so they need error correction in order to recover from a known expected error rate.  And that's where SpinRite lives is dealing with those kinds of problems.  So it does look like we've got plenty of future left still.



LEO:  Good.  I'd hate for you to starve.



STEVE:  And remember, people have been using it for 20 years, and it's still going strong.  So it does represent an investment for the future.



LEO:  There you go.  Steve, what is CoDel?  



STEVE:  Okay.  So CoDel is the way you pronounce the name of what will end up probably being the buffer management strategy which ends up dominating the Internet over time.  Sadly, we all have devices which are probably using what's known as "tail drop," which is the official term for if the buffer's full, and there's no room to put a packet, well, what can we do?  Throw it away.



So let's rewind a little bit and remember how we got here.  The fundamental, always understood problem with an autonomous packet-routing network is the need for buffering because, if you imagine like a lattice grid of nodes all connected to each other in a very complex topology where customers are located off of different of these nodes, and they put their Internet traffic onto a given node, that is to say, a router, and it sends it to the next one, which sends it to the next one, which sends it to the next one.



So you've got all this traffic moving, jumping from one router to the next as it goes from its source to its destination and back again.  And if you do like a traceroute command, the number of hops, as they're called, between routers, certainly it varies.  But we're used to seeing something like 13 to 17, something like that.  And we've talked about how the so-called "Internet diameter," that is, diameter of a circle is of course the two points that are the farthest possible away.  Similarly, the diameter of the Internet would be the two locations that had the largest number of routers between them so that the data has to go through that many hops.  And there was a problem that the so-called TTL, the Time To Live, was originally set at a number that was at the time reasonable, maybe 16 or 32.  Generally programmers like powers of two.



But it turns out that, as the Internet grew in size, more routers were added, and it was possible for an operating system to generate a packet that would never be able to make it to its destination because its time to live would expire before then.  So because we've got all of this, sort of this ebb and flow happening statistically, but without any overall plan, just sort of every packet for himself, it's necessary to buffer both packets coming into a router because they might be coming in from - you might have five or six all arrive at once from different interfaces.  And then the router figures out which interfaces each one needs to go back out of.  And you then need to put those in a queue, that is to say a buffer, so that they can move as soon as there's space available, and time, on the outgoing wire.



So buffering has always been present.  The problem, as we discussed it when we talked about buffer bloat in detail, is that there's been a tendency, as the price of memory has fallen, now there's just more and more RAM in these single-chip processors that all of our consumer routers are based on, and it's counterintuitive to a network engineer to think, wait a minute, I have a perfectly good packet here, and I have free buffer space.  Why should I drop it?  I've got room for it.



And the reason is there's a very subtle interplay between the overall efficiency of our protocols and time delay.  Big buffers create a time delay where more data is coming in than is able to go out.  I mean, anyone can sort of think of the model of a funnel, where if you put a lot of stuff in the wide open end of a funnel, and it's going out slowly, well, the funnel itself captures the material that's trying to get out through the smaller opening, and it holds it for a while.  So any given grain of sand sits in this funnel queue, waiting for its chance to finally get out of the funnel.  Rather than, if you were only pouring in sand at the rate it could flow out, then the delay through the funnel would be as near to zero as it can be, just the grain of sand's own passage through.  There wouldn't be a backlog.



So it's the backlog which represents a problem, and backlogs form any time you have a transition from a high-bandwidth connection to a lower bandwidth connection.  If you are sending things in at the high-bandwidth speed, they're going to have to back up.  They're going to backlog.



So many, as we've discussed before, many strategies have been designed.  In fact, it's an acronym soup of strategies.  I mentioned tail drop, which is the dumb one, the dumbest one, which is buffer everything until when a new packet comes in that needs to wait, and there is no place for it, we just drop it.  Now, again, as we've talked about packet switching, the way that works, it's inherently in the design of the Internet to tolerate dropped packets.  Routers are supposed to drop packets.  And what's interesting is that's informational; that actually the dropping of a packet in transit indirectly sends information back to the sender because the recipient never receives the dropped packet, thus never acknowledges the receipt.



And so the original protocol designers designed the Internet to function with the assumption of dropped packets and to deal with it.  So engineers that engineered larger buffers, and unfortunately these things chain, so if every router between here and there has a big buffer, then you can end up with many, many seconds required to get your data to transit from one place to the other.  And if we were only transferring big files, that wouldn't be such a problem.  But you and I, Leo, are having a conversation in near real-time over the Internet.



LEO:  It's kind of amazing.



STEVE:  And so we don't want to have a grain of sand stuck in a funnel where that's my voice trying to get to you.  And so these deep buffers really do not help anybody.  What we want is we want them to catch bursts.  We want them to, like, be a surprise.  Oh, suddenly more came in than we were expecting.  Well, as long as it doesn't persist, as long as that was a surprise event that will then quickly be removed, that's fine.  That's proper use of a buffer.  But not something that just sits there full and clogged with sand running over the sides of the funnel because more is coming in all the time than is able to get out the other end.



So the most popular solution is something called "RED," which is the acronym for Random Early Detection.  It's also been known as Random Early Discard, or Random Early Drop.  The idea there is we don't wait to have no room because obviously we have no room.  There's nowhere to put an incoming packet.  Instead, as we begin filling up, we increase the probability of discarding packets even though we've got room.  And counterintuitive as that is, you can imagine that that inherently causes the buffer to resist getting full.  It's discarding things before it's actually full because this is an acknowledgment of the truth, that discarded packets send a message to their sender.  Protocols are designed so that somebody that's sending things and stops getting them acknowledged will go, oh, maybe I ought to slow down.  And it's like, yes, that's the message we're trying to send you, slow down.



And so all these systems tend to throttle.  The problem is that, despite an amazing amount of industry being focused on this problem, as I said, acronym soup, all kinds of solutions proposed, there has never been one that works across the board, is independent of bandwidth, is independent of roundtrip time, is independent of traffic type.  Many of these things can be tuned for specific situations.  If you knew that your bandwidth was such and such, if you knew that your typical roundtrip time was going to be something, if you knew whether you had bursty traffic or more slow buffer, or if you knew you had UDP stuff or TCP, if you put all kinds of constraints on, then anybody could carefully tune a solution for a given set of traffic.



The problem is we no longer have homogeneous traffic.  We have heterogeneous traffic.  We've got all kinds of bizarre stuff happening, peaks and valleys, widely ranging bandwidth.  And in fact, what's interesting is that the problem with residential buffer bloat is largely caused by WiFi.  And I think it was - I was watching Tom and I think it was Brian Brushwood, they were talking about WiFi and maybe, like, grumbling.  I think he was using some sort of non-WiFi wireless to do some interacting with your studios yesterday.  And he went off on a rant about how useless free WiFi is in coffee shops or anything because it just...



LEO:  It's horrible.



STEVE:  Yeah, it turns out that the reason that is, is that what we can't see is that, as you move your hands around your laptop, as you rotate, as people walk by, the instantaneous bandwidth between you and the hotspot is jumping up and down and changing, and it's doing that separately for all the people who are trying to use it at the same time.  I mean, it's amazing it works at all.  And so as a consequence it really doesn't work very well.



So the challenge is huge.  So the news is, and this is just amazing when you put it in the full context of how big a problem this has been, how intractable it has been, how the best minds in the industry have been focusing on this, in fact, even Van Jacobson, who is the co-designer of this solution, he gave a speech six years ago, in 2006, and wrote a paper that never got published that was beginning to sniff at this, beginning to talk about this solution.  But it just never got adopted.



Now, the other problem is one of scale because we have big iron routers, like in Level 3 and at AT&T, with high-speed fiber optics, where the actual routing is done in silicon, and we have low-end blue-box pieces of junk that cost $30, that run off of a wall wart power supply, that have a low-power chip barely running Linux in a consumer router.  And the problem is the same.  It's at a different scale, but fundamentally nothing changes.  And so what they were looking for was something that solved this entire problem.



So this was developed by Kathleen Nichols and Van Jacobson.  Van Jacobson is known for having come up with a next-generation flow control for TCP.  It's called "Van Jacobson's algorithm."  And he is regarded as the guy who singlehandedly saved the Internet from collapse in the late 1980s and early 1990s, that is, the first version of TCP we're no longer using, and it would not have worked.  We needed a better means of flow control, and it was Van Jacobson who came up with the algorithms everybody is using today, Tahoe and Reno.  You've probably heard those acronyms.



LEO:  I've been there, but no.



STEVE:  Those are some of the approaches used for congestion avoidance in TCP.  So what Kathleen and Van Jacobson figured out how to do was they developed an algorithm, which I'm going to describe to you, and it's tricky.  But one of the things that's so nice is that it absolutely fits the need.  That is, it can run on, and is actually running on, Linux-based home routers.  The CeroWrt does have CoDel, the CoDel controlled delay buffer management in it now as an experimental platform.



So CoDel is parameterless.  There's no knobs, as they put it, for operators, users, or implementers.  There's nothing that needs to be adjusted.  The same algorithm can run in a $30 piece of plastic as runs on huge big iron, where all the routing is being done in silicon at the high end.  Same algorithm.  Unlike many of the algorithms that have been proposed, as they phrase it, it treats good queue and bad queue differently.  And by that I mean it keeps the delays low while permitting bursts of traffic.  So it's exactly as I said we want.



I need to make sure I use the right words and that I define these terms because a buffer is like the static container for the data.  The queue is the actual lineup of the packets.  So I'm going to try to make sure I use the right terminology here.  So the queue is the present list of waiting packets that are lined up in a queue in the buffer, waiting to be sent.  CoDel adapts to dynamically changing link rates with no impact on utilization.  And that's one of its coolest factors.  There is a PDF which was published by the ACM.



I'm trying to think, if you Google "controlling queue delay," Leo, I think it's the first link that comes up, controlling queue delay.  And same for our listeners, of course, if anyone is interested.  There's a PDF.  And Figure 7 on I think it's page 10, looks like page 9 of the PDF, shows how this performs relative to the random early detection and the tail drop algorithms in the face of changing bandwidths.  And it's just spectacular what they have done.  And as important as anything else, it is simple and efficient.  That is, because it needs to run in an underpowered chip, or be easily implementable in router silicon, it's very important that it's not overly complex.



So what is different from this algorithm from all prior approaches, the general acronym is AQM, Active Queue Management, and that's the term that covers any approach of any sort for trying to intercede in managing the queue, managing the list of waiting packets that are sitting in a buffer such that you are able to respond to bursty traffic, where at the same time you discard and drop packets intelligently to send the messages to the existing algorithms that they need to throttle themselves.



So what's extremely cool about this is that they maintain what they call a "single-state variable," which is the length of time that a packet has been in the queue, that is, what they call the minimum queue length, but it's measured in milliseconds.  And having more resolution ends up being good for this, and that's generally easy to do these days.  They use the term "packet sojourn time," as the packets sojourn through the buffer.  And I'll just abbreviate that PST so I'm not having to say it all the time.  But so think of PST, this packet sojourn time, as the length of time a packet sits in the buffer while it's in the queue moving forward as packets are sent out.



So their algorithm is, and this is the result of extensive testing in all kinds of networking configurations, they have what they call their "target acceptable PST," that is, what they call the "standing queue duration," is five milliseconds.  That's the number, five milliseconds.  So this CoDel algorithm has as its target that no packet will be in the queue longer than five milliseconds, that is, within a - it's a little bit more flexible than that - within a maximum of 100 milliseconds, so one tenth of a second.  The queue has to have dropped to five milliseconds sometime within a hundred-millisecond window.  So this so-called PST is a minimum queue length that has to have occurred within a tenth of a second.



When that PST, that packet sojourn time, has exceeded five milliseconds for at least 100 milliseconds, then a packet is dropped.  So even when the buffer's not full, but if the length of time a packet has been in the buffer has not dropped down to their target of five milliseconds any time within a hundred millisecond window, then they start discarding.  Essentially, this just sort of switches into a discarding mode, and they drop the first packet.



The next drop time, and this gets a little hairy, but I'll explain what this means in a second, the next drop time is decreased in inverse proportion to the square root of the number of drops since the dropping state was entered.



LEO:  So the more drops - go ahead.  You lost me.



STEVE:  The next drop time is decreased.  The drop time is decreased, so that means the drop rate is increased, in inverse proportion to the square root of the number of drops since it began dropping.  What that means in practice is it accelerates.



LEO:  Faster, okay.



STEVE:  Yes, it gets faster until it gets back to its target of five milliseconds.  And believe it or not, that's it.  That's all there is to it.  What this ends up doing is CoDel then acts, in engineering terms, as what's called a "closed-loop servo system" that gradually increases the frequency of dropping until the queue is controlled.  And it turns out in packet-switching theory there's actually a well-known relationship of throughput to the probability of dropping, so that dropping ends up helping your throughput.  And they end up then, they have on their site, and there's an appendix referred to in this PDF where they post the pseudocode, because this is all public domain, obviously this will be an RFC.  And I imagine, I hope that router vendors run to implement this, that the big router vendors like Cisco and so forth offer firmware updates, and even little routers, Linksys and the Cisco SOHO routers offer firmware to implement this because it turns out it is simple to do.



Even this inverse square root drop probability, it turns out that the inverse square root can be computed efficiently using only integer multiplication.  So even that isn't going to cause any great problem.  And the entire algorithm is implemented with just four variables:  the time of the first drop, the time to drop the next packet, the count of the numbers dropped since going into the dropped state, and then just a Boolean that says whether we are currently dropping or not.  And so it is really simple to do this.  I mean, it's no more complex than statistically dropping at a probability based on how long the queue is, which is the RED, the Random Early Drop or Detection approach.  It is simple to do.



In their paper they demonstrate exactly this WiFi nightmare of rapidly changing bandwidths.  And, for example, they start off at time zero with a 100Mb channel.  Then they drop it to one tenth of that, to 10Mb; then again by a factor of ten to 1Mb; and then jump it up to 50; and then up to 1Mb; and then down to 10 again.  And they show for all of those changes what CoDel does versus what the standard buffer management of either random early detection or tail drop does.  And it's just shocking how well CoDel performs.  It very quickly adapts.  It responds to the change.  And this little closed-loop servo that I described drops, I mean, intelligently starts dropping to keep the overall delay through the buffer short, yet also signaling in an optimal fashion to any TCP traffic that is going through that it needs to slow itself down.  And the consequence is essentially, after decades of trying, we've got this problem solved.



LEO:  Yeah, except you can only get it in one router.



STEVE:  Yeah.  Nobody has it yet.



LEO:  And I doubt this is the kind of thing you can do in firmware.  Maybe, could you do it in firmware and update existing...



STEVE:  Oh absolutely.



LEO:  You could.  So it's just software.



STEVE:  Absolutely.



LEO:  Just an algorithm.



STEVE:  Right now, yeah, right now firmware is maintaining, probably in a brain-dead fashion, just having a buffer, and is probably huge.  It's probably...



LEO:  So the fact that they've got these giant buffers, because they have so much RAM, is controlled by firmware, so you can change how this works.



STEVE:  Exactly.



LEO:  Even if you have all the hardware, you don't have to use it.



STEVE:  And that's been the problem, is that our own, our SOHO buffers in our SOHO routers, they now have buffers that are multiple seconds long in terms of our upstream bandwidth.  So when we're uploading something or trying to play, like, a game while somebody else is doing something in terms of bulk bandwidth transit, suddenly all of your interactivity, all of the game interactivity just disappears because, even though it's well meaning, this SOHO buffer fills up, and it's several seconds of delay.



Well, the bulk transit, the data being moved doesn't care.  But somebody who's trying to do an interactive online game, it just comes to a stop because, I mean, several seconds, think about that.  I mean, you and I could not be having a conversation.  We've all seen newscasters trying to talk to somebody via a satellite delay.  And you have to have some skill in order to control yourself and wait for that satellite delay and manage that kind of delay.  It's really difficult when you want to be interactive and operating in real-time.  So what they've got is something with minimal processing, minimal state.  You know that one of the things that they're very proud of is that they only need to track the minimum delay through the buffer.  They do not need the average.  And that's significant...



LEO:  That's a big difference, yeah.



STEVE:  ...because, yes, in terms of computation, to do the average you need to add up all the delays and divide by the number of packets.  To do the minimum, all you need to do is see what the timestamp of the packet as you're removing it is, and that's how long that guy's been there.  And then you maintain the smallest one you've seen within a window of a hundred milliseconds.  And if that's never down at your target of five milliseconds any time during a tenth of a second, then you kick into beginning to discard, and you increase the rate that you're discarding until you bring it down.  So it's got some state in it.  It kind of switches into we need to start signaling to the people who are using this buffer that they need to back off, and it does it in a way that seamlessly fits with the Internet's protocols.



So having this is the first step.  Getting it ratified, getting the word out, and getting it then moved into firmware gives us some hope that we're going to get this buffer bloat problem solved.  But users can keep an eye on firmware for their own routers because remember the problem we have is where we go from high bandwidth to low bandwidth.  That's the choke point, that funnel problem.  And all home networks have 100Mb local networks suddenly squeezing into a 2Mb uplink through a DSL or cable modem.  That's where their buffers fill up.  And so that's where we see this problem.  And what would happen is this would then provide signaling back to the machines in the network to slow down in order to allow the residential buffer to stay real-time, yet actually increasing the overall throughput, counterintuitive as that is.  They show charts where they show the throughput under these varying conditions, even though they're discarding intelligently, and it's right up between 90 and 100 percent; whereas the traditional algorithms collapse down into the low 10s of percent of overall throughput.  It's just - it's fantastic.



LEO:  Steve Gibson explains all.  And now if we can only get the router guys to put it in, we'll be good.  If you want to follow along with the transcripts - couple of people have said in the chatroom "I'm going to read this one" - you can go to the website, GRC.com.  That's where Steve lives.  He puts transcripts and 16Kb versions of the show, audio versions of the show there every week.  You can also get full video and audio versions at our site, TWiT.tv/sn.  Steve will be answering questions next week; right?



STEVE:  Well, will I?



LEO:  Oh, it's the Fourth of July.



STEVE:  Yeah.



LEO:  I don't know.



STEVE:  Well, the memo I got said that you guys...



LEO:  Take the day off?



STEVE:  Well, that we're not going to be prerecording.



LEO:  That's a shock.



STEVE:  I know.



LEO:  Do you want to do a prerecording?  I can check.



STEVE:  Of course.



LEO:  I can check.  I'll check with the people.  I'll check with the people.  But you're right, it is the Fourth of July next Wednesday; isn't it.



STEVE:  It's the Fourth of July.  I had assumed we would find some other time to record, but I got a note saying nope, there will be no prerecording of podcasts.  It's like, oh.



LEO:  Lisa's trying to protect me.



STEVE:  My thoughts exactly.  It did come from Lisa.



LEO:  Yeah, she's very aggressively protecting my time.  But she doesn't understand that this show must go on.  We don't miss episodes of this show.



STEVE:  We never have.



LEO:  Never have.  Let me check, and I'll get back to you.  But meanwhile, if you have a question, if it's this week or next, go to GRC.com/feedback and fill out the feedback form.



STEVE:  Yes.



LEO:  We will do a Q&A episode in our next episode, which is unknown when that will be.  And of course there's lots of other good stuff there, not just SpinRite, the world's finest hard drive maintenance and recovery utility.  You must have it.  But also...



STEVE:  It works.



LEO:  It works, even on SSDs.  But also lots of other great stuff that Steve gives away for free because he's just a nice person.  GRC, Gibson Research Corporation, GRC.com.  You can follow Steve on Twitter, @SGgrc.  He's also got some other - he's got a "vlc" for the "very low carb," @SGvlc.  He's got @SGpad for the pads.  I'm hoping we're going to get one of these new Nexus tablets in here, and we can take a look at that.



STEVE:  The Nexus 7, yes.



LEO:  Yeah, it looks pretty sweet.  We'll have details on that.  Thank you, Steve.  And you know what, folks, go to the calendar at TWiT.tv, and it will have - whenever the next recording is will be on the calendar.



STEVE:  And anybody who's following me on Twitter.  When I know what the story is...



LEO:  Oh, you'll tweet it, of course.



STEVE:  ...I will tweet it and let people know.



LEO:  Very good.  Thank you, Steve.  Steve Gibson.



STEVE:  Thanks, Leo.



LEO:  Have a great day.  We'll be back next time, unknown when, but next time on Security Now!.



STEVE:  Bye.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#360

DATE:		July 11, 2012

TITLE:		Listener Feedback #147

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-360.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is back!  He's refreshed, he's ready, he's going to talk about the Microsoft updates, security flaws, password leaks and, yes, your questions, too.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 360, recorded July 11th, 2012:  Your questions, Steve's answers, #147.



It's time for Security Now!, and what a great opportunity.  This is one of our most popular shows.  Steve Gibson is here, of GRC.com, our Explainer in Chief.  This is one of our most popular shows, and in fact one of the few shows that numbers are going up and up consistently.  And I have to think it's just people are more and more aware of the issues of security.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you after our two-week hiatus.



LEO:  Yes.  Thank you for letting me do that, by the way.



STEVE:  I'm not letting it happen again.



LEO:  Oh, no.  Why not?



STEVE:  Well, I missed it, actually.  It was like, wow.  It was odd not doing it.  And all I need is a little hour of your time, just to do a little time skew.



LEO:  So never again.  You're saying we will never miss an other episode again.



STEVE:  No.  And maybe it was good that we did one, just so that we broke our perfection.



LEO:  Well, I'm just going to say this.  You're going to be fighting, not me, but a person named Lisa.  And whatever you guys work out is okay with me.



STEVE:  All right.  And someone tweeted that we were okay until 2018.  They've already figured out when the next time is...



LEO:  Oh, once every five years.  That's good.



STEVE:  ...that July 4th falls on a Wednesday.  So it's like...



LEO:  Oh, well, that's fine.  In 2018 we'll take the day off.



STEVE:  What?  No.



LEO:  We'll discuss it then.



STEVE:  All right.



LEO:  Actually this was an important week because of the hoorah, and I don't know if you plan to talk about it - in fact, I should run through your outline, I don't think you are going to talk about it - of DNSChanger.



STEVE:  It's the topic of the entire next week's podcast.



LEO:  Ah.



STEVE:  Because Paul Vixie...



LEO:  Love him.



STEVE:  ...who is extremely well known, he's one of the Internet pioneers, he's a cofounder of ISC [Internet Systems Consortium] that are the creators of BIND, the leading DNS server.  He was very involved, it turns out, with the FBI's effort in doing it.



LEO:  Really.  Well, then I can blame him.  I'd like to hear his explanation of why this was such a good idea.



STEVE:  Well, as a matter of fact, that's what we're going to do next week.



LEO:  Good.



STEVE:  We're going to completely cover it.  And what was interesting was, as you said, it was like this biggest non-event.  I was...



LEO:  CNN said, "There is a major virus out there, and it strikes on Monday."  Morons.



STEVE:  Yeah, and people were coming up to me as they were hearing about it, saying, "Oh, Steve, do I have to worry about this?  What's going to happen?  I'm told that there's some horrible thing's going to...."  I said no, nothing is going to happen.



LEO:  Idiots.  Not the people.  I don't blame people because they're getting informed by news media that is stupid.



STEVE:  Yeah.  And people were being told that it was some malware that was going to strike them, rather than a six-month delayed reaction to something that was pretty much by now a non-issue.  It was weird that it captured the amount of press that it did.  But Paul Vixie...



LEO:  I was just disappointed that more people weren't angry at the FBI.  But maybe you're going to convince me that this was a good idea.



STEVE:  I think I'll be neutral on that topic because to me that's...



LEO:  Okay.  I'll be the negative.



STEVE:  What captivated me was the things that Paul said and wrote that I'm going to share with our listeners next week.  He had a lot of really interesting points to make.  So I'm going to share that, and then we're going to get into a discussion next week.



LEO:  I have huge respect for him, and of course he's the father of DNS.  So if he says it's a good idea, then I still don't believe it, but...



STEVE:  And actually he has a lot of good stuff about all of the recent - as I was digging into this, doing some pre-research for next week, I realized naturally he would have been very, very much out in front of the whole DNS filtering, SOPA, and all of that nonsense that we have been dancing around with.  So that's for next week.



This week is Q&A #147.  We've got 10 great questions.  Actually, some surprises that I encountered as I was going through the mailbag.  So we've got a great Tip of the Week to wrap it up, and something that surprised me is second to last, and a bunch of things to talk about.  But I just wanted - there was so much reaction, literally withdrawal, from us not having a podcast for our listeners last week, that I was going to assure everyone that, by hook or by crook, we'll make that not happen again.  But it was kind of fun to have it happen once because, you know.



LEO:  Whatever you say, Steve.  Another Patch Tuesday.  Seems like it was just Patch Tuesday.  I guess last month.



STEVE:  That's because we skipped an episode, Leo.



LEO:  Oh, come on, stop it.  Geez, you'd think I let something die or something.  Come on.



STEVE:  Oh, you didn't hear from the listeners.



LEO:  Oh, I hear from the listeners.  Are you kidding?  You think I don't hear from the listeners?  You think they don't contact me at the drop of a hat? 



STEVE:  Okay.



LEO:  I love hearing from them, but that doesn't mean they get their way every time.  That's your mistake.



STEVE:  We did have the second Tuesday of the month pass by just before the day that we skipped the podcast.  And we had finally the XML Core Services flaw patched.



LEO:  Well, well.



STEVE:  This was something - yes.  This was the zero-day exploit that we've been talking about every week since it was revealed because it was revealed shortly before June's Patch Tuesday, certainly not enough time for Microsoft to do anything, although they did put up one of their Fixit buttons, their single-click Fixit.  And I really strongly advised all of our listeners to go push that button because we just don't need XML Core Services in Internet Explorer for sites that we're visiting.  We can live without that.  Again, this is Microsoft's "default enabled" approach, unfortunately.  So they got that patched, plus 15 other problems of varying security.  There was, like, two problems with IE and something else with WebDAV or a database something or other.  So it's one of those, just do it.  I've done it on my various machines.  And it's good that we've finally got a correct fix for this XML Core Services problem.



Now, the thing that was related to this that I just sort of shook my head over was Microsoft's Security Advisory No. 2719662.  Now, that to me looks like, not a date encoded in that, but probably Advisory No. 2,719,662 because that feels like it's about the right number of advisories that we've had with Windows so far.  And this one is "Vulnerabilities in Gadgets could allow remote code execution."  And there's another Fixit.  This Fixit turns off the Windows Vista and 7 Sidebar and Gadgets.  Just turns it off.  It's like, whoops.  We're sorry we ever thought that was a good idea.  We're turning those off now.  And I was like, what?  What?  And so, quoting from Microsoft's advisory, it says:



"Microsoft is announcing the availability of an automated Microsoft Fixit solution that disables the Windows Sidebar and Gadgets on supported editions of Windows Vista and Windows 7.  Disabling the Windows Sidebar and Gadgets can help protect customers from vulnerabilities that involve the execution of arbitrary code by the Windows Sidebar when running insecure Gadgets.  In addition, Gadgets installed from untrusted sources can harm your computer and can access your computer's files, show you objectionable content, or change their behavior at any time."  What a nice technology.



"An attacker who successfully exploited a Gadget vulnerability could run arbitrary code in the context of the current user.  If the current user is logged on with administrative user rights, an attacker could take complete control of the affected system.  An attacker could then install programs; view, change, or delete data; or create new accounts with full user rights.  Users whose accounts are configured to have fewer user rights on the system could be less impacted than users who operate with administrative user rights.  Applying the automated Microsoft Fixit solution," we are announcing today, "described in Microsoft Knowledge Base Article [blah blah blah] disables the Windows Sidebar experience and all Gadget functionality."



So they're saying, whoops, we're sorry about all those desktop gadgets that we were promoting so heavily for the last many years.  We've decided they're no good anymore.  So just click this button which we're proudly announcing, and they'll all go away.  Now, I only miss one.  And that's the gadget that tells me how many hundreds of days left I have of Windows XP support.  I rest my case.



LEO:  Ooh.  Very good point.



STEVE:  And then of course the big news that occurred, dare I say during our hiatus, was the Cisco/Linksys router firmware fiasco.  You have to call it that.  This affected two brand new high-end routers, the EA3500 and the EA4500, which were first released in April.  These are big, as I said, high-end routers.  The lesser of the two, the EA3500, is $140.  And that's an N750 dual-band gigabit USB, powered by - and here's the problem - powered by Cisco Connect Cloud App Enabled.  And then its bigger brother at the top of the line is the EA4500, $200 for this sucker, an N900 dual-band gigabit USB DLNA media server, powered also by the Cisco Connect Cloud.  Well, this is the new thing, this Cisco Connect Cloud, that is causing the problem, is behind all of this.



What happened was everybody bought these in April.  And you're not going to have low-end users, probably, spending between $140 and $200 on a router.  This is going to be your serious home networking guy that wants DLNA-enabled media server stuff.  So these are people, my point is, that knew what they were buying and why.  And so they doubtless - this is now, what, April, May, June, July - plugged it in, logged into its admin interface, and pushed a bunch of buttons, and tuned it up.  And if they're podcast listeners, if they listen to this podcast, they probably disabled Universal Plug & Play support, if they know they don't need it, or maybe statically mapped ports through in order to use the Xbox gaming through their router, I mean, deliberately spent some time tuning it up.  Probably disabled WPA PIN use of the router.  So spent some time with it to get going.  Then, a couple weeks ago, without notifying anyone, Cisco autonomously, in the background, updated the firmware across...



LEO:  Really?  Without asking?  Without notice?



STEVE:  Without any notice.  Without any notice.



LEO:  Oh, that's not nice.



STEVE:  So what that means is all these routers were phoning home periodically.  That's the only way Cisco would know where they were.  They were phoning home, saying hi there, I'm this fancy new router, got any news?  And Cisco said, ah, thanks for checking in.  Here's new firmware, brmmp, and sends the firmware down.  Now...



LEO:  Wow.  I didn't even know they had that capability.



STEVE:  Get this, Leo.  It removed the admin interface...



LEO:  Oh, come on.



STEVE:  ...so that then these high-end router customers attempted to log onto their router and were told, oops, sorry, you need to go set up an account with Cisco Connect Cloud in order...



LEO:  Come on.  I bought this hardware.  You're making me do something?  Holy cow.



STEVE:  In order to manage their own router.



LEO:  Oh, that's just evil.



STEVE:  Well, and it gets worse because then people looked at some of the fine print in the agreement that went with this, that says, for example - and I'm quoting.  I copied and pasted this out of their license this morning.  "For example, if you download a media app, the Service" - that's capital "S" because attorneys were involved - "Service will need to share information with the third party about what media content..."



LEO:  What?



STEVE:  "...you have in your home network, or if you download a parental control app, the Service" - again giving you a big Service here, a capital "S" - "will need to share information with the third party about what devices are inside your home network."



LEO:  Well, that's weird.  Can you think of a reason why that would be needed?  Anti-piracy is the only thing I can think of.



STEVE:  Well, and it also says, "When you use the Service, we may keep track" - okay.  And remember, using it is not optional.  You attempt to log onto your router, and your only choice...



LEO:  You have to.



STEVE:  ...is to go create an account with Cisco Connect Cloud in order to then use web-based admin.  And what they're selling is that you can remotely administer your router.  So it's cross-device, it's web-based, meaning that you can use a smartphone from somewhere outside your home network to do stuff on your router.  And it's like, okay.  That can't possibly go wrong.  Uh-huh.  Yeah.



LEO:  Wow.  I have one of those.  I'm throwing it out right now.  That's it.  Goodbye.



STEVE:  So they're saying, get this:  "When you use the Service, we may keep track of certain information related to your use of the service.  Among other things, that data may include how much traffic is going through the router every hour and includes the Internet history from the home network."



LEO:  No, no.



STEVE:  So basically people have installed spyware boxes without knowing it.



LEO:  What?  Now, I'm trying to think, because sometimes they do these Terms of Service because for a technical reason they need to be able to act.  But I can't think of any technical reason why they'd need to know any of this.  Your history?



STEVE:  You can imagine the backlash...



LEO:  Holy cow.



STEVE:  ...against this as people dug into it and read these Terms of Service.



LEO:  This is clearly the Motion Picture Association of America, people like that.  Right?



STEVE:  Well, the most benign thing we could say is that it is some plan that Cisco has for monetizing their customers in a new way.  So they're talking about selling aggregate information.  This looks like it's - they're saying they need to peer into your network and see what media you have and what devices you have.



LEO:  And why would they need my Internet history?  That is just a flagrant invasion of privacy.



STEVE:  Yeah.  And the problem is they have access to it.  They are the router that connects the internal home network to the Internet.  Everything, as we know, passes through it.  The good news is SSL doesn't.  But, for example, DNS queries do, unless you're using encrypted DNS.  So they're in a position with a powerful router to aggregate information.  And we already know these things are phoning home because they all - every installed one spontaneously updated itself...



LEO:  Horrible.



STEVE:  ...to do this.  So as a consequence of the backlash, Cisco quickly responded and put up instructions for downgrading these routers back to the previous firmware because users were so upset.  Many people simply returned them.  They said, "I'm not keeping this."



LEO:  That's right.  Don't keep it.  Because you know what, that means they still could do this.  They have unmonitored access.



STEVE:  We don't know what the router is doing on the outside, on the WAN link.  There's no way to know.



LEO:  Shocking.



STEVE:  Not good.



LEO:  Shocking.  I will never use another Cisco/Linksys router again.  And we won't use them in our enterprise.  That is appalling.  And I don't think that's a mistake.  There's a new trend going on, and I call it - this is not a mistake.  I call this the "Facebook M.O."  Facebook's pioneered this, and I'm seeing more and more companies do this, which is you do it even though you know it's wrong and bad.  You apologize afterwards.  You fix it for those who complain.  Meanwhile, 90 percent of your customers never notice and just go along with it.  And you get away with it, basically.



STEVE:  Yes.  Imagine all the people who have not logged into their router to discover what has happened behind their backs.



LEO:  Right.  Or they don't care because they don't understand the ramifications.  And Cisco knows that, as does Facebook, as do a lot of these companies now.  This is the new M.O. in Silicon Valley.  Shocking.  Horrible.



STEVE:  See what you can get away with.



LEO:  Yeah.  Well, just do it, apologize afterwards, and most people will never notice anyway so you really will get away with it.  And those who complain, you fix it for them.  Horrible.  Well, I won't be using their stuff ever again.



STEVE:  Yeah, I have an old little Netgear that I'm quite happy with, and an older Belkin.



LEO:  Holy cow.  That is just shocking.  That's true malfeasance.



STEVE:  So we had another 420,000 password hashes stolen.



LEO:  I saw that.  Geez.



STEVE:  Formspring, a social networking Q&A site, whatever that is.  I kind of went there and poked around.



LEO:  I have an account there.  Quora is better known.  On Formspring you can ask me a question, and I can answer it.  It's a Q&A form.



STEVE:  Ask the 'Net?  Like ask everybody?  Or...



LEO:  No, ask specific people.



STEVE:  Oh, really.  Interesting.



LEO:  So Quora is you ask an open question.  Anybody can respond.  This is more like Reddit's Ask Me Anything, where you say, "I'm here, what do you want to know?" and you'll answer questions.



STEVE:  So the good news is they were hashed, and they were salted, and they were well hashed.



LEO:  Good.



STEVE:  They were not as well hashed as they could be.  In their blog they said, "We were notified" - and it's really fun, or not fun, but it's interesting to see how these companies find out because the first any of these companies know that this has happened is when they discover, people tell them, "Oh, by the way, apparently 420,000 of your you-thought-they-were-secret password hashes are out on the 'Net, have been posted, and people are rummaging around through them."  So they said, "We were notified that approximately 420K password hashes were posted to a security forum, with suspicion from a user that they could be Formspring passwords.  The post did not contain usernames or any other identifying information."  Of course the bad guys had those, but they were just posting the passwords to prove they had everything.



So this blog goes on:  "Once we were able to verify that the hashes were obtained from Formspring, we locked down our systems" - too bad they hadn't done that previously, I guess - "and began an investigation to determine the nature of the breach.  We found that someone had broken into one of our development servers and was able to use that access to extract account information from a production database.  We were able to immediately fix the hole and upgraded our hashing mechanisms from SHA-256 with random salts" - so, okay, they were implying good practice - "to bcrypt to fortify security.  We take this matter very seriously and continue to review our internal security policies and practices to help ensure that this never happens again."



Now, bcrypt is not something we've spoken of directly.  I've spoken of what it does many times because this is the password-strengthening approach.  What's sort of interesting about bcrypt is it's explicitly scalable, that is, we've talked about, for example, how I think iOS was initially hashing, iteratively hashing using so-called password-based key derivation, that horrible acronym PBKDF2.  iOS was doing it, I don't remember now, like 2,000 times, and now they're doing it 4,000 times.  And we talked about how a couple weeks ago LastPass added that, but to existing customers it was still set to zero by default, so we advised all of our listeners to go set it to 512, which I think is their recommended number.  And then they're now doing iterative hashing.



The point is, it doesn't actually create more security, but it lengthens the time that any kind of brute-force cracking requires by that factor, by a factor of 512 or 4,000 or whatever.  So the fact that Formspring has switched to a bcrypt-based approach says, okay, they were good already, random salts, SHA-256, that's all good.  And now they've decided, well, there is a little more we can do, so we're going to do that, too.



So there's really no egg on their face.  It's not like they had MD5 hashes, as we recently saw.  They were doing good hashing.  Random salts is best practice for hash management.  So it's unfortunate that those got loose.  They immediately shut down logins, required all users to change their hashes using an email loop in order to reauthenticate themselves and had to create new passwords.  And they also posted at that time best policies for what constitutes good passwords.  So they acted as we would hope anyone could.



LEO:  Should you change your Formspring password now?  Should I?



STEVE:  You have no choice.  You cannot log in without doing so.



LEO:  Good.  Even better.  Even better.



STEVE:  Yes.  So they immediately improved their security and then required all of their users to use that improved security for the passwords which they are now storing in a password database which they believe is more secure than, well, I'm sure it's more secure, and hopefully it's secure enough to keep from the bad guys.



But speaking of that, something else happened that had a lot of people scratching their heads initially, and that is there was a massive attack across 50,000 websites that were defaced with the installation of the Blackhole Exploit Kit.  Now, this is something we spoke of recently because, for example, the XML Core Services vulnerability was turned into an exploit that was recently added to this Blackhole Exploit Kit, which is a popular hacking kit that the black hat people are using in order to, for example, get into people's machines using unpatched vulnerabilities in Windows.



So people were saying, wait a minute, how did people get into 50,000 websites?  There was initially not anything obvious that they had in common.  They had completely different servers, some running Windows with IIS, many on Linux and UNIX running Apache or other web servers, different automation, some were running .NET, some active server pages, some PHP, so it's like it's very heterogeneous.  But someone noticed they all had the same management software.  They were using a system called Plesk.



LEO:  I've used that.  It's excellent.



STEVE:  Yes.  It is the second most popular remote website, remote server management, remote site management.



LEO:  It's a PHP-based sysadmin tool.  cPanel's another one, yeah.



STEVE:  cPanel is No. 1 most popular; Plesk is No. 2.  Turns out that Plesk had a known vulnerability that was fixed months ago.  But before that, people were able to get in and acquire the server management passwords, which unfortunately Plesk was storing in the clear.



LEO:  Oh, dear.



STEVE:  So even after Plesk was updated months ago, the people used it pre-update, that is, bad guys got in, got the management passwords, the master management passwords for those servers.  So when Plesk was updated to fix the problem, the passwords had already left the barn, to mix a metaphor.



LEO:  The password has left the building.



STEVE:  The password has left, yes.  So anyway, what happened was 50,000 websites were defaced.  And what people need to do, I imagine this is old news for anyone who actually is in charge of any of those websites, you have to change all the passwords because the bad guys have got your passwords using a vulnerability in Plesk that is now old.  So there you go.



LEO:  The real problem with Plesk is your provider usually has to update that.  And they often are slow to do so.  So you may...



STEVE:  Correct.  I don't think they'll be slow this time.



LEO:  Maybe not, yeah.



STEVE:  Well, and it's a simple thing to do.  They update it, and it fixes that for all their customers who are using remote admin on their services.  So that's a good thing.



Now, I have to go a little bit off topic.  I'll make it brief because we've got Q&A to get to.  But I just did want to mention a couple things.  I tweeted some links just now for the podcast, so those are at my @SGgrc feed in Twitter.  So Twitter.com/SGgrc.  One is a wonderful "Prometheus" parody.  And "Prometheus" has been out long enough that I can now release...



LEO:  Spoilers, right, yeah.



STEVE:  You have to see it, if you haven't, Leo.



LEO:  I haven't.



STEVE:  It is the essence of what we were talking about was disappointing about the movie.  And so this is a sort of a pep talk, pre-landing consultation of somebody in charge to this group of - we see that they're not that impressive when they actually get on the ground.



LEO:  Yes.



STEVE:  And it's wonderful.  So I won't try to...



LEO:  Unfortunately, I'm looking for "Prometheus" parodies on YouTube, and there's dozens.



STEVE:  Yes.  And what I tweeted was this was my favorite of the so many deservedly created parodies.



LEO:  Guess it kind of begged to be parodied.



STEVE:  Yeah, you just can't tweet, you can't Google "Prometheus parody" because there are too many of them.  But this one that I have in my link is...



LEO:  It's a pre-prequel, is what they call it, the pre-prequel.



STEVE:  That's the one, the pre-prequel.  Well, because "Prometheus" was an "Alien" prequel.



LEO:  Right.  So before the prequel, there's the prequel.



STEVE:  Yeah.  And, oh, it's just wonderful.  So people will love that.  On Monday I saw "The Amazing Spider-Man."  And it's interesting, as I've talked to people about it, many people have heard it was bad.  I loved it.



LEO:  Oh, good.  I haven't seen it yet.  Okay.



STEVE:  So I just wanted to say I loved it.  I liked all the Spiderman movies.  I liked the new Batman.  And I should mention that this is a restart of the series in the same way that the new Dark Knight series is a restart.  And so it starts with Peter Parker before he's been bitten and so forth.  And I thought it was the most effective 3D I've seen.  Of course "Avatar" and then "Prometheus" in 3D.  "Prometheus" in 3D just didn't do it for me; but this, it wasn't overdone, but the depth, I was conscious of the depth of field photographically.  The things that were further away were also nicely out of focus, so you knew what you were supposed to be looking at, and it was kind of right there in the middle, and things closer to you were out of focus.  They did a really nice job.



So if anybody - the point of bringing this up is, if anyone has been dissuaded because they heard it was bad, I loved it.  I thought it was great.  So I just wanted to say that.  And speaking of great, two non-sci-fi things.  "The Newsroom," which is a new series on HBO?  Wow.  I love Aaron Sorkin.  And I liked "The West Wing."  It was that dialogue that normal people don't actually speak.  And in fact he was interviewed by Colbert last week, and Stephen Colbert said, "You realize, Aaron, nobody talks that way."  And he says, "Yeah, I know."  But anyway, I watch each episode twice, it's so good.



LEO:  Sometimes you have to, they talk so fast.  You miss stuff.



STEVE:  Oh, it's just wonderful dialogue.  I just love that.  And then just a blast from the past:  After 20 years, "Dallas" is back.



LEO:  No.  Don't tell me you love "Dallas."



STEVE:  Oh, I do.  And Larry Hagman still has it.



LEO:  He's in it?  He's not J.R.?



STEVE:  Yes, J.R. is back.  And Patrick Duffy, and Linda Gray, and Ray.  Now, they of course have had kids, and the kids are grown up now, and the show is mostly about them.



LEO:  [Geezer voice] "Well, you better go get him now 'cause you're in trouble, J.R."



STEVE:  Anyway, those two shows are the top two new dramas of the season.  Both have already been renewed for a second season.  HBO has already committed to a second season of "The Newsroom," and "Dallas" is the No. 1 show now running, nearly seven, 6.9 million viewers per episode.



LEO:  Wow.



STEVE:  So anyway, I watched it in the old days.



LEO:  What channel is "Dallas" on?



STEVE:  It's on TNT.



LEO:  I will have to watch it.



STEVE:  Ah, there's our music [old "Dallas" theme].



LEO:  It's not the same theme, is it?



STEVE:  Yes.



LEO:  They kept the theme?



STEVE:  Yes.



LEO:  So it's a pure nostalgia play, then.



STEVE:  Yeah.



LEO:  Because this is the most '70s theme ever.  Wow.  That's funny.  I'm going to have to watch it.  I haven't been watching that.



STEVE:  Yeah.  I have to say, now, Larry, J.R., has flown off in a helicopter and left John Ross sort of in charge, which I realized is the way he negotiated his contract.  He says, okay, I'll be there for the first three episodes to get this thing going, but then I'm...



LEO:  Right, right, right.  He is 80 years old.



STEVE:  Yes.  But I'm not kidding you, Leo, it is just so fun to see him still.  Even the old...



LEO:  Here's the new theme [new "Dallas theme].  They did update it.  They at least got rid of the wocka-wocka-wocka guitar there.  Oh, yeah, this is much more 21st Century.  But it's the same theme, same melody.  That's great.



STEVE:  Yup.



LEO:  Wow.



STEVE:  Even when he was the colonel, was it a colonel on "I Dream of Jeannie"?



LEO:  Oh, yeah, yeah, yeah.  Major.  He was Major Nelson.



STEVE:  Major Nelson.



LEO:  I think he became Colonel later.



STEVE:  He was a good actor.



LEO:  Yeah, Hagman's a good actor.



STEVE:  Yeah, he really is.



LEO:  Now, if they redo "I Dream of Jeannie," I'll be watching.



STEVE:  As long as they don't use Barbara Eden.  I think she's probably a little too far...



LEO:  Well, yes.  [Geezer voice]  "Hey.  Hey, Astronaut Nelson.  I think I left my teeth in the capsule."



STEVE:  We don't want to see her in her Jeannie outfit, though.  Just have her maybe in a nice pantsuit, that would be good.



LEO:  Oh, dear.



STEVE:  So, okay.  Finally, sci-fi books.  I know that many people did follow my recommendation for the Lost Fleet series, which I really liked because remember that we had this Commander Geary, who was a hundred years in suspended animation.  They found his capsule, revived him just in time to use his long-lost knowledge of large-scale fleet maneuvers in order to rescue the Alliance.  And so we had six books:  "Dauntless," "Fearless," "Courageous," "Valiant," "Relentless," and "Victorious."  Then we ran out.  Some people may have been glad.  But he has a new series called Beyond the Frontier.  I just finished yesterday "Dreadnaught," which is the first of those.  And then "Invincible" I have in hardback because it wasn't available for Kindle, but it is now.



So for any listeners who want more, I just wanted to let everyone know that there's two more books now out.  I'm less excited about them.  There was much less battle and much more feeling that, unfortunately, the author, Jack Campbell I think is his name - I didn't write it down, but I think it's Campbell - it feels a little bit like he's stretching it out.  Like okay, come on, let's get going.  It's, like, way political.  And this was a little - I was impatient as I was reading "Dreadnaught."  So I don't recommend it highly.  And so there you go.



I did get a nice note from a listener, Brian Semingson, who's in Indio, California.  He said, "Hello, Steve.  I'm an IT manager professionally, so that means I'm the IT fixit guy for everyone who knows me."  And of course many of our listeners and you, Leo, know how that is.



LEO:  Oh, yeah.



STEVE:  "And that brings me to SpinRite.  A family friend's PC would freeze on the XP splash screen every time he attempted to boot it up.  The only thing I was told was that the computer froze up while their kids were using it.  I was thinking I would have to spend the time to get their files off and then reinstall XP, which also meant buying the restore disks, since they didn't have those, either, and it was no longer possible to boot up and get into the machine to create the restore disks.  I thought, well, I'm going to try SpinRite.  This could save me a lot of time.  Plus I've been wanting to try it anyway since I started listening to Security Now!.  I ran SpinRite at Level 2 against the drive, and it only took about three hours to finish.  Restarted the computer and" - now, he says "boom," but I think he means in a good way.



LEO:  One doesn't know with "boom."



STEVE:  Not that it exploded.  "And, boom, loaded right up normally.  I was able to create restore disks from the computer's utilities in case it happened again, and was able to give them their computer back the next day.  Everybody won on this one.  You have a happy customer.  I'm happy since SpinRite made this an easy fix.  And my friends are happy that they got their computer right back anyway.  Thank you, thank you, thank you, thank you."  And thank you, Brian, for sharing that.



LEO:  Very good.  All right.  I think you will like these questions, Steverino.



STEVE:  You know, the world is amazing, Leo.  While you talking, I just checked my Twitter feed, and someone named Free, or with the handle FreeJAC, J-A-C, in Canada, tweeted me the link to the BlackBerry sounds that I miss from the past.



LEO:  Oh, you're kidding.



STEVE:  So he's listening in real-time.



LEO:  Holy cow.  Yeah, because you didn't mention it on the show, this was pre-recording, that you forevermore wanted to keep your own sounds because once you'd lost your sounds.  And he sent you the BlackBerry sounds?



STEVE:  Yeah.  I changed BlackBerrys, and the new Blackberry had different sounds than the old BlackBerry.  So it's like, oh, I miss those sounds, because I had them all set up to respond to different things.  And I couldn't find them.  I couldn't get them off.  So thank you, FreeJAC.  I appreciate that.



LEO:  I'm going to have to - did he give a link that we can use?  Because I might want to download those, too.



STEVE:  Yeah, it's BlackBerry App world, BlackBerry's 5.0 sounds.  It's fun because the item description says "Download the 5.0 BlackBerry sounds heard around the world for years everywhere:  Lightspeed, Sonar, Classic Phone, the entire set."



LEO:  Wow.  I'll probably recognize these.



STEVE:  Oh, and he said, "These sounds are not preloaded in BlackBerry 6 or higher, and the set is available free for all users to download here."  No, you're right.  You will certainly recognize them because I was hearing other people's phones doing that for years.  It's like, oh, I know that sound.



LEO:  Well, I had a BlackBerry.  In fact, I had BlackBerrys from the moment that they were just pagers, just those big pagers with a keyboard, to the BlackBerry Curve.  And then this thing called the iPhone came out, and I never used a  BlackBerry again.  And I have a feeling there's a lot of people like that.



STEVE:  Yeah, except I'm still, as you know...



LEO:  You don't use a BlackBerry, do you?



STEVE:  Oh, my god.  That's what you're hearing go crazy like a squeaky toy.



LEO:  That's a BlackBerry?



STEVE:  Yes.



LEO:  Like a BlackBerry phone?



STEVE:  My best, the best communication device I have ever owned.  Absolutely.



LEO:  What are you going to do when RIM goes out of business next month?



STEVE:  I'll buy a few more and have them in storage.  I'll stick them in the refrigerator along with my Palm Pilot.



LEO:  Wait a minute, wait a minute.  Which BlackBerry are you using?  The Curve?



STEVE:  I've got something late model, 9650 or...



LEO:  Oh, yeah, that's a Curve.  Wow.



STEVE:  It's got the 640x480 screen, really nice high-res screen.  And it's got the new little touchpad instead of the ball.  I had to replace the ball, the little roller ball.



LEO:  I liked the ball.  That's the Bold.  You have the Bold.  That's what you have.



STEVE:  I had the Bold.  You're right, I had the Bold.  And now I've got the Curve.  And...



LEO:  No, no, I think the - you had the Curve, and now you've got the Bold.  I think the Bold - I don't know.  Does the Bold come later?  Or is it a Torch?



STEVE:  I think it's the...



LEO:  Wow.  You are an old-fashioned guy.



STEVE:  Oh, I want a keyboard.  I do not want, I cannot stand typing on a touchscreen.  I just - because Apple hasn't done it right.  If I press a key and slide my finger off, and it goes click, that means I pressed that key.  Apple does not register it.  They give me the sound, but they do not register the key.  And I just - I guess the way I'm typing, I'm not lifting my finger off of it, I'm sliding it a little bit.  And so I just - I can't stand it.  I want pushbuttons.  I want buttons.  I love my BlackBerry.  It's the best thing I've ever owned.  That and my iPad.  Those are my two devices.



LEO:  Wait a minute.  The iPad's the same as the iPhone.



STEVE:  Oh, I don't type on the iPad.



LEO:  Okay.  So you mean, when I hear those sounds like the Yabba-Dabba-Do, that's a BlackBerry, not your computer.



STEVE:  Oh, no.  The Yabba-Dabba-Do, actually it's going to be moving to my BlackBerry soon because I thought it would be fun to be able to walk around and have that happen.



LEO:  What a character you are, Steve.



STEVE:  But I like the squeaky toy, and Jenny has a sound, and so I know when she's sending me something.  So, yeah.



LEO:  That's cute.



STEVE:  Yeah, she likes her sound.



LEO:  Question #1.  No comment.  Ahem.  Steve, sometimes I feel like you're living in the 20th Century.



STEVE:  I'm quite comfortable there.  I've got PDP-8s behind me.



LEO:  He's using Windows XP.



STEVE:  I have TiVos with the PowerPC that are byte-swapped, TiVo Series Is that are modified.  Mark Thompson keeps bugging me to switch to C.



LEO:  No, but you have a point because, when something is perfect, just because you make a newer one doesn't mean it's better.



STEVE:  Oh, and frequently, I mean, we just talked about Cisco here with this ridiculous...



LEO:  You don't have a rotary phone, do you?



STEVE:  Well, not plugged in right now.



LEO:  Question 1, Dustin B, Seattle, Washington.  He wonders about password system setup:  Greetings.  Longtime Security Now! listener.  I've received a lot of advice over the years about personal password use.  My questions today are actually how to best set up an account system such as a small-time web application developer.  I don't believe you've talked much about the system side of enforcing user security.  Password requirements:  While we know the benefits of having our own long pseudorandom passwords, how far should an application go in forcing its users to use a secure password versus causing user frustration by forgetting their password?  Is, for instance, more than five characters, including a number, enough?  Does it have to be 12 characters with upper, lower, special characters, et cetera?



He's suggesting this is an invalid password message:  I've noticed on failed login attempts the message is generally "Username/password combination not found."  I find this very frustrating as I use multiple usernames and passwords across services and would like to know if the issue is simply I'm thinking of a different username, or if it's an old/different password.  Is eliminating independent verification that the username was valid really needed to have a secure login system?  So two questions:  What do we need for passwords to be secure, what should we require; and, secondly, why doesn't it tell me which is wrong, username or password?



STEVE:  So, okay.  My feeling is that I really like sort of what I would call the state of the art now, which is, as you're creating an account and for the first time defining your password, this page that you're typing it into is using JavaScript on the fly to look at your password, very much the way that my Password Haystacks page does, to rate the strength of your password.  So the idea is it gives anyone who's creating a password a sort of a built-in tutorial.  They can choose if they want to have a weak password.  But if they do, then they're doing so deliberately, with foreknowledge of that.



And so my sense is I don't know that I like the idea, I mean, certainly maybe set a ridiculously low limit.  You don't want a two-character password.  So Dustin says how about greater than five with a number.  So you could create whatever rules you want.  The problem is users do chafe at specific rules.  Certainly I hear from people all the time who are annoyed when things say they can't have a password longer than X.  And that's, as we know, frightening because it implies that the password is being stored in plaintext in a limited-size field in a database somewhere because, if a password is being hashed, then it hashes to something always the same length, which is the bit length of the hash, regardless of how long the user's password is.



So for me, I like the idea of showing a meter where, as they're typing, and as they're using special characters and numbers and things, some JavaScript code is looking at the size of the alphabet that they have used so far times the length of the password that they have used, or actually raised to the power of, in order to give them a little bar graph, maybe change the color from red to orange to yellow to green, like how safe is the password that you've used?  I like that because we're teaching at the same time, and we're giving them responsibility.  We're not saying here's the requirements of anything that you type in here.



And the other thing, too, is that I've noticed, if you're going to have requirements, put them right there.  Don't wait until the password the user types in and submits fails your requirements to tell them what your requirements are.  If you're going to have some, let us know before you make us put one in that's not going to work the first time.



LEO:  I know, I hate that.



STEVE:  Isn't that dumb?



LEO:  It's so annoying.  Oh, you didn't have - and almost everybody does this, by the way, Steve.



STEVE:  I know.



LEO:  It's very common.  Oh, you know, you should have a number in there.  Well, tell me, for crying out loud.  If you'd told me, I would have put a number in.



STEVE:  It's not like the bad guys aren't going to...



LEO:  Even Apple does this.  I think Apple does this.  They say, oh, no, no, sorry, you have to have an uppercase letter.  Well, if you'd just tell me ahead of time.



STEVE:  Yeah, then we'll do one.



LEO:  But I do agree, we don't want to leak information about which of the two choices is wrong.  I think that's a bad idea; right?



STEVE:  Oh, about Part 2 of his question.



LEO:  Oh, you haven't got to that, yeah.



STEVE:  You're absolutely right.  So he says in Part 2 he doesn't like the fact that, if you fill two fields in, typically email address and password or username/password, then submit them together, he doesn't like just getting a notification that something was wrong.  He wants to be told, he's asking, is it less secure or worrisomely less secure to give the user more help?



LEO:  Absolutely.



STEVE:  And I agree with you, yes, it is, because it allows one to be probed independently of the other.  So that is absolute information disclosure which is not secure.  I unfortunately, I mean, I understand the inconvenience.  But Dustin, how are you not using one of the password managers like LastPass in order to solve the problem of multiple usernames and passwords on different sites?  That's really the way to do it.  So I understand he's doing it from the implementer's side now.  The question is, I'm going to implement a system, what should I do?  So he's asking can we tell them.  It's like, eh, I don't think you should.  And nobody else does.  So, and there's a reason.  It's not good because it allows you to probe one separately from the other.



LEO:  Fortunately, that's something most sites do right.



STEVE:  Correct.



LEO:  They don't come back and say, oh, your username's wrong,  but your password's right.



STEVE:  Correct.  And then lastly, by pure coincidence, I remembered three days ago somebody tweeted me a link, actually it's a devout listener to the podcast, on his rsum.  He has as one of his self-certifications that he has listened to every Security Now! podcast twice.



LEO:  It takes at least two times, frankly.  It's like "The Newsroom."  You've got to listen twice.



STEVE:  Yeah.  So in this case, I just tweeted the link to it.  He's a guy up in Canada.  I can't quite remember the name now, .ca, although the link I tweeted is not his normal main website.  But anyway, the point is that he has an absolutely beautifully assembled page of here's how you process and store users' passwords.  So Dustin, go check my Twitter feed, Twitter.com/SGgrc, and not far back because I won't be tweeting much, I never do, you'll find a link to a page where I agree with everything there, actually because it's what I've said.



LEO:  Is this the CrackStation page?



STEVE:  Yes.



LEO:  CrackStation.net?



STEVE:  Yes.  And because there he is a Security Now! listener, very technical.  Actually his site and his home site, I poked around there for a while, lots of neat stuff.  And he refers to the Personal Passwords Page and everything.  But it is all the advice on one page with the password-based key derivation function, hashes, hash tables, rainbow tables, I mean, he just lays them all out.  So in one page there is the advice for how to set up a secure password system using all the best practices that we know of.



LEO:  And it's Defuse, Defuse.ca.



STEVE:  That's the site.



LEO:  This is his business, I think.  It looks like, anyway.



STEVE:  Looks like he's a good guy.  And definitely...



LEO:  He's a security guy, yeah.



STEVE:  Definitely a listener.



LEO:  Yeah, I love that.



STEVE:  He's got our JavaScript, or zero JavaScript, menuing system, too, because his menus worked for me with no JavaScript.  It's like, oh, that's always cool.



LEO:  Oh, he's serious.  He's serious about this.  Article and code written by Defuse Cyber-Security.  Moving on to our next question, which comes to us from the Netherlands.  I like this one.  And I'm going to butcher your name, so my apologies in advance:  Anne Stellingwerf in Apeldoom, Netherlands - she's @AnneSt - tweeted this question about buffer bloat:  What would be the effect of one CoDeling router in a chain of non-CoDeling routers?  Does position - whether it's at home, the ISP, the Internet at large, or the destination - matter?



STEVE:  I loved the question because I forgot to explicitly address it when we talked about CoDeling our routers.



LEO:  I guess it'd be germane because if your Internet service provider CoDeled, for instance, that would be protective; yes?



STEVE:  Well, here's the problem.  It's a problem, and it's a good thing.  What we really want is this beautiful CoDel active buffer management technology to be ubiquitous.  We want it to be the way buffers - any buffer that exists is managed this way because the system doesn't have knobs and dials, doesn't need tuning.  It's adaptive.  It works across any speed of bandwidth, I mean, this is the answer to managing buffers.  The problem is, even one unmanaged buffer somewhere can cause a problem.  The problem is we want to minimize our delay.  We want to minimize having an oversized buffer filled and being stuck full because then it means that all the packets going have to wait through this long queue, and the inherent rate-throttling technologies that we have and that work beautifully, they're not getting the signaling that they need for slowing down in order to manage the buffers.  So technically even one non-CoDeled buffer somewhere between the two endpoints can cause a problem.



But practically, the good news is, the only big problem we have - remember the reason typically that you're going to have an overloaded buffer is it's at a pinch point.  You are going from high bandwidth to low bandwidth.  And where that happens most often is from a very high-speed local network which people have at home, through the pinch point of their ISP, out onto the Internet.  Once you get on the Internet, you're dealing with BigIron fast routers that are able to keep up with the bandwidth of their links, so you're not having buffer bloat problems there.  Where the buffer bloat is occurring is at home.  And that's the one router that you have control over.



So the answer is, yes, in theory, non-managed buffers anywhere can be a problem.  But the need for management occurs only at the pinch point, where you go from high bandwidth to low bandwidth, because that's where you're going to get a backlog.  And what you'd like then is that backlog to be minimized by having intelligent drops of packets that then signal the protocols to throttle themselves.  That keeps everything interactive, and you don't really lose much bandwidth.  And you have that at home.  So there's hope, without needing the rest of the Internet to update itself.



LEO:  Yeah.  Or your router, to put spyware on it.



STEVE:  Yeah.



LEO:  Oh, god.



STEVE:  Oh, god.



LEO:  Preston, Silicon Valley, found a security vulnerability, but now what?  Chief Explainer:  First, to get it out of the way, listener since May 2008.  Went back and got caught up.  SpinRite owner.  Favorite podcast of all time, yada yada yada.



STEVE:  Let me interrupt you for one second.  Everybody starts off their posting.



LEO:  They all say that.



STEVE:  And I have started to cut those out because I get a little embarrassed that, like, we're reading them endlessly every week.  So I'm going to just - I don't want anyone to be offended if that gets cut out from their question.



LEO:  We reserve the right to edit, just like a newspaper, for clarity and content.



STEVE:  We're happy to be told that we're doing a good job, and I appreciate that.



LEO:  Rush Limbaugh asks his listeners to say "ditto."  So we can just - you could just say "ditto."



STEVE:  And in fact, Preston's - this is already long, but it was a lot longer.  And so I wrote, I already wrote to Preston and said, Preston, I really liked your question, I want to include it, and I'm paraphrasing it to keep the intent, so just --  because I don't like to edit people's stuff because they sent it to me as they wanted it to be sent.  So anyway, okay.  Continue.  Sorry.



LEO:  I have no compunctions about editing people's stuff.  In late 2010 I downloaded a copy of Cain & Abel and was playing with it on my home network, implementing a man-in-the-middle attack on SSL, and I discovered that I could see my PayPal credentials in the clear.  That night there was no sign of anyone else on the 'Net knowing of it.  But by the next morning the news was out that others had seen it, too.  I felt proud to have discovered something independently.  But it raised the big question in my mind:  What would I have done with that information if no one else had reported it?



Now, fast-forward to last month:  I was at a conference on mobile banking where there was a talk given by Andrew Hoog, the CIO of viaForensics, a security firm specializing in mobile apps.  He told a story of how they found a vulnerability in the PayPal app where all traffic was being sent securely, but the app wasn't checking the identity of the certificate to make sure it belonged to PayPal.  We're sending it securely, we just don't know who to.



STEVE:  Yeah.



LEO:  Thus a man-in-the-middle attack would be trivial.  After his talk I asked him if this happened in late 2010, and he said it did.  He said they found it about three weeks earlier, and he recounted the story that, even though viaForensics was an established security company, PayPal chose not to believe them at first and tried to ignore them.  The only way to get them to look into it was to document it in step-by-step video.



If enterprises treat a known security company like this, I wondered what steps a little guy could take if they found something like this in the future.  I suppose the white hat thing to do would be contact the company.  And by the way, not necessarily a good idea, and I'll tell you why not.



STEVE:  Uh, no.  Yup.



LEO:  But what do you do if they don't listen?  Just release it to the wild?  Sell it on the black market?  Do nothing and let someone else take the credit?  No, no, and no.  I'll let Steve answer this one.  But I'm champing at the bit.  Steve and Leo, I love the show, especially the series on how a computer works, and I look forward to each new show every week.  Sincerely, Preston in Silicon Valley.



STEVE:  You go, Leo.



LEO:  No, no, come on.  You're baiting me now.  Actually I do know people, there's a guy you probably all have heard of named Adrian Lamo, who considered himself a white hat hacker and broke into a number of places, including The New York Times, then offered up the information, saying look, you're insecure, I've found an insecurity, and he was arrested.  Our friend Randal Schwartz of FLOSS Weekly claims he was doing the same thing.  He was also arrested.  So it's very, very risky.



STEVE:  Randal got arrested?  Wow.



LEO:  Randal has, yeah, Randal has a conviction, I believe.  So this is a very risky thing to do.  It is not a good idea, if you're not an established security firm, to just walk in the door of some company, say you've got a flaw here.



STEVE:  Yeah, unfortunately.



LEO:  They may not take it lightly.



STEVE:  Yeah, what I would say is, the way I would summarize that is, unfortunately, many companies do not react the way we think that they should when they learn of a problem.  They literally shoot the messenger, when that's not the mature thing to do and doesn't help them at all.



LEO:  So what should you do? 



STEVE:  Well, that's a great question.  And I think the answer that I would have for Preston is, when he says what should one do, what I would do is I would contact, not the victim company, but contact a reputable security firm.



LEO:  That's what I would suggest.



STEVE:  Yes, and tell them.  You're losing the glory.  You're not going to get any great prize anyway.  If your motives are to be a bad guy, and you want to sell it on the black market, well, good luck.  I don't know how to do that, but these things are valuable.  We know that.  But if you're a listener to the podcast, hopefully a white hat hacker, and you're playing with Cain & Abel or whatever, and you find a problem, I would say, yeah, turn it over to a legitimate security company.  First of all, they'll verify it.  And then they no doubt have established channels to large enterprises where they can say, hey.  They're able to even say we didn't find this ourselves.  This was found by somebody else, just a random user of the service.



LEO:  Who shall remain nameless.



STEVE:  Yes, who wanted us to notify you because he wanted it to be taken seriously.  I think that's the right protocol. 



LEO:  Just to complete the story so that people don't have to kind of some strange thought about this, Randal was working for Intel, did some pentesting at Intel.  He was charged by the state of Oregon for compromising their security.  Intel prosecuted.  He was convicted on three felony counts with one reduced to a misdemeanor.  But, and I'm very happy to say this for Randal, a few years ago his arrest and conviction records were sealed, expunged, and he is not a felon any longer, so he can vote and all of that.  And he says this was his complete mistaken, you know, I was just doing pentesting for Intel.



STEVE:  I mean, I can't think of a nicer guy.



LEO:  I know.  Randal's a sweetie.  Now, it's more complicated.  He was doing pentesting in a system he no longer administered.  It's a complicated story.



STEVE:  Look, it's a little gray, maybe.



LEO:  It's a little gray.  I don't think he was in any way hacking.  Adrian, same story, where you might say he did break into The New York Times.  He changed some stuff on their servers.  Nevertheless, it is a risky thing to do to go to a company and say, hey, you've got a problem, I found it.  But you go to a security firm and let them do it, and generally speaking they have channels.  Not that they don't get ignored, as this guy did.  I remember talking to Matt Conover at w00w00 Security.  They found a significant bug with a major operating system's company, told them about it.  For months the company never fixed it.  This happens time and time again.



STEVE:  Oh, well, and how many times have we talked about people notifying Microsoft and being really frustrated that six months later they still haven't addressed something that they have found.



LEO:  It was Microsoft.



STEVE:  And it is very frustrating.



LEO:  And finally w00w00 released the - this is what often happens.  These companies get frustrated.  Six months in, they start seeing the exploit in the wild, and they say, look, we've got to release it now.  And that's usually what forces the company to finally fix it.  And it's why often - always be suspicious if there's a fix a week after you hear about an exploit. 



STEVE:  Yes.  Not the week before.



LEO:  It usually means they've been working on it.



STEVE:  Not the week before.



LEO:  The week after.



STEVE:  The week after.



LEO:  It usually means they've been working on it.  Rene Matthiassen, Copenhagen, Denmark - I love our international listenership, viewership - wonders about missing security frameworks for cloud computing:  My question is, when everyone's talking about cloud this, cloud that, it's worrisome no one's talking about security frameworks to support best practices for cloud computing.  Basically, all vendors or suppliers can pretty much do whatever they find fit for their purpose.  There isn't any security standard in this area.  Each time I ask vendors for cloud services about which security standard they are using, they either try to explain something ridiculous, or just look back and blush, "I got nothing."  Is there something on its way?  Or is this just the Wild West?  Thanks for putting a good show together week after week.  Rene, Copenhagen.



STEVE:  So it's absolutely the case that everybody's making this up as they go along.  And what this question put me in mind of was something that I've always found interesting, Leo, and that is, this is always the way it's been.  I don't know what attorney wrote the first software license agreement.  But that first software license agreement said we have no responsibility, we the vendor, no responsibility whatsoever for what this software does or what you may do with it, how it behaves, how it behaves in the past, now, or in the future, and we're really not even sure where it came from, but you owe us money.



And that's the way all software agreements have always been.  This amazing ability that our - I want to say "our industry" because I'm of course a software vendor.  The software business has always been able to get away so far with taking no responsibility whatsoever for what its product does, which just strikes me, when I remember that fact, as remarkable.  You know?  Nobody else could do that.  I mean, you've got consumer protection, and you've got all kinds of regulations, and...



LEO:  But it's always after the fact, even in that space; right?



STEVE:  Yeah, and that is a very good point.  It's one of the points, actually, that Paul Vixie brings up that we'll be talking about next week, is the way everything seems to be done afterwards, not beforehand.  But it is just an odd thing about this industry.  It seems to be powerful enough and confusing enough that no one really knows how to regulate it or control it.  And it's moving so fast, I mean, the whole cloud thing has just sort of exploded.  After being possible for a while, the incredible lack of cost in mass storage has allowed all of this.  It's what enables storage to suddenly all move limitlessly to the cloud.  And bandwidth.  The explosion of bandwidth has allowed the data to get there and back.  And suddenly we're dealing with a new model that we didn't have just a few years ago.  So, yeah, it's all new again.



LEO:  It's technology.



STEVE:  It's continuously new.



LEO:  We just throw it up against the wall, see what sticks, fix it after the fact.



STEVE:  And we'll say we're sorry.



LEO:  Exactly.  Well, I think about Dropbox and the fact that we found out kind of later that they actually had the security keys, things like that.  And it's just - there isn't a standard.  I don't think you could really make a standard, reasonably, ahead of time.



STEVE:  One thing that we're doing on this podcast, by establishing things like TNO, Trust No One, and Pre-Internet Encryption, we're saying, although we're not part of any standards-making body, we're helping to raise the awareness of this is clearly the way these things should be done.  We have no ability to compel people to do it.  But on the other hand, when we look closely, as we have in our cloud computing series, what are these companies doing?  Are they TNO or not?  We're certainly helping to influence companies to, I mean, we're seeing the influence of our pressure.



LEO:  And you did this before with ShieldsUP! where you effectively convinced router companies that the best way to behave was in stealth mode, which stood for something they didn't even - you coined the term.



STEVE:  Yeah, that was my word.



LEO:  Yeah.  So I think that that's appropriate.  I mean, that's one of the ways this happens, which is watchdogs and people with an interest in this kind of at least propose, well, this is what we think should happen.



STEVE:  And point to instances where it's not happening.



LEO:  Right.  And then let the market decide.  The market will tell you.



STEVE:  Yep.



LEO:  I think this is not a broken system, but it is good to be aware of that's how technology works.  And it's because it happens so fast.  You don't want a governing - look how long standards take.  You don't want a governing body setting standards before things happen.  You want to try stuff.



STEVE:  And they'd so often be wrong.



LEO:  And they could do it wrong.  Look at WEP.



STEVE:  Yeah.



LEO:  John Couzins, Blackpool, England wonders about password salting versus password strengthening:  Hi, Leo and Steve.  Big fan of the show, blah blah blah blah blah, bah blah blah blah blah blah.  I'm currently - that's what I'll say from now on, not "ditto," just "blah blah blah."  I'm currently in my last year of a Cyber Security Masters at Lancaster in U.K.  I'm hoping to focus my efforts on securing virtual environments.  Wow.  Anyway, do you not feel that, while salt can be used to further secure hashed passwords, specific password hash algorithms like PBKDF2 would be more effective in preventing situations occurring like the LinkedIn breaches?  John Couzins, Blackpool.



STEVE:  You know, I forgot we had this question.  This must be the reason that I tweeted the link to the Defuse.ca guy's page because...



LEO:  Yes, yes.  That's about salting particularly, yeah.



STEVE:  Exactly, and the use of - so he's saying, yes, we have got salt.  And in fact this is the same thing that the form, was it formworks, form...



LEO:  Formspring, Formspring.  You had me confused, too.  Formspring.



STEVE:  Formspring, right.  This is what they were doing is they were salting and using secure hashes.



LEO:  They were doing it right; right?



STEVE:  Yes.  But they were not going through a password-based key derivation function, this PBKDF2, which is to say doing it many times.  It's one of the things, for example, that WPA got, the successor to WEP, which you just reminded us was so badly broken and poorly done.  The WPA spec, remember, has a 4,096 iteration PBKDF2, where they take the user's password and the SSID, using the SSID as the hash, essentially, and iterate on that 4,096 times to create the final result.  So John, yes, you essentially go to, again, Twitter.com/SGgrc, get that link, and there's the answer.  That guy did a beautiful page that just lays it all out.



LEO:  Jim Hartz in New Brunswick, New Jersey wonders and worries about a backdoor to Symantec's PGP Whole Disk Encryption:  I use OS X Snow Leopard, he says, and utilize whole disk encryption via Symantec PGP.  I have been told this implementation of PGP has government backdoors to decrypt data.  Any insight as to is this so?  And, if so, any recommendations on an alternative?  Thanks for the great podcast and helping to keep my drives running with SpinRite.  Can't wait for the next version.  Backdoor in Symantec's PGP?



STEVE:  Yeah.  I just had to say no.  I mean, I don't...



LEO:  It was open source.  I don't know if it is still.



STEVE:  Yeah.  I don't know either way.  But it feels - of course we don't know who's told him this.  He says, "I've been told this implementation of PGP has government backdoors."  Doesn't that sound like something that some weenie posts on a forum somewhere?



LEO:  Sounds like something Adam Curry would say.



STEVE:  Yeah, it just...



LEO:  We don't know.  It's an easy thing to say.



STEVE:  Yes.  And I would be very surprised.  But to answer your question, Jim, TrueCrypt.



LEO:  There you go.  Open source.



STEVE:  TrueCrypt, we know, is open source.  It's cross-platform.  Those guys have nailed it.  I've lost track of what version it's at.  It's at 6 or 7 or something.  It solves the problem.  So if you have any concern at all that there might be something funky going on, I absolutely wouldn't think so at all.  To me that, "Oh, yeah, that has a backdoor," sounds like something you read where script-kiddies are posting nonsense on forums.  It's like, okay.  I see that kind of nonsense all the time.  But TrueCrypt is your friend; and, end of story, they've nailed it.



LEO:  TrueCrypt is your friend.  But it's funny because you've come around.  Because I've said for a long time the only encryption to trust is open source.  It's the only way you can be absolutely sure.  And I know that there's some commercial encryption technologies you've talked about in the past.  But I think we're in agreement now.  If it's not open source, you don't know.  And I would say, for instance, one response to this would be, well, Apple's got full disk encryption, FileVault, you could use that.  But again, you don't know, and no one can know, what's in there.



STEVE:  I guess what I like is sort of the hybrid, where someone - and I'm seeing this more and more - someone says we're selling a product that incorporates encryption, and we need this to be ours.  But here's the protocol, and here's an open source implementation that demonstrates that this is what we're doing.



LEO:  Yeah, but you could still have a backdoor tacked onto that open source implementation.  I want to see all the code.  I want to be, in fact, if you really care, you want to be able to take the code, look at it, then compile it and use that.



STEVE:  What that does say, then, is that you really can't do commercial crypto.



LEO:  That's my feeling.



STEVE:  Which is to say that crypto has to just be given away.  It has to not be where your value is added.



LEO:  That's where I've always believed that.  Let's move on.  Patrick McAuley, Guelph, Ontario, Canada wonders about bandwidth and whether it's best to take the top measure.  This is what you recommended last week, not take the average, but take the highest.  That's the max you can get.  He says he just listened to that:  Responding to one question about checking your online speed, you said we should test our speed several times, then take the highest reading as our actual bandwidth.  But I'm wondering, couldn't this be misleading for people who get to the Internet by a cable connection?



Here in Canada, I use Rogers Cable, and they advertise "SpeedBoost" as a benefit.  Comcast in the U.S. has the same thing under a different name.  That's absolutely true.  The idea is that when you first connect to a site, for instance Netflix, they'll boost your speed well beyond your normal bandwidth for the first minute or two if that bandwidth is available.  This is great to speed up the initial buffering on Netflix, but it can give a very misleading reading if you use a site like Speedtest.net to check your speed.  If your ISP provides this feature, would you not be better off taking the average of several readings as a more accurate value for your bandwidth?



STEVE:  Well, okay.  So here's the problem.  We have a situation where our bandwidth is not constant.  And the question then is what is it that we're trying to measure?  Do we want to measure the SpeedBoost effect, or do we want to measure the post-SpeedBoost nominal speed?  If we take the average, then we've sort of got neither of those.  We've got some that was boosted, and so our number will be skewed high from the average.  So I guess I don't know what to suggest except to be aware of what's going on.  Maybe, if there's any way to look at the speed initially and separately after SpeedBoost has been removed?  I guess sort of...



LEO:  The SpeedBoost after the first couple of minutes doesn't do anything.



STEVE:  Perfect.



LEO:  It settles down.



STEVE:  Perfect.  In which case you'll have to be extra clever.  The reason I said you want to take the highest measure over several different tests, and you would still want to do that, even if you have SpeedBoost, is that arguably your bandwidth is the best that your line, that your connection can deliver, rather than its current performance, which may be weighted down.  Like I noticed, like, my cable modem slows down when people start getting home from work, for example, in a residential area, because they turn their computers on, and they start doing whatever they want to do.  So it certainly depends upon time of day and the nature of your connection.  A DSL connection probably doesn't have that same characteristic.



So if you care about this, get to know by doing lots of tests, and you'll begin to see patterns, and you'll understand.  But keep in mind that you probably want to think in terms of, at any given time, what is the highest you can get in those circumstances because I think that's your real bandwidth, your actual bandwidth.



LEO:  Yeah, it's really two numbers.  If you have SpeedBoost, it's two numbers.  It's what that SpeedBoost peak is, and then what your sustained throughput is.  And it's good to know both.  I mean, SpeedBoost is valuable.  As he says, it fills the buffers fast.  If you're just doing web pages, it makes web pages pop up.  In the Comcast implementation, it's the first 25MB.  Well, that's going to be plenty for a web page to load very quickly.



Matt's sentiments from Auburn, Washington were echoed by so many listeners:  Steve, I know this is a heated topic, but since everyone else is giving you their opinion, I wanted to, as well.  For anyone who complains that episodes are too long, why don't they just hit the Stop button?  Those of us who want to hear more, but can't because there is no more, don't have an option.  It's sad every time you have to stop before finishing your questions, or can't go into as much depth as you want to.  Believe me, tens of thousands of people listen to you because you have that depth to go into, which we can't find anywhere else.  So I say 'tis better to have more, and let people stop when they want to, than not to have enough.  I can't begin to understand why people would spend the time to write you to shorten your podcast when the Pause button is right there.  Thanks for listening, and keep on talking.  Matt.



STEVE:  So I just wanted to acknowledge all the people that have written.  This was one question or statement from among so many that I found in the mailbag when we were discussing this.  So I just wanted to thank everybody.  And I think Matt's probably right.  I think we found about the right formula.  You and I, Leo, nominally have two hours.  We screw around and talk a little bit and get recording maybe about 20 minutes in.  And so we're generally - and then typically I sort of pace the things.  I've got my eye on the clock.  We've got 10 minutes to go right now, and we've got two questions left, so we're right on target for a greater than 90-minute podcast.  It's funny, too, because some people have said, "I remember when those were 30 minutes."  And it's like...



LEO:  They were, briefly, very briefly.  I don't actually want to say it that way, as the owner of this network.  Let me say something a little different.  I do appreciate the feedback about podcast length.  We always are paying attention to what people tell us, and he of course has the right point.  You could listen to less.  But I don't think people are saying that.  I'm thinking they're saying, not that they want to cut you off or that they want you to be less than thorough, but that they don't need the podcast to be that long or whatever, and I listen to that.  Whether you listen or not is another matter.  But I listen to it, and in fact it is too long right now because I'd like to get these done a little quicker.  And there's a number of reasons.  One is we have a schedule.  The other is I'd like to eat lunch before TWiG.  But also, there's also the issue of, well, how much material do you want to put in a podcast?  How much content do you really need in a podcast?  I don't ever, and we never will, want to shorten stuff as broadcast media does just because it's got to be six minutes.  The topic should go as long as it needs to go.  That's absolutely the case.



STEVE:  Yay.



LEO:  But then there's other issues, as well.  And I certainly don't, believe me, I love to hear from people.  And if it's your opinion it's too long, I will listen to it, absolutely, as well as his opinion, that it's not long enough or whatever, or it's just right, or hit the Pause button if you don't like it.



Anthony in Melbourne, Australia shocked Steve with this news:  Steve, on SN-358 a listener was unimpressed with Microsoft's recommendation to close down all browser windows to clear all logon sessions, et cetera.  It's kind of surprising.  This may be true for Internet Explorer, but ever since Firefox 4, all sessions including SSL are saved.  Oh, I didn't know that.



STEVE:  I didn't either.



LEO:  Try it for yourself.  Close down Firefox, then reopen it.  Hit History and click "Restore previous session."  You should now be logged in to all your previous site sessions.  What?



STEVE:  Yes.



LEO:  I had a difficult time finding out how to disable this, and eventually came across a page on MozillaZine.  It's a long URL.  Actually, if you search for "browser sessionstore privacy level" in MozillaZine's knowledge base, that should probably be sufficient.  I hope you can mention this to Security Now! listeners. 



STEVE:  Okay, now, I was very surprised.



LEO:  Yeah, wow.



STEVE:  What we're talking about, and we've discussed this many times, are session cookies.  When you log onto a facility, you are given a cookie.  Hopefully this has been done over SSL, and the cookie is flagged with a secure flag, so it will never be transmitted unless you have an SSL connection.  Your browser says before it adds the cookie to its query headers, is this secure?  And if the cookie is flagged secure, it will not include that cookie unless it's going to the intended domain that the cookie is set for, and the connection is secure.  That guarantees that men in the middle, nobody sniffing or snooping can see what the cookie is because, once you've logged in, that is your token that keeps you logged in as you move through the site, as you post, as you browse, as you do whatever.  You keep reasserting your authentication to the server because, as we know, web-based surfing is sort of event-based.  It's individual queries and replies.



All of this means - it's called a "session cookie" because, when your session is over, it's gone.  And it's always been the case that it's not stored on the hard disk.  It's kept in RAM as the session.  And when you close the window, when you close the browser, that's it.  It turns out only IE honors that.  What happened, apparently, when they went from Firefox 3.6, which is where that ended, into this new era that began with 4 and has rapidly shot to 13.0.1, which is where we are now, they deliberately changed that.



Now, I immediately changed it back.  I just don't like that.  And I proved it to myself.  I have a way of using session cookies on GRC where I assumed that shutting the browser down lost the session cookie.  So I logged in with a session cookie.  And, I mean, this is my code.  I know what the cookie is.  I can see it.  And I shut down Firefox, fired it back up, and it still authenticated me.  Which is like, whoa.  Not the way it's always been.  IE forgot me.  I did the same thing on Internet Explorer, shut it down, came back up, relaunched it, it said I have no idea who you are.  And Google remembered me also.



So I can see where this limits customer service complaints and so forth, where it's like, okay, this will just be easier for users.  And it's one thing if you click the checkbox, like eBay has "Keep me logged in for the day" or whatever.  And many sites allow you to manually say I want to stay logged in.  Normally that checkbox is off by default.  But what this means is you're staying logged in anyway.



So we all know, or long-time Firefox users know, in the URL bar where you normally type in http://, so forth, you can put "about:config," hit Enter, and that takes you to an amazing depth of optional configuration stuff.  And there's a search bar in there on that page which you need.  If you type "sessionstore," all one word, into the about:config page of Firefox, you'll still then see, I don't know, maybe 20 items.  One of them there is "privacy_level."  And I think I recall it defaults to zero.  You need to change it to 2.  I have.  When you do, then Firefox behaves the way I think it should, which is closing it actually does cause it to release all of its session cookies, the way IE still works, but no longer the way Firefox or Chrome work, which really did catch me by surprise.



LEO:  Yeah, because as you say, it's a session cookie.  It should be only for a session.



STEVE:  Yeah.  That's the way it was designed.



LEO:  I mean, that's the expectation, yeah.



STEVE:  These guys decided differently.



LEO:  I understand why they did it, because maybe people want to not have to log in again.



STEVE:  Well, actually I followed back, I backtracked why this happened.  It's because of crashing.  It used to crash, Firefox would crash, and people...



LEO:  Ah, of course.  So you restore your session after a crash.  That's it.



STEVE:  Yup.



LEO:  You're right.  I get it.



STEVE:  Yup.  And unfortunately it also restores it after a graceful shutdown, which I don't think it should.



LEO:  Yeah, you could change that.  You could say, hey, a shutdown erases that, doesn't save it.



STEVE:  Yeah.  There is an option, actually, among those settings, for doing that, where a crash will still restore it, but a shutdown won't. 



LEO:  So that should be the default.  Randy Hammock, KC6HUR, in Sun Valley, has our last question and our MacBook Pro Camera Tip of the Week.  Do you tape over your cameras on your laptops?



STEVE:  I don't think I have any cameras on my laptops.  They're old.



LEO:  Another reason to go with old.



STEVE:  Right.



LEO:  Regarding placing a sticker over the camera for privacy causing the light sensor not to function for keyboard backlight and screen brightness control, not true.  Did we say it was?



STEVE:  Yeah, we did.  Or a listener...



LEO:  We were questioning whether it did.



STEVE:  A listener did, yes.



LEO:  I discovered the light sensor is located in the place where the green camera active LED is.  If I place my finger over the camera, nothing happens.  If I place my finger over the LED holes - and by the way, this is specific, he says, to his MacBook Pro.  It's probably different for different computers - the keyboard lights come on and the screen dims.  Older MacBook Pros had the light sensor in the speaker grills, both of them.  If you place a hand over both speaker grills, not just one, keyboard lights come on, and the screen dims.  So go ahead, cover the camera for privacy, and you'll retain keyboard and screen auto light control.  Thought your listeners would find this useful.  Randy in Sun Valley.



STEVE:  And I do because cameras spying on people have been a recurring problem that we keep covering.  Spyware turns cameras on.  Even babysitting software that schools use, as we've extensively covered, turns the cameras on and spies on their students without their knowledge.  So I really endorse the idea of just taking a little square of the sticky part of a Post-it note, a 3M Post-it note, and just stick it over the camera.  If it's not something you use all the time, just cover it up because that seems like it's simple, and it's a physical shutter.  And now you know, do not cover the little green light because you'd like your light sensor to still work.  And then you've got a solution.  Old school.



LEO:  [Chuckling] Steve Gibson, he is old school.  He's the definition of old school.



STEVE:  Yeah.



LEO:  XP, BlackBerry, PDP-8s.  You can hear this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC, if you want to listen live.  We'd love it if you do because I pay attention to the chatroom and all of that.  And so it's a great kind of feedback mechanism.



STEVE:  And actually, Leo, there is 20 minutes of fun that our regular podcast listeners don't get, unfortunately.



LEO:  Yeah.  Like, for instance, I try to keep the diet information out of the show.  We do that, we talk about our diets before the show.



STEVE:  Whether you're floating on the surface or not.



LEO:  Exactly [laughing].  You can get this...



[Talking simultaneously]



LEO:  Yes, exactly.  You can get this show, not that part, but you get the rest of it on demand, after the fact, via our website or Steve's.  Now, Steve has an unusual version.  He has a 16Kb audio version for people with severe bandwidth impairment, or who are just cheapskates.  You can also get a transcript.  And we hear lots - you just talked about somebody who listens twice.  You know what, you could listen once and read the transcript.  That would be a good way to do it, too.  The transcript is a great way to kind of follow along.  All that's at his site, GRC.com, along with SpinRite, the world's best hard drive and maintenance utility, all the freebies he gives away all the time, GRC.com.  And if you want to ask a question for our next Q&A episode, there's a feedback form there you should use.  It's GRC.com/feedback.  Steve is on the Twitter, @SGgrc.  He's also got a feed for the very low carb contingent, @SGvlc.  Steve, thank you so much.  Always a pleasure.



STEVE:  It is always a pleasure.  And we're going to have a great podcast next week with news from Paul Vixie and DNSChanger and the non-event.  But I read what he wrote, and it was so good, I'm going to share it with our listeners.  Then we'll discuss it.



LEO:  I want to hear his defense of what I thought was an indefensible action on the part of the FBI.  But if Paul Vixie, the father of DNS, says it's okay, well, that's different.



STEVE:  I don't think that's really where, I mean, he was called in because he was someone with such a reputation, and the FBI wanted to make sure it was done right.  And he did help them get it done right.  So we're going to have a great podcast next week, and I always enjoy this.



LEO:  Thank you, Steven.  Thank you all for joining us.  We'll see you next week on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#361

DATE:		July 18, 2012

TITLE:		Paul Vixie & DNS Changer

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-361.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's security news, Steve and Leo take a close look at the recent "DNS Changer" malware, the FBI's role in the "takedown" of the malicious servers, and the expert technical assistance provided by Paul Vixie, one of the pioneers and principal developers of the Internet's Domain Name System (DNS).



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  We'll take a look at the newest Firefox, what's new; a little bit about Mountain Lion OS X and its security features; and we'll hear from Paul Vixie, the guy who practically invented DNS, talking about why his company, ISC, helped the FBI take over servers to protect people infected with DNS Changer.  Paul explains all, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 361, recorded July 18th, 2012:  DNS Changer.



It's time for Security Now!, the show that protects you, your loved ones, and all you know, all about you.  For privacy and security online, there's nobody better than the Explainer in Chief himself, Mr. Steve Gibson.  Hello, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  I was just showing Steve some fine Cabernet, sent to me by a viewer.  I'll save it for you because I know you're a Cab fan.



STEVE:  That's my poison, yes.



LEO:  Preferred poison.  So today I'm really interested because I have been, and I remain so, and I'm willing to have my mind changed - somebody tweeted me because we were talking about another topic, I think it was Windows or Microsoft strategy, and I changed my mind on the air because Andy Ihnatko convinced me that Microsoft's strategy was actually good for consumers.  And I said...



STEVE:  There is a strategy?  I wasn't aware.



LEO:  That was my problem.  But I thought, this is a badly run company.  They're telling people ahead of time that here's a new version of the Phone system, Windows Phone 8.  It is going to be available sometime in the future.  And any phone you buy today will not be upgradeable.  That to me was like Osborne, the Osborning of Microsoft, saying don't buy it.  Whatever you do, don't buy the current product because a new better one's coming, and you can't upgrade.



And he kind of convinced me that, yes, but isn't this honest, telling consumers?  Apple would never do that.  But really isn't it more honest to say, look, we've got something better coming along.  It's bad for business.  And so I changed my mind.  And somebody tweeted me, saying "You're such a flip-flopper."  And I really wanted to kind of say, no, it's appropriate to change your mind when presented with...



STEVE:  New information.



LEO:  ...new information.  And if there's a...



STEVE:  Absolutely.



LEO:  So I am prepared, all of this is a long way around saying I'm prepared to change my mind on my position.  But I'll restate it, that the FBI mishandled DNS Changer, that they should not have kept that DNS server running silently along until last week, that they did us all a disservice.  But I guess we're going to talk about that today.



STEVE:  Well, yeah.  What I liked was that I ran across a really nice sort of retrospective, here's what happened, by the god of DNS.  And I'll set this up, after we get caught up with the week's news, by explaining a little bit more about who Paul Vixie is because he is DNS, for all intents and purposes.



LEO:  He wrote BIND, which is the original DNS.



STEVE:  Yeah, I think like from version four point something to eight point something.  So, like, 4.2 through 8.2, he was the chief officer.  And what I liked about what he wrote was there were a number of useful insights that I thought would, first of all, this gives us some really great background.  This was all sort of brought to the fore because I was surprised by the amount of popular press - this was weekend before last, the weekend before the Monday that these alternative servers, the DNS servers that had been sort of switched over to and commandeered and, well, we'll explain all this.  But I was surprised how much of the popular press got involved, warning people that malware was going to strike on Monday.  And it's like, okay...



LEO:  Wait a minute.  It already struck.



STEVE:  Way the wrong message.  And so it's like, okay.  And so anyway, so I saw what Paul wrote.  And I thought, okay, there are so many really interesting points he makes that it's a perfect discussion for us.  So that's our podcast for today.  I think people are going to find it really interesting.  And a bunch of interesting news.



LEO:  And I'm prepared, if need be, to modify my opinion.  I can't think of a single thing that would make me, but...



STEVE:  And this may not.  It isn't my goal to do so.



LEO:  Hey, but Paul Vixie says something, I listen.  Right?



STEVE:  Yeah.  I would.



LEO:  If you say something, I listen.  If Vixie - there are certain people you just know they know their stuff.  Mr. Gibson.  Let us get underway.  First, Firefox 14 came out.



STEVE:  Yeah.



LEO:  And I knew you would jump on this.  This is so cool.  Go ahead.



STEVE:  So, yeah.  We're now seeing a chain of releases from the Mozilla folks.  Instead of having - I know Firefox 2.0 we had for a long time, then 3 finally.  Then with 4 they began to accelerate their release schedule.  I did see an ex-Mozilla person, and I don't know what cross he might be bearing or what axe he has to grind, complaining, saying that this new approach that the Mozilla team has taken is lowering the quality of the product, as if they're trying to keep up with the release rate of Google's Chrome browser.  From our client standpoint, from the standpoint of users, I see nice things happening.  So we got 13, which then jumped to .0.1 when they fixed a couple of little release things, just recently on June 5th.  So, what, six weeks later we move to 14.



Now, what 13 gave us was the ability for a new tab to show a series of most visited thumbnails, and the SPDY protocol was enabled by default.  And I ought to mention that a number of people tweeted me about SPDY apparently not being as SPDY as we thought.  It was one observation from sort of a grumbly old guy who seems to not be very happy with where HTTP - wait, no, not that, yeah - HTTP 2.0 is headed.  There are a number of sort of converging programs, and in this posting he attacked all of them on differing reasons.  And he did have specific things that he needed from HTTP that SPDY wasn't providing.  And it's like, okay, well, sorry we didn't provide what you wanted.



So I just think it's good that it's there.  It is the case that you can support the protocol and not get a lot of the benefits until you deeply support the protocol.  That is, there really needs to be a little bit more engineering going in than just adding a few of SPDY's features.  And that's certainly what Google did when they were developing it in order to get a sense for what it could really do.  So it doesn't cost us anything.  It's like, okay, so now it's enabled by default from Firefox 13 on.  And certainly it's supported by Google's Chrome.



So now we're at 14, as of, I think, Monday it was released.  It was in the beta chain for a while.  And as I understand it, they've got a number of major releases sort of moving along over time.  One of the headline features of 14 is that it now supports Google searches up in the - they have some funny name for it, the WonderBar or something, I can't remember what they call it.



LEO:  The AwesomeBar, I think, is...



STEVE:  The AwesomeBar, right.  It's like, okay, well, I guess that's more awesome than not having it.  Anyway, they're now, since Google robustly supports HTTPS, all of the searches that it's doing for you in the AwesomeBar are SSL protected.  So that's nice.



LEO:  That's nice.  That's actually great.  I mean, it would be nice if they just turned SSL on everywhere.  But I guess that's asking too much.



STEVE:  Right, well, you need to know that you've got it over on other side, that is, on the server side.  Otherwise, attempting to SSL when not being instructed to can really slow things down.  You're going to fail.  You're not going to have a certificate.  Then you've got to back off and so forth.  Also, sort of in a bug fix-y thing, they're now offering full-screen support for Firefox under Mac OS X Lion.



LEO:  Yay.



STEVE:  Yes, which they didn't have before, especially since you seem to have - you were just saying a second ago that you were backing away from Chrome for the moment.



LEO:  I've been using Safari because Chrome is slow and buggy on Mac OS X.  And so I'm trying Firefox 14.  I made it my default browser today, just to see.



STEVE:  And then something that we have touched on since it's been in the works for a number of their major versions, it's known sometimes as "click to play" and other times as "opt-in activation for plugins."  That's sort of the formal name in their developer docs.  And it's at the preliminary stage now, with a release target for version 16, so a couple more obviously major releases from where we are at 14.  It's disabled by default.  But once again, you can go to about:config, anyone who wants to play with this.



The idea is it is giving us, for the Firefox users who really do want the sense of and the reality of more control over their web surfing experience - see, what I recognize clearly is that we're all not cut from the same cloth.  There are people who just - they're not into security. They're not into the experience of using the Internet the same way probably listeners to this podcast more tend to be - those of us, for example, who are using NoScript and don't mind saying, okay, wait, this website doesn't seem to be working right, let's enable scripting and see if that fixes it, so that we're in general not surfing with scripting enabled.



Now, natively in Firefox, you'll be able to not surf with plug-ins enabled, like Flash, like Java and anything else that is an add-on to your browser, unless you selectively enable it for a page.  And you are now able to do per-site enabling, so that you could say, if I have a plug-in that Google wants to run, then, fine, I'll allow Google to do it, but not if I'm randomly surfing around the web and get zapped.  And in fact, we'll be talking a little bit later in this podcast about a new multiplatform trojan which has been found, which infects Windows machines, Mac machines, and Linux machines.  It's an equal infecting opportunity trojan.



So there are obviously some benefits to not running with plug-ins going all the time.  This is built into 14 disabled.  So you go "about:config."  And then, since that page is ridiculously full of settings, you want to search, just put the phrase "plugins" into the search term.  Even so, you get a huge list of things.  Look about two thirds of the way down, and the item you're looking for is plugins.click_to_play.  It'll be set to False normally.  You can just double-click it to turn it to enabled and restart Firefox and experiment with this new feature.



So anyway, I'm delighted that they're moving forward.  I'm a little upset with Chrome at the moment because it really seems to be suffering from what Firefox was suffering from for quite a while, and that is it's become quite memory intensive.  I mean, "bloat" is the word I'm trying to work around saying.  If I launch it, it squats on about 333MB of RAM, just firing it up.  I love their security model, that they have a separate process model and they're communicating cross process, that each tab is in its own process.  There's a lot architecturally that I think they've done well.



I hope at some point they will, as the Mozilla folks did, realize, whoa, while we've been busy adding things, this thing has gotten really big.  We need to now step back and get this under control because, I mean, it's - I have Task Manager running in Windows, and I launch Chrome, and as I said, about a third of a gig of memory is just gone, taken by it.  And that's without any expensive pages loaded.  So at some point I hope they are going to get that under control.



Speaking of which, they have just taken themselves, that is, Chrome, to v20.  And it's 20.0.1132.57 and counting.  They fixed three critical vulnerabilities.  Two were "use after free" errors, where memory is released, but there's still a pointer to it which a clever hacker can use in order to exploit that fact, that dangling pointer, essentially, in order to execute code of their choosing.  There is also something that they described as a "layout height tracking bug," which they called a critical vulnerability.  So somehow, someone clever found a way to do that.  In fact, the guy's handle is "miaubiz."  He's someone who has found many bugs in the past.  And I had forgotten that they have a Security Hall of Fame at Chromium.org, and they really do pay out.  The top two guys who have been finding bugs have earned for themselves each $60,000 by finding...



LEO:  That's not bad.  You could make a living doing that.



STEVE:  It is.  And in fact, just for these three critical vulnerabilities, this miaubiz guy, who's No. 3 in the Hall of Fame, although he's ranked there with a bunch of others who also have made $10,000, for these three he received $8,000.  And I don't know whether that thousand was updated in the Hall of Fame list yet.  So, yeah, there are guys there who have made $60,000, thanks to Google's paying people for finding problems.  Which I think is effective for them.  This also includes some stability improvements for the browser, as well as updates to the Flash Player flug-in - Flash Player plug-in.



LEO:  The Plash Player flug-in?  Okay.



STEVE:  And their JavaScript engine, V8, has also been improved.  So they've continued moving it forward.  And just after the podcast last week came to the news was the fact that Yahoo! lost control over 450,000 logins for their voice messaging service.  And they of course learned, the way these companies do these days, unfortunately, because their customers' email addresses and plaintext passwords were posted publicly.  So this tells us not only was their security not up to par - because an SQL injection was able to go in and query an SQL backend database that was available.  So not only was that a problem, but what was stored in that database was plaintext passwords, no hashing being done.



So, I mean, and the way people began to see this also, and we see this also, was people began to get their accounts hacked.  So the hackers stated that they posted the data to highlight the need for improved security.  It's like, okay, well, good.  Yahoo!'s response was, "We moved aggressively to fix the problem," which I guess is being unaggressive about fixing it.  And in the news, what, I guess in the last day or two, Leo...



LEO:  Yesterday, yeah, Marissa Mayer.



STEVE:  Yeah, Yahoo! has acquired a new president.



LEO:  And that's actually very exciting.  It's a daunting task.



STEVE:  I was going to say, don't you think it's too late?



LEO:  I don't know.  You know, it's so funny, technology companies, up and down, up and down, it's very volatile.  And I think that having...



STEVE:  Yes, they could remake themselves.



LEO:  That's right.  Yahoo! is still a strong property, and having somebody like Marissa Mayer at the head, there's a lot to do, but I think she can bring - she's such a marquee name.



STEVE:  Yeah.



LEO:  It's a shock, frankly.  Nobody had talked about her at all, and we don't know how it happened.  But I think it's the best possible scenario for Yahoo!, let's put it that way.



STEVE:  Yeah.  So here's a really interesting scenario that I thought is also a perfect cautionary tale for our listeners.  And Mark Russinovich's second book is not out yet.  I've read it, and it's going to be coming out in September, he said.  He has agreed to appear on the podcast.  So we're going to get...



LEO:  Yay.



STEVE:  Yes, we're going to get Mark R. on to talk about the book and the things that it talks about because I can't think of a better fun, fictional, but, boy, is it fact based, read.  It reads like a novelization of many of the things we talk about on the podcast.  So here is a true story that reminded me of Mark's book.  And this was the - H-online.com reported this, that a number of infected USB drives were recently left in the car park of a Dutch chemical firm, DSM - and they're DSM.com - in a failed corporate espionage attempt.  According to a recent report from a Dutch newspaper - and I went there, but it was in Dutch, so I didn't make very much progress there because I don't speak Dutch.  But it's Dagblad de Limburger is the newspaper's name.



They said the drives were planted by an unknown party in the hopes that one or more of the company's employees would find them, pick them up, wonder what's on them, and insert them into their office computer.  But this was foiled because, instead of plugging it in one of the company systems, the employee who found one of the USB sticks turned it over to that company, DSM Chemical's IT department.  Upon examination, the IT department discovered that the drives contained malware that was set to automatically run upon being inserted into a computer.  The malware is said to have been a keylogger designed to capture usernames and passwords and access that company's internal network to send them to an external site.



And upon finding this, the company blocked all access to the IP addresses which the malware attempted to contact because, they say, it was a clumsy attempt to steal data, and no damage was done.  And of course blocking the IP addresses that the malware was attempting to connect to would prevent it from succeeding if there were other - and apparently several other USB drives were found.  They went out and looked through the parking lot and found some other ones that were identical.  So they were hoping that one employee would just pick them up, find one and think, huh, I wonder if there's anything tasty on these, and in the process get this thing installed inside the corporate network.



And of course we know that this is the way that Stuxnet was propagated because the internal network that was being used by the Iranian nuclear enrichment process was deliberately isolated.  There were no networking connections.  Yet that didn't stop it from jumping, from using a USB drive and the zero-day exploits that Stuxnet was using at the time allowed it to jump the so-called "air gap" over to those systems and wreak the havoc that it was designed to.  So but this is the kind of thing going on at the corporate espionage level is let's just toss some USB drives around, and maybe we'll get lucky.  And if not, we'll send targeted email or whatever it takes in order to get inside this company whose network we want to be in.  So, wow.



LEO:  Spear phishing.



STEVE:  Yeah, yeah.  And I just picked up on this.  I thought maybe you would have some more news about it, Leo, and that is that Mac OS X Mountain Lion, the Golden Master, was just released to developers.  Apparently the rumors are it's scheduled for release on July 25th, so pretty soon.  And I was looking at it from a security angle, was there any security news that I could bring to our listeners, and all I really saw was more UI sort of things where they're continuing to move OS X and iOS closer together, mostly by moving OS X closer to the feel and features of the iOS platform.



LEO:  The big change - and by the way, of course no one knows dates, but they have said, Apple has said the end of July.  So it will be, without a doubt, in the next couple of weeks.  And the 25th seems reasonable.  They have an earnings call on the 24th.  Last time they announced that Lion would be available the day after the earnings call, which this time would be the 25th.



STEVE:  And I did hear that there was some employee announcement that went out saying plan to work late on the 24th.



LEO:  Those are pretty much useless.



STEVE:  Okay.



LEO:  Take it as a veteran Apple watcher.  Because they do overnights all the time.  But there is a thing, and I would love for you at some point to look at it, there is a security feature that is significant in Mountain Lion.  It's called Gatekeeper.



STEVE:  Okay.



LEO:  And there's a couple of very big changes.  But the key to Gatekeeper is that from now on you will have a setting on all OS X devices that controls what's installed.  So it's going to be a little bit like iOS or Android.  And by default you'll only be able to install from the Mac App Store.  You have a box that says "Mac App Store" and "Identify Developers."  And Apple will have a certificate situation, a public key crypto certificate, identifying developers; or the least secure, of course, the way it is now, you could download anything, anytime, anywhere.



STEVE:  Free for all.



LEO:  Free for all.  So these - I think this is really great.  I'm not sure what the default setting is.  The way it's marked on their Apple website is the middle setting, which is actually probably what most people will want, which is either buy it from the Mac App Store or by a developer with a certificate.  So malware, of course, unless they can figure out a way to hack the certificate situation, will never have a real identity.  So I think Gatekeeper is going to be a significant security feature.  And they are now requiring developers who want either to be in the App Store or a certificate to identify ahead of time what kinds of access to the operating system they want.  They'll be sandboxing.  And if you do not identify - you won't have - for instance, let's say you want to have access to the file system.



STEVE:  Yes, this is major changes.  And we've talked about the sandboxing in OS X before, and so they must be moving it forward.



LEO:  In effect they're going to kind of somewhat require it.  You'll have a choice.  They're also, let's see, I think that they are adding address randomization.  I don't know if they had that before, but they certainly will have it now the address space, data space randomization.



STEVE:  Yes, ASLR.  What I remember was that it was not as robust as it could be, and that they were going to be increasing it to make it more useful somehow.



LEO:  My suspicion is that this will be the beginning of that.  And then they are adding to the privacy controls.  So as you know, the Do Not Track setting will be added to Safari, not by default on, but it will be there.  And you can limit or block cookies and limit website access to location services.  I think they're going to have a built-in password generation assistant.  They've always had that, but it's been hidden in the Keychain.  Now it'll be much more public.



STEVE:  And I think it's, like, $20, right, to upgrade?



LEO:  It's $20.  Almost everybody will do it.  That's the way it is in the Apple world.  People tend to do upgrades more so than in the Windows world.  And it's an App Store update.  So you just go to the App Store, you download it, and it installs.



STEVE:  Oh, nice.



LEO:  Yeah.  So I think this is a major move toward security.  There's underlying stuff that Apple doesn't talk about, antimalware stuff that Apple doesn't talk about much in OS X.  And I suspect that will also be beefed up.  So, yes, I think there are actually some significant security implications to the new one.



STEVE:  Cool.  So F-Secure, the well-known security company that we refer to every so often when they come up with something interesting, discovered a cross-platform Java trojan.  It's the first one that we know of which runs on all three major platforms.  There have been some Mac and Win cross-platform malware.  This one now brings UNIX and Linux into the fold.  And they show in their posting the source code or the Java code for this, where it uses the system objects getProperty and gets the os.name, changes it to lowercase, and then it checks to see if that contains the string "win."  If so, it customizes some code and installs the Windows-specific malware.  If not, it checks that string to see if it contains the substring "mac."  If so, it installs the Macintosh variant of the malware.



LEO:  Wow.  That's pretty sophisticated.



STEVE:  Otherwise, it checks to see whether that os.name either contains an "nix" or an "nux."  And if it's either of those, it installs the Linux/UNIX malware.  So they called it Trojan Downloader:Java/GetShell.A for the Java component.  And then either W32, OSX, or Linux/GetShell.A for the three different versions.  And interestingly, the OS X is a PowerPC binary.



LEO:  They couldn't be bothered to update it, for crying out loud?  That's ancient history.



STEVE:  So you have to have Rosetta installed on an Intel platform in order...



LEO:  Rosetta does not come with Macs anymore.  So either they're intentionally targeting old systems...



STEVE:  And creaky.



LEO:  ...or they don't know what they're - maybe they just don't know how to update the code.



STEVE:  Yeah.  Odd.



LEO:  That's weird.



STEVE:  Very odd.  And when you get infected by this multi-headed Hydra, it connects to a Command & Control server and awaits further instructions.  And that's typically downloading and executing additional malware.  They have been monitoring the Command & Control server with their own honeypot install, and so far no instructions have been forthcoming.  But maybe the bad guys are waiting to acquire a critical mass before they start using it.



And then we also had a Dropbox Spam and Outage event in the last couple days.  European Dropbox users began receiving gambling casino spam to email accounts which they only used and set up just for Dropbox accounts, which was of course the canary in the coal mine that, oops, somehow email accounts got loose from Dropbox.  And the last posting I saw from Dropbox was at 3:37 p.m. Pacific time yesterday, where they said - oh, and I should mention that there was also an outage, about 30 minutes, where Dropbox stopped working.  We don't know if it was Dropbox taking themselves offline in order to fix the source of the security problem, or I also heard reports that it was some sort of denial of service attack against Dropbox.



So at this point things are a little bit muddy because this has just happened.  But the Dropbox PR face said, "We're aware that some Dropbox users have been receiving spam to email addresses associated with their Dropbox accounts.  Our top priority is investigating this issue thoroughly and updating you as soon as we can. We know it's frustrating not to get an update with more details sooner, but please bear with us as our investigation continues."  And I want to thank Brian Krebs, who was my source for this information.  He was on top of it and tracking it down.



And while I'm thanking people, I want to thank Daniel, who is in Bedfordshire, England.  He said, "Hi, Steve, Leo.  I've been listening to you guys since the first episode and want to thank you and Leo for making my journey to work so much more enjoyable.  I bought a copy of SpinRite many years ago in support of your podcast, but never had the opportunity to use it.  Well, it finally happened.  My hard disk failed.  And rather than worry about data loss," and he said in parens, "(fortunately I use Carbonite)," he said, "I immediately went looking for my copy of SpinRite.  I popped it in, and two hours later I was up and running again.  So yet another hard drive saved.  Thank you for a wonderful podcast and building an HDD recovery tool that does what it says on the tin for a very affordable price."



LEO:  Does it come in a tin?



STEVE:  Eh, no.



LEO:  I like the idea, though.  You might want to put it in a tin.



STEVE:  I love the jargon.  And then in Bedfordshire, England-ese, he says, "Keep calm and carry on.  Best regards, Daniel."



LEO:  Isn't that great.



STEVE:  Daniel, thanks for the report.



LEO:  All right.  Back we go to the task at hand, Mr. Steve Gibson.



STEVE:  You know, I did realize, I was thinking about commuting, and it is now the case that the standard image you see of any sort of gym club environment is everybody with things in their ears as they're on their treadmill or doing their machines.  We don't know if they're listening to music, but could also be audible podcasts.



LEO:  I really like listening to books because you don't have enough time in the world to read, frankly.  And so that hour a day that I work out, that's an hour a day of extra reading.  I think that's really, really nice.



STEVE:  Okay.  So who is Paul Vixie?  I pulled together some sort of interesting and fun bio stuff because I wanted to give our listeners a sense for who this was who wrote what I will then read.  So he's got his Ph.D. - I put "Ph.D. in DNS."



LEO:  [Laughing] It's true.



STEVE:  But he is Dr. Paul Vixie.  He's currently the chairman and founder of Internet Systems Consortium, ISC, who Internet-savvy people know is the publisher and maintainer of BIND.



LEO:  And, by the way, the people who ran the FBI server for them. 



STEVE:  Yes, exactly.  And I said, as I was researching this, I said, I note that Paul was also previously president of ISC in addition to chairman and founder because I found this dated January 15th of 2011.  He says, in quotes, "'I am relieved.'  That lovely double entendre is what Captain Pike said to Captain Kirk..."



LEO:  [Laughing] That is nerdy.



STEVE:  Uh-huh, "...at the end of last summer's most excellent reboot of the Star Trek series.  I am likewise...."  And you remember, like, Pike was in his wheelchair at that time.  And he said, "I am relieved."  He said, "I am likewise relieved to have been relieved of my long-time post as president of ISC by my good friend and long associate Barry Greene.  I continue at ISC as Chairman and Chief Scientist, which is the equivalent, to me, of escaping to the candy factory.  When ISC was smaller, this was the half of my job I loved most."  So this is Paul's way of saying I love the technology; but I was president for a while, and, boy, am I glad that I get to hand that off now so I can just get to play with the technology again.



So he was the principal author, as I mentioned before, of BIND from versions - he took it up at version 4.9 and carried it through 8.2.  And I'm sure most of our listeners know that it is the leading DNS server software in use today.  There are other server companies.  For example OpenDNS famously uses their own.  Microsoft got into the game late.  But the big DNS servers, the big iron DNS servers, they're universally running BIND.  It is, like, it's the gold standard.



Paul was the principle author of the DNS RFCs.  He did RFC 1996, which is the DNS NOTIFY RFC, which provides a means for a DNS server to notify one that is authoritative to it that it's got changes in its records; RFC 2136, which is the DNS UPDATE spec; RFC 2671, which is eDNS/rDNS extension fields and how they're handled.  And he coauthored 1876, which is DNS LOC; 2317, which is DNS for CIDR, where you don't just have networks that are A, B, and C class, but you have flexible masking so you can sort of tune networks to whatever size you want; and RFC 2845 for DNS TIG.



So, I mean, he's really been into it.  And I found another little thing written about him that says he served as president of MAPS, PAIX, and MIBH; as CTO of Abovenet/MFN; and on the board of several for-profit and nonprofit companies.  He's served on the ARIN Board of Trustees since 2005, where he served as chairman in '08 and '09, and is a founding member of ICANN, the Root Server System Advisory Committee (RSSAC) and ICANN Security and Stability Advisory Committee (SSAC).



"Vixie has been contributing to Internet protocols and UNIX systems as a protocol designer and software architect since 1980," so, what 32 years.  "He is considered the primary author and technical architect of BIND 8," which was, for those who don't know, a major rewrite to bring it current.  And the open source projects do, if they have a really long history, they tend to get a little crufty over time.  And so every so often you have to just say, okay, wait a minute, we're going to take everything we've learned, and we're just going to start again.  And so it was time to do a major rewrite of the server platform.  And he hired many of the people who wrote BIND 9 and the people now working on BIND 10.  So he's really steering the future of DNS on the Internet.



And then, in something completely different, but I just thought this observation was interesting, I found where he had written something sort of sad, but it demonstrates that he does have his finger on the pulse.  He wrote, "Most new domain names are malicious."  He said, "I am stunned by the simplicity and truth of that observation:  Most new domain names are malicious.  Every day lots of new names are added to the global DNS, and most of them belong to scammers, spammers, e-criminals, and speculators.  The DNS industry has a lot of highly capable and competitive registrars and registries that have made it possible to reserve or create a new name in seconds, and to create millions of them per day.  Domains are cheap; domains are plentiful; and, as a result, most of them are dreck or worse."  Which is sort of a sad statement.  But, unfortunately, this is what happens as something like this evolves and matures.



So on March 27th, Paul wrote of his experience with DNS Changer.  He said, "Takedown:  One fine night in November 2011 I got an opportunity to get my hands dirty, working on a project for the United States Federal Bureau of Investigation (FBI).  They were planning to seize a bunch of computing assets in New York City that were being used as part of a criminal empire that we called 'DNS Changer,' since that was the name of the software this gang used to infect half a million or so computers.  I work for Internet Systems Consortium (ISC), a small, non-profit company headquartered in California.  ISC is best known for our work on the Domain Name System (DNS) and our DNS software called BIND, but we have a growing Internet security practice, as well.



"My task that night in New York City was to install two replacement DNS servers supplied and operated by ISC.  This was important because the victims of DNS Changer were dependent on the assets that the FBI needed for evidence, and none of us wanted a half million DNS Changer victims to go dark.  It was a little odd for ISC to send me  ISC's chairman and founder  on this job, but rank hath its privileges.  It was a very long night, since there was no way to complete a detailed plan before the takedown began.  After the DNS Changer gang was in custody and I could 'go intrusive' on their equipment, it took me a couple of hours to figure out exactly how everything was wired together."



And of course I should say that by that he means he's just seeing some stuff running, but obviously he knows everything there is to know about the subject matter.  But it's always the case when you're approaching something like this, it's like, okay, how, down at the lowest level of detail, have they done this?  What ports are they using, what relocators, what routers, what proxies, I mean, you need to really understand it.



So he says, "It took me a couple of hours to figure out exactly how everything was wired together and to move the first group of victims over to ISC's replacement DNS servers.  It then took a couple more hours to move and test the rest of the victims.  All this long night I had a cell phone headset in one ear and a half dozen chat windows open on my laptop.  The full takedown team was worldwide, and there were other actions occurring elsewhere.  By the time we were done, and it was safe to power off the DNS Changer equipment, it was 7:00 a.m., and I nearly missed my train.  Note to self:  If another chance comes along to run huffing and puffing through the New York City subway system and Penn Station, trying to keep up with a younger and better conditioned member of FBI's New York division, take it, but maybe next time bring better shoes."



So about cleanup he says, "Since the original court order that authorized ISC to install and operate these replacement DNS servers was due to expire on March 9, 2012, a new DNS Changer Working Group (DCWG) was formed to handle victim notification and remediation.  We had roughly four months to identify and notify half million or so DNS Changer victims, and to help these victims clean up their infected computers.  Many victims would have to reinstall Windows on their computers, which at first was the only sure cure for this particular infection.



"On top of that, many of the victims have had their DSL or cable modems - their home routers - reconfigured by the DNS Changer malware" - so that's one point we want to talk about is, as we know, this stuff was able to access their routers and change the settings there - "so that they were using ISC's replacement DNS servers, even if none of their computers are still infected, and even if none of their computers were running Windows.  Most Internet users do not have the skills necessary to check and repair the configuration of their home routers, and most Windows users are also unwilling to reinstall Windows.  So even when we could identify and notify a victim, we had a hard time closing the deal.



"We didn't make it.  When March 9, 2012 loomed, we still had hundreds of thousands of victims dependent upon ISC's replacement DNS servers.  Therefore, the FBI asked the judge for an extension, and we were given four more months.  No fooling around this time.  There won't be another extension.  It's now or never.  Put up or shut up, et cetera.  Noting that no private company or individual can legally operate this replacement DNS service on the open Internet unless they have a judge's permission to do so, many ISPs are now starting up replacement DNS servers inside their own networks, accessible only by their own customers, in order to control the risks that they would otherwise face on July 9, 2012, when the second and final court order is due to expire.



"But that kind of risk management isn't the same as cleaning up the problem.  I don't think we want to kick this can down the road.  If an ISP wants to run a replacement DNS server for the purpose of forcibly breaking these computers in small batches, to get their owners to call in and then ask for help, that's one thing.  But it's just going to be a new permanent service that the ISP offers these customers" - oh, I'm sorry.  He says, "But if it's just going to be a new permanent service that the ISP offers to these customers, count me as opposed.  We as a digital society...."  And here's one of the things that I really loved about what he wrote:  "We as a digital society are much better at strategies for coping than we are at strategies for remediation."  Which is to say, for fixing.



"Is your DNS okay?  A half dozen Internet security teams around the world have created special websites that will display a warning message to potential victims of the DNS Changer infection.  For example, if you visit http://dns-ok.de, you'll get a German language page saying either that you appear to be infected or that you appear not to be infected.  Andrew Fried and I created dns-ok.us" - which I mentioned to our listeners a week or two ago - "for the same purpose," he says, "though of course our page is in American English.  The full list of these DNS-checking websites is published on the DCWG's website, along with a lot of information about the threat, the arrests, the takedown, the court orders, and clean-up information for victims.



"Now that we've got all these websites that are able to tell someone if they're a victim and that tell victims what to do to clean up their computers and their home routers, the problem seems to be getting people to care."  Meaning people still aren't caring.  "Internet users are endlessly bombarded with warnings about their security and with offers of services and software, some of it apparently free, offering to make their computers healthier.  The victims of DNS Changer are by this time jaded or overwhelmed or both.  The Internet seems to be a very dangerous place, and most Internet users probably feel that they could spend more than half their waking hours just installing patches and responding to warnings, unless they just put their heads down, ignore all that noise, and try instead to get their work, or play, done.



"I'm sympathetic to this mindset," says Paul.  "The problem is, the Internet really is that dangerous, and people really do need to pay more attention to the dangers of unpatched or infected computers.  Given that most people can't take the time to care enough about these dangers, their infected computers become a threat to everybody else, thus completing the cycle of dangerousness begetting more dangerousness.  All those within the sound of my voice, please check out the DCWG website and find out if your DNS is okay.  Ask your customers, your friends, and your family to do likewise.  Or use this as an excuse to go visit the people in your life less technical than yourself and show them how to check their DNS."



And so, wrapping up under, he says, "July 9 and Beyond:  On July 9, 2012 the replacement DNS servers operated by ISC will be shut down" - remember he was writing this on March 27.  So they "will be shut down, and any victims who still depend upon these servers will face new risks.  Notice I'm not saying that they will go dark, since that's not entirely clear.  Some of them will go dark; some of them will face long delays on every web page they visit; some might not show any symptoms at all.  The long-term risk I foresee is that some new criminal empire, or more than one, will offer services to again replace ISC's, and they will easily recapture a large part of the DNS Changer victim population.  There are ways to do this that don't leave tracks, so not every criminal who does this will be automatically and immediately detected, arrested, and charged.  I would like to see these computers cleaned up so they don't pose a lasting but latent threat to the rest of us.



"Speaking of lasting, latent threats to the rest of us, I was part of the Conficker cabal recently immortalized by Mark Bowden's book, 'Worm.'  We still don't know the identities of any of the criminals who foisted Conficker on an unready world back in 2008, but we do know that the victim population has not dropped below six million.  So we still collect the sinkhole data about these victims; we still report on it to network operators; and every year we buy another rack of disk drives to hold the next year or so worth of data.  We're out of ideas for how to get people to care that their computers are infected with Conficker.  These victims seem to feel that they have more important things to worry about.  My gut feeling is that they're wrong, but I can't seem to prove it.  My other gut feeling about all this is that we, as a digital society, are doing this all wrong.  Paul Vixie."



LEO:  Hmm.



STEVE:  So there's a lot of things to think about there, Leo.



LEO:  Absolutely.  Absolutely.  I still think they did the wrong thing, but that's...



STEVE:  What's interesting, I was working with Jenny, setting up a new laptop for her.  Hers was just getting old, and I wanted to get her set up with a new one.  And so we were sort of inventorying her existing one.  I wanted to, in setting it up, not reinstall things she didn't use any longer.  And it's funny because we were sitting side by side, and dialogue boxes were popping up which she was - her immediate instinct was to close them.  Say "Okay."  And it was educational for me because I read these things.  I know that there's something that I'm being told, and I wanted to know what it was.  But Jenny is not a computer person.  She just wants to write her novels and screenplays and, as Paul says, get on with her life.  And so this is all just intrusive for her.  And she sees it as something she clicks "Okay" to, in order to just get on with what she's doing.  Which I'm sure she's representative of the majority of PC users.



As Paul writes, somehow we haven't done a good job of this.  Somehow we have - and again, the listeners of this podcast are with you and me, Leo.  But they represent the people, the broader, I mean, this narrower audience, this group who are the influencers of - they're the people whose voice has been reached by Paul and through this podcast.  And they're the tech support for their families and their neighbors and their coworkers.  And doubtless they see this as you and I do, that there's something not right about, unfortunately, about the way this is working.



And I thought these numbers were very sobering, that despite months of DNS being misconfigured, they were never able to get the last third of these systems fixed, no matter how hard they tried.  And here's six million machines infected with Conficker.  And anybody who puts a packet sniffer out on the 'Net is getting pinged by Code Red and Nimda.  They're still out there, scanning the 'Net, trying to infect machines.  And I coined the term, as you know, a decade ago, IBR, Internet Background Radiation.  That's what this stuff is.  It's become part of the ecosystem on the Internet.  And it is sad that we've sort of abused the users who just want to get their work done.



LEO:  You know, I detect a little hint of a kind of common paternalism that you hear from old geeks.



STEVE:  [Laughing] Yeah?



LEO:  And a little bit of blaming the user.  It's their fault.  And I think really he should take more blame for setting up a system that doesn't work and should be putting more effort into fixing it than blaming the user, to be honest.  And there's a lot of old-time geeks who say, well, if we could just get people to - he says something, the most important paragraph to me in here is he says, "If an ISP wants to run a replacement DNS server for the purpose of forcibly breaking these computers in small batches to get their owners to call in and ask for help, that's fine.  But if it's just going to be a new permanent service that the ISP offers to these customers, count me as opposed."



But that's exactly what he did for seven months.  I no longer blame the FBI.  I think it was a little misguided on Paul's part.  But we could debate that.  I think the point that he makes that's interesting, that I hadn't really thought about, is had they just pulled down those servers, there's the risk, and there's the risk now, that some malicious entity would just recreate a server at that address.



STEVE:  Yes, recapture, exactly.  And the other thing he made clear that wasn't obvious to me is that only by permission of a court could they operate servers at those addresses.  And the point about the ISP is that an ISP can control their network.  The ISP's network is not the public Internet.



LEO:  And they can see outbound traffic to that DNS server.



STEVE:  Exactly.  So they could set up some filtering on their routers to route those malicious DNS IP queries to their own DNS servers and provide valid service to their customers.  And also notice that the ISP does know who those people are because they're getting - every DNS query comes from an IP that the ISP controls.  And so, one by one, they could log them and send them email.  They have their email address.  Send them postal mail.  They're probably charging them, so put a big red pink slip...



LEO:  Fix it or else.



STEVE:  ...in their bill.  It's like, okay, call us, please call us.  Your machine may still be infected.  And in any event, it's still misconfigured.



LEO:  Nobody wants to do that because the amount of support that's required to fix it is so expensive that no ISP wants to assume that mantle.  I can promise you.  Look at Comcast, how many millions, tens of millions of users do they have?  They're the biggest ISP in the country.  They start doing that, they're responsible somehow for fixing millions of computers?  Whoo.  Fortunately...



STEVE:  Yeah.  It does creep me out, though, I mean, just the idea that in every ISP would be a DNS server or some filters, like permanently stuck in a router...



LEO:  It's just a redirect.  It's just a redirect.  It's a router saying, hey, if they go to this address, send them here.  It's not a hard thing to do.  The problem I have with doing that is the same problem that Vixie has.  You cannot keep these infected machines online.  You have to do something.  My opinion is the best thing to do would have just been break it right upfront.  So what if there's a howl of protest?  Those people need to know immediately that they're infected so that they can take action.



STEVE:  So the idea would be that they would get a court order to so-called "blackhole" that IP.  That is, they would not offer DNS services, but they would just acquire the IP and just, like, have the machines go dead.  And then the users would say, oh, crap.



LEO:  Something's wrong.



STEVE:  Something's wrong.



LEO:  And then they would - some of them would call their ISP.  Most of them would bring it into the shop or call me on the radio show...



STEVE:  I wonder if...



LEO:  ...and we'd tell them what to do.  The problem is those people for seven months have been running infected machines.  And as you know, the chances that they have more than one infection are high.



STEVE:  Yeah.  I wonder if there are some unappreciated consequences, unappreciated by you and me, of doing that.  See, we only think in terms of...



LEO:  I know.



STEVE:  Like what if their household alarm system is Internet based, or their...



LEO:  But the damage was done when they were infected by DNS Changer.  I think for Vixie, for ISC, or for the FBI to assume responsibility at that point - there's also, and I think this is really interesting, the notion that somebody might hijack that IP address.  Now, I wonder, if you get the court order, and you take the IP address, and you blackhole it, that kind of protects you, doesn't it?  I mean, they do control DNS.



STEVE:  So I don't know what the IP was or who actually owns the IP.  But it must be that it was a foreign IP.  And so what they needed was they needed a court order in order, essentially, to break that part of the Internet, to say we're not going to allow people who are trying to get to that IP, that valid IP owned by somebody else, we're going to filter that.  We're going to block that and keep people from getting there.  And so the judge said, okay, but you can't do that forever.  How long do you need?  And they said six months ought to do it.  And it turns out - or four months, I guess it was initially.  And it's like, oops, that wasn't enough time.



LEO:  So they went eight months.  The interesting thing is, and maybe this proves that their strategy worked, we didn't hear a lot of howls of my Internet's down.



STEVE:  None, none.



LEO:  So maybe that seven months was useful in getting people to fix it.



STEVE:  Or maybe the bad guys jumped in that quickly.



LEO:  Whoo, that's a scary thought.



STEVE:  Yeah.  So...



LEO:  Now, correct me if I'm wrong, but if, I mean, look, doesn't ICANN control the DNS servers?  Can't they say, look, no one will ever have this IP address?



STEVE:  No.  It's that they're blocks of IPs.  And so this is some block of IPs owned by somebody.



[Talking simultaneously]



LEO:  Probably somebody in Estonia.



STEVE:  Yeah, it's that kind of thing.  And so it's like a valid - all over the Internet there are routers that are routing that block of IPs to somewhere.  And so...



LEO:  That's right, you can't block an IP unless you block it on all routers.



STEVE:  Right.  And so, I mean, this was a major event in terms of intercepting a couple specific IPs and saying, nope, we're going to send them over here.



LEO:  No, I can see the puzzle, and I can see the challenge, and I'm sure that people have thought a lot longer and harder than I have about this and decided this was the right thing to do.



STEVE:  Yeah, see, I'm wondering if the trick here, Leo, is that we're not appreciating the depth...



LEO:  Yeah, of consequences, yeah.



STEVE:  Yes, that it's more than just people not being able to log into their Facebook games or something, that taking DNS down for organizations would be, like, a big problem, mission-critical sort of stuff.  On the other hand, you really don't want to be referencing evil DNS servers.



LEO:  No.



STEVE:  That certainly has a set of consequences.



LEO:  Or continue to operate without knowing that you're operating an infected machine.  I think they had a responsibility to let people know that there was something wrong.



STEVE:  Yeah, I'm hoping that dns-ok.us still functions.



LEO:  No, it does not.



STEVE:  Ah.  That's unfortunate.



LEO:  I'm not sure why it does not.  That seems odd.  If you go to dns-ok.us it says, "This site can no longer determine if your system is infected."



STEVE:  Yeah, okay, well, now, the reason is that the way it was working was, as we said when we were talking about Google, is that they know that their server picked up your query, and in this case they're no longer running the servers.



LEO:  Yeah.  Somebody, Scott Mishoe [ph] is suggesting in the chatroom, and this is certainly one of the things that I would have at least investigated, maybe they decided this couldn't be done, is to serve up the Internet in an iframe and all around that frame say "Warning, warning, warning, you have a virus."  The problem is we have trained users to ignore that kind of thing.



STEVE:  Yeah, and that requires content filtering, too.  So that's a step further.



LEO:  They didn't want to get in that deal, did they.



STEVE:  Yeah.  And you can't do that for SSL.  It's impossible to intercept that.  So there would be a lot of limitations for that approach.  Anyone who's interested, DCWG.org is up.  That's the URL that Paul references here as what to do from now on.  And so there is a detect and fix and protect item there.  And so DCWG.org.



LEO:  It's the DNS Changer Working Group, is what that acronym is.



STEVE:  Yes, yes.  And more information there.  And, ooh, there's an interesting word map.  Shadow server has pulled together a word map based on country to illustrate which countries - oop, it just changed.  It's running some Flash...



LEO:  Yeah, but it's a tag cloud of which countries are most infected.  It's kind of interesting.



STEVE:  Yeah.



LEO:  However, and I think this is a symptom of, see, I think that the problem is that these engineers don't really understand users.  For instance, if you click the Detect button, it sends you to dns-ok.us, which can no longer detect.  So they didn't bother to update this page.



STEVE:  Yeah.  Wow, the United States is the biggest tag by far.



LEO:  Yeah, but it was still 70,000 out of 300,000.  It wasn't a majority.  It was a plurality.  If you go to the Fix page, yeah, it's okay.



STEVE:  Wow, it's not very friendly.  They don't have...



LEO:  Yeah.  I think that these guys, we need to - the sad thing is the engineers who understand this do not understand users.  And the users don't understand the engineers.  So there's a real impedance mismatch here.  That's the real problem.



STEVE:  [Laughing] I love that.  That's a great term for it.



LEO:  The tracks just don't meet in the middle.  So I don't know exactly what the solution is.  I would say, if I were Paul Vixie and company, I would take this as a huge wakeup call because they don't want to have to ever do this again.  And they need to figure out what's broken and fix it.



STEVE:  Well, everything's broken.



LEO:  That's the problem, isn't it.  It's an intransigent problem.



STEVE:  Really.



LEO:  Really is tough.



STEVE:  I mean, when my mom is typing "http://," that tells you something, this system was never designed for the applications it is seeing.  We're just sort of limping forward.  And as he says, "We as a digital society are much better at strategies for coping than we are at strategies for remediation."  And it's interesting, while I was also doing the research, I ran across some other comments about IPv6.  And one of the problems it's had is it doesn't really do anything that anyone is really sure they need.  I mean, it doesn't offer, like, tremendously better benefits.  It's like, yeah, well, we should be moving to it.  Okay, but no one's in a big hurry to do that because everything's fine with IPv4.



LEO:  Right.



STEVE:  Whereas, when something comes along like SSH, overnight it replaced all the insecure alternatives to that because everyone said, wow, this is much better.  So a protocol that really - oh, I think this is in regard to SPDY, and it was the guy grumbling about HTTP 2.0 and when are we going to get that and what's it going to do?  He used SSH as an example of a protocol that really did offer benefit; and, wow, it got adopted.  And here, HTTP 1.1 seems to be good enough, and we're not sure where to go from there.



LEO:  Well, I think that's why it comes down to operating system manufacturers making locked-down operating systems so malware has a harder time getting on them.



STEVE:  These are all good, incremental movements, yes, and the SSL Everywhere,  Google switching to HTTPS...



LEO:  Routers that are locked down a little better.



STEVE:  Yes, and options like No Not Track that allow users to just sort of express a preference, which is, I mean, this is all new technology.  This is the way we'll get there is a little bit at a time.  And as things get old enough, we can finally let them go.  I mean, that's always  been Microsoft's strategy is they keep the old stuff alive for a long time.  And we just lost compatibility with 16-bit code.



LEO:  And that's the problem is this stuff is starting to get antiquated, and it's falling apart, and it's going to get worse and worse.  And you can't just pull out, pull the rug.  And I think what really this ISC thing is saying is, look, you can't pull the rug out.  You've got to fix it before you pull the rug out.  And so we wanted the eight months to try to fix things.



STEVE:  I think I may have mentioned that my buddy and yours, Mark Thompson, when he switched to Windows 7, he was stunned to see how much 16-bit code he was still using.



LEO:  Still running, wow.



STEVE:  Because he was just, I mean, it's one of the reasons I'm staying is I'm using Brief, which is a 16-bit...



LEO:  Brief, you're kidding me.  That's DOS program.



STEVE:  Hey, I can wave my BlackBerry in front of the camera, Leo, and you'll see I'm really a dinosaur.



LEO:  Gibson uses DOS.  Steve Gibson does this show every  Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time.  That's 1800 UTC.  Watch live.  The chatroom and I talk back and forth, and it's a good way to kind of be part of the show. But of course we make on-demand versions available always after the fact, both audio and video.  In fact, Steve has an unusual version that only this show has.  Two things, really.  He has a 16Kb audio version for really small downloads.



STEVE:  One quarter the size.



LEO:  And, yeah, and transcriptions, which are great if you like to read along.  He also has a lot of other stuff, including SpinRite, the world's best hard drive  maintenance utility, right there at GRC.com.  You must go there and get it.  You can follow him on the Twitter, @SGgrc.  And we make the larger files, audio and video, available at TWiT.tv/sn for Security Now!.  Or go to iTunes and subscribe.



STEVE:  Next week, Episode 362 will be a Q&A.  So GRC.com/feedback.  Send your thoughts, your questions, your comments, whatever you want.  I will go through the mailbag, and we'll select a bunch and discuss them next week.



LEO:  GRC.com/feedback.  Thanks, Steve.



STEVE:  Thanks, Leo.



LEO:  Have a great week.  We'll see you next time on Security Now!.



STEVE:  Right-o.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#362

DATE:		July 25, 2012

TITLE:		Listener Feedback #148

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-362.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to take a look at the security news of the week, maybe throw in a little sci-fi here and there, and then he's going to answer some great questions from you, the members of the audience.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 362, recorded July 25th, 2012:  Your questions, Steve's answers, #148.



It's time for Security Now!, the show that protects you, your loved ones, their privacy, their security online.  And we couldn't do it without this guy, the Explainer in Chief, Mr. Steven Gibson.  Here, let me just move the painkillers out of the way.



STEVE GIBSON:  I didn't ask you before we began, officially.  You are recording this; right?



LEO:  I am recording this, sir.



STEVE:  Normally I ask before.



LEO:  No, no, no.  You need not ask.  I have trained professionals now who push the buttons, if I'm incapable of doing so.



STEVE:  When was it that you recaptured the feed from Justin?



LEO:  Oh, gosh, yeah.  We haven't done that in a while, though.  I don't know if we've done that since we moved here.  This is now - well, actually, maybe we have.



STEVE:  Speaking of which, it's coming up on a year, isn't it.



LEO:  Yesterday was one year.  And Dick DeBartolo flew out.  We had a little parade, recap, a party, sheet cake.  It was so fun.  It has been one year.  Isn't that amazing?



STEVE:  Wow, yeah.



LEO:  And I'm so happy here.  I'm so happy here.  We really are.



STEVE:  Well, my god, you've built yourself a little kingdom.  It's fantastic.



LEO:  Yeah, and I'm the Napoleon of this little kingdom.  No, it is so great.  And the real joy of this - and it sounds insincere, but I'm deeply sincere - the real joy in this is the people I get to work with, like you.  I get to talk to you every week.  If it weren't for this, I probably wouldn't.



STEVE:  No, because we're both busy people.



LEO:  The people in the studio that I get to, I mean, I just love the team.  And so that's a real blessing, to be able to come to work.  Because I know, I've been in jobs where I had a stomach ache every day of going to work.  And so it's such a joy to come in here.



STEVE:  I had a job once, I was in my mid-20s, I had to put alarm clocks down the hall from the bedroom to the bathroom, just to drag me along.



LEO:  You've worked for yourself, though, for almost your entire life; right?



STEVE:  Ever since that job, yes.



LEO:  You see, unlike me, you're smart.  You learned the lesson.  I had to wait till I was 50 before I figured that part out.  But you learned the lesson early.  And this is, I think, a really important lesson.  And I'm trying to get this into our schools, certainly the high schools...



STEVE:  That everybody else is a moron?



LEO:  No, well, shh, that's the subtext.  But the real lesson is you don't learn to get a job, you learn to make a job.  And not everybody can do this, and certainly I have 25 employees, thank god they're employees.  But if you can, if you can learn to be the person who creates their own job, you will, I think, often be happier.  You may not be more wealthy, but you will be happier.



STEVE:  You can work a lot more and have periods of stress, but at least it's yours.  It may fall, but it's yours.



LEO:  Nothing worse than, in fact, I remember I saw a study years ago of what people are happiest in their jobs.  And it was traffic cops and orchestra conductors were way up there.  And it was because they were calling the shots.  The thing that makes this more stressful than anything else is having somebody else tell you - at least it is for me, and I think this is true in general - what to do.  That's stressful.



STEVE:  Well, and that's why I have a small company, and I'm just a really crappy manager, is I don't want to tell other people what to do.  I don't like looking over people's shoulders and being a manager.  I hired people back in the day and just wanted them to go launch and...



LEO:  Do it.  Go.  Just do it.



STEVE:  Yeah.  And it would work.  It was sort of a parabolic launch.  It would go up and reach its crest, and then it would begin coming back down, and we'd have a crash landing about four or five months later because they just realized, oh, look, if I don't come back from lunch, Steve apparently doesn't notice.



LEO:  Yeah, we have that problem here, too.  But, see, I did a really smart thing.  I hired Lisa.  And she is a good manager.  She knows how to manage teams.  And I let her do that.  So this is the other lesson.  Create your own job.  And then, if you can, hire people to do the parts of it you don't want to do.



STEVE:  And that's what I have.  It's Sue and Greg, famously, handle customer support and all of the books and bookkeeping and finance and stuff.  So I get to do the fun stuff, and they're happy that I give them total freedom with scheduling to do what they need.  So it works.



LEO:  Right, exactly.  That's how TWiT happened, by the way.  I wanted to do the shows, but my dream - and I thought this was pie in the sky - was to do a show, like do this show, and then get up and walk away and have everybody do the stuff I didn't want to do - produce it, edit it, push it, all that other stuff.  And I have it now.  It's so cool.



STEVE:  Yes.  As I said, kingdom.



LEO:  Kingdom.  But I get to do what I'm good at, and I avoid what I'm bad at.  Boy, was I bad at doing taxes.  Boy, was I bad at doing payroll.



STEVE:  I'd be in prison.  The IRS...



LEO:  I would be in prison, too.



STEVE:  Not because I meant to do anything wrong.  I would have been delighted to write them a check.  I just would have kind of forgotten about it.



LEO:  Exactly.  Anyway, we have security news.  And this is a Q&A episode, 148.



STEVE:  It is?  Yes, it is.  No, that wasn't a question.



LEO:  Not how many questions.  This is the 148th question-and-answer episode.



STEVE:  Yes, and otherwise we would never finish this podcast.



LEO:  Only 10 questions.



STEVE:  Actually, we haven't started it yet, so perhaps it's fair that we wouldn't finish it.  We had a bizarre event since I last spoke to you, which was probably the single most tweeted observation from the people who follow me and wanted to make sure that I knew about the news of unbreakable crypto which allows you to store a 30-character password in your brain subconsciously so that no one can torture it out of you.



LEO:  What?  So, like, you don't even know it?



STEVE:  You don't know it.  Now, the bad news is it doesn't do that.



LEO:  Oh.



STEVE:  It's not 30 characters.  It's a little better than 30 bits.  So unfortunately the headline - and this was in ExtremeTech.  And for what it's worth, I'm seeing, whatever ExtremeTech talks about, I get tweeted.  So we have a huge following of ExtremeTech watchers.



LEO:  It's a good site.  It was started by Bill Machrone. You remember Bill; right?



STEVE:  Oh, of course I know Bill.  Yeah, yeah.



LEO:  He was the former editor-in-chief of PC Magazine for years.  I don't know who owns ExtremeTech these days, but his idea was let's - PC Magazine was getting its lunch handed to it by sites like Tom's Hardware and AnandTech.



STEVE:  Right.



LEO:  He said, well, we should do an enthusiasts site.  And that's the result is ExtremeTech.  So this is the article here.  But they got it wrong, unfortunately.



STEVE:  Well, yeah.  The headline is wrong.  But I want to talk about it because what it does, I mean, it is serious neuroscience.  It's being presented at this upcoming USENIX conference.  And it really does work.  So they were a little wrong in this 30-character password storage.  It doesn't do that.  It actually stores something with an entropy of about 38 bits, which is more like 6.5 characters.  But...



LEO:  That's not very strong, is it.



STEVE:  Well, and it's authentication only.  Anyway, we'll get into it.  I imagine you've got a sponsor you want to talk about, and then we'll get into our show, and we'll do that, and a bunch of questions.



LEO:  You are so good.  And what a great tease.  Steve Gibson, the Explainer in Chief.  And we're going to show you how you can store this in your subconscious; right?



STEVE:  Yes, actually, there is an online version of this that's a little Flash app that people can play with.  I would imagine...



LEO:  It would take me an hour to do this, so I'm not going to do it on the air.  But maybe tonight.



STEVE:  Yeah.  I would imagine that people want to understand what it's about.  That's what I'm going to explain.  And then they can go look at it, if they want to.  It's been referred to as sort of like Guitar Hero and the way that works.



LEO:  I play the game a little bit.  I'll play it, yeah.



STEVE:  And we'll do our user-directed episode of Security Now! this week.



LEO:  Yay.  Steve Gibson, time to plant something subliminal in my mind.



STEVE:  Okay.  So this is very cool and sort of tangentially security related.  The idea is that neuroscientists have long known that it's possible to teach us things, sort of like muscle memory, in the way that, like when you're learning to play tennis, you have to be very conscious about everything you do, where your feet are, how you move, where your balance is, how you're gripping your racket.  It's very conscious.  And if you're serious about the game, you'll get a pro to work with you and look at you and sort of get you started down the right path.  But what happens is that, after some length of time, that becomes unconscious, or subconscious, that is, you're directing yourself at a higher level, and it's often called muscle memory, where it's...



LEO:  Hey, there's no muscle in my brain.



STEVE:  It's not actually your muscles that are remembering.  But those sort of subroutines are established, and then you're calling them, rather than running them by hand, to use a computer analogy.  So this was "Neuroscience Meets Cryptography."  And the title of the paper is a little worrisome.  It's, I'm not kidding you, "Neuroscience Meets Cryptography: Designing Crypto Primitives Secure Against Rubber Hose Attacks."



LEO:  Oh, dear.



STEVE:  So and of course a "rubber hose attack" is the slang for hitting somebody.



LEO:  Torture, yeah.



STEVE:  Exactly, hitting somebody over the head or somewhere to get them to tell you what secrets they have.  So what these guys designed is a means for training people on a sequence of events such that they're unaware of the sequence, but on a subconscious level they become better at following one sequence than another.  And so this, for example, you don't have the ability to simply sit down and type out a password that you're not consciously aware of.  So the way the system would work is you would first authenticate yourself normally.  You would use a username and password, things that you know, maybe even something that you have.  But then this next level of authentication would - it would know who you're claiming to be, and it would know the sequence that you had previously been trained on.



So this is all kind of Jason Bourne sort of stuff.  And the idea is it would give you a sequence of events that you respond to, knowing what you're supposed to be better at, that is, that you have been previously trained to be better at, than somebody trying to impersonate you.  And what they found was it works.  So what's online, and our listeners can play with it, it's BrainAuth.com/training.html.  And if you go there, you skip around a couple of initial screens.  If you just go to BrainAuth.com, there's this strange thing about how you're going to get paid $5.



LEO:  Oh, well, there, now you've convinced me.



STEVE:  But there's a disclaimer saying, oh, whoa, we're not doing that anymore, so ignore that.  But it's like, okay.  Or just go to /training.



LEO:  Oh, whoa, whoa, whoa, it's going so fast, I can't keep up.  It's like Guitar Hero.



STEVE:  What they were doing was, initially, they were soliciting people to train up on these sequences for their research, and when they finished it, they would get a coupon that was redeemable for $5.  And so they were offering five bucks, probably for some students at Northwestern.  This is a guy at Stanford, some people at Northwestern, and SRI, the Stanford Research Institute, put this whole thing together.  So what you'll see there is six columns...



LEO:  I'm terrible at this, as I am at Guitar Hero.



STEVE:  Yeah, and the circles drop, and the columns are ADF and JKL, which are two groups of three keys on the keyboard.  And so the idea is it's choosing what drops in what sequence, and you're supposed to be pressing the keys at the right time to get these things to drop into the holes that are down at the bottom.  So with six symbols, what they were trying to do is they're trying to build associations, temporal associations between pairs and triplets and quadruplets.



LEO:  It's too hard.  I can't do it.  I can't do it.



STEVE:  So where this 30-character thing came from is actually what's known as the "Euler walk."  If you take six things, and you draw interconnecting, bidirectional arrows between each one and every other one in some sort of big star formation, then the Euler walk traverses each path through that exactly once.  And so that does result in a 30-object sequence.  And so what happens is this thing, when you're using it, it arbitrarily chooses an Euler walk through this six-character alphabet, essentially.



LEO:  "Euler" is E-u-l-e-r, like the Euler Constant?



STEVE:  Exactly.



LEO:  Okay.  He's a famous mathematician.



STEVE:  Way old and long dead.  But he...



LEO:  He would hate this game.



[Laughter]



LEO:  [Geezer voice] What are you doing?



STEVE:  They explored all these things a long time ago.  So anyway, so what happens is, without you being aware - and this also throws in non-training sequence events, so you're not just training up on exactly that Euler walk, it sort of throws - it deliberately throws in other things.  And the point is you don't know, thus, what parts of what is happening on the screen is part of the secret sequence you're being trained and what isn't.  So you're never given it.  You're never explicitly told, here is your 30-character sequence.  Instead you just play this game several times for 30 to 45 minutes, they say in their paper, and they run through it a number of times.  Then they wait a week.  They wait one week, and they test you again, and two weeks and test you again.  And what they found was there's some loss of retention after the first week, but then it sort of flattens out, and you don't lose nearly as much in the second week.  And it's sticky enough that they're claiming it could be used for authentication.  And so again...



LEO:  But how, I mean, I don't know it consciously, the keystrokes, but somehow I can trigger it?



STEVE:  Well, no.  The idea would be that you're actually getting better.  Even though you're not thinking, Leo, that you're very good at that right now...



LEO:  I'm terrible at it, yeah.



STEVE:  You did spend...



LEO:  I bet a pianist would be very good at it.



STEVE:  If you did spend an hour, there would be things it would be deliberately doing, like SKD.



LEO:  No, I'm recognizing some patterns, actually.  I do see some things repeat, yeah.



STEVE:  Right.  And so you wouldn't be able to speak it, necessarily, but your body and like those lower levels of your autonomic stuff...



LEO:  Autonomic nervous system.



STEVE:  Yes, it would be sort of acquiring a bias.  And that's really what this is.



LEO:  It is.  I have a bias towards doing it right, that's right, yeah.



STEVE:  Yeah, it's giving you a bias towards things that it has deliberately caused you to expect.  And so at some time in the future it could test you for that bias, and you would have a particular bias.



LEO:  Oh, I see.  So it would give you the same game again, basically.



STEVE:  Yes, exactly.  And that's why it couldn't recognize you from a crowd.  But if you're claiming to be you, then it could test...



LEO:  I should be better at this than somebody off the street.



STEVE:  Exactly.



LEO:  In this particular sequence that I get again and again.



STEVE:  Yes.  You should be better at the one particular pattern that you had been previously exposed to.



LEO:  Right.



STEVE:  Thus the Jason Bourne, sort of.



LEO:  Yeah.  He doesn't know he's Jason Bourne.  But he is.



STEVE:  He triggers, yeah.



LEO:  This is going to drive me insane, and I can't seem to stop.



STEVE:  So SISL, Serial Interception Sequence Learning.  Anyway, that's what that is.  Many people sent the link from ExtremeTech to me, and so I wanted to thank them and acknowledge it and explain.  And unfortunately it's not storing a 30-character password in your brain, but it's creating a something unique in you that nobody else would have, that could at a later date be checked for.



LEO:  That makes perfect sense.  That makes perfect sense.  And the NSA couldn't suddenly come to you and say, okay, what's your sequence, because you have no idea.



STEVE:  Exactly.



LEO:  It makes sense.  And it is muscle memory because I would guess it's probably as much muscle as it is brain.  I don't know.



STEVE:  I think at some point after about 30 minutes you probably zone out, and you just...



LEO:  You do, yeah.



STEVE:  You just sort of start doing this...



LEO:  Exactly.



STEVE:  ...and you're thinking about other things while you're continuing to try to press the right keys.  And it probably actually does sink into your subconscious.  There's a 17-page PDF, if anyone really wants to go into this.  If you just put in, probably "rubber hose crypto"...



LEO:  That's pretty much a unique phrase.



STEVE:  Yeah, I think that Google will find it for you.  And it's interesting.  You pretty much know all you're going to find out from having just listened to this from me.  But they said:  "A cross-disciplinary team of U.S. neuroscientists and cryptographers have developed a password/passkey system that removes the weakest link in any security system: the human user.  It's ingenious.  The system still requires that you enter a password, but at no point do you actually remember the password."  Now, here again I'm quoting from ExtremeTech, where they don't quite understand...



LEO:  They thought because it was 30 characters that it was somehow 30 characters.



STEVE:  Yes.  And you're not entering a password.  You are demonstrating a bias, sort of a statistical bias which only you have.  So you first have to tell it who you are.  Then it's able to challenge that assertion with sort of an additional step of authentication.  So anyway, it's very cool.



LEO:  Yeah.  If you were really Leo Laporte, you would perform 10 percent, it's probably a small amount, 10 percent better at this than...



STEVE:  Yeah, they've got charts and graphs.  And it's enough better that it's useful.  You could imagine some really over-the-top, super-secret...



LEO:  It is about 10 percent.  This is interesting.  8.6 percent difference.



STEVE:  Yes.



LEO:  It's that close.  It's very interesting.  And they used Mechanical Turk to do this.  Did you know that?



STEVE:  Yeah, on Amazon.



LEO:  On Amazon.  That's really interesting.  What a good way to get research subjects.  Wow, I love it.



STEVE:  So a little sci-fi update.



LEO:  By the way, in their bibliography, among other things, this is where the rubber hose comes from, an article on CNET.  "Turkish police may have beaten encryption key out of TJ Maxx suspect."  So maybe they named it appropriately.



STEVE:  Yeah, I'm afraid maybe they did.



LEO:  Wow.



STEVE:  I wanted to give our listeners a bit of a sci-fi update.  I did read those last two, the most recent two "Lost Fleet:  Beyond the Frontier" novels.  I mentioned after having only read - I think I was maybe two-thirds through the first one, which was "Dreadnaught," that it was really sort of disappointing me.  I wanted to mention, just for those who had read the first six, that seven and eight - seven is a little slow, but eight really picks it up.  And I'm not sure why I'm not as enthusiastic about it as I was the initial ones.  I don't want to lead anyone one. But it was good.  And so if you're looking for something to read, and you like the Lost Fleet series, seven and eight are useful.  And "Invincible," which is the last one, was better.  And I am now in the process of "Kill Decision," which is...



LEO:  Ooh, how do you like that, yeah.



STEVE:  Yeah, I'm just starting.  I'm back on my stair climber again.  I'm working myself back into shape.  I really had some substantial keto adaption period.  I was having to drink a lot of bouillon in order to keep from just dehydrating and cramping.



LEO:  You were feeling weak.



STEVE:  And I'm past that phase now.  I've weaned myself from the bouillon, and I'm fine.  So I thought, okay, now I'm going to start getting back into shape.  While this was going on I didn't want to really tweak myself too hard with my workout, so I backed off on that.  But so Daniel Suarez is - so far it's really interesting.  I just like his writing.  It's good stuff.  It is not a trilogy going from the first two books.



LEO:  It's unrelated.



STEVE:  Yeah, it's unrelated.  Although, again, it's good cyber stuff.  It's good tech.  It's good military.  So it's a nice read.  I am enjoying it.  And I did want to mention that Jenny and I saw "The Amazing Spider-Man" the other day.  And it's, I thought, the best 3D that I've seen so far.  I was more impressed with it, for some reason, even than "Avatar" and "Prometheus."  I saw both in 3D, and I was not that blown away by them.  But "The Amazing Spider-Man" I liked.  I've liked all the Spider-Man movies, Tobey's movies.  And this one was good, too.  So if anyone is curious.



And I did get a nice note from a John Newcomb, who's a listener of ours.  He said, "Dear Steve, just wanted to tell you how much I appreciate all the great info I get from your podcast with Leo Laporte.  You guys are a great team.  I recently bought a copy of SpinRite that I've added to my bag of tricks.  I'm a computer tech and work for a company who services the dental industry.  SpinRite has already saved me a lot of time.  I was in an office the other day, working on a machine that would not fully boot Windows.  I ran SpinRite, and it recovered several bad sectors, which then allowed me to image the drive and install a new one.  Thank you for making my job so much easier.  You software works so well.  In using it and observing all the little details, I think it's clear how much care you put into its design and development.  Sincerely, John Newcomb."  So thank you, John.  I appreciate the feedback and letting our listeners know.



LEO:  Well done.  You know, we don't have another ad, so let's get right to the questions.  Are you ready, sir?



STEVE:  I be ready.



LEO:  I be ready.  But I'm not.  So wait a minute, now, hold on.



STEVE:  Oh, I did want to mention, while you're getting it ready, Leo, that many people, many of our listeners have had tremendous physical benefits from experimenting with very low carb stuff.  I had a bunch of tweets that I was considering sharing, but I thought, oh, I don't want to clutter up Security Now! with that.  But remember that SGvlc is my Twitter feed.  If anyone is interested to hear real listeners talk about many 10s, 20s, 30s, 50s, pounds of weight that they've lost, blood pressure normal for the first time in their adult life and all kinds of other good stuff, do a search on SGvlc and take a look at those.



LEO:  Yeah, I kind of surprised my doctor today.  He said, "Wow, you're looking good."  So thank you very much.



STEVE:  You are, actually.  I've noticed, too.



LEO:  I feel good.  Question No. 1 for Mr. Gibson from Brian Finn in New Hampshire:  Hi, Steve.  After thinking about all the precautions you've discussed in the past, and the best way to protect ourselves, it occurs to me that much protection is going to be wiped out by the switch to apps.  Which is really ongoing, isn't it, not only on mobile, but also on the desktop.



Using the iPad negates LastPass.  It's a nuisance, but doable in Safari.  However, it's impossible to use LastPass in an app.  While it may be possible to craft clever passwords, I believe the inevitable result will be to go back to our old habits, using the same password everywhere.  And I have to say, I think he's probably right.  Maybe I'm paranoid, but this looks like the next big thing, apps.  What do you and Leo think?



STEVE:  Yeah.  And, I mean, I'm having the same experience.  It's fabulous in a browser mode, where you're logging into sites.  I am so happy having LastPass there.  But my iPad, that is probably the app environment where I spend most of my time when I'm off at Starbucks in the morning reading and poking around and doing research.  You can do sort of - and I tried it for a while.  Actually it was on the iPad 2 where I used some JavaScript snippets in order to invoke LastPass and try to - but it was, like, so awkward that I didn't even bother doing it when I switched to the iPad 3.  It's like, okay, I just, you know.



And they have been moving, LastPass has been moving their own browser forward.  The LastPass Tab, it's called, which is a nice iPad browser.  So of course it brings LastPass to a web environment.  But as you said, or as Brian said, we're generally more app-centric.  One of the things that I find annoying, frankly, because I've already got so many apps, is that when I'm surfing with the iPad, now the sites I go to are all pumping their own app.  It's like, oh, get the Slate app.  Oh, get the...



LEO:  I know, I hate that.  I hate that.



STEVE:  I do, too.  It's like, I don't want an app for a site.



LEO:  No.  I'm here in my browser.  Give me the page.



STEVE:  Yes.  And so sometimes you close it, and it comes back, or you change pages and it comes back again.



LEO:  Oh, that's so frustrating.



STEVE:  It's like, oh, please.  It's funny, too, because there was a comment in the mailbag about somebody - actually it was Jared, who sends me a lot of stuff - asking about spoofing user agent.  And I was thinking, boy, I'd like to be spoofing my user agent because that's...



LEO:  I'll spoof your user agent.  What does that mean, "spoofing your user agent"?



STEVE:  Well, the user agent is part of the request header that browsers send out to tell the server what it is.  It used to be in the old days they would disclose the screen resolution.  Now they'll say I'm iOS and Safari on an iPad, blah blah blah.  And so that's how these sites know that you're in mobile mode.  And in fact, one of the things I find annoying is I'm unable to authenticate with PayPal when I'm mobile and I want to get something through eBay on PayPal because the mobile version of PayPal gets all tangled up because I've got multiple one-time password things.



I still have the football from the old days, and I've got the VIP, the VeriSign Identity Protection, running on my BlackBerry.  So I've got mobile six-digit changing, time-base changing code.  But that requires an extra step in authenticating because you've got to tell it which one of the devices you want to authenticate with, and the mobile version doesn't understand that.  And once, for a while, they had a button to go to the non-mobile site.  It's like, oh, thank you.  That's gone now.  They upgraded, and they took it away.  So I'd like to be able to tell them, no, no, this is not - I'm not on an iPad.  I'm on IE on Windows.  And that's information that comes through the user agent, which is where the browser declares what it is.  So it would be nice to be able to spoof that.  And in fact, I think LastPass, the LastPass Tab browser does offer you that option.



LEO:  Oh, that's nice.  That's a separate browser for LastPass Pro users.  



STEVE:  Yes, exactly.  And worth taking a look at if you're really a committed LastPass person and you're an iPad user because it does give you access to LastPass, your LastPass database, synched through the cloud, secure as we know it is, with websites.  But I still like - I just sort of like to use Safari.  It's there.



LEO:  Well, Apple kind of pushes you that way because you can't change the default browser.  So when you click a link, you're going to get Safari.  You know, Chrome has, and this is one of the nice reasons to download Chrome on iOS, it has a menu item, "Request Desktop Version."  So you can, in Chrome, on iPad, and I think on iPhone, too, say give me the desktop.  I don't want the mobile version, give me the desktop.



STEVE:  Wait.  Download Chrome on your iPad as opposed to Safari?



LEO:  It's available for the iPad.



STEVE:  Oh, Chrome, Chrome, Chrome.



LEO:  Google Chrome, yeah.



STEVE:  Ahh.



LEO:  So that is a nice feature of Google Chrome.



STEVE:  But Brian's right.  I mean, as we are being pushed away from a web-centric mode in our mobile devices...



LEO:  Well, we've got to push back.  We can't let people - this is annoying.



STEVE:  Yeah.



LEO:  For other reasons.  I think a free and open web is important.



STEVE:  Yeah.  And I like the idea, the model that Google has initiated and other people are following, of the web browser being your portal.  There's a lot about that that works.



LEO:  Yup, that's how it should be.  But you can't control the advertising as well.  That's the issue, of course.  Jay Atkinson in Sydney, Australia, was left with a "coddling" question:  Gentlemen, I have a problem.  I find the information you provide intensely interesting - yes, that is a problem, but there's a cure.  No, I'm sorry.  I'm being facetious - and I often find myself wanting to talk through the content of the netcast to confirm that I understood what's been discussed.  That's a good idea.  Get a Security Now! buddy, listen together, and then afterwards say, okay, this is what I understood.  And then he could say, well, this is what I understood.



My problem is following along with 357 I realized the very limited number of friends I have with whom I could discuss the netcast without them glazing over and sending them into an information-induced coma, so I'm very cautious to control my enthusiasm and choose my audience carefully when discussing anything Security Now! related.  You just need better friends, Jay.  Any mention of "Uncle Stevie Gibson" or Leo in my household already has my six year old rolling her eyes.  She'll come around.  But I know that this is the safe forum for posing such questions.  So - I love this, Steve.  I don't care what his question is.  This is great.



Can you provide an explanation as to how they came up with the hard limits of "5ms in 100ms" in relation to the buffer coddling algorithm - oh, I'm glad he didn't ask me that - as on the face of it, it seems an arbitrary timing.  Do you see any reason these timings would need to be reviewed in future?  Thanks, gents.  Leo, hope to catch up when you are down this way later in the year.  I will, Jay, be in Sydney on November 7th, and I think Brisbane - is it Brisbane? - I think Brisbane on November 9th.  Jay Atkinson (Magooligum), Sydney, Australia.  Your response.



STEVE:  Yeah.  So, great question.  And I know, Jay, many of our listeners can sympathize.  Relative to the 5ms in 100ms, we'll remember that what that was in the coddling algorithm was their criteria for whether or not to start dropping packets at an accelerated pace.  If sometime during 100ms the delay through the buffer ever got down to 5ms, then the algorithm was happy with leaving things alone.  But if at no time during 100ms was the delay through the buffer ever at or lower than 5ms, then the algorithm would worry that it needed to start sending some messages back to the protocols that were sending data through the buffer, that they needed to back themselves off a little bit.  So this allowed bursts to occur, but not long-term overuse of the buffer.  Those timings were arrived at empirically just through lots of modeling and testing.



But the 5ms in 100 actually comes from our real-world experience.  It is an amount of time which, when multiplied by the number of hops packets need to traverse, still makes the Internet feel responsive.  So the idea is we want both to be able to be downloading blocks of data, big video streams and things, where we really don't need interactivity.  We don't need real-time round-trip interactivity.  But we also want to be able to be playing games with shared servers, and we want to be able to click on a link and have the page immediately start loading and populating.



So we have differing priorities.  But for us humans, if we take 5ms times a number of hops, we'll keep the sense that the Internet is working, that it's fast enough, that something hasn't broken.  And that's where that came from is just, I mean, it's we as humans, and what do we ask?  If it were all just big, non-interactive, huge streams of data moving autonomously, no one would care if buffers got deep and fat.  That wouldn't be a problem.  But we want the Internet to still feel reactive to us.  And so that's the key is to keep those buffers small so that our intentions don't take long to get somewhere and the responses to get back.



LEO:  So his question actually is legit because that might change when bandwidth situations change and so forth.  Yes or no?



STEVE:  Well, no.  And that's what's so cool about this, is this is bandwidth independent.  This is based on time.  So as bandwidth increased, then the buffers could be deeper, and they would automatically deepen, but the time factor would stay the same.  And that's the genius of this is that it's based, not on bandwidth, and not on particular buffer packet size or length, but just on time.  And time, the interactivity of our experience, is really what we're trying to preserve, and this does that.



LEO:  Really interesting stuff.  I love it when big minds solve problems and really think about this stuff.



STEVE:  And this thing is decades old, this problem.  I mean, this is...



LEO:  It's about time we fixed it.



STEVE:  This has confounded the best minds for quite a while.  And then these guys finally said, okay, we really need to sit down and figure this out.  And they did.



LEO:  Two questions in a row here, so hang on.  First from Carlos Alfaro in Rockaway Beach, New York, about iOS and Android security:  Steve and Leo, love the show, been listening since Episode 1, own SpinRite, et cetera, et cetera.  I know that both the iPhone and Android have their own implementation of sandboxing and memory protection to prevent applications from getting to the information they shouldn't have access to.  But looking over the security - uh-oh.  Let me make this a little smaller.



STEVE:  We've got a page boundary.



LEO:  Yeah.  Looking over the security - ah, here it is.  It does this to me every time - model - and then it reformats.  Okay, let's see.  Let's view this as a single continuous scroll.  Thank you.  Just have to tell preview how to do it.



Looking over the security model for both platforms, I wonder whether they are really secure.  An example of my concern would be using a banking application to access a bank or credit card institution.  How would I know that another application is not getting my user name and password?  If you read the permissions some applications ask for, it's out of control.  Some apps "require" permission to read the state of the phone and see the number you're dialing.  They can see your contact list.  This is more so, I would say, on - you get these granular permissions on Android, not so much on iOS.  We don't really know what they're asking for on iOS.



They can see your contact list, maybe even copy it.  They can record sound, even phone conversations.  A scary one is they can turn on the camera and take both pictures and video even when you're sleeping.  Which used to be the case with IMDB on Android.  The Internet Movie Database asked for permission so the application could turn on the camera and take pictures.  They use the GPS to determine locations, coarse or fine setting, and others.  Now, I know those permissions are not needed by some of the apps requesting them, and I know it does not mean that just because they have permission, they will use those permissions.  I guess they look at all that information to monetize it?  It's more complicated.  I can explain why they have to ask for those permissions.



So finally, my question is, can I trust either Android or iOS to allow me secure access to my bank and other secure sources of information?  Because I am not sure I have never used my Android phone for that purpose - I carry a USB stick with Ubuntu Linux all the time just for that - I've removed all applications that ask for permissions other that what I think is necessary for them to fulfill the purpose for which I installed them.  Thanks again for looking at my question, and I apologize for such a long email.  Carlos Alfaro, Rockaway Beach, New York.



And Brian Tannahill of Overland Park, Kansas, same kind of thing:  I heard the news item a couple of weeks ago about Microsoft telling us to abandon and disable Desktop Gadgets and the Sidebar because they're insecure.  Five years later.  I'm amazed at how everything is riddled with security vulnerabilities, and I want to know, is it feasible to produce a reasonably secure operating system?  Or is this nonsense going to continue forever?  That's Brian Tannahill.



STEVE:  Okay.  So, yeah.  My sense is, and I'm sure you're seeing this and probably feel it, and our listeners I'm sure do, too, we're still as an industry trying to work these things out.  You were just talking about, I think it's before we began, the new Gatekeeper in iOS X or Mac OS X...



LEO:  Mountain Lion, yeah.



STEVE:  ...Mountain Lion, and how it's causing some problems for users who aren't used to it because it's additional protections that have been built in.  The mobile platform is in general somewhat frightening.  We've covered throughout the years problems with apps misbehaving, with permissions not being handled correctly, so on.  So there's the problem of the platform itself not properly restricting controls, with mistakes being made there.  Then there's, as our first questioner asked, there's the problem of apps overly broad asking for permission.



My pet peeve that we've discussed a couple times is the way the authentication platform OAuth, where for example you, quote, "Sign in using your Facebook credentials," where you bounce over to another site and then come back, I'm annoyed that sometimes apps, all you want to do is allow them - or, for example, Twitter is another example where you want to sign in using your Twitter account.  They'll say, oh, well, the site you're coming from, asking for authentication on Twitter, wants to be able to post to your Twitter stream.  It's like, no.  That's not what I want to give it permission for.  But you have no control.  You can't say, yes, authenticate me, but don't allow it to do those things.  It's not an option on the screen.



So I do think it's going to take, as you said, Leo, it's going to take user pushback to some degree.  It's going to take applications.  The other thing that I see is sort of just an egocentricity on the part of developers who all feel that their app is God's gift to the platform, and their users are going to want to give it all these permissions so that it can do all these amazing things.  There was a story the other day about how Google, I think it was a Google R&D project, would be looking out of your camera phone to sort of see where you were and what was doing on, and it would be able to recognize if you were at the beach and start feeding you beach ads.  And, I mean, it would, like, know if there were baby strollers around and then give you ads relative to those.  And it's just - some of these things get a little bit creepy feeling.



LEO:  Yeah.  And these guys have got to be aware of this.  And I agree, more granularity.  Part of the reason that apps sometimes ask for overly broad permissions is because that's how it's set up by the companies doing the APIs is that...



STEVE:  Right, those are the only things that are given.



LEO:  ...that's your choice.



STEVE:  Yes.



LEO:  Right.  So one thing would be for Google and Apple to have more granular APIs where they could say, okay, you could do this.  If you want to do this, ask for this.  You don't have to ask for all of that and so forth.



STEVE:  And I guess then, of course, the back pressure on that, because arguably at some level, even if everything was done right, if everything was bug free, if there were no problems in the platform, if there were no malicious applications that were going to be abusing this, then you've still got the issue of users being annoyed by being asked anything.  Some users are just like, don't ask me anything, just do, just go.  Whereas there are a lot...



LEO:  They're going to have to get over that.



STEVE:  Yes.



LEO:  Sorry.  You can't have both.  You can't have apps that don't bug users and have privacy and security.  You've got to have one or the other.  And I think there's more of us who care about privacy and security than people who say, oh, just do it.



STEVE:  And then the other thing you would like is that, instead of an app saying you must agree to all these things or we won't work, you'd like - it'd be nice if the apps would say, here's what we want, and here's the features that are associated with those needs, and you can turn off the ones you don't want to provide and still use everything else.



LEO:  Right.  And I think that Android's moving in that direction.  I think Google has made some noise saying, yeah, we want to give, not only more granularity, but give people the chance to turn stuff down and just the app just can't do that particular thing.  But it doesn't mean you don't get the app.  You just get a more limited app.



STEVE:  Well, I have to say that I am really impressed with the $200 Nexus 7 little tablet.  I mean, it's a beautiful tablet.  I was unimpressed with the Fire, but this is the first Android tablet that I thought, wow, this thing, I mean, it is nice.  And I do like the idea, much as I am an iOS and iPad fanboy - I mean, I acknowledge it, I love what Apple has done.  But we know from having seen so much history here that Apple needs some competition.  And so I love the idea that Google with the Android platform could be establishing some standards of behavior that Apple, even though Apple has a reputation for ignoring everybody else, if there is push, then Apple will respond.  So it would be good to...



LEO:  Yeah, well, I think they are.  I think the rumors are strong they're going to do a tablet of roughly this size.



STEVE:  Yeah, although I'm not a 16x9 person.  I really like 4x3.  I just don't think...



LEO:  Well, that's what Apple's going to do.  You're in luck.



STEVE:  I know.  That's why I bring it up is it's 1024x768 in a 7" form factor.



LEO:  We should say this is all rumor and speculation.



STEVE:  Yes.



LEO:  Apple has not said anything that it's going to do.  I don't mind 16x9 because it's a little thinner and taller, right, so it can slip into pockets and so forth.



STEVE:  Yeah, true.  And it is more oriented toward media.  And my bias is more toward reading.



LEO:  Yeah.  Well, but this is good for a book, too, isn't it?  It's very much like the Kindle.



STEVE:  Pages, yeah, well, no, no, the Kindle is much more square.



LEO:  Is it?



STEVE:  The Fire is also 16x9, and it's like reading in a long column.



LEO:  Ah.



STEVE:  That doesn't work as well for me.



LEO:  Really.  Because this seems like roughly the page of a paperback would be.  Maybe it's too tall.



STEVE:  Too tall.



LEO:  Too tall for you, huh?



STEVE:  Yeah, well, compared to - 4x3 I think is a nice compromise because then you can still do media, you just lose some pixels on the top and bottom.



LEO:  Yeah.  I don't know.  I think this is pretty doable.  I think one thing that all of these have over traditional books is you can change the font size to make it just the right comfort level for you.



STEVE:  Oh, I'm an eBook reader.  You were talking about my Palm Pilots that are in the refrigerator before we began recording.



LEO:  You're never going to use those.



STEVE:  I was reading books on those.



LEO:  But isn't this better than a Palm Pilot?  Come on.



STEVE:  Oh, yeah.  Oh, yeah.



LEO:  I have to say I do believe that that transition is happening now.  For a long time I thought, oh, no, paper books, my generation will never give them up.  My generation is giving them up.  I see eReaders everywhere now, everywhere I go.



STEVE:  Yup.



LEO:  People love the convenience.  They love the lightweight ability to carry to dozens of books.  Magazines, too, I think that that's turned out - I don't read magazines.  But for people who do, that's turned out to be a big part of this platform is reading eMagazines.



STEVE:  Oh, yes.  Avoiding that throwaway paper makes so much sense.



LEO:  Oh, I love that, yeah.



STEVE:  So much sense.



LEO:  I'm so guilty, I'm a guilty New Yorker subscriber.  I just want to read it.  I don't need the paper.  I don't need to make a coffee table item.



STEVE:  And I think there are people also who, like myself, we enjoy - I like holding the thing.  I like the technology.  I mean, I was jonesing for these things when Captain Kirk and Spock had them, and Uhura would bring the tablet over, and Kirk would sign off on the commissary or whatever it was.



LEO:  They hadn't figured out that styluses are dead.  Oh, yes, Uhura, let me just approve that.  There we go.



STEVE:  He was always signing something.



LEO:  He was.  He was always signing a tablet.  Brandon Hamilton, Rockford, Illinois writes:  I'm worried about password security if the length is known.  Oh, interesting.  When it comes to brute-forcing a password, we know the longer the password, the longer it takes to crack it.  But what happens if somebody knows the password is X number of characters long?  For example, somebody wants to hack an account on a site that has a password requirement of at least eight characters.  They know the password is at least eight characters long, so they don't bother brute-forcing five, six, seven-character passwords, reducing the amount of time needed to crack it.



The same holds true, for instance, if a person or entity learned a TrueCrypt password was 30 characters long.  They wouldn't bother forcing all the possibilities from one to 29.  Wouldn't that significantly reduce the time needed to brute-force a password?  But how would one go about calculating this to determine if a password is still safe from centuries of brute-forcing, or if it would now be cracked in a few years?  Thanks for the time you two put into producing a great show.  I put no time into it.  It's all Steve.  What's the answer, Steve?



STEVE:  Ah, but you show up every week.



LEO:  I show up roughly every week at 11:00.



STEVE:  So there's no mystery to this.  And, in fact, one of the things that I appreciate is when I see applications and websites that deliberately hide the true length of your password.  Sometimes they'll put up just a bunch of dots to sort of represent the fact that you need to enter your password, rather than leaving the field empty.  But they deliberately don't even show the length because it is understood sort of implicitly that, oh, if you knew how long it was, that would give you a leg up on cracking it.



I immediately thought, when I was reading this, of the Password Haystacks page because it's all about the size of the dictionary and the length of the password.  And what I did when calculating the length of time required to crack a password, and from that or before that the total number of combinations, is I did the math of the number of combinations with a single character, plus the number of combinations with two characters, plus the number of combinations with three characters and so on.  So I did the sum of all the numbers of possible passwords of all shorter size, up to and including the one that the user entered.  And because the theorem or the thesis that I was working on was that a true brute-forcer would start with A and then try B and then C, run through that and then go AA, AB, AC, AD and so forth, in order to go all the way up.



But Brandon's right.  If you knew that a site said passwords must be 12 characters long minimum, then you would - no brute-forcer would try passwords of one through 11 characters.  They would just start at 12.



LEO:  The real question is how much time does that save really?  Compared to what solving that 30-character password's going to take?



STEVE:  Right.  And it actually turns out not to save much time because every character you add multiplies the length of time by the size of the character set, which is typically like 96, so it's 96 times 96 times 96.  And so even if you know the minimum, you are still having to go from there up to whatever their maximum is.  And Brandon, if you're curious, you can use the Haystacks page to easily see that.  So, for example, put in a large character set 11-character password and look at the number of combinations that the Haystack page reports.  Then type one more character and look at that, and subtract the first one from the second one.  And that will give you the number just for that, for example, if you put in 11 characters and then added one to make it 12, well, subtract the value, the number calculated for 11, from the value calculated for 12, and you'll see that it's going to be, what, like on the order of 1 percent, something like that, a little more than 1 percent is what you're going to be losing.



LEO:  The bottom line is it's such an astronomically large number to solve long passwords, we can give up a little bit, and it's still impossible.  Not impossible.  Time-consuming to the point of absurdity.



Scott Broschell in Ottawa, Canada wonders about - I like this - Elliptic Curve Crypto:  I had a question I was hoping your expertise could help me with.  I'm a software developer investigating some licensing software, and I came across the term "elliptic curve cryptography."  Suspicious of any cryptographic algorithm I've never heard of, I did some research; and, somewhat surprisingly, what I read seemed to make sense on a security level as this cryptography works the same way as standard public key crypto with a hard math problem, often the integer factorization problem, but instead uses the discrete logarithm of elliptic curves.  Ever heard of this?  Is it secure? 



STEVE:  Okay, so, yes.



LEO:  Clever.



STEVE:  It is actually, in the crypto community, very well known.  It is the currently most actively researched by the academic guys public crypto system that we have.  What's interesting about it is that the computational complexity is lower, yet the apparent and well-tested and believed security is higher.  So that's really important.  For example, Microsoft's Phone has used it.  BlackBerry has been using it for years.



LEO:  Oh, interesting.



STEVE:  And it's a well-known technology.  In fact, DNSCurve, which is the encrypted DNS technology, it's all ECC based, Elliptic Curve Crypto based.  So to give you a sense, we were recently talking about how 1024-bit keys are being, well, they're still in active use.  But, for example, they're regarded as a new RSA public key ought to be 2048.  I had to, for example, use 2048-bit keys when I got my extended validation certificate.  EV certs have to be 2048.  And Microsoft, as our listeners may remember from a recent news blurb, is in, I think it's next month, they will be formally removing support for RSA crypto shorter than 1024.  There are some 768-bit RSA things still around.  They're removing that from XP SP3 and on in August.  So 2048 bits is where we're moving to under RSA.  But get this.  256-bit elliptic curve provides comparable security to 3072-bit RSA.



LEO:  Oh, interesting.



STEVE:  Yeah.  So only 256 bits of ECC public key provides about the same security as 1.5 times the bit length of 2048, which is 3072.  And the reason Windows Phone and BlackBerry and other people are moving toward ECC is, again, those are lower powered systems, and they need the benefit of that greater gain.  Essentially, you get more protection for less cycles with elliptic curve crypto than you do with RSA, partly because you're able to get more security with a shorter key, and key length is directly proportional to complexity, as we've talked about.  When you go from 1024 to 2048, you get a large scaling of computational complexity, so you'd like to keep the public key as short as possible, yet not sacrifice security.



So ECC, it's well known, I mean, it's been around for many, many years.  These very conservative crypto technologies take a while to happen.  RSA's patents, for example, on the RSA technology, those patents expired in the year 2000, that was done so long ago.  So RSA is well known.  Elliptic curve is less well known, but it is present in the various crypto toolkits now.  So it's available, and anyone can use it without concern.  As far as we know, it's absolutely solid.



LEO:  Sometime that might be a good subject for...



STEVE:  To go into detail?



LEO:  Yeah, how that works.



STEVE:  Yeah, that's exactly how it works.



LEO:  Little bit of math.



STEVE:  Yup.



LEO:  Abhi Beckert in Cairns, Australia waxes thoughtful about browser session cookies:  I'm a web developer, and I've noticed Chrome/Firefox remember cookies more than IE/Safari.  I don't know what that means.  But maybe you can explain.  But my question is, how long should a session cookie last?  If you're reading your email and have three tabs open in Safari, and if RAM is low, iOS and sometimes OS X will suspend Safari to disk, then relaunch Safari again with the same memory.  If you restart your iPad or iMac, they are suspended to disk and re-opened as is.  In OS X, Safari forgets the session cookies over a restart.  It tells the kernel it's not capable of being closed/reopened in low RAM situations.  I bet this will change soon, he says.  But Chrome on a Mac and Safari on iOS can be terminated without losing cookies.  I get it.  So these are the session cookies that are, well, we've talked about them before.  I'll let you explain.



STEVE:  Exactly.



LEO:  In a world where an app cannot - [announcing dramatically] in a world where an app cannot be expected to be running at all times, perhaps that browser window is just a screenshot, and the app - I wouldn't be surprised, really - and the app has been quietly killed until you click it.  When should session cookies be erased?  And what about the reverse problem of users who never close their browser?  I might leave a tab open on my iPad for two years, never closing it or the iPad.  Should that cookie be revoked, or never be revoked?



My conclusion is servers should simply expire cookies after inactivity.  Period.  That is what I recently did when refactoring how our servers handle session cookies.  Two hours without reading a cookie, it gets deleted from the server.  Clients can keep them for years if they want to, but the server will give them a new one if they try use it.  Abhi.  Interesting question.



STEVE:  Yeah.  Now, this follows from our discussion about my recent discovery that only IE honors what we have traditionally thought of as session cookies.



LEO:  Right.



STEVE:  When you close IE - and that was following on from a user in a Q&A, like probably two back, saying, hey, Microsoft didn't impress me with their support when they said "Close IE, and that'll flush your existing login sessions."  And it turns out that Firefox silently changed the behavior of what we've always thought of as session cookies.  I mean, I guess I'm - I've been programming HTML for more than a decade, and I'm old school.  Session cookie means session.  It means it's never written to the disk.  By definition it is never written to the disk.



Well, browsers kind of went off the reservation.  They all started cheating except IE.  Chrome preserves them.  Safari preserves them. Firefox preserves them.  Unless you, in the case of Firefox, as we talked about I think it was last week, go into about:config and manually override and push it back to its behavior before v4, back to good old v3.6 that many of us stayed with for a long time, was honoring session cookies.  But what happened was so many web-centric systems are now using session cookies for their logon authentication, that users were being inconvenienced.  And as we talked about, back when we were discussing this in Firefox, Leo, you'll remember Firefox tends to crash.  And so when it restarts it was losing all of its logons, which was upsetting people more than having them be more sticky.  So the behavior got changed.



So as it happens, I have come to the same conclusion that Abhi has.  In my own use of cookies, for example when my employees are roaming and need to log into our backend database in order to perform customer service functions, the cookies that I'm continually providing them contain a timestamp.  And if the server ever receives one that is aged more than an hour, in my case, because of the kind of work that they're doing, they're either doing things or they're not, if the server makes a request containing an expired cookie, then I require them to reauthenticate.  I just tell them they have to log in again, essentially.  And so as long as they're actively using the application, they get to stay there.  If at any period of time they don't log out, but they stop using it, then after whatever reasonable amount of time the developer chooses, we just decide, okay, there's enough of a chance that somebody else has come along that you'd like them to reprove who they are.  So we're going to be fighting authentication issues probably for the rest of our lives in this crazy Internet world.  But I thought that this was a useful observation and comment from Abhi.  I think the idea of allowing people to explicitly log out or logging them out - and essentially, session cookies are no longer being treated as what we used to think of them as, as session cookies.



LEO:  That's what's really happened; right?



STEVE:  Yeah, it has.  And so now it's up to the web developer on the server side to recognize that they could be getting a cookie from a year ago, a session cookie from a year ago, so they need to take responsibility for assuming that they are sticky.



LEO:  A year ago.  It's true, though, yeah.



STEVE:  It's funny, when he mentioned he might have a tab open in iOS, I'm thinking, yeah, I've got a couple stale tabs, yeah.



LEO:  We never reboot anymore; right?  That's all ancient history.



STEVE:  No, no.  Yeah.



LEO:  Bill Barnes, Charlotte, North Carolina wonders what's all that jive about Java?  Steve, every other episode or more you talk about the evils of scripting.  But you also mention "good" scripts and "bad" scripts, especially Java.  So this has all left me confused.  Could you enumerate in a single place what are the "good" scripts?  You say remove Java unless I need it, but Java's okay because it runs in a safe sandbox.  I know there are two computer products called "Java"; right?  But I don't know how to tell the difference.  If I uninstall the program in "Add & Remove Programs," will I still be able to edit my blog?  Thanks, Bill.  Oh, I'll let you do this one.



STEVE:  So, okay.



LEO:  He's a little tangled in here.



STEVE:  Yeah.  Nobody knows why Netscape named their client-side...



LEO:  Oh, I know.



STEVE:  You do?



LEO:  Yeah.  But go ahead.



STEVE:  Well, nobody but Leo...



LEO:  I'll tell you why.  I know.  They were literally - there's a whole story about it.  But go ahead.



STEVE:  Okay.  For some reason, which Leo will...



LEO:  I'll enumerate later.



STEVE:  ...shortly explain, Netscape named a completely unrelated client-side web browser scripting language JavaScript, though it has nothing to do with Java, which is what Sun Computers' Scott McNealy famously named their interpreted object-oriented set-top box language when they were developing it.  So what we have is two completely different entities.  They run differently; they're treated differently; they're completely different languages; and, sadly, they both have "Java" in their name.  One is Java.  The other is JavaScript, though JavaScript is not a scripted version of Java.  So there's the first issue of...



LEO:  Problem No. 1.



STEVE:  ...deobfuscation, yes.



LEO:  And by the way, it's no longer - did you know that it's no longer JavaScript?  It's ECMAScript?



STEVE:  ECMAScript, yes.



LEO:  Yes, ECMAScript.  So there.  So it was originally called Mocha, and then later it was called LiveScript.  But coincidentally, when Netscape...



STEVE:  Wait, wait, wait.  You mean in Netscape it was called Mocha?



LEO:  The original code name was Mocha.



STEVE:  Okay, so there was a coffee flavor.



LEO:  So there was a coffee flavor, but not an intentional confusion with Java.  And then it was named LiveScript.  That was the official name, I remember.  A guy named Brendan Eich created it.  But it was coincidentally at exactly the same time that Java was deployed in Netscape, in a joint release with Sun, that they announced that they were going to name its scripting language JavaScript.  Some say, according, to Wikipedia, "The choice has been characterized by many as a marketing ploy by Netscape to give JavaScript the cachet of what was then the hot new web programming language.  It's also been claimed" - now, that's what I believe, the former.  But "It's also been claimed that the language's name is the result of a co-marketing deal between Netscape and Sun in exchange for Netscape bundling Sun's Java Runtime with its browser."



STEVE:  I believe it, too.



LEO:  It happened at the same time.  So everybody knew what they were doing, and it's confused people ever since.  And I do believe that's why they've changed the name to ECMAScript.  ECMA is a larger industry group.



STEVE:  Yeah.  My feeling, my own reading on that is that it really is becoming a standard language.  I mean, I like it.



LEO:  You've become proficient in it.



STEVE:  Yeah, actually I've been coding a lot in the last few days.  I'll be showing some people some stuff that I've been doing before long.  And so my sense is it has outgrown the browser.  And, for example, it's supported in Windows now, separately.  So I'm really glad that it has become standardized; it is moving forward; it is maturing.  And there's a lot of positive things to be said about it.  Now, unfortunately, if Bill thought he was confused before...



LEO:  We haven't helped.  But it's a very important - and we say this a lot.  Java does not equal JavaScript.



STEVE:  Right.



LEO:  They're in no way related except for the fact that Sun and now Oracle owns both names.



STEVE:  So from a utility standpoint, one of the things that both languages do is allow cross-platform stuff.  So all the browsers now support very much the same implementation of JavaScript.  For some reason Windows and IE, still just dragging their heels behind, but they're catching up rapidly.  So web servers don't have to care where they're serving the page to.  Java is a plug-in.  And that's a key concept.  JavaScript is built into the browser.  Java is a plug-in, kind of like a PDF reader is a plug-in for most browsers, although they're beginning to support PDFs natively also.  But it's sort of like an add-on.



What Java provides is also cross-platform compatibility, where you can write the same code and run it on a Mac and on a Windows machine and under Linux and under Sun, different systems.  However, one of the things that Java provides is much more power.  You can do networking stuff.  That famous buffer bloat packet delay meter application, you'll probably remember, the one that they designed that measures the amount of packet delay and buffer bloat that you've got in your network connection.



LEO:  Netalyzr.



STEVE:  Netalyzr, yes, was written in Java because, I mean, it's very aggressive in what it's able to do because Java is a complete programming language, whereas JavaScript is deliberately constrained.  For example, in JavaScript you cannot save something to your computer.  They've deliberately kept it for doing browser visual things.  But it's unable to write files to your PC.  Java can do that.



And so while technically they're both sandboxed, inasmuch as they don't have lots of freedom, the Java plug-in sandbox is to keep its behavior constrained; yet, if the programmers want it to do aggressive things, like be a botnet, for example, it could completely do that.  Whereas JavaScript doesn't have the ability to do those sorts of things.  The Java plug-in could write files to your system, and often does; whereas JavaScript deliberately is constrained.



So to answer your question, Bill, could you uninstall the program in Add/Remove Programs?  If Add/Remove Programs shows Java, then that's the plug-in, and you can definitely remove it and still be able to edit your blog, since your blog editing would certainly be done in JavaScript, using JavaScript, not the Java plug-in.  And the Java plug-in has been a constant source of security problems in the past.  Can you think of anything else I've left out, Leo?



LEO:  No, I think you nailed it, baby.  I'm sure you didn't help, or Bill has no idea what you're talking about.  But that's okay.  Sorry, Bill.  Listen to this over and over again.  Maybe the transcription, that will help.



STEVE:  Yeah, and unfortunately it is, I mean, this just demonstrates how...



LEO:  It's intentionally confusing.  They did it that way.



STEVE:  ...how messed up it is, yeah.  And once upon a time it helped both of their interests.



LEO:  It really was marketing.



STEVE:  And I don't think we're ever not going to call it JavaScript.  I mean, that's a name that's going to stick.



LEO:  Well, ECMA is the worst name ever.  I mean, seriously, it sounds icky.  It sounds like a skin disease.  "I have ECMAScript."  "Oh, I'm sorry.  Maybe you can get a salve for that."



STEVE:  Yeah.



LEO:  But I agree with you.  And by the way, ECMAScript, I mean, we're going to get emails from people saying, well, technically ECMAScript is not JavaScript.  Yeah, well, there's JavaScript, there's Jscript, there's ActionScript, there's a lot of these things.  And ECMA I think going forward is going to be the standards body, and it's going to determine what it is, and that's frankly what we need as a unified standard.



STEVE:  Yes.



LEO:  On the lighter side, Kevin Ghadyani in Overland Park, Kansas says:  Mailbag?  What is this mailbag of which you speak?  If, as you and Leo stated, most of the people listening are school folk from assigned reading, wouldn't the term "mailbag" predate them by at least 10 years?  He's saying it's like "dial the phone."  When is the last time you saw a dial?  Being older than most of them at age 25, I can say when you speak of the mailbag, I'm only familiar with one because of old TV shows and movies from when I was a kid, you know, when people used to actually hand-write and postal-mail letters to each other.  I guess it's a bit like the way Leo is able to "read" a book with his eyes closed.  So I'm curious, then:  Why use the term "mailbag"?  Kevin Ghadyani.  By the way, he says, I'm aware the term "inbox" is also showing its age.  Because of the methodology of email, this terminology still fits.  I'm also aware I wrote this email in the form of a letter. Thank you, second-grade teacher.



You know, it's not just "mailbag."  There's all sorts of anachronistic - "dial the phone" is one.



STEVE:  I used the term to a couple of Starbucks baristas who were in their teens.  I used the term "asleep at the switch."  And I thought, you know, they have no idea what that...



LEO:  But they know what it means.  They don't know where it comes from.



STEVE:  Right, right.



LEO:  Look, have you ever said "the whole nine yards"?  Do you know what that means?  That's a complete anachronism, but everybody knows what it means.  "I shot my wad."  People think - no, it's not sexual.  People think that's something - it's not.  It has to do with hand-loaded muskets.



STEVE:  Yup, sticking gunpowder down and...



LEO:  It goes back to the Revolutionary War.  So I don't think it's unusual.  I think that's how language evolves.  And what's interesting is that in fact these anachronistic phrases, which have lost all meaning, at least in terms of...



STEVE:  Still maintain their context, or their...



LEO:  Exactly.  They've lost all context.  They maintain meaning, yeah.



STEVE:  Right.



LEO:  I think that that's fascinating.  So I don't know about "mailbag."  I don't know if that's one of them.



STEVE:  I remembered, when I was reading that, I immediately pictured a scene from "Andy of Mayberry."  I think that's where I remember...



LEO:  [Geezer voice] Hey, Opie, the mail's in.



STEVE:  And the bag slung over his shoulder.  In his little gray mailman outfit.



LEO:  So "the whole nine yards" of course means everything, right, the total thing.  But no one actually is sure what the origin of that is.



STEVE:  I was going to say, Leo, I don't know where that comes from, "the whole nine yards."  Because that's such a - it's not like the ninth hole.  That's obviously a golfing reference, but I don't know if ninth hole means anything.



LEO:  Some people attribute it to the length of a machine gun belt, nine yards long.  So if you shot all nine yards of the machine gun belt - this is from World War II vintage aircraft - that that would be it.  However, nobody said that until 40 years after the war ended, so it seems unlikely.  The other argument is that nine yards is a cubic measure, refers to the volume of a cement mixer.  But in fact that doesn't work, either.



STEVE:  Dump the whole nine yards.



LEO:  Yeah, or the length of a bolt of cloth or a sari, the structure of certain sailing vessels, and American football, none of which make any sense at all.



STEVE:  So we're all saying it, and we have no idea.



LEO:  No idea.  And so that's what I think is going to happen to "mailbag."  See, London Bob's in the chatroom saying, no, it's a naval term.  Well, we don't know.  Go read the Wikipedia article on "the whole nine yards," and you can see that no one really knows.  They call it an "etymological mystery."



STEVE:  Ooh, nice.



LEO:  "The most prominent etymological riddle of our time."



STEVE:  And you heard it here, folks.



LEO:  And you heard it - but what's interesting, it wasn't used until the '60s.



STEVE:  Maybe someone just made it up.  It doesn't really - it never has...



LEO:  I think somebody like Dvorak made it up and said, "Heh heh.  Let's see, heh, if they'll adopt it."



STEVE:  Exactly.  Foisted on an unsuspecting public.



LEO:  Now, you know "hoisted on your own petard," the Shakespearean line, a "petard" was an explosive device.  And to by "hoisted by one's own petard" was to be blown up by one's own device.  Now...



STEVE:  Hoisted.



LEO:  Hoisted, because it lifted in the air.  But I think, unfortunately, that is a term that has become an anachronism.  I don't think I could say to a young person, "You have been hoisted upon your own petard," and they would have any idea.



STEVE:  No, I think at that point they would lock Grandpa up.



LEO:  Grandpa, get off my lawn.  One more, one more, one more, and then we'll wrap this thing up.  From Scott Van't Land - I hope I'm saying that right, Van't Land - in Coalhurst, Alberta, Canada, a little password humor.  We sure can use a little password humor.



STEVE:  Very little password humor, actually.



LEO:  Hey, you included it.



STEVE:  I know.



LEO:  [Geezer voice] In the mailbag.  Steve, love the show, listen every week.  In all the discussion about secure passwords, I saw this joke, thought you might find it amusing:  A large company was doing a security audit of current passwords and found one that was unusually long.  When they asked the employee why the password was "Mickey, Minnie, Goofy, Huey, Dewey, Louie, Donald, Sacramento." she explained, "Oh, I was told it had to be seven characters and a capital."  That's pretty funny.  Mickey, Minnie, Huey, Gooey, Dewey, Louie, Donald, and Sacramento.



STEVE:  Yeah.  I have to...



LEO:  It's good.



STEVE:  This lets everyone know that I read my Twitter feed.  About three months ago I got just flooded with this.  And I don't know, again, if it was XKCD or XCKD or whoever that guy is.  I don't know where it appeared.



LEO:  Love him, yeah.



STEVE:  But our listeners all thought this was really funny.  Or at least thought I would think so.  And I avoided mentioning it until now.  And for some reason I thought, well, okay, I'm just in a mood today, so we'll share the seven characters.  And actually, these don't strike me as Sleeping Beauty's seven dwarves.



LEO:  No.  There's Mickey Mouse and Minnie Mouse.  There's Goofy.



STEVE:  And he wasn't one of the seven dwarves.



LEO:  Huey, Dewey, and Louie are Donald Duck's nephews.



STEVE:  Well, and they were also the three robots on that wonderful...



LEO:  Oh, you're right.  Wow, I forgot about that.  Yeah, with Bruce Dern, where he's the gardener in the - I forgot the name of that.  I'm sure the chatroom will tell us in a moment.



STEVE:  The space gardener.



LEO:  Yeah.  And then Donald of course, is their - "Silent Running."



STEVE:  Yes, "Silent Running."



LEO:  Thank you, [Name] in India.  They're fast.  And Sacramento, of course, the capital of the state of California.



STEVE:  Yeah, so seven characters and a capital.



LEO:  Huey, Dewey, and Louie.



STEVE:  Actually pretty secure.



LEO:  You know, it's a great password, especially if you capitalize, use commas.  That's excellent.  Might put an ampersand in there just to really throw them.



STEVE:  Yeah, do @Sacramento, that'd be good.



LEO:  @Sacramento.



STEVE:  There we go.



LEO:  Steve Gibson's at GRC.com.



STEVE:  Actually, I think that probably pretty much describes the Senate that we have.



LEO:  Huey, Dewey, and Louie?  Manny, Mo, and Mike?



STEVE:  Goofy, Mickey, and Minnie?



LEO:  Goofy?  Now, we can't get political, Steve.



STEVE:  Oh, okay, okay.



LEO:  But I share your sentiments.  And actually I don't think there's anybody in the land who doesn't.  We do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC, on TWiT.tv.  It's fun to watch live, if you want.  But if you can't, man, we make it available in a lot of ways.  And I'm not calling this a podcast, although it is.  I'm saying "on demand," how about that?  How about that for modern?  On demand, as needed, when you want it, where you want it, in audio and video.  In fact Steve, for the 16Kb folks, the folks who have limited bandwidth, makes a 16Kb version available at his site, GRC.com, and a text transcript, which is really lightweight.  You can find that at GRC.com.



STEVE:  Wait, wait.  What do you mean, "lightweight"?



LEO:  Nothing lighter weight than text, 8-bit, 7-bit probably, ASCII.



STEVE:  Oh, and it compresses down.



LEO:  Compresses, like, hmm, beautiful.  How big - have you looked at that?  I mean, really, after compression it's just a few kilobytes, probably.



STEVE:  Eh, it's nothing.



LEO:  Nothing.  Nothing.



STEVE:  You can read it with your eyes closed.



LEO:  You can also get SpinRite, the world's best hard drive maintenance and recovery utility, there:  GRC.com.  And don't forget, if you've got a question, we do these every other episode, so you can put your questions on the form there at GRC.com/feedback.  He's got information about sci-fi, about diets, about secure passwords.  You mentioned the Password...



STEVE:  Haystack.



LEO:  ...Haystack page.  That's GRC.com/haystacks.htm.



STEVE:  Yup.



LEO:  But it's all in the menu.  It's easy to find.  You can get audio, higher quality audio and video of the show as well at our site, TWiT.tv/sn.  It is a podcast, so if you subscribe, you'll get it every week automatically in whatever form you choose.  And never any charge, thanks to our fine sponsors.  Next week do you know what we're going to do?



STEVE:  I don't, but I think we ought to follow this goofy episode up with something really seriously deep and propeller-winding.



LEO:  Okay.



STEVE:  So I'm going to come up with a good one.



LEO:  You've got it.



STEVE:  Okay.



LEO:  Exciting.  Thank you, Steve.  Thanks, everybody, for joining us.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#363

DATE:		August 1, 2012

TITLE:		Ali Baba's Cave ... and Zero-Knowledge Interactive Proofs

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-363.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with an eventful week of security news, Steve and Leo explore a variant of the story of "Ali Baba's Cave" as a means for clearly explaining the operation and requirements of cryptographic Zero-Knowledge Interactive Proofs.



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  I got an email yesterday from Dropbox saying "We have changed your password."  What's going on at Dropbox?  Steve will talk about it.  Plus a bedtime story, all about Ali Baba's Cave and Zero Knowledge.  It's all next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 363, recorded August 1st, 2012:  Ali Baba's Cave.



It's time for Security Now!.  Get ready.  We're going to protect your security and privacy online with this guy right here, the Explainer in Chief, Mr. Steve Gibson of GRC.com, the Gibson Research Corporation.  You've probably heard the name.  Steve's been around the industry for years, going back to the first Apple II Light Pen, which he created.  He also wrote great columns.  What was the name of your InfoWorld column?  Was it InfoWorld?  



STEVE GIBSON:  It was Tech Talk.



LEO:  Tech Talk.  I miss that.



STEVE:  The original concept, the name I had was Behind the Screens, which I kind of thought was fun.



LEO:  Yeah, I like that.



STEVE:  But CompuServe, of all people - that sort of dates us - CompuServe claimed that they contacted the InfoWorld publishers and said, "We have a trademark on 'Behind the Screens.'  We'd like you not to use it."



LEO:  See, this has been going on since years ago, folks.



STEVE:  Yeah.



LEO:  Nothing new.  Well, I like it.  And did you - I know you were thinking at one point of making an eBook, compiling all of those.  Did you ever do that?



STEVE:  Never "e."  I did republish the first - I had co-publication rights from the beginning with InfoWorld.  That was my deal is that I just wanted to be able to do something with them in the future, which always seems to be my approach.  And so I did publish "A Passion for Technology," was the name of the series.



LEO:  That's right, yeah.



STEVE:  Yeah, it was five books that were the first five of the eight years that I did it.  And I went back and added more, of course.  I added diagrams because they were just, for a weekly column, they didn't have the budget or the personnel or whatever to create diagrams for publication.  So there are often times where a picture really helped the explanation.  And so I added graphics to almost every one of the columns to also give people something they hadn't had before.  And it was all printed on acid-free, archival-grade, museum-grade paper.  We made a couple tens of thousands of sets and sold them for years.  And somewhere I have them.



LEO:  I was going to say, can you still get them?



STEVE:  I mean, the books are out of print, but I do have all of that text.



LEO:  eBook.



STEVE:  It was - are you ready for this? - Ventura Publisher was the publication program that I used for doing the computer-to-print.  And that's around somewhere.  So I have thought it would be really neat to get them all up on the website.  I wouldn't sell them.  I'd just make them available.



LEO:  Maybe an eBook.  The real problem's going to be getting that out of Ventura.  It's a technical issue.



STEVE:  Oh, it's a challenge, Leo.  I want it.



LEO:  You might have to write some code.



STEVE:  Gives me something to do.



LEO:  All right.  What are we talking - I see the name of the show on the screen:  Ali Baba's Cave.  What are we doing today?



STEVE:  Well, I promised everyone I would give them something to think about.  And we have touched on, several times, we've touched on the terminology and some of the concepts underlying some cryptographic concepts known as "zero-knowledge interactive proofs."  A zero-knowledge interactive proof is something that fascinates cryptographers.  And in fact it's recently become of greater interest because of this approaching threat of quantum computing.  The idea is you want to - we have two people.  In traditional crypto parlance, we have Alice and Bob, A and B.  And sometimes C, we have Carol.  We bring Carol in.  But those are the names all the cryptographers universally use to describe interactions between people who are exchanging secrets or needing to agree on cryptographically secure tokens and so forth.  We have Alice, Bob, and Carol.  And then I think it's Doug or Dave.



Anyway, in the case of zero-knowledge interactive proofs, we have Peggy and Victor are the standard players.  Peggy is the prover, and Victor is the verifier.  And the idea is Peggy wants to prove that she has knowledge of something without giving any of it away.  So she wants to prove to Victor, the verifier - Victor is the verifier.  She wants to prove something without divulging any of its content.  So there's the traditional Ali Baba and the 40 Thieves myth, but there's a variation of it which can be used to explain these concepts.  So that's what we're going to do today is we're going to explore Ali Baba's cave.



LEO:  Wow.  So this is one that you really want to put your thinking caps on for because we're going to involve your mind.  No passive listening on this one.



STEVE:  Yeah.  What's happened is, because this has become important, the concept of zero-knowledge interactive proofs has been formalized.  And when academic people formalize stuff, they create very clear, careful definitions.  And the trickiest thing is the definition of what it means to have zero knowledge communicated.  And the end of the story that I'm going to tell...



LEO:  I love this.



STEVE:  ...is about that.



LEO:  This is great.  This is great.



STEVE:  Yeah.  This is going to be fun.



LEO:  This is the thing I think people love most about this show is the fact that this is a smart show.  You really learn something out of this show.  I love it.  I can't wait.  Well, let me take...



STEVE:  Now, speaking - oh.



LEO:  Go ahead.



STEVE:  There are some people who have not learned something.



LEO:  And we'll find out.



STEVE:  Dropbox and, let's see, Dropbox and Tesco.  It's a large supermarket chain.



LEO:  Okay.  Because I got an email from Dropbox which I forwarded to you.



STEVE:  Yup, and you were not alone.  So we will talk about that in a moment.



LEO:  I was very curious.  I'm so glad you're going to cover this because I was trying to figure out, why are they saying this?  Anyway, we'll talk about that in a second.  So what's the Dropbox deal?  I'm dying to know.  I got an email, in fact I could show this, from Dropbox, that said "Change your password."  But they did something that kind of puzzled me.



STEVE:  Well, okay.  So we discussed on the podcast a couple weeks ago that there was something going on because Dropbox users who have control of their email accounts and are able to create aliases for themselves whenever they need to, they were receiving spam on email accounts that they had specifically created for their Dropbox accounts and for no other purpose.



LEO:  Right.



STEVE:  Which led us to believe that there had been some problem at Dropbox which Dropbox was not talking about.  So just yesterday, on July 31st, there was finally a posting on the Dropbox blog.  It reads:



"A couple of weeks ago we started getting emails from some users about spam they were receiving at email addresses used only for Dropbox.  We've been working hard to get to the bottom of this and want to give you an update.



"Our investigation found that usernames and passwords recently stolen from other websites were being used to sign in to a small number of Dropbox accounts.  We've contacted these users and have helped them protect their accounts.  A stolen password" - here it gets interesting.  "A stolen password was also used to access an employee Dropbox account containing a project document with user email addresses."  So it wasn't just externally stolen account information that was being reused, but one of those happened to be an employee.  Meaning that an employee of Dropbox...



LEO:  Was compromised.



STEVE:  Yes, was compromised by reusing the same password that he used for his own Dropbox, Dropbox account as he used somewhere else.  So they say:  "We believe this improper access is what led to the spam.  We're sorry about this and have put additional controls in place to help make sure it doesn't happen again.  Keeping Dropbox secure is at the heart of what we do, and we're taking steps to improve the safety of your Dropbox even if your password is stolen, including:  two-factor authentication, a way to optionally require two proofs of identity (such as your password and a temporary code sent to your phone) when signing in."  And they said "coming in a few weeks."  Also, "New automated mechanisms to identify suspicious activity.  We'll continue to add more of these over time."  And, "A new page that lets you examine all active logins to your account."  And, finally, "In some cases, we may require you to change your password, for example, if it's commonly used or has not been changed in a long time."



LEO:  Okay.  That's BS.



STEVE:  I know.



LEO:  I'm going to call BS on this...



STEVE:  I know.



LEO:  ...because I have to, I use a unique generated password for Dropbox that's not used anywhere else.  It's a very strong password, and they have changed it on me, at great annoyance to me because we use this for our corporate account.  I have to go all over the place and change it in many locations.  This is proactively keeping me safe.  You idiots.



STEVE:  What would be interesting to know whether...



LEO:  They must have been compromised.



STEVE:  ...or how widespread this is because what they may actually...



LEO:  I think they changed everybody's passwords.



STEVE:  Right.



LEO:  And that tells me they got compromised in a much more serious way than they're acknowledging.



STEVE:  Right.  I'm afraid...



LEO:  Right?



STEVE:  ...that, reading between the lines, that's what I would have to assume.



LEO:  Why change my password, a good, strong, unique password, why change all these people's passwords if the only issue is a few people used the same password on multiple sites and they were hacked, or you've got your email address leaked out by our employee was hacked.  Neither of those justify changing everybody's password.  Certainly not mine.



STEVE:  Well, I was going to say, neither of those explain why you received that email because...



LEO:  Well, now, Bear is saying he didn't get that email.  Many people in the chatroom are saying that they did not get that.  So it wasn't for everybody.  All right.  I thought it was for everybody.  But then I'm wondering why it's for me.  Maybe because I haven't changed the password in a year?  I don't know.  But it's a strong password. Believe me, if you saw this password - I looked at it.  It was generated, I'm not sure if it was generated by 1Password, or it probably was generated by LastPass.  It's 12 characters, random numbers, letters, special characters.  There's no way it's not a strong password.



STEVE:  Well, and in following up on this, I, when I went to Dropbox, LastPass jumped in and logged me on.  And I did not receive any email from them.  But I also tend to obsolete my email addresses occasionally.  And so I thought, well, okay, maybe they tried to send me something, but it bounced.  So I still have an email address, and LastPass knows how to log me in.  But it's not a current email.  But it sounds like, from what you're saying, that  that many people are getting this, but not everybody is getting it.



LEO:  So even if they leaked my email address, that didn't mean they leaked the password.  So I just have to think there's more than they're admitting here.  Or they're being, I think, overly, well, you tell me.  You're the security expert.  If I haven't changed my password in a year, but it is a strong password, is there - we've had this discussion.



STEVE:  Yeah.  I just - I don't buy this notion that a really, really good password should be forced to be changed.  Well, okay.  Right.  I interrupted myself.  I don't think - I don't buy the idea that there's any benefit at all to be gained from periodically being forced to change a really good, strong password.  I don't see it.  The only reason would be if, in the background, somebody is persistently trying to crack it and doing a brute-force attack, and someday they're going to get there.  But then you could say, okay, the only benefit of changing it would be if I changed it to something that they had already tried so that this brute-forcer wasn't going to still stumble upon the new one.  I mean, there's no benefit.



LEO:  In my opinion, the only reason that you could reasonably say, "Change your password, Leo," is if they knew or thought or suspected or were worried that my password had been compromised, which means that they have in some way been compromised and have not yet copped to it.  That's the only thing I can understand.  Because with a service like a Dropbox, it's a real hardship because it's not just one machine.



STEVE:  Right.



LEO:  It's all over the place.  I'm going to have failures, intermittent failures in all sorts of places that I don't even know about because this is our company account.  There's nothing personal on here.  It's completely stuff we share with each other.  But I have it on I don't know how many machines.  It's just driving me crazy.  It's just unacceptable, I think.



STEVE:  Well, they're big.  And they've made mistakes in the past.  We talked about, remember, when due to a problem they had about a year ago, you could use any logon you wanted in order to access someone's account.  It wasn't checking the password at all.  You could just type "noodles" in as your password, and you'd get in.  So it's like, whoops, not good.



LEO:  I think they're not being candid here.  And we're not alone, by the way.



STEVE:  Well, I did quote here, I caught the top four, the first four, or three, rather, responses to that blog posting.  Someone posting as tekwarrior said, "You should start improving security by getting rid of email addresses as usernames."  Kellic wrote, "Please use Google Authenticator so I'm not installing yet another dang app on my phone for this.  LastPass already uses Google Authenticator, and it's slick."  And then an anonymous poster said, "Agreed.  Was thinking the same thing.  I don't use Dropbox now because of the security issues, but I may give it a second glance.  It would be nice if it was integrated with Google Authenticator."



LEO:  I resent the idea that what they're really saying is, "Oh, Leo, you are probably one of those people that use the same password on multiple services, so we're going to make you reset your password."  I resent that because I don't.  And I had a strong password for Dropbox.  I just really resent that.



STEVE:  And it's a true inconvenience that they have reset the password on your account.



LEO:  It's really, really, well, we're going to move off Dropbox.



STEVE:  Well, then something else really bizarre happened.  I got a tweet from someone called @Tinzien, who tweeted to @dropbox, @dropbox_support, and to me, @SGgrc.  And he said, "Dropbox.com is showing a very weird and expired certificate when trying to visit the site."  And I attached it to the email that I sent you, although you probably haven't seen the email.  I know that some of your guys did receive it because they knew what the title of this podcast was.  But so I have the JPEG of the Dropbox cert, which I captured.  It was for www.kitchensink.n0t with a numeric "0," n0t.



LEO:  What?



STEVE:  So kitchensink.n0t.  And in the URL he did not mistype it.  It's www.dropbox.com.  And the certificate came up, and it was for kitchensink.n0t.



LEO:  That doesn't sound right.



STEVE:  And then - I know.  And then I logged into Dropbox, over SSL, of course, checked what the certificate was today.  And I noted that it was not valid after 01/29/2014, which is some integer number of months later than last night.  So it sounds like something strange happened.  Maybe some funky certificate got served, or who knows what's going on.  But just another data point.  Dropbox, you were talking about moving away from them.  And as far as I...



LEO:  What is the n0t TLD?  There's no n0t TLD.



STEVE:  I know.



LEO:  This is, you know what, this is - they were hacked.  That can't possibly - how could you even get a certificate for a nonexistent TLD?



STEVE:  Well, that certificate is self-signed.



LEO:  So it's self-signed.  On, it's bogus.



STEVE:  Yeah.  So someone hacked it themselves and signed it.



LEO:  Got it.  Could be somebody at Dropbox.



STEVE:  Yes.  It could be just like an internal working certificate that somehow got put up on their servers by mistake, or they were changing certificates...



LEO:  I am less and less impressed with Dropbox.  How could you fumble this so badly, dudes?



STEVE:  Well, and remember, too, as far as we know they're not doing any pre-egress encryption.  So they encrypt, I'm sure, for transit. But as I remember from our last look at them, they're subject to subpoena.  So it's like, eh, I'm not putting my stuff there without having it encrypted first.



LEO:  Oh, wait a minute.  Now, this is interesting.  One of the chatters has sent me a Google search for kitchensink.n0t.  It's apparently - it was used in a Gmail hack attack?  This goes back to 2008.  Kitchensink.n0t is interesting.  What is it?  Wow.  105 million results for it.



STEVE:  Whoo.



LEO:  And going back many years.  I don't have time to do the research, but that's interesting.  What is it?  Wow.  It's not something, well, I would have just said, oh, they're just using something random they made up.



STEVE:  Clearly not, yeah.



LEO:  Clearly not.



STEVE:  So maybe there was some sort of an intercept of this one tweeter's posting.



LEO:  Could just be him, yeah.



STEVE:  Yes.  And somehow he got to a bogus Dropbox server with a self-signed cert.  But any browser is going to notify him that this is not valid, and that's what happened is that Firefox had a fit when it got the certificate and said...



LEO:  Yeah, but don't you find it interesting that the same domain was used in a Gmail man-in-the-middle attack?



STEVE:  Yeah, it is interesting, yup.



LEO:  Well, so there are many.  And if you want an alternative to Dropbox, we have a whole host of good TNO, Trust No One, choices.  Steve did a whole episode on other choices out there.  And I'm going to be relistening to that episode and picking somebody new because I'm not using them anymore.  I'm infuriated.  Why should I have to change my password?



STEVE:  Well, on that note, a number of tweeters commented that there was some strange behavior, well, unwelcome, from Microsoft's newly released Outlook.com.  And I went over to Outlook.com to poke around see what was going on there.  I guess it's a Gmail clone.  I'm sure you know all about it, Leo.  I've not spent any time there.



LEO:  What is the name again?



STEVE:  Outlook.com.



LEO:  Oh, yes, the new Microsoft Hotmail.



STEVE:  Exactly.



LEO:  Yeah.  In fact, I immediately - Dan in our chatroom said, quick, get your name.  And I did.  I immediately got LeoLaporte@outlook.com because that's important, to preserve that.



STEVE:  Absolutely.  Anyway...



LEO:  It's nice.



STEVE:  What people were tweeting was that it has a 16-character password maximum.



LEO:  Oh.



STEVE:  So here they are.  And someone sent me a screenshot showing the error message they received.  And Microsoft's - this new Outlook.com says, "You are apparently using a password longer than 16 characters.  16 characters is our maximum.  Please use only the first 16 characters of your longer password.



LEO:  That is a long password, though; right?  I mean, come on.  16 should be enough.



STEVE:  Yeah, but we know that it ought to be - we don't care how long it is.



LEO:  Shouldn't be limited at all, yeah.



STEVE:  Yeah.  It ought to be use what you want, and good luck to you.



LEO:  Do you think they have some sort of like a fixed-length field in their password database?



STEVE:  Well, that's the concern is that they're not, I mean, if you hash, then it doesn't matter how long it is.



LEO:  Right.  That's a bad idea.  It means they're not hashing; right?



STEVE:  Only if you're not hashing...



LEO:  Oh, boy.



STEVE:  ...that you care about the input length.



LEO:  Oh, boy.



STEVE:  Yeah.  Meanwhile, Tesco is in the U.K.



LEO:  Oh, here, by the way, just an update on that.  Apparently the team did a "I am the creator of Outlook.com, ask me anything"; and they said, "We are aware of this problem, and we are going to adjust it."



STEVE:  Yeah, we'll make it 32.  That ought to be long enough.



LEO:  But you know what, what that shows is how smart the community has become.  Why can't I have more 16 characters for a password?  That limitation has always existed, probably goes back to Hotmail days.  "We're looking into fixing it," says Martin.  Hmm.  Oh, so interesting.  So Hotmail has been accepting longer passwords but truncating it.  Oh, that's really bad.  So that's interesting.  So they are aware of it, apparently, and planning to fix it.  Interesting.



STEVE:  God, you know?  And what's amazing...



LEO:  Well, it's legacy.  It's legacy code.  That's the real problem.



STEVE:  This is just not hard to fix.  It's like it's Romper Room.  Anyway, Tesco...



LEO:  In fact, somebody asked - I love this.  They're so smart.  Recursion asks, "Why is there even a limit?  The password should be salted and hashed.  How can you not process a password of arbitrary length?"



STEVE:  Well, and that brings us nicely into our next story.  A security researcher named Troy Hunt - whose current blog posting is just www.troyhunt.com, so if you can go there, you can bring up his current posting.  And I saw some Twitter traffic about this, and this has hit the U.K. news, naturally.  The Register.co.uk picked up on it.  Tesco is, Troy explains, a major, I guess THE major supermarket chain in the U.K., like Coles is in Australia and like Safeway is here in the U.S.  And so Troy tweeted that - Troy explained that he had seen a rumor and then confirmed, because he's now in Australia but used to be in the U.K. and so had a Tesco web store account, that he asked them for his password, which he forgot, and they mailed it to him.



LEO:  Wait a minute, physically mailed it to him?



STEVE:  Just - no.



LEO:  Emailed it to him.



STEVE:  Sorry, emailed it to him in the clear, "This is your password."



LEO:  Here's your password, dude.



STEVE:  Here you go.  Now...



LEO:  I should point out we get a lot of heat because TWiT.tv has, for historic reasons, there's no reason to log into it, but it has a login because it shouldn't be exposed, but it is exposed.  And if you forget your password, we will email it to you in the clear.  But there's nothing there.  



STEVE:  Right.  So there's no value.



LEO:  There's no value to it.  So it has no - there's nothing you can do with your password.  So don't get mad at me.



STEVE:  So he asked them, because Tesco has an active Twitter account, and they responded:  "Passwords are stored in a secure way.  They're only copied into plaintext when pasted automatically into a password reminder mail."  [Buzzer sound]  So, oh, goodness.  So Graham Cluley, who is the Senior Security Consultant at Sophos, responding to this, wrote:  "It does look as though Tesco is not following industry best practice.  Any company that can email you your password is doing something wrong."  And Tesco has not replied.



And then TechWeekEurope picked up, and they reported - this is today they reported:  "A dangerous flaw has been found on the Tesco website, placing the company's online customers at risk, TechWeekEurope has learned, just a day after the supermarket chain was lambasted for weak security practices."  Their story goes on:  "Yesterday, security researcher Troy Hunt had exposed problems with Tesco security, including the fact that it appeared to be storing customer passwords in plaintext without proper salting and hashing."



Well, they may be encrypting them and then decrypting them to send, but that's not good either because, if their password database is captured, it could be decrypted in the same way they do it, and then everyone would have their passwords, making it easier than having to do the password  hash reversing.  Anyway, so their story finishes:  "Today it emerged that an cross-site scripting flaw on the site could be exploited by hackers to hijack users' accounts.  TechWeekEurope has seen evidence proving that the flaw exists and has warned Tesco about it, but received no response.  The XSS code will not be published for the safety of Tesco shoppers."



And if anyone is a Tesco customer, I would recommend you go take a look at Troy Hunt's current blog posting because he has an extremely comprehensive posting where he goes into many problems with Tesco security.  The more he looked, the more he found.  So, and it may very well - it's probably not a coincidence that a cross-site scripting flaw has surfaced the day after Troy started looking because I would imagine that his brought a lot of attention over to Tesco's website security practices, and they have been found wanting.



On the brighter side, LastPass, our favorite, has announced two new tighter security options that I really got a kick out of.  I thank Leon Zandman in the Netherlands, a listener of ours, for tweeting this to me.  This just happened.  So thanks to Leon I found out about it in time for this week's podcast.  Two new options for LastPass:  Restrict login to selected countries, which I think is very cool.  I mean, how often are you, if you're not an international traveler, or even if you are, you may be bouncing between here and the U.K., for example, or the U.K. and Australia.  But you're not planning to go to China or Russia.  So why allow logins from countries you absolutely never go?



And I think this is an example of the kind of forward thinking I love about LastPass.  And this is what everyone should have.  I'm not going anywhere.  So I absolutely don't want to allow any of my accounts to be logged into from anywhere else.  And if I'm planning a trip, I know.  And there ought to be, in the least, some extra-extraordinary login requirement if I try to log in from outside my normal geographic location.  So I just think this is very slick.  It's like, why isn't everybody doing this?



LEO:  This is kind of like the Google thing where they tell you somebody accessed your Gmail from an odd spot.  I think every site, everything should do this; right?



STEVE:  Yes.  And in fact I would go further because Gmail will - I guess we are seeing some things that are saying, wait, we're going to deny really abnormal behavior.  It's very much like how your credit card company will call and say, "Are you buying wigs in the Ukraine?"  No.



LEO:  No.  No, no, no.



STEVE:  Only in Southern California.



LEO:  And this is all - it's not somebody going, hmm, this looks odd.  They use business intelligence software that is very good now at detecting odd patterns, abnormalities.



STEVE:  Yeah, well, it won't let me buy gas, which is annoying.



LEO:  There, well, there are some things that maybe it's a little oversensitive.  But I prefer my credit card gets blocked in excess than less often than it should be.  We are - for some reason Bank of America with our business cards turns them off all the time.  Just some companies, Chase, I also have a Chase card, they don't do it as much.  Amex is very good.  They'll call you.  They really interact with you a lot.



STEVE:  I did add recently to my main card the ability to notify me by text.  And it has come in handy.



LEO:  Isn't that good.  That's the way to do it, yeah.



STEVE:  Yes, because I can very quickly say - oh, in fact, it was when Google charged me for the Nexus 7.  It had been a month since I ordered it, and I got the $249 one plus the case, so it was $303.  And I got a text coming in, and it's like, yup, I know what that is.  And I was able to acknowledge it right there on the spot.  So it was very cool.  And I'm going to talk to you about that in a second.  And then the second feature - the first one was restrict login to selected countries.  The second one is also very nice:  Disallow logins from the TOR network.



LEO:  Really.  Now, why would that be good?



STEVE:  Well, because what occurred to them, when they implemented the first one they realized, wait a minute, there are TOR nodes in the U.S.  So somebody outside the U.S. who is being blocked because of a geographic restriction could use TOR to proxy their connection inside the U.S.  And so that would be a way around this.  And so they said, oh, let's just toss that one in, too.  We won't allow a TOR access to LastPass login.  Which again is, like, really nice thinking.



LEO:  Well, I'm going to go into my LastPass settings.



STEVE:  Yeah.  You can just turn those on.  They're off by default, although the U.S. is turned on for U.S. customers.  So you're not blocked.



LEO:  That's the nice thing is you can be in Europe and say, oh, no, no, turn that off.



STEVE:  Absolutely.  Absolutely.



LEO:  You just log in.



STEVE:  Computerworld picked up a nice note that I just wanted to share.  We've talked a lot about Firefox's moving toward background updates following the successful Google Chrome browser model.  Just one week after v14 of Firefox was released, 46 percent of all Mozilla browsers were using v14.



LEO:  Wow.  That's amazing.  But it's automatic now; right?  So that means the other 54 percent just never use Mozilla.



STEVE:  Oh, I don't know what that means.



LEO:  Or they're so old, they're not in the automatic upgrade state.



STEVE:  That would be it, yeah, because if you're at 3.5 or 3.6 or back further, then it won't move you automatically.  So you've got to be into that automatic mode.  So half of Mozilla users have been manually updating themselves to the point now that they no longer need to, is probably the way to best phrase that.



LEO:  That's great.



STEVE:  And I noted a few things.  I saw a little blurb about Safari v6, which we all received - oh, my god, you're right, that was a long download, Leo.  Oh, my goodness.



LEO:  Well, it's half a gigabyte, isn't it?  No, no, it's 4GB, 4.something gigabytes.



STEVE:  That's no excuse because I downloaded - what did I - I downloaded something that was 3GB just yesterday, actually it's the latest version of FreeBSD, the full DVD install.  And it was 3GB, and it took a couple hours.  But not, oh, my goodness.  I think OS X v10.7 took all day.  I mean, it was just like, just waiting for it.



LEO:  Well, millions of people are downloading it.  That's why.  I mean, sounds busy.



STEVE:  So SAMS reported Apple has released an updated version of its Safari browser, Safari 6 for OS X v10.7.  And they said Lion, but we know that's Mountain Lion, because the other one was just regular Lion?



LEO:  Yeah, Lion.



STEVE:  That's what I thought.



LEO:  I ain't Lion.



STEVE:  So it addresses more than - are we sitting down? - 120 security issues present in v5.x of the browser...



LEO:  Jiminy.



STEVE:  Yah, that could have been exploited to allow cross-site scripting attacks, arbitrary code execution, and file theft.  So, yes, everybody, 120 security issues.  It may take all day to get it, and it costs $19.95, but probably a good idea.  Safari 6 also incorporates several new features, including a "Smart Search Field" that can be used to search and to input site addresses, and an Offline Reading List that allows users to save pages to a list to be read even when an Internet connection is not available.  Which would have been nice in 1997.  I don't know when an Internet connection is not available today.



LEO:  Hey, you know.



STEVE:  So I tweeted to @SGpad:  For $199, I am very impressed and loving the Google Nexus 7.



LEO:  Yeah, nice little tablet.  In fact, I've heard of a number of people who stopped using iPad.



STEVE:  Yeah, well, I'm not that.  But I did hear from someone who responded, saying that he used one of those "used devices, will buy your old stuff" sites, got so much money back that he was able to buy a Nexus 7 and take his girlfriend out to a nice meal.  So, and he's very happy.  And I am, too.  I have been - now what I've been doing is I carry it with me because I always have my iPad, a notebook, mechanical pencil, eraser, and the Kindle DX.  Now I've added to that, in a nice little case, I've added to that the Nexus 7 because I'm showing it to people, recognizing that there are people who aren't going to do an $800 iPad.  Especially when they've got kids.  One of my friends at Starbucks has a kid.  She bought him a new iPhone, and he dropped it in the toilet the first day he had it.  It's like, okay, well, this is not a kid you want to give anything really expensive to.



But for $199, I mean, and so I poked at it Saturday and Sunday at Starbucks in the morning.  And I installed Amazon, a couple free apps.  I poked around the Google Store.  I dug deep in and changed settings and things.  And it is what I wanted, which is it is responsive.  I mean, it's smooth.  It's a very impressive piece of work for 200 bucks.  So I just wanted to make sure everyone listening to the podcast had heard that.  I mean, it's - although I just saw some pictures of the expected 7-inch iPad toward the end of this year, and it looks pretty cute, too.  I don't know if those are real yet, but it looks like we're going to be getting that.  And we now know that it's going to be 1024x768, so the same resolution as the old iPad, the original iPad, in a smaller size.  But, boy, the Google Nexus 7, if you're, I mean, if you're just a counterculture person, if you don't want to do Apple, you want to do Android, it's a beautiful piece of work.



LEO:  And I actually like the 16x9 form factor.  Apple's tablet, if the rumors are true, it's going to be like an iPad, and that makes sense.



STEVE:  Will still be 4x3, yeah.



LEO:  And I have to say, even for reading - and we talked about this.  But I think even for reading this is a nice aspect ratio, and certainly for watching video.



STEVE:  And I meant to bring that up again.  What I did, "Damages" is in its fifth season.  It went to DirecTV, season four and five.  And so I was watching an episode of that.  And it was so nice not to have to mess with iTunes, also.  I just want to put this media on this tablet to go watch it.  And so the experience was completely nice.  It was widescreen.  And I did want to mention, Leo, that I'm not finding as much a problem with the 16x9 form factor as I expected.



LEO:  You were worried, yeah, I remember.



STEVE:  Although it would be nice if the home screen would also rotate.  The home screen insists on being in portrait.  It won't landscape.



LEO:  Yeah, I don't know if that's a setting, but I think that that makes sense.  Probably different launches would let you do that.  But it's hard to rearrange those icons.  Maybe on a 4x3 it isn't, but on a 16x9 there's such a difference between portrait and landscape that you really have to rearrange a lot of stuff.  I think that my - I'm interested in it, but I like Android.  But I was very interested to see the number of people who are very strong iOS supporters and iPad lovers say, yeah, you know what, it's actually - it was almost painful for them to admit, I think, it's actually not too bad.  Kind of like it.



STEVE:  Well, I feel like we're really seeing a lot of collision now in the patent territory.



LEO:  Well, yeah, that's another issue.  That's a huge issue, of course.



STEVE:  Yes.  I mean, so, for example, Apple, because they were there early and they did some good things on the iPhone, they locked down as inventions things which anybody else would have come up with if they'd been given the same problem.  And this is the problem with our patent system is that the actual law says that it is not subject to patent if it would be obvious to somebody trained in the art.  And I argue that a lot of what is having patents issued is just engineering.  It's just how do I zoom?  Oh, well, you pinch, and you expand.  Duh.  



LEO:  Well, I loved it when the judge said, hey, anyone can write a rangeCheck.  This was one of the issues, the patents in the Apple-Samsung case.  Anybody could write a rangeCheck.  I just wrote one yesterday.  I loved that.  And it's true.  That's an obvious patent.  It shouldn't have been made a patent.



STEVE:  Yup.  And so, for example, one of the things that I love on my BlackBerry is that I hold the key down, and it's initially lowercase, then it switches to uppercase.  Well, they have a patent on that, so nobody else can do that.



LEO:  That's too bad.



STEVE:  And so we're losing because of that, something which is arguably obvious.  It's like, well, okay, how...



LEO:  It's called "shift lock."



STEVE:  Yeah.  And so the problem is...



LEO:  You know, I completely forgot about that on BlackBerry.  I do miss that.  That's a great feature.  Now, fortunately, BlackBerry apparently didn't patent the double-tap spacebar to put a period, space, and start a new sentence, because that's now on everything.  Because that's useful, too.  And when you don't have that, you miss it.



STEVE:  Yes.  And so but what's happening is the ecosystem is being chopped up in pieces.



LEO:  Exactly, exactly.



STEVE:  And good features from something cannot appear on something else because of the ridiculous level at which we're issuing patents, which is really annoying.



So I mentioned last week, cryptically, something which you have seen, which I just thought I would share with our listeners.  And here it is:  GRC.com/animation.htm.  And this is - I've been writing some JavaScript.



LEO:  Actually, let me refresh it because it starts with 0000, so when you first get to it...



STEVE:  I have it do that because it makes it a little more clear than if just - I actually originally had it so it was just up and running immediately, but I like having it start that way.



LEO:  And then it gets the data.  There's a one, and now we're starting to see some data come in.  So what is this for, first of all?



STEVE:  So I've decided - there was somebody who asked on the podcast early this year, I think it was in January, he'd, like, looked around the GRC website and was trying to figure out what SpinRite was.  He's a listener to the podcast, and he wanted to buy it, but he thought it would be nice if he knew what it did.  And he said, "Is it a defragger?  Is it an undeleter?  What is it?"  And I thought, you know, I don't think I ever really explain that.



So I decided I ought to create a video, because everyone can see videos now, where I in a short period of time explain about hard drive data recovery.  Well, in order to explain about recovery, you need to explain about recording, I mean, how data is stored.  So I'm going to produce a video to explain what SpinRite does in a few minutes.  But I wanted some diagrams.  And to make them fun and interesting, I thought they should be animated also because animation is often the right way to explain something that's going on.  So GRC.com/animation.htm is just, more than anything, the page is 25k of code.  It actually does a lot more than what you'll see because that's the fourth of five frames that I've designed that will end up being part of the video.  But it's a nice little example of what can be done with JavaScript and the new HTML5 canvas API.



LEO:  Oh, that's interesting.  This is not like a PowerPoint slide.  This is done in HTML.



STEVE:  Yes, it's pure web coding.



LEO:  And JavaScript.



STEVE:  It runs beautifully on my iPhone, on my iPad, on my Nexus 7.  It does not run at all on my BlackBerry.  It's like you get about one frame every 30 seconds.  It's like, oh, just give up on the BlackBerry for web stuff.  But so it's universally cross-browser.  Since I'm in XP still, I wanted to see about IE.  But Microsoft, always the laggard here, didn't support the canvas API until IE9, and you can't run IE9 in XP.  But because IE is so far behind, Google created an add-on for IE which, if the developer adds a tag in the header of a web page, will invoke the Google Chrome frame, and then the page runs in essentially a transparent Google frame under IE.



LEO:  Oh, that's interesting.



STEVE:  So the point is that I'm in XP with IE8 and still able to look at this cool little animation, thanks to Google having created a frame for it.  So...



LEO:  GRC.com/animation.htm, if you want to test it on your particular browser.  Are you using any JavaScript libraries?  Or this is just the built-in JavaScript in the browser with HTML5?



STEVE:  All me, baby.  No libraries.



LEO:  No libraries.



STEVE:  In fact, there are no includes.  There's nothing else.  The page itself is the JavaScript.  So if anyone's curious...



LEO:  Oh, can I view source?



STEVE:  Yeah.



LEO:  Oh, how nice of you.



STEVE:  And it's commented and all that.



LEO:  That's seriously cool.  As somebody who you've convinced that I really should learn JavaScript, this will be a very useful example.  Thank you.



STEVE:  Yeah.  So speaking of SpinRite, I thought I would share a nice story from actually someone named Guy Story.  And he says KC5GOI.  Those sound like call letters; right?



LEO:  Yeah, that's a ham.



STEVE:  A call sign, KC5.



LEO:  Yeah.



STEVE:  Okay, KC5GOI.  He says, "I wanted to pass this on.  I am the network admin for a cancer treatment company in Dallas.  Today I received a phone call from the supervisor of our lab.  One of our remote offices had reported that their lab PC was giving the BSOD on boot."  Which we all know, those of us who have suffered through Windows, as the Blue Screen Of Death.  "When I arrived onsite I found that XP was at a BSOD and had an unmountable volume.  This system is under Dell Gold for troubleshooting, but not for hardware.  It is less than two and a half years old.  I'm still working to get that changed.



"So I booted up my personal copy of SpinRite and ran a Level 2 pass.  SpinRite worked for a while and reported that two sectors were beyond repair, but that it had been able to recover and repair three other sectors.  That appeared to be enough for XP and the needed application, since the system now ran perfectly.  I ran the Dell diagnostics after SpinRite.  I had to do this before calling Dell.  Funny thing, the Dell diagnostics said the drive was okay.  I guess it was, now that SpinRite fixed it.  I ran SpinRite first, since it tries to recover data.  The Dell app does not.  I suspect the Dell app is not as thorough as SpinRite."  Uh-huh, yeah.



"This PC does not store data, thus we do not have a regular backup of it.  I ran SpinRite to get the workstation back online.  Once I get the warranty issue fixed, we'll be rebuilding the workstation with a fresh drive.  Once that is finished and blessed, I'll be making a ghost copy of it, along with the other lab workstations.  If it was not for SpinRite, the employee would have had to rely on getting results faxed to her instead up pulling them up in real-time.  It would been midmorning the next day before she was back online.  I'm going to be pushing my employer to buy a corporate license from GRC.  Showing how SpinRite saved the day this time will make this an easier task.  Thanks, Steve."



LEO:  Aw.



STEVE:  And thank you, Guy, for sharing your story with me and our listeners.



LEO:  And thank you, Steve, for sharing your source code.  Boy, you're a clean coder.  Wow.



STEVE:  You know what I've realized, Leo?  The more I code, the more I appreciate how it's about communication.  Coding is communication.



LEO:  Not just with the computer, but with the human who might read this, including yourself.



STEVE:  With me when I come back later and go, okay, wait a minute.



LEO:  Boy, this is elegant.  Nice.  Nice.  I can't wait to kind of go through this.  That is great.  And by the way, it's really cool because this is the HTML I'm looking at.  By the way, Safari does a very nice of view source.  They've really got a code browser built-in here.  But the HTML, really there's very little HTML, it's just - it's the script.  It's all script.  It's very cool, very, very cool.



STEVE:  Yeah, I think there's, like, two lines of HTML where I declare the canvas and the size.



LEO:  And one of them is what happens if there's no script, no JavaScript enabled.  It's awesome.  Really beautiful.  That is gorgeous.  Wow.  I can't wait.  I'm going to get a good book, and I'm going to sit down, and I'm going to - I love language.  I collect languages.  And I've learned a lot of them.  But I think from a pure pragmatic point of view, learning JavaScript today is really useful.



STEVE:  I really think.  I mean, it is obviously, one, the world is moving to the client.  We're seeing more and more Google-ish sorts of the app-is-the-client approach.  It just makes sense.



LEO:  Yeah.  Very nice.  Hey, let's take a break.  And then we're going to get to Ali Baba's Cave.  Ooh.  Okay.  This is going to be one where some steam might come out of your ears.



STEVE:  I think so.



LEO:  That just means things are working right.  All right.  Get ready.  We are about to enter the Cave of Ali Baba.  Steve?



STEVE:  Okay.  So I was talking at the beginning of the show about how we have, in traditional crypto protocol descriptions, we talk about Alice, Bob, and Carol.



LEO:  From the movie "Ted and Bob and Carol and Alice," a '70s movie.



STEVE:  That's right.  When we're talking about zero-knowledge interactive proofs, we use characters Peggy and Victor as the prover and the verifier.



LEO:  Oh, I like that.



STEVE:  Now, in the formalization, the academic formalization of what is a zero-knowledge interactive proof, there are three requirements to, like, qualify for valid zero knowledge.  And I'm going to go through these first before we talk about Ali Baba because you'll see how these come into play in the story, which will immediately follow.



So the first is completeness.  The property of completeness says that the verifier always accepts the proof if the fact is true and both the prover and the verifier follow the protocol.  So that's like the formal way of saying, if everything is done right, and the actors here act properly, then the verifier always gets what he needs.  So that's called completeness, in this case, of the proof.  The verifier always accepts the proof if the fact is true and both the prover and the verifier follow the protocol.



The second property is the property of soundness.  The verifier always rejects the proof if the fact is false, as long as the verifier follows the protocol.  So completeness says, if it's true, the verifier will come to that conclusion.  Soundness is sort of the reverse.  It says, if it's false, the verifier won't arrive at a false positive.  The verifier will reject the proof.  And so that's the requirement of soundness for the zero-knowledge interactive proof.



And finally - and this is the one that's a little tricky, but the story does cover it in a clever way - the property of zero knowledge is the verifier learns nothing about the fact being proved - except that it's correct - from the prover that he could not already learn without the prover, even if the verifier does not follow the protocol, as long as the prover does.



LEO:  Let me see if I understand this.  Didn't we talk about this last week in the question-and-answer where it said, when you log in, shouldn't it tell you if you got the email right or if you got the password right?  Like if you got one thing wrong, just which one you got wrong.  Is that the same as zero knowledge?  It's leaking knowledge.



STEVE:  Yes, because, for example, this property goes on to say, in a zero-knowledge proof the verifier cannot even later prove the fact to anyone else.  And that's really key.



LEO:  That's key.  That's the key.



STEVE:  So, again, the verifier learns nothing about the fact being proved, except that it's correct, from the prover that he could not already learn without the prover, even if he does not follow the protocol.  And in a zero-knowledge proof the verifier cannot later prove the fact to anyone else.



Okay.  So now we need to talk about Ali Baba, which I just love saying, "Ali Baba."  I like saying that like "coconut."  I love the word "coconut."  And "Ali Baba."



LEO:  Okay.  You're just strange.  Now it's just getting weird.



STEVE:  So, very long ago, in the Eastern city of Baghdad, there lived an old man named Ali Baba.



LEO:  [Laughing] I love how this is beginning.



STEVE:  Every day Ali Baba would go to the bazaar to buy or sell things.  This is a story which is partly about Ali Baba and partly also about a cave, a strange cave whose secret and wonder exist to this day.  But I'm getting ahead of myself.



LEO:  This is so cool.



STEVE:  One day in the Baghdad bazaar, a thief grabbed a purse from Ali Baba, who right away started to run after him.  The thief fled into a nearby cave whose entryway forked into two dark, winding passages, one off to the left, the other off to the right.  Ali Baba, who was following, did not see which passage the thief ran into, though he did see him enter the main entrance.  So Ali Baba had to choose which way to go, and he decided to go to the left.  The left-hand passage ended after a while in a dead end.  Ali Baba searched all the way from the fork at the beginning to the dead end, but he did not find the thief.



Ali Baba said to himself that the thief must have been in the other passage.  So he searched the right-hand passage, which also came to a dead end.  But again he did not find the thief, figuring that the thief probably left from the right-hand passage while he was busy searching the left.  "This cave is pretty strange," said Ali Baba to himself.  "Where has my thief gone?"



The following day another thief grabbed Ali Baba's basket and fled, as the first thief had fled into the strange cave the day before.  Once again Ali Baba pursued him, and again did not see which way the thief went.  This time, however, Ali Baba decided to search to the right.  He went all the way to the end of the right-hand passage, but did not find the thief.  He said to himself that, like the first thief, the second thief had also been lucky in taking the passage Ali Baba did not choose to search first.  This had undoubtedly let the thief leave again and to blend quietly into the crowded bazaar.



Days went by, and every day brought its thief.  Ali Baba always ran after the thief, but never caught any of them.  On the 40th day, a 40th thief grabbed Ali Baba's turban - boy, he's down to his turban - and fled, as 39 thieves had done before him, into the strange cave.  Ali Baba yet again did not see which way the thief went.  This time Ali Baba decided to search the left-hand passage; but, again, he did not find the thief at the end of the passage.  Ali Baba was very puzzled.  He could have said to himself, as he had done before, that the 40th thief had been as lucky as each of the other 39 thieves.  But this explanation was so far-fetched that even Ali Baba did not believe it.  The luck of the 40 thieves was just too good to be a matter of chance.  There was only one chance in a million million that all of the 40 would escape.



Now, pausing for a second, we know that there's a 50-50 chance, given that the two tunnels dead-end, and Ali Baba has to choose one.  Every time he chooses he's got a 50-50 chance.  40 days, 40 thieves, that's 2^40, which is 1.1 times 10^12, which is in fact 1.1 million million.  So that would be the chance, if the cave is as Ali Baba suspects or believes at this point, that in 40 tries he could never once catch the thief.  That's very unlucky.



So Ali Baba said to himself that there must be another, more likely explanation.  He began to suspect that the strange cave guarded a secret.  And Ali Baba set out to discover the secret of the strange cave.  He decided to hide under some sacks at the end of the right-hand passage.  After a very uncomfortable wait, he saw a thief arrive.  Sensing he was pursued by his victim, the thief whispered the magic words "Open Sesame."  Ali Baba was amazed to see the wall of the cave slide open.  The thief ran through the opening, then the wall slid closed again.  The pursuer arrived and was all upset to find only Ali Baba hiding under the sacks at the dead end of the passage.  The thief had escaped.  But Ali Baba was happy, for he was finding out the secret of the strange cave.



Ali Baba experimented himself with the magic words.  He discovered to his amazement that, when the wall slid open, the right-hand passage was connected with the left-hand passage.  Now Ali Baba knew how all of the 40 thieves had escaped from him.  The very next day a thief was caught.  Ali Baba recorded this story and his discovery in a lovely illuminated manuscript.  He did not write down the new magic words, but included some subtle clues about them.  Ali Baba's lovely illuminated manuscript arrived in Italy in the Middle Ages, and today it's in the United States, somewhere near Boston.



LEO:  Wow, that's specific.



STEVE:  There it recently acquired the full attention of several curious researchers.  Through decryption of the subtle clues, these researchers rediscovered the magic words.  After several archeological excavations in the ruins of the old Baghdad bazaar, the strange cave was relocated.  It was not a myth after all.  And despite the centuries, the magic words still worked.  All agog, which is not a word you hear very often...



LEO:  One of my favorites.  Right up there with coconut.



STEVE:  All agog - ooh, coconut - the curious researchers went through the end wall between the two passages.  The television networks were quickly made aware of the unusual events taking place in Baghdad, and a big American network even got an exclusive on the story.  One of the researchers, whom we'll call Mick Ali, perhaps a descendant of Ali Baba, wanted to demonstrate that he knew the secret, but he did not want to reveal the secret.  Here's what he did:



First, a television crew filmed a detailed tour of the cave with the two dead-end passages, just like Ali Baba had found all those centuries ago.  Then everyone left the cave.  Mick Ali went back in alone and went down one of the passages.  Then the reporter, accompanied by the camera, went inside only as far as the fork, where he flipped a coin to choose between right and left.  If the coin came up heads, he would tell Mick to come out on the right.  If the coin came up tails, he would tell Mick to come out on the left.  It was heads.  So the reporter called out loud, "Mick, come out on the right."  And Mick did just that.



In memory of the 40 thieves, this demonstration scene was played 40 times.  Each of the times, everybody went back out of the cave, and Mick entered alone, all of the way down one of the passages, which he chose first.  Then the reporter and the camera went as far as the fork, where a coin was tossed, giving Mick the order which cave to come out of.  Mick succeeded all 40 times.  Anybody who did not know the secret of the cave would have been exposed on the first failure.  Each new test divided by two the chances of success for someone without the secret.  On the other hand, the secret allowed Mick to come out each time through the required tunnel.



Employed by another television network, a jealous reporter wanted to also film a story about the strange cave.  But Mick, honoring his nondisclosure and his exclusivity, refused to participate because he had given exclusive rights to the story to the first network.  But Mick mischievously suggested to the jealous reporter that the story could be filmed without possessing the secret.  The jealous reporter thought about that for a minute and then smiled to himself.  He said, "I even know a stage actor who looks like you and who could be mistaken for you."



And the second story was filmed.  In the course of the filming, half of the scenes were spoiled because Mick's double did not know the magic words and so could not get from one passage to the other as required to succeed every time.  So the jealous reporter simply edited the tape and only kept the successful scenes until he had 40 of those.



The two stories were aired at the same hour on the same evening by the two competing American networks.  And the matter went to court because it was believed that somehow this exclusivity was broken.



LEO:  Oh.  Even here, patent problems.



STEVE:  Yes.  Both videotapes that were aired at the same time on the same night were placed into evidence, but the judges and the experts could not tell the tapes apart.  Which tape was simulated?  Which tape was genuine?  The tapes alone were not enough to judge by.  The simulation surely conveyed - now, here's the cool part.  The simulation surely contained no knowledge of the secret because no knowledge of the secret was involved in creating the simulation, so it couldn't have any knowledge of the secret.  But the simulation and the genuine tape were indistinguishable from one another.  Thus the genuine tape also did not convey any knowledge of the secret.



The reporter who had gotten the exclusive story had been convinced at the time that Mick Ali knew the secret, and he was still convinced.  But the reporter, despite all of his efforts in court, was unable to pass his conviction on to the judges.  Or onto the television audience, either, because of course now he had a tape that was judged to be a fraud, or might be, because the other network had aired the same thing, apparently showing exactly the same miracle of this Ali Baba's Cave.  So Mick Ali had achieved his real objective.  He wanted in fact to show that it is possible to convince without revealing, and so without unveiling his secret.  And that's the story of Ali Baba's Cave.



LEO:  And what have we learned from this, Steve?



STEVE:  Okay.  So what does this tell us?



LEO:  Yes, what does this tell us?  It's clever, first of all.



STEVE:  Yes, it is.  So the cave construction is something we see in many discussions because it's so clear that it's a real-world, physical, simple-to-understand example of how someone could prove something without revealing what it is by statistically demonstrating that they have a fact which they need to use in order to produce an outcome, yet the fact itself is not part of the outcome.  And that's the key.  So they're in command of something, some knowledge, and they must use the knowledge in order to prove an outcome.



But what's interesting is that this is a statistical result, a statistical proof.  That is, we don't know with absolute utter certainty, even after 40 trials, that the person didn't actually just get phenomenally lucky because they could have.  And we know that it's one in 1.1 million million chances, given 2^40, with each one having a 50-50 chance.  But it's diminishingly unlikely that somebody without the knowledge could still provide this outcome.



So if we look back again at our three requirements, the formal requirements for zero-knowledge proof, the requirement for completeness is that the verifier will always accept the proof, if the fact is true and both the prover and the verifier follow the protocol.  So clearly, in our little cave model, we have that.  Which is to say that the verifier, understanding statistics and understanding everything about the structure of what's happening, but only lacking the knowledge of what's required to cross from one tunnel to the other, the verifier accepts the proof that the prover, Peggy, has the ability to cross tunnels by testing enough.  So this gives us completeness.



Soundness is the property that the verifier will reject the proof, if the fact is false, as long as the verifier follows the protocol.  So here, this would be, if Peggy were unable to cross between the backs of the tunnels in the cave, then all it would take would be one time that Victor the verifier says come out on the right; Peggy, unfortunately, went down the left tunnel.  She can't, no matter how much she wants to, come out on the right because, if she doesn't have that fact, she can't prove her knowledge, then that gives us the property of soundness.



And finally, the property of zero-knowledge is the verifier learns nothing.  So the verifier, Victor, out in front, learns nothing about the fact being proved, except that it is correct, from the prover that he could not already learn without the prover, even if the verifier does not follow the protocol.  In a zero-knowledge proof, the verifier cannot even later prove the fact to anyone else.  And that's probably one of the coolest things about this.



So Victor and Peggy, if we place them in the cave, Peggy can demonstrate her ability, her knowledge, as many times as Victor wants her to.  Yet when they're done, they emerge from the cave, Victor says, "She absolutely definitely can cross between tunnels."  And someone says, "Prove it."  And Victor can't.  He knows because, with absolute statistical close-to-zero probability, he's absolutely sure.  Yet he obtained nothing from the experience that he can pass on to anyone else.  And this may seem rather abstract and wacky.  There are some applications for exactly this that we will be covering in the future.



LEO:  Did you write this story yourself?  Or is this from somewhere?



STEVE:  I found it, and I modified it a little bit.



LEO:  It's good.



STEVE:  Yeah, yeah.



LEO:  It's good.  Did you add the TV part, or was that in there?



STEVE:  No, it was written - actually, I excerpted some stuff that wasn't relevant for our purposes.  And it was originally in French, and it was translated into English.



LEO:  Wow.  Very interesting.



STEVE:  Yeah.  If you put in Google, like, "zero-knowledge and kids," or something, it's sort of meant to be a kids' story, a way of, like, explaining...



LEO:  Oh, yeah, yeah.  "How to Explain Zero-Knowledge Protocols to Your Children."  The chatroom has given this to me.  You guys are good.  It's by Jean-Jacques Quisquater and a few other people.



STEVE:  Louis, yeah.



LEO:  Yeah, Louis Guillou.  Wow, that's hysterical.  That's so good.  There's illustrations.  Not very good ones, but...



STEVE:  Yeah.  Not very good ones.  And you do run across this tunnel analogy all over the place.  I mean, even in formal crypto papers.  I have about five of them that I read in order to see whether there was anything, you know, in order to get myself the depth of understanding that I wanted.  And they have much better graphics, but they're much less fun.



LEO:  This was really interesting.



STEVE:  And so I thought that Ali Baba's Cave was something that our listeners will now never forget.



LEO:  Now, it says "How to Explain Zero-Knowledge Protocols to Your Children."  I doubt that very many children would really - but it's a good story.



STEVE:  It's a great story.



LEO:  I'm not sure they would come away with it saying, "Oh, Daddy, now I understand.  Zero-knowledge."  You're great.  I love it.  Steve Gibson is at GRC.com.  That's the Gibson Research Corporation.  That's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility.  Everybody should have a copy of SpinRite.  You'll also find lots of other things for free there, including his health and nutrition information that Steve's done some really interesting work with.  Somebody was in here a couple of days ago, said "When is Episode 3 of the Sugar Hill?"  Do you plan one?



STEVE:  I feel like we ought to do a follow-up.



LEO:  Yeah.



STEVE:  But there are a couple other things I really want to talk about.  Magnesium is another component of health that I think is very critical, that we're all deficient in.  And I have quite a story...



LEO:  Oh, I'd love to hear that.



STEVE:  ... about my magnesium adventure.



LEO:  All right.  Well, maybe we'll do another one.



STEVE:  So if I can squeeze some more of your time free, Leo, I do think that there's a segment of our audience that appreciates it.  And boy, I can tell you that the first two episodes have really helped a chunk of our listeners.



LEO:  Helped me.



STEVE:  They're less chunky, in fact.



LEO:  I'm a lot less chunky there.  Actually, Saturday afternoons at 2:00 p.m. will soon be open, so that's a good time to do it, if you want to do it then.



STEVE:  Okay.  I'll keep it in mind.



LEO:  Keep that in mind when you feel up to it.  "Sugar Hill 3" starring Wesley Snipes.  It's coming to a theater near you.  Also, GRC.com has 16Kb versions of this show for the bandwidth impaired, full text transcripts, always helpful.  And we make audio and video versions available on our site, TWiT.tv/sn.  We do the show, and you can watch live, if you want to challenge your brain, in real-time, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, Wednesdays at TWiT.tv.  That's 1800 UTC.  Steve, thanks so much.



STEVE:  Always a pleasure.  And we'll be back next with a Q&A episode.  If any listeners have something in particular that is tickling their brain, they're wondering about or troubled by, drop a note to GRC.com/feedback.  I'll get it, and we'll go through the mailbag, which I did hear from several people saying, hey, I'm still familiar with the term "mailbag."  I don't think it's obsolete at all.



LEO:  Well, yeah.  In fact, I don't know we thought this, but every mail carrier has a mailbag still.



STEVE:  Yeah, or a box.



LEO:  My mailman comes around with a big old bag with a big leather strap and a little sheepskin on the shoulder pad.



STEVE:  Perfect.



LEO:  Yeah.  And shorts.



STEVE:  Of course, you are in Mayberry.



LEO:  We live in Mayberry, so we still have Andy, Opie, and the barber shop's just around the corner.  Floyd will be glad to cut your hair for 50 cents.  Thank you, Steve.



STEVE:  Thanks, Leo.  Talk to you next week.



LEO:  On Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#364

DATE:		August 8, 2012

TITLE:		Mat Honan's Weekend

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-364.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with an eventful week of security news, Steve and Leo describe and explore the details of the "epic hack" that recently befell well-known technology writer Mat Honan.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here, and it's very topical.  We're kind of going to change up what we normally do.  This would normally be a Q&A show.  But given the big hack that happened to Mat Honan, writer for Wired magazine, Wired.com this week, Steve's going to talk about the hack, how it happened, and, most importantly, what lessons we have learned.  Mat Honan's Very Bad Weekend, we'll talk about it next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 364, recorded August 8th, 2012:  Mat Honan's Very  Bad Weekend.



It's time for Security Now!, the show that protects you, your loved ones, and your privacy, whenever you're online or off.  Well, we can't protect you from some things, but we do our best.



STEVE GIBSON:  And anywhere in between.



LEO:  Anywhere in between.  Our Explainer in Chief, Mr. Steve Gibson, is here, the man at GRC.com, creator of SpinRite, world's finest hard drive maintenance and recovery utility, lots of free utilities.  We've been doing this show now, this is Episode 364.  Which means normally, nominally, it would be a Q&A episode.  Not so this time.



STEVE:  Well, yes.  We had one set up for this week.  Yet what happened was, late last week, on Friday, something happened to a well-known industry technology reporter, Mat Honan, involving - essentially he described it as the end of his digital life, I mean, a complete hacking of his digital life.  You had him on your main TWiT podcast on Sunday, which I watched.  And then he wrote about this in greater detail the following day, Monday of this week.  And what we have, thanks to Mat's having untangled this and him having conversations with various involved parties, including the guys who hacked him, we believe, is now an understanding of how this was done.  And I can't think of anything more on point for this podcast than us taking a close look at this.



And then, once we understand it, we'll discuss, Leo, how it happened sort of from a meta level;  what our takeaways are; what, if anything, we can do; and sort of the state of the industry's security.  So we'll catch up with news stuff.  And then I want to share what Mat wrote on Monday and then take our listeners through sort of a forensic timeline that I've assembled from that because what Mat shares is a little bit out of sequence, and it's great for drama, but it leaves us a little not quite understanding how it happened.  So I put it all together.  And then we'll talk about what it means.



LEO:  I would also be very interested in, yeah, in talking about what we do in response because it certainly made me completely rethink what I thought was a secure setup and change some things.



STEVE:  Yes.



LEO:  And so I'd love to get your advice on that.



STEVE:  One of the things we're going to see - and again, we couldn't invent a more compelling scenario than what actually happened last Friday to this nice, well-meaning person.  As a consequence, all the photos he ever took of his newborn daughter are hanging in the balance.



LEO:  Well, there's good news I think on that.  I think the forensics that Apple was able to do, the good news is that the overwrite hadn't happened yet.  So I've hooked him up with friends of mine in the drive data recovery business up at DriveSavers, and I hope that he will get his pictures back.  But that's the end of the story.  We're going to go back in time to Friday in just a little bit.  Also know you have some things to talk about including Mars.  All right.  Before we go to the "Honan Hack," as it is becoming known as, is there any other security news?



STEVE:  Well, the most interesting kerfuffle is - Ed Bott and a number of other people reported this.  I mentioned Ed because he was also on TWiT on Sunday.



LEO:  Yeah, love Ed.



STEVE:  Great old-timer in our industry whom you and I have known forever.  And that is that Microsoft has announced that, indeed, IE 10, the next version of Internet Explorer, which will run on Windows 7 and presumably 8, will in fact have Do Not Track enabled by default.



LEO:  Oh.  So this - they went back and forth on this.



STEVE:  They have.  Well, because there is such pressure against having this done coming from, as Ed described it,  the "tracking industry."  I got a kick out of that.  I thought, oh, the tracking industry.  There is a working group at the W3C that are putting together the specs for the Do Not Track header.  And as we know, it's an optional request header, meaning that it's metadata, not part of the URL.  It's additional stuff that the browser sends to the server for every request for pages and gifs and jpegs and images and scripts and everything.  And so every request would be embellished with this little statement saying that this user wishes not to be tracked, wishes not to have this query tied into other queries, not to have cookies linked and all the tricks that are used.



And so we're aware now that many browsers, I think we're at all browsers at this point, can have this optionally, but normally it's disabled.  Microsoft is the first, and I'm delighted because, as we know, I coined the term years ago "the tyranny of the default," which is sort of the expression I like to use for that most users don't go in and change things.  They just assume that someone smarter than them chose the settings that are best for them, and so they just say "yes" a lot when they're asked questions.



So what that means is that, if it's enabled by default, it'll tend to stay on, which the tracking industry doesn't want to have happen.  In fact, they're pushing the spec to state that browsers will have it disabled by default so then they can claim that Internet Explorer is not obeying the standards and can use that as their basis for ignoring the header.  So we have a little ways to go.  But it's clear that we're on the right track.



What Microsoft has said is that their express setup for IE 10 will enable it by default and make it clear that this is Do Not Track, that the request not to be tracked is enabled.  And that'll be part of the express setup.  If you use the custom setup, you'll be taken through more of a Q&A, like do you want this, do you want that, what do you want to be default search, do you want to disable - do you want to request not to have tracking?  And even there I would imagine most people are going to say, yeah, I'd rather not be tracked.  So this is a big event for the industry because Microsoft, even though most of us are no longer using IE, those of us within earshot of this podcast are probably on Chrome or Firefox with various...



LEO:  It's still a huge number of people.



STEVE:  The majority, I mean, it's still got - it's still the majority platform.



LEO:  Still the No. 1.



STEVE:  Yes.  So what they do matters.  And it does pave the way for other browsers that have added the header, but not yet taken the leap to enable it by default.  It paves the way for them to do that.  So that was this week's biggest news over on the security and privacy front.  The other big news I got a kick out of, as I'm sure you did, in fact I guess Tom was up and broadcasting as Curiosity was making its phenomenal, multiphase, can-you-even-believe-they-pulled-it-off landing.



LEO:  That's a good way to describe it.  I had, and I think a lot of geeks did because I saw pictures on Instagram and stuff, many screens open.  I had our live coverage.  I had NASA.  I had CNN, just to see what CNN was doing on the television.  And CNN's shameful coverage was just ridiculously stupid.  NASA was great.  And we had some great interviews.  We had Phil Plait, the Bad Astronomer.  We had Steve Sell, the guy in charge of the crane.  We had Dr. Kiki and, of course, Tom Merritt.  So I was really proud of it.  But you know what shocked me is how little attention this got.  I'm shocked.



STEVE:  I'm with you completely.  The next morning I specifically fired up a browser to look for news, and there was other stuff happening.  I mean, it did collide with the Olympics, and that's been a major passion for people for the last week and a half.  But still...



LEO:  Yeah, well, that happens every four years.  This has never happened.



STEVE:  Well, long-time listeners of this podcast will remember that I have always kept us aware of those cute little rovers, Spirit and Opportunity.  Some dust storm would come up and cover their solar panels in red Martian dust, and then they would power themselves, they would wind down as their batteries discharged.  And JPL, the Jet Propulsion Lab, would think, well, okay, that's probably it.  They started in the beginning of '04, and these little suckers just kept going.  I mean, they were the Energizer bunnies of Mars.  And then a wind would come up a few months later, blow the red dust off of the solar panels, they would charge themselves back up and ping JPL.  And it's like, oh, they're back.



LEO:  [Happy machine noises]



STEVE:  And off they would go again.  So who knows how long Curiosity is going to be driving around the surface.  But with any luck we'll have many years of keeping tabs on it.  So as I see things, I would love our people who are in Twitter to make sure that I know what's going on, and I'll pass that news on to our listeners.



LEO:  It was so exciting.



STEVE:  It was fun to watch those two cute little guys who just kept on going, year after year after year.



LEO:  Well, and, now, those were little guys.  This is a science lab.  I mean, this is a significant...



STEVE:  This is an SUV.  We dropped an SUV on Mars.



LEO:  Yeah, and it's got mass spectrometers, it's got the 3D stereoscopic camera, I mean, this thing, just the pictures we're already getting back are amazing.  And I just can't wait to see what we discover.  And it is a return, in some ways, I think, to space flight.  The debate, of course, goes on and on about manned versus unmanned missions, and you can do so much with unmanned missions, and it's so much safer and less expensive.  But I do think the reason there was less attention is because there was no human aboard.  Had there been a human, of course, the world would have been mesmerized.



STEVE:  Yeah.



LEO:  And that's why you put humans on these things.  I don't know if it's a good enough reason.  But that is why you do it.



STEVE:  Yeah, it's funny, I've watched our general sort of lack of interest.  And people have, like, wondered, why isn't this generating the same sort of attention that our original space exploration was?  And one of the things that has occurred to me is that, well, we don't have photon torpedoes.  These are boring compared to the stuff that we now...



LEO:  For chrissake, we hung a crane in the air and lowered the thing.  It was about the coolest thing I've ever seen.



STEVE:  Oh, I agree.  I mean, this really did happen.



LEO:  This was almost photon torpedo quality, I'm telling you.  But anyway, I do think that what I did see was that there was a bifurcation, that normal people didn't even know about it.  But everybody who watches TWiT, I was in there with a community.  There were a thousand people in the chatroom.  We had more people watching that space coverage late at night than watched TWiT earlier in the evening.  I'm convinced that the geeks, the Internet, the people who are into this stuff, were very much aware of it.  And that's why we're going to do more of that kind of stuff here on TWiT.  I think this is our job.



STEVE:  If Gene Roddenberry had written this landing sequence, and it was in one of the Star Trek episodes, we would have thought, oh, come on, you can't ever do that.



LEO:  I thought, oh, come on.  There's no way.



STEVE:  No, and this was real.



LEO:  And they couldn't test it.  It was too bizarre to even test.  They just had to do it, and they did it.  And brilliant.



STEVE:  Well, speaking of cars driving around Mars, we have cars driving around Nevada.  Nevada granted Google a license for its driverless cars to drive on public streets.  And the news came out that Google has passed 300,000 accident-free miles.  And I saw something that I just didn't have time to drill down, but maybe you know more about this, where they said they were going to start allowing the cars to drive their employees to work.



LEO:  I didn't see that, but that's great.



STEVE:  Before long.  So...



LEO:  Well, it's legal in California, or at least they've been doing it in California for some time.  And I know that...



STEVE:  On public streets?



LEO:  Oh, yeah.



STEVE:  Whoa.



LEO:  Oh, yeah, for years.  Now, I don't know if it is legal.  I think that what they do is they - the guy's hovering his hands over the wheel or something.  I don't know how they're getting away with it.



STEVE:  Very nervous copilots.



LEO:  The state of California, along with the state of Nevada and several other states in the union, are passing these laws that will make this legal.  I think this is very exciting.  Notice, by the way, they said 300,000 accident-free miles, but they said 300,000 miles free of accidents while under autonomous control.  The cars did have some fender benders while the guy was driving.  It was the autonomous control that was safe.



STEVE:  Hal just says, "Dave, let go of the wheel, I've got this."



LEO:  "I'm sorry, Dave.  Take your hands off the wheel, Dave."



STEVE:  So on my stair climber I am reading "Kill Decision," which is Daniel Suarez's third book.



LEO:  Awesome.



STEVE:  And I just wanted to recommend it.



LEO:  It's good.



STEVE:  I'm reading it slowly because I only allow myself to read it when I'm huffing and puffing.  But, oh.



LEO:  He is so good, isn't he?



STEVE:  It is really developing nicely.



LEO:  And tech topics, absolutely, I mean, he's so good on tech.  And the topics that he covers are - you know he's going to be on Triangulation this afternoon at 3:00 p.m. Pacific, 6:00 p.m. Eastern time, 2200 UTC, Daniel Suarez.  And I have so many questions for him.  You know, is Raconteur real?  Is there anything like this out there?  It's just fascinating.



STEVE:  Yeah, he gets this stuff.



LEO:  Oh, yeah.



STEVE:  Well, he gets the tech right so that it's satisfying.  But it's very well put together.



LEO:  There's some very challenging stuff in here.  It's very interesting.



STEVE:  Yeah, it's great.  Now, I heard you talking, I guess it must have been on Sunday when I had tuned in to listen to Mat and you talk, about "Total Recall," which I saw with Jen on Monday.



LEO:  Oh, good.  What did you think?  Because I love the - it's a Philip K. Dick book, which of course is brilliant.



STEVE:  And I loved the old, the original Schwarzenegger movie.



LEO:  "Get yourself to Mars.  Why am I standing here with a towel on my head?"  Great stuff.



STEVE:  There is a sense, and maybe it's me being as old as I am, where I'm feeling a little impatient with movies that just have action for its own sake.



LEO:  I know, I'm the same way, and maybe it is age.  There's just so much of it.



STEVE:  It's like, okay, come on, let's get on with the plot.  It's like...



LEO:  Another car chase?  Really?  Really?



STEVE:  Yeah, it's like those "Transformer" movies.  It's just like, okay, we know we've got CG figured out.  I can't tell the difference between what's real and not anymore, so thank you very much.  But let's just not fill 45 minutes of the movie with gratuitous, nonstop action.  That's just no longer that interesting.  So I'm very excited about the new Bourne movie that comes out at the end of this week.  And I'm glad I saw "Total Recall."  But it's like, eh, okay.



LEO:  I re-watched the old Arnold version, just getting ready for this.  And it is a little dated, but it's such a fun movie.



STEVE:  It's just - it's well done.



LEO:  I mean, kind of cheesy.  It just has, you know, the '80s, well, they didn't have the computer effects and all that stuff.  It all had to be real and rubber.



STEVE:  That had Johnny Cab in it, didn't it.



LEO:  "You're in a Johnny Cab."



STEVE:  "You're in a Johnny Cab," that's right.  I thought so.



LEO:  Was there no Johnny Cab in the new one?



STEVE:  Oh, no, we didn't have that.



LEO:  "You're in a Johnny Cab."



STEVE:  I mean, visually this thing was spectacular.  And I said to Jen, as I remembered feeling when I was watching "Avatar," I'm wide-eyed, and I'm looking at these scapes, and I'm thinking, how do you make this movie?  I mean, this is just - this isn't real, yet it looks perfect.  I mean, just like huge city stuff that doesn't exist, and there it all is, fully imaged.  Anyway, we're at a point now where we're just in sensory overload.  It's just incredible what...



LEO:  So you recommend seeing it, but don't expect a miracle.



STEVE:  Yeah, I think that "The Amazing Spider-Man" is still my favorite.



LEO:  That's the one you liked the best, yeah.



STEVE:  And I saw, of course, the new Batman, or the final of the third.  And it was good.



LEO:  I liked it.  I liked it better than I thought I would, to be honest.



STEVE:  Good, I'm glad you saw it.



LEO:  It was better than I thought it would be.  But I haven't seen...



STEVE:  And, boy, it's doing well in the box office.



LEO:  Yeah, interesting.



STEVE:  I wanted to share a brief, actually almost only a couple of sentences, from a Mike Kruzel, who was kind enough - actually this was a posting in our newsgroup.  I noticed that it's from grc.spinrite, which is the SpinRite newsgroup at news.grc.com.  And he said, "I have two Dell Dimension 4600C computers, and the main computer I use crashed over the weekend, giving the message 'Primary hard disk 0 not found.'"  That's never good.  He says, "I ran SpinRite 6, and in about five hours it repaired the drive, and Windows booted back up.  I did run Windows XP chkdsk in recovery mode, once before and then once after SpinRite.  Thanks for its work.  Mike."



LEO:  Good.



STEVE:  So, yeah, another...



LEO:  Usually, if you can't see drive 0, I mean, you can't see it, you can't fix it; right?  I guess it was Windows that couldn't see it.



STEVE:  It was Windows that couldn't see it.  But the BIOS, it was still physically there, so that was good enough.



LEO:  Anyway, now, let's tell this story.  Oh, boy.



STEVE:  Yes.  So Mat Honan is a well-known technology writer.  And this is a little dramatic, but this is the best way to introduce our listeners into what you and I now understand happened.  And then we'll go back and build a timeline forensically because Mat puts this out in a little bit of a jumbled sequence.



LEO:  And I have to say, first let me say right upfront, I've known Mat for years.  Really like the guy.  He's really the real deal, very smart.  And, yes, he made mistakes, as we all have, I think, in time.  But I'm grateful.  I talked to him last night.  He said, "This is a hard story for me to cover because it just kills me that this happened."  But at the same time, and I told him this, he said, "I think I'm making a difference."  I said "Mat."



STEVE:  Oh, he's done a service.



LEO:  Huge service.



STEVE:  No doubt about it.  So on Monday the story he wrote in Wired, in his "Gadget Lab" column, it was titled "How Apple and Amazon Security Flaws Led to My Epic Hacking."  And as you said, Leo, as we'll shortly see, he's really not laying it all off on them.  And our listeners will soon see that this can happen to anybody.



He says, "In the space of one hour, my entire digital life was destroyed.  First my Google account was taken over, then deleted.  Next my Twitter account was compromised and used as a platform to broadcast racist and homophobic messages.  And worst of all, my Apple ID account was broken into, and my hackers used it to remotely erase all of the data on my iPhone, iPad, and MacBook.



"In many ways, this was all my fault.  My accounts were daisy-chained together.  Getting into Amazon let my hackers get into my Apple ID account, which helped them get into Gmail, which gave them access to Twitter.  Had I used two-factor authentication for my Google account, it's possible that none of this would have happened because their ultimate goal was always to take over my Twitter account and wreak havoc.  Lulz.  



"Had I been regularly backing up the data on my MacBook, I wouldn't have had to worry about losing more than a year's worth of photos, covering the entire lifespan of my daughter, or documents and emails that I had stored in no other location.  Those security lapses are my fault, and I deeply, deeply regret them.  



"But what happened to me exposes vital security flaws in several customer service systems, most notably Apple's and Amazon's.  Apple tech support gave the hackers access to my iCloud account.  Amazon tech support gave them the ability to see a piece of information  a partial credit card number  that Apple used to release information.  In short, the very four digits that Amazon considers unimportant enough to display in the clear on the web are precisely the same ones that Apple considers secure enough to perform identity verification.  The disconnect exposes flaws in data management policies endemic to the entire technology industry and points to a looming nightmare as we enter the era of cloud computing and connected devices. 



"This isn't just my problem.  Since Friday, Aug. 3, when hackers broke into my accounts, I've heard from other users who were compromised in the same way, at least one of whom was targeted by the same group.  Moreover, if your computers aren't already cloud-connected devices, they will be soon.  Apple is working hard to get all of its customers to use iCloud.  Google's entire operating system is cloud-based. And Windows 8, the most cloud-centric operating system yet, will hit desktops by the tens of millions in the coming year.  My experience leads me to believe that cloud-based systems need fundamentally different security measures.  Password-based security mechanisms  which can be cracked, reset, and socially engineered  no longer suffice in the era of cloud computing. 



"I realized something was wrong at about 5:00 p.m. Friday afternoon.  I was playing with my daughter when my iPhone suddenly powered down.  I was expecting a call, so I went to plug it back in.  It then rebooted to the setup screen.  This was irritating, but I wasn't concerned.  I assumed it was a software glitch.  And my phone automatically backs up every night.  I just assumed it would be a pain in the ass and nothing more.  I entered my iCloud login to restore, and it wasn't accepted.  Again, I was irritated, but not alarmed.



"I went to connect the iPhone to my computer and restore from that backup  which I had just happened to do the other day.  When I opened my laptop, an iCal message popped up telling me that my Gmail account information was wrong. Then the screen went gray and asked for a four-digit PIN.  I didn't have a four-digit PIN [on my laptop].  



"By now, I knew something was very, very wrong.  For the first time it occurred to me that I was being hacked.  Unsure of exactly what was happening, I unplugged my router and cable modem, turned off the Mac Mini we use as an entertainment center, grabbed my wife's phone, and called AppleCare, the company's tech support service, and spoke with a rep for the next hour and a half.



"It wasn't the first call they had had that day about my account.  In fact, I later found out that a call had been placed just a little more than a half an hour before my own.  But the Apple rep didn't bother to tell me about the first call concerning my account, despite the 90 minutes I spent on the phone with [him].  Nor would Apple tech support ever tell me about the first call voluntarily.  It only shared this information after I asked about it.  And I only knew about the first call because a hacker told me he had made the call himself. 



"At 4:33 p.m., according to Apple's tech support records, someone called AppleCare claiming to be me.  Apple says the caller reported that he couldn't get into his .Me email  which, of course, was my .Me email.  In response, Apple issued a temporary password.  It did this despite the caller's inability to answer security questions I had set up.  And it did this after the hacker supplied only two pieces of information that anyone with an Internet connection and a phone can discover.  



"At 4:50 p.m., a password reset confirmation arrived in my inbox.  I don't really use my .Me email, and rarely check it.  But even if I did, I might not have noticed the message because the hackers immediately sent it to the trash.  They then were able to follow the link in that email to permanently reset my [own] Apple ID password.  At 4:52 p.m., a Gmail password recovery email arrived in my .Me mailbox."



LEO:  Uh-oh.



STEVE:  "Two minutes later, another email arrived notifying me that my Google account password had changed.  At 5:02 p.m. they reset my Twitter password.  At 5:00 they used iCloud's 'Find My' tool to remotely wipe my iPhone.  At 5:01 they remotely wiped my iPad.  At 5:05 they remotely wiped my MacBook.  Around this same time, they deleted my Google account.  At 5:10, I placed the call to AppleCare.  At 5:12 the attackers posted a message to my account on Twitter, taking credit for the hack.



"By wiping my MacBook and deleting my Google account, they now not only had the ability to control my account, but were able to prevent me from regaining access.  And crazily, in ways that I don't and never will understand, those deletions were just collateral damage.  My MacBook data  including those irreplaceable pictures of my family, of my child's first year and relatives who have now passed from this life  weren't the target.  Nor were the eight years of messages in my Gmail account.  The target was always Twitter.  My MacBook data was torched simply to prevent me from getting back in.  Lulz," he writes.  



"I spent an hour and a half talking to AppleCare.  One of the reasons it took me so long to get anything resolved with Apple during my initial phone call was because I couldn't answer the security questions it had on file for me.  It turned out there's a good reason for that.  Perhaps an hour or so into the call, the Apple representative on the line said, 'Mr. Herman, I....' 



"'Wait.  What did you call me?'



"'Mr. Herman?'



"'My name is Honan.' 



"Apple had been looking at the wrong account all along.  Because of that, I couldn't answer my security questions.  And because of that, it asked me an alternate set of questions that it said would let tech support let me into my .Me account:  a billing address and the last four digits of my credit card.  Of course, when I gave them those, it was no use because tech support had misheard my last name.



"It turns out a billing address and the last four digits of a credit card number are the only two pieces of information anyone needs to get into your iCloud account.  Once supplied, Apple will issue a temporary password, and that password grants access to iCloud.  Apple tech support confirmed to me twice over the weekend that all you need to access someone's Apple ID is the associated email address, a credit card number, the billing address, and the last four digits of a credit card on file.  I was very clear about this.  During my second tech support call to AppleCare, the representative confirmed this [to me]:  'That's really all you have to have to verify something with us,' he said.  



"We talked to Apple directly about its security policy, and company spokesperson Natalie Kerris told Wired, 'Apple takes customer privacy seriously and requires multiple forms of verification before resetting an Apple ID password.  In this particular case, the customer's data was compromised by a person who had acquired personal information about the customer.  In addition, we found that our own internal policies were not followed completely.'"  I'll just interject here that that turns out not to be true.  Continuing, she said, "We are reviewing all of our processes for resetting account passwords to ensure our customers' data is protected." 



"On Monday" - so that's three days later, Monday the beginning of this week - "Wired tried to verify the hackers' access technique by performing it on a different account.  We were successful.  This means, ultimately, all you need in addition to someone's email address are those two easily acquired pieces of information:  a billing address and the last four digits of a credit card on file.  Here's the story of how the hackers got them.  



"On the night of the hack, I tried to make sense of the ruin that was my digital life.  My Google account was nuked, my Twitter account was suspended, my phone was in a useless state of restore, and for obvious reasons I was highly paranoid about using my .Me account for communication.  I decided to set up a new Twitter account until my old one could be restored, just to let people know what was happening.  I logged into Tumblr and posted an account of how I thought the takedown had occurred.  At this point, I was assuming that my seven-digit alphanumeric Apple ID password had been hacked by brute force.  In the comments" - and he says, in parens, "(and, oh, the comments)" - "others guessed that hackers had used some sort of keystroke logger.  At the end of the post, I linked to my new Twitter account.  



"And then, one of my hackers @ messaged me.  He would later identify himself as Phobia.  I followed him.  He followed me back.  We started a dialogue via Twitter direct messaging that later continued via email and AIM.  Phobia was able to reveal enough detail about the hack and my compromised accounts that it became clear he was, at the very least, a party to how it went down.  I agreed not to press charges, and in return he laid out exactly how the hack worked.  But first, he wanted to clear something up:  'Didn't guess your password or use brute force.  I have my own guide on how to secure emails.' 



"I asked him why.  Was I targeted specifically?  Was this just to get to Gizmodo's Twitter account [that had been linked to mine]?  No, Phobia said, they hadn't even been aware that my account was linked to Gizmodo's, that the Gizmodo linkage was just gravy.  He said the hack was simply a grab for my three-character Twitter handle.  That's all they wanted.  They just wanted to take it, and [mess it] up, and watch it burn.  It wasn't personal.  



"'I honestly didn't have any heat towards you before this.'"  I'm quoting.  "'I just liked your username, like I said before,' he told me via Twitter direct message.  



"After coming across my account" - which, by the way, is cool, it's "mat," so @mat, a very nice Twitter account, which he clearly, as you mentioned on Sunday, Leo, got very early.



LEO:  Deeply regrets.  And got it early.



STEVE:  He says, "After coming across my account, the hackers did some background research.  My Twitter account linked to my personal website, where they found my Gmail address.  Guessing that this was also the email address I used for Twitter, Phobia went to Google's account recovery page.  He didn't even have to actually attempt a recovery.  This was just a recon [mission].  Because I didn't have Google's two-factor authentication turned on, when Phobia entered my Gmail address, he could view the alternate email I had set up for account recovery.  Google partially obscures that information, starring out many characters, but there were enough characters available, m****n@me.com.  Jackpot.



"This was how the hack progressed.  If I had some other account aside from an Apple email address, or had used two-factor authentication for Gmail, everything would have [been] stopped [there].  But using the .Me email account as a backup told the hacker I had an Apple ID account, which meant I was vulnerable to being hacked.  'You honestly can get into any email associated with Apple,' Phobia claimed in an email.  And while it's work, that seems to be largely true.  Since he already had the email, all he needed was my billing address and the last four digits of my credit card number to have Apple's [Care] tech support issue him the keys to my account.  



"So how did he get this vital information?  He began with the easy one.  He got the billing address by doing a WHOIS search on my personal web domain.  If someone doesn't have a domain, you can also look up his or her information on Spokeo, WhitePages, and PeopleSmart.  Getting a credit card number is trickier, but it also relies on taking advantage of a company's backend systems.  Phobia says that a partner" - that is, a partner of his - "performed this part of the hack, but described the technique to us, which we were able to verify via our own tech support [phone] calls.  It's remarkably easy  so easy that Wired was able to duplicate the exploit twice in minutes.  



"First, you call Amazon and tell them you are the account holder and want to add a credit card number to the [existing] account.  All you need is the name on the account, an associated email address, and the billing address.  Amazon then allows you to input a new credit card."  And he says, parens, "(Wired used a bogus credit card number from a website that generates fake card numbers that conform with the industry's published self-check algorithm.)  Then you hang up. 



"Next, you call back and tell Amazon that you've lost access to your account.  Upon providing a name, billing address, and the new [credit] card number you gave the company on the prior call, Amazon [now allows] you to add a new email address to the account.  From here, you go to the Amazon website and send a password reset to the new email account.  This allows you to see all the credit cards on file for the account  not the complete numbers, just the last four digits.  But, as we know, Apple only needs those last four digits.  We asked Amazon to comment on its security policy, but didn't have anything to share [at] press time. 



"And it's also worth noting that one wouldn't have to call Amazon to pull this off.  Your pizza [delivery] guy could do the same thing, for example.  If you have an Apple ID, every time you call Pizza Hut, you've giving the 16 year old on the other end of the line all he needs to take over your entire digital life.  And so, with my name, address, and the last four digits of my credit card number in hand, Phobia called AppleCare, and my digital life was laid waste.



"Yet still I was actually quite fortunate.  They could have used my email accounts to gain access to my online banking or financial services.  They could have used them to contact other people and socially engineer them, as well."  Which actually is a point that Ed Bott brought up on your TWiT show the day before Mat wrote this.  Oh, and he says, "as Ed Bott pointed out on TWiT.tv."



LEO:  Oh.



STEVE:  "My years as a technology journalist have put some very influential people in my address book.  They could have been victimized, too.  Instead, the hackers just wanted to embarrass me, have some fun at my expense..."



LEO:  Lulz.



STEVE:  "...and enrage my followers on Twitter by trolling.  I had done some pretty stupid things, things you shouldn't do.  I should have been regularly backing up my MacBook.  Because I wasn't doing that, if all the photos from the first year and a half of my daughter's life are ultimately lost, I will have only myself to blame.  I shouldn't have daisy-chained two such vital accounts  my Google and my iCloud account  together.  I shouldn't have used the same email prefix across" - that is, his name portion - "mhonan@gmail.com, mhonan@me.com, and mhonan@wired.com.  And I should have had a recovery address that's only used for recovery, without being tied to core services. 



"But mostly I shouldn't have used Find My Mac.  Find My iPhone has been a brilliant Apple service.  If you lose your iPhone or have it stolen, the service lets you see where it is on a map.  The New York Times' David Pogue recovered his lost iPhone just last week, thanks to the service.  And so when Apple introduced Find My Mac in the update to its Lion operating system last year, I added that to my iCloud options, too.  After all, as a reporter, often on the go, my laptop is my most important tool.  



"But as a friend pointed out to me, while that service makes sense for phones, which are quite likely to be lost, it makes less sense for computers.  You are almost certainly more likely to have your computer accessed remotely than physically.  And even worse is the way Find My Mac is implemented.  When you perform a remote hard drive wipe on Find my Mac, the system asks you to create a four-digit PIN so that the process can be reversed.  But here's the thing:  If someone else performs that wipe  someone who gained access to your iCloud account through malicious means  there's no way for you to enter that PIN.  



"A better way to have this set up would be to require a second method of authentication when Find My Mac is initially set up.  If this were the case, someone who was able to get into an iCloud account wouldn't be able to remotely wipe devices with malicious intent.  It would also mean that you could potentially have a way to stop a remote wipe in progress.  But that's not how it works.  And Apple would not comment as to whether stronger authentication is being considered. 



"As of Monday" - when he was writing this - "both of these exploits used by" - and I'm still reading from what he wrote.  Mat writes:  "As of Monday, both of these exploits used by the hackers were still functioning.  Wired was able to duplicate them.  Apple says its internal tech support processes weren't followed, and this is how my account was 



compromised.  However, this contradicts what AppleCare told me twice that weekend.  If that is, in fact, the case, that I was the victim of Apple not following its own internal processes, then the problem is widespread.  



"I asked Phobia why he did this to me.  His answer wasn't satisfying.  He says he likes to publicize security exploits so companies will fix them.  He says it's the same reason he told me how it was done.  He claims his partner in the attack was the person who wiped my MacBook.  Phobia expressed remorse for this and says he would have stopped it had he known.  'Yeah, I really am a nice guy.  IDK'" - I don't know - "'why I do some of the things I do,' he told me via AIM. 'IDK, my goal is to get it out there to other people so eventually everyone can overcome hackers.'



"I asked specifically about the photos of my little girl, which are, to me, the greatest tragedy in all this.  Unless I can recover those photos via data recovery services, they are gone forever.  On AIM, I asked him if he was sorry for doing that.  Phobia replied, 'Even though I wasn't the one that did it, I feel sorry about that.  That's a lot of memories.  I'm only 19, but if my parents lost the footage of me and pics, I would be beyond sad, and I'm sure they would be, too.' 



"But let's say he did know and failed to stop it.  Hell, for the sake of argument, let's say he did it.  Let's say he pulled the trigger.  The weird thing is, I'm not even especially angry at Phobia or his partner in the attack.  I'm mostly mad at myself.  I'm mad as hell for not backing up my data.  I'm sad and shocked and feel that I am ultimately to blame for that loss.  



"But I'm also upset that this ecosystem that I've placed so much of my trust in has let me down so thoroughly.  I'm angry that Amazon makes it so remarkably easy to allow someone into your account, which has obvious financial consequences.  And then there's Apple.  I bought into the Apple account system originally to buy songs at 99 cents a pop, and over the years that same ID has evolved into a single point of entry that controls my phones, tablets, computers and data-driven life.  With this Apple ID, someone can make thousands of dollars of purchases in an instant, or do damage at a cost that you can't put a price on."



LEO:  Well, and I'll give you a couple of PS's.



STEVE:  Yes.



LEO:  First of all, the good news is - you know, I don't know why Apple didn't ask Phobia for the PIN.  Maybe he did, and it wasn't given to him.  But Apple was able to apparently brute-force it because it's only four digits.  And they say that the data will be on that hard drive.  So I've hooked the man up with the folks at DriveSavers, and I think they'll be able to get his data back.



STEVE:  Good.



LEO:  So dodged a bullet on that one.  The other good news, and I'm sure you're going to say this, but we should say it right upfront, is that both Apple and Amazon have, in response to this, changed their systems.



STEVE:  Yes.



LEO:  Amazon permanently; Apple, it's not clear.



STEVE:  Yes, exactly.  So, okay.  Let me just - I'm going to briefly recount in sequence, adding a little more detail than Mat did.  So this began sometime mid to early afternoon on Friday, August 3rd, when one or more hackers just took a shine to an unknown person's Twitter account because they say it was three characters.  It was @mat.  They didn't know anything about him.  Didn't know who he was, just thought, hey, that's cool.  And I don't know how many followers he had.  I checked yesterday, and it was not hundreds of thousands.  So maybe they got lost in the account transfer or freeze or something.  I mean, it didn't look like there was a huge - it's nothing like what you have following you, Leo.  So I don't know.  Or maybe it's because it's linked to Gizmodo.



LEO:  It's so complicated.  He may not have been able to bring his followers with him.  And by the way, these guys, and I have corresponded a little bit with Phobia on Twitter, and his partner in crime, and they've got something going on because his partner in crime has a Twitter account that has 122 tweets and over 100,000 followers.  So there's something going on.  My suspicion would be they have more access to Twitter than they have acknowledged.  There's something.  Or maybe they've created 100,000 bots.  I don't know.



STEVE:  Well, so apparently, not knowing anything about Mat, but just liking @mat, they do some recon.  They see that, from the information on his Twitter account, @mat, which is where this whole thing starts, that account links to honan.net, which is Mat's personal website.  They go there, and they find his Gmail account, mhonan@gmail.com.  They access Gmail's account recovery, putting that in as their email address.  And because there's no additional protection - and this is what we're going to talk about here in a second, Leo.  The lack of two-factor authentication means that account recovery information is unprotected, and that account's alternate email address is visible, but obscured.  So what they see is m****n@me.com.



LEO:  Don't really have to guess what those are.



STEVE:  No.  They already saw mhonan@gmail.com.  So they realize, okay, he's used - and that's what Mat refers to in the article as using the same first name across his accounts.  So that of course allows them to guess Mat's Apple ID and Cloud address.  The hacker also does a WHOIS search on Mat's personal web domain to get more information.  Now, I've done that, and you could do that, Leo.  I'm not going to share what it shows because it's horrifying.



LEO:  Yeah. This is an argument for WHOIS privacy.



STEVE:  I'm annoyed that, at least if you're a Network Solutions customer, as I am, they want to charge you to obscure this.



LEO:  I should point out that Hover does not.  So if you do a WHOIS on our TWiT.tv or any of our sites, you'll get the administrative contact and technical contact addresses will be a company called Contact Privacy in Toronto, Canada, not us.



STEVE:  And that does not cost you anything?



LEO:  No.  That's one of the reasons I like Hover.



STEVE:  Good.  So what's here in this WHOIS is, right now, I mean, I did it an hour ago, and it's like, okay, Mat, fix this because here is way too much information exposed publicly still.  So Wednesday morning.  Okay.  So now they've got his street address.  They've got his, I don't know if this is a landline or a cell phone, but that's there, too.  And ZIP code, the works.  And a bunch of email addresses.  So now someone calls Amazon wanting to add an additional credit card to Mat's account.



LEO:  Now, this is kind of, I think, key because this is social engineering, not a technical hack.  This is not a MySQL attack.



STEVE:  How many times are we arguing about how many bits the crypto key has to have?



LEO:  Right, right.



STEVE:  No bits came into play here.



LEO:  Right.  I don't consider doing a WHOIS anything particularly technical.  And that's really all they were doing.  This is social engineering, 100 percent.



STEVE:  Well, and also, frankly, I am really glad that this whole story came to light and that Mat, I mean, I'm so sorry for his loss of data and the embarrassment and everything.  But the way Amazon was set up, and as you said, they are no longer, and that's like, thank goodness.  But someone was very clever to put this together.  Here's the Amazon portion.



So you call Amazon on the phone, and you say you want to add an additional credit card.  What do you need?  The name, which of course they have, Mat Honan; the email address associated with the account.  Now, they guessed that he would be using Gmail.  He was, so mhonan@gmail.com.  There were two ways to get that:  Twitter to website to Gmail, or WHOIS because Mat's WHOIS had that, too.  And as we know, email addresses are not hard to find.  And the billing address, which they got, right there, from WHOIS.  So that allowed them to invent a credit card and stick it on the account.



Then they hang up, and they call back.  They're going to get somebody else.  Now they say they've lost access.  What do you need to gain access?  The name, which we already know they have; the billing address, which they have; and the last four digits of any one credit card registered on the account.  So they gave the four digits of the one they'd just added a second before, and that allowed them to add a new email address to the account.  So now they've added an email address they control, which they don't yet have.



Then they go to the website and say, we can't log in.  Send us a password reset.  So, and we're going to see this a bunch, and this is one of the issues that this whole thing brings up is the use of email for password recovery, which is the weak link in much of this.  So they get an email address they control into the account, ask for password reset.  That sends them a link allowing them then to log into Mat's Amazon account, where they can see everything he's ever purchased and all of his actual credit cards.  Well, they see the one that they just spoofed and added, and they see his real one.



Now they have the last four digits of Mat's main card, and they've already got his name, email addresses, and billing address, which is the same as his home address.  So at 4:00 p.m., with all this information, the hacker calls AppleCare, impersonates Mat, claiming that he'd forgotten the password to his mhonan@me.com account, which they now know.



LEO:  These guys, I'll say one thing, they're ballsy.



STEVE:  They are, yes.



LEO:  They've got a lot of nerve.  And I think to do this you have to be good at acting.



STEVE:  Yes. 



LEO:  I think.



STEVE:  Yes, I completely agree.  You've got to sound convincing.  Although, frankly, I've had some calls from my credit card company where I wished the other guy was an actor.  I can barely understand what he's saying.



LEO:  Yeah.  Maybe not.  Apple can't make a judgment about its users.  And this is the whole point is Apple is trying to make it easy for users.



STEVE:  Yes.  Unfortunately, these systems fail open, rather than failing closed.  So he says, "I've forgotten the password, mhonan@me.com.  I need a temporary password so I can access my account."  Despite the fact that the hacker fails all the security questions, doesn't know any of Mat's security questions, the backup that Apple provides, or provided, maybe that's over, we're not sure yet, is, well, if you can't remember your security questions, how about your billing address and the last four digits of your credit card that they have on file?  Which of course they now have, thanks to the game they played over at Amazon.



LEO:  Probably other ways to get it, too.  It's fairly easy to do this; right?  I mean, it's not much to ask.



STEVE:  Well, and this was also the point that he makes about the Pizza Hut guy.



LEO:  He knows that.



STEVE:  When you phone for pizza, you give them your address because you'd like it delivered, and you give them your credit card number over the phone.  So they've got that.  And how many places now are we seeing people asking for your email address because we'd just like to inform you of any...



LEO:  Stay in touch, yeah.



STEVE:  Yeah, exactly.  So Apple issues a temporary password which allows the hacker to log into iCloud and Mat's mhonan@me.com email account.  And this is - this is one point that's important - this is in keeping with Apple's official Care policies at the time.  This was not a mistake.  And that's a point that Mat made, and I've read similar things coming at this from different directions about this earlier this week.  So it is not the case that that one spokesperson misspoke.



Okay.  That was at 4:33.  At 4:50, Apple sends the password reset link to Mat's mhonan@me.com account.  The hackers log in with a temporary password.  They receive and delete the password reset email, not that it really matters, and they reset Mat's password, locking Mat out of his own Apple ID and iCloud account.  Two minutes later, 4:52, Google Mail password recovery email arrives at Mat's mhonan@me.com account.



So what they did was they went back over to Google, where they had visited before, where they saw that he had a .Me account.  They do password recovery at Google which sends the recovery link to the .Me account, so they click that.  That gives them access to Mat's Gmail account.  They change his Gmail password, locking him out of his Gmail account.  Two minutes later, 4:54, mail arrives at .Me informing Mat, who can no longer log into there, either, that his Google Mail password has been changed.  So the notice goes out that the password change has been effective, but Mat can't see that because he's already been locked out of his accounts.



A few minutes later, at 5:00 p.m., with access to Mat's Apple ID and iCloud account, hackers remotely wipe Mat's iPhone.  A minute later, at 5:01, they remotely wipe Mat's iPad.  A minute later, at 5:02, the Twitter account password is reset, so a reset comes.  The password is changed.  So they now have taken over his Twitter account, Mat's locked out of his very cool @mat account, and hackers have achieved their intended goal.  A couple minutes later, having verified that, at 5:05, to prevent Mat from having any tools to regain control, they remotely wipe Mat's not-backed-up MacBook containing, as we know, his only copies of his newborn daughter's photo collection and pics of older relatives who've passed away.



At 5:10, five minutes after that, Mat notices his iPhone has been cleared and places his first 90-minute call to AppleCare.  Two minutes later, hackers, having control of @mat Twitter account, post a message to Mat's account taking credit for their actions.  So Wired successfully repeated many of these alleged hacks, verifying them through the weekend and into the beginning of the week.  Apple has reacted, as reported by Wired.  Wired said:



"Apple on Tuesday" - so that's the day before we're recording this, that would be Tuesday the 7th.  "Apple on Tuesday ordered its support staff to immediately stop processing Apple ID password changes requested over the phone.  An Apple worker with knowledge of the situation, speaking on condition of anonymity, told Wired that the over-the-phone password freeze" - on obeying this change request - "would last at least 24 hours. The employee speculated that the freeze was put in place to give Apple more time to determine what security policies needed to be changed, if any."



When Wired tried the exploit again:  "The representative said that the company was going through system-wide 'maintenance updates' that prevented anyone from resetting any passwords over the phone.  The rep said we should try calling back after about 24 hours, and directed us to iforgot.apple.com to change Apple ID passwords ourselves [using] the web instead.  'Right now, our system does not allow us to reset passwords,' the Apple rep told Wired.  'I don't know why.'



"In an earlier attempt on Tuesday to change an Apple ID password (which is the same password used to log into iCloud and iTunes), Apple customer service offered up a different response, saying that passwords could only be changed over the phone if we were able to supply a serial number for a device linked to the Apple ID in question  for example, an iPhone, iPad or MacBook computer.  The rep also suggested changing our Apple ID password online at appleid.apple.com or iforgot.apple.com."



On the Amazon side, also via Wired:  "Amazon changed its customer privacy policies on Monday, closing security gaps that were exploited in the identity hacking of Wired reporter Mat Honan on Friday.  Previously, Amazon allowed people to call in and change the email address associated with an Amazon account or add a credit card number to an Amazon account, as long as the caller could identify him or herself by name, email address, and mailing address  three bits of personal information that are easily found online.



"On Tuesday, Amazon handed down to its customer service department a policy change that no longer allows people to call in and change account settings, such as credit cards or email addresses associated with its user accounts.  Amazon officials weren't available for comment on the security changes, but during phone calls to Amazon customer service on Tuesday, representatives told us that the changes were sent out [that] morning and put in place for 'your security.'"



LEO:  Good.



STEVE:  So there is the story.  Yes.  Very, very good.



LEO:  So what have we learned?  In other words, I think the think that people really want is to know, well, what should I be doing so that I can make this harder?  I don't know if you could make it impossible, but what should I be doing to make it harder?



STEVE:  Clearly, the thing - how many times have we seen that convenience is the enemy of security?  What was so convenient for Mat was, first of all, that mhonan was the same email, whether it had the suffix of Gmail or .Me or - there was another one.  There were three.



LEO:  You don't want readily guessable email addresses.  So that's No. 1.



STEVE:  You don't want that.



LEO:  You could guess my email address on every service I use.  Every one. 



STEVE:  We all know your email address, Leo.



LEO:  Yeah.  But, I mean, so I failed at that.  And it would be a bit of a pain to go change all that, to be honest.  I have to get new accounts.



STEVE:  In fact, we made the comment last week when we were talking about Outlook.com, that there was a land rush to log in and lock down...



LEO:  Right, get your name.



STEVE:  ...your name on Outlook.com.



LEO:  But truthfully, knowing my email address, because I'm never going to have a - knowing my email address shouldn't - I guess what I could do is create some dummy email addresses that are the ones I use just for accounts and account verification; right?



STEVE:  Well, yes.  That's the big problem.  So on one side, one aspect of convenience was that Mat happened to use mhonan as an available account name across his services, such that it was obvious for the attackers to make the jump from his Gmail email address over to his Apple ID address, just by guessing.  So there's that.  But the main focus of convenience is that Gmail - everything pointed to Gmail.  His Twitter account recovery was Gmail.  His Apple ID recovery.  His Amazon billing address was Gmail.  Everything went there, which was also where he conducted all of his other business.  His website pointed there.



So that single account makes a person's life very much easier.  But unfortunately, that's the source, that's the major aspect of insecurity over which we have control.  We have no control over Amazon's policy.  And frankly, this was tricky enough that this gives me the creeps because I know from the dialogue that you shared with me that you had with these people we believe them to be, I guess last night, they said they know how to do this kind of thing against other services.



LEO:  Right.  I asked him, I said, if you were going to hack me, how would you start?  And he described this process.  He says, well, the first thing we want to do is get as much information as publicly online.  We search for you.  We want your "docs," he called them.



STEVE:  Right.



LEO:  And the problem is a lot of this stuff is online.  Even down to home address, which is, if you've ever bought a house, is public information.  It is out there.  Or contributed to a campaign, or any number of things.



STEVE:  We're also seeing a trend, I mean, I'm seeing this in the news, that the next generation of people growing up in this social networking environment, they sort of take it for granted, and they're putting their lives online.  There are people who are regretting it now because I'm seeing, for example, that in employment interviews they're asking for all of your social networking account names so they can go do research on you.  They're not using a rsum, they're going out and looking at your Facebook and who are your followers and digging into your lives.  So the people who are growing up in this environment, to a greater degree than you and I, Leo, I mean, I just checked, do I have iCloud on anything, or the "wipe my device," and it's like, no.  I just sort of...



LEO:  That is a very risky thing.  And yet handy, especially for a laptop.  I mean, to be able to wipe your portable device is great if it gets stolen.  It's a form of security.  The problem really is that Apple makes it a little too easy for somebody to hijack your account and then wipe your stuff.



STEVE:  Well, yes.  And that's a problem that is an outgrowth of the real problem, which is to this day the only means, the universal means for authenticating someone is demonstrating control of an email account.  That's the issue.  Are you the person who receives mail?  Now, the really frightening thing, I mean, if we want to look at that, is that email is unencrypted.  This is all going across the wire in plaintext.  Web sessions increasingly, as we know, are protected by SSL, HTTPS.  But email generally is not.  And so here are all these links for account recovery flying back and forth, and those are literally the keys to the kingdom.



So the problem is that, even today, in this day and age, at this point we don't - nobody has YubiKeys built in.  We're not all carrying Google Authenticator or VeriSign Identity Protection tokens or the "something you have" approach.  Which is why I loved that little tidbit we just heard about Apple sort of experimenting with you need to tell us the serial number of your device.



LEO:  That's a good one, yeah.



STEVE:  Yes.  That's good.  That's not something...



LEO:  Of course, if your device has been stolen...



STEVE:  Yes.  And unfortunately, once it becomes widespread, it'll be like your Social Security number.  It'll be posted and available and in databases for people to check and so forth.  So unfortunately we're just really bad at managing this kind of information.  I'm annoyed, for example, when I get statements like privacy statements from my credit card companies, and they're saying unless you send this back and tell us no, we're going to do the following things.  And I look at what they're - and it's like, share your personal information with our business partners.  Unspecified, just anybody who we think we want to do business with, unless you tell us we can't.  I say, wait a minute?  Why is this opt-out rather than opt-in?  So that's a problem.



But back to what we can do.  We know there are beginning to be second-factor authentication.  One of the problems is, these hackers whom you had the conversation with and whom Mat spoke with, they said, all we need is information.  Information.  When, you know, they made phone calls.  The essence of these attacks, as you said, they had to be rather bold because this was not something done all online.  This was people on the phone providing information.  So there was nowhere here, as we have discussed in multifactor authentication many times, something you have.  This was all something you know.  It was security questions, it was last four digits of your credit card number, all of this something you know, not something that you physically possess.



So I would say that the right thing to do, the best thing we could do - because, again, we cannot control the policies of all the companies we do business with.  I'm glad this happened.  I'm glad Amazon got a wakeup call.  I'm glad Apple got a wakeup call.  They're two biggies, but they're not certainly the only people that may have hackable policies.



LEO:  Well, and these guys claim they have many other companies with similar bad policies that they can take advantage of.



STEVE:  Precisely.  So you really want to bifurcate your - because email confirmation loops are the only way we have, still, for doing password recovery, you want to consciously separate completely an email account for those sorts of purposes from the ones you normally use during the day.  It's going to be less convenient.  It would be much easier if they were all going to the same place.  But you'll want to use a different account name.  You'll want to use a domain name, maybe, that is different.  But you also want an account where, to the best of your ability, it looks like they honor tight recovery.



I know, for example, even PayPal, I'm set up with my football that I'm still using, the six-digit time-varying code, and a VIP token on my phone, so I'm able to use it when I'm away from home.  But right there, underneath the challenge for those, is "Click here if you don't have it with you."  What?



LEO:  Right.  Almost every time.  Right.  Because, again,  convenience trumps security.



STEVE:  Yeah.  The point is, I'm promising I'm going to have it with me.  And I went looking around.  Is there any way I can say take that exception off?  I want the security of having to have what I'm telling you I will have, and you're telling me I have to have, except you're telling me I don't have to have it.



LEO:  Right, yeah.  So you've got to wonder, well.



STEVE:  Yeah.



LEO:  And that's the problem, by the way, with security questions because people don't remember them.  Then they go, okay, well, you don't need it.  All you need is the last four digits - or they did.  All we need is...



STEVE:  We're sorry you forgot your question.



LEO:  Just give us your email and last four, we'll call it a day.



STEVE:  Yeah.



LEO:  You know, I wanted to ask you specifically about two-factor authentication on Google.



STEVE:  Yes.



LEO:  And  Google has a particular problem.  Now, Facebook has turned on, or has available and you should turn it on, two-factor authentication.  And what it will do is it will send a code - actually, you have to use the Facebook app on your smartphone.  It will give you a code which you can then enter if you're going to log in on an unrecognized machine.  I think that's great.  The problem with Google...



STEVE:  So that probably means that they leave a persistent cookie on the machine.



LEO:  They do.



STEVE:  And then from then on...



LEO:  It's a known machine; right.



STEVE:  ...when that machine is being used.  Okay, that's cool.



LEO:  And you can, I presume, you can revoke those cookies and so forth.  I'm pretty sure there's somewhere you could say, I don't recognize any of these devices, let's start over.



STEVE:  Right.



LEO:  Now, Google has second-factor authentication, but it's more tricky for Google because, not only do you log into your Google account on the web and on Google applications, both of which understand second-factor authentication, there are a great many third-party applications that do not.  So what Google is required to do, if you turn on second-factor authentication, is give you one-time-use passwords which are all, by the way, alphanumeric.  Now, they're only one-time use, so that's probably okay.  They're not strong passwords.  And now, for instance, if I want to use - I have a calendar app that I use that uses Google Calendar.  Instead of using my Google password to log into this, I have to use this one-time authentication code.  And then, it's a pain in the butt, but that expires, in some cases every 30 days, in some cases in unknown ways.  And you've got to go generate another one and use it again.



And that seems to me, besides being a pain in the neck, and I keep trying to turn this thing on, and I always turn it off because I have so - I'm a little different than most people.  I have many, many devices with many - and they're all logging into Google eMail, Google Calendar, Google Voice.  That means I have to enter these in all the time.  I have dozens of one-time passwords.  It seems to me, if I have a strong password on Google and - and this I think is the most important thing people can do on Google - have attached a cell phone number for account recovery to it, that's not done by default...



STEVE:  And not link it to another address...



LEO:  And link it to a separate address that nobody knows, which I've done, that that's going to be as good as the second, well, not theoretically as good, but practically as good as second-factor authentication, and certainly...



STEVE:  Yes.  And more practical for you to use because, as we know, if it becomes a pain, it'll get turned off.



LEO:  Right.



STEVE:  Despite our best intentions and our desire to be secure, convenience will trump that, ultimately.



LEO:  Right.  If everything supported second-factor authentication, I could use that Google Authenticator to generate that, then I'd be happy.  I don't mind entering my password and a code for my cell phone.  But having to go back to the web, get a one-time-use password, enter it in, and it has to be entered manually in many cases because I can't cut and paste because it's not on the same device...



STEVE:  Now, are these, like, startup problems where the two-factor authentication has not yet permeated Google's ecosystem?



LEO:  I would guess, yeah.  It's not Google.  These are third-party apps.  So a lot of apps, for instance, are designed to get Gmail.  But they're not Google apps.



STEVE:  Oh, I got it.



LEO:  Or to get your calendar.  But they're not Google apps.  So even desktop apps.  So you can no longer, because you've turned on second-factor authentication, just use your Google password to open those apps up.  So Google creates for you a one-time-use password.



STEVE:  And do you want to use those, or do you have to use those?



LEO:  You have to use those.



STEVE:  Okay.  No, I meant those apps.



LEO:  Oh, well, if I'm using a smartphone, yeah.  So if you're using an iPhone, for instance, it doesn't support the second-factor authentication.  You have to use this one-time pass to get in there.  And that one-time pass, again, I think it's 12 digits, or 12 letters.  It's alphanumeric, all uppercase.  So it's not super-secure one-time use, I gather, but I'm not convinced.  And I have seen that there are ways to bypass.  So I've decided that it's just too inconvenient.  I'm not recommend this to people.  You should all turn on second-factor authentication on Google.  But for me it's just too much trouble.



And so in fact what I'm doing is I've got an account recovery phone number.  I think that that's a good way.  If he had had that, he could have recovered his Gmail account, changed the password, and they would have been locked out again.  Now, in the interim they would have gotten in to everything else, but...



STEVE:  Yeah.  Actually it was their access to Gmail that allowed them to get to Twitter.  And that was really where they wanted to get.  So it was because Twitter was pointing to Gmail, as was Apple, as was Amazon, everything was converging there on Google Mail because Mat is Google-centric, as a huge number of us are.





LEO:  Most of us are.  Many of us are, yeah.



STEVE:  Yeah.



LEO:  So diversity, heterogeneity is a very good idea. 



STEVE:  Yeah.  And being conscious of the fact that, unfortunately, where we are today, email password recovery is the only universally available solution, so it's what everybody offers.  And unfortunately, it's not something you can turn off.  It would be nice if there was a way to say I will take responsibility for this.  The perfect example is I've talked about how I can't buy gas with a particular credit card because they just shut it down when they see it at a gas pump.  And I've said, can I please override this?  And they go, no, sorry, you can't.  So there are no options typically for disabling account recovery.  Maybe, well, no, you can't not have an email address.



LEO:  I truly - what I actually believe is that we're all vulnerable to some degree, and that you should do the best you can.  But we're somewhat at the mercy of these third parties.



STEVE:  What was creepy - and I've talked about how porous security is, that it's more porous than we think - what's creepy is that it was a whim.  These one or more people just decided, ooh, look, @mat, that would be - it'd be fun to post to that Twitter account.  Let's go do that.  And they were able to.  There was huge collateral damage, as Mat described it, as a consequence of their simply wanting to send tweets out through his Twitter account.  So you've got to wonder how safe we are to somebody wanting to get us.  



LEO:  I'm not clear, by the way, these single-time passwords, I have to ask Matt Cutts.  There's unclarity in my mind about how - they do not expire, but I am told that, once you use one, you can't reuse it.



STEVE:  That would make sense.  Thus "one-time."



LEO:  I would think that's how it is.  They're called "application-specific passwords."  And you can revoke them at any time.  But you have to go to the website, log into Google using two-factor authentication, and revoke them.



STEVE:  It would be nice if - again, lots of things would be nice.  What Facebook is doing does raise the bar, the fact that they provide a secure cookie.  I'm sure it's flagged secure, meaning that it will not be divulged over a non-SSL connection.  So you have HTTPS secure connection to Facebook, which we know they have.  We've seen these changes, and we've discussed them as they've been occurring over the last couple years.  So there's a cookie that only that machine has that will only send in a query over a secure connection from your browser, which identifies it to Facebook as one that has been seen before.  So that's a nice barrier.  So that is allowing Facebook to painlessly tag devices that you have in the past logged in from and allow you to do so again.  That would be some nice tech for Google to add.  One wonders why they don't yet.



LEO:  Yeah, I mean, I think we're in a world where we have to balance convenience with security.  And so inevitably there are going to be flaws.



STEVE:  Yes.  I guess the main takeaway, the only real takeaway I can suggest from this fun, I mean, sad but really gripping adventure with Mat, is consider separating accounts that could be used for password recovery so that - and really, it's not clear that you want a single account.  You kind of want a family of accounts.  And that really becomes a pain, if your main services all need to point somewhere different.  Boy.  The problem is using email for this is just really - that's the source of major insecurity.  And I don't see that going away anytime soon because there's nothing to replace it until we get good "something you have" additional factor authentication.



LEO:  I use it on Battle.Net.  I use it wherever it works.  So Blizzard has one, and they have an authenticator that you have to download another app on your phone, and it gives you the one-time key, and you'd use the password...



STEVE:  Mine is never far from me.



LEO:  Yup, I've got my fob for PayPal.  Although, as you point out, PayPal's got that little thing saying, "Did you lose your fob?  Well, let's help you get in."  So how good can this really be?  And by the way, using LastPass would not have saved Mat in the least.  It wasn't an issue of somebody stealing his passwords.



STEVE:  Nope.



LEO:  And that's the key to this is that there are holes, it turns out, in all sorts of places.  And it just takes somebody who's willing to kind of mess around...



STEVE:  And work the system.



LEO:  ...and work the system.  And that's what these kids are good at.  They've got a lot of time.  They're smart.  And they're motivated, apparently.



STEVE:  And there's a culture.  They're passing...



LEO:  There's a culture.  They pass this stuff around, exactly.



STEVE:  Exactly.



LEO:  So I asked this guy, "How did you get started?  Where did you learn this stuff?  How did you get all these techniques?"  He said, "I started when it was 16, and I wanted a cool gamer tag on Xbox 360.  And I asked my friends."  And, see, this is what happens.  They start passing around techniques for hacking.  And I doubt very much that these guys came up with their own techniques.  Maybe they did.  But I think in most cases they're just - it's like a recipe book.



STEVE:  There is an underground.



LEO:  Step 1:  Call Amazon.  There's an underground.



STEVE:  Yep.  And they're chatting, if they're in high school, I guess they're around that age, they're sitting around at lunch, passing back and forth new ways someone has found for running a scam.  It's like, hey, I tried this, and this worked.  And the person who comes up with it might be too timid to do it, but he tells somebody who's brazen enough to go give it a shot, to get on the phone and call Amazon and Apple.



LEO:  There's no harm to doing that.  They could say, well, if they get suspicious, you hang up and move on.



STEVE:  You've got to wonder, too, how anonymous those calls were.  It's not as easy to obscure your phone number as it is your Internet connection.



LEO:  Oh, yeah, it is.



STEVE:  Oh.



LEO:  Oh, yeah, it is.



STEVE:  Okay.



LEO:  But let's not go into that.



STEVE:  Okay. 



LEO:  Steve, this is such a good subject.  It's a fascinating topic, and I'm really glad you addressed it.  I guess we'll do questions next week.



STEVE:  Yes, we will.  We spend so much time talking about technology because that's where all of this comes from.  But this was a perfect example of how technology can't save us, if the policies are in place and the systems are in place that allow this kind of scheme.  This had nothing to do with how long the passwords were, as you said, or how many bits of crypto were in use.  These guys cut right through all that and sent tweets out of Mat's Twitter account.  So, wow.



LEO:  Thank you, Steve Gibson.  He's the man.  Next week your questions; right?  We're going to do Q&A?



STEVE:  Yup.  Yes.



LEO:  So go to GRC.com/feedback to ask those questions.  While you're there, check out SpinRite, the world's finest hard drive maintenance and recovery utility.  You might pick up a couple of freebies - Steve's got a lot of them - including Perfect Paper Passwords.  You can just print out some passwords.  They're perfect.  They're paper.  The Password Haystacks, which I use now all the time.  See, this is the irony.  I know I have very secure passwords.  I'm not worried about my passwords anymore [clearing throat].



STEVE:  Yup.



LEO:  Apparently that doesn't matter.  All his stuff is available at GRC.com.  We do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time.  That's 1800 UTC on TWiT.tv.  Watch live.  We love it if you do.  I love to see the chat and the feedback, and I certainly would pay attention to it.  But you can also catch it after the fact.  We make on-demand versions available.  Now, Steve does some unusual on-demand versions.  He does a 16Kb version for the bandwidth-impaired.  That's at GRC.com.  He's also got transcripts, which is the ultimate in compact, ASCII text, baby.  All of that, GRC.com.  But for the video, the higher quality audio, we've got that at TWiT.tv/sn.  Steve's on the Twitter...



STEVE:  Oh, and Leo?



LEO:  Yeah.



STEVE:  I forgot to mention, I made an improvement to the little animation that you saw last week for the first time.



LEO:  Steve was playing with his HTML5 and his JavaScript.



STEVE:  If you do GRC.com/animation.htm, I added peak detection to the output of the read amplifier.  So it came out pretty cool.



LEO:  This is - you're having fun with this, aren't you.



STEVE:  Yeah, I am.  I've...



LEO:  This is cool.  This is all programmatically generated.  None of it is graphics; right?  You're just drawing lines and boxes and squares.



STEVE:  Yeah.  And it's like, oh, I think it's less than - it's around 30K.  And when those waveforms get into the write amplifier there, then it starts switching its polarity, which changes the direction of magnetism on the disk platter.  Then the platter rotates over my little schematic.  Then the read head picks up on it.  And now here's...



LEO:  Whoa.



STEVE:  We've detected the pulse, the peak of the waveform.



LEO:  Peak detector.  Peak detector.  You are a crackup.  Oh, what fun.  And by the way, you can view source on this.  He has not obfuscated the code.  I'm learning JavaScript, inspired by you, and I'm looking at the code because it's very cool.  Very, very cool.



STEVE:  Fun stuff.



LEO:  Yeah.  Thank you, Steve Gibson.



STEVE:  Okay, my friend.



LEO:  Thank you, everybody, for being here.  Steve's on the Twitter, @SGgrc.  He doesn't follow people, but you can @ message him, and he reads those.



STEVE:  Yup, I do.



LEO:  And he responds, too.



STEVE:  I do.



LEO:  Thanks, Steve.



STEVE:  Thanks, Leo.



LEO:  We'll talk again next week on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#365

DATE:		August 15, 2012

TITLE:		Listener Feedback #149

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-365.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Yes, there was a big, big, big, big Microsoft Second Tuesday Patch.  He'll tell us all about it.  Also a new version of Flash.  That and your questions and Steve's answers, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 365, recorded August 15th, 2012:  Your questions, Steve's answers, #149.  It's time for Security Now! now, ladies and gentlemen.



STEVE GIBSON:  After that wind-up, I have to ask you, are you recording this, Leo?



LEO:  Yes, I am.



STEVE:  Okay.



LEO:  Let me put it this way.  If you're hearing this, folks, I must have recorded it.  And if you're not hearing it, I didn't.  But then you wouldn't know.  It's a conundrum wrapped in a riddle.



STEVE:  We deal with these sorts of things every week, Leo.



LEO:  Steve Gibson's here.  He's Explainer in Chief, the guy in charge of security and privacy on the TWiT network.  And it's really interesting because this is easily the nerdiest, geekiest, the hardest-core show on the network by far, and one of the most popular shows.  The numbers continue to go up.  And I just have to think that it's a real demonstration that people want hardcore tech.  They like the information.



STEVE:  Yeah.



LEO:  So today we are going to do the Q&A that we deferred last week because of Mat Honan's - so now we're once again Mod 1.



STEVE:  Well, we're at Episode 365.



LEO:  If you start listening now, one show a day, you'd finish next August.



STEVE:  Same time next year.  So we have our Q&A this week, and a little bit of security news, not too much, some interesting questions.  The topic of last week generated a lot of interest, the whole issue of authentication.  And I started to put together some commentary because I realized there'd been sort of a critical mass built up in me, and I was thinking I would do it this week, but I'm going to defer it next week to give it the treatment that I want to.  So some commentary about the issue of authentication, the problems that we have, and the next step we have to take.  We've trained users now about passwords.  Do not use "monkey" as your password.



LEO:  As I did, by the way, for a long time.



STEVE:  It's surprisingly popular for some reason.



LEO:  Really, wow.



STEVE:  Yeah, it's bizarre why random people would all choose "monkey" for some reason.  But don't use "monkey"  and don't use "password."  And try to use different passwords on different sites.  Those lessons are sort of sifting out into the ether of understanding.  And I think it's time to take the next step, and I'm going to talk about what that is next week.  Not as the topic.  That's not worthy of a topic.  But to deliver a little bit of a commentary.  And in the meantime we'll do Q&A this week.



LEO:  Well, that sounds great.  I've got some good questions, which you have come up with.  Leo Laporte here; Steve Gibson there.  We are ready, Steve, to get the latest tech news before our Q&A.  What's going on out there?



STEVE:  The big news is rather routine, unfortunately, which is we are on Wednesday after the second Tuesday of the month, which is always the day after Microsoft's Patch Tuesday.  These are rather important this month.  They're a little frightening.  We've got nine sets of patches.  More than half of them have critical ratings.  They address at least 27 security holes in Windows and related software, and some of them look kind of frightening.



There's one set of four privately reported vulnerabilities that affect IE, all versions 6 through 9, and that's a remote code execution problem.  Microsoft writes that the most severe vulnerabilities could allow remote code execution if a user views a specially crafted web page using IE.  Then they go on to explain that an attacker would have no way of forcing you to go to a website, blah blah blah, as their CYA because we now know that that's not the way these things work.  People send you links in email.  High-reputation websites get compromised with exploits installed on them unbeknownst to their webmasters.  So that's one.  There's IE, all versions.



Remote Desktop has a problem where, if you have the remote desktop exposed to the Internet, it's possible to send it some packets to execute code remotely on your machine.  Windows Print Spooler's got four privately reported vulnerabilities which they fixed.  And something we don't often see, the Windows Common Controls, that's the library of all the components that make up a window - dropdown list boxes, the tree list, the text box, the buttons and things.  To have a remote code execution vulnerability there is uncommon and very worrisome.  And they say of that the same thing.  The vulnerability could allow remote code execution if a user visits a website containing specially crafted content designed to exploit the vulnerability.



There's a problem with their JScript, which is their version of JavaScript, and their VBScript.  It affects 64-bit versions of Windows, which are generally regarded as more secure than the older 32-bit instances.  And even something, a remote code execution problem with Exchange Server.  So this will require a restart, but it's not something I would put off for very long because many of these are privately recorded, but several are public.  And this is not something you want to leave your system exposed to..  There's too much opportunity for exploit.



And Adobe, just yesterday, on August 14, also Tuesday, they released news of a critical Flash Player update across all platforms - Windows, Mac, Linux, UNIX.  And what's odd is I'm not seeing any push from them for this.



LEO:  I did.  I got a new Flash yesterday.



STEVE:  Oh, you did.  Okay.



LEO:  But it was on a Mac, yeah.



STEVE:  Okay.  I've restarted IE.  I've clicked on Check My Version.  I also fired up Google specifically to see whether it was going to update me on its own.  At least on the Windows platform I'm not seeing it yet.



LEO:  Maybe you have to go to a site that uses Flash.  I bet you that's it.



STEVE:  I've tried that, too.



LEO:  Didn't do it, huh?  Hmm.



STEVE:  And clicked on the player or had the browser see that I'm instancing the player.  What I have currently is the most recent vulnerable one.  11.3.300.270 and all earlier players are subject to this vulnerability.  The reason I'm bringing this up is it is being exploited actively in the wild through targeted attacks.  In this instance, at the moment, it's a malicious Microsoft Word doc which exploits the ActiveX version of Flash Player.  Oh, it's IE, in my own notes here.  And I tried Firefox, and I tried Chrome, but I didn't fire up IE and use Flash.  So it may only be a problem with IE.



But you want to update to the latest one, which is .271 rather than .270.  And that is being actively exploited.  So you can go to Adobe.com/software/flash/about, and that will run a little animation and show you what your current version is, so you can quickly see whether you are yet at 11.3.300.271, which is where you want to be.



And I noticed something that I thought some of our listeners would find interesting.  We've talked about the Khan Academy and what a nice piece of work all of the resources there are.  They're just in the process of launching a new computer science site which focuses on what they said was the critical early adolescent years where children broaden, or unfortunately, in some cases, narrow their interests.



LEO:  More often narrow, yeah.



STEVE:  Yes.  And their identity before high school.  What I thought was interesting about this, TechCrunch carried the story.  And they said, "The lessons don't get much more complicated than basic algebra, and how these intuitive mathematical concepts can create powerful, artistic, videogame and website experiences."  What they've done is, and this is not the first time this has been done, but I think it's nice to see it again, they're merging computer science education with graphics.  So they're using sort of the compelling visuals of graphics in order to teach concepts of computer science.  And of course you'll remember the LOGO programming language with its so-called "Turtle Graphics," which was an early effort in the mid- to late '60s to interest young people in computers by making something accessible.



LEO:  Yeah.  It was very cool, yeah.



STEVE:  Yeah.  And I was thinking of it because it also relates to the page I just did where I had the way magnetic data storage functions shown graphically.  And you and others immediately jumped into it, wanting to see how I did the things that I did.  So there's definitely a connection between something as visual as a graphic presentation and the code behind it that makes it go.  And in this day and age now, with videogames being so phenomenal, we understand that there's a lot of code behind there to make it all happen.



So anyway, the Khan Academy launching a computer science curriculum that is based on graphics.  And in the little onscreen sample that I saw, it looked like some simple JavaScript that actually they showed implementing a version of Pac-Man, and showed the code to do it, where you could see the way they were actually creating the graphics to draw the little ghosts that were going around the maze.  So I thought that was cool.



And from the Twitterverse I had one tweet that caught my attention, and this relates a little bit to one of the questions that we'll be encountering in a minute.  Someone named Paul Morgan tweeted, he said, "Just listened to Mat's story.  Those kids are in a bad situation, if caught.  There is no 'pressing charges' when it's a felony."  Which I thought was a good point.  Remember that Mat said that he agreed with the hacker not to press charges.  But this was serious stuff that these kids were up to, which we will discuss in one of our upcoming questions today.  So I thought that was worth noting.



And I did have a really well-written and really neat note from a Joe Kozak, August 8th, so just recently.  The subject was "Another satisfied customer, thank you."  He said, "Dear Steve, I have an older HP computer with a partitioned 80GB hard drive, C: for me, and D: for HP programs, if they needed to be reinstalled.  For several months I was getting warnings from my hard drive.  It would make clicking sounds.  I foolishly ignored them and failed to back up the drive.  Then one day the computer would not boot.  It would get to the Windows screen, go no further, then reboot.  This loop continued.  I shut it down and tried again, dot dot dot, many times, but with no success.  I always got the same result.



"I thought, no big deal, I would remove the hard drive, use a USB cable, and read the drive from my other computer, back it up there.  No such luck.  My other computer didn't even know it was attached.  Sure, it saw the D: partition, which I didn't need.  But it did not see the C: drive.  This is when I started to panic.



"I started to research my situation and learned about SpinRite.  I watched the videos and read many, many, many positive testimonials.  I must admit, even after watching the videos and reading the testimonials, I was still skeptical, but decided to purchase SpinRite anyway due to the 30-day absolute satisfaction guarantee," which of course we are.  Anybody who is sorry they purchased it, who regrets their purchase, we're happy to put the money back on their credit card.  So he says, "After running SpinRite for a straight 23 hours, it seemed like nothing was happening.  It remained on one sector for over 13 hours."



LEO:  Wow.



STEVE:  "So I emailed tech support to ask if that was normal.  They informed me" - "they" meaning Greg - "informed me it wasn't normal, but it was possible.  So I let SpinRite continue working.  After an additional five hours" - now we're at 28 - "I wanted to give my PC a rest, so I again emailed tech support, this time to ask how I could stop SpinRite without losing its location.  Again, tech support quickly replied with detailed instructions, and I stopped SpinRite.



"At that time I was curious to see what would happen if I turned on my computer without booting SpinRite.  This time it did not loop as before.  I could tell the computer wanted to boot, so I let it continue trying.  After about 10 minutes, it booted, and my desktop appeared.  It was like magic.  I absolutely could not believe my eyes.  Without shutting it down, I spent the next five hours backing everything up.  The next day I ran another long session, 20 hours of SpinRite, from the place it left off the first time, to recover additional data from the remaining sectors.  Throughout the next few days I ran several more sessions.



"At the end, it ran for over 113 hours, spread out over eight sessions.  Additional files were located and backed up as it went.  My final analysis is that it recovered 99.999 percent or more.  I noticed only a few files in one folder which were not recovered.  Conclusion:  Low cost, 30-day absolute satisfaction guarantee, excellent technical support.  Purchasing SpinRite should be a no-brainer.  Be patient and let it do its magic.  It's the best software investment I've ever made.  Thank you, Steve, for this great program.  Best regards, Joe Kozak."



LEO:  Hey.



STEVE:  So, very nice story.  I haven't shared an adventure like that with our listeners for some time.  So when I saw that, I thought, ah, that'll be fun.



LEO:  All right.  I've got questions.  You ready, Steve?  You got answers? 



STEVE:  Speaking of technology, yeah.



LEO:  Speaking of technology, this is Question #1.  Seth Jameson, Fort Collins, Colorado.  He was reading that - remember we talked about that animation that Steve did a little while back, and he said the JavaScript - view source, you'll see the JavaScript.  Steve, thanks for sharing the code you used to produce the amazing magnetic storage animation which you'll be using in a video of a forthcoming SpinRite.  I've been studying it, and I've learned some neat tricks.  But I have a question.  The Scalable Vector Graphics, or SVG drawing system, predates HTML5 and the canvas API.  Did you think about using SVG instead?  And if not, why not?



STEVE:  Well, okay.  I chose two questions out of many.  I was really surprised, and I thought it was neat that our listeners were as interested in what was going on under the hood, behind the scenes, much as you were, Leo, with that little demo.  So I thought I would just take a second to talk about it a little bit, since this is a forum for doing that.  The scalable vector graphics has been around longer  than the canvas API.  Apple actually originated the canvas API, and it then became a standard much later than scalable vector graphics.



The SVG objects are themselves objects, in the sense of, for example, if you have a rectangle and a circle, for example, they exist as things in what's called the DOM, the Document Object Model, of the page.  So in the same way that in an HTML page you've got divisions and tables and images and so forth that are part of that document structure, the drawing objects, the scalable vector graphics are sort of the same class, the same level.



So what that means is that a circle, for example, will have a defined center and a radius and then some things like color and outlying color and outlying thickness, properties of that circle.  And if you were to want to animate that, you could change any of those properties, and the browser would show you the new circle.  So the circle exists as something virtual, physical, actual, as part of the document.  By comparison, the canvas API is just drawing.



LEO:  So you have primitives like moveTo, lineTo, arcTo, drawing primitives.



STEVE:  Exactly.



LEO:  Stroke, which will do the drawing itself.



STEVE:  And the way to think of it is as a bitmap.  You define a so-called "canvas," which is a drawing surface, and then the order in which you draw affects the pixels of this bitmap as you draw across it.  So you can set a line width and say that it's going to be this color, and then you say "move to this coordinate" and then "draw a line to that coordinate" and, bang, it exists.  But there's no notion that the line itself doesn't exist as an object.  So, for example, you couldn't change one of the coordinates and have the line move.  You'd have to erase the whole canvas and then redraw everything.



LEO:  This is not SVG.  This is with...



STEVE:  The canvas API.



LEO:  The canvas, the HTML5 API.



STEVE:  Yeah.  So for what I was wanting to do, the kind of graphics that I was envisioning didn't feel to me like they would fit into sort of an object-ish template.  For example, we were talking earlier about the Pac-Man, the idea of recreating Pac-Man.  That's a perfect example of where you might use the scalable vector graphics because you might define the shape of one of those little ghosts, and then moving it around the maze is just a matter of changing its location, and the browser will update the entire presentation showing these things in a new position.



LEO:  That's what they call "sprites" typically in videogames.



STEVE:  Precisely.  As opposed to what I'm doing, which is more sort of freeform graphics that don't really fit into that same object-oriented way of describing things.  Arguably, you could do either with the other.  But some things just sort of make more sense in one form than another.  And also it feels to me like scalable vector graphics is sort of a transient, I mean, it was here first, but it's...



LEO:  I think HTML5 is the future, absolutely.



STEVE:  Yes, that's exactly right.  So I was wanting also to invest because it was going to take me a while to learn either of them.  Since I could probably do anything on the canvas that I could do in scalable vector graphics, I thought, well, I'm going to do the one that is part of the W3C standard and moving forward.



LEO:  This is also kind of intuitive, if you've ever done any graphics.  I'm looking at the amplifier, the code to draw the amplifier which is just basically a simple box.  And you set some parameters.  "C" is your canvas.  You set the color, the fill style, the shadow blur.  And then you say what the stroke style is.  Then c.strokeStyle = hex 000000.  Then you say what the line width is, c.lineWidth = 2; and then you draw it, c.strokeRect; and you give it the four coordinates, the four corners, and it's done.



STEVE:  Yeah.  We were talking about the Khan Academy earlier.  And if somebody wanted to play with JavaScript, it is that easy.



LEO:  It's pretty straightforward, I have to say.



STEVE:  I think graphics, yes, I think graphics is a tangible, immediate feedback, kind of like, ooh, look, I just drew something, and then you start asking yourself questions.  This is a little bit like the Portable Dog Killer moral, which I ended that story with saying, look, just do something.  Just start.  And you'll immediately get sucked into thinking, oh, hey, I've got an idea.  How do I do this?  Or what about if I do that?  And before you know it, it'll be 4:00 a.m., and you'll realize you really should have gone to sleep.



LEO:  And that's the fun of programming, kids.  A lot of sleepless - so let me ask, though.  There's animation - by the way, you can see this at GRC.com/animation.htm.  You could see this.  Are you erasing, for instance, the read amplifier puts a plus and minus up whenever it reads a bit.  Are you erasing those pluses and minuses and redrawing them?  How do you that?



STEVE:  Well, that's a very good question because there are, since it is just a bitmap - if I wanted to change the whole canvas, it would make more sense to erase it all and then repaint it all anew.  But because this is a bitmap, I can just erase the part that I'm changing.  And so, for example, in the plus and minus case, that's what I'm doing.  There are only little areas that are changing.  And so I go in and just blank those out and then change the plus to a minus and so forth.



LEO:  So you do erase, then redraw.



STEVE:  Yes.



LEO:  And actually you're doing a really cool thing with the plus and minus.  They're growing and shrinking.  So you're really having fun with that.



STEVE:  Yeah.  Again, it's a nice way of playing with a simple programming language like JavaScript and immediately getting feedback, immediately getting some traction for what you do.  But do keep an eye on the clock because otherwise the sun will come up.



LEO:  This is pretty cool.  If you go there and view source, and most browsers will let you do that, actually I'm looking at it in Safari, which has - you open up the developer menu, then you actually have a really great interface to the JavaScript.  But it's only about 800 lines of code, very clearly commented, really easy to understand.  And if you just go back and forth, looking at the animation and looking at the code, I think this is a little lesson in itself.  I think you can probably understand exactly what he's doing.  It's all fairly straightforward.  It's neat.



STEVE:  Well, it is part of this video that I'm putting together.  I've finished all of the work.  There's actually a bunch more stuff I haven't made public just because I haven't had any reason to.  But I'll let our listeners know as soon as I have the video put together because I've done - I also showed the design, the morphing of the longitudinal recording head into vertical recording, and how that increases the density, but what the consequences are to recording much higher bit density because then those pulses begin interfering with each other.  They get very close together, and they start pulling towards each other, which has some unexpected side effects, which is part of what SpinRite knows about.



LEO:  Is this all integer math, or is it floating point?



STEVE:  In JavaScript it's sort of typeless, meaning that JavaScript tries to keep everything floating with a lot of resolution.  If you do any logical sort of bit manipulation, then JavaScript says, ooh, he's trying to "and" some bits or "or" some bits.



LEO:  So smart.  Hmm.



STEVE:  So, yeah, it'll switch it into integers and allow you to do the right thing.  So they've really done a nice job.  I'm impressed.  As I have spent more time with it, I've come away feeling that, wow, here's the language which looks like it's got a future.  If only they hadn't called it ECMAScript.



LEO:  Well, everybody calls it JavaScript.  We can ignore the fact that it's really ECMAScript.



STEVE:  Yeah.



LEO:  I went out and got the four O'Reilly books.  And learning JavaScript is, if you've ever used the O'Reilly learning series, you know that they're aimed at kind of programmers, so they're brusque.  But there are also some good - there's "Eloquent JavaScript" which is nice for a first-time programmer.  There are some good choices out there.  And you used a book on web graphics.  What was the name of that?  Do you remember it?  He's looking for it.



STEVE:  "JavaScript Graphics."



LEO:  There you go.  It's another O'Reilly book.  It's got a - looks like a bison on the cover.  What is this?



STEVE:  I don't know.  It's got a big beard.



LEO:  It's some sort of African wildebeest.  Question 2, Peter Wilson, Atherton, California:  Steve, you missed a trick.  Speaking of meat?  I see.  Love the show and Leo's others, mostly due to how meaty they are with compared with what else is out there.  Got it.  Speaking of meat, I was looking at your magnetic recording animation page and noticed you're not using the cool new AnimateFrame feature which was specifically created to facilitate animation.  Instead you're using the old, general purpose setInterval timer to drive your animation.  That's 'cause Steve's old school.  I've been listening to this podcast for many years.  I have a feeling you would have done what was best even if it might have been more difficult.  Is there a reason you didn't use AnimateFrame?  Thanks, Pete.



STEVE:  Okay.  Well, I'll answer this question, and then everybody's on their own.



LEO:  Okay.



STEVE:  So, yes.  AnimateFrame is clever, and I tip my hat to the designers of HTML5 and the canvas and this feature.  What AnimateFrame does is it tells your code what time it is and uses that, together with your browser, to set the optimal frame rate.  The idea is that you might have something really complicated that you're drawing on a slow machine or a slow tablet or something else where there's a huge overhead, and this set interval essentially, we all know that animation is the illusion of motion thanks to showing a series, a rapid series of still frames.  So even movies, movies are just a succession of still frames shown one after the other, and our brain fills in the gaps, and we see something that's continuously moving.



So the setInterval is a - I use it because I'm saying that I want my code to be called to draw the next frame every X milliseconds, like 30 times a second, so every 30/1000 ms or 1000/30 ms, rather.  And so what that does is it allows me to generate that smooth-looking animation because essentially I'm drawing those frames at 30 times a second, which is fast enough so that we see it, we perceive it as smooth motion, even though it's actually not.  But it might be that there's a very complex drawing which can't be done at that rate.



So the idea is - and I would imagine users have seen, for example, maybe in the old gaming days, where if you had a slower computer or even a faster computer, I know there was a problem as PCs began to get faster, Leo, remember, there was a problem where you would have to slow the clock down on the processor because otherwise the videogame was running too fast.



LEO:  Because people used loops for timing.  It was because they weren't tying the timing to the clock.  They were just saying, count to 30 and then do another frame.  Count to 30, do another frame.  Now, that might have worked on the original computer.  But then as computers get faster, they count to 30 faster, and it doesn't work so well.



STEVE:  Exactly.



LEO:  So that was just bad programming, if you ask me.



STEVE:  Well, so the reason I used the SetInterval was that I wanted to get a feeling for how this looked at 30 frames per second because remember that my real goal was not to show an animation on the web browser page.  I did this whole thing in order to capture those frames which I will then import into a video presentation.  So my real target was not the web browser and the ability, I mean, it's cool that it works as well as it does on all browser and iPhones and iPads and things.  And it's surprising, I'm very impressed with how efficient this whole thing is because it uses, like, 2 percent or 3 percent of the system on my machine.  So it's very efficient.



But anyway, so what AnimateFrame does is different.  It says we're going to work with the browser to show frames at a rate that we think fits your system, whatever that is.  And we're going to tell your code what time it is, that is, when the frame is being shown.  So, for example, imagine you had a ball moving across the screen.  In the old days, as we were just talking about, with a system based on delay loops, if you had a faster computer, then the ball would move too quickly.  But if instead the programmer asked what time it was, that is, with sufficient resolution, then they would know how much time had passed since the last frame they drew, and they could compute the position of the ball for this frame.



So the idea is, instead of moving the ball a fixed amount per frame, you get the time, like the time of day, with a lot of resolution, when the frame is being shown.  And so you compute where the ball should be at that time, literally using simple physics to say, at this time, if the ball is moving at this speed, it should be here.  And what that does is it makes the experience uniform across computers of any speed.  You could have a really slow web browser, and although the ball might be jumpy because it wasn't being drawn often, it would at least be moving at the speed that you intended it to be moving.



So anyway, because my target was generating frames for a video, rather than outputting them through the browser, what I wanted was to see what 30 frames per second would look like, and ultimately I'll be capturing those frames and then merging them into a video presentation.



LEO:  Kewl.  Kewl.  Question 3, Andrew Constantine.  He's asking about something that we talked about a couple of weeks ago and that I immediately turned on, it's not on by default, the new Password Iterations feature:  Hello, Mr. Gibson.  This may have been answered in an earlier episode of Security Now.  If so, feel free to point me in the direction of that show.  My question is regarding the new Password Iterations or PBKDF2 option.  I've read the online help articles on it several times, but the way LastPass explains it's a little over my head.  You're really good at explaining these complicated things in layman's terms.  That's why we call him the Explainer in Chief.  So what the hell does Password Iterations (PBKDF2) actually do?  Love the show, applaud your passion for the security stuff even though it is, for the most part, over my head.  Cheers, Andrew.



STEVE:  We've had a couple of people who've asked the question.  I won't spend much time on it because we have covered it before.  This PBKDF2 stands for Password Based Key Derivation Function.  What it really means is that there is a way to slow hackers down.  We've often talked about password hashing.  Hashes were designed to be fast.  But if a hacker is trying to brute-force by guessing all possible combinations, then we don't want that job to be fast.  Yet logging in, like using the password interactively, if it took a second of two for the system to say, ah, okay, that was the right password, well, we wouldn't feel that.  We wouldn't mind that.



LEO:  But a bad guy might.



STEVE:  Yes.  If it took a second to test every attempted password, then that would dramatically increase our security.  So the smart guys at LastPass recognized that, as is the case for all offline password-guessing systems and, for example, WPA that protects our passwords in WiFi, has the same sort of situation where you could capture some traffic in the air and then do an offline brute-force attack, trying to guess the password that was used.  And for that reason, the smart people who designed the WPA protocol have the same thing.  They've got a 4,096-iteration, PBKDF2 option.



And so the LastPass guys said, hey, they realized they could add that, too, just to further strengthen an already well-designed and strong solution.  So it appeared in an upgrade, but they don't turn it on.  They recommend, I think, what, 512 iterations, 500.  And so...



LEO:  Yeah.  But you could use more if you wanted to.



STEVE:  You could.  And the only consequence of using more would be a little bit, maybe a delay you could feel on a slower platform.



LEO:  You know what's interesting, this ties into your last question in an interesting way because these calculations are done client-side.  So if you had a faster computer, you might want to turn those iterations up to slow it down.



STEVE:  Correct.



LEO:  It's kind of like a loop.



STEVE:  That's a very good point, yeah.



LEO:  So, yeah.  You do have to go into your LastPass settings to modify that.  They won't do it for you.



STEVE:  Right.  Although they are now recommending it.



LEO:  Yes, yes, yes.  It's recommended.



STEVE:  So it's a good thing.  You turn it on, and it increases your security, and it's painless.  I've done it, you've done it...



LEO:  Yeah.  I even notice.



STEVE:  Yeah.



LEO:  Speaking of which, I finally gave in, and I left the two-step authentication - notice I say "two-step," not "two-factor," because that's what Google calls it - on.  I turned it back on.  It's kind of a pain because you have to do those one-time passwords on the application, the application-specific passwords.  But once you've done that - one thing they did that made it better, they don't expire it every 30 days now.



STEVE:  Oh, good.



LEO:  So that eliminates - because if you expire it every 30 days, that means every day I have to change something.



STEVE:  Right.



LEO:  Something's complaining.  Question 4.  So do turn that on.  I'm not recommending against it.  Question 4, James Parsons in Virginia - his Twitter handle is @PolicyEconomy, which is interesting, I wonder if he works for the government - tweeted to SGgrc:  Is it possible to implement PIE securely using JavaScript?



STEVE:  Well, PIE is Pre-Internet Encryption.  That's an acronym we coined here on the podcast to stand for this concept of encrypting data before it goes out over the Internet.  And it's absolutely possible to implement Pre-Internet Encryption for some applications in JavaScript.  And the famous one is LastPass that we were just talking about.  It knows what your passwords are in the browser in your system.  And it never sends them unencrypted into the cloud over the Internet to LastPass.  LastPass keeps only a pre-encrypted blob which, if you then connect up on your Android device or your iPad or a different machine, LastPass will send the blob down to that machine where, again, using JavaScript, it will decrypt the blob there and make them available to that local browser.  So that's a perfect, LastPass is a perfect example of Pre-Internet Encryption in JavaScript.



Now, the problem is that JavaScript is deliberately constrained.  Because it's running in a browser, and a browser, as we all know, is an untrusted client - I mean, we would like to trust it.  Unfortunately, it's going out and reaching over to foreign websites all the time and is a constant source of security problems.  So for that reason we did not want a language in every browser that gave it access to our computers.  So JavaScript is useful, for example, in that animation page that I did, for LastPass encrypting things before the browser sends it.  But it would not, for example, be able to encrypt files on your system and then send them to the cloud because we don't want JavaScript to have access outside the browser to general system things.  That would just be asking for trouble.



LEO:  Right.  Sam Fineberg, Palo Alto, California, suggests - he's talking about our last episode.  We talked about Wired.com writer Mat Honan, senior writer Mat Honan, who was hacked last week.  He says Mat might have already been doomed:  I was thinking about last week's episode.  My conclusion is that Mat's digital life was doomed.  He may have been lucky to be hacked since there is in fact a way to get his data back.  And now he better understands what was always at risk.  What if his hard drive had died beyond SpinRite's ability to repair?  Someone stole his MacBook?  Or if he'd dropped it?  Without a backup, those pictures were already toast.  You know, parenthetically, that's what Alex Lindsay says, is one copy of anything is no copies at all.



Another thing that troubles me is that his drive was recoverable.  If I remotely wipe a drive, I want it gone.  Period.  I don't want it to be possible to recover the data with a four-digit PIN.  I'll explain what happened.  I want it securely wiped, or encrypted with unbreakable encryption.  Any device I take outside of the confines of my house I consider vulnerable, especially a laptop I run though airport security or leave in a hotel room.  That's why I encrypt my laptop drive, and not with an easily brute-forced pin.  However, the flipside of that is that it means that I would rather lose my data than expose it.  Period.  It seems unfathomable that anyone would only keep a single copy of precious data, and even worse to have the only copy on a laptop or mobile device. 



As I said, Mat's data was doomed from the moment he didn't back it up.  He should consider himself lucky something worse didn't happen.  Sincerely, Sam.  I guess that's true.



STEVE:  Well, okay.  I have a couple things, and I know you have a couple things you wanted to comment to.



LEO:  I'll explain what the hard drive does.



STEVE:  One of the things that I have noticed is that, over time, we've become increasingly dependent on our gadgets.  And that our appreciation of the "what if something went wrong" somehow for some reason, a quirk of human psychology or maybe there's a sense of, well, it was fine yesterday, so it'll be fine today and probably fine tomorrow.  My favorite example is back when we used to talk about online banking, and the family would have their communal family PC.  Now everybody's got their own.  But at one point they were still expensive, and so everyone was sharing them.  And there was no security.  I mean, there was no notion of security.  The kids would bring their friends over after school, and they'd download strange software on it or get stuff off the Internet,, or they were using filesharing stuff that was a big source of problems.



And then Mom and Dad decide that they want to - their bank is saying, hey, you could do your banking online.  And so into this disaster of security they begin to add new functions and features that really do need security.  But because this sort of happens a little bit at a time, just sort of drip, drip, drip, at no point is there anything that says to them, wow, you need to really start taking this seriously because, have you noticed, you've now got your accounting, now Quicken and QuickBooks is on your system, and your banking is on, and your husband or your family's investment portfolio is there, blah blah blah blah.



So one of the things that happens, I think, is that we just sort of - this creeps up on us.  You can imagine, for example, that Mat may have transferred the first photos of his newborn from his camera to this laptop.  And at that point he didn't have a huge investment in that particular content of his laptop.  But it slowly grew over time, and it never occurred to him to say, okay, what if this all disappeared tomorrow?  What if it was just gone?  And we've talked around this in various ways over the years, like what would happen - again, no one wants to think of what if I didn't wake up in the morning, but how would my family deal with all of the passwords that I have in my head that they don't know, that are vital?  So this notion of "what if" planning is important.



But I think it's very easy for us not to appreciate how important it is because of sort of over the time that we can look back and remember, we've become far more dependent upon these things.  The security of them has become far more important as more and more of our life has become digital.  As Mat put it, his digital life, he suddenly realized how important that was because he had digital photographs that used to be printed out on film and on paper, now they're on a hard disk.  And as Sam says, you could turn the computer on, and it says we don't have a hard disk here anymore.  So I think I liked this because I understood what Sam meant, and I know that Mat is probably now taking measures to make sure that he's backed up.



LEO:  Oh, yes.  I talked to Mat.  He's definitely - cue the Carbonite ad.  He's definitely doing that.  And I don't know, I have not talked to him since he got hooked up with DriveSavers.  I asked the DriveSavers people to help him out.  So I don't know.



So I'm a little curious, and Apple understandably is a little cryptic about what happens in the remote wipe.  One would presume that what happens is it erases data, then overwrites it, and then erases it and overwrites it.  And that's what I assumed happened.  And in fact, when I talked to Mat, he said Apple said the overwrite portion had not completed, so they believed that the data would be recoverable.  Now, there is a four-digit passcode you have to enter, but they were able to brute-force that, that's not so difficult, and get in and unlock it for him, and then he has to bring it in.



STEVE:  Yeah, something...



LEO:  Now, it gets more complicated.  So the Mac Observer had the same questions.  And they did, this week, they did something kind of interesting, a couple of days ago.  They wiped a drive, and they wanted to see, can it be recovered?  And in fact they were able to recover the data.  It took a long time, but they were able to use an application that is designed to recover erased data, called Data Rescue 3, and they were able to recover it.



Now, they point out that, if it's on a solid-state drive, which Mat - it was a MacBook Air, Mat was - that the TRIM feature built into the operating system might in fact make data recovery impossible, or at least spotty, because TRIM overwrites data as part of the "trim" process.  And this is probably the takeaway:  If FileVault had been turned on, which is the whole-disk encryption built into OS X, then it would have been unrecoverable.  The wipe would have been sufficient because, of course, with the wipe you lose the FileVault encryption key.



STEVE:  Okay.  This is all sounding very sketchy, Leo.  I mean, it sounds like they just did a delete, like they deleted files, and then you can undelete them.



LEO:  It does sound like that, although I think they do more than a delete.  I think they delete the partition tables and whatever the equivalent in HFS is of a file allocation table because they had to use the deep scan, which is a sector-by-sector recovery process.



STEVE:  So this just sounds like...



LEO:  But the data was recovered.



STEVE:  Well, I'm glad for that.  But I would say to our listeners, we know about TrueCrypt.  TrueCrypt is real encryption.  TrueCrypt is - anybody who's concerned, as Sam indicated he was that anybody else would have access to his data, TrueCrypt is a beautiful piece of work that runs under Windows and on the Mac platform.  It has the overhead of you need to enter a password in order to boot your system.  But, boy, it solves the problem in the right way.  This sounds really hokey.  I don't know what Apple's...



LEO:  Now, but think about it.  Maybe this was - I don't bet it's a conscious decision because what you're doing is you're wiping it figuring the bad guy is going to, even if he can get through the four-digit passkey, is going to say, well, the hard drive's wiped, and just sell it.



STEVE:  Okay.  But the notion of a four-digit PIN is at complete odds with any kind of, like, wiping.  What does that word mean?  No, we're not getting the whole story.  This is all funky-sounding.  Well, we're wiping it, but we have a four-digit PIN.  What, so you can unwipe it?



LEO:  Yeah.



STEVE:  Okay, then it wasn't wiped.



LEO:  It wasn't wiped.  It was deleted, but not wiped.



STEVE:  So, okay, so what's the four-digit PIN do?  No, there's something - I don't know.



LEO:  Well, the four-digit PIN keeps people from using the computer.  So there's two points here.



STEVE:  Okay.



LEO:  The bad guy can't even use the computer.  And then, should he get in, he'll find a...



STEVE:  The PIN does not unwipe the drive.



LEO:  Oh, no, no, no.  You have to use...



STEVE:  The PIN locks the computer so it's no longer useful to them.



LEO:  There are two options, if you've lost your Mac, on this.  One is to put a PIN on it; one is to put a PIN and wipe the drive.



STEVE:  Got it, got it.



LEO:  So that's fine.



STEVE:  Okay, yes.  Now I...



LEO:  And I think the message, apparently, is, if you're really concerned that some bad guy will get your drive and be smart enough to do a data rescue on it, then you should use whole-disk encryption, which will provide an additional layer of protection.  But Apple, of course, is not going to tell anybody what they're doing because they don't want anybody to know.



STEVE:  Yeah.



LEO:  Quite understandably.  I mean, you know, security through obscurity.  Wil Agnew, Connecticut, takes issue with our casual attitude regarding the Mat Honan hacking: 



First - I'm going to read it in a Connecticut accent - let me say I have immense respect for what you do.  I am a fan of you and your work.  However, I am disturbed by your casual attitude toward the legality of the actions these young people seemed to ignore.  Not being a lawyer - I'm not going to continue this way, obviously.  Not being a lawyer...



STEVE:  I think this would discourage Wil from writing to us again, so...



LEO:  Yeah, well, we're just - we're having a little fun with you, sir.  Not being a lawyer, I may be wrong, but what was described in this hack seems to be a clear violation of Title 18 of the U.S. code, with penalties of 20 years in prison and millions of dollars in fines.  I heard no mention of the seriousness of these hackers' actions under the law, and I seemed to detect an acceptance of this sort of activity, especially regarding the "culture" mentioned near the end of your show.  



Being an IT security person myself, it is clear to me that the first shots of the Cyberwar have been fired - oh, please.  I'm sorry.  Maybe I'll go back to that accent, "...and the U.S. needs young people who have this sort of interest to become the next generation of cyberwarriors rather than waste those skills and interest in technology trying to hack and gain access to a cool Twitter account handle.  Perhaps some constructive feedback by - I did, but, well, all right, I'll finish the letter, then I'll respond.



Perhaps some constructive feedback by people these kids respect could help with this.  I think we mentioned this.  I understand the intent of your podcast was to illustrate an example of all the types of issues you regularly discuss being applied.  I'm just disappointed that the tone of the program never really touched upon the severe penalties this activity can bring to people who do this type of activity.  As a consequence I worry that the Wired article, and your podcast, may actually be encouraging these people to continue doing these activities, in a sense giving credibility to them.  What do you think?



Can I just say, first of all, on the podcast, I said it was a federal offense, a felony.  I did attempt to get Kevin Mitnick, who has served time in jail, about three years - nobody gets 20 years, certainly not for a hack like this - but who did serve three years for a much more severe hack, to talk to them, and he quite wisely said, you know, maybe it'd be better not to talk to people actively engaged in criminal activities, considering my history.  So he declined.  But I did say to these guys, behind the scenes, this is a felony.  Nobody needs to press charges.  The feds do not take well to this.  And I think I even mentioned on the podcast, in this post-9/11 world, these things are - it's dumb to do this.



STEVE:  Nobody is laughing about this, yes.



LEO:  I don't think we mocked it.  I don't think we encouraged it.  It is not our job to enforce the laws of the United States.  There are people duly nominated to do that.  But I think we were very clear about - I don't...



STEVE:  Yeah.  I chose this, obviously I didn't have to, because I thought it was worth mentioning that there was no benefit that these young kids were deriving from this, yet they really were taking a substantial risk.  I mean, as you said, Leo, in this post-9/11 world, and as we really seem to have this notion of cyberwarfare, and cyber is going to be the next battlefield, mindboggling as that is, still, to me, there's a serious consequence to this sort of hacking.



LEO:  Yes.  But nobody denies that.



STEVE:  It's one thing for the Russian Mafia to be doing this, and entirely something else for a bored 19-year-old kid to be sort of wantonly committing felonies.  And so I don't want to see anyone locked up in jail for just screwing around.  And so I guess I see a point to what Wil was saying, which is my sense is these kids probably, as part of their gang or their group or their culture, don't appreciate, I mean, the fact that he was able to ask Mat to agree not to press charges demonstrates a lack of appreciation for the severity, the legal consequences of what he was doing.  And, wow, I mean, he was saying that someone else made the calls to Amazon and was impersonating people.  But this - it was a lot to do.



LEO:  But I'm pretty sure I read this on Security Now!, our conversation in which he said, "Oh, Mat's not pressing charges."  And I said that he doesn't have to.  I said, "I'm no lawyer, but I think you can.  It's a felony, wire fraud."  He said, "Exploiting methods for the better cause, seems unlikely you'd get in trouble."  I said, "Well, the feds don't have a sense of humor."



STEVE:  Yes.



LEO:  I said, "You want me to get Kevin Mitnick to tell you what's going on here?"  But the point is, look, we talk about also bank hacks on this show frequently.  We are not nannies.  It is not our job to say parenthetically, oh, and by the way, it is illegal to hack a bank, and you could go to jail, so don't.  That's not our job, I'm sorry.  I'll leave that to you, Mr. Agnew.  You can go around to the teenagers in your neighborhood and remind them that the U.S. needs their hacking skills.  But it's not my job.  I'm sorry.



Question 7, Dan in South Carolina.  He's wondering about achieving security in the face of extreme access limitations:  Steve, I'm looking for a better business practice for personal account management.  I've wanted to go to a LastPass-like solution for a very long time.  I don't think it will work for me.  I'm in the military, and I work long hours on systems with tight IT controls.  I am often not allowed to have my iPhone with me when I work.  I also travel regularly and find myself on completely new systems.  These are all well-secured systems, but often by different IT departments inside the DOD, with different IT policies.  This guy's a heavy-duty hitter here.



STEVE:  Yeah.



LEO:  The nature of my work necessitates my being able to conduct personal business from work computers during lunch or off-duty hours.  I'm surprised he can.  Six months away from home is a long time not to check your bank account.  Ah, now I understand why.



STEVE:  Yeah.



LEO:  Currently, my password management system is a password-protected Excel spreadsheet - hmmm - mixed case, numbers, and special characters that I email to myself.  Oh, god.  This way, if I find myself sitting down at a new computer in a new place, I can get oriented and get things done.  You bet.  Anyway, these are not random computers in a hotel lobby.  I worry my Excel spreadsheet method may not be sufficient to protect me.  Any advice?  Regards, Dan.



STEVE:  So I thought about this a bit, and I kept coming back to the notion of a pad of paper, essentially.



LEO:  Yeah, one-time passes or something, yeah.



STEVE:  Well, actually, the Off The Grid system that I designed is exactly for this kind of purpose.  Now, I need to also mention that I never put the links up publicly after I described it and discussed it.  A couple people noted that I hadn't handled the case of repeating characters in the domain name during the initial sort of warm-up phase, and I got pulled off of that to work on something else before I got the pages finally all buffed and made public.  But I haven't forgotten it, and I am going to - it's on my short list of things I want to get back to and get finished.



But that kind of system, something that is, I mean, if nothing else, maybe just paper in your wallet or something, I mean, frankly, the Off The Grid system is perfect for this because it's low tech.  I'm a little worried, and I could hear in your tone of voice, Leo, that the notion of a password-protected Excel spreadsheet...



LEO:  Seems an oxymoron.  In the past, it is true that Office password protection has been easily hacked.  But they did go to a much more secure system.  I think they're using a strong encryption technology now.  But I still wouldn't rely on it.  And you really are, if you're emailing it, you're basically making it public.



STEVE:  Yeah.  There's a cool little utility we've talked about a couple times called AxCrypt.  AxCrypt is just a very simple AES-256, standalone, very solid little encryption utility which is freely available on the Internet.  And I would trust it much more than I would trust Microsoft's password on their Office documents.  You're right, Leo, that there's all kinds of "remove the password from your Excel spreadsheet" turnkey third-party utilities floating around.  Maybe they no longer work.  It's not something I've looked at.  But running it through my own encryption I would feel - and then you don't have to really use a spreadsheet.  You just use any file that's convenient.



LEO:  He could probably use - I'm sure LastPass would work on a USB key.  I don't know if he's allowed to bring, and probably isn't in a secure environment...



STEVE:  That's what I was wondering, too, yes.



LEO:  And certainly KeePass, which is an open source password safe that's quite good, does work on USB keys.  You can bring the password database around with you.  You could even email it because it's fully encrypted.  But I bet you, given what he's just described, he's not allowed to bring USB keys in, either.



STEVE:  Yeah, that's why a paper-based system looked like it was the perfect solution for him.



LEO:  Yeah, in your wallet.



STEVE:  Yeah.



LEO:  So you don't have those grids online anymore?



STEVE:  No, actually, it's all online.  And I think Google knows where it is.  But I have never linked it.



LEO:  It's not on your menus.



STEVE:  I haven't taken them officially public yet, yes.  Off The Grid.



LEO:  So Google "GRC Off The Grid."  Let me just see.  Oh, yeah.  No. 1 hit.  But are you saying it's imperfect?



STEVE:  No.  It works.  Some people noted that I had - there was a case that I hadn't handled yet, and so I just haven't gotten around to updating the documentation.  And I just want to read it all again.  I feel like I just hadn't quite finished it.  And so I didn't take it public yet.



LEO:  But he could currently print this grid out.



STEVE:  Absolutely.



LEO:  And create an algorithm for generating a password that only he knows.  And then he'd have it.  And these are all unique.  Each time you load this page you get a unique grid.



STEVE:  Yup.  And then there's also the Grid Generator page a little bit further in.



LEO:  Ah, okay.  So all the details are here.  That's probably the best thing.  And that - they can't stop him from bringing his wallet in.



STEVE:  No, or just a sheet of paper.



LEO:  Or a sheet of paper.  Philip Boccia - I bet you it's Boccia - in New Hyde Park, New York, asks about the Internet WHOIS system:  Steve, in Episode 364 you and Leo talked about the problem of no privacy with WHOIS lookups. Isn't one of the reasons this information is publicly available is to thwart the creation of rogue websites?  If you make the WHOIS information private, wouldn't that essentially be protecting those bad guys who set up illegal and phishing sites?  We should explain. Go ahead.



STEVE:  So WHOIS, yeah, back in the beginning, the dawn of the Internet, there was an interest in creating a sort of a translation between the virtual world and the physical world.  And there was actually one physical server that DARPA was running that was the WHOIS server.  And anybody could send it a query.  You could say, who owns this block of IPs, who owns this domain name, and it was like a big lookup database that was freely accessible to anyone.  And it's never gone away.  You used to even be able to give it wildcards, like you could say, tell me all the Gibsons you have, and it would just dump them out.  Clearly those days are long since past.



Today what we have is still this notion of the WHOIS system being used to map domain names to real-world entities.  The problem is that it's up to the registrars to fill out this information.  And the registrars are not in the business, especially if you're not asking for SSL certificates, they're not really in the business of verifying people's identities or performing any great amount of follow-up to make sure that what you've told them is valid.  They're happy to take your money and essentially give you control of a domain name that they stick into the Internet's DNS system, and they feel that their job is done.



I'm unimpressed by several things.  First of all, it is, unfortunately, it's been used as a source of spam.  That is, spammers have figured out that there are email addresses of what used to at one point have been important people who were administrative leads for their domains.  And so it was one way that spam found its way to people is that they would put real email addresses in their WHOIS records.  By law, technically, you're supposed to have real contact information there.  I mean, that's what it's for.  So what annoys me most, frankly, is that someone like Network Solutions charges money per year, it's like $9 or $10 per year per domain name to obscure your WHOIS lookups.



Now, to answer Philip's question, Network Solutions knows who's behind or theoretically behind the WHOIS information that they manage.  So certainly, even if it was obscured or encrypted or protected, they could be served with some government documents compelling them to tell them what information they have about somebody who owns a domain, and I'm sure they would turn it over.  So unfortunately it's just become useless, pretty much.  It's full of junk.  It's not accurate.  It only contains whatever information someone chose to give the registrar.  What do you think, Leo?



LEO:  I think Steve Gibson is not impressed by WHOIS.  And by the way, the current WHOIS privacy system, if it were a bad guy, they'd just go to the server, and they'd say, well, who is it?  I mean, it's not hidden from the hosting company.  It's just from the casual WHOIS searcher.



STEVE:  Right.



LEO:  So I don't think that that's a problem.  And I think privacy's important because otherwise my personal address is posted in there.



STEVE:  Yeah.



LEO:  Colin in Cleveland says, what about best practices for security questions?  Which are insecure to begin with.



STEVE:  Yeah.



LEO:  Listener for about a year here, love the show.  Last week's show following the details of Mat Honan's hacking has brought a question back to mind:  What's your approach for handling security questions?  I've done what I can to avoid questions that could be answered by a Google search, but I've never been able to find a reliable method for having secure answers that are easy to remember.  I'm already using LastPass for my passwords, so anything I can do to improve these questions will significantly boost my online security.  What are your thoughts?  Yeah, I wish we could just turn these off.  Wouldn't that be nice.



STEVE:  So the good news is Colin is a LastPass user.  LastPass has a Secure Notes option, and security questions are not something that you generally need to have on the tip of your fingers or that you're being bugged about all the time.  It's sort of a fallback password recovery option.  On the other hand, one would hope, if you're using LastPass, you've got enough technology at your beck and call that you're not needing to use password recovery.



But my point is that you could just generate things that look like passwords, I mean, like nonsense strings, to answer security questions, but you could never remember those.  So LastPass has this cool little secure notepad where you're able to create notes and name them.  So you would name the notes after the domains that you have answered these questions for and store your answers there so that LastPass will keep them secure.  They're encrypted.  You don't need to remember them.  And if you ever need them again, you can ask LastPass what it was that you used for your first girlfriend's name or your favorite teacher from high school or whatever.



I ran across somebody, I think, of the email I saw, or maybe somebody tweeted - I think it's too long to have been a tweet.  Someone was saying, though, that they were in an online conversation with some people that they connected with, who were sort of chatting back and forth.  And after a while, one of them sort of casually said, "So, out of curiosity, if you had to, who would you say was your first childhood friend?"



LEO:  [Laughing] Just askin'.



STEVE:  Just, you know, we're just...



LEO:  My first childhood friend was Sally.  Who was yours?



STEVE:  Uh-huh.



LEO:  Wow.  That's just...



STEVE:  I'm not kidding.  And this person, whoever it was, it must have been a follow-up that I saw from our Mat episode last week.  And he said, sure enough, I went back to the system that we were using, and that was the security question which this particular service had.  And so they were just - they were trying to socially engineer him.  Just kinda curious who would you...



LEO:  Do you remember your first pet's name?



STEVE:  You know that six degrees of freedom?  Maybe we happen to know the same...



LEO:  Who was your favorite schoolteacher?  Just off the top of your - you know, the truth is, I just realized I said they should turn them off.  It's easy.  If you don't want them, don't use them.  Just put nonsense in there and don't use it.  But understand that if you ever have to - now the onus is on you not to lose your password.



STEVE:  Correct.



LEO:  I guess there are some places like your bank and stuff where you - actually, when I call my credit card, they will ask what's the name of your first teacher.  It's so - that's the problem is that they - no one should rely on these.  That's the real problem.



STEVE:  Yeah.  The one thing that I've seen a couple times are sites that allow you to provide the security question...



LEO:  Yeah, write your own.



STEVE:  And the matching answer.  So at least there, they're not all the same.  Apple, I guess, has a set of really dumb things that are like, okay, well...



LEO:  The concept is flawed.  The whole point of a security question is what's something you can easily remember and easily retrieve from your mind if you forget your password, you nitwit?



STEVE:  Yeah, and we've talked about the nature of multifactor authentication is multiple factors.  One of the things that Mat's story showed us last week was that Apple said, oh, you don't remember your security questions.  Okay, well, in that case...



LEO:  No problem.  You're even stupider than we thought, but that's okay.



STEVE:  Either honor them or don't.



LEO:  Yeah, or don't use them.  And as you said last week, then let the onus be on the user.  We can't help you.  You forgot your password, sorry.  Maybe you'd better set up a new account because we don't know.  And really that's another problem.  I don't know if you got emails about this.  But should customer service reps have access to that kind of information?



STEVE:  Yeah.



LEO:  Because that's a hole.  That's a flaw.  And I think the fact is that stuff's not going away.  I don't know what we can do about it.  I mean, it's going to happen.



STEVE:  No. 10.



LEO:  This is our last question.  Security Now! listener Paul in Ottawa, Ontario, Canada, shares his observation about Mat Honan's Very Bad Weekend as it relates to compromised user databases:  Steve, as you know, recently several user information databases at Sony, Yahoo!, LinkedIn and others were compromised.  With so little information required to reset someone's password at some companies, wouldn't a compromised database be easy to use to access someone's account, or everyone's account, even if their password is hashed?



A lot of the other information, like email addresses, billing addresses, credit card numbers could not be hashed.  It's needed by the company; and that information possibly, and most probably, is not encrypted, or at least could be decrypted.  If someone were to reset their password after learning of a compromised database, all the information is still there.  And that really was, I think, the lesson of this hack, to simply call and get a password reset.  A company's password reset policy could be the weakest link in the chain.  What do you think?  Paul from Ottawa.  I think that was really the point we were making is that you can have LastPass, strong passwords.  And in a case like this, if the company doesn't have good security policies, you're screwed. 



STEVE:  Yes.  And I've been thinking about it in the week since, and I'm in the process of putting together sort of a commentary that I will share with our listeners next week.



LEO:  Excellent.  Well, there you go.



STEVE:  And I agree with Paul.  It is clearly the case that the password reset policy is the weakest link.  We're to the point where we need to change something, and I have a suggestion.  And we'll share that next week.



LEO:  What a tease you are.  Steve Gibson, the Explainer in Chief.  You'll find him at GRC.com, the Gibson Research Corporation.  That's where he hangs his hat and SpinRite, the world's finest hard drive and maintenance utility.  You can also find lots of freebies there.  In fact, even though Off The Grid's not on the menu, it's off the grid, you can Google it, and it's there, too, and a lot of other very useful stuff.  He tweets on the Twitter at @SGgrc.  There's also @SGpad and @SGvlc, but don't tell Dr. Mom what that means 'cause she's sitting right over here and giving me the stink-eye right now.  But it's okay because I had some chocolate, and she feels better.  Isn't that interesting.  I had chocolate, but you feel better.



STEVE:  You have chocolate, and she feels better.



LEO:  Yeah, it's interesting.  Steve, it's always fun.  I really appreciate it.  We will talk next week about security, privacy, science fiction, coffee, and anything else that's on your mind.



STEVE:  Fantastic.  I look forward to it.



LEO:  Take care, Steve.  We do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC on TWiT.tv.  Do watch live.  We'd love it if you do.  I interact with the chatroom and so forth.  And of course after the fact we make on-demand versions available.  Steve's got a great 16Kb audio file for the bandwidth-impaired, also the smallest version of this show, which is a text transcription.  That's at GRC.com.  We have the audio and video, the fat stuff, at TWiT.tv or wherever finer podcasts are offered for download.  Thank you, Steve.



STEVE:  Thanks, Leo.



LEO:  See you next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#366

DATE:		August 22, 2012

TITLE:		Password Cracking Update:  The Death of "Clever"

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-366.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a collection of miscellaneous and interesting security-related news, Steve and Leo take a close look at the long-term consequences of the many massive password leakages which have occurred.  The upshot?  Hackers are getting MUCH better at cracking passwords, and "clever" techniques can no longer be regarded as safe.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about, well, he calls it "The Death of Clever," what password crackers know about your password and how easy it is to crack.  It's coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 366, recorded August 22nd, 2012:  The Death of Clever.



It's time for Security Now!, the show that covers security and all that great stuff with this cat right here, the Explainer in Chief, Mr. Steven Tiberius Gibson.  I gave you a middle name.



STEVE GIBSON:  I watched a fun movie the other day, which had a sort of a surprise for me, sci-fi, of course.  Well, not of course, but in this case it was:  "The Puppet Masters."



LEO:  I don't know that one.



STEVE:  Donald Sutherland and some other people who we've not really seen much of.  And I watched it with Jenny.  Jenny had never seen it before, and she really enjoys sci-fi as much as I do.  But she was sort of thinking, well, okay, all of these plot vehicles are sort of familiar.  Like, well, you know, this is from "Aliens" and this is from this and this is from that.  And I said, yeah, but this was a lot - this, like, predated them all.  Well, I didn't know by how much until I found my copy of the paperback, which was copyright 1951.



LEO:  Wow.



STEVE:  And I was like, whoa, Robert Heinlein really was ahead of his time.  That was just amazing.



LEO:  And when was the movie made?



STEVE:  Oh, the movie was in the, like, late '80s, I think, or maybe early '90s.  Wasn't a long time ago, although I didn't remember how hokey the cinematography was.  We were sort of laughing about it because it was kind of cheesy.



LEO:  You know, it's funny, it doesn't take long.  I was watching "Total Recall" with Arnold Schwarzenegger, the original, and that was late '80s, something like that.  And it really looks dated.  It looks like a bad '70s cop show, practically.  I mean, it's funny how far we've come.



STEVE:  Yes.  This had exactly the same feel.  And I was asking Jen, I said, what is it?  It's like little subtle things, I guess, that have evolved in our understanding of how to make something...



LEO:  And fast.



STEVE:  Yes.



LEO:  IMDB says 1994 for that movie.  So that was only 18 years ago.  That's not a huge difference.  But things have, you know, it's computers.  You've heard about them; right?  They've made a big difference in everything, including filmmaking.



STEVE:  There was sort of some exposure, like it was kind of overexposed, or a little too much brightness or contrast.  And, oh, the other thing I noticed was that they seemed to be much more kind of in our face, as if we were looking at a smaller screen, much further away...



LEO:  Interesting.



STEVE:  ...than we are now.  Now we've got much bigger screens.  They generally are closer.  And of course the resolution is way up, so we don't need things really big in our face any longer.



LEO:  Yup.  We've gotten subtler, and we have more lens flares, that's right, chipo burrito.  That's thanks to Joss Whedon, I think.  Today the show is called, not "The Puppet Masters," "The Death of Clever."



STEVE:  Well, yes.  This is a - I guess I would call this a "crowd-sourced topic" because there has never been an article that received so much tweeting to my attention as a recent article in Ars Technica.  Their cybersecurity guy, Dan Goodin, did a very nice, very comprehensive, four-page piece about sort of a snapshot on where we stand with password hacking.  And obviously this is a recurring topic for us.  But I decided that we really needed - well, first of all, many people were tweeting, Steve, what do you think, what do you think, is he right, blah blah blah.



Now, he didn't really draw any conclusions.  We will, because this is what we do in the podcast, have some takeaways from this.  But what I felt as I was reading it was that I needed to make sure our listeners understood something that I don't think I've ever made sufficiently clear.  So I titled this "Password Cracking Update:  The Death of Clever" because what this really drives home is that - and this is really interesting, too, because this is a consequence of the breaches that we've had.  We've covered these massive breaches for the last few years.



Well, it turns out having access to more than 100 million actual in-use passwords, which is what are now available, freely downloadable over the Internet, having those actual passwords has changed the complexion of password-cracking.  All of those things that we sort of "wink, wink" about doing, like changing alphabetic characters into the numbers that they resemble, or those sorts of things - and we'll talk about what those are because they've all been analyzed now.  What's happened is, and this is another thing you would expect, over time there's evolution of the technology.  The cracking is really getting better.



And so today's podcast, driven by so many questions that were tweeted to me about it, will update everyone.  And if anybody still thinks that they're being cute with the way they're designing passwords, I hope to be able to increase their security further by putting them off of those habits because they're just not working any longer.  And we've got a bunch of interesting news, as well.



LEO:  You must be hitting something people want to know because we have five people in studio here watching.  We've got the Gale [ph] family.  They're visiting from Vancouver.  And we've got Joe visiting from Richmond.  And six more people have arrived.  I guess they heard you're going to be talking about this.  And we have an overflow audience here at the Brick House.  We're going to have to put them in the living room.



STEVE:  You need stadium seating.



LEO:  Boy, you're turning out to be quite the popular fellow, Steve.  Good.  This will be very - I'm looking forward to it.  I actually saw that article.  I read that article, and it scared me a little bit because, well, he mentions a well-known person who has a password that is, I would have thought, secure, and how easy it was to crack it.  It reminded me a lot of passwords that I have used.



STEVE:  Well, yes.  And that's really what I want to - I think one of the takeaways is - he actually refers to a doctoral thesis by someone who analyzed how badly human-chosen passwords are.  So the idea is you just - you don't want it to be up to you.  You want to turn over responsibility to something else.



LEO:  I started, after reading article, more religiously using the generator built into LastPass, and I set it for 12 characters and special characters mixed and everything.  Although I'm a little disappointed.  I opened an account at a new bank the other day, and I was actually quite disappointed.  First of all, I could only use, I can't remember what it was, 12 or 13.  After that it stopped.  I couldn't use more characters, which I know from listening to the show means that they're not hashing passwords, or it wouldn't matter.  And second, that they wouldn't allow me to use special characters.



STEVE:  Yeah, I get reports of these sorts of bad security practices constantly, so it's amazing how widespread this is.



LEO:  And yet they use two-factor authentication.  They do all sorts of jump-through-hoops things.  So I'll just turn that on, and now I feel a little bit better about it.



STEVE:  That's good.  Well, so one bit of news that I thought was important because it had been underreported and misreported, and it potentially bears on our listeners.  And that is that our friend Moxie Marlinspike, along with an associate of his, Dave Hulton, gave a presentation at the DEF CON 20 conference some time ago, I think it was in June.  But their particular talk was just, I don't know if it was that it was not understood or what the problem was.  But, for example, the thread post site said "New Tool From Moxie Marlinspike Cracks Some Crypto Passwords."  And I saw some other sort of lukewarm explanations of what Moxie and Dave did.  And I thought, okay, I need to give this a little bit of time because people need to understand what happened.



What they looked at was a longstanding mutual authentication protocol that Microsoft created called CHAP, or in Microsoft's version, MS-CHAP, which did have security problems in v1, which they updated to v2.  And it's made people uncomfortable, but not sufficiently uncomfortable.  The reason this is important is that it is still the authentication protocol used in almost all VPNs.  Most VPNs are still using the so-called Point-to-Point Tunneling Protocol which we talked about years ago, PPTP, you remember, when we were having fun with that acronym, Leo.



LEO:  Yes, I do.



STEVE:  And many enterprise environments are using this for their radius server authentication in their WPA2 environments.  So just to read from the beginning of Moxie's posting, he said, "The first obvious question is why we looked at MS-CHAPv2, given a lingering sense that the Internet should already know better than to rely on it."  He said, "Unfortunately, however, even as an aging protocol with some prevalent criticism, it's still used quite pervasively.  It shows up most notably in PPTP VPNs  and is also used quite heavily in WPA2 Enterprise environments  often in cases where its mutual authentication properties are being relied upon.



"For the talk, we put together a list of the hundreds of VPN providers which are now dependent on PPTP."  That is, all of these commercial VPNs that are available online are using PPTP, Point-to-Point Tunneling Protocol.  "This included some high-profile examples such as iPredator, The Pirate Bay's VPN service, which is presumably designed to protect communication from state-level observation," and so on.  And in the case of The Pirate Bay, they say on their site, "Right now we only offer PPTP," where this MS-CHAP is the authentication protocol for it.



Well, without going into infinite detail - because there's really no point.  Moxie does describe this on his CloudCracker site in sufficient detail.  What they essentially did is they carefully analyzed the handshake which the endpoints that are negotiating for mutual authentication go through, and looked carefully at the assumptions and what was known.  And they managed to reduce it through a very clever series of analysis down to a total complexity of only 2^56.  So that's 56 bits, which is the strength of a single...



LEO:  That's terrible.



STEVE:  ...DES encryption.  And we all know that DES has long since been determined to be extremely far from secure enough.



LEO:  3DES is what we use now, three times; right?



STEVE:  Yes, yes.  And I had - I don't see it.  I had it, and I'm afraid I closed it.  I had the page open to - shoot - to his blog site.



LEO:  I can link to it.  I have your notes.



STEVE:  I wanted to explain what he's done so that I get everyone's attention here because this is - I found it here.  This is significant, essentially, in what these guys have done because the way Moxie explained it, on his page he breaks down the protocol, shows how they divide this thing in the way the handshaking is going, all the way down to a key space, essentially, of 2^56, which we know is not strong.



So then he says, "At this point a question of feasibility remains.  In 1998 the EFF used ASICs" - Application-Specific ICs - "to build [their] Deep Crack [machine], which cost [them]" - in 1998 - "250,000 and took an average of 4.5 days to crack a [56-bit DES] key.  David Hulton's company, Pico Computing, specializes in building FPGA (Field Programmable Gate Array) hardware" - which is like sort of a modern-day version of an ASIC, but you're able to just load the circuitry into it through software.  He "specializes in building FPGA hardware for cryptography applications.  They were able to build an FPGA box that implemented DES as a real pipeline, with one DES operation for each clock cycle.  With 40 cores at 450MHz, that's 18 billion keys per second" that this box, based on basically standard hardware, is able to crack.



"With 48 FPGA [chips], the Pico Computing DES-cracking box gives us a worst case of about 23 hours for cracking a DES key, and an average case of about a day" - I'm sorry, an average case of half a day, worst case 23.  So that's what we would expect.  You might get lucky and hit it on average of half of the worst-case time.  So the worst case, about 23 hours, is the entire 56-bit key space, and you're probably going to get it in half that.



LEO:  Wow.  That's the average, right, is half that.



STEVE:  Right.  But these guys, what I love about Moxie is he drives it, because he has moxie, all the way home.  He says, "With Pico Computing's DES-cracking machine in hand, we can now crack any MS-CHAPv2 handshake in less than a day.  It wouldn't be a ton of fun if only David or I could crack MS-CHAPv2 handshakes, however.  So we've integrated the DES-cracking box with CloudCracker, in order to make David and his team's genius and skills and resources available to everyone.  We've published a tool called 'chapcrack,' which will parse a network capture for any MS-CHAPv2 handshakes.  For each handshake, it outputs the username, the known plaintext, two known ciphertexts, and will crack the third DES key.  It will also out put a CloudCracker 'token,' which is an encoded format of the three parameters we need for our divide-and-conquer attack," which is what they called this attack.



"When this token is [then] submitted to CloudCracker, the job is transmitted to Pico Computing's DES-cracking box, and you receive your results in under a day.  What do you win?  At this point, you can plug the cracked MD4 hash CloudCracker gives you back into chapcrack, and it will decrypt the entire network capture and all future captures for that user."  So he says, "Alternatively, you can also use it to log into the user's VPN service or WPA2 Enterprise radius server."



So what they have done is completely reduced this protocol to rubble, which is the No. 1 most used protocol for VPN authentication today, used by thousands of commercial VPN services.  So this means you capture the traffic.  You've got to jump through some hoops, so this is not yet single pushbutton ease, but we know that that's the way these things begin is not being that way, and they evolve into that.  And this will decrypt the entire VPN encrypted communications.  So I thought that was just worth mentioning, Leo.



LEO:  But does anybody use, what is it, CHAP, does anybody use it anymore?



STEVE:  Every VPN.



LEO:  Oh, crap.



STEVE:  Yeah.



LEO:  CHAPv2.  That's how VP - oh.  I thought it was just - not just Microsoft.



STEVE:  No.  The Point-to-Point Tunneling protocol is...



LEO:  All PPTP does it, not just Microsoft's implementation?



STEVE:  Yes, all PPTP.



LEO:  Oh, crap.  But it is Microsoft's CHAPv2.



STEVE:  It is, but it's an RFC standard that everybody else has adopted.



LEO:  Wow.



STEVE:  Yeah.



LEO:  And we thought VPN was safe.  So how practical is this?



STEVE:  Again, this is, well, for example, you want to use an SSL VPN.  That's the buzzword you look for.  You don't want to use PPTP.  Unfortunately, most VPNs today, and for example, The Pirate Bay's VPN, that's all they offer for their service, is they're all using PPTP.  Just because of inertia, basically.  It's stable.  It's reliable.  It's free.  It's online and open source, and that's what people set up when they're creating VPNs.  Well, if your traffic is captured, Moxie and his team now make it trivial to basically decrypt the entire conversation.  



LEO:  Wow.



STEVE:  Yeah.



LEO:  Wow.  That is kind of surprising.  Wow.



STEVE:  Now, I saw something really nice.  Reuters on Monday put up a story about how a group is working on strengthening the security of cars, which I'm really glad for because I'm really worried about automotive security as everybody rushes to compete with each other headlong into more technology.  What caught my eye in the article, and the reason I wanted to mention it, was a reference specifically to Ford, and it's good news.  So I'm just going to share that much of the top of the article.  This was written by Jim Finkle for Reuters.  He said, in Boston:



"A team of top hackers working for Intel Corp.'s security division toil away in a West Coast garage, searching for electronic bugs that could make automobiles vulnerable to lethal computer viruses.  Intel's McAfee unit, which is best known for software that fights PC viruses, is one of a handful of firms that are looking to protect the dozens of tiny computers and electronic communications systems that are [today] built into every modern car.  It's scary business.  Security experts say that automakers have so far failed to adequately protect these systems, leaving them vulnerable to hacks by attackers looking to steal cars, eavesdrop on conversations, or even harm passengers by causing vehicles to crash."  And of course we've talked about these problems, those specific problems, through the last few years as this has begun to make the news.



"'You can definitely kill people,' said John Bumgarner...."



LEO:  Oy.



STEVE:  Sorry?



LEO:  Oy.



STEVE:  Yeah.  Oh, yeah.  You can slam on the brakes.



LEO:  You could, like, lock up the brakes, yeah.



STEVE:  Yes, "...said John Bumgarner, chief technology officer of the U.S. Cyber Consequences Unit, a nonprofit organization that helps companies analyze the potential for targeted computer attacks on their networks and products.  To date there have been no reports of violent attacks on automobiles using a computer virus, according to SAE International, an association of more than 128,000 technical professionals working in the aerospace and the auto industries.  Yet, Ford spokesman Alan Hall said his company had tasked its security engineers with making its Sync in-vehicle communications and entertainment system as resistant as possible to attack.  'Ford is taking the threat very seriously and investing in security solutions that are built into the product from the outset,' he said."  Which was, frankly, that was good news.



LEO:  That's a relief.  No, I know Alan, and I know this because I've talked to their technologists, as you know, for years.  And they have a very clear separation between the in-car computer, the real computer, and the - it's not the same computer, even.



STEVE:  There was one instance where an infected CD was played in the CD player that allowed it to get out of the player and into the car's automotive electronics.



LEO:  Not in a Ford.



STEVE:  Not in a Ford.



LEO:  I just want to point this out.



STEVE:  Not in a Ford.



LEO:  In another company's setup.  No, and we've seen all sorts of weird - you could drive by, and they can reprogram the car.  But that's not in a Ford because they understand this, and they very intentionally separate the two systems.



STEVE:  Yup.  And just to wrap up, it says, "And a group of U.S. computer scientists shook the industry in 2010" - and we covered it then - "with a landmark study that showed viruses could damage cars when they were moving at high speeds."



LEO:  Yup.  Yup.



STEVE:  "Their tests were done at a decommissioned airport."



LEO:  In case the car took off.  Yeah, no, I remember we did that story.  In fact, it was after that that I asked the Ford folks.  And they said, oh, no, no, no, you couldn't - no, no, couldn't happen with us.



STEVE:  Yup.  And I was just glad to see that Ford and Alan were quoted as saying, yes, we're on top of it, because this is something you need to get ahead.  You need to be proactive rather than reactive.



And finally, Amazon has a new service that I just - every time I look at the name, it makes me grin.  And I'm glad for it because I think it's really interesting.  It's called Glacier.  What it is...



LEO:  Oh, I like this.



STEVE:  Yes.  It is long-term...



LEO:  I like the logo, too.



STEVE:  ...archival, yes, long-term archival storage for an amazingly low price.  The idea is it is glacial in its response.



LEO:  Brilliant.



STEVE:  Yes.  So again, quoting from them, they said:  "Amazon Glacier is an extreme" - it's aws.amazon.com/glacier.  "Amazon Glacier is an extremely low-cost storage service that provides secure and durable storage for data archiving and backup.  In order to keep costs low, Amazon Glacier is optimized for data that is infrequently accessed and for which retrieval times of several hours are suitable."  So it's offline storage.  "With Amazon Glacier, customers can reliably store large or small amounts of data for as little as" - and here it is - "$0.01 per gigabyte per month."



LEO:  That's awesome.  That means it's 10 bucks a terabyte.  That's great.



STEVE:  Yes.  Let's see, so...



LEO:  Is that right?



STEVE:  Let's see.  So 100GB for $1 per month.



LEO:  So 1000GB for $10, yeah.  Terabyte is $10.  That's amazing.  That's great.



STEVE:  Yes.  So the way they have it organized, data are stored as archives.  Retrieval of an archive takes, they're quoting, three to five hours.  Archives are organized in vaults.  And there is zero transit cost to upload.



LEO:  Unlike Amazon S3, where you pay for...



STEVE:  Actually S3 has gone to zero.



LEO:  Oh, it has, too.  Because you used to pay for transmission plus storage.  Now it's just storage.



STEVE:  Yes.  Well, no.  Or retrieval.  You do pay for transit down to you, but not up to them, which I love because my main application is sending images up to them after I encrypt it locally.



LEO:  So that's what I'm going to do.  This is where I put my photos.  And then my children, and my children's children, will be able to ignore those photos for generations to come.



STEVE:  So I don't know what the model is.  I don't think it's tape.  I think it must be powered-down, offline hard drives, that they must actually take them and pull them out of servers and store them somewhere so that, if you submit a request, maybe it's a bot or a robot or I don't know if it's a person or what the model is, but...



LEO:  Somebody goes down - I know what it is.  It's an Indiana Jones-style giant warehouse.



STEVE:  Yes.  I think it probably actually is, Leo.



LEO:  And as a machine goes down, a robot goes down and gets the hard drive, pulls it out, and runs it down to the data center where - I bet that's what it is.



STEVE:  I bet it's not a bot, though, because that wouldn't really explain that time delay, unless they just want to give themselves some buffer.



LEO:  They want to give you the time delay so that you don't use this instead of S3.  That could be completely arbitrary.



STEVE:  That's a very good point.



LEO:  It's just a distinction.  I love this.  This is great.  Who doesn't - who, I mean...



STEVE:  I know.  I'm never needing to access these snapshot images fast.  But you don't want them to break the bank, and three to five hours, that's fine for a big image.  So anyway, I really think this is a nice service.



LEO:  Very, very, very cool.



STEVE:  And then I have...



LEO:  Is it going?  Is it started?



STEVE:  Yeah, it's available now.



LEO:  That's great.



STEVE:  And I did get a nice note, a short one, from a Wayne Scott in Australia, who said, "I've known about SpinRite for many years, using it on my own PCs after deciding to purchase a copy when I had to do a recovery on a customer's hard drive.  Another company had attempted data recovery before that and returned the drive as faulty and unrecoverable.  So I wanted to have a go.  Where the data recovery company had failed, other" - he says "other SpinRite," it's a little typo here.  "Where the data recovery company had failed, SpinRite made the drive readable once again, and I got the data off.  The customer was very happy because it was for the tax department."  So once again...



LEO:  Ooh, wow.



STEVE:  ...SpinRite to the rescue.



LEO:  You don't want to lose your tax information.



STEVE:  No, you don't.



LEO:  Unh-unh.  All right.  We're going to talk about "The Death of Clever."  I like this subject.  Are you ready?  Let's talk about the end of clever.



STEVE:  So Dan's article, or his security blog posting, was "Passwords Under Assault."  Anyone who wants to read the entire four-page piece can just Google "Passwords Under Assault," and it's the first link that comes up.  And he titled it, "Why passwords have never been weaker and crackers have never been stronger."  Which sort of reminds us of the famous Bruce Schneier quote, where he noted years ago that attacks never get weaker, they only get better.  And Dan said, "Thanks to real-world data, the keys to your digital kingdom are under assault."



So essentially what's happened is there have been consequences, there's evolutionary effects that we would expect, that is, passwords are very tasty fruit for hackers to try to grab.  And, unfortunately, websites have proven themselves surprisingly inept at managing user logon credentials.  We're routinely, actually, covering the major breaches in passwords.  It was just a couple months ago, in June, that LinkedIn famously lost control of 6.5 million passwords.  What's happened is, as a consequence of those and other breaches - there was another major gaming site that lost, I think it was 32 million of their user passwords all at once.  And so what's happened is it's moved the hackers' understanding of what passwords people are using from theoretical, like the planets of the Klingon universe, to the actual.  And we've learned weird things, like "monkey" is used unusually often, Leo.



LEO:  It's so embarrassing because it in fact was my default password many years ago.



STEVE:  But how obscure is that?  But the point is that, for some bizarre reason, lots of people chose the word "monkey."  Well, nobody would guess that.  So it's only by looking, doing statistical analysis of actual password databases, that these sorts of things come out.  Another thing that is often occurring is that people capitalize words, instead of them being all uppercase or all lowercase.  They tend to - first character is capital, then the rest of them are lowercase.  Many times people create passwords which are word followed by four numbers, like their date of birth, for example, or 1492, something that is memorable to them, but they think, oh, this is clever.



LEO:  But that's what you're talking about with Password Haystacks.  That's padding.  That's not a bad thing, as long as it's not guessable.  Right?



STEVE:  Well, okay.  So the problem with patterns, like the idea of eight characters where the first one is uppercase and the other ones are lowercase and then, for example, a four-digit number, if you made it five digits, that is, if you broke the pattern, then you get security.  If you don't, what analysis of databases have shown hackers is that, in the same way that for some bizarre reason the password "monkey" gets chosen way more often than randomly,  people are using eight-character alphabetic words followed by four-character numbers, I mean, exactly that pattern.  And so what happens is, if that's known, or even just believed, that is, if it's tried for, then it completely changes the math.



For example, say that you didn't know what a 12-character password was, and that it could use the full alphabet and special characters and numbers.  Well, any one character, as we've talked about many times, could have approximately 96 different possibilities.  So 12 of those would be 96^12, since it's 96 for the first character, 96 for the second character, 96 for the third.  But we also know that that really only applies if the 12 characters are really random.  They could be anything.  And 96 raised to the power of 12 is 612.7 times 10^21.  Huge number.  That's 612,700 billion billion possibilities for 12 characters.



But people don't choose their 12 characters randomly.  And what statistical analysis of these captured online databases have shown hackers is that, as I was saying, for example, there's a huge preponderance of first letter is capitalized, the next seven are lowercase alpha, and then they're followed by four digits that is, like, a year.  It's something generally in the 20th Century.  So what that does is that dramatically changes the math.  Now that means you only have 26^8 power since you have only - you know you're going to have capital A through capital Z, then lowercase A through Z for the next seven characters.  Then say that you didn't even constrain it to a modern-era year, but you just did 0000 to 9999, so now you're at 26^8 times 10,000.  Well, that's only 2.08 million possibilities, compared to 612,700 billion billion possibilities.



So the point is that, what hackers have done is, by analyzing the actual databases of captured passwords, they have found all of these tendencies.  It is absolutely no longer the case that we can do anything clever.  We cannot use, like, "Prince$$," where we change the S's into dollar signs.  They got that.  You can't use...



LEO:  Cracked.



STEVE:  Sorry, Leo.  You can't turn your E's into 3's.  They got that, too.  I mean, all of the kinds of things that people typically do, thinking that they're being clever, trying to sort of - essentially we're trying to compromise.  We're trying to come up with something that's sort of ours and that we think nobody else is going to do.  Well, surprisingly, because we're all human, and we have similar experience, we're generally doing the same things, it turns out.  When you statistically look at 100 million passwords, there aren't that many possible things that people can do that meet these criteria.  And of course there's certainly some communication among people.  Not everyone is coming up with these things on their own.  They're talking to their friends about, oh, what do you do, how do you make passwords?  And so they share some of their ideas.



Oh, the site was RockYou.com which, in 2009, through a SQL injection attack, lost their 32 million plaintext passwords, which all went into this huge 100 million-plus hopper for statistical analysis.



So the other thing that has happened is, and this is the evolutionary part, not only are hackers really focusing on this, but as we know, there's been huge movement in technology over time.  We've talked about how GPUs, the graphic processing units that are now powering our graphics cards in order to give us the 3D realism and high frame rate performance that we want for gaming, those can be repurposed to create essentially cryptographic pipelines which are able to run cryptographic algorithms at very high speed.



One of the takeaways from all of this is that hashing was never the right thing to do.  Hashing was better than leaving things in plaintext, certainly.  But hashes were designed, as we have said before, for speed.  They were designed to be efficient.  But efficiency is exactly what you don't want in password security because it allows brute-forcing to run at tens of millions of guesses per second.  So while it's certainly better that sites have been hashing their passwords than not, it turns out that we no longer should consider that very useful.  Certainly not if they are unsalted hashes.



The LinkedIn breach that we talked about in June, where 6.5 million passwords were lost, to give you some sense for this, for what this really means in the real world, independent security researcher Jeremi Gosney took the leaked LinkedIn unsalted but hashed, it was hashed with SHA-1, database.  He applied it against his 500 million strong word list of common words, using a block of GPUs, which are able to make 15.5 billion guesses per second.  This is not the NSA.  This is some guy in his bedroom who can do 15.5 billion guesses per second.  Against LinkedIn's 6.5 million passwords, he cracked the first 20 percent in 30 seconds.  He had one out of every five of that 6.5 million passwords cracked in 30 seconds.  The next 33 percent took two hours, so in two hours and 30 seconds he had 53 percent of them cracked.  It began to slow down exponentially so that, after a day, 24 hours, he was at 64 percent of the 6.5 million passwords cracked.  And after five days, he had an additional 24 percent.



So we're not talking long-term protection here, if a database gets loose, even if it is salted.  That's no longer the case. The other interesting thing to Google is a new, open source, free, GPU-based cracking facility called Hash Cat.  You should bring it up onscreen, Leo, H-a-s-h and then space, Cat, Hash Cat, calls itself "advanced password recovery."  It's the first result in Google, and it's just HashCat.net, also.  And it says, "Download the latest version."  The requirements are, for NVIDIA users, you need to have their ForceWare 290.40 or later; for AMD users, you need to have Catalyst 12.4 or later.  And it looks like a very nice, professional piece of work.  Under features they claim the world's fastest md5crypt, phpass, mscash2 and WPA/WPA2 cracker; the world's first and only GPGPU rule-based engine.  Its multi-GPU support can run 16 graphics processing units in parallel; has native binaries for both Linux and Windows.  Low resource utilization - you can still watch movies or play games while cracking in the background.  Isn't that convenient.



LEO:  There's plenty of CPUs to spare.



STEVE:  Absolutely.  Focuses on highly iterated modern hashes; uses dictionary-based attacks.  Oh, you can even pause it and resume it while cracking.  So it has all the features of a modern password-cracking system.  It can read words from a file, so you can have dictionaries; can read from standard input.  It has an integrated thermal watchdog, just in case you overheat your system by running too many hashes too quickly.



LEO:  This is nicely done.  Nicely.



STEVE:  Isn't it nice.  More than 20 algorithms:  MD5, Joomla, osCommerce, SHA-1, Base64, Oracle 11g.  Here we have OS X v10.4, 10.5, 10.6, and a little bit lower is 10.7.  Not to be outdone, we've got Double MD5, SHA-256.  Oh, there's NT LAN Manager, Microsoft's NTLM is there.  And on and on and on.  So, yeah.  Oh, and runs in both 32- and 64-bit OSes, tested and fully supported.  And free.  Did I mention that?  Free.



LEO:  Yes, free, free.



STEVE:  So you no longer need to be a GPU programming guru.  And of course this is the same pattern that we see over and over and over.  Remember when Firesheep was released, which allowed anyone to download this add-on for Firefox, wander over to Starbucks, and people's pictures and logon credentials started popping onto the screen.  What we're seeing is the standard evolution in password-cracking technology that once truly was rocket science.  Now it's turnkey.



It's not quite where Moxie is with capture packets through the ether, dump it into his CloudCrack, and he'll handle all that for you.  But somebody who is interested in playing with this no longer needs to write a lot of code or understand it.  There are videos on that site, how-tos, forums, and an offer to download the latest version into your GPU, and you, too, can start cracking like crazy.  And of course those forums will have links to the 100-million-plus password databases and 500-million word lists and so forth.  So, I mean, this really has gone exponential in terms of the fun that people are having and how easy it is...



LEO:  That's the way to put it, "fun."



STEVE:  ...to get into the password-cracking business.  So looking at these lists, essentially no one is any longer believing that people's passwords are truly maximum entropy random.  What this says is, I mean, as you said earlier, Leo, using a LastPass-generated, long, absolutely unmemorizable password is the best thing you can do.  Now, my Haystacks notion was a compromise, admittedly.  It was the recognition that, in the face of brute-forcing, length trumps complexity because, if you're off by one character, you get no result whatsoever.  It's got to be an exact match, so close doesn't count.  So the Password Haystacks idea was to get you something long, if you couldn't use LastPass, or for whatever reason you didn't want to, you needed something memorable that would not be quickly crackable.



LEO:  That's the problem, memorable.  And that's where we get this complication; right?



STEVE:  Yes.  Now, it is still the case, and I think on maybe the last page of Dan's four-page piece he shows a very interesting chart which you should put on the screen if you can find it there, Leo, where it goes exponential.  There is still the so-called "password cracking wall," which means, if none of these dictionary attacks work, if your password isn't something, a normal word where the E's are changed into 3's or three exclamation points are added to the end, or if it's not something where you have been clever, but in fact the password you're using doesn't fail in any of those ways, and you have to assume now clever is broken, clever is no longer good enough, if it doesn't match that, then you're back to brute-forcing.



LEO:  And boy, does it go up.  After seven characters of true randomness, it gets impossible.



STEVE:  Yes.  And it doesn't matter if you use a GPU or if you use CloudCracking or anything.  So to put a number on it, there's a picture shown of a homebrew, $12,000 machine containing eight AMD Radeon HD7970 GPU cards, running Hash Cat.  It requires 12 hours to brute-force the entire eight-character password keyspace.



LEO:  Of random numbers, random letters.



STEVE:  Yes.  Now, remember that what I said at the very top of the Password Haystacks page was, if every single one is tested, sooner or later they will get yours.  So this thing, for $12,000, eight AMD Radeon GPU cards running Hash Cat, takes 12 hours to test every possible eight-character password.



LEO:  That's upper and lower, digits and symbols.  The whole thing.



STEVE:  Yes.  But now remember, you add one character to that and it's 96 times longer.  One more character, 96 times again.  One more character, 96 times again.  So that's why this thing still exponentiates.  It goes straight up because, if you really have very high entropy, if you have not - if your password hasn't crumbled because you did something that you thought was clever - oh, another one that is mentioned here I thought was interesting, that apparently, again, lots of people think, oh, I'm being tricky, no one's going to think of this.  It is to spell a word forwards and then concatenate that word backwards.  Whoops.  They know about that, too.



LEO:  That's not that tricky.  Really it shouldn't be the death of clever, just the death of kind of clever, or maybe clever, or you think you're clever.



STEVE:  Yeah, I just don't think you can be clever enough.  That's the problem.



LEO:  Maybe that's it, yeah, random is better than clever.



STEVE:  What has been learned is that we're just not very good at coming up with something really clever.  The classic was transposing the keys on the keyboard.  Yeah, they know about that, too.  There are dictionaries of all the words shifted one up and over to the left, or one down and over to the right and so forth.  All of that.  So the idea is that what we as users need to appreciate is that this day and age, this is the low-hanging fruit.  The hackers are just having a ball, literally spending their time thinking, okay.  They'll look at a password that was captured and think, that looks random.  Where did that come from?  And they'll realize, oh, look, that's shifted down and to the right from a normal word in the English language.  So they add that strategy to their cracking library, and suddenly all passwords of that form fall to the addition of that strategy.  And this is only going to get better in the future.  So if you haven't yet switched to something that will not fall to this kind of attack, the sooner you do, the better.



LEO:  Wow.



STEVE:  And one other piece of analysis showed that the typical web user is logging onto - I'm trying to find the number here.  I just saw it.  I think it's 26 different sites, but only using 6.5, on average, that is, between six and seven different passwords.  So it is still the case that we're seeing cross-site - oh, it's 25, 25 separate accounts, but uses between six and seven passwords for protection.  So there is still a substantial amount of password reuse going on.  And we know why that's not safe because, if a site like LinkedIn, with its 6.5 million passwords and associated email addresses, if those passwords get cracked, and 90 percent of them have been now after a couple months, and you use the same credential elsewhere, then you're very vulnerable to impersonation, which is of course all of what this is supposed to be protecting us from.



So the argument is that, yes, over time, we are moving to multifactor authentication.  But unfortunately, today, in this day and age, we're still being forced to authenticate with passwords.  And this is where the action is.  People are having fun just with the idea that a GPU has this much computing power, and all these resources are available on the Internet.  You no longer need to be a rocket scientist in order to play these games and play with this stuff.  And the consequence is that more and more people are going to be doing so, and freely downloadable software is going to be getting more and more clever.  So that anything that you've thought of that you think is like your trick, your tricks have gotten loose, or people like your tricks have gotten loose.  They've been analyzed and added to the strategy.  So that it's no longer just simple, try every possible password, aaaaaa, aaaaab, aaaaac and so forth.



So what we need to do is abandon this and just use entropy, ultra-high-entropy passwords, and something then to manage them, like LastPass of course is what I use, 1Password, and there's a collection of great utilities to help people remember.  I haven't looked at any of the others, that is, the security of any of the others other than LastPass.  So that's the one, as we know, that I've looked at closely.  And as far as I can tell, they've done everything right.



But I would say, from this point on, and as you have the chance, you really want to migrate away from things you did that you felt were clever because, if those get loose - and unfortunately that is the attack model today, it's not somebody logging in through the web interface, guessing your account.  No.  It's that a database on the backend escapes, and then millions of credentials are being cracked in parallel.



LEO:  [Sigh]



STEVE:  Yeah.



LEO:  I have all these tricks that I use.  But really you're convincing me that tricks are just a bad idea.  You just should use totally random passwords.



STEVE:  Who would have guesses that everyone would choose "monkey"?  We weren't telling each other.



LEO:  I didn't think that was a trick.  I knew that was bad.  A dictionary word, yeah.  But then, I mean, all these other tricks are bad, too, apparently.



STEVE:  Yes, yes.  Well, I mean, think about it.  Anything you can think of, they can, too.  But more importantly, you thought of it, and you used it.  And then some website where you used it got cracked.  What happens is the hackers look closely at the ones they could not crack, and they go, hmm, why couldn't we crack...



LEO:  Oh, that's neat, yeah.  And they try to find patterns in it.



STEVE:  They zero, exactly, they zero in on the ones they couldn't crack, and that leads them to strategies they don't yet have crackers for, and so they add crackers for those strategies.



LEO:  And this is why you need regular wars so that people like this can go to places like Bletchley Park and use their genius for good, not ill.



STEVE:  Yeah.



LEO:  I rest my case.  No, I don't.



STEVE:  The good news is we're talking about this on the podcast.  We've got tens of thousands of listeners who are hearing this, who have advance notice...



LEO:  Are doing as I'm doing and changing their passwords right now.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  The nice thing, too, is you can use something like LastPass that has learned all of your passwords, and go through and figure out which ones you really need to change.  I have had some neat feedback also from our podcast about, was it Tom Honan?



LEO:  Mat Honan.



STEVE:  Mat, yeah, Mat.  Got a little bit of alliteration there, or dyslexia.  Yeah, Mat.  Many people were focusing their password recovery in the same way that he was.  And so I've had a lot of feedback from people who said, hey, thanks for explaining that.  I was doing the same thing.  I've broken my accounts apart now so that they're no longer chaining in the same way that Mat was.  So that's good, too.  I'm glad that we're able to help people.



LEO:  LastPass has a security, a password security audit feature I'm seeing.  Jesse tells me in the chatroom.  I didn't know about that.



STEVE:  I thought it did, yes.



LEO:  So try that.  It finds duplicate passwords, I think, is mostly what it does.



STEVE:  Well, but that's good, too, because we know that you don't want to have re-use.



LEO:  Unique is good, yeah.



STEVE:  Yeah.



LEO:  Well, I'm more and more using that Generate from LastPass to generate passwords.  It seems to...



STEVE:  I do, too.  I resisted it at first because it was like, oh, this just looks like total noise.  But that's the point.  You want something that looks like noise and trust LastPass to remember it for you.



LEO:  Mr. Steve Gibson is the man at GRC.com.  That's where you can find SpinRite, his bread and butter and the world's best hard drive maintenance and recovery utility, SpinRite, at GRC.com.  He's got a lot of freebies there, too, though, including lots of information on passwords and security of all kinds, freebies.  It's GRC.com.  That's where you'll find the most compact versions of this show.  There's a 16Kb audio version Steve makes available and also transcriptions, which are even more compact.  We do the big fat ones, the audio and the video, at TWiT.tv/Security Now!.  And of course the best way to get it is to subscribe so you don't miss an episode.



You can watch live.  And I think it's fun to watch live.  I talk with the chatroom while we're doing the show and fill them in.  For instance, somebody said, well, is OpenVPN safe, given this CHAPv2 crack?  And of course it is because...



STEVE:  Yes, because it's an SSL VPN.



LEO:  Yeah, yeah, so that's good news.  So if you want to watch live, we do it 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC on TWiT.tv every Wednesday.  We are going to move you, Steve, just a heads-up, if Apple does this announcement September 12th.  That's a Wednesday.



STEVE:  Ah, okay.



LEO:  But we don't know yet because they haven't sent out invites.



STEVE:  Will I swap with MacBreak Weekly?



LEO:  Yeah, we'll just swap you to Tuesday at 11:00 a.m.  But we probably won't know that until September 5th because Apple doesn't like to tell anybody ahead of time.



STEVE:  Although I did see, you're right, I saw that a number of, like, what was it, retail staffs had been put on alert.



LEO:  Verizon, yeah.



STEVE:  Right.



LEO:  I think it's true.  But I'm not going to reschedule a show based on a rumor.  Andy Ihnatko's flying out based on a rumor.



STEVE:  Jen was asking what the iPhone 5 has.  Is it, like, more than just thinner?



LEO:  "It goes to 11."  It'll be taller, four inches tall - well, it's all rumor - and 1136 by, what was it, 640?  I can't remember.  1136.



STEVE:  Wow.  So even more screen resolution.



LEO:  Yeah, going up, though.



STEVE:  Yeah.



LEO:  16:9.



STEVE:  And thinner.



LEO:  And we don't know.  I don't know.  I haven't seen thinner, although I think that's the speculation.  And a new connector, a new nine-pin connector.



STEVE:  Oh, that's right, no longer that big dock, the traditional docking connector.



LEO:  No 30-pin, yeah, yeah.  But I don't know - LTE for sure because you've got to nowadays.  But I don't know if there's much else.  We've seen iOS 6.  There's an improved Siri, things like that.



STEVE:  Yeah.



LEO:  No more Google Maps.



STEVE:  And you've seen that the Nexus 7 is doing phenomenally well.



LEO:  And rightly so, yeah.  Love it.  And I'm looking forward, you know the Galaxy Note comes out in a week, the Galaxy Note 2.  And I love that big form factor.  That must be a 5.5" screen.  So it's heating up.  It's getting hot in here.



STEVE:  It is.  Fun stuff.



LEO:  Thank you, Steve.  Steve Gibson, GRC.com.  We'll let you know as soon as Apple lets everybody else know if we're going to move shows.  That's not for a few weeks yet.



STEVE:  Thanks.  No problem for me.



LEO:  All right.  Thanks for joining us.  We'll see you next time on Security Now!. 



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#367

DATE:		August 29, 2012

TITLE:		What a Busy Week!

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-367.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  We have so much security news and information to cover this week that we didn't have time to take questions from our listeners.  What we have, instead, is a LOT of interesting news about the new Java vulnerabilities, new TNO cloud storage solutions, and lots more.



SHOW TEASE:  It's time for Security Now!.  The Explainer in Chief, Steve Gibson, is here.  He's going to talk about a big Java exploit that affects not only Windows, but Mac and Linux, as well, and give you his take on the Samsung/Apple verdict.  He is, after all, a software designer.  It's all coming up next on Security Now!.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 367, recorded August 29, 2012:  What a Busy Week!



It's time for Security Now!, the show that covers your safety and privacy online with this guy right here, our Explainer in Chief, Mr. Steve Gibson of GRC.com, the inventor of a lot of very useful security tools and, of course, the ultimate hard drive maintenance and recovery utility, SpinRite.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you this week.



LEO:  What a week it has been.



STEVE:  Well, in fact, we've got so much to talk about, just sort of across the board, that I was looking at - this is nominally a Q&A week.  But I thought, okay, there's just no way we have time to take any of our listeners' questions.  So I'm going to push that to next week, and this week we'll just talk about everything that's happened and has been going on.  I have found - we need to talk about the big Java problems which people need to be aware of.  There's some new malware that is able to infect virtual machines images, VMware images at rest.  That is, when they're not in use, this will go and infect the static file.  So it's like, okay, well, I guess that was foreseeable, but it now exists.



Dropbox made some news with the addition of two-factor authentication.  I've been playing with it and have implemented it, and I'll talk about that.  And I found some new Trust No One cloud storage solutions.  So, and a bunch of all kind of miscellaneous stuff.  And I want to talk to you a little bit about the Apple vs. Samsung thing.  I don't have a strong position.  I'm not screening in either direction.  But as a person who's gone through the patent process a number of times, and an innovator and developer, I thought it would be fun to chat with you a little bit on the consequence of all that.



LEO:  I would love to hear that.



STEVE:  Lots of stuff.



LEO:  Our expert witness, so to speak.  Great.  I think we can launch right in, actually.  We have but one commercial.  We'll do that before, well, we'll just figure out a spot.



STEVE:  Yeah.  Okay, so I got a kick out of one, I guess sort of a hacker code tester person, I can't remember.  His tweet handle is @0xabad1dea.



LEO:  Ooh.



STEVE:  As in "a bad idea."  Anyway, he coined the term and our friend Simon Zerafa, who watches a lot of feeds, apparently, retweeted it, so I saw it.  He called this the "Javapocalypse."  What we have is we have a bad new problem in Java, such that everyone is now being advised to remove it.



LEO:  I love the, who was it, the guy in charge of security at F-Protect who, what was his quote?  It was really quite funny.  It's Windows, Mac, and Linux.



STEVE:  Yes.  Well, and this is the mixed blessing of Java.  I mean, the whole point of Java is you write it once, and you run it anywhere.  And so what happened is that, with the release of v7 - we recently went from 6 to 7, and 6 is still being updated a little bit for people who haven't moved yet to 7.  But two new classes were added to 7.  And it turns out that there is a very clever way of leveraging some mistakes which were made in 7, which have been around for a while.  So no one is sure where this may have been used before, but it suddenly exploded into public awareness over the last couple days because, well, because it's now being used for targeted attacks.



The typical, you browse somewhere with a computer that has Oracle's Java 7 installed.  And I'm a little confused about, because I keep seeing - I've seen conflicting reports.  Some have said that you have to have the very latest version, v1.7.  Some have said that 1.6 is not vulnerable.  Other people have said, oh, no, all versions of 7 are vulnerable.  We do know that this happened with the move from 6 to 7, so 6 is not vulnerable to this, but it's vulnerable to other things.  So no one is recommending people go to an earlier version of Java.  I mean, it's a mess.  So it's, as you said, all three operating systems - Windows, Mac, and Linux.  Now, it's interesting, the Ubuntu doesn't come normally, for example, with Oracle's Java.  They've got their own OpenJRE, the Java...



LEO:  Just like Apple.  Just like Apple.



STEVE:  And it's not vulnerable.  So if you use the Java that's natively in Ubuntu, for example, you're okay.  And one of the people exploring this had to remove that, then install the latest version of Oracle's Java, and then was able to make the exploit happen.  There were some early reports that Chrome was not vulnerable; but, I mean, this has been moving very fast.  I mean, just minute by minute, hour by hour.  It's already in the Metasploit framework.  It's already in the Blackhole rootkit, which is used by bunches of bad guys.  So it's completely available.  There's a full technical explanation that shows the source code, step by step of how this works.



There are some security experts who are unhappy with what they consider to be irresponsible disclosure of this.  I mean, everyone just kind of went crazy.  Some people early on were actually posting links to infected websites which could have infected people who clicked on those links.  So there's been a bit of a frenzy about this because it's any browser, any OS.  Now, currently it's only carrying Windows malware.  But the way this works is interesting, too.  Leveraging these two particular methods in two classes, what this essentially allows is the applet to modify its own operating system security settings.  So it's not a buffer overflow or anything like that.



There's a way for the applet that you would download a .JAR file when you clicked on a link, went to a website or opened email or something.  Normally there's containment of the Java environment within your browser so that it can't arbitrarily do things to your system.  So the applet doesn't have read, write, and execute permissions on the operating system file system itself.  But what these two methods allow, when used together, is the applet to give itself unrestricted permission to read and write and execute code.  So when it has that, it then goes out and gets another executable, I think in this case it's called "hi.exe," which it grabs.  And at this point it's a Windows-only exploit.  So although the vulnerability exists on the other platforms, it's not currently, in the wild, as far as people know who have seen it, going against Mac and Linux machines.  But it's fully capable of doing so.



In the Windows case, it overwrites a file in the Windows/system32 directory where all the components of Windows are kept.  And this is the portable media serial number service that gets overwritten.  It's an awkwardly named file, mspmsnsv.dll, that gets replaced.  And at the moment what it does is it downloads and installs the Poison Ivy RAT.  RAT is an acronym for Remote Access Trojan.  So that's what people are being afflicted by who click on links in their browsers who have Java enabled and running.



So once again, this is essentially a call to disable Java.  Now, as we know, Apple has already made the move, as a consequence of the catastrophe they recently suffered where so many hundreds of thousands of Mac machines were infected because of Java, where it's disabling it by itself.  You have to manually reenable Java.  And then if you don't use it for a while, it goes to sleep again and redisables itself.  Unfortunately, it's really looking like this is the only way we're going to be able to coexist with Java.  It's a shame because Java is so powerful.  It can do many things.  There are organizations that are critically dependent upon Java.  They've written big chunks of their own stuff in Java because they were convinced that it was a good thing.



There is available a patch.  Now, the problem is that Oracle has a four-month patch cycle.  They only patch, not even quarterly, but three times a year, every four months.  And so that was the middle of February, the middle of June, and the middle of October.  So here we are approaching the end of August.  We've got all of September and half of October.  It's October 16th is the official next patch cycle for Java.  Everybody has been asking Oracle, what's going on, are we going to get an out-of-cycle patch, are they going to fix this quick.  And so far, silence from Oracle.  No one that I'm aware of who has asked has received any answer.



So this again, we've talked many times about opening up Add/Remove Programs, looking at plugins in your browser.  If you don't know you need Java, it's difficult to justify it in this situation.  We don't know how soon it's going to get fixed.  There is a website which basically just checks your version number, but it's IsJavaExploitable.com.  So you can safely go to IsJavaExploitable.com.  Now, I went, and because I've got NoScript running in Firefox, nothing happened.



LEO:  So this is from Metasploit, so they're a reliable company.



STEVE:  Yeah.  And if you enable scripting, then it will use Java to report on its own version number and tell you where you are vulnerable, not by executing the vulnerability, but by just looking at the version number because, if you've got 1.7, and you've been up to date, and unfortunately that's what I had when I enabled it, then it's like, oh, yes, you are vulnerable.  So our friend Brian Krebs at KrebsOnSecurity.com recently blogged how to unplug Java from the browser.  So if anyone who listens to the podcast is not already clear about going to Add/Remove Programs in Windows and removing it and then looking at your plugin, your browser plugins, and either disabling it or removing it, Brian does have some nice browser-specific step-by-step instructions on a recent blog of his.  So it's KrebsOnSecurity.com.



LEO:  So if you're using Ubuntu or using Macintosh, you're probably all right; right?  Because you're not using...



STEVE:  Well, that's a good question.  What happens, for example, on your Mac?  I didn't try it yet on mine.



LEO:  Mine, I just ran it, and I have an up-to-date Mountain Lion installation, and it said it's not exploitable.  But I always get from Safari the warning before Java runs anyway.



STEVE:  Yes.



LEO:  Which is helpful because, if Java suddenly - if you go to a website, and it says I want to run Java, you might want to say no.



STEVE:  Yes.  Now would be a good time to say no.



LEO:  Yeah.



STEVE:  Now, I've listened to quotes from hackers, read quotes from hackers, and they're just jumping up and down because they feel like they have a six-week window, minimum.



LEO:  Woohoo!



STEVE:  Yeah, I mean, it's not often that you get a completely cross-platform, wide-open exploit which is able - and what this will do, let me just make it clear, it will not just download a Windows exploit.  I mean, all it is, you could easily have a multiplatform exploit.  It will download anything and run anything on any system.  It has that capability.  Essentially, it completely unchains a programming language, Java, from any security constraints, allowing it to do, like an app running on your machine, with you doing nothing but visiting a website, if you have no other protections in place.  So you can imagine the script kiddies and the hackers, it's like, oh, boy, here's an opportunity for some creativity.  Ha ha, how are we going to be able use this?



And again, within the range of this podcast, people are probably going to be safe.  The problem is that not everybody listens to us, Leo, and there's going to be lots of people probably caught out by this.  And again, Oracle's not saying when they're going to have any fix for this.  The good news is, it's not installed, for example, in Windows.  Normally you get it because you have done something in the past that required it, and so you installed it.  Windows doesn't come with Java.



LEO:  Same with Macintosh.  Doesn't come with Mac either, yeah.



STEVE:  Yeah.  So that certainly lowers the attack surface, and that's good.  Although for corporations, which are known to be reliant on Java, this is probably going to get applied in strategically targeted attacks.  Now, I did want to mention that a patch has been independently developed at DeependResearch.org.  They've got a patch.  And if you are not an end-user, they're not going to help you.  But if you're a major corporation that is dependent upon Java for your operations, so that it's just not feasible not to use it until Oracle fixes it, you can send email to admin@deependresearch.org and explain who you are, what your need is, and they will provide you with a link to a patch.  Essentially it's changing the problems with these two now well-understood problems.  So it's trivial to fix.  And so everyone's feeling is this is something Oracle could jump on immediately and get to.



Now, the other problem is that, when I recommended that people have Java look for updates more quickly, I have noticed, and I've had other people confirm, that when Java updates itself, it resets its "how often should I check for updates" to - I'm thinking it's a month.  So the problem is that, even when it's been fixed, Java isn't going to be looking more often than a month.  So...



LEO:  That's really not often enough.  That's just silly.



STEVE:  Yeah.  It's not.  Now, we are also seeing, and maybe the browsers will step up, we're seeing, as we know, browsers being more proactive about checking for the vulnerabilities based on versions of their own plugins.  So you could, for example, easily see Mozilla step up to the plate immediately with their evolving on-the-fly patching, just as Chrome does, and preemptively warn people that they've got a vulnerable version of Java, please fix it as soon as there is an update.  So I think we're going to end up talking about this over the next few weeks.  This is looking like, unfortunately, because it's so pervasive and multiplatform and such a powerful exploit, I mean, there's nothing more that a bad guy wants than to be able to run any program of their choosing on any machine that visits, that clicks a link in email or visits a website.



LEO:  Someone in the chatroom said, "Write once, exploit everywhere."  True.



STEVE:  Yeah.  And I don't know what the future is for Java.  I mean, we're seeing JavaScript really take hold.  It's been standardized.  It's becoming increasingly powerful.  It's not clear that Java is not going to sort of fall the same way Flash has.  It was necessary for a while, but it's not clear that you want something that is powerful enough to do what Java does, that is, web exploitable.  I mean, the beauty of JavaScript from a security standpoint is that it doesn't have a file I/O or socket-level I/O where it can do packet things.  I mean, JavaScript was designed to run in a browser environment and be limited.  Java is a full-fledged programming language that is constrained in an applet, in a downloadable applet environment.  But it is inherently powerful.



So what's happened is it's broken free from its constraints in this instance.  And so we see the danger of having a full-fledged programming language that can be invoked from a browser link.  It's just, I don't know how that's ever going to be a safe thing to do.  So it seems to me that what we're going to end up evolving towards is, I mean, and Flash has the same problem.  Flash is very capable.  It can do lots of things.  The problem is, it's invokable from a browser.  So I think we're going to, in the future, we're going to see JavaScript continue to mature, its speed improve, its capabilities get fleshed out, yet will always be, hopefully, constrained so that it's safe to run in a browser, and then we really want to move away from high-use plugins that are general purpose programming languages.  It's just not safe to invoke them through a browser by clicking on a link anywhere.



LEO:  Yeah, wow.



STEVE:  Yeah.  So...



LEO:  Unfortunately, one of the most popular games in Existence, Minecraft, is a Java game.  So that's on a lot - a lot of people have Java for that reason.  Citrix apps are also Java.



STEVE:  And it's not a problem to have it on your machine.  It's a problem to invoke it with a browser.



LEO:  Connect it to the browser is the mistake.



STEVE:  That's, yeah, exactly.



LEO:  So you can keep Java.  Disable the browser connection.



STEVE:  Yeah, I mean, you can also run "C" programs on your computer and VBScript and all these other things.  So it's just that it is so typically, I mean, when you install Java, it installs its browser plugin.



LEO:  Right.  That's not a good thing.



STEVE:  Because it wants to offer those services.  I mean, unfortunately, it's funny, I saw someone say three billion machines are vulnerable.



LEO:  Yes.  Oracle said that.



STEVE:  Well, because that's how many copies of Java are loose at the moment, unfortunately.



LEO:  So disable - in fact, you can do this in most browsers.  Just uncheck the Enable Java box; right?



STEVE:  Yes.



LEO:  And there's no reason, you probably don't want it in your browser unless you're, I don't know, playing Yahoo! Games or something.



STEVE:  I saw a posting that Larry Seltzer had posted in June of 2010, so a little over two years ago.  You and I both know him, a great longstanding columnist for PC Mag.  And he experimented with removing Java, and his comment at the time was that - and this was two years ago - that, eh, nothing really much happened.  Nothing broke.  And he said The Wall Street Journal was using Java to display some of their financial charts, but other than that, eh.



LEO:  That's because he's not a gamer.  A lot of games, RuneScape runs in the browser and is an MMO that runs in the browser.  But most modern browsers, including Chrome and Safari now, will not run Java automatically, but will say, this program is asking me to run Java, should I?  So just say no unless you're running RuneScape; right?



STEVE:  Well, and, okay, but here's the problem.  We know to say no.



LEO:  Right, right.



STEVE:  But, I mean, it's so funny, I love Jenny, but whenever we're - when, like, we're working on her laptop, things pop up, and she reaches to just click and make it go away.  Just, oh, it's in the way.  I go, "Wait, wait, wait, I read these things."  And she says, oh, okay.  But, I mean, I don't mean to pick on her, obviously.  She's typical.  I mean, this is what everyone does is...



LEO:  Yeah, let's get rid of Java.



STEVE:  Yeah, we really have to.



LEO:  Now, here's the interesting thing.  Java, when it came out, was really billed as secure, as sandboxed and everything.  And I don't understand what went wrong. 



STEVE:  What went wrong was that it's very much like the firewall model.  You have an inherent problem when you have capability that you want to restrict.  It's better not to have the capability.  And so the problem is we have a general purpose, powerful, state-of-the-art programming language, Java, which can do anything.  You can write powerful applications in Java.  I mean, full-on, standalone, multisystem applications.  However, it's the  browser component, the idea that, oh, look, we can also use it for web apps.



Well, the second you do that, the second you allow the browser to have access to a full-strength programming language, you're asking for trouble.  So they solve that by saying, oh, no, no, don't worry, we're going to restrain its security.  We're going to take away, for example, its ability to read and write and execute programs on the hosting system's file system.  And everyone says, oh, well, that's good.  Well, except that what just happened here was a way around that, where the applet was able to give itself permission.  Which is really not what you want.



LEO:  Right, right, right.



STEVE:  So I drew the example of a firewall because, of course, if you have insecure services behind a firewall, I mean, then - and this was the history of Windows in the early days, before there was even a firewall, it was just one problem after another because people would keep finding ways to execute their own code through buffer overruns on Microsoft servers because Microsoft had all these services running on consumer machines that had no need for all these services.  They were all just exposed to the Internet.  Then we got the firewall, but it wasn't turned on by default, so we might as well not have it.  And it wasn't until SP2 of XP that it was on by default.  And overnight the problem was gone.  Still, a little worrisome to have vulnerable services behind the firewall.  But at least we have one.



So in this case I think the lesson we're learning painfully slowly, over and over, is we cannot give our browser access to a full-strength, full-feature programming environment like Flash and like Java.  JavaScript was designed for the browser.  And arguably Flash was, although it also runs separately.  Those are just too powerful.  There's just no good way to do it.



LEO:  It was the problem ActiveX had.  It's just you don't want a browser running arbitrary code on your computer.



STEVE:  ActiveX the same problem, exactly.  It was like downloading a DLL and saying, okay, here you go.



LEO:  And we should once again say that the issue is with Java browser-based applets as opposed to standalone Java applications.  I mean, the same thing could happen with a standalone application, but you'd have to download the malicious application directly and intentionally.



STEVE:  Well, and you could have Java on your system used for application execution, as long as you did not have the browser plugin component present and installed.  Now, the problem is that Java tends to aggressively reinstall these things in the same way that it turns back its "how often should I check for updates" back to a month, even if you say, oh, I want you to check nightly.  If you come back after a while, you realize, oh, wait it's gone to a month again.  So it's not behaving itself very well.



I think when the history books are written, Flash will have been a problem, Java in browsers will have been a problem.  It was something we may have needed at the time, probably never very well advised.  But as no one knew what the Internet was going to become, how pervasive, and how many people who were not computer experts would be casual users of it.  And people do just click on - they just click on yes, yes, okay, fine, I want to - get out of my way, whatever you are.



LEO:  [Sighing]



STEVE:  So I saw this little note, I got a kick out of it, that SANS, the SANS Security Institute, caught a story that I wanted to share, just because I keep saying this.  But I saw it, but they had it in a story that ComputerworldUK and Yahoo! Finance covered.  They said:  "An annual survey of 11,000 public company directors and 2,000 general counsels shows that, for the first time, data security is now a prime concern for U.S. boards."  As in corporate boards of directors.



"The survey, conducted by advisory firms Corporate Board Member and FTI Consulting, shows that over half, 55 percent in their survey, of general counsels surveyed rate data security as a major concern, while 48 percent of the directors surveyed felt the same.  A similar survey in '08" - so four years ago - "found that only 25 percent of directors and 23 percent of general counsel noted data security as a high area of concern, which reflects a doubling of this concern in four years."



And then the president of Corporate Board Member group said about the results, "'While a number of companies are taking steps to become more educated on IT risks, the fact is that not enough are taking the appropriate actions to fully prepare their organization.'  He went on to say, 'I think it is going to take several well-publicized security breaches before a majority of corporate boards finally embrace the fact that doing business today without a prudent crisis plan in place is a formula for disaster.'"  And I had to read that last sentence a couple times and say, wait a minute, a crisis plan?  How about planning not to have a crisis?



LEO:  How about that?  Well, you should do both.  You should try not to have one, but you should have a response plan; right?



STEVE:  Yes, absolutely.  And in fact, one of the ways people or corporations are getting themselves in trouble these days is when they respond poorly to a problem.  How they respond is as important as the unfortunate fact that they're being forced to respond to something at all.  I'm just - I'm amazed, Leo, at the inertia, at just how slow this is to move forward.  But as I keep saying, with all of these widely publicized breaches, these companies are being embarrassed, and that may be the only way that the IT departments are able to get the money and the staffing that they need.  Because when you talk to the IT guys, they're like, yes, we're jumping up and down, we tell them all the time.



LEO:  We're begging them, please.



STEVE:  Please, please, please.  But instead it's like, well, okay, we'll talk about that next quarter because right now we have different priorities.  So it's like, ah, okay, right.



LEO:  I think the decision was made at some point by a lot of banks and so forth that they're just going to take a certain amount of loss.  You know?



STEVE:  Yeah.



LEO:  This is just the cost of doing business.  We can't really stop it.  It's like shoplifting.



STEVE:  Well, look at the credit card fraud problem.



LEO:  Totally, they totally accept a percentage of loss.



STEVE:  Precisely.  They just go, okay, well, a certain percentage of these charges are going to be fraudulent, so we'll just bump up the interest rates - and use that as the excuse, by the way, for bumping up the interest rates.



LEO:  Very convenient.



STEVE:  And cover our losses that way.



LEO:  Yeah, exactly. 



STEVE:  So "Crisis" is the name of a new piece of malware for Windows which was discovered last month, in July.  It's been found to be capable of infecting VMware virtual machines as well as Windows mobile devices and removable USBs.  When originally discovered, Crisis was thought to target just Windows and Mac OS users.  It has the capability to record Skype conversations, capture traffic from instant messaging programs, and track websites visited in Firefox or Safari.  Symantec says Crisis "searches for a VMware virtual machine image on the compromised computer and, if it finds an image, it mounts the image, then copies itself into the image by using a VMware Player tool."  So there's a new first, folks.



LEO:  Wow.



STEVE:  How many times have we talked about virtual machines being one sort of safe harbor, a means of testing viruses and creating some containment and something that we had some control over.  But unfortunately, as they've become increasingly popular, it was probably foreseeable that we would end up with a virus that would mount the image, then infect it, and then dismount it so that...



LEO:  It's brilliant.



STEVE:  So that then you fire up your VMware thinking, okay, now I've got a brand new clean thing.  And in fact, when it wasn't even running, behind your back it got infected with this thing.  Amazing.



I noted that California legislators on both sides of the aisle overwhelmingly passed the Location Privacy Act of 2012.  It's a new bill requiring law enforcement agencies to obtain a warrant before collecting any GPS or location data...



LEO:  Yes.  Hallelujah.



STEVE:  ...from cell phones or smart phones.  It was co-sponsored by the EFF, our friends at the Electronic Frontier Foundation, and the ACLU, the American Civil Liberties Union.  And it's been passed now to California Governor Jerry Brown for his hopeful signing into law.  He did refuse to sign something last year that was related.  I can't remember what it was now.  It came as a disappointment and a bit of a surprise.  Hopefully this is constrained enough that he's willing to do it.



The EFF had a statement.  They said they "urge Governor Brown to have California take the lead on this issue and sign SB 1434" because it "strikes a sensible balance between keeping the public safe and preserving our privacy."  So the ACLU did a study, I'm just pulling this from memory, I think it was 383 agencies across the country, law enforcement agencies, they did a Freedom of Information disclosure act request, and more than 200 were in fact using warrantless tracking, which at this point can be done.  Some were applying for warrants; others weren't.



And so apparently, as I remember reading this, the fact that some were was taken to mean that everyone could, if we asked them to.  So I know that I saw this story also in the SANS security news, and one of their editors was quoted saying, "Another example of California leading the nation in sensible cybersecurity legislation."  I understand that law enforcement has a hard time with all this technology.  But our Constitution and freedoms require that there be a balance.



LEO:  Hey, you know, it's - you can get a warrant.



STEVE:  Yeah.



LEO:  Just get a warrant.  I know it's a pain.  You know, it's a pain.  Get a warrant.



STEVE:  So Dropbox has added second-factor authentication.



LEO:  This is good.



STEVE:  It is good.  Dan Wheeler blogged two days ago, on August 27th.  He said, "Hi, everyone.  A few weeks ago we discussed a number of steps we're taking to add an extra layer of security for Dropbox users.  Today we'd like to announce the launch of two-step verification, a feature that will enhance the security of your Dropbox by requiring two levels of authentication:  your password and a security code that will either be texted to your mobile phone or generated by a mobile authenticator app, available for iOS, Android, Blackberry, and Windows Phone 7."



Okay.  So I jumped on this and played with it.  I haven't actually been an active Dropbox user, Leo, since you and I stopped using it when we switched to Pogoplug.  We were using Dropbox for a while, and I just...



LEO:  That's right.  I made you use it.  What do we use now?



STEVE:  Now I just go grab the high-quality version.



LEO:  Okay, and you just work from that.  Okay.



STEVE:  And just work from that, so it's easy.



LEO:  Sorry.  I didn't realize - I had kind of lost track of all that.  There are people now, you know.



STEVE:  Well, actually they are great about getting an edited version to me, like within hours.  And then I'm able to - see, the problem is Elaine is out in the boonies somewhere with a satellite connection with bandwidth caps.  And so downloading 64MB files chokes her.  And so if I can bring it down by a quarter of that, it's worth her while for me to do that, so I'm happy to.



So, okay.  It is a good thing.  What I'm really thinking we're going to see is I think we're going to see a movement to the TOTP, the Time-based One-Time Password.  This is the Google Authenticator.  This is a version of the football that we talked about eons ago when PayPal and eBay adopted it.  This is the idea that every 30 seconds the code changes, and it's just - you need to have an accurate clock.  You need to be synchronized.  But the Internet provides time now, so you can expect that things know, your phone knows what time of day it is.  And we know that there are even means for achieving synchronization when there is a mis-sync, so that can work.



Google Authenticator is of course open source and free.  This TOTP is on the OAuth spec, and it's public domain.  It's RFC'd.  It's a well-known algorithm.  So all of this is open and secure.  The idea is that you have a clock which runs through a crypto.  So this is a keyed sequence of six-digit changing values.  And so the idea is something you want to authenticate with gives you the key.  You give the key to this Authenticator, and it's then able to generate the changing six-digit codes that the site you're wanting to authenticate against expects.



So this is nice because the problem that I had with VeriSign, I loved what VeriSign did with their VIP program, it's that they were the single point of failure.  Everybody running through them depended upon them.  So that was one problem.  If they got DDOS'd or went down or got broken into, then there's that problem.  The other is they're very expensive.  So you don't see lots of people using them because they charge per authentication.  So it's great for them if they can convince people to use them.  But, boy, it's difficult to use.



Here what we're seeing, instead of having a single device where you use a single third-party service to authenticate, what Google has done is they're saying we'll do like a multi-account authentication.  So you can add as many of these keys to Google Authenticator as you want.  And so I've got one now that's for Dropbox.  And it shows me what the six-digit code that Dropbox expects me to be able to provide when I want to log in.  Now, I also - I haven't messed with Windows Phone 7.  Maybe you know this, Leo.  They talk about something called "Authenticator."  Is it just part of Windows?



LEO:  I don't know.



STEVE:  I don't know, but...



LEO:  I don't know.  I mean, there's Google Authenticator.  Maybe there's a Microsoft authenticator.  Maybe the chatroom knows.



STEVE:  Well, now, Google Authenticator is Android, iPhone, and BlackBerry.  



LEO:  Right.  So there's no Windows Phone version of that. So there must be some - maybe it is a VeriSign or something.



STEVE:  Well, probably not because it's going to be open, where VeriSign is not.



LEO:  Right, right, right.



STEVE:  But what I'm aiming at here is I bet you we're on the cusp of seeing this time-based one-time password system built into our devices.  I mean, it's nearly the optimal solution, where you're able to create a code, and this is a one-time password, device-based.  Everybody's got a smart phone, pretty much.  So the problem with Dropbox is it's a little bit tricky to get set up.  They will put up a QR code that you can scan, and I snapped it with an iPad, and it immediately registered.  In fact, while the little scanner was open, as soon as it locked into it and focused it, Google Authenticator said, okay, I got it, and showed me the six-digit code that Dropbox then was asking for to confirm that I had received it.



The problem is you can't - I was unable to, and I poked at it for a while, to ever get it to show that to me again.  So, and I wasn't able to say, show me my QR code for my valid guy.  There is an option to get the equivalent 26-character key.  And so because what I wanted was I wanted to try this also on my BlackBerry.  So I had it on my iPad and my BlackBerry.  Now, the BlackBerry Google Authenticator is bare bones, to say the least.  I'm glad to have one, but there's no frills.  There's no option to have it snap it with the camera.  You have to enter it by hand.  And as soon as you respond to the QR code, then you no longer have the option to get the 26-character TOTP key.  So I had to delete it and start over.  This time I got the 26-character key, so I could write that down.  Now I have that for my Dropbox account so that I'm able to manually provide it to any instances of these TOTP authenticators that I want.



So to me it feels like it's a little bit awkward yet.  It'd be nice, I mean, it's great that they have it.  It works.  I really think this is going to be the future.  It looks to me like this is the two-factor authentication technology which is - it costs nothing.  It's multi-account inherently.  It's standards-based.  It's secure.  I bet you we're going to start seeing it built into devices.  It's the right solution.



Oh, and one last thing, they do provide, Dropbox does, a 16-digit backup code which they give you as your override.  So if you - this is something that you write down and put in the safe or in your safety deposit or somewhere because, if you can no longer do your two-step verification, I mean, arguably there has to be some solution for convincing them that you're still you.  So there's a much more cumbersome, yet reasonable, super-secure because it's 16 random digits, actually I think it's characters, I can't remember whether mine - I think mine was full alpha.  So very, very high entropy code they provide which allows you to get back in if for some reason you can't do so with your one-time password device.  So I feel like the UI needs a little bit of work.  But we now have two-factor authentication for Dropbox.  So that's definitely a yay.



LEO:  I don't know if this is the one Dropbox is recommending.  There's a third-party authenticator that works with Google 2-step.  So I presume this is what they're talking about for Windows Phone.  But it's from a company called Slug on a Mission.  I, you know...



STEVE:  Is there something - the word I have is just "Authenticator," as if that's the name.



LEO:  That's what this is called.  But golly.  I would rather it were offered by, I don't know, somebody besides Slug on a Mission.



STEVE:  And then they also mentioned Amazon AWS MFA, that's probably Multi-Factor Authentication, for Android.  Although Google Authenticator works for Android.  I don't know why you'd look any further than that.  So anyway, the idea is, if I had that football, and I still do, and I use it, I don't have control of it generally.  That is to say, PayPal uses it with VIP, presumably, VeriSign Identity Protection, paying the price to have that kind of protection.  But it's not generally available.  I mean I can't use that for other things unless those services sign up to validate with the same back end.



The beauty of this transformation that we have now seen, probably led largely by the presence of the Google Authenticator, is the concept of let's take the time-based one-time password and allow the user to provide the key, and we'll use that cryptographically to generate the code.  And we can have, the user can have as many accounts as they choose.  So there will be Dropbox, there'll be Google Mail,  there'll be Amazon S3, whatever.  And I think that's probably going to be the solution that wins for this kind of multifactor need.  So I'm glad for it.  I think we're going to see...



LEO:  Yes.  Everyone should go two-factor.  Everyone.



STEVE:  Yes, yeah.  I got a tweet from James L. McMahan, Jr. that I just thought I wanted to thank him for, showing that Revision3 is detecting ad-blockers.  And when he went there with his ad-blocker on to Revision3, it said - he got a little note on the screen that said, "Oops, your ad-blocker is on.  Revision3 content requires ad-blocking software to be disabled.  Thank you for your support."  And I think that's entirely appropriate, Leo.  I mean, I think that's the right thing to do.  We've talked about the inherent tension that exists between tracking and advertising and all that.  And I have absolutely no problem with the idea of a site saying, wait a minute, you're not accepting some content which we need you to accept in order for us to be able to give you every thing else we want to.  So please accept it.



LEO:  Good.  And I accept it.  We don't do that, by the way.  But I understand why they do that.  They've got to pay for their bandwidth and stuff.



STEVE:  Oh, yeah.



LEO:  That's not free.  I wonder if that's a Discovery thing, now that they're owned by Discovery.  I wonder if Discovery does that.  



STEVE:  Oh, interesting.



LEO:  Yeah.



STEVE:  I tweeted, I'm trying to think, late last week I think, about something that I had received a lot of tweets about previously.  It's a really nice directory of free online Internet courses, Coursera.org.  Coursera.org/courses is a list of all the courses that they have available.  And just, I think it was yesterday or maybe Monday, the Crypto course, which has run several times, was restarting.  So that was Coursera.org/course/crypto.  And I got a lot of people who thanked me for the tweet.  Some signed up.  Some said, hey, I did that last cycle, and it was really good.  One guy, in fact, who's a listener, obviously, said, hey, you'll get a kick out of the fact that the MS-PPTP, which is what of course we talked about as not being secure last week, he said, that was used as an example of an insecure protocol in the course.  And many people have said that this stuff, especially maybe the crypto course, is very good.  So I just wanted to bring it to our listeners' attention, Coursera.org/courses.



LEO:  It's very cool.  It's very cool.



STEVE:  Yeah, and these are major universities.  I mean, this is Stanford and Princeton and Columbia and Rutgers and a bunch of real players who are doing this.  And total miscellanea, but I missed the 80th birthday of LEGOs a couple weeks ago.



LEO:  Man.



STEVE:  And that just - I saw that today, I said, oh, LEGOs turned 80.  Wow, that's very cool.  LEGOs, of course, are a favorite geek toy.



LEO:  And no longer copyrightable or patentable.



STEVE:  [Gasping]



LEO:  So anybody can make - that just happened in the last year or so.



STEVE:  No kidding.



LEO:  For a long time you could not make a LEGO-compatible block.  And now you can.



STEVE:  Wow.  I wonder how they kept the intellectual property for that for 80 years?



LEO:  That's a good question.  I don't know.



STEVE:  Yeah.  I did get a nice short note from a happy SpinRite user, Mark Cole, who wrote back to Sue.  He must have been corresponding with her about something, oh, apparently about our consultant license.  He said, "Sue, thank you for your prompt reply and thank you for the explanation.  I'm sorry I missed the specific web page you referred me to, but I am so glad you have consultant licenses.  I'll work towards purchasing the four copies."



Just to pause for a second, the way we do this is you buy one copy of SpinRite, and you can use it on all the machines you yourself personally own.  But of course there's been a demand over the years for people who are computer fixers to be able to use it on all of their clients' machines.  And so we said, well, if you keep four copies current, then you're entitled to do that.  That seems, I mean, nobody else is - I just kind of invented that.  I like it, though, because it allows someone to try one copy, and then they don't have to, like, ask for a refund for their one in order to get a consultant license or something.  I mean, it's just, it's like, oh, no, just get three more.  And so I always smile when I hear three yabba-dabbas come out of our eCommerce system because that tells me, first of all, that someone tried their one copy, and it worked, and they liked it, and also that they're being honest, actually...



[Talking simultaneously]



STEVE:  They're saying, hey, you know, I'm going to get three more so that I am a valid consultant and can use it on all of my friends' machines.



LEO:  Aren't they nice.



STEVE:  So anyway, so he finished, says, "Also I wanted to share that I went to the location where I was working on the PC with the Blue Screen of Death, and SpinRite comes to the rescue again.  It took a couple of reboots after SpinRite did its thing, and Windows XP followed up with doing its own chkdsk, and the PC is up and running like nothing ever happened.  The customer is going to be absolutely thrilled when they come in tomorrow morning and their PC will be up and running.  Thank you.  Mark Cole." So, Mark, if you're listening, thank you.



LEO:  Winna winna chicken dinna.  I like it.  And now we move on.



STEVE:  Okay.  So two good TNO, that is to say Trust No One, cloud storage clients or solutions.  And they're very different, but I wanted to bring them to our listeners' attention.  I've been playing with them both.  And one of them I think is going to end up being the official Security Now! solution.  But I'll talk about that one in a second.



First is a very lightweight little, I almost want to call it "applet" or "utility."  It's called DataLocker from AppSense Labs:  appsense.com/labs/data-locker.  And I just tried to Google DataLocker, and I can't tell whether it's the same - I don't think that's the one that comes up.  Oh, it is the second link on Google, if you just put in "DataLocker" into Google.  The second link you'll see www.appsense.com/labs/data-locker.  Anyway, this is - it's very small.  It's one file.  It's 1.576MB.  It does require that you have .NET v4.  And I'm thinking that it is cross-platform, but I didn't write that down.  I think there's a way of running similar apps over on the Mac with some library that you need to have.



LEO:  Yeah, yeah.  There's an open source .NET.  Maybe that's how you do it, yeah.



STEVE:  I think that's it.  And so, okay, so this is minimal, minimal, minimal.  And I like it because I like small, lightweight solutions.  It's simply a drag-and-drop target, so you drop a file onto it in a little window that it provides, and it asks you for a password, which is not recoverable, which it doesn't store.  You put the password in.  And then by default it encrypts it, adding its own extension to the end, and returns it to the same directory that the file originated from.  Or you can send it to a different directory of your choice.  And there's two tabs.  There's Encrypt, and there's Decrypt.  And that's all it does.  But it's cute.



Now, they're not apparently taking it very seriously.  It feels to me like it's something they did to draw attention to themselves, and here it's working, because they are, like, all about other things.  I wrote to them a couple days ago and said, hey, this looks very nice, but there's no documentation anywhere about the crypto protocols you're using, the file format or anything.  So what can you tell me about that?  Silence.  Never got a reply from them.  Other people have said they didn't get a reply.  And I told them that we have a podcast, and lots of people, and this might be interesting, but I don't know.  Maybe they're not looking at that email anyway.  To me it feels like it's not a mainstream deal for them, but something, I mean, it's so, frankly, simple and easy to do this.



But it's cool.  It's a little drag-and-drop simple encrypter/decrypter that you give a filename to.  It doesn't remember the password.  I don't know how I feel about that.  It might be nicer if it was sticky.  It doesn't remember the directory that you tell it to put things in, and it would be nice if that was sticky so that, for example, you could use it with Dropbox or one of those utilities, cloud services.  But anyway, it's a cute little, I mean, to me, I imagine they're using AES-256.  I looked at the encrypted file a little bit, and there's a little bit of a header that they add to identify themselves.  I have no reason to believe that they did anything nefarious.  And it is very small and lightweight.  So easy, quick and easy drag-and-drop encryption.



Now, the one I'm impressed by is called Duplicati.com.  It is over on code.google.com, so open source, being run by a couple guys.  And I'm, well, let me just tell you what it does.  It is a very flexible general-purpose TNO encryption backup solution that is completely oriented toward cloud usage.  It is Windows, Mac, and Linux, so all three major platforms.  It has awareness, specific awareness of the Amazon S3 service, Microsoft's SkyDrive, Google Drive/Google Docs, Rackspace Cloud Files.  It can also just go - it can operate on a file-based basis.  It can talk to WebDAV servers.  It understands the Tahoe-LAFS, the Least Authority File System, which is a distributed secure cloud file system.  It can also talk to FTP servers and also SFTP, Secure FTP, using SSH.  So very flexible from that standpoint.  AES-256 crypto.



It will do a full backup of chosen subdirectories and then follow that with incremental backups, and you can tell it how long you want it to do incremental backups before it does another full backup, so it just doesn't do that forever.  There's a command line tool available also for it, for power users, although it's got a nice little UI.  And I'm trying to think how much storage it uses.  It's been running on my machine for, like, a week or two.  And it looks like it's 45MB, so it's behaving itself well.



There's something in Windows called the Volume Snapshot Service, VSS, which allows backup utilities to perform backups of files that are open.  This has traditionally been a problem, for example, with people who just run with Outlook open because the PST, that central Outlook database file, causes backup problems for utilities because it's open all the time.  So it's able to do - it uses the VSS under Windows, or the equivalent, the Logical Volume Manager under Linux.  Very nice and flexible control over what it backs up.



I sent my entire source code tree under my assembly language directory, which of course I don't do casually.  I sent it up to Amazon S3.  I was able to say I want to back up this entire tree except exclude .EXEs, .OBJs, .RESs, basically all of the intermediate files other than my include files, my header files, and assembly code files and so forth.  So you're able to say I want - very accurately specify.  It's got a nice sequential process rule-based system that understands regular expressions or simple expressions.  Internally they're all regular expressions.  So, I mean, like, really lots of control.  So you can say match on this, then exclude if this, and then include if that, and so forth.  And it's not huge.  The entire directory containing it, it's got lots of little itty-bitty parts and DLLs and things, but it's about 18MB installed.  And again, cross-platform, cross-service.



I'm using it, and I will report back after a while.  But I wanted to bring it to everyone's attention.  I am very impressed.  It's a nice little system.  The idea would be, then, that everybody's offering free storage now, Dropbox and Google and SkyDrive and so forth.  This also allows you to have different named backups, which you can collect in groups and control how often and when and under what circumstances they are run.  So you can have multiple groups with multiple backups.  The backups can contain multiple folders, subdirectories, and those can have the whole rule-based system applied.  So it's very hierarchical and tons of control.  And each group can be sent to a different service.  So it's not like you have to commit the whole thing to Amazon or to SkyDrive.  You can say, okay, I've got a bunch of free space scattered around.  I want to put these files over on this service, and those files over on that service.  And this thing just does the whole thing.  It's a terrific little gizmo.



LEO:  Too bad no Mac version of it, unfortunately.



STEVE:  Yeah, there is.  Windows, Mac, and Linux.  Yeah, all three platforms.



LEO:  I saw the Windows and Linux, Linux using Mono.  I guess if you use Mono on the Mac you could do it.



STEVE:  Then you're ahead of me.  I did not pursue it beyond...



LEO:  Yeah, I see it, I see it.  Released on, yeah, yeah.



STEVE:  So Duplicati.com.



LEO:  You have mentioned this before.



STEVE:  Did I?



LEO:  Yeah.



STEVE:  I guess I didn't drill down into it and look at it closely.



LEO:  Yeah, I think it was in your long...



STEVE:  My big roundup?



LEO:  ...roundup.  But so it's something that - I know I've seen this before.  I'm still using Arq, which you had recommended on the Mac, which I really like.



STEVE:  Yup.  And this is also full TNO.  So they're doing crypto right.



LEO:  Yup, and this is free.



STEVE:  So, Leo?



LEO:  Yes?  Yes, Steve?



STEVE:  The patent system is messed up.



LEO:  Yeah, well, I agree with that.



STEVE:  And I've been watching and listening to people talking about it for a long time.  One of the problems, one of I think the clearest problems is that 20 years is a long time to provide protection for things that don't involve, like, the building of factories and laboratories and facilities in order to implement the patent.  Software moves very quickly.  And granting really broad rights to a company which largely uses its size in order to enforce and in some cases intimidate is discouraging.



I wanted to tell our listeners about a site that the EFF has put together called DefendInnovation.org.  They have a petition there, and they're collecting names and just a little bit of information to assure the world that you're legitimate.  And I would invite people to go over to DefendInnovation.org and take a look around.  They break their concerns down to seven points.  The first one is that a patent covering software should be shorter.  And they're suggesting no more than...



LEO:  It's 17 to 20 years right now.



STEVE:  It is, exactly.



LEO:  Which is ridiculous.  I think it shouldn't - they even say five years, but I think maybe five months or a year because cell phones move pretty darn fast.



STEVE:  Right.  And, I mean, as someone who has experimented and played with the patent system, I've written patents and have attorneys, and I've explored this, there are many problems with the system.  One of the problems, I think the most pervasive problem is that it's often just the company that looks at something first, that basically says, oh - like Apple did.  And I'm an iPhone user, iPad user.  I love Apple stuff.  It's beautiful.  But the tendency is to get patents on everything, even if somebody else who was put in a clean room, had no contact ever, and asked to solve the problem, would just do the same thing.  I mean, oftentimes things are obvious.



And the obviousness test I think is one of the biggest problems we have because, unfortunately, the way our legal system works, we get a jury of 12 people who were selected randomly from the voter roles and the DMV, and is this obvious to them?  No.  But it's obvious to every other programmer on the planet.  But you didn't get 12 programmers on the jury.  So they say also, if the patent is invalid, or there's no infringement - and then here's a little bias showing through.  They say, "The trolls should have to pay the legal fees."



LEO:  They're not talking about Samsung here.  They're talking about people like Nathan Myhrvold who collect patents purely for the point of either extorting license fees or sue.



STEVE:  Just to litigate, exactly.



LEO:  Yeah.  The problem is, that doesn't distinguish between people like Apple and people like patent trolls.  So that's kind of the challenge here is Apple, I mean, regardless of how you feel about the outcome, Apple acted in good faith in suing them.



STEVE:  Oh, absolutely.  And...



LEO:  So had they lost, having them pay costs wouldn't necessarily be appropriate.



STEVE:  Yes.  And, for example, I remember smiling when I looked at my - I was playing with my Nexus 7 tablet.  And when I come to the end of something, it doesn't bounce.



LEO:  Right.



STEVE:  It stops.



LEO:  For a good reason.  That's a patent.



STEVE:  Apple has a patent on bouncing.  And it's like, well, okay.  I mean, so, I guess - and we've talked about this in various contexts before.  I love the fact that I can hold the button down on my BlackBerry, and the letter capitalizes.  Well, I can't do that on my iPad.  It would be nice if I could do it on my iPad.  But BlackBerry has that, and so Apple can't offer that.  So, I mean, there's a problem here in that there's certainly a tension between features that would benefit the consumer and competitive features that benefit the companies offering them.  And so to your point, Leo, should that be 17 years?



LEO:  No, it's too long.  It's too long.



STEVE:  It's crazy, yeah.  And so it would be really nice if, for example, if hold button capitalization, which BlackBerry came up with first because they had a phone with a keyboard on it before Apple ever looked at the situation - now, again, it's a matter of who got there, who had the problem first. 



LEO:  But this is kind of the point of FRAND [Fair, Reasonable, And Non-Discriminatory], which is fair-priced licensing should be required.  And a lot of companies are agreeable to FRAND.



STEVE:  Yes.



LEO:  And that maybe is what you want to enforce, which is, yeah, sure, somebody deserves a license fee.  But it should be a reasonable license fee.  You know Apple was asking $30 per phone.  Whether that's reasonable, I don't know, but it was so much that no company could afford it.



STEVE:  Right, right.  And so on the issue of trolling, for example, the EFF said: "Shift court fees away from innocent parties:  Both the winner and loser in a patent suit almost always pay their owns fees and costs, which can total well into the millions of dollars if the case actually goes to trial.  Because the potential costs are so high, and there is no way to recover those costs, defendants will often settle to avoid hefty legal bills - even if they have a strong legal case that they never infringed on the patent or the patent was invalid to begin with."  So...



LEO:  Right.  That's the case in lawsuits in some states.  They have a SLAPP law, which means if it's deemed a frivolous lawsuit, you pay the costs if you lose.



STEVE:  Yeah.  And again, it's not, I mean, frivolous is a value judgment.  I would imagine that most patent suits are regarded as serious suits.  But anyway, so the point is, at this point, these suits are so expensive that somebody in the right is in tremendous peril and expense if they push this.  So it is, I mean, one of the complaints that I've had generically about the patent system is that, because the patents are complex, the Patent Office, the theory is that the examiners are, I don't know, Einsteins - actually, that's a bad example because he was a patent examiner - but the idea that the patent examiners are, like, omniscient and actually only issue patents for inventions.  But they're not.  The Patent Office is overwhelmed, understaffed, underfunded.  And so what happens is patents get granted if it's not obvious that they should not be granted.  And they just figure, well, we'll let the courts battle it out.  We'll let the courts figure it out.



LEO:  Right.  And that's what happened, I think, with these patents, in fact.  It's like, well, it looks like a good patent.  We'll just make it - we'll prove it, and we'll see what happens.



STEVE:  Right.



LEO:  I don't think people understand that, that in fact it's often the courts that are asked to rule.  And that's inappropriate.



STEVE:  Right.  The fact that you have a patent means nothing.  And in fact, I'm sure you're probably - you'll be able to pull up the number or the name of this.  But there have been sort of some crowd-sourced efforts to help with prior art because the way the patent system works, and this was the instance of some dialogue that you captured at the beginning of the show, before we began recording, Leo, where the bore on the way the Apple vs. Samsung suit went, the idea being that oftentimes there'll be a patent that's been granted for something that already existed in some corner somewhere, in some university, some grad student published this.  And in completely good faith the person submitting the patent may have been unaware of that.  It is the case that the same stuff is independently invented all the time.



LEO:  Sure.



STEVE:  I mean, it's the nature of this.  I mean, and that's one of my problems with this notion that the way this really ends up happening is because this concept, the definition of what is an invention has been so weakened and watered down that it's just who was - what engineer was asked to solve the problem first.  Now, I mean, I love Apple's springy pages, and the pinch-and-zoom thing.  But it's like, oh, okay, was that an invention?



LEO:  I don't think you can argue that the thing, the patents Apple was suing over were for things that made the iPhone better than other phones.  You don't need the bounce.  The Nexus 7 lives without it.  The tap to zoom is great.  Apple invented it.  There's no question.  Although they did show prior art.  It was actually interesting because I played this cut before the show began for you.  The foreman of the jury, in an interview, said he had an insight about one of the patents because he has a patent of his own, so he's an expert.



STEVE:  Ah.



LEO:  I think that's why he was elected to be foreman, I'm sure.  His patent, by the way, as far as I could tell, is completely generic and meaningless.



STEVE:  I'm surprised that he got past the attorneys.



LEO:  I am.  I am, too, because that's the guy that the jury is going to end up looking to.  Hey, you have a patent, you understand this process.  And he, now, I'm very curious about this because he says, I was really struggling with this particular patent.  I think it's the tap-to-zoom.  I'm not sure.  I'll have to go back and look.  But I had an epiphany.  I went home, and I had an aha moment.  Apple's invention wouldn't run on the prior art device that Samsung submitted into evidence, nor would Samsung's code run on Apple's device.  Different processors.  So it wasn't, he says, he used this to determine it wasn't prior art because it didn't run on the same processor.  That doesn't make sense.  Is that right?



STEVE:  No, no, that's a complete misinterpretation of prior art.



LEO:  That's what scared me.  And because he's the expert, the jury bought it.



STEVE:  If Apple had been patenting the particular algorithm code, the algorithm that they used, then that would be one thing.  But they're not.  They were patenting bounciness.  Just like - or pinchiness.  I mean, they were patenting the concept of how can we gently tell the user they reached the end?  Now, I've got to say, Leo, I like that enough - and I guess I'm supporting the notion that this is valuable to Apple.  I like that enough that, if I could pay Apple 30 bucks to add the bouncy package to my Nexus 7, I would probably do it.



LEO:  But this was Apple's contention.  We made some inventions that made our products better, and Samsung just blatantly copied them so that their products would be as good as ours.  But in fact we deserve the right to have this uniquely for 17 years.  And I don't, I mean...



STEVE:  17 years.



LEO:  There's problems.  I understand that.



STEVE:  We're going to be beaming ourselves up to another planet.



LEO:  Right, no, I agree.  And that's - but Apple was acting with the current state of the law.



STEVE:  Oh, yeah.  I mean, they're acting in the interests of their shareholders, which they're obligated to do.



LEO:  Right.



STEVE:  And I guess my point is that, as a consumer, I can't have "hold the button down and capitalize it" on the iPad.



LEO:  I know, it drives me crazy, right.



STEVE:  I have it on the BlackBerry.  I can't have bouncy pages on my Nexus 7.  I want them.



LEO:  I agree.



STEVE:  And so it would be nice, for example, if it were possible to, like, purchase these accessory patents.



LEO:  Can I license them from Apple.



STEVE:  Right.



LEO:  Let me license them.



STEVE:  Yeah, yeah.



LEO:  It's a real - it's a thorny problem.  I think - I signed the petition because I do think we need patent reform.  DefendInnovation.org.



STEVE:  Well, yes, let's just revisit this.  Let's get some smart people, I mean, and you see me, I'm not saying that that was right or wrong.  I love the bouncy pages.  I understand that that's valuable.  I would argue a little bit about whether somebody else encountering the problem wouldn't have the same solution.  So do you know what I mean?



LEO:  It's the obviousness of the patent, right.



STEVE:  Yes.  They just happened to get there first.



LEO:  And the Patent Office is, I think, supposed to consider the obviousness.



STEVE:  Oh, yeah.  The way the actual language is, anything is disqualified for being considered an invention if it would be obvious to someone trained in the art.



LEO:  Right.



STEVE:  That is, if somebody, if a software engineer were given the problem or shown this, would it be, like, obvious?  Or would it be like Velcro, oh, my god, or a zipper, maybe, which I still can't figure that out.



LEO:  Yeah, zipper is not obvious.  I have no idea how that works.  I understand Velcro.  That is why, in the Google/Oracle case, Oracle lost its case because one of the patents that they were fighting over was a range check.  And the judge even said, no, this is obvious.  I learned Java and wrote a range check last night.  It isn't, it is not a non-obvious thing.  So the judge threw it out.  There was no jury in that one.  And I have a feeling, had there been a jury, it might have been a different outcome.



STEVE:  Well, as I was telling you before we began recording, Leo, a couple decades ago I used to accept assignments or opportunities, whatever you would call it - consulting, I guess - as an expert witness in trials.  And I was involved in several that were intellectual property trials.  And when contacted by the attorneys, they'd say, hey, Steve, you wrote a column in InfoWorld where you said the following things, and we agree with you, and we have some litigation about that.  And so I would understand what it was they were talking about, and if I was on their side, then I would say, okay, I agree with you, so this sounds interesting.  The problem was I watched the court system just fumble over and over and over, I mean, essentially reaching what I knew was the wrong conclusion.  So finally I said, okay, I'm not doing this anymore.  It's just too frustrating.  Oh.



LEO:  And I have to say politics and the law and courts are frustrating for normal people.  Thank goodness there are people who have longer attention spans than you or I.



STEVE:  The news was that it was a $1.something billion judgment.  And I guess that it was willful infringement.



LEO:  Which means the judge has the right to triple it because it was deemed willful.



STEVE:  Ohhh, ow.



LEO:  Now, we don't know what she'll do.  And I think the case can be made, frankly, that Samsung, it's pretty clear from the evidence, this is what the real - really the jury did rule from the Samsung emails in which they said we have a crisis of design, we've got to do something, this iPhone's too good.  They kind of - there was a smoking gun.



STEVE:  They copied it.



LEO:  It's pretty obvious that Samsung said we've got to copy it.  And I think it's reasonable to say that Samsung did a calculation and said, look, the best business would be at this point to copy it, take the chance, pay the fine if we get fined.  They probably talked to Apple.  Apple said we want 30 bucks a phone.  Samsung said there's not enough money in the phone to give you 30 bucks a phone, so we're not going to pay that, we'll just take our chances.  And they lost in court.  They made $21 billion on these phones.  They'll pay the $1 billion fine or even a $3 billion fine and say that was our R&D cost for these phones.  And now...



STEVE:  And they'll take the bouncy out of the...



LEO:  And now what they're doing is they're responding and they're changing and they're innovating.  And you look at the phone that Samsung just announced, which is the Galaxy Note II, it's not an iPhone.  It's 5.5".  So there's no question.  Nobody's going to look at that and say, oh, yeah, you stole the iPhone.  So Samsung I think probably made a very conscious business decision infringe.  That would be my call.



STEVE:  Well, and Samsung is also still the huge major part supplier for Apple for all of these phones that...



LEO:  Yeah, they're frenemies.



STEVE:  ...it's been sued against copying.



LEO:  Yeah.  And that business never went away, by the way.  At no point did Apple say, oh, we're going to go somewhere else.



STEVE:  Yeah, there is nowhere else.



LEO:  Well, there are.  There's LG.  There's other people they could go to.  It's a big - there's a big business here.



STEVE:  So I would ask people to go, consider taking a look at that site, DefendInnovation.org, sign the petition if you think as we do that this ought to get some attention, that 17 to 20 years is a long time for a company to own exclusive rights to something that an engineer said, oh, let's do this.  A few years would be a good thing.  And then - or it'd be great if, like, reasonable licensing terms or, who knows, something, I mean, it'd be...



LEO:  I suspect that we will, in fact - this has been such a high, I mean, these suits go on all the time, and there are many more.  Motorola's suing Apple.  There's plenty more going on.  And I suspect this is such a high-profile case that these companies are going to say, look, this is a war of attrition, nobody's going to win, let's figure this out.  And it's actually over now.  This was only a crisis in the first few years of iPhone dominance.  I think it's pretty  much over.  I think there's a - the two have gone their separate ways.  No one's going to confuse an Android phone with an iPhone.



STEVE:  No.



LEO:  It was a good show, Steve.  Very interesting stuff.  It was a busy week.  Now, we will do the Q&A next week, so we're back on our Mod 1 or Mod 0, whatever it is.



STEVE:  Yes, I was thinking, well, we have the advantage of skipping back to the original phase that we were in.  We had a 180-degree phase shift, and we've phased it again.



LEO:  It's Mod 2, right.



STEVE:  We're back in phase, yes.



LEO:  It's even-numbered shows.  So next week, if you have a question, a comment, or something you'd like to say and have Steve address it, you can go to GRC.com/feedback.  That's where - don't email me, don't email Steve, just the feedback form is meant for this purpose, GRC.com/feedback.



STEVE:  Yeah, I'm nodding, but no one can see that.



LEO:  Steve is nodding.



STEVE:  Yes, I'm nodding.  So, yes, go there.



LEO:  Yeah, nodding doesn't work on audio.  We do make audio and video versions available of the show.  I don't know why you'd watch the video except to see Steve's smiling face and his nods.  But you can get both at TWiT.tv/sn.  And of course Steve makes the little teeny-weeny 16Kb version available on his site, as well as full text transcripts by a human being, which means they're legible and spelled properly.  That's at GRC.com, where you also find SpinRite.



STEVE:  Oh, and I actually forgot to give Elaine credit for the Coursera.



LEO:  That was her pick.



STEVE:  Several people had mentioned it to me, but I just hadn't gotten off the dime to go pursue it because I would see the tweets come in when I was in the middle of something else.  And finally Elaine said, hey, I was - the thing that made me think about it is that she does so much research when she's doing the transcriptions.  She's going out and checking spelling and verifying things, I mean, there's a whole lot of - it's much more than just an automated process for her.  And so something that she was doing took her to that site, and she said, hey, I'll bet this would be interesting for Security Now!'s audience.



LEO:  Coursera's amazing.



STEVE:  So thanks to Elaine, yeah.



LEO:  I just wish I were a young person again, and I had more time.



STEVE:  Oh, gosh, I know.



LEO:  SpinRite is also at GRC.com.  That's Steve's bread and butter, the world's best hard drive maintenance utility.  You must have a copy and get it there.  Also lots of freebies including ShieldsUP! and the Password Haystacks, all that stuff.  GRC.com.  We do this show every  Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time on TWiT.tv.  That's 1800 UTC.  Now, Steve, just a program note, I think we mentioned this last week, two weeks from now, supposedly, although the invitations haven't gone out, is Apple's...



STEVE:  We're going to do a Tuesday/Wednesday swap?



LEO:  Yeah, we might.  We don't know.  But I suspect we'll want to do a Tuesday/Wednesday swap on Episode 369.  But we'll let you and everybody else know before we do that because of the Apple announcement.



STEVE:  And that's supposed to be the iPhone 5; right?



LEO:  That's going to be the new iPhone.  I think there seems such a consensus among all the pundits that I think we're pretty much sure that that's what will happen September 12th.



STEVE:  And a 7" tablet has been pretty much confirmed, too.



LEO:  But not for that - now the consensus is that it will be a separate announcement in October.



STEVE:  Right.



LEO:  So, you know, it's all made up.



STEVE:  I like mine at 10.whatever it is.  That's, to me, I'd like, if I think about the same thing in a smaller one, it's like, I don't know.



LEO:  I'm excited.  I love the 7.  You have the 7, the Nexus 7.  And I love that size.



STEVE:  Oh, I do.  It's beautiful.



LEO:  But I'm excited about the Note II, which is 5.5".



STEVE:  Okay.



LEO:  I think that that's going to be a perfect in-between because it's a phone and it's a tablet.



STEVE:  And a stylus; right?  A stylus-based tablet.



LEO:  It has a stylus.  And it's actually the stylus that it uses is very sophisticated.  You can do some really interesting things.



STEVE:  When is that happening?



LEO:  They didn't say a date, but I think it's generally thought that it will be available in Europe next month.  The European versions always want to be ahead of everybody.  And the American carriers will get it in December.



STEVE:  Ooh, December, that's a little late for Christmas.



LEO:  Before the end of the year.



STEVE:  Ah.



LEO:  Steve Gibson, thank you so much.  We'll see you next week on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#368	

DATE:		September 5, 2012

TITLE:		Listener Feedback #150

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-368.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about the latest security news, including that leaked FBI laptop, and, of course, your questions and Steve's answers.  We've got some great questions for you, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 368, recorded September 5th, 2012:  Your questions, Steve's answers, #150.



It's time for Security Now!, the show that protects you online.  Steve Gibson, the Explainer in Chief, is here.  He is from GRC.com, the creator of SpinRite, world's finest hard drive maintenance and recovery utility, and joins us every week to talk about security.  And a good day to you, Steve.



STEVE GIBSON:  Hey, Leo, great to be with you again, as always.  After some delays for important news...



LEO:  We actually have a Q&A?



STEVE:  We actually have a Q&A this week, yeah.



LEO:  Wow.  Well, you know, I almost thought, because there was that FBI database that was leaked yesterday, I almost thought, oh, crap, we're not going to do questions against this week.



STEVE:  Well, we're definitely going to be talking about that.  So that's happening for sure.  I have a fun quote from the hackers who posted the list up on Pastebin.  And as we know, the FBI is denying that they ever had that data or that it came from that laptop.  We don't know.



LEO:  Well, who are you going to trust, a bunch of anonymous hackers or the FBI?  That's a tough question, actually.



STEVE:  Neither.  None of the above.  Is there a third choice?



LEO:  I mean, I trust the FBI.  But on the other hand, there's a lot of incentive to deny this breach.



STEVE:  Yes, yes.  Strong need to deny it.  And although at the same time the hackers could simply be trying to give the FBI a black eye.



LEO:  I'm kind of in that - well, we'll talk about it.  That's good.



STEVE:  Yeah, yeah.



LEO:  Yeah.  And we have a Q&A?



STEVE:  We have news.  We have news that we discussed at length last week with Java.  And many of our listeners, probably every one of our listeners know that immediately, I would say the ink was hardly dry, but we don't use ink on the podcast, so the files were still freshly dated when the Java update...



LEO:  The bits were newly minted.



STEVE:  They hadn't really settled down yet.



LEO:  No.  The electrons were still buzzing.



STEVE:  And we got another one, which is not right, either.  So we'll talk about that and a bunch of other cool things.



LEO:  Steve Gibson, let's get the security news.



STEVE:  Let's do that.  So we spoke extensively last week of Java, yet again.  And I was explaining, I think, what I liked best about the way I posed things last week was the idea that Java being invokable by web browsers was inherently a problem because it was a full-strength language, not designed for web clients; whereas JavaScript was designed for web clients.  So JavaScript is safer.



LEO:  Er.



STEVE:  Certainly not without its problems.  Thus we have NoScript, in order to even control scripting.  But Java is very dangerous.  And the problem with Java is that, in order to try to control it, they have attempted to sandbox it.  And we talked about sandboxing off and on through the years because it's very much like a firewall, where you've got goodies behind the firewall that you want to keep bad guys from getting.  Well, that creates an inherent tension.  There's a problem because then you're depending upon your firewall to limit access to something you don't want people to have.  It's much safer not to have it in the first place.  So JavaScript is better in that way.



So what happened was, almost immediately after last week's podcast, the day after, Oracle did release their emergency out-of-cycle update, which wasn't scheduled until the middle of next month, I think October 18th or 16th, if I remember correctly.  But they did it immediately because this was a zero-day, two different vulnerabilities that had been reported, I think, more than a year ago, and they had not gotten around to fixing them.  So they pushed that out immediately.



And at that point Adam Gowdiak of Security Explorations, who had some dialogue with Oracle as recently as April of this year about those and other problems, he posted:  "Hello, all.  Yesterday, an out-of-band patch was released by Oracle, which among other things incorporated fixes for the issues exploited by the recent Java SE 7 attack code."  And then he says in parentheses, "(ClassFinder/MethodFinder bugs)," which is what we discussed last week.



He said, "One of the fixes incorporated in the released update addressed the exploitation vector with the use of the sun.awt.SunToolkit class," which is where those two methods are.  He said, "Removing getField and getMethod methods from the implementation of the aforementioned class caused all of our full sandbox bypass Proof of Concept codes not to work anymore."  And so that's the good news.



He says, "Please note that not all security issues that were reported in April of 2012," so about four months ago, "got addressed by the recent Java update.  [So] today we sent a security vulnerability report, along with Proof of Concept code, to Oracle.  The code successfully demonstrates a complete JVM," which is Java Virtual Machine, "sandbox bypass in the environment of the latest Java SE software, [which is] version 7 Update 7 released on August 30," which was Thursday of last week, "2012.  The reason for it is a new security issue discovered that made exploitation of some of our not-yet-addressed bugs possible to exploit again."



So Oracle chose not to fix all the problems that they knew about.  They only fixed the two that were being actively exploited, left the other ones alone.  And so these guys designed yet another proof of concept to show to Oracle yet again that there's still trouble.  Now, this of course exposes us to the same problem, which is further indication that we really do need to start listening to all the security people in the entire industry who are now saying get rid of it.  If you don't need it, remove it.  I did see some disturbing tweets from people in, I'm thinking Sweden, maybe Switzerland, somewhere like that, saying that the banks over there depend upon Java for all of the online banking.



LEO:  Yeah.



STEVE:  It's like, okay.  That's not going to be a problem.



LEO:  I think there's a lot of places where you do need Java.



STEVE:  Yeah.  Unfortunately.  I mean, it is powerful.  It's multiplatform.  We need to consider it to be a transitional technology in the same way that Flash was.  And where the evolution of the native capabilities of our browsers, represented by the movement to capabilities available in HTML5 from HTML4, and things like those extra services which will be available in JavaScript will increasingly replace these sorts of third-party solutions.  And the good news is there is certainly pressure on everyone.  In the same way that Adobe and Flash has been in the doghouse because they were not in the sandbox for so long, the same thing is happening with Java.  I mean, you can't have the industry advising everyone to uninstall it without that creating some pressure on it.



LEO:  Is it as good - people keep asking me this.  We talked about it last week.  But is it as good to disable it in the browser as to uninstall it?  It certainly is better than nothing.



STEVE:  Okay.  If you really need it, then I think the better - a workable compromise is to use a different browser.  For example, when you click a link, you'll have your system default browser, whatever you choose for it to be - Chrome, IE, Firefox, whatever.  Maybe do not install the plugin for Java in that browser so that your random link-clicking and surfing just cannot invoke Java, but have a browser which you use for playing games or talking to your Swiss bank or whatever it is you're doing.  And that browser has the Java plugin so that it's able to invoke Java.  That way you've created on your end - although you have responsibility for doing this correctly.  The idea would be, though, that the default browser you're using doesn't have Java plugin, cannot invoke Java through the browser.  And then you need to, I mean, many of us do that, for example, with IE.  I don't use IE for anything except Windows Update that wants to use IE under XP.  So that's an example of the idea of multiple browsers, sad as this is to suggest the need for, but multiple browsers to create some isolation.



LEO:  And modern browsers like Chrome and Safari will warn you before they run Java.  They don't run Java ever without warning.  They say I want to run Java, allow or disallow.  Right?



STEVE:  Oh, okay.



LEO:  Safari does.  I'm pretty sure Chrome does.



STEVE:  Apple has been making some good inroads from a security standpoint.  As we know, it keeps it disabled.  It times it out and redisables it.  And so, I mean, they've been very proactive on behalf of their users after the catastrophe of hundreds of thousands of machines getting infected from the prior Java zero-day exploit.



LEO:  So tell people also, pay attention.  It's one thing if you're running a game, and it says "May I launch Java."  It's another thing if you're just at a regular website and it says "May I launch Java."



STEVE:  Yeah.  And so here we are, we're looking at the difference between the common, the typical user, and our audience.  Our audience...



LEO:  Right, they know.



STEVE:  ...I can say "Two browsers, one with Java, one without."  Not a problem.  That same audience will say, ooh, wait a minute, why am I being prompted to run Java?  Steve and Leo have told me over and over and over, I could get in trouble when I do that, and here I'm going somewhere where I'm not expecting to run Java.  So this audience understands that.  But there's just no way that anybody who's just your typical Internet user is not going to get in trouble.



So, I mean, the industry needs to protect users from the dangers of common actions.  And, unfortunately, running Java is a common action.  Certainly at some point many people have had their browsers say, "Oh, in order to do this, you need to click this button."  Most people do.  And so, like, it downloads and installs Java.  And annoyingly, it also installs extra stuff you don't want to.  I can't even believe that, Leo.  When I was updating my Java there was an opportunity to install some - was it a security, I think McAfee security scan.



LEO:  Oh, no.



STEVE:  Oh, yeah.



LEO:  Thank you, Oracle, you piece of junk.



STEVE:  Unbelievable.



LEO:  Jiminy.



STEVE:  I know.



LEO:  Ugh.  Blame Oracle.



STEVE:  Of course I do.  And that's just wrong.



LEO:  Yeah, blame Oracle.  That's just wrong.



STEVE:  I mean, they're getting revenue from that.  They're upselling their...



LEO:  Java's free, but it's always been free.  This is part of the deal when you bought Java, you bought Sun.  Open source it or something; you know?  If you're not going to keep - it's one thing if they would keep it up to date.  Then maybe I wouldn't mind giving a little something.  So if I go to Free Java Download, oh, it won't let me because I'm on a Mac.  I don't even know if...



STEVE:  Yeah, my most recent Java update, I'm very sure that it was checked by default, and it was "Get a free McAfee security scan."  It's like, ohhhh.



LEO:  It's so not okay.



STEVE:  Bad people.



LEO:  Bad people.



STEVE:  So, okay.  The big news is, of the week, new news instead of new old news, or old new news or something, anything, new new news is that 12,367,232 Apple iOS unique device identifiers, UDIDs, along with usernames, the name of the device, the type of the device, something called Apple Push Notification Service Tokens, users' zip codes, their cell phone numbers, their physical addresses, et cetera, and personal detail fields referring to people, were leaked onto, well, were obtained by a group of hackers.



So I tweeted, if anyone is curious to see this themselves, I tweeted at SGgrc, so Twitter.com/sggrc, and my very first - my most recent couple tweets, I tweeted just this morning for the podcast.  There's a link to the Pastebin page where 1,000,001 of these 12 million-plus UDIDs have been posted.  And excerpting a piece from the long dialogue that's there, it says:



"During the second week of March 2012, a Dell Vostro notebook used by Supervisor Special Agent Christopher K. Stangl from FBI Regional Cyber Action Team and New York FBI Office Evidence Response Team was breached using the AtomicReferenceArray vulnerability in" - [cough] wait for it - "Java.  During the shell session some files were downloaded from his desktop folder, one of them with the name of 'NCFTA_iOS_devices_intel.csv'" - so a comma separated values file.  It "turned to be a list of 12,367,232 Apple iOS devices, including Unique Device Identifiers, user names, name of device, type of device,  service tokens, zip codes, cell phone numbers, addresses, et cetera.  The personal details fields referring to people appears many times empty, leaving the whole list incomplete on many parts.  No other file on the same folder makes mention about this list or its purpose."



LEO:  Now, this is all allegedly.  I mean, these guys...



STEVE:  Yes.



LEO:  Who knows?  These guys, we can't trust them.



STEVE:  So we don't know, this is true.



LEO:  We don't even know who they are, yeah.



STEVE:  We don't know this is true.  This sounds plausible.  So does the FBI's denial that they ever had such a list.



LEO:  And Apple just minutes ago denied that they gave the FBI such a list.



STEVE:  Okay.



LEO:  Not that Apple would have to give the FBI a list to have such a thing.



STEVE:  A security consultant in Dunedin, New Zealand, Aldo Cortesi, has been worried about the whole issue of UDIDs for years.  In his little "about me" he says, "I hack on things that interest me and run Nullcube, a small security consultancy that provides services worldwide."  And I liked his description, so I'll share it.  And this is a post from him a year ago, 9th of September, 2011.  He said, "A UDID is a 'Unique Device Identifier.'  You can think of it as a serial number burned permanently into every iPhone, iPad, and iPod Touch.  Any installed app...."  Now, this is a year ago, and we'll talk about what Apple has done since and then current state.  So a year ago.



"Any installed app can access the UDID without requiring the user's knowledge or consent.  We know that UDIDs are very widely used.  In a sample of 94 apps I tested, 74 percent silently sent the UDID to one or more servers on the Internet, often without encryption.  This means that UDIDs are not secret values.  If you use an Apple device regularly, it's certain that your UDID has found its way into scores of databases you're entirely unaware of.  Developers often assume UDIDs are anonymous values, and routinely use them to aggregate detailed and sensitive user behavioral information.



"One example is Flurry, a mobile analytics firm used by 15 percent of apps I tested," he writes, "which can monitor application startup, shutdown, scores achieved, and a host of other application-specific events, all linked to the user's UDID.  I recently showed that it was possible to use OpenFeint, a large mobile social gaming network, to de-anonymize UDIDs, linking them to usernames, email addresses, GPS locations, and even Facebook profiles.



"This post looks at the way UDIDs are used in the broader social gaming ecosystem.  The work is based on a simple question:  What happens if we swap our UDID for another while communicating with the network?  There are a number of ways to do this.  In my case, I used mitm" - which of course we know is an acronym for "man-in-the-middle" - "mitmproxy, an intercepting HTTP/S proxy I developed which lets me re-write the traffic leaving a device on the fly.  In most cases this was a simple matter of replacing one string with another.  But two networks, Scoreloop and Crystal, prevented UDID substitution using cryptography.  Unfortunately, both networks relied on the secrecy of key material distributed in the application binaries to every device.  I have verified that it is possible to reverse-engineer the application binaries to extract the key material and circumvent the cryptographic protection."  Okay.  But that's a little detail.  So he's saying, in general, swapping UDIDs swaps your identity.



"The outcome of this experiment shows," he writes, "that social gaming networks systematically misuse UDIDs, resulting in serious privacy breaches for their users.  All the networks I tested allowed UDIDs to be linked to potentially identifying user information, ranging from usernames to email addresses, friends lists, and private messages.  Furthermore, five of the seven networks allow an attacker to log in as a user using only their UDID, giving the attacker complete control of the user's account."  Full impersonation.  "Two networks had further problems that compromised a user's Facebook and Twitter accounts.  Crystal lets an attacker take control of user accounts by leaking API keys, while Scoreloop partially discloses users' friends lists, even if they are private."



Okay.  So we have a situation where, from day one, our iOS devices have all had a unique ID.  There have been apps on the App Store, I've downloaded them, one called "UDID," which you run it, and it shows you your UDID.



LEO:  You can get that in the About box, too.



STEVE:  Exactly.



LEO:  You don't need an app for that.



STEVE:  Well, in this case it makes it simple because what I was doing was I was beta testing apps that were not yet public, and so I needed to provide the app developer with the UDID of my device so he could...



LEO:  That's the most commonly used purpose for UDIDs.



STEVE:  Correct.  And so this made it easy because I was able just to put in that person's email address, and it sent a preformatted piece of email, including the UDID, so it was all done for me.



LEO:  Otherwise you have to type it in, yeah, yeah.



STEVE:  Yeah.  So what we have is something very much like an Internet or, sorry, Ethernet MAC address.  It is a globally unique ID that uniquely identifies the device.



LEO:  But, I mean, the phone has at least that, has a MAC address, UDID, and it has an IMEI number.  It has numerous unique identifiers.



STEVE:  Right.  And so what's happened is 12 million...



LEO:  All phones have this, by the way.



STEVE:  We presume 12 million of these are, well, and remember these are also non-phone devices, iPods and iPads.



LEO:  iPads, too.



STEVE:  In addition to the iPhone.  So anyway, so we have 12 million ostensibly leaked with a ton of user information.  There is a site that we've referred to in the past, ShouldIChangeMyPassword.com.  And I also tweeted the link to that, where you can get your UDID, put it into here, and it will do a check to see whether yours is in the leaked data.  And there are a number of anecdotal posts on the Internet of people who have been active iOS users finding three of their devices' UDIDs among this first million leaked IDs.



So where's Apple on this?  A year ago Apple acknowledged that this was probably not a good idea.  There was an API, an Application Programming Interface, that essentially allowed any application to ask for the device's UDID.  And it was just a convenient token to represent the user.  The problem is that it was common to all the applications on the device.  So with the release of iOS 5, which is where we are today, which was about a year ago, Apple has formally said that the use of UDIDs is deprecated and will be removed from iOS.



LEO:  And since March they've stopped approving any app that uses UDIDs.



STEVE:  Right.  So they're saying "Unique Identifier, an alphanumeric string unique to each device based on various hardware details.  Deprecated in iOS 5.  Instead, create a unique identifier specific to your app."  And so they're saying do this yourself, don't use something global.  So this is, I mean, this is not the end of the world.  This isn't, I mean, we'll see how this gets leveraged and exploited.  These things tend to have some legs.  So there may be - we may be talking about this again in future weeks or months, if bad things happen as a consequence of this.  But for the time being, I just wanted to bring it to the attention of people who like to follow interesting events in the security world.



LEO:  Yeah.  And I guess we don't really know what happened.



STEVE:  We don't.  We have absolutely...



LEO:  We have no idea.  This is all the assertion of a fairly discreditable group.



STEVE:  Yes.  I completely agree.  They're saying this is where it came from, with lots of information that sounds plausible.  But we don't know.  So I'm not...



LEO:  Or even what to do with it; right?  I mean...



STEVE:  Well, we'll see.  I mean, depending upon what the information is.



LEO:  Right.



STEVE:  If in fact there are networks and apps that simply - that identify and authenticate their user purely with the UDID, then this means anyone who's in this database can be impersonated.  That's not good.



LEO:  Right.



STEVE:  So what I would say is, any app developer who is still using this really, really needs to stop right now.



LEO:  It would be, I mean, nobody's doing it, as I said, actively, because Apple won't approve you.



STEVE:  What about apps that have been?



LEO:  That's the problem.  There's probably a whole bunch of legacy apps that do that.



STEVE:  Yes, yes.



LEO:  And but they have to be updated to stop doing that.



STEVE:  Yes.  And so the takeaway from this for app developers is consider that your users are not safe any longer if you are giving a UDID too much power.  And we've seen that many apps do.  So developers need to immediately change that behavior, like yesterday.



Okay.  This is a bizarre little tidbit that wraps up our security news for the week.  A security researcher has figured out that it is possible to put an entire phishing web page in a URL.



LEO:  The whole page.



STEVE:  The entire page.



LEO:  It shows the whole page.  [Laughing] That's good.



STEVE:  Yes.  I posted a link to the - I think I posted a link to it, also in my Twitter feed.  Anyway, so this is - there's an RFC, 14 years old, August of '98.  It's RFC 2397.  So because of its age, it is completely supported in all browsers.  In the same way that you can have http: and then something, like // and domain name and so forth, you can have the word "data," data:, and you then specify the media type, like image/gif, and optionally whether what follows is base64 encoded, to allow you to encode anything which might otherwise have a problem being encoded in the character set.  And then you follow it with the content of whatever it is.  And in the RFC is an example of them encoding a jpeg image in an image tag.



So, for example, normally, for people who haven't done web pages before, normally a web page would contain an image tag where it would say SRC, for the source of the image, equals, and then http:// and then, you know, so forth.  That is the URL for the browser to go fetch the image.  It turns out you can use this data: approach instead and actually put the image data right there in the page, so that the browser isn't going and fetching this object, going back and fetching it from the server, but the page itself contains it.



Well, what the researcher recognized was that this would also be honored in a URL.  Which means that you could use any of these link-shortening services to have a shortcut which expands to a full-blown web page, and it works.  Now, browsers treat this a little differently.  They all know about the data: option.  Firefox and Opera work perfectly.  They allocate as much memory as necessary and interpret this.  You could have JavaScript.  You can invoke Java exploits.  You can do anything you want to.



So the point is, what's different about this is that, traditionally, phishers, p-h-i-s-h phishers, had to have a site somewhere.  They had to maybe have it say PayPal with Pa1 instead of Pal, to sort of trip you up.  They had to have a hosting server that your browser would be bounced to.  Well, no longer.  We don't need to have a site at all.  We can bundle the entire fake web page into the URL of the browser using this approach.  So the good news is IE limits the length of the data: element so that it inhibits what can be done.  And Chrome is interesting.  Chrome does it, but brings up a security kind of warning saying, um, this is sort of strange.



LEO:  That's an awful long URL.  Are you sure you meant that?  How long can it be?  256 characters?  I mean, is there...



STEVE:  No, 23K.



LEO:  23K.



STEVE:  Yeah.  And, I mean...



LEO:  But what does IE limit it to?



STEVE:  I didn't look...



LEO:  Not 23K.



STEVE:  Yeah, a lot shorter.  So that in...



LEO:  That's an awful lot.



STEVE:  In this PDF, in the appendix, they show a complete base64-encoded page.  Anybody who is curious could, like, copy and paste it into their URL, and up comes a well-formed, ready-to-go phishing page.  It's just incredible.  So I thought, okay, that's...



LEO:  I'm looking at it.  It's a pretty long - because it's base64-encoded, it's...



STEVE:  Yeah, but, I mean, that's the URL.  And Firefox and Opera go, wow, okay.



LEO:  All right.  If you insist.  Here it is.  Wow.  Look at that.



STEVE:  Isn't that something.



LEO:  Yeah.



STEVE:  Yeah.  And Chrome, you are able to click through Chrome's questioning of this and go, yeah, that's what I meant.  And then you get the page.



LEO:  Well, I'm going to try it now.  Now you've got my curiosity.  Wonder what Safari does.  It's quite a bit of copy and pasting here.  All right.



STEVE:  Yeah.  And it's across page breaks and so forth.



LEO:  Well, and I hope I didn't get page numbers in there.  Doesn't look like it.  It looks like they made it so that you could do that.  Let me try it in Safari here.  Yup, it opened.  Oh.  Login to create account.  Wikipedia.  Looks just like the page.



STEVE:  That's the page.



LEO:  That's it?  Holy cow.



STEVE:  Yes.



LEO:  So that it didn't go out and get any of this.  This is all in that base64-encoded text.  And no warning from Safari at all.



STEVE:  Nope.



LEO:  It just did it.



STEVE:  And so you use a link shortener and click.  That's in email, or it's wherever.  And your browser just says, oh, I'm going to display all of this right from the address bar.



LEO:  Now you've got me going here.  Let's try Chrome.  Paste that in.  Oh, did I get it?  Maybe Chrome won't even let me.  Yeah, see, maybe I don't have it anymore.  Huh.  Well, that's - oh, yeah.  You know what, I bet you that, among other things, it cleared my clipboard.  Does it?  With everything else it did?



STEVE:  It's running a script. 



LEO:  Yeah, it's running a script.  It could have cleared the clipboard so that you can't investigate.  Wow.  Nice job.



STEVE:  Wow.  Isn't that cool?  I was just like, okay, well, this is unintended consequences.  Allow us to put embedded data in anything.  So instead of http:, we have data:, and anything you want.  Yeah, it's cool.



LEO:  Love it.



STEVE:  So before we began recording the podcast, I mentioned to you, we discussed a little bit, or maybe it was even when you were doing the Audible mention, that Mark Russinovich's book "Trojan Horse" that I referred to a couple months ago and read a couple months ago - Mark was kind enough to provide me with a galley of the book - is now out.  I looked over on Amazon, and it's in hardcover, paperback, and Kindle versions.  And a great read.  It follows on from his first novel with the same characters that he developed there.  And what was chilling as I'm reading it, I was thinking about our listeners the whole time, as I mentioned a couple months ago, because everything he was talking about is exactly how this stuff works.  And it gives you sort of this queasy feeling in your stomach about, wow, the world really is crazy right now, for lack of a better word.  Anyway, I enjoyed the read, and I wanted to let everybody know that it exists.



I also wanted to clarify an acronym collision.  We were talking about the Google Authenticator and its support of OAUTH.  Well, there's two "o-auths."  There's OATH, which is the Initiative for Open Authentication, and that's what I meant when I said "o-auth."  But of course I have often also spoken of OAUTH, where it's OAUTH, which is the technology that we have done a full podcast on, where you log in using your Twitter credentials, log in using Facebook.  That's the whole using-one-site-to-authenticate-another technology, which is controversially now at version 2.



There was an interesting posting a while ago from someone who had been really deep in the management of the project, who gave up and pulled up stakes and left the project out of disgust over the nature of sort of committees designing things, and he was completely unhappy with how OAUTH was evolving at that point.  So anyway, I guess O-ATH versus O-AUTH?



LEO:  Yeah, because I would pronounce it O-AUTH, both.  Yeah, that...



STEVE:  Yeah, I know.  It's like...



LEO:  It's confusing.  I actually didn't know there was a difference.



STEVE:  Yes, and so I wanted to make clear that these are very different things.  There's the Google Authenticator, which I - and the reason I wanted to bring it up, make sure people understand it, is that I think this is going to win.  I think the idea of individual accounts in a software-based time authenticator that runs in all smartphones and PCs and so forth and is open source and, I mean, this is a great way of strengthening login.  So...



LEO:  Yeah, I use the Google Authenticator.  I like it.



STEVE:  Yeah, me, too.



LEO:  You have to use it for Google, and LastPass uses it, too.



STEVE:  Right.  LastPass has, yes.



LEO:  Love it.



STEVE:  Yeah.  So OATH versus OAUTH.



LEO:  I guess it's "oath" versus "o-auth."



STEVE:  Oh, OATH.



LEO:  OATH.



STEVE:  OATH, yeah, you're right.



LEO:  But, see, what's confusing, it's the Initiative for Open Authentication.



STEVE:  Exactly.



LEO:  Which would be OAUTH, but it's not.



STEVE:  Okay.  So many of our listeners have been excited about the Raspberry Pi project.  And I think I've heard you mention...



LEO:  We've interviewed them, yeah.  We have one, yeah.



STEVE:  Yeah.  And of course instantly sold out the first batch and scrambled to make more.  It's a very inexpensive, lightweight, very capable platform for messing around with an ARM-based RISC chip.  Well, Cambridge University has a very nice-looking set of free open courseware for taking someone from the very beginning and learning low-level coding in the ARM's native RISC assembly language to build a small operating system.  Which is really neat.



And so one of the shortcuts in the tweet that I tweeted this morning is the Ras-Pi RISC coding tutorial.  Anyone who's interested go to, again, Twitter.com/sggrc.  You'll see my tweet there.  That'll take you over to the University of Cambridge page.  And it's a few levels in because I couldn't really find a way to get in there through navigating.  So I thought I would drop you in because you can easily back yourself out using their little "You Are Here" hierarchy menu up at the top of the page because there's lots of stuff.



It looks like they're standardizing on the Raspberry Pi themselves.  Every student who is enrolling in computer science gets one, and so they're assuming their students have them, and they're developing a bunch of courseware around it.  And it's all free and on the 'Net.  So I wanted to point our users to it:  bit.ly/RLsoyj.  Our listeners.





And I did just want to make a mention that - I meant to mention this last week, but I forgot, Leo, my discovery that 3D, that is, television in your home, is real.  I had no idea that home 3D was real, but I was upgrading an old Sony, a big Sony glass bottle CRT, I'm trying to remember the name of it, it was XBR, a Sony XBR receiver that I had.  And so I just - I went to Amazon and poked around, and there was an LG, it was about the size I wanted, 47".  I said, oh, okay, that'll fit.  And it said 3D.  And it's like, okay.  I just didn't believe that it was anything but a gimmick.  But I also needed to update my Blu-ray player, so I got one that was 3D capable.



And sure enough, I mean, it uses the spiral polarization so that one eye is counterclockwise polarized, and the other is clockwise polarized.  We talked about this some time ago.  This is the real 3D technology.  And so they're passive glasses, no active shutters, no batteries or anything.  And, I mean, it's pretty good.  It was like - it didn't cost anything, so I didn't pay much extra for it.  But I was just surprised that it was real.  And I was tickled by that.



I'm in the process of updating my creaky old home media approach.  About a decade ago I set up a trio of Series I TiVos, and I have updated them.  I've updated the Linux kernel in them.  I've given them larger drives.  I've sort of kept them going and alive.  But they're standard definition.  And so I figured it was time to move.  And I know that you and Paul have talked a lot about the Media Center, the Windows Media Center.  And after poking around and looking at Sage, which was the one that Mark Thompson was loving, except that Google bought them, so that's sort of no longer an option, I decided to build myself a Windows Media Center box.  So there's a...



LEO:  Oh.  You're really - welcome to the 21st Century, Steve.  And some day you'll be in this decade.



STEVE:  Yeah, there's some things where I don't want to be on the bleeding edge.  Because apparently it had a rough history.  It used to be an app that you could get for XP.  And I guess there was, what, like a Media Center edition for a while.



LEO:  Yeah.  They're offering it on Windows 8.



STEVE:  Yeah.  And it's just there in some of the versions of Windows 7, which is what I'm running.  But it's very smooth and slick.  There's a card by a company called Ceton, which is - it's called the InfiniTV, and it's a PCIE card, a 1x PCIE card that you plug a cable card into that you get from your cable company, and it'll decode four streams.  So I can record four different things at once.  And it is a DLNA server.  And it turns out that all the devices I've recently purchased, this LG flat panel is itself a DLNA client, as is the Blu-ray player.  So then I get the whole watch-stuff-in-the-other-room sort of capability.  So as you said, yes, I know, welcome to the 21st Century.  But, okay.



LEO:  I'm glad you're happy, Steve.



STEVE:  I'm having a good time.  And speaking of having a good time, Anthony Pitcher wrote, on the 1st of September, on Saturday, with a little note.  He said, "SpinRite saves me again."  He said, "Hi, Steve.  I just felt compelled to tell you that SpinRite saved me again.  I was having frequent total computer freezes, i.e., the mouse would not move, nor the NUM LOCK lights change, and a full reset and hard reboot was the only resolution.  After running CPU Burn-in tests, Memtest86 for over 24 hours, tests and drive SMART checks all reported okay.  The freezing still occurred every day.



"I decided to run SpinRite as I know it's the only sure way of knowing the disks are okay.  SpinRite did not report anything was fixed."  How many times have we heard that?  He said, "But I have not had a single freeze in over a week.  Fingers crossed, but it looks cured.  If SpinRite did fix the program, I didn't know a faulty hard drive would cause Windows to completely lock up.  Is this common?  Thank you again."



And actually, for example, one of the things that the drive is doing, might be doing a lot of, is swapping.  And it's typically code which is swapped out and swapped back.  So your memory could be fine.  But if the drive channel was flaky, I mean, and not all errors are caught, which is a problem because these are just pretty simple checksums that are being done.  It's very possible for errors to get by if they're recurring a lot.  And so you might have, between the time the code went out and came back in, you could have some code altered.  And when the CPU then attempts to execute that code, which it would do because that's why it was asking for it to be swapped back in, it could easily just lock up completely.  So, yeah, this is another instance where SpinRite fixes things silently because it's working with the drive to clean up sectors and swap them out and make sure that they're being read correctly.  So thanks, Anthony, for the report.



LEO:  I'm glad it worked.



STEVE:  Yay.  Me, too.



LEO:  Yeah, really.  Of course it worked.  All right.  I have questions.  Steve has answers.  If you are ready, sir, I shall begin with our first question, from Berlin.  Michael Walther - I wonder if his family invented the gun - paying close attention, caught a verbal typo, or a "verbo."  Dear Steve, just a - and his isn't even his native language, and he caught it.  Just a short aside:  In Security Now! 365, you mentioned the Logo programming language with its Turtle Graphics.  You then said Logo was a product of the mid-'60s.  Well, not quite so.  In the mid-'60s we used to have punch cards and hand-wired magnetic core memory, but not much more.  I seem to remember it was shortly after I bought my Apple II, back in 1980, that the Logo language appeared.  Love the show.  Cheers, Michael.



STEVE:  And of course he's right.  In the early '70s, in between, was when I was programming my PDP-8s, working in the afternoons after high school.  And so if I said '60s, I wanted to thank Michael and correct that.  Certainly it's 1980.  That's when...



LEO:  Nope, it's 1967, Steve.  You were right.



STEVE:  What?



LEO:  Seymour Papert created it in...



STEVE:  Oh, that's right, he was on the ground back East.  Yeah, yeah, yeah, at MIT, was it?



LEO:  MIT.  And it's based on LISP.  So, no, it's vintage.  It is vintage.



STEVE:  That is right.



LEO:  It was true that the first - a lot of people got exposed to it in school and so forth with Apple IIs.



STEVE:  Right, right.



LEO:  But, no, no, Logo's been around a long, long time.



STEVE:  I did remember vaguely.



LEO:  And I don't think it was originally designed to be teaching kids.  In fact, I'm looking at the article on Wikipedia.  The first implementation of Logo was called Ghost, written in LISP on an SDS 940 at Bolt, Beranek and Newman, BBN.



STEVE:  Yep, BBN.  And I was going to say, you don't want to give kids - you don't want to let them even see the LISP programming language.



LEO:  Now, well, actually, "The goal was to create a math land where kids could play with words and sentences."  So, and they did use turtles right from the beginning.  But the first turtle was a physical, as you say, on the ground, a physical turtle.



STEVE:  Right.



LEO:  That moved around.  So Michael, it may have been your first experience, but in fact they are that old.



STEVE:  I was right from what I remembered.  Cool.



LEO:  Yup.  Question No. 2, soon as I can find it.  I keep closing these.  Here we go.  From Max Cohen.  He's considering the plight of Mat Honan, our friend who's the writer for Wired.com and lost all his data, and obtaining change:  I understand how the people who "wreaked havoc" for Mat might face criminal charges, but how would one have gone about telling Amazon and/or Apple about a security flaw unless someone with access to a large website, in this case Wired, published it?  If a person found a security issue, they could contact the company.  But let's be realistic.  Would that company even do anything without pressure similar to that which Wired created?  It would seem the one reporting the problem could face prosecution for having that knowledge.  What are hackers supposed to do?  Where's the safe haven or whistleblowing protection for reporting issues?



STEVE:  And this perfectly leverages against what we were just talking about, the Oracle problems that had been reported quite some time ago, but because they weren't critical...



LEO:  It's tricky.



STEVE:  I mean, it is, exactly, it is tricky.  I mean, you can understand, on the side of the developer, their not wanting to respond to every flaw, unfortunately, because there are so many of them.  So they would like to aggregate them.  And on some level they must be holding their breath that, like, ooh, we've been privately informed...



LEO:  We know it's there.



STEVE:  ...of, like, really bad - yeah, it's like, oh, crap.



LEO:  Hope nobody finds it.



STEVE:  Yeah.  We've been privately informed of some really bad stuff, but we would really like to stick to our release schedule.  And we hope we make it to October 16th.  I mean, maybe that explains why they were able to do it in a day, is it was ready to go.  But they thought, well, we don't want to confuse people, we don't want to push it out unless we have to.  And but I think Max Cohen, who asked this question, raises a very good point because we have many situations where people report, I mean, we're talking about all the time where these disasters befall companies, they knew about the problem, but famously were not fixing it.  And unfortunately it only is when it really becomes a problem or when enough press gets behind it that, I mean, essentially that resources get allocated in order to handle it.  Until then, everybody's busy doing other things.  So it's probably just competition for resources.  And unfortunately, not everybody is Mat who writes for Wired, and it may even be difficult for someone who found a problem to be able to generate the press required to make something happen.



LEO:  Well, that, and there's some risk, too, perhaps, that you could be arrested.  I mean, I could think of people like Adrian Lamo who...



STEVE:  Yes, yes, we see that all the time, too.



LEO:  Yeah, I mean, he says I was pentesting, I was just showing The New York Times - because he broke into The New York Times and started changing data there.  Not maliciously, he says, but just to show them their flaw.  But he was prosecuted.



STEVE:  Well, and the Digital Millennium Copyright Act, the infamous DMCA, really is overbroad in the protection that it provides to copyright holders, allowing them, for example, I mean, there are university professors who are now afraid to publish their discoveries about crypto that we're using because it's DMCA protected.  And so that's hurting academia.  It's hurting the development of the crypto industry and the security for all of us.



LEO:  Let's move on.  Double-click.  Thank you.  It's funny, it's open, but it's not showing that it's open.  I don't know why.  There's something weird going on with my computer.  Ethan Stone in Berkeley, California suggests a prevention of Honan's Bad Weekend:  Hi, Steve.  So here's my current thought about how to minimize the problem.  Oh, boy.  I set up 10 to 20 free "feeder" Gmail accounts with strong passwords, different for each account, and two-factor authentication.  I set them all up to forward to an additional "aggregator" account.  I'm not sure that it should be Gmail.  Further discussion below.  I also set that one up with a separate strong password and, I think, two-factor authentication.  I then assign feeder emails at random to everyone who needs an email address.  I never post the aggregator email address anywhere and never give it as a direct email address to anyone for any reason.  I then stay logged into the aggregator, possibly running Chrome for that purpose only, since I usually use Firefox.



I know this isn't a complete protection, but it will stymie lots of Honan-style attacks, since any one feeder account is likely to be different from the one used on the account that the attacker is trying to get into, effectively putting a firewall between those two accounts. 



I'd be curious what you think.  I'd also be curious what your thoughts are about using Gmail account for the aggregator versus an account under a custom domain through my hosted Exchange provider.  As I see it, Gmail gives me two-factor authentication and some additional separation from my other accounts.  My "real" email accounts are all hosted Exchange accounts on my own domains.  Then again, it makes Google's security procedures a single point of failure.  Ethan Stone.



STEVE:  So this sort of represents - I chose this as a proxy for many people who proposed similar ideas.  I think our Matthew Stone - Stone.  Our Mat Hogan...



LEO:  Honan.



STEVE:  Honan.  Right.  It gave a lot of people pause because they realized, oh, that's what I'm doing.  That could happen to me.  And clearly, what we saw in the scenario that we covered with Mat was the problem of guessability of his email accounts and the multiuse of an email account.  And we discussed this a few more times during the remainder of these Q&A.  So I'll go into this as we encounter them because we wrap up with perhaps a superior approach that I like a lot for what it offers.  But essentially I wanted to sort of highlight this as the thinking that many people have done and the fact that it certainly begins to solve the problem.



I agree with Ethan that I don't think having an aggregator that's in Gmail is a problem.  Google offers strong authentication.  I talked a couple weeks ago about wanting to assemble sort of a formal statement.  And the news overrode my ability  to do that.  So I'll just take this moment to say that it seems to me the source of most of this is the whole issue of password recovery.  And, for example, as we have mentioned, Leo, it is crazy for me to use a multifactor authentication device to log into PayPal, and underneath the field where I am to provide the code from my hardware football there's a link that says "I don't have it with me."  Okay.  Wait a minute.  What is wrong with this picture?  Because the hacker doesn't have my football with him, either. 



LEO:  Right.



STEVE:  And so what I think we need to - the next step in this, what we need from websites, and this is not a hard problem to solve, is a checkbox which can be enabled by default, that's okay.  And what that says is, when we're creating our account, we're in our security settings, it is "Enable password recovery."  And it can be on.  Fine.  We need to be able to turn it off.  We need to be able to say, we're adults.  We care more about security than we do ease of being hacked.  I mean, the reason I want this device is I'm saying I will take responsibility for arranging to have it with me one way or the other.  And now that we have OATH for smartphone-based Google Authentication style, it's easy to have it with us.  And if you can grab, as I talked about last time, the key, and put it in your various iOS devices so that you're not stuck with it only in one, then we've created much stronger authentication.  But then, if that's the case, don't ask me the name of my first girlfriend or of my dog or my favorite teacher in high school.  Turn that stuff off.



LEO:  That's just more stuff you know.  That's not really another factor.



STEVE:  Oh, exactly.  And obviously, remember that in the story that Mat related...



LEO:  Not stuff just you know.



STEVE:  ...the hacker was asked those questions.



LEO:  I don't know.  And he said, "I don't know.  I don't know.  Here, but I have the last four digits of my credit card and my address.  Isn't that enough?"  Oh, yeah, sure, that's enough.



STEVE:  So what we need to move forward is now we have multifactor.  Now we have to turn off the bypass.  Turn off - give us the option.  Have it on by default.  That's fine.  Most people, that's probably okay.  But every time I'm logging into PayPal, and I'm being asked the six-digit code, and I'm holding my football right here, and right underneath that I see the link, "I don't have it with me," it's like, okay, why am I holding my football?  I'll just click that link.  It's crazy.



So to move forward, this is what we have to ask for.  We have to say, give me the option to take responsibility.  And whatever it is.  Or maybe have something way more onerous than something as convenient as what's my mother's maiden name, something that's not like that.  Or absolutely no excuses.  No-excuse login, whatever.  That's the only way we're going to move forward is for us to be able to take responsibility for not forgetting our credentials.  Because otherwise, almost by default, I mean, almost by definition you can say, unless we're given responsibility, we don't have responsibility.  And if we don't, then we don't have authentication because anybody can impersonate us.



LEO:  Somehow I just doubt it's going to happen because the companies will say, but, yeah, but then we're going to get calls from customers who've lost their dongle and have lost access as a result to their accounts.



STEVE:  And that would be inconvenient, yeah.



LEO:  Yeah, yeah.  Well, it could be more than inconvenient for that company.  They could get...



STEVE:  Oh, and look at No. 4.  What do you know?  The next question.



LEO:  The next, which takes us to Tim in Sydney, Australia, who proposes perhaps we don't need immediate gratification on password resets:  Hi, Steve and Leo.  I say DITTO!  At the end of the last show you pretty much concluded that the weakest point in our online security system these days is the password recovery system.  I completely agree.  I do wonder, though, why we need instant gratification when we lose a password.  Why do we need to be able to access our account straight away?  Why not simply deactivate the account for a couple of days after an "I forgot my password" reset?  After all, it is my fault, and I should be made to suffer a little in the interests of security, especially for these free services.  If this were enabled in Mat's case, he would have quickly realized something was up and contacted the service provider before any damage could be done.



More generally, I figure that there is a business opportunity for a trusted organization like the post office to offer an in-person identification service.  If, for example, you were to lose an important password or otherwise be hacked, you could call Google tech support and, after supplying the "usual" weak identifying information, put a "hold" on your account.  Then Google could get you to print out a prefilled PDF form with reference numbers and bar codes and everything.  You take that to the post office, where they could verify that you have what we here in Australia call "100 points of ID."  Through the post office computer system, Google would learn that you are the real deal, then release the account.



Sure, this would not be a free solution, with the post office charging a fee for each verification.  But the onus is on me to maintain password security; and, if I fail at that, I would be very happy to pay for my mistake.  Similarly, if I were subject to a hack attack that would otherwise succeed, I would be happy to pay, as well.  If such a feature were a option in Gmail security settings, I would enable it in an instant.  Tim.



STEVE:  It's interesting to invoke the post office because this is not the first time the post office has come up in the context of security.  You may remember, Leo, that there was some discussion for a while about the idea of some sort of personal IDs, personal certificates.  And the question was, well, how would that be managed?  How would people prove their identity, and who would issue them and so forth?  And the answer that was proposed was the post office.  At least in the U.S., and apparently in Australia, they're ubiquitous.  They're staffed with people.  If you have a package that you need to pick up that's registered, you have to provide some proof of identity in order to pick it up.  So it's sort of - that's an interesting idea.



And also the notion that, well, maybe we don't need an instant bypass of our identity.  The notion of sending out information to the registered email address and putting a hold for some length of time on the account would allow - would certainly shut down the hackers' immediate need to do all these things.  One of the things that we saw in the Mat Honan story was that, remember, there was a timeline where it was like, at 5:45 this happened, at 5:50 this happened, at 5:55 that happened, at 6:00 o'clock that happened.  And so it was like, bang bang bang bang bang, where they were in lockstep, sort of spreading through his own electronic identity, all because they were able to do this very quickly.  And so the notion of some sort of a refractory period after a password recovery is an interesting one.



LEO:  Hmm.  Eh.



STEVE:  I know, I know.



LEO:  You guys are living in a dream world.  Dream on.  Ed Reilly in Springfield, Massachusetts wonders how web-based WiFi authentication works:  Steve and Leo, love the show.  Using SpinRite since 1993 - wow - when we would use it to change the interleave - he says "interweave," but it's interleave - on the old drives to speed up them up.



STEVE:  Yup.



LEO:  I remember that.  Did SpinRite do that?  You could change the interleave from 1:1 or 4 to - what, it was originally at 4:1 to 1:1?  Make it faster?



STEVE:  It's an amazing - it's amazing.  IBM released the XT, which was the PC with a hard drive in it.  And the interleave was wrong.  They didn't know what it was supposed to be.  It was 6:1.



LEO:  6:1.



STEVE:  6:1, which meant that every - that successive logical sectors were spaced six sectors ahead, so that the...



LEO:  The idea was that you wouldn't have to wait for the drive to spin all the way around to...



STEVE:  Well, yeah.  The problem was the bus at the time was so slow that, if you read a sector, then you asked for the next one, that was already - and if the next one was physically adjacent, it was already too late to get it.  So you'd have to go a whole revolution around to get sector 2.  Then you got that, and you'd ask for No. 3, and you'd have to go all the way around again.  So they would be spaced out and interleaved among each other to give the software time to ask for the next sector.



Well, then what happened was Western Digital came along with the famous 1003 controller that was in all the clone, all the PC clone machines.  And they thought, well, we're going to have our controller be twice as fast.  We'll set the interleave to three.  And so what happened was, with an interleave of six, naturally it would take six revs to read all 17 MFM formatted sectors.  Western Digital could do it in three revs because you would get every third sector each time around.  The problem was the clones were not fast enough to do an interleave of three.  They needed four.  And so the other problem is that all this interleaving is in the low-level format.  It's the actual sector headers that contain the interleaving.  So you can't fix this in software.



So SpinRite started out to be a nondestructive re-low-level formatter.  It would low-level format the drive and determine, by building a table of performance versus interleave, what the optimal interleave setting was for your particular computer in your environment.  And then it would fix it, and it would re-low level format the drive, tuning the interleave to be optimal, and people would get a 400, in the case of Western Digital, all the clone computers, 425 percent performance improvement after running SpinRite just once on the drive.  So, and it turns out that the IBM XT, it could also run an interleave of four, so it would speed it up 50 percent, from six revs to four revs, after just running SpinRite once.  So those were the days, 1993, yup.  What were we talking about?



LEO:  Oh, I'm sorry, Steve.  I'm online with my bank.  I have a fraudulent charge.  I'll get back to you in just a second.  [On telephone]  Okay.  Thank you.  I don't, I don't.  Thanks so much.  All right.  Bye bye.  Apparently just a few minutes ago somebody charged $5 in an Arkansas Hyatt on a card that I have right here. and then, like, 50 cents on something in England.  And I asked them, I said, I definitely didn't do those.  And I said, what?  He said, well, sometimes they'll do these small charges to test...



STEVE:  Those are test charges, yup.



LEO:  Arkansas and England.  And they immediately flagged it because I don't normally buy things in England and Arkansas within a few minutes of itself.  And I do have the card right here.  It's my business card.  So they caught it.  So now I'm without a card for three days.  But better that than more charges.



STEVE:  Yup.  That happens.  I think I've mentioned, when I'm traveling home for the holidays, which I do, well, the holidays, annually, my travel agent will say, okay, Steve, do we still have the same card as last year?  Because they tend to be a little slippery.  It's like, ah, yeah.



LEO:  That's right, yeah.  No, and by the way, I don't answer the phone normally.  In fact, it normally never rings, I was kind of surprised, during the show.  But it said "Bank of America Fraud."  And I thought, oh, I'm on Security Now!, I should probably answer that call.



STEVE:  And I'm busy talking anyway, so you'll probably just be able to slip that one in.



LEO:  Snuck it in there.  Question No. 6, James Gilbert in the woods near Micanopy, Florida questions backup:  Good show.  I've been listening for about a year.  I remember watching Leo back in the ZDTV days.  You, too, Steve.  You were on with us.



STEVE:  Yeah.



LEO:  I got to thinking about the whole subject of backing up your computers.  Yes, it's terrible to lose important pictures, or financial records, or that great novel, or in my case my great music composition that I've been working on.  But if you're old enough, think about it.  When we got our 35mm film developed, we rarely had more than one print made.  No backup.  Many people tended to store negatives and prints together - no offsite backup.  I still get a paper statement from my financial institution.  Nobody makes a backup of that.  In spite of not making local or offsite backups of these important things in the pre-personal computer age, we managed to keep the important photos and important papers.  I've got a file cabinet full of music arrangements from the 1980s that were performed once then and, given the way the music business is going, the world may never hear again.  But I've still got them.



This suggests a couple of possibilities to me.  One, we've become a bit paranoid about backups; two, we don't treat our data with the same respect and concern we had with those old photos; or, three, computers have a long way to go before they can be considered as reliable as paper.  I lean toward No. 1, but I suspect all three are true to some degree or another.  Any thoughts?  James.



STEVE:  We've sort of talked about this in different contexts from time to time.  And it interests me because I'm on No. 3, computers have a long way to go before they can be considered as reliable as paper.  I'll bet that, if I were to somehow do a survey of the reason most people purchased SpinRite initially, it would be because photos were lost.



LEO:  Right.



STEVE:  I think photos uniquely are, I mean, that's certainly not the only thing that people have to recover.  But music most people don't create themselves.  They got them from CDs, or they downloaded them from online or something.  Movies they're not creating themselves typically, again.  Those came from somewhere else.  But photos are uniquely media they created themselves.  And as we moved to digital cameras and away from the 35mm film, they've been in digital format.  And I've just - I was just seeing another SpinRite story this morning when I was going through the mailbag about SpinRite recovering absolutely precious photos.



And so what's different, I think, about this digital domain, as James notes, or asks us, is that this stuff still, I mean, computers are failure prone.  That's my business is helping people recover from the fact that hard drives are always being pushed to store probably more data than they really should to offer the reliability that people would like.  I don't think I've mentioned, Leo, I don't know if you're aware, you may have seen the news go by that the warranty periods of hard drives have been snuck down also?



LEO:  They're, like, three months now; right?



STEVE:  They used to be multiple years.  And they've said we're going to kind of shorten those warranty periods.  It's like, ooh.



LEO:  I think part of that is people are buying OEM drives now.  They want the cheap, cheap, cheap drives.  Remember OEM warranties were always 90 days, and then you could buy the inbox shelf version, and they were...



STEVE:  Yes, I think they were like, like Western Digital used to be three years.  And I think it's brought it down now.



LEO:  Yeah.  Five years on the Western Digital RAID edition.  Five years.  Nobody's going to warranty a drive for five years.  That's crazy.



STEVE:  So a shoebox of photos, unless your house burns down, but they don't spontaneously cease to exist.  It really is the case, though, that some percentage of data stored on computer media, it's not only hard drives, although they're physical and the most temperamental.  People have problems with thumb drives where it just - it breaks.  Maybe a little static zap goes out and touches one of the pins.  And suddenly it's all gone.  And without backup or data recovery, you're in trouble.  So it's a different problem.  But I think people really do need to maturely understand that, if it's really precious, if it's irreplaceable, make copies because the computer may not give it back to you.



LEO:  Somebody in the chatroom, Web1038, said - and the other thing, the other side is there's zero cost in space and time to making a backup of digital, or very little cost.  So it's one thing to say I'm going to make a backup of this shoebox of photos.  That's nontrivial.



STEVE:  Or to Xerox a whole pile of papers.



LEO:  Right, right.



STEVE:  And, I mean, people do lose photos in fires all the time.  And it's a tragedy.  But it's just so much difficulty to back it up.  Whereas backing up your hard drive, if you just do it, is not a lot of difficulty.



LEO:  So I think Web1038 in the chatroom also has a point there, that it is easier.  That's one of the advantages of the digital.  You know, when we - I had - we had one set of slides in the family.  They were our family slides, and they were in my mom's attic.  And I felt like that was risky; right?



STEVE:  Yeah.



LEO:  So my sister brought them in, got them scanned, and each member of the family got a CD.  Now I feel much better about those pictures, and I uploaded them to SmugMug.  So those pictures are preserved.  There isn't just one copy.  And that made me nervous.  So in a way I think this is a new capability that we didn't have before that makes it better to save stuff.  Not that anybody's going to want to see those pictures in a few years, but - you know, you wonder.  You save all this stuff.  Who's going to look at it?  My grandson?  I don't know.  Maybe.  I think if I had pictures - wouldn't it be interesting if you had pictures of your great-great-great-grandfather?



STEVE:  Yes, yes.



LEO:  That would be of some interest.



STEVE:  Yeah, and there really is a notion of the world before the Internet not being online.



LEO:  It's not recorded.



STEVE:  Everything since is, like, going to be archived forever.  And everything before, it's like, oh, it's kind of creaky and dusty and just never going to be online.



LEO:  Yeah.  I wish we had archival footage of Abe Lincoln and George Washington.  Those things would be really, really intensely valuable now.  So it is a different era.



STEVE:  Yeah.



LEO:  Mark in Melbourne, Australia wonders about secure usernames:  Steve and Leo, we know what makes a password more or less secure - length, size of character set, randomness, unique to website/service, et cetera.  But I don't think yet I've heard you talk about what makes for a more secure username.  How do you choose your usernames, Steve?  And when the website/service uses email addresses, should you use your main email address?  This is actually germane because one of the things that made it easy for the bad guys to get Mat Honan's stuff is he always used mathonan@service.com.



STEVE:  Yes, gmail.com and @me.com.



LEO:  So they could guess his email address.  And that would turn out to be crucial in the success of the hack.



STEVE:  Yes.  And so this is a really good point that we'll leverage into our closing question also.  And this is a problem, is that email addresses are our usernames.  The common practice now is you create an account with your email address and your username, I mean, sorry, your email address as your username, and then a password.  And from the account service side, from the web service side, there's an advantage to that.  You don't need a username separate from email address.  The username is their way of contacting you for verifying it, for unfortunately bugging you with free offers and random garbage that you may or may not want.  But also importantly, think about it, they don't have to worry about username collisions because two different people don't have the same email account.



LEO:  Which is great.



STEVE:  Yes.  And so it's like, oh, sorry, this username is taken.  Well, we have that with Twitter because there we really want a separate username, our Twitter handle, separate from our email address.  But that creates a chunk of overhead.  And if you use an email account as your username, you solve the uniqueness problem of usernames because email accounts are sort of inherently unique.  So, but we'll talk a little bit more in a second about what makes a good one.  Clearly, though, as you said, Leo, you don't want it to be...



LEO:  First name, last name, yeah.



STEVE:  ...the same on all of your accounts, yeah.



LEO:  I'm going to have to really look at that because I use that everywhere.  I shouldn't have said that.  Alejandro - but nobody knows my middle name.  Alejandro in Chicago has encountered "non-routable 5.x.x.x" addresses:  Steve, this is my very first time contacting someone over the 'Net.  Wow.  Welcome, Alejandro.  But I thought it would be a great opportunity to get a little more information about IP addresses in the 5-dot range.  I remember these from Hamachi.



STEVE:  Exactly.



LEO:  I'm currently seeding Ubuntu and other open source distributions and noticed that on some of the peers I'm connected to, the IP address begins with 5.  As I recall, you once mentioned that this range is non-routable and used only in virtual mode by Hamachi, now LogMeIn.  If I can see these IP ranges, does that mean they are public or these hosts are simply disguising their real IP?  Every one of them, by the way, in Russia.  If it helps, I was able to ping them, too.  Thanks.  I'm hopeful you'll choose my question for one of your episodes.  Wow, that is a mystery.  This is worthy of Sherlock Holmes.



STEVE:  Well, and this is what we would predict with the depletion of the IPv4 address space:  5 has been allocated.



LEO:  Oh.  It's no longer unallocated.



STEVE:  No, because remember we're running out.  And 5 is - the whole 5.x.x.x or *.*.*, that's 16 million IPs very - or, wait, 16?  2^24.



LEO:  16 million.



STEVE:  Yeah, 16 million.  So there's 16 million IPs that for the longest time was just sitting around.  There was no 5 anything.  And that's why Hamachi was able to very cleverly at the time use it because there was no danger of it colliding with anything public.  Well, now...



LEO:  But it wasn't guaranteed unused.  It was just unused.



STEVE:  Absolutely not.



LEO:  It wasn't like 198.162 or...



STEVE:  Right, those have been set aside on purpose.  Like 10.*.*.*, that is still - there's 16 million IPs nobody ever gets to use because that's been deliberately set aside for local networks.  But 5 just had - no one had gotten around to allocating it.  From what Alejandro has said, that's no longer the case, which I thought was really interesting.  I haven't verified, haven't seen who got them.  But if he's seeing peers connecting - I'm assuming he's talking about, like, torrent peers.  If he's seeing torrent peers connecting, and he can ping, then, I mean, there's no way those can be disguised.  They have to be real.  So that means 5 is now public, which I thought was an interesting development.



LEO:  Yeah, it's kind of depressing.  The end of Hamachi.  Somebody asked on the radio show this week, he said he wanted to make - he had two houses at different locations, wanted to have them be on a LAN.  And I said, well, Hamachi, but I don't know what the status of that is now that LogMeIn...



STEVE:  I don't know now either.  They had to have changed something because they can't be using 5.



LEO:  Can't be using 5-dot.  Alan M. in Manchester, U.K. suggests a strategy for safely emailing passwords:  If your military/DoD guy can run portable versions of programs-



STEVE:  And you'll remember that he's referring to a Q&A we covered where somebody was - he was in a sensitive environment where he couldn't bring any devices in, but he wanted to know how to transport his password lists from place to place.



LEO:  Right, so he was able to use a portable USB key - as you would need to do for AxCrypt, then Keepass (the open source LastPass, basically) might be a good idea for him.  There is a PortableApps.com version of the software.  It fully encrypts the password database, which is easily emailable, as would be the program itself.  It's less than 5MB uncompressed.  It may not be LastPass, but it's quicker to use than Excel, which is what the guy was using.  Enter your passwords, then double-click the username or a bunch of asterisks to copy to clipboard.  Then it clears it after 12 seconds, in case you forget to clear the clipboard.  Hey, that's a good idea.



STEVE:  Isn't that nice, yeah.



LEO:  I thought this was slightly easier to use than AxCrypt due to the auto-clearing clipboard and that someone over your shoulder never actually sees the passwords because they're just stars unless you wish to open the details about that specific item, then click it to uncover it.  It also will remember URLs, notes and all that good stuff, if you want it to.  It's kind of like LastPass, but it's open source and free:  Keepass, K-e-e-p-a-s-s.



STEVE:  Right, and its little database you are able to carry around with you.  So I wanted to share that with our listeners.



LEO:  Yeah.  Keepass is great.



STEVE:  And JD's final question.



LEO:  Our last question of the day, JD in Memphis.  He has a solution for completely unique, per site and service, email accounts:  Great show, been listening for a while, LastPass, SpinRite, yada yada yada.  He's got a post on his blog, jd7.org:  In it I talk about how to make a different email address for every online service but manage it all with only one email account.  Basically I quickly talk about buying a domain, using Google Apps free with that domain, and creating a mailbox that's a catchall.  You keep the primary email account secret, don't use that anywhere, and choose a secure eMail address.  Security Now! listeners would know what such a thing should look like, basically random characters and letters and numbers.



STEVE:  Exactly.



LEO:  But then, when you sign up for Amazon or Pinterest or anything else, use something like pinterest@domain.com that will go to your primary account because you own the domain.  You use LastPass to keep up with all the usernames - per-site email addresses - and passwords.  My question is would this be strong enough to prevent the @mat problem?  Would love to hear how to strengthen this.  Currently I am using this, and that's why I suggest it in my blog post.  I have a short, three-character Twitter name - that's what they went after Mat for - and do not want to become a target, as well.  But I don't use my me.com email for anything, either.  Thanks for all you and Leo do.  JD, Memphis, Tennessee.



STEVE:  So, okay.  This is the remaining link that I shortcutted in my Twitter.com posting, so anyone who wants to read what JD wrote...



LEO:  Seems like a great idea.



STEVE:  He has, essentially, a step-by-step how-to.



LEO:  And it's free.



STEVE:  Which is very nice, yes.  Well, almost.  What he suggests is you start by getting your own domain.  So Hover or...



LEO:  That's not free.  That's 10 bucks or something, yeah.



STEVE:  Yeah, 10 bucks a year.  But you have the coolness factor of your own domain.



LEO:  You should do that.  And you control it that way.  You don't, if you're changing your email server, you don't have to tell everybody, you just control it.  That's better.



STEVE:  Exactly.  It'll never change.  And he does mention making sure that you use a service that allows you to mask your WHOIS data.  We've talked about that.



LEO:  Hover does that for free.



STEVE:  Yes.  So Hover looks like it would be a great choice.  So get a domain name.  You'll have your own domain name, which is a cool factor anyway.  And using Google Apps you can have, essentially, wildcard email, which is - this is the coolest thing about what JD has suggested is he calls it a "catchall mailbox."  But the idea is that anything coming to that domain, so it's anything@domain.com, whatever your domain is, will go into there.  So what's cool is this gives you instantly per-site, per-service email accounts.



Now, I would not - one improvement I would make, I would not use pinterest@domain.com because then we're back to guessability.  Someone might say, oh, well, then, he's probably using amazon@domain.com and twitter@domain.com and so forth.  So you want unguessable names.  But you can make them up on the fly.  You can, as he said, use LastPass as your userID, which would be your - we were just, before this, we were talking about how our email addresses have become our userIDs, or our usernames.  So you really want them to be unguessable.  You want them to be something, someone who sees one can't guess what the other one is.



And I have to say also that common names are spam bait.  For the longest time I was just steve@grc.com.  And I couldn't figure out how my name got out.  Well, it didn't.  They were just - I once looked at the traffic on my own email server, and servers were hooking up and just running through name lists.  They were just trying to send email to every first name at GRC.com that they could.  And I finally got a clue and made my email address something else from that.  So you don't want to be "Amazon" or "twitter" or something common.  You want to do something to it that will not have it just automatically and easily guessable.



But anyway, so I wanted to point people to this because it is a cool solution.  It will cost you, I think it's 10 bucks a year grand total because Google Apps is free, and you're only having to pay for the domain, but it's neat to have your own domain, too.  And then you get this wildcard concept with email.  And if you're willing to, I mean, it's not as easy as using the same email address for everything, but our email addresses are becoming our userID.  And it would really be nice if those were unique, too, in addition to our passwords being unique.



LEO:  So much to do to secure ourselves.  At least the information is out there, and it's all here at Security Now! thanks to Steve Gibson.  Steve, you're the best.  If you want to...



STEVE:  Well, I'm all we've got.



LEO:  You're all I've got.  If you want to ask a question of Steve, he does these feedback episodes every other episode in general, and you can go to GRC.com/feedback.  Don't email him, just GRC.com/feedback.  And then you can handle that without any trouble, just fill that form out.  You can also find, once you're there, SpinRite, the world's best hard drive maintenance and recovery utility, and all of Steve's freebies.  You've got a ton of them, ton of stuff.



STEVE:  We should remind our listeners of a scheduling note.



LEO:  Oh.  Yes.  We won't be here next Wednesday.  We will be here next Tuesday.  We'll flip-flop with MacBreak Weekly because of the Apple announcement on the 12th.  So if you're planning to listen to Security Now! live, it will be September 11th at 11:00 a.m. Pacific, 2:00 p.m. Eastern time.



STEVE:  And if you're not live, it'll probably be available a day early.



LEO:  Yeah,  we'll just put it out a little bit earlier.  Yeah, we make on-demand versions available after the fact at TWiT.tv/sn.  Steve has special online, on-demand versions, both 16Kb audio for very small file sizes and the transcripts, even smaller, which are done by humans so they're very good, done by Elaine, and...



STEVE:  One good human.



LEO:  One good human at GRC.com.  You'll find all of that.  I think that's it.  Yeah, see you next Tuesday, not next Wednesday.



STEVE:  Yup.



LEO:  We'll do the Apple iPhone event at 10:00 a.m. on Wednesday, next Wednesday.  We're going to move TNT up an hour, and then we'll do the iPhone event, then we'll do MacBreak Weekly.  It's going to be a crazy, jam-packed day next Wednesday.



STEVE:  Cool.



LEO:  Thank you, Steve.



STEVE:  My pleasure, Leo, always fun.



LEO:  See you next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#369	

DATE:		September 11, 2012

TITLE:		Internet Identity Update

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-369.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with an eventful week of security news, Steve and Leo step back for an overview and discussion of the slowly evolving state of the art in Internet Identity Authentication.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about, of course, the Microsoft Second Tuesday Update, the issues with GoDaddy going down daddy, and we'll talk a little bit about OAUTH, OATH, and other Internet identification protocols.  It's all coming up next on Security Now!.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson.  This is Episode 369, recorded Tuesday, September 11th, 2012:  Internet Identity Update.



It's time for Security Now!, the show that protects you and your loved ones and even the people you hate online.  When it comes to security and privacy, there's no one better than this guy, the Explainer in Chief, Steve Gibson, who plays no favorites.



STEVE GIBSON:  We're an equal opportunity protector.



LEO:  Hey, Steve.



STEVE:  That is correct.  Hello, Leo.  Great to be with you again, as always.



LEO:  Steve is the guy in charge at Gibson Research Corporation.  They do a great piece of software, we'll talk about it later, called SpinRite, world's best hard drive maintenance and recovery utility.



STEVE:  Yeah, no one's ever heard of it before, Leo.



LEO:  Nobody on this show has ever heard of SpinRite.



STEVE:  No.



LEO:  And then, of course, there's lots of freebies and so forth.  But I think at this point you may be best known for Security Now!.  I'm just guessing.  I don't know.



STEVE:  I think that's probably the case.



LEO:  369 episodes in.



STEVE:  I figured out how hard drives work, and then I thought, okay, I'm bored.  What else can I...



LEO:  That's, you know, I think that that's the blessing in this industry is they get a lot of people who are easily bored.  And so we move on to other things all the time.  Today we're going to talk about identity.



STEVE:  Yeah, that's a constant recurring topic, not surprisingly, because in my opinion it's probably the No. 1 most important aspect of security and privacy.  We come at it from the crypto tech side.  We come at it from the best practices side, and databases being compromised, and what does it mean if Apple's UDIDs all get out.  I mean, the whole issue of identity is crucial.  And one of the things that I see in the mailbag coming from our listeners is, because there's a bit of an acronym soup, and because so many acronyms are colliding with each other - we talked about OATH and OAUTH last week - I thought, okay, let's just - let's step back a bit and do sort of a "where do we stand and who's winning" because there have been competing standards.



We discussed, for example, actually we've discussed all of these in episodes past, given them their own podcast.  But it's clear now that we're seeing a winner.  And so I thought, let's talk about the terminology, differentiate these, sort of carefully put them in the context of each other, which is something we've never done, and just sort of do, okay, where are we and where does it look like we're probably going to go?



I did, however, want to make sure everyone knew that we're going to have one of our rare special appearance, guest appearances next week, someone who many of us in the computer industry know by reputation.  He's arguably famous, and that's Mark Russinovich, who was the co-founder of Sysinternals that was a go-to website for years when you wanted utilities that Microsoft wasn't producing that really drilled down.  Mark has written a bunch of books, I mean, he's a Microsoft operating system internals guy, and we were all a little worried when Microsoft acquired Sysinternals.  The good news is those tools have remained available over on Microsoft's site.  So they didn't disappear, and Mark has continued to maintain them.



The context for his appearance next week is to chat a bit about his own change of, well, not change of profession because he's still at Microsoft doing that.  But he became a novelist.  And several months ago he sent me the galleys, I guess you'd call it, of his second novel, "Trojan Horse," following up on his first novel, which was "Zero Day."  And "Trojan Horse" has become available, as I mentioned last week.  And so I thought, hey, let's get Mark on and chat with him about...



LEO:  That should be awesome.



STEVE:  ...that stuff and where the world is and what's happening.



LEO:  Yeah, that's going to be fantastic.



STEVE:  Yeah.  Okay.  So, news.  Lots of news.  Interesting things have happened this week for you and me to discuss with our listeners, Leo.  The happily minor event was - this is, because we're recording this on Tuesday, this is the second Tuesday of September.



LEO:  Oh, that's right.



STEVE:  We're normally always a day late for that.  But in this case, oh, actually we ought to take a moment to note also that it's September 11th.



LEO:  Should have said something about that.  So, yeah.  We moved the show because tomorrow's the Apple event, as we always do.  And Steve was very generous and kind about that.  And that puts the show on a Tuesday.



STEVE:  Boy, it's such a problem for me, Leo.  I just sit in this chair a day early, so...



LEO:  I think you're sitting there anyway, probably.



STEVE:  I pretty much would, Leo.



LEO:  But also...



STEVE:  I answer the phone when you call.



LEO:  Yeah, that's basically the difference.  But also, yeah, you're right.  And in fact maybe it's more appropriate to do Security Now! on September 11th.  This is a day, 11th anniversary, of course, of the terrorist attacks on the World Trade Center and the Pentagon.



STEVE:  Actually one of the main networks, one of the cable networks over, I think it was on Saturday, replayed the two hours, as it happened, of their coverage.  And, oh, it was, oh, wow, I mean, it was something.



LEO:  I think a lot of us have kind of put - this is what happens when something painful happens.  You just kind of lose the memory of it, and you don't want to be refreshed.  And boy, when you remember, it was just a horrible day, horrible.



STEVE:  Yeah, yeah.  What were we talking about?



LEO:  Oh, Mark Russinovich is going to be on.  That's good news.  It is the second Tuesday of the month.



STEVE:  Oh, second Tuesday of the month.  And it's a - I read somewhere, and this was not my observation, it was someone else's, but it seems to be holding, and I've shared it before.  Microsoft seems to alternate big months and small months.  And it's odd that it - or even - that it continues to do that.  But last month was a biggie.  It was one of those, okay, seriously, you want to update Windows now.  And this one is, eh, you could skip a month if you wanted to.  Truly, there's nothing critical.  The only two patches they have are marked "important."  They're privilege elevation vulnerabilities which affect the Microsoft Visual Studio Team Foundation Server 2010 SP1 for developers.  And then over on the server side, Microsoft Systems Management Server 2003 SP3 and Microsoft System Center Configuration Manager 2007 SP2.  So actually most people who don't have those installed, Windows will go and say, do you have anything for me, and Windows Update will say, uh, no.  So I think most people won't even know anything happened on the second Tuesday.



LEO:  Wow.  It's been a while since that's happened.



STEVE:  It really has been.  Although, if we average things out, last month, as I said, was a "press update now" month, and who knows what we've got in store for us for October.  So we'll see.  But anyway, if you wonder why your computer just cruises through the second Tuesday of the month with nothing wanting to happen, it's because the very few things that were done you probably don't even have installed on your computer, and so there's nothing to update in your case.



I did want to also mention that it seems that, when we do the podcast, and we talk about Java, a problem gets solved the next day.  And this happened again last week.  We of course were talking about Adobe, or, I'm sorry, Oracle, fixing the big Java vulnerabilities the day after the prior week's podcast.  This time Apple updated Java for their platforms on the Thursday following last week's Wednesday podcast.  So I just wanted to note, for those people who are using Java on Apple platforms, that Apple fixed their instance also, a week after Oracle, but in a timely fashion, and that I certainly think Apple's doing the right thing with the measures they've taken to protect their users from Java being enabled all the time, even if it's not necessary and not being used.



Then the most interesting, well, one of the two most interesting events of the week was the relatively massive outage at GoDaddy yesterday.



LEO:  Yeah.  Boy, did I see a lot of Twitter traffic on that.



STEVE:  Oh, my goodness, yes.  It was crazy.  And, now, there was some - it wasn't the Anonymous group, but it was a person claiming to be a member of Anonymous took credit, saying that it was an attack that he had launched.  And...



LEO:  Yeah, but you know what, after the FBI database thing of last week, I don't credit anything Anonymous says.  I mean, they are - it's in their interest to disinform.  



STEVE:  Yes.  And in fact that's our next topic.  We will come back to the UDID leakage, which you and I were skeptical and, as it turns out, rightly so.  But in the case of GoDaddy, when I first saw Twitter begin to say something's wrong, I tweeted that there was apparently an attack of currently unknown origin.  And, for example, GoDaddy.com, the DNS would not resolve.



LEO:  Oh, really, the main site.



STEVE:  Yeah.



LEO:  Wow, that's not good.



STEVE:  And the report was that millions of sites that they're in some way responsible for, apparently they run servers with MX records, Mail Exchange records, which were not resolving, so email died for people who are using GoDaddy's MX records as part of their service, and people who are using GoDaddy to provide their DNS.  I mean, GoDaddy was dark.



And we've now heard from Scott Wagner, who's the interim CEO.  He posted earlier today, I think it was.  He said,  "The service outage was not caused by external influences. It was not a 'hack' and it was not a denial of service attack.  We have determined that the service outage was due to a series of internal network events that corrupted router data tables.  Once the issues were identified, we took corrective actions to restore services for our customers and GoDaddy.com.  We have implemented measures to prevent this from occurring again.  At no time was any customer data at risk or were any of our systems compromised.  Throughout our history, we have provided 99.999" - the so-called five nines - "uptime in our DNS infrastructure.  This is the level our customers expect from us and the level we expect of ourselves.  We have let our customers down, and we know it.  We take our business and our customers' businesses very seriously.  We apologize to our customers for these events and thank them for their patience."



LEO:  So it was not hackers.



STEVE:  Well, it was not hackers.  It must be that this is true because the CEO can't make this up.  And because, if it were an attack, there would be lots of other people who knew that.  But what's curious is that this was six hours of outage, from 10:00 a.m. Pacific time to 4:00 p.m. Pacific time.  That's a long time for some router tables being messed up to, like, be causing all of GoDaddy.com and all of their ancillary services to be - now, I mean, maybe it was just DNS.  Because, I mean, of course, as we've talked about, if DNS is gone, everything else is, too, because that's the way we get to everything.  So I did not know what GoDaddy's IP was in order to, like, try to do a connection to them without DNS.  And, frankly, I wasn't that interested in pursuing it at the time.  But six hours is, ouch, that's a long time to be down.  So, yeah.



LEO:  Now, TechCrunch is saying that Tipster said that their three DNS servers, CNS1, 2, and 3 .secureserver.net were inaccessible for those six hours. 



STEVE:  Yeah.  So that could be...



LEO:  I mean, that's, if you really wanted to DDoS them, that's what you'd do; right?  You'd hit those servers.



STEVE:  That's exactly what you would do, yes.  And what I tweeted was that apparently someone tripped over a cord.



LEO:  For six hours.  You know, it took them six hours to find which plug was pulled.



STEVE:  That's the problem is they've got it.  And, okay, now, where does this plug in?



LEO:  If you tripped over a cord in our basement, that would actually be the truth.



STEVE:  There's too many sockets.  We got too many sockets and one plug.



LEO:  Not the wiring Russell our IT guy did.  The wiring we did is a little spaghetti-like.



STEVE:  Okay.  So we did hear from, well, we did - almost certain we believe that the data did not come from the, I'm sorry, the Apple - remember that we discussed it last week, 12 million leaked unique device IDs of 12 million of Apple's devices - iPads, iPods, iPhones.  Every device that Apple produces has a 40-character unique ID which Apple uses, I'm sure it's tied to iTunes and accounts and so forth.  Unfortunately, the official API up through 5 but fully endorsed up through iOS v4, offered this UDID to any application running on any of those devices.  And as developers will do, here was a unique token, ready made, courtesy of the API, which Apple was saying, here, this is a unique ID for the device.



Now, one of the things that I'm taking away from all of this is we're learning how to do this, how to do global devices that are connected.  We're not good at it yet because this was a mistake.  And we now, as a community of developers and device creators, we're learning, okay, don't do that.  I mean, make it not possible.  Maybe, for example, have the API which you query produce a unique ID which is different for every app that queries it.  And so the apps still get something unique that ties that instance to that device.  But it doesn't give a leakable ID that is across all the apps, which is what we have had and what Apple, with the release of iOS 5 they said, we realize this has not been - this is being used in a way which could compromise the privacy of owners of our devices.  We would like you to stop using it.  And then it was reported that in March they began declining new apps that wanted to use it.



So anyway, so that's the background.  And my sense is, okay, everybody should learn that the idea of a cross-application global ID that's available is not something that in the future we're going to do.  Apple's going to fix it.  I don't know where Android stands with that.  But if they've got something like that, or other phones do, it would be a good thing for everyone to just say, okay, this is not - this is too much opportunity for compromise.



So, as we know, there was the claim, and we shared it on the podcast last week.  The claim came with an awful lot of detail about exactly whose laptop and where it was and how this happened and so forth.  Apparently all nonsense.  The FBI denied that they ever had that data.  And what happened was that a couple days ago an independent researcher, David Schuetz - he tweets as @darthnull, and he has a blog at DarthNull.org.  And he's a hacker and a security guy.  And he grabbed the million and one posted sets of data, which was, you know, the million and one were posted on Pastebin, I think it was, out of all 12 million.



And he was just sort of doing some data crunching, like looking to see - kind of looking at the UDIDs.  And he ran it through some filters to see if there were any repetitions, and he noticed a surprising pattern that, I think he was first looking at, like, eight digits of the device ID, and there seemed to be a lot of dupes.  So then he looked at the entire device ID, and he found to his surprise that it was a very non-uniform distribution, and that some occurred far more often than most.



And then when he drilled down and looked at the human readable data, email addresses and names and so forth that were tied to those IDs, he saw a pattern and sort of peeled layer after layer of the onion and came up with a theory that there was a very non-uniform instance of devices associated with one company called BlueToad that has a site, BlueToad.com.  And they are a company that provides exactly what you and I have commented many times annoys us, Leo, these per-site or per-company iPad apps.  So when you go somewhere and you get this window that comes up and says, oh, would you like to get the app for this, for us, for our site?  It's like, no, I want to browse on the browser.  As you and I have said, the browser is supposed to be the app for the site.



Anyway, these guys are an instance of a company that creates that for companies for tablets and smartphones and so forth.  So essentially what happened was, because they were testing their stuff, many, many more of their device IDs appeared across their company than was normal.  And so David contacted the CEO of BlueToad and said something's funny here.  He was being very responsible, and he certainly wasn't going to point fingers before he knew for sure.  And he said, what do you think about maybe you were the source of this massive 12 million-record leak?  And it took a couple messages, then the BlueToad guy got back in touch with him and thanked him for being responsible.  And he said, "We're looking into this.  We'll get back to you."



And then he got another call from the CEO saying, okay, I can talk to you, but I need your agreement to embargo what I'm going to tell you until Monday, that is to say, yesterday, so September 10th, yesterday.  And David said, okay, well, the fact that you're asking me to keep this quiet until then tells me that I probably want to say yes.  So he said yes.  And then the CEO explained that they were sure that they had been the source of the leak.  They found the problem.  And someone with NBC News wanted to talk to David right now.  And so David was on the news and explained how this happened.



And now we know that, I mean, it's not inconceivable that the FBI might have had this as part of a, like a copy of it.  They might have already known that it had gotten loose, part of an investigation they were doing.  We don't know why this claim was being made.  But it seems that it's entirely bogus.



LEO:  Well, I mean, come on.  This group is not - they're committing illegal acts, so why you would trust anything they say one way or the other is...



STEVE:  Right, right.  And so I think we need to remember that what was an apparently completely bogus claim was made.  And, unfortunately, that hurts their credibility in the future.



LEO:  True.



STEVE:  And for a while they were seeming pretty credible.



LEO:  Right.



STEVE:  Okay.  Now, this has been on my list to talk about for a couple weeks, and I've just - it keeps getting pushed down.  Many of us who use laptops enjoy the finger swipe, the little - it's UPEK is the manufacturer of the little capacitive finger reader than laptops have.  And it's like, oh, look, biometrics, that's got to be more secure than not; right?  Well, turns out someone took a look at the UPEK software.  And this is software which comes with Acer, Amoi - which is not a laptop I have heard of, A-m-o-i...



LEO:  Yeah, they're like a Taiwanese clone, yeah.



STEVE:  Yeah.  ASUS, Clevo, Compal, Dell, Gateway, my favorite the Lenovo, Itronix, MPC, MSI, NEC, Sager, Samsung, Sony, and Toshiba.  I think there are 16 of them, if I remember.  And their software is in all of those.  The message is, if you have ever entered your password into this UPEK software, in order to give it the ability to log you in, then your password has essentially been stored in the clear in the system registry.



LEO:  So it's not how they do the fingerprints that's a problem.



STEVE:  Correct.



LEO:  It's just bad software.



STEVE:  Yes.  I mean, it's just like, okay, here again, our listeners that have been educated now...



LEO:  In the registry [laughing].



STEVE:  I know.  Apparently it's not quite in plaintext.  But it's reversed, or the case is changed or something.  It's something so trivial, I haven't bothered to drill down and figure out exactly what it was.  But what I have seen from the bit of research I did is that, if you knew a password, you could see what they were doing, and then you would know how to do it to all the other passwords on all of these 16 laptops that were using fingerprint authentication.



So it's a classic instance of what we've often talked about, is that security is a chain of links.  And it's the strength of the entire chain which yields your security.  And so by definition the weakest link in the chain limits the security of all the other - the effective security of all the other links.  So here we've got, oh, high-tech, I've seen this in the movies, fingerprint recognition.  Yet the thing stores the password virtually in the clear with no useful security at all.  And the problem is that, for example, many people rely on the encrypted file system, EFS, which is very well designed.  It is effectively unbreakable unless you use UPEK's biometric fingerprint login to access it, in which case it's pretty much in the clear.



LEO:  It just shows you how you can assume that you're being more secure, adding biometrics, and you're not.  You're being less secure.



STEVE:  Right.



LEO:  By the way, that's not two-factor if you don't enter  the password.  It's single-factor still.  It's just a different factor.  So if you use a fingerprint reader to log in, it's not more secure because it's a fingerprint reader.



STEVE:  Right.  Well, it is - correct.  Instead of adding something you have, meaning your pinky, and sort of adding that to something you know, it has exchanged something you have for something you know.



LEO:  Right.  It's still single-factor.



STEVE:  So you don't need to know anything anymore.



LEO:  Yeah, just single-factor.  And there's been all sorts of issues that I've heard of with fingerprints anyway.



STEVE:  Okay.  Now, Leo, you and I need to - we may disagree on this.  Which is fine because it's arguably controversial.  The cofounder of Apache...



LEO:  Oh, I know what you're going to talk about.  I know where you're going.



STEVE:  ...has decided that the most recent committed build and henceforth of the very popular Apache web server will ignore the Do Not Track, the DNT header, if it is part of a query coming from Internet Explorer v10.



LEO:  And we knew this would happen, by the way.  We talked about this.



STEVE:  Well, we - okay.  I didn't know this was going to happen.



LEO:  Oh, no, no, I think we talked about it.  In fact - maybe it wasn't on this show.  I thought it was on this show because, well, go ahead.  I'll let you describe it and...



STEVE:  Well, so just to rewind for our listeners, Microsoft made the decision that with IE10 they're going to push Do Not Track maybe a little further than, well, certainly further than anyone else has so far.  And that is, part of the installation of it will have it defaulting on.  And in the express install there is an opportunity for you to say no, but...



LEO:  No, it's the other way around.  So the way IE10 is going to work - so there's three states for Do Not Track.



STEVE:  Correct.



LEO:  Which is unset, which is no preference expressed, on, or off.  There are three things.  If you go through the normal configuration of IE, it will not turn it on without telling you.  It's only if you use the express configuration.  So the express configuration of IE10, which most people pick - remember when you install IE10 it says, would you like to do a custom, or do you want to just accept our express settings?  If you accept the express settings, then it turns Do Not Track on.



STEVE:  Okay.  And nowhere do you see that it's doing that.



LEO:  Right.  That's the express settings.  Now, if you go through the normal setting process you will be asked.



STEVE:  Right.  So the...



LEO:  And most people use express, including me.



STEVE:  This guy, the cofounder of Apache, is also on the committee that has worked on standardizing Do Not Track.



LEO:  That's the W3C.



STEVE:  Yes.  So he's also got - but, I mean, specifically the DNT subgroup or whatever.  So he's been involved in this and is adamant about the idea that there ought to be these three states:  no specification has been made, either the user has said they do want tracking, or they don't.  And anyway, so what Apache has taken it on themselves to do, because now they're claiming, and this we have talked about before, that IE10 is not standards-compliant - not that Internet Explorer really ever has been for other things - IE10 is not standards-compliant in complying with the letter of how the Do Not Track should be implemented, meaning that it needs to be, by definition, a clear user choice.  He's taking the position that, because Microsoft sets it for users who choose the express install, they have not asserted a choice.  Therefore IE10 does not abide by the standard.



And what is the controversial aspect of this is that the web server itself, not the apps running on the server, but the server will remove that on the way in so that it is not available to applications.  And so it's a little - that, I mean, I guess that's the problem I have is that what if applications assume that Do Not Track is working, and that they'll at least be given the headers that the client has provided.  Apache is proactively filtering the request headers, removing it, I mean, and altering them from what the client has sent.  So I don't know if this is a little power struggle between Apache and Microsoft, if they hope to force IE to change their behavior...



LEO:  I think it's more nuanced.  I would interpret his decision in a more nuanced way.  In fact, he says in the patch, the quote is - the patch's title:  "Apache does not tolerate deliberate abuse of open standards."  So I'm not sure he's necessarily expressing an opinion on DNT.  But he's expressing an opinion that there is an open standard that was set in a normal open standard process.



STEVE:  Process.



LEO:  And that Internet Explorer 10 has chosen to ignore an open standard, and so we're going to ignore the setting.  And it may be more nuanced.  It may really be about open standards and saying Microsoft's got to - there's a standard.  Now, you could dispute the standard, and there was an opportunity to do so at the W3C level.  But having set the standard, Microsoft either has to adhere to it, or we have to ignore their choice.  Now, he may also be saying something else.  But I think that that title tells you that what he's saying is you've got to - the standard's set, so you need to adhere to it.  It has the net effect, though, of somebody, whoever uses IE, even if they decide to actively turn off tracking, it's going to be ignored.



STEVE:  Yeah.



LEO:  Which I think is not the effect that's - it's very much like dimpled chads.



STEVE:  [Laughing]



LEO:  It's attempting to understand the intent of the user; right?



STEVE:  Yes.  It's too bad that there isn't an intermediate between zero and one for the DNT value, which means the browser turned this on on behalf of the user.  I mean, like, too bad there's...



LEO:  Yeah, well, the browser should be configured so that you have to make the choice one way or the other.  Explicitly.  The problem, I think the problem they have is the browser doesn't tell you explicitly that you're making that choice.



STEVE:  Yeah.  And of course the reality is probably users would choose it if they knew it was available.  But users don't choose things.



LEO:  Right.



STEVE:  They just, as I...



LEO:  It might, believe it or not, have underlying - he might be on the side of the angels, and I'll tell you why.  Because if advertisers decide that the Do Not Track is being set without the choice of the user, but just by default...



STEVE:  Then they're justified in ignoring it, too.



LEO:  Right.  So I think he may - I'm giving him a very positive spin on this.  But I'm just saying, you could say - he said, look, at the World Wide Web Consortium we discussed this.  And they did, I'm sure, endlessly, because they changed their mind once.  And we've decided that, if this is going to have any merit, advertisers cannot in any way say, no, no, the user didn't have a choice in the matter.  It has to be - we have to be able to say to advertisers, no, look, a clear choice has been expressed.  Our standard says so.  So you must honor it.  And I think that he may be defending that.  He may be protecting it.  But certainly he's protecting open standards.



STEVE:  I can certainly see that.



LEO:  In other words, it's complicated.  And whether - and we're taking out our disagreement over tracking cookies completely from this.  That's not it at all.



STEVE:  Yeah, it's not about that.  And what this really says is don't use IE10.



LEO:  Well, if you want to use Do Not Track, don't use IE10.



STEVE:  Yeah, until Microsoft - and which is where him putting pressure on Microsoft comes in.  So, I mean, and Microsoft has to have thought about this a lot.  They keep touching this third rail with advertisers every time.  8 was going to have it, then it got pulled back.  9 was going to have it, then it got pulled back.  Actually 7 was going to have it and it got pulled back.  But now...



LEO:  And really what Microsoft's doing is just a PR move to users.  Look, we protect you.  But the effect of what they're doing, by ignoring the open standard, is they may in fact be doing the reverse.  And, by the way, Apple does this.  And this was the whole thing that Google went around on Safari.  Apple did turn on Do Not Track by default.  So it looks good for a company to say, look, we're...



STEVE:  No, it was - I think Apple was blocking third-party cookies by default.



LEO:  That's it.  Same idea, though; right?



STEVE:  Yes, right.



LEO:  That doesn't have a standard one way or the other.  DNT is something new.  In response to third-party cookies.  It's really - and I'll dial out on the, I mean, I would love to see - you know what I'd like to see?  Every browser - and, by the way, Chrome doesn't have a setting at all because Google is never going to turn on Do Not Track.  But what I would like is everybody - Chrome, IE10, everybody - in the setup process to have a little description of what tracking cookies are, what they're used for, and then say, "And you must choose now."  That may violate the standard, too, because the standard allows for three settings:  unset, on, or off.



STEVE:  I really - I think that what I saw Rev. 3 do, I can see that that's going to happen.



LEO:  What's that?



STEVE:  Where Rev3 notices that you've got this blocked, and they say, you know, we're happy to give you all this content, but we need you to take a look at all of the content.  In this case it was advertising blocking.  And they said, you know, just turn this on.  So it's like, okay.



LEO:  Yeah.  Or I think we may win this one, and advertising companies may just say, fine, we don't need to track you.  Because there's not a lot of proof that tracking works.



STEVE:  That's absolutely right.



LEO:  Because - and at least, as used as an ad preference, ad customization preference, ad customization doesn't seem to work at all.



STEVE:  Yeah, that's so perverse.  That's what's so perverse about this is they build all these huge databases that are oftentimes de-anonymized, but it's not clear that offering per-user ads, I mean, for those who even notice it, it creeps them out.



LEO:  Right.



STEVE:  I mean, it freaks out users.  It's like, wait a minute.  I'm over on this site.  How do they know I was just over there looking at that?  I don't want anyone to know that.



LEO:  We're really in the early days of recommendation engines.  Just look at your ads on Facebook, which are absolutely, by the way, every ad on Facebook, you are tracked on Facebook.  Whatever the setting that you want to set is, you're on a single site, so there's not third-party cookies.  And the ads, personalized ads on Facebook are worthless.  They're stupid.  I mean, just look at the ads you're being fed on Facebook.  And that's the best possible case of tracking cookies.



STEVE:  I was just going to say, look how much information they have and the result of that, yeah.



LEO:  So I think advertisers might just say this is the third rail.  I mean...



STEVE:  Nice while it lasted, but...



LEO:  I'm looking here, I've got an ad for T-Mobile, Chevron, giving away money to public schools, San Francisco '49ers store, make money with your photos, sign an anniversary card for Barack Obama, and cut my electric bills by 75 percent, and State Farm Insurance.  I don't think that that's particularly tied to anything.  But these are all customized heavily.  It even says my friends Brett and Jessie and Robert like T-Mobile.  That, if I were Jessie, Robert, and Brett, I'd be pissed.



STEVE:  Yeah, that's leakage.



LEO:  That's real leakage.



STEVE:  Yeah.



LEO:  And that's, when you do a "Like" on Facebook, then your name may be used with your friends to say, hey, Leo likes this.  Why don't you?  That's annoying.



STEVE:  We ought to just change that from "Like" to "Leak Me."



LEO:  Leak Me.  Leak.  Leak.  Anyway, I'm glad you brought that up because I thought that was a - we tried to talk about it on TWiT, and I think you did a better job.



STEVE:  Well, and you were all up to speed for it, too, so that was really good.



LEO:  Yeah, I am up to speed on this one, boy.  [Whistling]



STEVE:  Okay.  So Kindle's new Paperwhite screen.  I'm excited.



LEO:  Yeah.  I want to see it.



STEVE:  It looks great.  And for some reason I feel like I have, and of course I haven't because I don't have a time machine.  Or, if I did, I couldn't tell you.  But the way the screen is illuminated is wonderful.  And I don't know why I know that.  But that's what - maybe I was dreaming it.



LEO:  You have faith.  You believe.



STEVE:  Sometimes I have vivid dreams.



LEO:  You saw the ad.



STEVE:  Maybe I just dreamt it.  Okay.  But here's my gripe.  You got that link in the show notes, Leo, the g-ecx.images-amazon.com link?



LEO:  Yes.



STEVE:  They posted what I think is a very deceptive graph.  And that just bugs me because it's like, okay, this is not necessary.  They show tiny bars for laptop, for the battery life of laptops and smartphones and obviously competing pads or readers and things, showing, like, nine to ten hours.



LEO:  Eight hours, nine hours, ten hours, yeah, yeah.



STEVE:  And then this monster bar of theirs that, like, you have to scroll your browser in order to see where it ends, that says eight weeks.  And then underneath in fine print it says "Based on 30 minutes per day of Kindle use."  Oh, at a setting of 10.  Well, now, the brightness is 24 levels.



LEO:  Oh, so it's half brightness.  Ooh.



STEVE:  Less than half.  It's only 42 percent of max brightness.  And eight weeks at 30 minutes per [day] is 28 hours.  Which is only twice as many hours as the times they show for the competing devices.



LEO:  They're mixing apples and oranges.



STEVE:  The bar goes off to New Jersey.



LEO:  Yeah.



STEVE:  So, okay, Jeff, clean up your act here.  This is not necessary.



LEO:  Eight weeks sounds good, though, doesn't it.  [Laughter]  If you only used your tablet 30 minutes a day, it would last how many days?  It would last 20 days; right?  10 hours?  So that's what they should really be showing.  20 days, eight weeks.



STEVE:  Yeah.  If you use your tablet for the same amount, then it'd be this long compared to that long.



LEO:  They're mixing apples and oranges.



STEVE:  I did get a nice note - because I tweeted this.  I was just - this just really infuriated me because, I mean, I'm - lord knows I am a Kindle fanboy.  There's no doubt about it.  I've got every model and make that there is, and I love the Kindle, and I've already got two of these on or der, one for Jen and one for myself.  Anyway, Chad, tweeting as @laurion in Framingham, Massachusetts, he said, "Fortunately, the increased contrast and resolution should mean needing the light less than a typical Kindle.  It's not always on."  And that's a great point is that - although it's got this wonderful ghost-y glow look to it.  And again, I don't know why I know that.



LEO:  Let's see.  It's only 25 percent more contrast.  So I don't think it...



STEVE:  I'm sure if you make it look white on the...



LEO:  Paperwhite.



STEVE:  I hope they didn't mess that up on the web page, either.  



LEO:  It's grey-green.



STEVE:  Yeah, although much higher - I'm excited about more pixels because I'm always - I'm Mr. Pixel.  I like...



LEO:  And it's, I mean, you know, look, there's going to be incremental improvement in this stuff always.  The thing they should probably point out is the reason you're only using it 30 minutes a day is because it doesn't do as much as the tablet, the laptop, and the other stuff.  All you can do is read.



STEVE:  Okay.  That's true.



LEO:  Yeah.  You'll use it less, so it will last longer.



STEVE:  Okay.  Actually, you could just, like, glue it to the back of your tablet so you just flip the thing over, and then you've got a Kindle.



LEO:  That's what Kenny did.



STEVE:  Okay.  So, finally, I just wanted - I did want to bring - I tweeted this.  Anyone who's curious, with a touch device - a tablet, an Android, an iPhone - something very cool.  You and I gripe, our listeners have heard me say how annoying it is when I go to a website, and the site wants you to download their own app.  I know they're trying to get mindshare, and you have now their icon on your icon array and home screen or whatever.  But it's just, it's like, okay, no, I don't want your app.  I want to - give me a good experience with my web browser.



And so in researching the story about the discovery of how the UDIDs really did leak out, that is, where David did this, I went to IntrepidUSGroup.com/insight.  So that's IntrepidUSGroup.com/insight; or Twitter.com/SGgrc, look at my feed because the link is there.  And what I was presented with was what looked like an iPad app, where you can move between articles, you can see summaries, I mean, a complete sort of fluid touch custom app.  And it took me a minute to realize I hadn't been taken to an app.  There were still browser tabs at the top of the iPad screen.  I'm like, wow.  This is JavaScript.  They've written an app in JavaScript.



Well, it turns out it's from a company called OnSwipe.com.  And if you go to their site with a pad, then it's also a nice experience.  And it's free.  So I just wanted to give a shout-out to these guys.  This is beautiful touch tablet technology that allows companies to pour their content into this framework which is free and not require people to download an app, which there's certainly some resistance to doing.  I'm not the only person who feels this way.  Certainly you do, Leo.  And again, it's like, that makes you do something else.  Here I got a very nice browsing experience without having to download another app.  So I thought it was just very, very cool.



LEO:  HTML5, baby.



STEVE:  I know.



LEO:  You know.



STEVE:  And I got one nice note also from James Lewis, who said, "SpinRite got me a free TiVo."  And he said, "I was skeptical SpinRite even worked.  I figured it was worth giving a shot for 89 bucks.  I've been using my Series 1 TiVo for years.  My friend had one of those fancy Humax Series 2 with DVD burners."



LEO:  Those were good, yeah.



STEVE:  "One day" - yes, yes.  He said, "One day it wouldn't reboot for him, so he gave it to me for free.  SpinRite spent a couple of hours on the drive, and when it was done I had a Series 2 TiVo.  Thank you."  So, yeah, SpinRite fixes everything.



LEO:  We've heard other people talk about it on the TiVo drives.



STEVE:  Yeah, yeah.



LEO:  Because it doesn't care about file system.  It doesn't know or care.



STEVE:  No.



LEO:  I think TiVo uses Linux ext2 filesystem.  But it doesn't matter.



STEVE:  It does.  And, in fact, it's saved my own Series 1s many times.  And they use a PowerPC chip that is a big endian rather than a little endian chip.



LEO:  That's right.



STEVE:  Yup.  So the bytes are even in the wrong order, and SpinRite says, eh, I don't care what's there.



LEO:  It just fixes it.  Before we get to our topic, which is about online identity and authentication - and I'm glad you're going to do this, which is kind of everything you need to know about OAUTH, OATH, as we talked about last week.  Steve Gibson here, a little bit of a different time because we flip-flopped, as we often do.  Apple does its events on Wednesday these days, which means Steve gets to move to Tuesday, MacBreak Weekly to Wednesday.  We will be doing live coverage of the Apple iPhone 5 event starting 10:00 a.m. Pacific, 1:00 p.m. Eastern tomorrow, 1700 UTC.  And we've decided, and this could either be great or it could go very, very wrong, that since Apple doesn't provide a stream for us, we're going to reenact the keynote with puppets.



STEVE:  You're not.



LEO:  Yeah.



STEVE:  No.



LEO:  Yeah.  You think I'm joking.  No, I commissioned Brian Hogg, puppet master, who did my Leo puppet, which you see behind me, he's doing a - he did Walt Mosspuppet, which was quite a character for a long time.  He's doing a Tim Cook puppet for us.  We didn't have time to do everybody that could conceivably be onstage because there's a lot of people.  Could be Tim Cook, Phil Schiller, Scott Forstall.  So Tim will be everybody.  And he will be reading the live blog back.  Not the whole time, but when there's something - and we have the images from the live blogs.  And so we have a little stage.  We're going to put him on a little stage.  It'll be great.  Puppet show tomorrow.



STEVE:  Why does Apple not just make a stream available?



LEO:  We've been discussing that.  We talked about it on TWiT.



STEVE:  I know.



LEO:  One network engineer in our audience said, you know, the cost of making something super reliable that would be watched by that many people simultaneously is probably prohibitive.



STEVE:  It's too big.



LEO:  It's too big.



STEVE:  Yeah.



LEO:  And there are other things.  Apparently they do have engineers sitting there doing secret sauce during it because, I was told by somebody in the know, because they turn around the keynote almost minutes after it ends and put it online.



STEVE:  Have the video up, right.



LEO:  So they're doing some stuff.  And maybe someday it'll be ready for primetime.  They've done in the past, like unaccountably, like a year ago, they did one live, and then never again.  I would think they'd want to do it live.  There's such interest.



STEVE:  God, yes.



LEO:  But anyway, puppets might work.



STEVE:  If not, Leo, if they see your puppet performance...



LEO:  Oh, I gave up on Apple ever...



STEVE:  That may convince them to go back to a live stream.



LEO:  To go live.



STEVE:  It's like, either Leo's going to do the puppet, or we're going to stream.



LEO:  It is our - you know, it's funny, we do a lot of live events.  We do a lot of stuff.  Obviously we do 40 hours of programming a week.  There's nothing like an Apple event for driving traffic.  There really is interest.  And I was talking to Ryan Block of Gdgt.com.  They do a live blog of it, and he said, oh, yeah, easily our biggest.  He said AOL burned up a server when they were doing it.



STEVE:  Oh, that's too cool.



LEO:  They actually burned one up.  It broke.



STEVE:  A meltdown.



LEO:  Which I guess you can have - a switch, if you have too much traffic going through it, can melt.



STEVE:  Okay.  Maybe it's made out of chocolate.



LEO:  It was a chocolate switch.



STEVE:  Oh, goodness.



LEO:  Anyway.



STEVE:  Okay, now, and why - okay.  So you're calling it the iPhone 5 event.  I mean, is it just a bigger screen?



LEO:  Well, we don't know.  But...



STEVE:  How can it be any better?



LEO:  So the invitation has a "12" for the day; right?  And then the shadow the 12 casts is "5."  Now, it's not the fifth iPhone.  There have already been five.  The 4S is the fifth iPhone.  So it's really the sixth iPhone.  But we think they must, maybe, well, some - and then a number of people tweeted me, well, what if instead of being about the iPhone 5, they're saying there are going to be five new products we're going to announce?  I don't think so.  I think they're going to call it the iPhone 5.  And it will be 1136x640, one extra row of icons.  There's quite a bit of debate over where it will have LTE or...



STEVE:  Less scrolling of your home screen.



LEO:  Right, yeah, more on your home screen.  And it will be 16:9, so it'll look better for movies and games.



STEVE:  Oh, cool.



LEO:  Yeah.  I don't, you know, I think that it's gotten pretty competitive now.  I don't think Apple's got a free pass anymore.  Maybe they do.



STEVE:  And we do think that there's going to then be, like in October, a mid-size pad?



LEO:  "We" being John Gruber and John Paczkowski and Jim Dalrymple, you know, the pundits who seem to have a handle on all this, yes, they believe a mini iPad.  Now, that will be interesting, especially after the Kindle Fire HD.  I bet you ordered one of those, too.



STEVE:  I didn't.



LEO:  You didn't.



STEVE:  No.  I'm going to wait and see.



LEO:  You're not interested.



STEVE:  The Kindle Fire burned me, if you'll pardon my choice of words, so badly, it's just so horrible, that I thought, uh, you lost me on this one, Amazon.



LEO:  Interesting.



STEVE:  You sold me a piece of crap, and I'm not buying a second one.



LEO:  Now, the Nexus 7, same thing, $200, great.



STEVE:  Oh, my god, I love it.  And I have said to everybody, $199, this is a completely workable, worthwhile pad.



LEO:  Right.  Well, I had to order the Fires.  Not that I, you know, I might kind of agree with you.  My Kindle Fire, the original's just sitting there, not doing anything.  But I looked at it the other day, it's on my dresser, and it hasn't charged in months.  And I thought, well, I'll bring it in for the event.  And I guess I'll Gazelle it after that.  But I am going to get the 7", and we'll get that in two days, I think, the 14th, three days.



STEVE:  Oh, no kidding.  So it is available soon.



LEO:  Yeah.  That one is the first thing to come out.  So we'll have that, I'll have that by next Security Now!.  I'll let you know.



STEVE:  I ordered a pair of the Paperwhites as soon as I saw that it was up, and I have an arrival date of, like, mid-October, I think October 17th.



LEO:  Yeah, they're not shipping those right away, yeah.



STEVE:  But I hope they have a lovely glow.



LEO:  They will glow.  I'd be very - I'm really - so, see, I didn't order a Paperwhite.  So I'll let you tell me how they are.



STEVE:  Oh, perfect.



LEO:  And I'll tell you how the HD Fire is.



STEVE:  Deal.



LEO:  We have to work these things out ahead of time.  Our show today...



STEVE:  You're going to have it for next week's podcast; right?



LEO:  I will.



STEVE:  Okay.



LEO:  If all goes well.  Will I have an iPhone 5 by then?  They're 12th, 19th, no, it comes out on Friday, a week from Friday.



STEVE:  There is a huge staffing effort, isn't there?



LEO:  Yeah, but it won't be till two days after we do the show.  So Friday the 21st is when it comes out.  Sorry.  Meanwhile, you know, I buy everything, and this is the first time I'm kind of thinking, I wish I didn't have to buy everything.  I just want to stay with one phone for a few months, please, I beg of you.



STEVE:  And it's easy to fall behind when this much is happening. 



LEO:  I have never seen a more fecund fall.  I'm going to call this the "fecund fall."  Fertile with gadgets.  They're blossoming everywhere.  And there's Nokia phones, there's Motorola phones, there's tablets, there's Windows 8 stuff is coming out any minute now.  Oh, my gosh.  And I've got to buy it all.



STEVE:  Bezos is claiming that one of their things, I guess it's the Kindle HD, is better than the iPad.



LEO:  Well, it is in many respects.  Its DPI is lower, but very close.  It's got two speakers with Dolby sound, which the iPad, the new iPad has terrible sound.  It's got one little tinny speaker.  I guess they figure - and in fact most games now say, "Please wear headphones for a better experience."  I don't know in what other respects it's better.  It might be faster.  We'll see.  I don't think it is.  The software is dumbed down, it's dumbed-down Android.  It's not a content creation device, it's a content consumption device.  It's a door to the store.  Exit through the gift shop.  All right, Steve, let's talk about authentication.  I guess...



STEVE:  Okay.  Yeah.  Obviously it's crucial.



LEO:  Yeah.



STEVE:  We have looped around it, coming at it from all different directions, because there are so many different facets to the issue.  One of the things that I was thinking about after we were talking last week was remember someone, we did a Q&A, and someone was suggesting maybe the role of the post office as an authenticator of identity.  And that reminded me that there's two very different classes of identity, which is worth noting because it's important.  And that is, there's the notion of real-world identity, that is, who you actually are in the physical world, which is entirely separate or is at least entirely separable from your online identity, or you might call it a "virtual" identity.  And there you still want to authenticate, but you want to authenticate, at least optionally, anonymously.



And then it's like, okay, well, wait a minute.  Why would you care about anonymous authentication?  And the reason is reputation.  And "reputation" is just a wonderful word in this online context, the notion of you're investing in an online virtual personality.  And what you are doing over time is acquiring, earning, building a reputation among the people you're sharing this community with.  And so for that reason the strength of your reputation is directly tied to the community's understanding that it's unlikely you could be impersonated.



And so once again, even though in that entire universe we're disconnected from what's your street address, what's your Social Security number, what identity would the post office see if you walked in and showed them your driver's license, it's not about that.  It's about the integrity of the system's, the Internet's ability to provide authentication of a virtual person.  So it's just this is who I say I am, and nobody else is able to say that they are me, and over time that builds value.  So that was something we hadn't really ever explicitly discussed, so I wanted to do that.



But something happened last week that surprised me.  And I thought, oh, this is further along than I thought.  I brought up IMDB, Internet Movie Database, which I poke around from time to time.  And this was the app on my iPad.  Same experience under Firefox, for example, in Windows.  And it prompted me to log in with IMDB, Amazon, Facebook, or Google.  And I thought, Amazon?  What?  And sure enough, if I click on Amazon, I jump over to Amazon, then LastPass sees that I'm being prompted to log into Amazon, it does that for me, and I'm back to IMDB, having logged - and it knows my name.  It says, "Hi there, Steve Gibson."  It's like, oh, okay.  I didn't know we were here yet.



We've talked about, we've seen and discussed the "Log in using Facebook," "Log in using Twitter."  We know that Google is active in this area; and, of course, the Google Authenticator we've talked about.  I was unaware that Amazon was offering that service, and I'm delighted because I'm an active Amazon user.  I'm not an active Facebook user.  Actually I use Amazon more than Facebook, Google, or IMDB or anything else.  So that was cool.  And of course Amazon is now also offering multifactor authentication.  So if I were using that, then I would have been prompted for, if I had set it up, for another factor of authentication.



So what's happening is there are groups working to standardize these protocols.  And it comes down to three acronyms that are essentially - two of those are protocols, another one is sort of crypto technology.  And that's OATH, which you helped me produce, or pronounce, because I was saying, wait a minute, O-A-T-H and O-A-U-T-H.  And of course OATH, obviously, is how you pronounce OATH.  And actually it's kind of a good acronym for that.



What OATH is, is just - it's not a communications protocol or an authentication Internet protocol.  It's just the crypto standards that, for example, Google Authenticator is based on.  And what's significant is that, for example, the VeriSign VIP service that we have talked about extensively in the past, here's my little PayPal football that I got, I think was it free or $5 or something?  I think it was very inexpensive from PayPal, which I'm still using.  And one of our listeners famously realized that the upper digit of the six-digit code is incrementing linearly, not part of the pseudorandom sequence driven by the secret key.



Well, Google Authenticator doesn't work that way.  Neither does the Windows Phone 7 Authenticator, which by the way is, I have verified since, Google Authenticator compatible.  So how is it possible that the PayPal football, which is tied into the VeriSign VIP system, uses a different protocol?  Well, and that brings us to another critical or sort of key aspect to this which is the VIP system, VeriSign's, is closed.  It is not an open system.  You get credit cards from them that are time or event based - in this case they are event based, so they don't have a clock running all the time or the battery wouldn't last long - using the little eInk printing that we talked about a long time ago; or you get the football from them.



But they're not publishing, and their technology is not open.  So they know what the key is associated with my token, and they can have any algorithm they want to.  We now know that, since the first digit is linearly incrementing, it is a weaker authentication than if it were six fully pseudorandom digits.  And we understand that they're doing it because it's time based, and having that most significant digit changing uniformly allows them to better lock onto and deal with time drift.



But the central factor here is the notion of a closed versus an open system.  One of the reasons I am so bullish about Google and their effort to push this open, this OATH open standard is that, when I inquired of someone who was using the VeriSign VIP system, I was a little taken aback by how expensive it is.  And while I know that they've got lots of customers and their enterprise class and so forth, to me this feels like a problem that ought to have a free solution.  Which is what Google is helping to push with the success of the Authenticator, which is based on these open standards, so it's not a closed system.  But there's a downfall.



LEO:  Can I ask you one question about the Authenticator?



STEVE:  Yeah.



LEO:  Because a listener to the radio show called this week.  He said, "I'm nervous about the Authenticator.  Can it be reverse engineered?"  And it would be the same question about the VeriSign dongle.



STEVE:  Okay.  So the Authenticator, the OATH protocol, I'm sorry, well, the OATH, I don't want to use the word "protocol" because...



LEO:  It's not a protocol.



STEVE:  ...OAUTH and OpenID are protocols. 



LEO:  Right.



STEVE:  The OATH standard is a hash-based standard where it takes either an event counter or a time-of-day clock.  And in the case of a time-of-day clock, essentially it creates an event every 30 seconds tied to Internet time.  One of the things I loved as I was reading through the standard was they make a point of saying, "And this must be 64-bit Internet time."



LEO:  High resolution.



STEVE:  Well, the reason is the Internet time that has been established, the so-called UNIX time, same sort of thing, it's 32 bits, and it wraps around in 2038.



LEO:  Right.



STEVE:  So it's like, whoops, we go back to the beginning of time.



LEO:  This won't wrap around till the beginning of the actual end of time.



STEVE:  Correct.



LEO:  64 bits, [indiscernible].  So it's taking, okay, so it's taking the Internet time at 64 bits.  Is it hashing it with something?



STEVE:  Yes.  It uses a keyed hash.  So, and I'm thinking that we ought to talk about that in detail.  I don't want to get into the crypto today.



LEO:  No.  I speculated, though, that it was a one-way hash.



STEVE:  Yes.  It is a secure keyed hash.



LEO:  I liken it to a meat grinder where you can put a steak in and get hamburger out, but you can't put hamburger in and get a steak out.  It's one way.



STEVE:  And the other thing is the hash is large.  It's like SHA-1 or SHA-256.  Now, one of my annoyances with OATH, this standard, is it doesn't specify this tightly enough.  That is, it says, oh, well, you could use SHA-1.  You could use SHA-256.  You could do this; you could do that.  It's like, no, no, no, no.  Please don't, don't give people the choice because they will take different choices, and we will have nonstandard implementations.



So it's another reason why I'm glad some entity as large as Google has said here's ours.  And here it is at code.google.com.  It's open.  Please, take it and use it.  And so it's available for free download for our devices.  It is being copied, which is fine, but it's being compatibly copied.  And so it behooves people to do this, to implement exactly the same set of choices that Google chose out of the OATH standard.  So while the standard is not nearly as rigid as I would like, I mean, for example, back in the early days of TCP there was a lot of things that were not closely enough specified, and people implemented incompatible TCP stacks.  So you had an interoperability problem in the beginning.  And in fact TCP is complicated enough that a lot of the way it works has sort of gone into sort of mythology, almost.  It's like, oh, just take one that works.  Don't go reinvent that because, even if you follow the standard, you may run across some edge cases where you'll have problems.



So knowledge about actual implementation has now been embedded in the code, and it's more a spec than the standard that is written.  And so we have the same sort of effect with the Google Authenticator, where it's like, this is Google's implementation.  Copy it.  Do exactly this, and you will get something right.  So but the point is the width of the hash is much larger than the digits we see.  So we don't even see all of the hash output.  Which is good for security.  If we saw all of it, it'd be an insanely long thing that no one could type in in 30 seconds before it changed, and that would be a problem.



But also, if we only see part of it, no cryptographer, even if they wanted to do, like, brute-force one-way functions, because we know that hashes can be brute-forced with rainbow tables and by, like, putting every possible value into the front and see what comes - or into your meat grinder, Leo, and see what comes out.  And so you just keep putting enough things in until you get a match.  The problem is, or, well, the problem for the cryptographer or the cracker/hacker is that all we're seeing is a tiny piece of the hash output.  So to do any kind of meaningful crypto you've got to see it all.  And what that - so what that practically means is that we have a hash function which is doing a very good job of producing pseudo, really high-quality pseudorandom numbers.  And, for example, it is possible that when the 30 seconds elapses and the next number is shown, that it doesn't change.



LEO:  What?



STEVE:  Yeah.  Because...



LEO:  That's highly unlikely, though, isn't it?



STEVE:  Very unlikely, but very possible.



LEO:  But possible.



STEVE:  Because we're only seeing six digits of a much larger hash.  And so any of the other high end of a hash would be different except those six digits.  So we know that six digits is one out of a million.  So there's a one in a million chance that you will get the same code again because it's truly very good random.  And that's what you would like.



So here's the danger, and your question is the perfect setup for this.  The problem with having your phone full of accounts - remember I was excited that Google Authenticator essentially allowed me just to create as many individual instances for authentication as I wanted.  For example, we were talking about Dropbox and how Dropbox now supports multifactor authentication using Google authenticator.  And that's cool.  Except that Dropbox knows the key for this instance.  And as long as I only use the key with Dropbox, well, then I have some security.  But if I deliberately gave other authenticators the same key because I wanted to reuse the instance of Google Authenticator, that is, that account in Google Authenticator, now we start having the same problem again as using a common password across multiple sites.



So the point is that we have a nice system with Google Authenticator and its clones because there are now a bunch of people doing a compatible solution, and I think that's great.  But in order for this to be secure, because essentially we're able to manage our identities by creating instances of these authentication accounts, we again bear some responsibility in managing those well.



Now, to make this more clear, I don't have that problem if I were using VeriSign with VIP because theirs is not a distributed system.  Theirs is everybody I authenticate with has to go to VeriSign to determine what my code should be, rather than just asking me, and my phone knows.  So these are different models.  And it's not clear to me, I mean, it's not completely without cost that we remove any  middleman from the solution and take responsibility ourselves.  And remember that the downside of the VeriSign approach is what we saw with RSA when they had the huge breach because RSA was the same thing.  They had all the keys to the kingdom, all of their time-based RSA tokens that corporations the world over and a lot of government were using for, for example, logging in securely to their VPNs.  They lost the keys.



So there is a, if you centralize like that, there's a single point of failure.  If they were down like, for example, GoDaddy was down yesterday, no one can authenticate during that period of time using their approach.  So you would want to have some sort of backup solution.  And also there's a single point of vulnerability to them losing the keys to the kingdom as they actually did in the case of that breach.



So where we are today, I think, is we're moving towards a - thanks to probably the strength of Google and the pressure from users who want something better than username and password, where in fact username is email address more often than not, so that doesn't even count, as we were talking about last week, where we have a distressingly loose standard in OATH which has been adopted and is now being copied.  And so in the same way as other standards that were not well specified but became well specified in practice, we've got that.  And that's beginning to happen.  Now, so that's OATH.



Then in terms of protocol there's OAUTH and OpenID.  Now, we talked about OpenID years ago when that effort was relatively new.  And their site claims, I think it's nine billion websites are now using - no, it has to be million, nine million websites.  But it's like it's, I think it's one billion users and nine million websites.  Is that possible?  That sounds like a...



LEO:  Yeah, that's possible.  There's a billion Facebook users.



STEVE:  Okay.



LEO:  Yeah.



STEVE:  And so I don't encounter OpenID that often.  I mean, I've seen it.  The idea is it's got kind of that little funky sort of 3D, it's like gray and orange sort of thing standing up.  It's kind of a funky little logo.



LEO:  Oh, the logo, okay, yeah, yeah.



STEVE:  Because that's the visual cue that you can use your OpenID identity to log into this site.  And so, and you'll remember that the concept was you give them a domain name or a URL for a page on the 'Net which you control.  And so the idea was, in the same way that an email confirmation loop is useful because you control that email account, and so you've said this is my email account when you set something up, and so you hold onto that, and so the idea is you know how to log onto that email account, you control it.  Similarly, the OpenID concept was you control a page that is available.  Now, it may be your blog.  It may be your own website.  Or more often it's going to be a provider, an identity provider where you have established an OpenID account.  And then they've given you this string which essentially is your page there.



LEO:  Yeah, I used a company called claimID for this purpose for a long time.



STEVE:  Yes.  Yes, exactly.  And so the idea is that that's your universal tag.  And if you are at any of these sites that says, oh, you can authenticate, you can identify yourself, essentially, with your OpenID, if you've got one, you use it there, and off you go.  Now, that's competing with OAUTH.  And I think it's lost.  I think it...



LEO:  [Sighing]



STEVE:  I think it was a nice idea.  But there is so little tolerance for any friction in authentication that the idea that I could go to IMDB and am presented with how would you like to log on, with us, Amazon, Facebook, or Google?



LEO:  Yeah, that's the problem, or Twitter.  That's the problem.  It's so much easier, and everybody's got one of those.



STEVE:  Yes, yes.  And so there isn't a way to compete with that.  I mean, there just isn't.  Now, the good news is that - so what we have is we've got - it could not be easier than that.  I mean, it just - as you said, Leo, because everyone has at least one of those, they don't have to go create an account on IMDB.  And so I think we're going to see now OAUTH adoption take off.  As people get - they see this more often, they encounter it more often, they see that it worked for them, oh, look, I can just log on using my Facebook.



LEO:  So that's what Facebook's using.  That's what - I know this is what Twitter's using.  Google+.



STEVE:  Yes, everybody.  The way to differentiate it is, if you are not - the OpenID has to get information from you first.  It has to ask you for your ID.  And then it goes off and authenticates you against that.  Anything that says "Log on using Facebook, Twitter, Amazon, Google," whatever, that's OAUTH.  And we do have a podcast in the past about it in detail [SN-266].  Essentially the way to think about it is it uses browser page redirection on the front end.  That is, when I click on "Log in using Facebook," my browser receives from the server instructions to go to a particular URL which Facebook publishes for this purpose.  And that's where my browser receives a login page from Facebook, asking me to authenticate who I am, that is, to log into Facebook.



LEO:  Is that going to leak information back to Facebook?  That's, I guess, the privacy concern that people have.



STEVE:  That's a good, that's a very good point, yes.  Facebook knows who has sent me to them.  And so that is a potential privacy concern, you're right.



LEO:  And sometimes when you click Facebook it'll ask you, besides logging in, to give that app permissions, including "Post on your behalf" and things like that.



STEVE:  Yes, yes.  Now, OAUTH was actually more designed for that, the notion of autonomous background inter-application data exchange, the idea being, for example, you've got some web-based printer app that wants access to your Flickr account.



LEO:  Right.



STEVE:  And so when you're using the web-based access thing, it says we'd like to be able to print your Flickr photos for you.  You need to give this website permission to access that website on your behalf.  And so OAUTH is more than just bouncing you around and log on using Facebook.  That's an aspect of it.  And then the other is this notion of persistent permissions.  And in fact we can see that, one very easy place to see that is in Twitter because so many people have allowed other Twitter clients to access their Twitter accounts on their behalf, and that's OAUTH.  All of this is happening by OAUTH.



If you go to Twitter.com, log in through a web page, if you drill down through security and permissions and things, there's applications that have permission to access Twitter on your behalf.  And so there's an enumeration that you'll be shown of all the things you have given at some point in time permission to access your Twitter account on your behalf.



So OpenID was a nice idea.  It was competing for a while.  But what I'm seeing more and more is that nothing can compete with the simplicity of asking a user, I mean, when you go to a - one of the things that really annoys me is having to create an account on some site that I probably am never going to come back.



LEO:  Right, never be back, yup.



STEVE:  Yup.  And so being able to just say, oh, use my  Amazon identity, fine.  I mean, as I did on IMDB.  It's like, wow, this is clearly the solution that's going to work.  We probably need to take a look at OAUTH v2 at some point because it's been kind of lumbering along in committee mode.  Some of the early founding people have gotten a little bit miffed and disgusted by just the nature of the development.  It hasn't gone in the direction that they had wanted.  But it really looks like it's the solution that is going to win.  And I can just see, as  libraries become available, as authentication continues to strengthen, you would be able to, for example, establish strong authentication with your Google account if you tend to be Google-centric, or strong authentication with your Amazon account if, like me, you are Amazon-centric.  Or with Facebook.  Is Facebook multifactor yet?



LEO:  Oh, yeah. 



STEVE:  Oh, okay.



LEO:  You may not know it.  I don't think anybody knows it because they describe it in a very bizarre way.  I should show you this because...



STEVE:  But are you able to use Google Authenticator?



LEO:  No, you have to use Facebook's authenticator.



STEVE:  Okay, but they have one.



LEO:  Yeah.  I don't think people know it.  If you go to it...



STEVE:  An app for smartphones?



LEO:  It's the Facebook app has an authenticator built into it.  So here's the deal.  You have to go to...



STEVE:  Oh, there's a Facebook app for your phone.



LEO:  ...the Facebook app itself.  You go into Security, and there's a setting for - and this is why it's not clear what it's asking for.  "Login approvals.  Approval is required when logging in from an unrecognized device."  If you turn that on, you have two choices.  And I'm not going to show it because I'd have to show my cell phone.  But you can have a security code texted to a phone number.  Or you can use a code generator.  And it turns out the code generator's built into the Facebook app.  So they've got it down, actually.  But I don't think they've publicized this.



STEVE:  Nice.  So we have multifactor authentication at Amazon, multifactor authentication to Facebook, or multifactor authentication to Google.  Who doesn't that cover?  I mean, that's got to be the world.  And so as soon as libraries become available that allow webmasters to easily incorporate OAUTH, I mean, and the libraries are there, they'll just be part of the default install, or they'll be enabled or whatever, or there'll be pressure from users, hey, look, let me log on using my Facebook account.  Everybody else does.  And so I think this is the direction we're going to go.  And there were some glitches, there were some security problems early on that have been solved.  So I don't see this as a problematical solution that we're moving toward.  To me, I think this is going to be a great step forward.



LEO:  I should - I have been showing - I just showed the Facebook code generator, which is built into the app, at least on Android.  I think it's on the iPhone app, as well.  And then I before that showed my Google Authenticator.  And people are starting to freak out, hey, wait a minute, you're showing your codes.  But they change every 30 seconds.



STEVE:  Well, not only do they change every 30 seconds, but a proper implementation refuses the same code again.



LEO:  Right.



STEVE:  So even somebody who was monitoring and, like, if you were logging in with it and showed it, even using the same code within the 30-second window that that code is valid, it would not be honored a second time.



LEO:  And they'd have to have my password, as well; right?



STEVE:  Exactly.



LEO:  So I feel fairly secure showing that.



STEVE:  Yeah.  And, oh, no, I mean, I don't have it near me, but, yeah, there's just no reason not to because it is really good, pseudorandom, changes every 30 seconds, and it being used a second time is blocked.



LEO:  Rorx has a good point, and I guess this is - he says, you know, it's too bad, though, that I have to be forced to use Facebook to authenticate.  Is it possible to run your own OAUTH authenticator like OpenID?  And the problem is that, no, because the page you're logging into has to know, oh, you're going to use Leo's authenticator, not Google, Amazon, Facebook, Twitter.



STEVE:  Yes.



LEO:  It has to support those OAUTH implementations.



STEVE:  And that's a perfect example of what OpenID was giving us...



LEO:  Right, yeah.



STEVE:  ...is that you were providing it with your own URL to represent you, and it would go there, and then you would negotiate with it.  So there you had control.



LEO:  I have an OpenID token at TWiT.tv.  So I could, if I wanted to OpenID, I could go to TWiT, use TWiT.tv as my identifier.  But nobody uses it, so.



STEVE:  Yeah, yeah.  And so, yes, we do lose some flexibility.  And then there is the issue of, as you said, some privacy concern because anyone you authenticate with knows where you're coming from.



LEO:  Right.



STEVE:  But it's like, eh, okay, well, you know, it's way convenient.  And I think it's a great solution.  And it looks like it's winning.



LEO:  It's winning.



STEVE:  Yup.



LEO:  And, by the way, we allow, not that we use it, but you could use OpenID - Drupal supports OpenID.  And it's possible in this case, this is the TWiT.tv site, to log in using OpenID or to sign in with Facebook.  There's no point in logging into the TWiT.tv site.  We don't do anything with those.  Those are for administrators.  But still, Drupal has that built in, so it's kind of free.  But, and then in order to log in using OpenID, what do you - you provide it with your - I've forgotten now.  I guess I just give it my URL.



STEVE:  Yeah.  If, for example, if it was your own domain and web server, you could literally use TWiT.tv to represent you.  But oftentimes it'll be a domain and then a specific page at that ID location.



LEO:  Yeah, I have claimID.com/leo, I think, as an OpenID.



STEVE:  Yeah, exactly.  So we're step by step, little by little, we're figuring out how to do this.  We're fixing the mistakes we make as Apple learned the hard way with making their unique device ID available to developers and even promoting it for that purpose for a while until they realized, oops, that's not what we want to do.  And so we're learning these lessons.  And I just think that, when I imagine my mom or my sister or somebody going to a website they haven't been to before and being offered the choice of create an account, which no one gets off on creating accounts all day long, versus push this button to log in using your Facebook, they, like, oh, done.  It's like, thank you.



LEO:  So easy.  And of course because the token's on your machine, once you've done that, it's painless because it just knows you are who you are.  Which is another security flaw because now that token could be used by others if they can get access to your machine; right?



STEVE:  It is over SSL.



LEO:  That's what Firesheep showed us.



STEVE:  Exactly.  Yup.



LEO:  So Firesheep could be used - could it be used to do an OAUTH authentication?



STEVE:  Well, remember that Facebook has moved to SSL pervasive, so it's not easy.



LEO:  You're okay; right.



STEVE:  Yup.  It was not an easy transition.  But, I mean, here during the podcast over the last couple years we've seen one little problem after another fixed and solved and moved.  We can see our progress.  We really are moving forward and getting this stuff done right.



LEO:  Steve Gibson is a major proponent of all of this and probably has had a lot to do with it getting better and better and better.  You can hear 369 episodes now of Security Now! on his site, GRC.com.  He's got 16Kb audio and transcripts of all those episodes.  We've got audio and video at TWiT.tv/sn for Security Now!.  GRC is also where you'll find SpinRite, the world's best hard drive and maintenance utility, all the free programs and information Steve offers.  There's a ton of great stuff.  It's worth browsing around.  And while you're there, if you have a question about this or any of the topics we talk about on the show, you can ask at GRC.com/feedback for that feedback form.  And that's the one and only way you can ask a question for the show.  Next week we'll do a Q&A episode.



STEVE:  And we'll have Mark Russinovich at the top of the show.



LEO:  Oh, that's exciting.



STEVE:  Yeah.



LEO:  Mark Russinovich joins us next week.  For those who are watching live and saying what the heck, we flip-flopped MacBreak Weekly and Security Now! because tomorrow's the Apple event, 10:00 a.m. Pacific, 1:00 p.m. Eastern time.  We'll stream that live.  But Steve will be back Wednesdays on his usual time, 11:00 a.m. Pacific, 2:00 p.m. Eastern, 1800 UTC for Security Now!.  And I hope you'll join us live.  Thanks, Steve.



STEVE:  Thanks, Leo.



LEO:  See you next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#370	

DATE:		September 19, 2012

TITLE:		Mark Russinovich & Other News

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-370.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  We begin the week with a visit with our distinguished guest, Mark Russinovich, late of Sysinternals and now with Microsoft.  Mark joins us to chat about the release of his second security thriller, "Trojan Horse," and to share some of his view of the security world.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got lots of security news, including a zero-day exploit in IE9, IE8 and 9.  Oy oy oy.  But before we do that, we're going to talk to one of our favorite authors.  Mark Russinovich is here, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 370, recorded September 19th, 2012:  Mark Russinovich.



It's time for Security Now!, the show that protects you and your loved ones online and your privacy online.  And we've got a great show planned for you today.  Let me first introduce our Explainer in Chief himself, Mr. Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.  Before we began I didn't just double-check that you've got your recorders running, but...



LEO:  I am recording this.  Because if you're hearing it now, ladies and gentlemen of the jury, then it must have been recorded.  So according to time travel precedents...



STEVE:  I was going to say, that's sort of a time travel paradox.



LEO:  Said by Isaac Asimov or somebody, we're okay, retroactively.  You know, there's that new movie, and I...



STEVE:  "Loopers."



LEO:  Yeah, to me it's like paradox city.  How could Bruce Willis - anyway.



STEVE:  Yeah.  I don't understand why the, I mean, I'll see it, of course, because it's sci-fi.  But the premise is that the mob 30 years in the future, which first of all doesn't seem like very far for us to have developed time travel all of a sudden, and then for it to be in the hands of the mob.



LEO:  Yeah, that was quick.  Those mob R&D departments work fast.



STEVE:  When they want to assassinate someone, they send them back into the past, into what is apparently our present.  And it's like, wouldn't it just be easier to do it the old-fashioned way?



LEO:  Well, there's more room for the bodies, apparently, in the 20th - nowadays.



STEVE:  Ah, or maybe part of time travel is omniscience on the part of the feds or something.  I don't know.  Anyways, it's interesting.



LEO:  I'm sure they'll explain that.



STEVE:  I hope they've come up...



LEO:  But you would think Bruce would know, well, I guess he does know, maybe there was nothing he could do about it, that he was going to - he knows the outcome of this whole thing.  Otherwise he wouldn't be there.



STEVE:  I will say something.  And that is that there is something compelling about time travel.



LEO:  It is.  We love it, don't we.



STEVE:  There's a special pack of all the Star Trek time travel episodes across the entire set of series.  The original ones with Spock and Kirk, then the Janeway ones -  Janeway actually was getting herself in all kinds of trouble on "Voyager" - and various ones. 



LEO:  Well, this is kind of their version of the if-you-kill-your-grandfather-what-happens saga, only in the other direction, I guess.  Anyway, it'll be fun.  But we don't need to spend time with this.



STEVE:  No, because we have got something much better.



LEO:  Introduce your guest.  He's sitting here.  He's lurking right next to you.



STEVE:  Someone much better.  Our listeners will know, actually we told everybody last week, so unless someone missed last week they'll know that we have a special guest this week, Mark Russinovich.



LEO:  Woohoo!



STEVE:  Who long-time security and computer insiders know from his work at Sysinternals, where all of us were downloading fancy utilities that were absolutely unavailable in any form anywhere else, just like the best stuff.  I remember every so often I'd go over and suck everything down, just in case anything ever happened to the website that would cause them to become unavailable because they were so...



LEO:  Good stuff.



STEVE:  They were so good.  They were so important.



LEO:  Oh, yeah.



STEVE:  And then, I don't know, I guess it was last year, Mark dropped me a note and said he'd written a novel.  And I said, "What?"  He said, "I'd like to send you a copy."  And I said okay.  Now, I have a review of his second novel, which is the occasion of his joining us on the podcast to chat a little bit about that and how we got into this and all that, sort of the human interest side.  But I thought I would quickly share what I wrote publicly about Mark's work.  I said:



"Like so many of this terrific book's early reviewers, I've known Mark for many years.  Mark is a celebrity of significant note within the computer industry.  But I only knew that Mark could write world-class code.  I had no idea that he could also write world-class novels.  And being artful at one certainly doesn't suggest any strong talent for the other.  So being very picky, I worried when Mark sent an early copy of his first novel, 'Zero Day.'  I wanted to like it and worried that I might not.  So I'll just say that I wasn't the least bit worried, I was delighted, when he sent an early copy of novel No. 2.



"If you haven't yet read 'Zero Day,' you don't really need to.  But I loved that Mark told his second story through the eyes of the two protagonists whom he introduced and developed throughout his first work of fiction.  So by all means, click the purchase button above; but, if you haven't already read 'Zero Day,' why not begin at the beginning?



"Today, everyone understands that modern 'connected' life requires some concern for online privacy and security.  If you know very little about the details of how bad things happen to people online, you'll find Mark's stories compelling from that standpoint.  They explain this clearly and intelligibly, wrapped around exciting narratives that bring those details to life.  And if, on the other hand, you know your way around computer security, you'll find Mark's stories not only compelling, but also technically perfect.



"I'm so glad that Mark decided to share his imagination and storytelling talent with the world.  Once you've read Mark's novels, I'll bet you find yourself recommending them to others, as well.  I certainly have."



LEO:  Well, that's exciting.  And we should mention that Mark will be back on Windows Weekly tomorrow and probably will talk more about Windows tomorrow.  But today we'll talk about "Zero Day."  Mark Russinovich, welcome.



STEVE:  Well, and so what I loved about the book, just by way of introducing it to our audience - you know we have a special audience that have been maybe listening to us for seven and a half years.  We've covered, as I was reading the book, I mean, everything that Mark discusses, we've done podcasts on.  And we've come at it sort of from a dry, technical, this is the way it works, here's the technology side.  And as I was reading this, I was thinking this would really be interesting for our listeners because the technology will be intimately familiar, but here Mark actually employs these things in a very interesting plot that's exactly real.  And it gives you a chill to sort of see this stuff come to life the way Mark pulls it together.



LEO:  You're talking about his, of course, wonderful book, Windows Internals Part 2, now available in paperback.  Oh, no, you're not talking about that.  Okay.  Welcome, Mark.  It's good to have you on Security Now!.



MARK RUSSINOVICH:  Well, thanks for having me on the show, and thanks - I emailed Steve when I saw that review.  I'm thrilled and flattered and honored that he liked the book so much and that he took the time to write a review and share that opinion with everybody else.  And it's great to be on the show.



LEO:  Well, so I guess my first question is, how did this happen?  We all know you as a codesmith.  And now you've written two really good novels.  What's the back story?



MARK:  So, well, it really happened because I had this - I've always had this urge to write a book, a novel, like many people that get involved in reading when they're young, science fiction and techno thrillers.  And I would read these stories that were so well crafted and yet built on solid technological grounding, so that I'd read it, and I'd feel smarter at the end.  It was like I was going to school but having fun as I was reading a book, and thought it'd be really fun at some point to challenge myself to construct something like that.



And what pushed me to the edge of actually dedicating the time required to craft something was the strong belief, post-9/11 and post-SQL Slammer and Blaster and Code Red, that terrorists would see cyberweapons as an ideal weapon for achieving their agenda, which would just be indiscriminate destruction.  We saw with those kinds of worms that people would write them, kids would write them in their basements, let them loose just to see how fast they could spread, without any real kind of malicious payload really involved with them.  And yet they would cause so much disruption just in that form.



So that's what pushed me to write the book "Zero Day," what I think is a realistic threat, and also one that I could tell a story that was a techno thriller built on technology and share what a security professional's life is like and what cybersecurity is all about and the kind of risks that we operate with because our systems and our lives are so dependent on computer systems.  So that's what pushed me to write that.  And I actually finished it in mid- or early 2006.  It took me several years to find an agent and then a publisher and then finally get it out the door.  So, but that's what was the impetus.



And then I had started working on "Trojan Horse" a couple years before "Zero Day" [inaudible] in case "Zero Day" did well, then I wanted to have another one ready to go.  I finished it after "Zero Day" came out.  It was kind of the reception to "Zero Day" encouraged me to push through and get that one out the door.  And I've been working on a third one, as well.



STEVE:  Whoa, wait.  You just said you've been working on a third one?



MARK:  Yes, working on a third one.



LEO:  What, is that in between writing Windows Internals?  How do you find time to do all that?



MARK:  Well, Windows Internals, as you showed, Sixth Edition Part 2 is going to be out, I think, next week.  RTM and Microsoft Press announced that earlier this week.  So it's now off to the publishers and Amazon.com to get out there.  But that's my last rev of the Windows Internals book.  And that one I actually finished several months ago.  And I've been working with Dave Solomon and Alex Ionescu, with contributions from some other people.  So it's been kind of a low-level background activity, working on the book for the last few years, on the Windows Internals book series.



LEO:  It's funny, I would have thought it would be the other way around, the novel would be the - you go home and go up to the attic and spend an hour each night working on it.



MARK:  Well, actually the novel is that way.  But the novel comes in more dedicated spurts than the book did.  And the book, the book research for the Windows Internal book and some of the original writing for the book started many years ago, around the time of Windows 7 RTM, as I was writing magazine articles and blog posts and researching and just being familiar with what the product was and researching areas that I wasn't directly involved in.  So that has been kind of ongoing for a long time.  But the novel work is more - I need to dedicate serious time in more shorter spurts so that I don't lose my train of plot and thinking and being immersed in it.



LEO:  Is it like programming, writing a novel?



MARK:  It is kind of like...



LEO:  What you just described sounds like a programmer might say that.  I don't want to lose the thread of my - you're juggling many balls when you write a program.



MARK:  It is totally like a program.  In fact, I've experienced the same kind of context switching overhead - and there's a programmer term for you - when I'm working on a Sysinternals tool, and then I am pulled off to do other things and return to it a week or two later, it's, okay, I need to get back in the mindset of what this tool is and the flow and the architecture of it to figure out how to evolve it.



LEO:  Now, you have comments, you have comments in source code to make that possible.  What do you do in a novel?  Do you have comments?



MARK:  Yeah, I've got notes of things that I make as I go along to keep track of what my thoughts are and where I think things will go, things that I'd like to include.  So I do have some of that to help me get back into it.  But it's still - it is massive context switches.  And even switching between writing and coding is a big context switch.  So I try and minimize the number of times I do that.



STEVE:  For what it's worth, having read both novels, I feel strongly that there is an important social good that you have accomplished.  I mean, it really - those books are technically accurate.  They give anyone who is familiar with what's really going on in the security scape, I mean, a deep chill because what you paint we understand is absolutely possible.  And, I mean, I really did get a sense of almost foreboding.  And that's a useful thing to be able to give people, for example, decision-makers in government who don't really get it, don't understand what's happening because what you've portrayed is technically, I mean, it is happening at, like, right now.  And frankly, I'm very impressed that you wrote "Zero Day" six years ago because, I mean, it was contemporary last year.  I mean, it was - for that to have been already five years old is impressive.  You were looking into the future back then.



MARK:  Yeah, and I was actually concerned in that time gap that something would happen and the book would become obsolete.



LEO:  No fear of that.



MARK:  But you said that...



STEVE:  Yeah, I mean, we had Stuxnet happening at the same time.



LEO:  It got more germane.  It got more topical.



MARK:  Yeah.  I mean, I actually did, I complained to the publisher, why is this taking so long, it's going to become obsolete.  They were like, no, it'll just become more topical.  They're putting a positive spin on it.  But absolutely, I think I wanted to send a message to everybody because everybody's involved with cybersecurity.  Anybody running a small business, even in your home, you've got cybersecurity as one of the kind of responsibilities for keeping your own data secure, keeping your identity secure, keeping your business up and running, keeping your customers' data secure, keeping our national infrastructure secure.  And you've seen with the Cybersecurity Act of 2012 and the debates in Congress and the partisan politics that we've seen going on with that, there's a lot of people that don't get it.



So I think that there's this antiregulatory philosophy that a significant portion of our politicians have which I think that, if you look at some of the industries that we've regulated, it's hard to argue that the regulation was unnecessary and not beneficial.  You look at food, for example, or water, or the financial, the regulations we've got there that we're not all better off because of some regulation.  And yet they'll sit and argue, no regulation necessary in cyber sphere...



LEO:  But isn't the concern that the government, unlike food and water, that our governmental officials just seem to lack a basic understanding of technology?  I think people are afraid that they're going to write something - look at SOPA - that makes no sense technically.



MARK:  I think that is a concern, and it's a valid concern.  But I don't think that that's a good reason to say, well, we're not going to do anything about it, and let everybody - and just have it be cooperative and voluntary and let people do what they want to, especially when the nation is depending on these systems for us to continue to operate well.  So we outsource so much of our critical, national critical infrastructure to private industry, and yet say, well, you can voluntarily have security best practices and voluntarily share information with us and voluntarily - and I just don't see that as working.  It's not in their best interest to spend money on something that they view as maybe low risk, or, well, if it's going to happen to us, well, it's going to happen to everybody, so why should I encumber myself with being the best at it.  The free market pressures that people say will influence people to do the right thing I don't think really are there.



LEO:  Congress recently decided not to regulate.  But the President a couple of days ago proposed an executive order that would add some cybersecurity.  Have you looked at his proposed executive order?



MARK:  Yeah, it is pretty watered down.  It is focused on, again, their voluntary sharing and voluntary adherence to cybersecurity principles.



LEO:  It's not enough.



MARK:  I think that - yeah, I don't think it's enough.  And I think that one of the - a lot of the language is vague, so it's really open to interpretation.  But I think one of the theories about what this executive order is really aimed at is not for the President to come out and issue an executive order, but rather to scare Congress back into talking about a bill and getting a bill through, which is the right way that this should happen, not just the President issuing something.  So I think it's - somebody's - I've read articles that people say looks like it's potentially a bluff, just to get people back at the table.



LEO:  Was the Cybersecurity Act sufficient, in your mind?  Was it well written, well crafted?



MARK:  Well, I think that the original Lieberman version was.  I think that the one that, after McCain got his hands on it, became way too watered down.  And that one, if you look at it, is basically volunteer versus regulation.  And I'm not saying, by the way, when I say "regulation," that it's just purely regulation.  I think we need to have incentives through tax breaks and other ways of positive reinforcement for people doing the right thing, not just the negative side of it, too.  But the Republican version of it is definitely, I think, more close - it's closer to what the executive order looks like.  And I think maybe that the Obama administration figured, okay, maybe this is a first step.  Let's just agree, let's just establish what we can agree on, and then we can build from there rather than just not have anything.  So that's why you saw Lieberman say, okay, fine, we'll go with this one, and then it still fell apart.



STEVE:  I guess as a consequence of the way the Internet sort of grew organically and the way computing and personal computers sort of grew organically, but I'm noticing this sort of, I don't know, a schism between the - or as a consequence of the amount of damage that an incompetent programmer can actually do.  And I note, for example, by way of comparison, that attorneys and medical doctors have to get substantial additional education and then pass tests and essentially become certified.  And programmers don't have anything like that.



But at the same time it's sort of gone from a casual hobby into something that is really a potent tool for good.  But if code is written incorrectly, sloppily, casually, a lot of damage can be done.  And of course all the license agreements say that there's no responsibility on the part of the producer of the software, which is another odd aspect to this computer industry that has persisted from the beginning.  What do you think about the idea, I mean, not that I'm wanting to impose regulations and the same sort of MD degree and law degree on people.  But something, it feels to me like somehow we need something to begin to tighten down the quality of the software being produced because it's become - it's gone from not really mattering much to being national security and nation-state level.



MARK:  Yeah, and I think you're absolutely right.  One of the things we do at Microsoft is people have to go to SDL training, Software Development Lifecycle training, which includes the threat modeling aspect of it.  Not just the threat modeling, but then what kind of tools do we have available to us to make sure that the code is more secure, the tools that flag improper use of variables and uninitialized variables and then why you - the defense in depth things that we apply to our software.  And Microsoft tries to help the industry in general by publishing SDL training publicly.  And there's a number of companies adopt it.



It would be great to see that, at least starting with people that are developing the systems that are at the heart of things like our electrical grid or communications systems, that those people would have to have some certification in SDL and maybe - and probably have it renewed every year or two years, as well, just to make sure that they are at least aware that this is a way to look at their software to make sure that it's more secure and more resilient to attack.  I think - I totally agree with you.



STEVE:  Where would you - you sort of touched on this before.  But I'm wondering where would you split the responsibility for the trouble that we're seeing between the technology suppliers and the technology consumers?  That is, how much of the responsibility is on the software authors, and don't users have some responsibility for their own conduct?



MARK:  I think I would put, yeah, it's hard to put the blame on the consumer because the consumer assumes, right, when they buy software that it's being developed properly and it's not going to have flaws with it.  So I find it hard to put the burden on them.  But I also find it hard to put the burden on the software provider in that scenario, too, because they're sitting in a market where it's one of those - I've got certain competitors.  If I spend too much time and energy on this stuff, I could fall behind on features and being competitive.  And so what if it's secure if people aren't buying it because the company next door has all the cool features everybody wants, even if it's insecure.  Those guys are playing this risk-management kind of situation while it's unlikely to really come back and slam us in the face.



And so if you look at what the government does, they've got this program called FISMA which has now evolved a bedrock where they'll say we do have certain requirements for the software that we're going to deploy our applications onto and run government workloads on top of that include things like making sure that you have two-path replication for your administrators and a whole number of other things that don't go as deep as the software developed using software security development lifecycle, but at least hitting some of the outside, very visible aspects of having a secure environment.  In that case it's the consumer, in the government's case, which has leverage, which is the money and the dollars required that they're willing to spend on buying solutions.  And so unless we have all consumers be that way and have certification and auditing, which the government has, then I don't see a way to change that dynamic between the consumers and publishers of software that people are using, like in a dentist's office.



STEVE:  Yeah.  So I guess there will, from what we can see, always be a tension between the suppliers and the consumers, but also a tension within the developer side between new and features and spending more time on security, but not having as many features.  People talk about how nice it would be to have a closed system which could inherently be more secure.  The problem is, though, then they want - oh, but I need this and this and this.  And it's like suddenly they push it away from being closed.  And as soon as you do that, you open it up to exploitation.



MARK:  Yeah.  And we're seeing actually, as we move to the cloud, and we've got all these startups, agile software development bringing it on as fast as you can.  And you know that you're sacrificing something there.



STEVE:  Yeah.



MARK:  It's good enough to run for now.  We'll move on to the next thing.  But at some point it becomes a house of cards that you're playing with.  So, yeah, I don't see a good way out of that dynamic without the kind of leverage that government's put in place that really cares.  It's like paying taxes or eating broccoli.  That's what security boils down to.  It's sort of paying insurance; right?  So unless you really believe that you're going to - that you're at risk of something bad happening, you're just not going to pay that price.



STEVE:  Yeah, for example, we advise people not to use the same password across multiple websites.  And that's now becoming sort of standard, if you really want the best security, this is what you need to do.  But wow, that's much more difficult to manage and maintain over time than saying, oh, I'm not going to worry about that, I want the convenience of just using one password everywhere.  So again, it's exactly that kind of a tradeoff of convenience versus security.



MARK:  Yeah.  And very few people are making that tradeoff right now with passwords, despite the fact that you see these huge password breaches from one account surface that enables the attackers to get into a whole bunch of other related ones.  That's still not stopping people from doing that risk calculation of it's unlikely to happen to me, so I'm just going to continue operating the way I am and cross my fingers.



STEVE:  Right.



MARK:  The other thing, too, I wanted to point out about this regulation aspect, in that some of the arguments that McCain will make and some of the people against regulation and even government [indiscernible], they'll say the free market will take care because, if there is a problem, then there'll be a lawsuit, and that's the way that the free market will fix it.  But I wouldn't want to bank our national security and infrastructure on, well, if it falls apart, well, then we'll sue the people that created the holes because by then it's too late.  You've already - the damage is already done.  You're not going to redo or fix things with a lawsuit and putting the company out of business after the fact.



STEVE:  Yeah.  Okay.  So here's a big, wide-open question that I think our listeners would find interesting, which is from your perspective, and this is completely wide open, what major trends of any kind do you perceive, like in the way the industry's moving, the way security's changing, the way attitudes are changing, development is changing, sort of what's - where are things going?



MARK:  Well, the bigger trends, I think we're right in the middle of the third disruption in the computer industry, the first one being the mainframes, the second one being client-server, and this one being cloud and mobile.  So that's one that's affecting everybody and the way that everybody thinks about software, from enterprise developers to ISDs to consumers.  But underneath that, as far as security goes, I think that what we're seeing - and I've been a proponent of this form of security, the security technique, the security mechanism since shortly after 2000, when I started to really focus on what my software company, Winternals at the time, could do from a security perspective, and that is whitelisting.  Back then whitelisting was something that nobody used.  Windows and UNIX had some whitelisting capabilities, but very, very few people used it.  And that's been the case up until very recently.



And people I don't think are really aware of this, but now whitelisting has become one of the key security features of the modern client platforms.  When you look at iOS, for example, Apple's ecosystem, it's a complete whitelisted ecosystem.  The whitelist, you can only run the software on the phones that have been approved by Apple and curated by Apple.  Apple is essentially creating their whitelist in their Apple store.  And that has made those platforms - Android's got one.  It's not as well curated, so we've seen a problem with that.  And then Windows Phone's got a curated whitelist, as well, and Windows 8 does, too, that those whitelists, you see the dramatic impact on the security of the system by having that whitelisting in place.  Even if there is - and the sandboxing that goes with the whitelisting, as well.  So I think I feel somewhat vindicated because I've always believed whitelisting would come back and become one of the primary tools in a cybersecurity posture or platform.  And we're seeing that with the cloud platforms really adopting it and seeing the dramatic effects of that being in place.



STEVE:  And that's really interesting, too, because it does parallel the same kind of evolution that we've seen elsewhere.  We've talked several times on the podcast about how the very first deployments of firewalls were default open and blocking only specific things that were known not to want to be made public.  And it took a while, but we finally reversed that model in firewalls where it's default block, and then you selectively open availability for those services that you do want to allow through.  And it was only after making that switch, although it's arguably more difficult, you're going to perhaps false block when you don't intend to.  But that's better than having everything open by default and blocking only the things you know you want to prevent.



MARK:  Yeah, no, that's a great parallel there.  And we see the mirror of that in cybersecurity, too, with the blacklisting approach of antimalware.  And just what I think is hard to argue not being a complete failure.  I mean, the fact is, when I give a talk on security and Sysinternals tools for troubleshooting security, I have a fake piece of malware, which it's a piece of malware that I created, and it is malicious in the sense that it's a demo piece of malware, but it is completely unknown to the blacklisting antimalware solutions.  Now, if I tried to deploy that in a system that was employing whitelisting, it would be totally ineffective.  It would get blocked.  And very similar to what you were talking about with firewalls, where for a long time we operated with a blacklist approach with firewalls, and then switched over to whitelisting and realized that's much more effective.  I think the same thing is happening with antimalware.  The places where it hasn't caught up are desktop systems and even server environments.



I don't - listing is not mandated as part of bedrock, and I believe it should be, or as far as software that's operating our national critical infrastructure.  There should be policies in place for what software is running on those systems and stopping any other software from operating on those systems.  And that would go a long way to keeping those systems more secure.



STEVE:  Yup.  So you have...



LEO:  Well, I - go ahead.  I didn't mean to interrupt you, please.



STEVE:  No, I was just going to say - I was just going to wrap up by saying, so you do have a third novel to tease us with at some point in the future.



MARK:  Right, I do, it's called - I've been working on it, and it's called "Rogue Code."  It is, see, if you look at the first book, the theme was cyberterrorism.  The theme of the "Trojan Horse" was state-sponsored cyber espionage and spear phishing.  And the theme of this third one is insider threats in systems now.



LEO:  I love it.



MARK:  Which I think...



STEVE:  Good, good.



MARK:  ...if there's any weak spot in any system, you can have the best technological defenses in place.  But if you have an insider, a malicious insider, that is very hard to defend against.  And social engineering, of course, a slightly weaker form of the same thing as an insider threat, but also extremely hard to defend against.



STEVE:  Very cool.  Well, Mark, thank you very much for joining us.  And...



LEO:  We'll see you tomorrow.  And actually LouMM, who is in our chatroom and I guess a colleague of yours, is going to run over with a Heil PR 40 microphone for you to borrow for tomorrow.  I think he's already linked you.  But really great to have you, and I appreciate, boy, we've been fans since the Sysinternals days.



STEVE:  Yeah, I was going to say, thank you so much for all your contributions through the years, to be able to have those tools.  And they did not disappear when Microsoft sucked you up.



LEO:  Thank goodness, yeah.



STEVE:  I remember when that happened, everyone was like, oh, my god, we're going to lose Sysinternals, no.  Microsoft's got Mark now.  And it's like, they're still around, and they're getting better all the time.



MARK:  Business as usual.  Still that's my other hobby is the Sysinternals tools.  Still working on those.  Thanks for having me on the show.  It's been fun.



LEO:  Nice to meet you, Mark.  Really appreciate it.



MARK:  And nice meeting you, Leo.



LEO:  Take care, bye bye.  Mark Russinovich, Russinovich.com.  And then Sysinternals is still on the Microsoft.com site if you just Google "Microsoft Sysinternals."



STEVE:  And people can...



LEO:  I should have asked him if he's updated.  We'll ask tomorrow if he's updating them because I think, I don't know if there's a Windows 8 version.



STEVE:  I remember looking at one of them not long ago, I needed something, and it was there, and it was current.  It was at least Windows 7 current.



LEO:  Good, good.



STEVE:  And it was like, oh, thank goodness, this stuff is still around.  So, yeah, just some of the best tools there are.



LEO:  Yeah, Part 2 tomorrow.  We're going to take a break, come back with more Steve Gibson and security news.



STEVE:  Yup.  We had a very, very busy week.  This was nominally a Q&A week.



LEO:  Right.



STEVE:  But I thought with Mark and with so much news to talk about, once again we just don't have a chance to get to questions.  So I did download 289 pieces of email this morning, but you have another week to send more stuff in to GRC.com/feedback, and we will do that next week.  Today, for the second half of this podcast, we'll catch up on the week's news because there was a lot that happened.



LEO:  Excellent.



STEVE:  I did find, I ran across a really neat note from someone named Philip Cooke that I just wanted to briefly share.  He had a success, not surprisingly I guess, with SpinRite.  He said, "A week ago I started my day with a Blue Screen of Death, advising that I had an unmountable boot volume."



LEO:  Ugh.



STEVE:  "Efforts by a Dell tech only led him to the conclusion that we should reformat the drive and lose all my data.  Nothing would recognize the drive, and all of the chkdsk commands in the book could not even see it or result in anything but the same blue screen on every reboot.  A Maxtor utility that I ran from a downloaded file advised me to return the drive for replacement.  After getting estimates ranging from $400 to $2,700..."



LEO:  Huh-ho.



STEVE:  Which is, unfortunately, it's typical because they often - it's like a manual process to do this.  "...[T]o recover my data and trying numerous other tricks recommended by online chats, et cetera, I was fortunate to come across SpinRite.  At first the glowing testimonials seemed just too good to be true, and I will admit that I thought they may have even been fake.  So I invested the $89, downloaded the file, and fired it up.



"At first I thought that it was going nowhere 'cause after four hours it still said 2 percent complete.  I figured I would leave it running over the weekend.  And imagine my surprise when I came back this morning, saw the message that it had completed.  It booted up, ran chkdsk, and then started Windows.  All I can say is wow.  Thank you for taking the time to create this program.  It's bad enough losing data, but I also saved the hours it would have taken to recreate my desktop, links, et cetera.  Needless to say, I am impressed.  Philip Cooke."  So...



LEO:  Yay.



STEVE:  Yay.  Thank you for sharing that, Philip, with me and our listeners.  So, okay.  Well, Mark is not involved in IE security.



LEO:  That's an important thing to say right upfront.



STEVE:  Yes.  There is a serious, all abuzz this week is a, I mean, Microsoft warning, sending out emails warning about a new zero-day IE exploit that was found in the wild.  It was discovered by a researcher monitoring some servers that were known to be used by bad guys.  He discovered this on Friday, and it has since been found in the wild.  The Rapid7 guys who manage the Metasploit framework have - they dove in over the weekend and have already updated Metasploit to demonstrate this.



Microsoft has no really good answer at this point.  This affects all versions of IE that are current, that is to say, not Window 8 and IE10, but IE9 and earlier, across all versions.  Apparently the exploit that's in use now is aimed at XP, but there's nothing that prevents it from being used on Vista and 7.  And in fact exploits have been developed, I think the Metasploit framework instance is even more effective than the one that's out in the wild.  So what the one in the wild is doing is installing the Poison Ivy trojan that we've talked about many times, the so-called RAT [Remote Access Trojan]...



LEO:  I like the name.



STEVE:  ...the remote takeover trojan.  Now, Microsoft's only response has been - they're not telling people to switch to Chrome.  They really can't say that.



LEO:  [Laughing] That would be a good answer.  Hey, you know, you might just want to use Chrome for the time being.



STEVE:  Yeah.  They're telling people to install EMET, the Enhanced Mitigation Experience Toolkit.  The problem is that's not always effective, either.  And it can represent problems in corporate settings and in the enterprise where it conflicts with other things.  So everyone's sort of holding their breath.  The real solution for our listeners has probably already been taken, which is no one is using IE for their main surfing all the time anymore.  They're using it periodically, when necessary, to run Windows Update, if they're running Windows Update through their browser, or only when necessary.



Hopefully people have already taken the advice Microsoft can't give and switched to Firefox or Chrome, and then you don't have this problem.  This is enough of a problem, and this next second Tuesday of October is far enough away, that is, the 9th, that we're - and Microsoft did react to this immediately.  I was impressed with how quickly they were on the ball with this, when you consider this was only discovered on Friday, and I was getting mail Monday morning, two days ago, saying there's a problem.  Unfortunately, we don't really have a good solution.



So October 9th is their next opportunity for their regularly scheduled in-band update.  I don't know if they can be ready in time.  Maybe they'll be ready sooner.  So we'll see.  But really the only thing you can do is stay away from IE, or I guess you can crank the security all the way up so that IE won't run scripting.  That is one of Microsoft's recommended mitigation measures.  Of course...



LEO:  Should probably use it anyway; right?



STEVE:  Yeah.  Increasingly, things don't work on the 'Net.  In fact, you can't even do Windows Update if you follow Microsoft's advice for making IE secure because it requires an ActiveX control and scripting in order to work.  So just don't use IE.  It's just - it's got to be your...



LEO:  Even IE8, even IE9, even IE10, even...



STEVE:  Yes, yes.  No, no, not 10.



LEO:  10's not out yet.



STEVE:  10's not out, and Windows 8 is not out.  And it is not - the betas...



LEO:  Are not vulnerable.  Oh, okay.



STEVE:  Yes.



LEO:  Well, that's good news.



STEVE:  So whatever this is - and there are very little details.  I've not bothered to go, you know, this is the exploit du jour.  So I can't spend much time figuring out...



LEO:  Yeah.  Nobody has time to read about all the flaws in Internet Explorer, it's...



STEVE:  There'll be another one tomorrow.



LEO:  ...a full-time job.



STEVE:  Now, LastPass has just added an interesting service.  They call it the LastPass Sentry service, which is, interestingly enough, opt-out for all LastPass users who are at the paid level, either premium or enterprise users.  So if you're just using the LastPass completely free, this is not available.  But if you're a LastPass premium, if you've given LastPass some money and are a premium user, then what LastPass is doing for you, and by opt-out I mean that you're in now unless you tell them you explicitly don't want this, is they've made a deal with a group called PwnedList that are - this PwnedList group are aggregating all of the publicly leaked usernames and passwords.  They currently have a list of 24 million of these.



And so what LastPass is doing is making a daily check of their paid LastPass users' account email addresses against this master list.  And LastPass will proactively notify any of their paid premium and enterprise users if at any point their LastPass account email appears in the PwnedList, which is very cool.  They have interesting future plans because of course the first thing I thought was, well, that's nice, except here we've recently been telling people don't use one email address for everything because we know that that could be a problem.  That was essentially what bit Honan with his problems.



So many of us have deliberately custom or differing email addresses.  And but that's not our LastPass account email.  In fact, we may explicitly have, for security, the high-value email is different than others.  So we would like to know if those are leaking.  Well, they say that they're working toward providing local verification of users' entire database of LastPass data against public leakage.  To do that, that would mean that there would be an agent which was added to the LastPass scripting, the JavaScripting which is running in our local browser since, I mean, I haven't thought this all the way through.



They would be, I mean, I guess they could hash everything and send hashes up and then check that.  Or our own machines could be checking against a list through a service that they provide, which is what I'm guessing they would do, is they would take all of the email addresses that they see, well, email addresses and usernames that we have in our locally stored LastPass in-browser database, protect that so that our security is preserved, and then presumably they would provide an API in their servers that allowed our browsers to check those in a secure way against this master PwnedList.  So it wouldn't be just the LastPass master account that was being checked, but all of the email addresses and usernames that we use with LastPass.  So that's very cool.



Oh, and they're also saying that they're working - that their plans are at some point to work toward increasing the frequency so that it's much more frequent than once a day, more towards something closer to real-time.



LEO:  Wow, that's neat.



STEVE:  So, very neat.  Now, Symantec - this really comes perfectly on the heels of what Mark was talking about with his novels.  And he's off the line now, so I'll just say to our users again, I mean to our listeners, they're really good books.  I mean, I can't imagine anything more interesting to the listenership of Security Now! than what Mark wrote because it is everything we have talked about, set in a - here's the way the stuff would be applied and how it escapes detection.  It's really neat.  And as I was reading book No. 2, "Trojan Horse," I was thinking, wow, this is just so perfect for our podcast listeners.  So it's really - it's fun.



But speaking of nation-state scale stuff, which is clearly one of the focuses Mark has had from his perspective, Symantec just produced a 14-page paper which I posted a link in my Twitter feed yesterday.  And we are now - I've got this in the show notes.  And, Leo, you have a person who is posting the show notes somewhere.  Is this - I've never...



LEO:  On the wiki:  wiki.twit.tv.



STEVE:  Okay.



LEO:  Every show, theoretically, on the wiki has show notes.  But it's all volunteer.  And so I had been posting stuff up there.  I've given him all the notes for the past year's worth of episodes, and I think he's getting them all up there bit by bit.  So I'm very grateful to our volunteers.



STEVE:  Well, I did have a number of people, or maybe one person multiple times...



LEO:  Probably that.



STEVE:  ...tweeting me, asking me, couldn't find some stuff that I had referred to in the last week or two.  So I do want to explain that I produce notes with links to everything in them.  And we're now, since Leo's got a neat volunteer who's going to be moving those into the wiki, I would recommend to everyone, take a look at the TWiT wiki in order to find these.  But also my Twitter feed has it, in this case.  Anyway, it's a 14-page...



LEO:  He's still catching up, I think.  So it looks like he's got quite a ways to go still.



STEVE:  Maybe he could start on the most recent ones and work backwards.  If that makes sense.



LEO:  I will suggest that.  I don't know where he's putting them, now that I look.  Anyway.  All right, so we'll see what's going on.



STEVE:  Okay.  So this is gripping.  And again, I tweeted it because it's a fantastic, another fantastic sort of real-world, bring-this-down-to-reality look at what's going on.  And Leo, I think on page 9, if you want to put that onscreen, there is an amazing graph that Symantec has pulled together.  I'll just read their overview because it gives you sort of a chilling sense of what is actually going on.  And this is not a Mark Russinovich novel, though it is just like one.  They said:



"In 2009 we saw the start of high-profile attacks by a group using the Hydraq" - and then they said "(Aurora)."  And we remember Aurora being referred to as what was - I think it was the Google attacks, and maybe the RSA attacks were the Aurora trojan horse.  "Symantec has monitored this group's activities for the last three years, as they have consistently targeted a number of industries.  Interesting highlights in their method of operations include the use of seemingly an unlimited number of zero-day exploits; attacks on supply chain manufacturers who service the target organization; and a shift to 'watering hole' attacks."



This is the first time I had seen that term.  We've talked about phishing attacks, where someone is, like, spear phishing, where you know who you want to compromise, so you send them emails containing links or documents which will directly lead to their machine being taken over.  A watering hole attack is Symantec's term, and I think it's going to catch on because it's a great term, where you know who you're trying to target.  But rather than going after them, you are able to anticipate the websites they are likely to visit.



LEO:  Like a wildebeest, which returns again and again to the watering hole on the desert veldt.



STEVE:  Exactly.  So the predator lays in wait at the watering hole and attacks at that point.  So they say the "watering hole attacks compromising certain websites likely to be visited by the target organization.  The targeted industry sectors include, but are not restricted to, defense, various defense supply chain manufacturers, human rights and nongovernment organizations (NGOs), and IT service providers.  These attackers are systematic and reuse components of an infrastructure we have termed the 'Elderwood platform.'  The name 'Elderwood' comes from a source code variable used by the attackers.  This attack platform enables them to quickly deploy zero-day exploits.  Attacks are deployed through spear phishing emails and also increasingly through web injections in watering hole attacks.



"Although there are other attackers utilizing zero-day exploits, for example, the Sykipot or Nitro or even Stuxnet, we have seen no other group use so many.  The number of zero-day exploits used indicates access to a high level of technical capability.  Here are just some of the most recent exploits that they have used."  Then Symantec enumerates four that we've talked about over time:  Adobe Flash Player Object Type Confusion Remote Code Execution Vulnerability, Microsoft IE Same ID Property Remote Code Execution Vulnerability, Microsoft XML Core Services - remember when that was happening a few months back - and Adobe Flash Player Generic Remote Code Execution Vulnerability.



LEO:  There's so many.  How can we count them all?



STEVE:  Oh, god.  It says, "In order to discover these vulnerabilities, a large undertaking would be required by the attackers to thoroughly reverse-engineer the compiled applications.  This effort would be substantially reduced if they had access to source code.  The vulnerabilities are used as needed, often within close succession of each other if exposure of any of the vulnerabilities is imminent.  The scale of the attacks, in terms of the number of victims and the durations of the attacks, are another indication of the resources available to the attackers.  Victims are attacked, not for petty crime or theft, but for the wholesale gathering of intelligence and intellectual property.  The resources required to identify and acquire useful information, let alone analyze that information, could only be provided by a large criminal organization, attackers supported by a nation-state, or a nation-state itself."



So in this 14-page report which, again, I recommend our listeners take a look at, I think anyone would find it interesting, Symantec details the structure that they have tracked down over three years and how the specifics of the attacks which might look disparate on the surface, you might not easily note that these things are connected, they found the connections and built a connectivity graph showing how all of these pieces spread over the years are associated with each other.  And they've also noted, based on the time, the windows during which the attacks were deployed, when the zero-day vulnerabilities were found, and when backtracking from the next attacks backwards, what they've been able to deduce is that, shortly after a zero-day vulnerability is discovered and patched, the entire platform immediately deploys the next one, as if they have an inventory of these things.



LEO:  Isn't that amazing.  Wow.



STEVE:  Yes.  So, I mean, here we are, from our perspective, talking about, okay, what happened this week and what happened last week.  It all just sort of seems like salt coming out of the shaker, bouncing around chaotically without any connection.  But at least in this case Symantec, by looking carefully at these and noticing things like common variable names and common deployments, they've got - they got a Shockwave Flash file which there appear to be automated systems in place for, like, compiling exploits into this Shockwave, this generic Shockwave Flash package that allows them to quickly - and again, this is all about windows of opportunity.  We understand that there are moving targets, that there are people looking for malicious connections and malware, so it's all about time, how quickly can you get in and suck things out before the window is closed, before you're discovered, and you then need to come at it in a different direction.



And interestingly, some of their advice for, for example, defense contractors, is you really need to look at your suppliers because what they're seeing is they're seeing that the one or two steps away suppliers, who have relationships with the contractors they're actually targeting, the suppliers who presumably have somewhat less stringent networking security, maybe sloppier management of their own websites and so forth, they represent points of entry into the network that then allows them to piggyback in on the relationship the supplier has with the contractor.  I mean, and this sounds like science fiction.  But there's a map of this in this PDF.  So it's just, I mean, this is going on.  And so there is reference to China.  This does sound like a nation-state that has a formal program assembled.  And what's bizarre is this is a chunk of Mark's book.  Even though...



LEO:  Oh, really.  How interesting.  He called it.



STEVE:  Yeah.  I mean, again, I read this three months ago in his book.  And I'll say again, I am amazed that he put together "Zero Day" in '06 because Stuxnet was happening just a couple years ago.  It's like, whoa, okay.  Which really...



LEO:  He didn't have prior knowledge, I don't think; right?  But it just - it was - you think?



STEVE:  No.  No, no, no, I don't think so.  I think that...



LEO:  He just saw it coming.



STEVE:  Well, and you've heard me do the same thing.  If you understand the technology, you know what's going to happen.  I mean, you can just say, okay, this is going to happen.  And there have been a number of times when that has come true.  And so he gets it, too.  He understands the technology.  He realizes where the weaknesses are.  And I thought he did a good job of sort of characterizing at the legislative level the tension that exists.  The shuttle software, the U.S. shuttle program, had to be absolutely bug free.  And we can do that at an incredible expense.  Software that's being produced commercially, eh, you know, it can get updated.



LEO:  We'll fix it in post.



STEVE:  Yeah.  The cost of making it perfect goes exponential.  You hit the hockey stick where, to make it incrementally better, you've got to spend amazingly more money.  You will get something for it, but is it worth it?  And then there's of course ever-present time pressure and competition, who eats your lunch because they're producing sloppy code faster, yours is better, but they're getting the sales that you're not.  So it's not a perfect world.



Anyway, I'd really, if somebody wants to have charts and graphs and numbers rather than generalities, Symantec has put together an amazing piece of work.  Oh, it looks like it's on - it's Fig. 6 on Page 7, Leo, is a graph of what they've actually found of the way all of this ties together.  And they've put together a beautiful paper.  So I wanted to recommend it to people.



Speaking of foreseeable problems, for the last couple months BMW has had trouble.  Theregister.co.uk, in their typical inflammatory but factual fashion, they had a post recently titled "Got a BMW?  Thicko thieves can easily nick it with $30 box."  And they said, "BMWs and other high-end cars are being stolen by unskilled criminals using a $30 tool developed by hackers to pwn the onboard security systems.  The new tool is capable of reprogramming a blank key and allows non-techie car thieves to steal a vehicle within two or three minutes or less.  Onboard diagnostics (OBD)" - which is a term, an acronym we're going to be hearing in the future.  "Onboard diagnostics bypass tools are being shipped from China and Eastern Europe in kit form with instructions and blank keys, says a news report linking the release of the tool to a spike in car thefts in Australia, Europe and elsewhere during 2012.  Would-be car thieves need to grab the transmission between a valid key fob and a car before reprogramming a blank key, which can then be used to either open the car or start it, via the OBD system."



Okay, now, that's one instance.  There's a different one which is unrelat- well, it's related, but not identical.  Back in July Motor Authority magazine carried a story.  They said, "It's every car owner's worst nightmare:  You wake in the morning, grab your keys, and head to the parking lot, only to find that your car is no longer there.  While new technology such as chipped ignition keys and Near Field Communications (NFC) key fobs have made cars more theft-resistant, they haven't made cars theft-proof.



"In fact, as Piston Heads points out, European fair trade rules have opened a back door of sorts for car thieves, one that allows them to create their own NFC fob to steal a car.  We're not experts - and if we were, we wouldn't publish the info online - but it appears that all thieves need to snatch your ride is a diagnostic device that also reprograms blank NFC fobs.



"Break into a car via conventional means, access the diagnostic port" - which is typically located under the steering column - "and you can program a new blank key in a matter of minutes."  And this works on BMWs right now.  "While BMWs seem to have the highest incidence of theft via this method, models from Opel, Renault, Mercedes, Volkswagen, Toyota, and Porsche are also reportedly susceptible to fob-cloning theft.  While Britain's Society of Motor Manufacturers is working to make access to key reprogrammers more difficult, doing so may conflict with the EU's competition rules, which allow independent facilities to access all data available through onboard diagnostic ports."



Okay, so that was July.  So our update of September is, they said, "In July we brought you news that car thieves, in Great Britain anyway, had gone high-tech, stealing new cars via the use of NFC key reprogramming devices.  Instead of relying on old-fashioned methods to steal certain new cars, today's thieves just need access to the car's diagnostic port, a blank NFC key, and a key reprogrammer.



"BMW models built between 2007 and September of 2011 are the cars of choice for these thieves, and the Bavarian automaker has just announced a software fix that will eliminate the chance of NFC key theft on X5 and X6 models.  Per Auto Express, BMW dealers in Great Britain will upload the revised software to owners of affected vehicles at no charge."  Well, isn't that nice.  "While that solves the..."



LEO:  Your car's gone.  By the way...



STEVE:  We have an update for you.  If you can find your car, we'll happily give it to you.



LEO:  Find your car, yeah.



STEVE:  No charge.



LEO:  Oh, boy.



STEVE:  "While that solves the problem for owners of X5 and X6 models, it won't do anything to resolve the issue on other BMWs.  The company advises that a software upgrade is in the works for its other products and is expected to be ready within the next eight weeks.  In the interim, BMW is advising owners to park their cars in a locked garage or under the watchful eye of closed-circuit cameras."  And then in a sort of a strange, yeah, well, this would happen note, they said, "Even after the software updates re installed, expect to see a high number of break-ins of BMW vehicles."



LEO:  Why?



STEVE:  "Since the modification is transparent, thieves won't know..."



LEO:  They won't know, yeah.



STEVE:  "...which cars have been updated and which ones haven't.  In other words..."



LEO:  You should put a sign in the window.  "I've got the new firmware.  Move on."



STEVE:  "In other words, even after the fix, BMW models will still be seen as targets of opportunity, so park appropriately."  Now, I have a link in the notes I'm not going to dig deep into, but it is very disturbing, about the onboard diagnostics.  This was a presentation that Rob Vandenbrink gave to a SANS group, a SANS security presentation at SANSFIRE 2012.  Turns out that there is a set of standards, international standards for the networking technology that is across all cars.  It is a CSMA/CD, the standard sort of Ethernet Carrier Sense Multiple Access Collision Detection, which there are lots of tools for, that uses a serial protocol at, well, I think it's like 115K baud.  But it's open.  It's documented.  You can give it commands.  It tells you whatever you ask it.  And it's ubiquitous.



So when I hear you say, Leo, that Ford is really, really, really taking this seriously, I'm glad.  And I have said to people, I'm glad I have an older Beemer" that doesn't have any of this stuff in it because I don't want it.  Not probably ever.  But that's just - it's a better way to operate.  We're going to - apparently we're going to learn these lessons all over again.  So, I mean, like for example it's mandated that all new cars have to have tire pressure transmitting sensor systems, and that's RF, and that's a way into these systems because people that have engineered them haven't been willing to spend a lot of time, and they've been in a hurry, and same old routine again on our cars, which are becoming rolling networks, essentially, of small computers.  So I have a feeling we'll be talking about these things in the future.  And I'm glad Ford is really taking it seriously.



In a surprising development, Google has added the DNT technology to the latest developer build.  Do Not Track will be in Google's Chrome browser by year's end.  Google's spokesman Rob Shilkin said that the Obama administration had asked the entire industry to adopt the Do Not Track technology, and Google was complying with that request and the consensus that arose around it.  There was sort of a - I kind of got this sense, reading the whole thing, they weren't that happy about it.  But they were the last browser without it.  So they decided, okay, we'll put this in and let our users decide.



Okay.  A bunch of people tweeted this.  And we'll have details probably next week.  Do you remember, Leo, a couple years ago, that there were two hackers, one of whom was on the beach in Indonesia, communicating with a friend of his.  I think we were imagining him sipping on umbrella drinks while he was reading the TLS CBC at RFC.net.



LEO:  I remember that, yeah.



STEVE:  That was Juliano Rizzo on the beach, and his partner Thai Duong.  They're back.  They were the people who figured out BEAST, which was the Browser Exploit Against SSL and TLS.  That was a man-in-the-middle attack which they crafted by taking advantage of a weakness in the cipher block chaining, which is CBC, employed in SSL, in order to crack into secure connections.  So they now have a new attack called CRIME.  That stands for Compression Ratio Info-leak Made Easy.  



LEO:  That's a retronym.



STEVE:  Compression Ratio Info-leak Made Easy.  And I love it because what that says is that this is a classic side-channel attack.  They've come up with a way, and it's not public yet, they're putting their paper out today, tomorrow, and Friday, that is, September 19, 20, and 21, at this year's Ekoparty in Argentina.  They said that the new attack works much like the BEAST attack.  Once they have a man-in-the-middle position on a given network, meaning that they're inline in the communications path, they are able to sniff HTTPS traffic and launch the attack.



Their current implementation requires JavaScript running in the browser.  Rizzo was quoted, Juliano was quoted saying, "By running JavaScript code in the browser of the victim and sniffing HTTPS traffic, we can decrypt session cookies."  Now, we all know what that means because session cookies are the way persistent authentication is created in browser-client sessions, so that allows impersonation.  That's much like what Firesheep was doing with Firefox some time ago.  So "...we can decrypt session cookies.  We don't need to use any browser plug-in, and we use JavaScript to make the attack faster, but in theory we could do it with static HTML."  Rizzo also said that both Mozilla Firefox and Google Chrome are vulnerable to the attack.  However, the browser vendors have developed patches for the problem that will be released in the next few weeks.



Now, I saw elsewhere in researching this that browser vendors have stated they're no longer vulnerable.  So I don't know who's right.  But any browsers that support either TLS compression, which is a standard, or Google's SPDY - SPDY, of course, offers compression, as well.  Basically what these guys are doing, we've talked about side-channel attacks on crypto.  The idea is by changing the data being sent, or sending their own, with and without compression, the content is leaked by the amount of compression it gets.



So, for example, we know that completely random data won't compress much, or at all.  Pure entropy, absolutely random data, there's no pattern that a compressor can use in order to represent the same thing more densely.  On the other side, a string of 10 A's takes up a lot of space unless you encode it as there will be 10 A's following, in which case it compresses extremely well.  So the point is the ratio that you get of compression is set by the contents.  So by tweaking the contents, it must be that these guys are looking at the difference in compression and then reverse-engineering what the unknown data is by subtracting out what is known.  So a very clever attack.  I'm guessing about most of this, but that must be, if they're called it Compression Ratio Info-leak Made Easy, that's what it would have to be.



Now, you need TLS compression or SPDY in this HTTPS link.  So that would require support at each end.  Both are still relatively rare.  Some guy said, I read, "My calculator doesn't have enough zeroes to the right of the decimal point for me to tell you what percentage of traffic on the Internet is subject to this attack at the moment.  Meaning it's too far off to the right.



LEO:  Nothing, yeah, zeroes.



STEVE:  Nothing.  So not a big problem, nothing to worry about.  If anyone is worried, and you're a Firefox user, you can disable SPDY by putting "about:config" in the URL address and then hitting Enter.  That brings up the massive configuration settings for Firefox.  And then in the search bar put in "spdy," and that'll give you a nice little block of settings.  And I found mine said network.http.spdy.enabled=false and .enabled.v2 is false and .enabled.v3 is false.  So I had mine all turned off.  I don't remember why.  I think because there were some concerns about it earlier.



LEO:  You were worried, probably.  You had talked to Mark Russinovich, maybe.



STEVE:  Yeah.  So anyway, I will probably have confirmation that this is the problem.  It doesn't sound like a bad attack.  I will try to determine what's going on here between one story that says the browser vendors will soon have this fixed and then others that say they already have had it fixed.  My Firefox hasn't updated recently.  I'm 15.0.1, which is probably current.  So maybe that had it fixed, or maybe that's why I've got SPDY turned off.  Maybe that's what the point of 0.1 was, because mine was all off.  So maybe other people will find that, too.  We will see.  And I don't know how you fix this.  Maybe you pad the compression with pseudorandom data so that it's not deterministic.  That would block this.  Anyway, we'll see what they suggest.  But again, this is a very clever hack using the fact that different data compresses by a different amount to reverse-engineer the unknown portion from what is known, which must be what they've done.



And finally, before we get into a quick little bit of miscellany, our old friend John Graham-Cumming was in the news with his most recent blog post:  blog.jgc.org.  Our listeners will remember that we had John on about his neat techie book of interesting wacky tech locations scattered around the globe.  And John has been a participant over at GRC's newsgroups for years.  And what happened was there's been news, I haven't been talking about it a lot because it's sort of always in the background, of the depletion of the IPv4 address space.



One of the Twitter feeds I monitor is a big - unfortunately it shows a big atomic bomb mushroom cloud glowing red to remind us that we're running out of IPv4 space.  And there was a recent announcement that in Europe the last one was gone.  They were down, I think it was that RIPE was down to one final network.  And rather than giving people huge allocations, they were now giving them a thousand, like out of the 16 million IPv4s in this remaining /8 network.  So being very, very stingy about them.  And John somehow said, uh, you know, what about 51.0.0.0/8, the 51-dot network?  What's going on there?



LEO:  Who owns that, Steve?



STEVE:  It's registered, yeah, it's registered to the U.K. Government Department for Work and Pensions.



LEO:  I saw this.



STEVE:  And, you know...



LEO:  How many addresses is that, Steve?



STEVE:  That's 16+ million addresses.  And they're not - they say it's in use.  But it's not public.  So they're using it like a 10-dot network.  They're using it as their own privately routed nonpublic sort of LAN in the same way other large organizations use 10-dot.  It's exactly the same as a 10-dot.  I chose to use 10-dot for myself, although I hardly need 16 million IPs.  And they're saying, well, we like - we want to keep it.  And so...



LEO:  No.



STEVE:  I mean, they can't.  It's like, it's wrong.  They're saying, well, 80 percent of it is in use.  Okay.



LEO:  Just replace it with a router.  I'm sorry.



STEVE:  Well, all they have to do is change the 51 to 10.



LEO:  Yeah.



STEVE:  All they have to do.  I mean, yes, many times.  But still it is a publicly routable block that is not being publicly routed.  Well, John, as we've talked about before...



LEO:  This is like some sort of spy agency or something; right?



STEVE:  Well, he launched - remember that he launched the petition to get Turing's reputation, like, fixed because...



LEO:  And won.  He got an apology from the Prime Minister, yeah.



STEVE:  Yes, yes, a formal apology over the way they had been treating Alan Turing - posthumously, obviously.  Well, he's launched another one.  There is now a petition in the works to bring to light and to bring pressure on - I'm sure that he's not real popular with them right now - to bring pressure on this Department for Work and Pensions to give up their 51-dot, huge, I mean, okay, that's one - that's more than one 256th of the entire Internet.  So is it 16 million, or is it more?  It's going to be 2^24.



LEO:  Oh, that's a lot.



STEVE:  Yeah, that's more than 16 million.  That's two to the - I think I was doing - well, no.



LEO:  That's trillions, isn't it?



STEVE:  No.  2^24, okay.  Here's a little math.  Oh, yeah, I was right, 16 million.



LEO:  16.8 million.



STEVE:  So that's a huge block.  And they can't keep it because it is...



LEO:  It's needed.



STEVE:  Yes, we need it.  And it's not, well, I mean...



LEO:  And they don't need it.



STEVE:  As soon as it - exactly.  They're not using the public routability of it.  They're using it like a private network, their own little private network.  All they have to do is change all of those 51s to a 10, and everybody will be happy.



LEO:  It'll be a little messy.



STEVE:  Be a little messy.



LEO:  But that's all right.  I wonder if there are other blocks like that out there.  Do you think?  Do we know?  Because that's just such an egregious example.



STEVE:  I know that HP had, like, it had 14 and 15, even recently.  And but maybe they can make a convincing case for their using it.  So I just wanted to make a little miscellaneous category.  "Revolution," the new J.J. Abrams future power outage global sci-fi series started on Monday, and the jury is out in my case, in my instance.  I read a couple very negative reviews.  I'm less negative about it.  We'll see how it turns out.  It's too early to say.



LEO:  I like the premise.  I love dystopian future, the world is, you know...



STEVE:  Yeah.  The acting seems fine.  The people are interesting.  We were teased at the very end.  I mean, there is a definite, okay, what is going on...



LEO:  Kind of Hunger Games-y in the plot, it seems to me.



STEVE:  Yeah.  Yeah, that's a very good point.



LEO:  Somebody said, hey, that "Hunger Games" movie, that's real big.  What can we do that's like that?  What have we got in the bin?



STEVE:  Yeah.  Hey, J.J., you know...



LEO:  Hey, J.J., can you crank something out?



STEVE:  Yeah.  And lastly, for anyone who is interested in what we've been talking about recently in multifactor authentication for their own websites, I ran across an implementation of Google Authenticator written in HTML on GitHub.



LEO:  What?



STEVE:  Yes.



LEO:  Wow.  JavaScript or HTML?  Must be JavaScript.



STEVE:  Don't know what it's in at that end.  But probably if you Google "html5-Google-authenticator," or maybe not even put the dashes, and it is at GitHub, you'll find it.  And I just thought it looked nice.  And so anyone who's interested in dropping that into their own website to allow for Google Authenticator-compatible authentication...



LEO:  Wow, that's awesome.



STEVE:  And I'm sure we're going to see a lot of that.  But I just wanted to point our listeners at it.



LEO:  That's neat.



STEVE:  Yeah.



LEO:  That's it?



STEVE:  That's it for today.



LEO:  That's all she wrote?



STEVE:  That's it for today.  That's our news.  And we had Mark.



LEO:  That was great.



STEVE:  And we will do Q&A next week.  So by all means, if you've got any questions, GRC.com/feedback.



LEO:  If you're just tuning in late, go back and listen to the beginning of the conversation.  And Mark will be back for Windows Weekly tomorrow, which is a coincidence.  But I have a feeling we'll talk more about Windows.  I don't know.  Maybe we'll talk about the books.  I don't know.  Don't know.



STEVE:  And I'm jealous he's going to have a good microphone for that, for Paul's podcast.



LEO:  Yeah, thanks, Lou.  Lou's running it over from the other side of the campus.  Steve is at GRC.com.  That's where he keeps SpinRite.  He hides it there, the world's finest hard drive maintenance and recovery utility.  Hey, the Ford Motor Company has 19.0.0.0/8, according to Sidera.



STEVE:  Wow.  I wonder about these companies that have such massive, I mean...



LEO:  Well, they have a lot of employees, and they're all over the world.  But do they need it publicly routable, is the question.



STEVE:  Yeah, exactly.  And once upon a time it was easy to do.  I mean, we're going to go through a period of anxiety.  The rebuttal, not surprisingly, from the U.K. group, this U.K. Government Department for Work and Pensions, their rebuttal was, hey, IPv6.  That's what it's for.  Go use that.



LEO:  Right.  Yeah.  Well, they're right.  I mean, we need to move.



STEVE:  Yeah.  Sooner or later we won't have...



LEO:  But we don't need them to kick us in the butt to do it.  I mean, come on, guys.



STEVE:  And then the question is, in order for an organization like HP or Ford to give up their IPs, first of all, Leo, you are 100 percent right.  They do not need publicly routable IPs.  I mean, really only servers need publicly routable IPs.  Everybody else can come out of a smaller pool of NATed IPs, which is, for example, what ISPs are doing now, which is what we all do in our home networks.  We've got one IP publicly, and a bazillion inside our homes.  So that scales in a hierarchy beautifully.



Now, of course there are Internet diehards that are - hopefully they're not dead yet, I was going to say turning over in their graves to hear me.  But they're, like, moaning because they bemoan the whole notion of NAT.  The original purist concept was one IP per machine, and every machine will be accessible by every other.  Yeah.  Well, that was before firewalls and before nation-state-supported crime rings of very, very good hackers began to happen.  But my point was, if a company did want to give up some of their excess space, what they would need to do would be to move their allocation all - sort of compress it to one end of their network block.  Essentially, they would, for example, if Ford was - was it 17?  Don't remember what number it was.



LEO:  Yeah, what number, yeah.



STEVE:  Anyway, I know that HP, for example, has 14 and 15.  If you took - or say the U.K. Department for Work and Pensions.  They've got 51.0.0.0.  There's no way they have, they need 16 million IPs.  They couldn't have 16 million  machines in the Department for Work and Pensions, no matter how bloated their bureaucracy is.  So all they would have to do would be to move those, if they didn't want to switch to 10-dot, move them all to one end.  So that right now, for example, there might be 51-dot, and then rather than 0, they might be using 0 and 1 and 2 and just sort of have come up with a very, oh, look, we've got 16 million IPs, we'll use 51.1 for this location, 51.2 for this location 51.3 for that location.  And the idea being that, if the squeeze that down so they're only using, for example, 0, then that would free up 51.1 through 255.  And they could keep their little 51.0 network, which is a small fraction of the total 51-dot Class A network.



They would essentially have a Class B network.  And that would be a compromise.  It would free up the bulk of their allocation.  And of course that scales.  They might have 51.1, .2, and .3, but be able to cram all of their allocation down into, like, three Class B networks.  And then, again, release their allocation for the balance.  So I think we're going to see some back-and-forth and some tension as people resist the move to IPv6 just because it's not easy.  It does require equipment and firmware and routing upgrades and so forth.



LEO:  General Electric has 3.0.0.0/8.



STEVE:  Yeah.



LEO:  IBM uses 9.0.0.0/8 for internal IPs, supposedly.  So there's a few out there.



STEVE:  Yeah, well, but once upon a time, Leo, 4 billion.  We're never going to use 4 billion.



LEO:  We're not going to use all those.  No sirree.  Steve Gibson is at GRC.com.  That's where SpinRite is, and of course your chance to ask questions for next week's episode, GRC.com/feedback/8.  No, no /8.  He also has lots of free stuff there, including SpinRite, the world's - oh, I said that.  Oh, ShieldsUP!, Shoot The Messenger, DCOMbobulator, all those other free things.  Password Haystacks, all of that stuff.  GRC.com.  And 16Kb versions of this show in audio for the bandwidth-impaired; text versions, transcriptions by the great Elaine.  We have the video and the high-quality audio over at our site, TWiT.tv/sn.  But you're still putting show notes at your site, right, Steve?  GRC.com?



STEVE:  I have not been doing show notes.



LEO:  Oh, okay.  Okay.



STEVE:  For a long time.



LEO:  We'll get our wiki guy on it.  We'll get him up to date.



STEVE:  That would be great.  And the transcripts that we have really come in handy because, as I was reading about the new CRIME attack, the Compression Ratio Info-leak Made Easy, I thought, Juliano Rizzo.  Wasn't he on the beach somewhere developing the...



LEO:  And the nice thing is it's text search; right?  That's the...



STEVE:  Yeah.  So, like, I went to GRC.com/sn, which bounced me to /securitynow.htm.  I put - I think I might have put "beach" into the search box, and up came...



LEO:  Lo and behold.



STEVE:  Oh, no, I think I put "Rizzo" in because I knew his name.  And sure enough, there were three hits on that, and one took me to Elaine's transcript from the time we were talking about the BEAST attack.



LEO:  Fantastic.



STEVE:  So it's easy to find those things here.



LEO:  All right.  We're going to sign off.  Coming up, This Week in Google, Jeff Jarvis in-studio with us.  We will see you next Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time.



STEVE:  Yup, for a Q&A.



LEO:  A Q&A.  Steve Gibson.  Thanks for joining us.



STEVE:  Thanks, Leo.



LEO:  See you next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#371	

DATE:		September 26, 2012

TITLE:		Listener Feedback #151

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-371.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 371, recorded September 26th, 2012:  Your questions, Steve's answers, #151.



It's time for Security Now!, the show that protects you and your loved ones and your privacy and all that jazz online with this guy right here, our Explainer in Chief, our security guru, Mr. Steve Gibson of GRC.com.  Steve was of course the guy who discovered spyware in the first place, coined the term "spyware," wrote the first antispyware app.  He's also the author of SpinRite, the world's best hard drive maintenance utility, so he's an expert on hard drives.  Joins us every week.  I don't really need to introduce you except there may be some new people in here listening.  We welcome you all.



STEVE GIBSON:  I know that we do get new people from time to time.



LEO:  Oh, yeah.



STEVE:  I think probably we have - certainly we have people who are dedicated long-time listeners.  But there's also some churn.  There are people who get busy and sort of drop off the roles, and new people coming along.  There was a question that I selected today about SSL authentication and man-in-the-middle stuff.  And I thought, well, we've discussed it, but it keeps coming up.  And so that says to me it's an important issue, and it's worth giving it a little bit of time.  And I always try, even for the people who believe they know this as well as I do, and very well may, try to come up with some new information, even when I readdress things that we've talked about before.  So I think I have that.  And, boy, we had a busy week.  Some weeks, not so busy.  This week, lots of fun stuff to talk about.



Of course, two days after we recorded last week's episode with Mark Russinovich - which we got a great bunch of great feedback about, by the way, everyone really enjoyed having Mark on.  So that was neat.  Two days after that, Microsoft did release a formal patch for Internet Explorer, which they pushed out through - this is an out-of-cycle patch they pushed out through their Windows Update facility.  So we were talking about this bad vulnerability that IE had.  And at the time there was only the little Microsoft Fixit deal that would shut that down.  And, wait, no, I'm confusing myself.  That was different.  This one they were recommending the enhanced experience security, that EMET deal, which it turns out didn't really close it down very well.  So the only real advice was don't use IE.



So as a consequence of this and the fact that this was being actively exploited in the wild, they pushed out an out-of-cycle patch.  It fixed not only that, but four other privately reported vulnerabilities.  They wrote that the security update resolves - I'll paraphrase.  The security update resolves one publicly disclosed, which is the one we've been talking about, and four privately reported vulnerabilities in Internet Explorer.  The most severe vulnerabilities could allow remote code execution if a user views a specially crafted web page using Internet Explorer.  An attacker who successfully exploited any of these vulnerabilities could gain the same user rights as the current user, blah blah blah, we've heard that all before.



This update is rated "critical" for IE6, 7, 8, and 9 on Windows clients and "moderate" for IE6, 7, 8, and 9 on Windows servers.  And that's because in Windows servers the Internet Explorer runs automatically within a much more constrained environment, so it can do less damage there.  And under no circumstances is IE10 affected.  Actually, IE10 is not affecting many people's lives at this point.



LEO:  It's not out yet.



STEVE:  Exactly.  So that's been taken care of pretty quickly.  However, we will in a second be discussing, well, let's jump to it right now.  I'll do this a little bit out of sequence.  We have another massive Java exploit.



LEO:  What?  Already?



STEVE:  Yeah, well, Leo...



LEO:  That was last week.



STEVE:  This is a new week.



LEO:  So this is a new one, not one you've referred to before.



STEVE:  Never referred to this before.



LEO:  Geez, Louise.



STEVE:  This is from Adam Gowdiak of Security Explorations.  And this is either their 50th or 51st exploit that they have found.



LEO:  Wow, they should have a cake.



STEVE:  Well, they ought to - Oracle should be paying them.  It's like, come on, let's get this fixed.  Okay.  So this one is really significant because it affects all Java versions since 5, which is the last eight years' worth of Java, which is all of 5, all of 6, and what we have so far of 7.  And due to the back reach of this problem, they're estimating, when you update or install Java, it brags about how it's in three billion devices, and then it goes and tells you all the things.  It's, like, in your shoes and all clients everywhere.  So the estimate is, due to the back reach and the depth of Java's reach, maybe a billion users.



LEO:  Well, and people don't update their shoes very often, so the chances are you're running the old Java in there.



STEVE:  Exactly.  And you might get tripped up.



LEO:  [Laughing]  Nice.



STEVE:  So Adam wrote that, "The impact of this issue is critical.  We were able to successfully exploit it and achieve a complete Java security sandbox bypass in the environments of Java SE 5, 6, and 7."  Adam wrote that Security Explorations, his group, successfully pulled off the exploit on a fully patched Windows 7 32-bit computer in Firefox, Chrome, IE, Opera, and Safari.  Although testing was limited to Windows 7 32-bit, Gowdiak told Computerworld that the flaw would be exploitable on any machine with Java 5, 6, or 7 enabled.



LEO:  Now, presumably on those browsers like Chrome and Safari, it said, "I would like to run Java now.  Is that okay?"  Right?  Did it bypass that?



STEVE:  Well, if your browser asks you, then yes.  Now, this is - note also they were messing with it in Windows 7 32-bit, but also 64-bit Windows, Mac OS X, Linux, and Solaris.  So this is also cross-platform.  This is a core vulnerability in - actually it's an exploitation of Java's type management, not like...



LEO:  It's write once, exploit everywhere, as we said last time.



STEVE:  Right.



LEO:  The beauty of Java.



STEVE:  So last time they advised Oracle of a problem, Oracle ignored them for four months.  And then we had that really bad zero-day Java exploit as a consequence of Oracle sitting on their, whatever they were sitting on for those four months.  They've advised Oracle.  They've given them technical details.  They've given them proof-of-concept code.  And so we'll see how long Oracle takes to respond.  It's not clear whether what little has been divulged is enough for bad guys to go duplicate it.  But we do know that it's in Java's type management.  We know that it's been there for eight years.  So there's some clues.



We'll see now who's first, the bad guys exploiting it - well, the other thing that can happen, we're seeing evidence, as we talked about last week, of there being inventories of known vulnerabilities in the bad guys' toolkits.  And they're keeping these vulnerabilities offline and doling them out as necessary.  There's a chance that the bad guys already know about this, but haven't had an opportunity or a need for another Java zero-day vulnerability.  The news of this hitting, though, means for them that there's a window.  And so that would mean that they would immediately bring out the implementation of this in exploits, knowing that now that Oracle knows about it, there's a time limit on how long they're going to be able to use it.



That's the reality, from everything we've seen of today's cybercrime world, is that all of these web exploits are potentially known, and the evidence is that bad guys have an inventory, and they bring them out as they need them.  But learning about this, publicizing it this way, means they would be induced to use it now because they know pretty soon it's going to get shut down.  So don't...



LEO:  Has that changed, now that they do these exploit kits?  In other words, this model that you're talking about is some elite hackers who are saving this stuff, and they have a reserve and a reservoir.  But it seems like many of these exploits, especially exploits like this that take place over the web, are just being sold into kits.  And so as soon as they're discovered, they're added into a kit which bad guys buy.



STEVE:  Right.  Now, normally what'll happen is, for example, Rapid7 is the group that is managing the Metasploit kit.  And so once the nature of the vulnerability is public, then Rapid7 will immediately stick it into, I mean, in a matter of hours, stick it into a new module in Metasploit, and then it's available widely.  So that's sort of a different aspect of this.  Right now, as far as we know, no one except the Security Explorations guys, well, and Oracle, know the details of what they have found.  We have a few little clues, but presumably, well, presumably this is obscure.  We don't know yet whether this exists in someone's inventory.



But the Rapid7 Metasploit  folks probably, unless they were really motivated to go after this, they'll wait until it appears in a zero-day vulnerability.  Once that happens, then it becomes public.  So essentially their role is mass availability of something that was previously limited in availability.  And that's not good, either.  I mean, it's bad because, as you said, Leo, it turns it from something you might have to have some expertise to use into a drop-in toolkit, where it's like...



[Talking simultaneously.



STEVE:  Exactly.  And so the problem here is that eight years of this problem's being present means, for example, it's in all of our DVD players.  Now, that's not maybe a problem.  But our DVD players are now on our networks.  And so it's like, okay.  DVD players all have Java in them now.  It's one of the things that Oracle brags about.  And I notice the sticker on the box and the back panel of mine.



So there are problems with Java itself having been vulnerable this long.  So it's not necessarily just drive-by web attacks, but because of the pervasiveness of Java in devices which are not just mainstream smartphones and laptops and desktops, if bad guys had a really focused targeted desire to get in somewhere, very much like we saw with Stuxnet, where that entire enterprise was focused on one specific target, we want to mess up the nuclear enrichment program in Iran.  Similarly, there's Java all over the place.  A billion is a big number.  So this is unfortunate that a problem like this has been found which has such long legs.



LEO:  So what, I mean, do we know, is it in cars?  I mean, what kinds of devices do you think it's Java 5 or later?



STEVE:  I'll bet it's in cars.  The problem is it has been  a very popular implementation language for quite a while.  I mean, Java is in my BlackBerry.  My BlackBerry uses Java.  I mean, like as a core runtime for the BlackBerry.  So that's a problem.  And dishwashers and microwaves and just - it really is pervasive.  It is in devices of all size and makeup.  Now, if bad guys can't get to the device by its nature, then that's not such a problem.  Or if the device isn't able to do any damage if it became exploited, then that's not a problem.



LEO:  Right, yeah.  So your car's not online.  On the other hand, having it hacked would be a high-risk enterprise.



STEVE:  Right.



LEO:  Oy oy oy.



STEVE:  I think we probably haven't seen the last of...



LEO:  Heard the last, yeah, yeah.



STEVE:  Yeah, of this one.  As it turns out, the guess that I had, which was actually not a big deal because it was pretty clear from the meaning of the acronym, we talked last week about this year's follow-on to last year's BEAST exploit, this one called CRIME, from our buddies who hang out on the beach sipping umbrella drinks.  That was CRIME, which was unveiled at the Ekoparty late last week.  The acronym stands for Compression Ratio Information-Leak Mass Exploitation.  And it works...



LEO:  Nice acronym.



STEVE:  Yeah.  It's one of those, as you said, you reverse-engineer the acronym.  You say, well, let's call it CRIME.



LEO:  Yeah, retronym, yeah.



STEVE:  We have compression ratio, CR.  Ooh, information, CRI.  What ends with CRI?  Oh, ME.  Now, what can that stand for?  Oh, mass exploitation.



LEO:  Perfect.  Easy.



STEVE:  Yeah.  Works.  So this essentially creates a serious problem for Internet on-the-fly compression because, well, and so when we talked about this last week, I talked about how there had been mitigation already put in place.  Well, what that turned out to be is Chrome and Firefox both immediately shutting down compression.  Chrome and Firefox were the only two browsers which were standards-compliant enough, or you might say advanced enough, to be supporting the compression, the SSL/TLS compression that is in the spec and has been, I think since '04.  It's been there for a long time, the idea being that there is a specification actually in the SSL specification for how the endpoints can negotiate and perform compression.



So that's at the connection level as opposed to what you'd call the "application level."  The application level, the server, the browser can say, independent of the connection, I'm able to decompress using Deflate and Gzip, for example.  And then the server says, oh, good.  We're going to save bandwidth by compressing those things before we send them to you since you've said you know how to decompress them.  So that's at the application level, or at the HTTP protocol level.  It's also possible to do compression at a lower level, down at the SSL link level, essentially.



So only Chrome and Firefox ever did that.  They no longer do that as a consequence of what these guys found.  Also, SPDY used to do that, and SPDY no longer does that.  Basically, compression has been, at this level, was immediately backed off of.  Now, it's not news that compression can leak information, that is, sort of generically.  It's been well understood for many, many years that compression and privacy were at odds with each other for exactly the reasons I explained last week, which is because the amount of compression you get is a direct function of what you're compressing, if the bad guys have any control over what is being compressed, that allows them to probe for what they don't know, what they don't have control over, which they're trying to determine.



So in this attack they arrange to put their own data in front of unknown data and then compress the entire packet.  If what they're putting in front is very similar to what they don't know is behind, it compresses highly because the compressor sees that it's already seen something similar.  So instead of storing it again, it just points to what it's already seen.  Thus you get the compression.  So by fiddling around with injecting their own data in front of the unknown, for example, cookie in an HTTP transaction, they're able with surprising efficiency, it takes about six transactions, to decrypt one byte of cookie value.  So doesn't take a long time.  They're able to crack cookies which are being used for sessions and then hijack a session.



So for the moment the industry needs to rethink this.  It's going to be necessary to add some protections in order to put compression back into our links.  Compression is something we want.  It's tremendously efficient, especially when you're compressing, like, big web pages where they're just a huge amount of redundancy.  You've got English in large blocks of text.  You've got all that HTML representation, which is highly redundant.  You get a huge gain in compression.  But as we've seen, it's also possible, I mean, as we now know, this is something that went from a theoretical problem in information theory, like, oh, compression and privacy are at odds, to, hey, that's true.  Here's how you use that fact.  And these guys have.



So what's happened is the browsers have all backed off of this in order to protect us so that we listeners, users, don't have to do anything.  The browser manufacturers have already taken care of it.  This all got shut down before this went public, so we're safe.  And the problem is well understood, very clear now.  And I would imagine at some point we will come up with some solutions.  So, you know, really, really interesting attack.



LEO:  Yeah, no kidding.



STEVE:  Just another one of these where...



LEO:  Clever.



STEVE:  ...it's very clever, and it's difficult to foresee these problems.  But once they're made clear, we know how bad they are.  A lot of news, I guess grumbling maybe is the right term, for an error message or a warning message or an advisory message that Microsoft's Hotmail began delivering since we last podcasted.  People logging into Hotmail received a surprise notice that said:  "Microsoft account passwords can contain up to 16 characters."  And here's where it gets good.  "If you've been using a password that has more than 16 characters, enter only the first 16."  Well, okay.  Our users know what this means.



LEO:  It means they're not hashing; right?



STEVE:  Well, it means - we don't know for sure.  So here's what it could mean.



LEO:  I mean, 16 is a lot.  So it's not like it's too short.



STEVE:  That's my feeling, too.  16 well-chosen wacky characters is more than enough.  So that really wasn't the issue.  It's what does this mean about what Microsoft is doing.  So what we know is that you're able to enter only the first 16 and log in, even if the password you had been entering was longer.  So passwords may have been stored in plaintext, and now only the first 16 are being checked.  And I'd be surprised if that were the case, but it's certainly possible.  Remember that Microsoft bought Hotmail, acquired it at some point, after it existed.



LEO:  But they rewrote it because it was running on Apache.  It was a LAMP stack app.



STEVE:  True, true.



LEO:  And they rewrote it to work with .Net.  So they probably...



STEVE:  Although in rewriting it they, as far as I know, didn't force everyone to revamp their passwords.



LEO:  Well, they must have maintained the system, that's right.



STEVE:  They may have, yeah, left that legacy stuff in place.  So maybe they were stored in plaintext, and now only the first 16 are being checked.  Or they may have been stored in plaintext, and Microsoft recently decided to switch to hashing.  And look at the news, I mean, all of this leakage of plaintext passwords.  Imagine that Hotmail had been in plaintext, and they said, oh, we've got to hash these passwords.  So what they could have done is decide to switch to hashing, but for some reason - seems arbitrary to me, but Microsoft sometimes is inscrutable in their thinking - maybe they decided to only use the first 16 characters in their hash.  So that's a possibility.



Or they were always hashing only the first 16 characters, and now Microsoft is just informing people.  That is, they may have always been throwing more than 16 away and just decided, well, we ought to just - I mean, the wording of this, "Microsoft account passwords can contain up to 16 characters," this feels to me like it's broader than just Hotmail, like Microsoft's trying to - because they've got SkyDrive, and they've got all these - they're in general going cloud mode.  So there are other ways and things that Microsoft's users will be logging into.  So maybe they're trying to unify this, and Hotmail was sort of weird compared to the way they were doing other things, and so they're trying to pull it all together.  Anyway...



LEO:  It does have two factor; doesn't it?  Or maybe not.  I have to look.  They're moving everybody to Outlook.com instead of Hotmail anyway.



STEVE:  Right.



LEO:  BSD, by the way, not a LAMP stack, my apologies.



STEVE:  So what we do know is that, given their ability to log people in with only the first 16 characters, it could not be that the entire length of the user's longer passwords were being hashed because they would have a hash for the whole thing, and there's no way then, by virtue of the strength and power of hashing, there's no way for Microsoft to know what the hash would be for only the first 16 characters.  So we do know that they were not hashing the user's entire passwords historically.  They were either in plaintext, or they were only hashing the first 16 characters.  Or they were always only doing that.  They may have switched to that, or they may have always been only hashing the first 16 characters, and now just sort of letting people know, don't bother typing any more, you're not getting any better security.  I don't know.  But people got upset.



Also, there was a little mistake that was discovered in Samsung phones.



LEO:  Yeah.  The GS3 that I use, as a matter of fact, yeah.



STEVE:  Yeah.  So it was a flaw in Samsung's, what they call their "TouchWiz" software.  So, first of all, this is only Samsung phones and not the pure Android phone, so not the Nexus.  Only some Galaxy S2 and S3-class phones were susceptible.  And in some cases this depends upon which firmware version was running.  Samsung has since updated their S3, the Galaxy S3 firmware to fix the problem.  But some S2 models may still be at risk.  And also apparently the Galaxy Ace and the Galaxy Beam are also affected.



Okay, so what's going on?  The vulnerability is the result of the way the native Samsung dialer app handles what's called USSD codes and telephone links.  USSD codes are special combinations of characters that can be entered in the keypad to perform certain functions.



LEO:  You know, those have always made me nervous.



STEVE:  Yeah, and it turns out that they just had a bunch that were not documented.  It's like, okay.  So, and here again, this is just pure obscurity, which is never a good  idea, especially when something is this simple.  So these were, like, enabling call forwarding, accessing hidden menus on the device...



LEO:  Some of these are known.  I mean, when you do call forwarding, Google Voice, for instance, will tell you what to, you know, the weird thing to enter.  And there's also there's usually a service mode and things like that.



STEVE:  Yeah.  So on Samsung phones, turns out there's a USSD code for factory resetting the phone.  Oh, and also presumably another one for nuking the phone's SIM card.



LEO:  Oh, wow.



STEVE:  Since that's been reported to be possible, as well.



LEO:  Oh, my.  And there's no check.  It just does it.



STEVE:  Nope.  It requires no user interaction.  It doesn't pop up and say, are you really sure you want to factory reset your phone?  Who knows why they did it this way.  They just thought, oh, well, no one'll find out about it.  And maybe...



LEO:  And I'm sure it's long and obscure, but that doesn't mean anything.



STEVE:  No, no, no.  Star pound zero six pound.



LEO:  That's it?



STEVE:  That's it.  Don't type that, anybody.  Don't enter that into your Samsung phone.



LEO:  Oh, my goodness.



STEVE:  That's all it is.  So, okay.  The good news is there is a test.  Oh, I should mention that what's bizarre is that, on top of all of that, so that's if you are using the native dialer, well, it turns out that for various fancy easy-of-use purposes, it's possible for other Samsung apps to forward those to the dialer.  As a consequence, QR codes, NFC events, and URLs dropped into the standard browser will invoke the dialer and can maliciously give it that code and wipe your phone completely, immediately.



LEO:  So they could text, send you a text message that would wipe your phone.



STEVE:  Don't know if text - I'd be surprised.  But certainly QR codes and URLs.  So the concern is that you can have a malicious website that would tend to be visited by Samsung owners, and they would go there, and their phone would wipe itself.



LEO:  Wow.



STEVE:  So there is a test, for anybody who's worried or wondering:  androidcentral.com/ussd-test.  And it's a benign test.  Again, androidcentral.com/ussd-test.



LEO:  Obviously do this on your phone.



STEVE:  On your phone.  Yes, you go there on your phone, with your phone's native browser.



LEO:  Oh, okay.  Not Chrome.  So I'm going to use the stock browser, okay.



STEVE:  Your phone's stock browser.



LEO:  Okay



STEVE:  Go there.  And then click the button.  What will be shown if your phone is vulnerable is your own phone's IMEI number, the International Mobile Equipment Identity number.  If you see that, it's very likely that your phone is vulnerable.



LEO:  Wow.



STEVE:  But if your dialer just pops up showing you either nothing or that star pound zero six pound, then that's been disabled on your firmware, and you're probably safe.



LEO:  And Samsung did push an over-the-air update.  Many of you got that today.



STEVE:  Right.



LEO:  What is that?  Androidcentral.com/...



STEVE:  Ussd-test.



LEO:  Why couldn't they just make it shorter?



STEVE:  I know.



LEO:  All right.  I'm going to try it on mine.  Now, I'm running - the good news is I'm running CyanogenMod.  I'm running a mod on here.  So I'm sure there are other vulnerabilities, but not that one.



STEVE:  Now, okay.  So at this point, if our users or our listeners have, for example, Galaxy S2 phones, for which updated firmware is not yet available, if you switch to a third-party dialer, such as apparently there's one called Dialer One, Dialer One isn't susceptible to this.  So moving away from the Samsung dialer, it's Samsung's dialer that knows about these special codes.  If you switch to a third-party dialer as your default dialer for the phone, then you'll also be safe.  And you can of course verify that using this Androidcentral.com test.



LEO:  Wow.



STEVE:  Yeah.



LEO:  That's amazing.  So when you get to that page, it has a test, and you have to click that, click here to begin.



STEVE:  Right.



LEO:  And then it will run the thing.  And what happened with me is the dialer popped up with that string, that star pound.



STEVE:  Yup.



LEO:  So, and then I dialed it, but it said nothing happened, so...



STEVE:  Good.



LEO:  It's okay.  What you don't want is for it to display your IMEI.



STEVE:  Correct.  If you see that, that's not good news.



LEO:  And that's a long, much longer number.



STEVE:  Oh, yeah, it's like a huge serial number kind of thing.



LEO:  Right, right.  Wow.



STEVE:  So as you mentioned earlier, Leo, the IEEE.org website turned out to have a rather substantial username and password leak.  A TA, teaching assistant at the University of Copenhagen, Radu Dragusin, reported that he found 100,000 usernames and passwords stored in plaintext that had been sitting for a month on a publicly accessible FTP server belonging to the Institute of Electrical and Electronics Engineers, the IEEE.



LEO:  Amazing.



STEVE:  But after finding that, he poked around the Internet some more and found 15 web pages' worth of 14-month-old IEEE log folders on a Russian website.  Which tells us that the IEEE files may have been publicly accessible for more than a year.  So another instance of, whoops, you know, information leakage from a site that we would hope would be more secure than that.



LEO:  And by the way, I believe Radu is a listener because he was in our chatroom earlier.



STEVE:  Oh, cool.



LEO:  Yeah.  So there you go.  Nice job.



STEVE:  Yes, very.  Finally, Bruce Schneier, our good friend/cryptographer guru in the industry who's designed a bunch of great ciphers, had an interesting blog post.  He mentioned that the six-year-running competition to select the successor to the SHA-2, or SHA-2, as it's sometimes pronounced, family of secure hash algorithms is coming to an end, and that the NIST, the standards-setting body, is nearing, very near to choosing the final hash for what will be called SHA-3.  So this is similar to what we saw happening years ago where Rijndael, the Rijndael cipher, won the next-generation cipher competition to be assigned the designation of AES for that standard, the Advanced Encryption Standard.



So in this case they started off six years ago with 64 contenders for this title, now winnowed down to just five, one of which is Bruce's team's own - they call it "Skein," S-k-e-i-n, which is based on Bruce's ThreeFish large-block cipher.  We know that Bruce did Blowfish, which is still strong and useful.  Then he did another generation called TwoFish.  And now he has ThreeFish.  And this sounds like a Dr. Seuss book.



LEO:  By the way...



STEVE:  OneFish, TwoFish, ThreeFish.



LEO:  ...Radu came back in the chatroom, and he said, "And not only that, but I used Squarespace for the site that I demonstrated this on."  So not only is he a listener, he supports our sponsors.  Thank you, Radu.  Isn't that awesome.  That's great.  I love that.  I'm sorry.  Back to the OneFish TwoFish ThreeFish BlueFish.



STEVE:  ThreeFish and BlueFish, yeah.  Blowfish.  So what happened was, okay, I should explain that Bruce thinks none of this is necessary, even if his own hash wins.  He explains in his posting that six years ago this competition was initiated for the successor to the SHA-2 family because it was just assumed that, with computers getting faster and crypto getting better, and everybody being better at understanding vulnerabilities and cryptanalysis, the assumption was made that the SHA-2 family would not withstand the test of time.



And he says, but six years later, SHA-512, which of course is a hash that gives us a 512-bit digest, more bits being better, for example, the SHA-256 is there, and it's fine, but SHA-512, he says, is holding up extremely well.  That is, we don't need anything more.  And so he points out that none of the five currently surviving contenders for the SHA-3 crown is enough significantly superior to really justify switching.  He says some are faster, but not orders of magnitude faster.  Some are smaller, but not orders of magnitude smaller.



And he said that, when SHA-3 is announced, he's going to recommend that, unless the improvements are critical to users' applications, that is, for example, if speed really matters, or if size really matters, whatever this next generation is will probably be faster and smaller.  So there is that aspect of evolution in our ability to design a secure hash function.  That we have seen over the course of since SHA-2 family was designed.  He said, but unless those improvements are critical, he's going to recommend that people stick with the tried-and-true SHA-512, at least for the time being, at least until there's some reason to move.  So I thought that was interesting, that what we've got now is holding up.



Now, essentially we'll have a - assuming that NIST does pick some, or one, we'll have a successor sort of waiting in the wings that is ready to be deployed.  And you might just go ahead and use it for new things.  But absolutely no reason, as far as we know at this point, to stop using the existing SHA-2 larger digest hashes because they're, as far as anyone knows, completely strong and solid.



LEO:  How rarely do you hear that?



STEVE:  I know.



LEO:  Usually it's like, oh, they're broke.  No, these work.



STEVE:  Yeah, I know.



LEO:  They're not broken.  They work.



STEVE:  I got a note, a tweet from a listener of ours, Thomas Fors in Chicago, who brought to my attention Adobe's release of a very nice-looking new font that might be of interest to any of our coding listeners.  It's called Source Code Pro.  And if you just Google the phrase "Source Code Pro," the first link is to their announcement.  And there's a number of links there.  And it's very attractive.  They did a Source Sans, which is a very nice sans serif typeface.  But then the Source Code Pro is a monospace typeface, meaning that every character is the same width, so that they all line up nicely.  And they paid special attention to disambiguating - that's one of my favorite words, I don't get to use it often - disambiguating lookalike characters.  So, for example, the numeric zero has a dot in its center to help make it very clear that it's not a capital "O" alphabetic.  So I just wanted to let people know...



LEO:  Yeah, I like that.  I tell you, because I have passwords that have zeroes, capital O's and zeroes in them.  And I can never tell the difference.  I like a font that will let me know that.



STEVE:  Yup.  And like the number "1" and the lowercase "l," those get confused.  And, yeah.  So this is very nice.  They did a great job of making them extremely clear.



LEO:  Good.



STEVE:  And then finally, we've talked about this before, or actually relative to Nevada, but just yesterday California joined Nevada in officially allowing "autonomous self-driving automobiles."



LEO:  Yeah?



STEVE:  On the roads.  It's like, okay.  I guess if you look at the car passing you, and there's no one there, it's not - you're not seeing a ghost.  That's just Google driving by.



LEO:  Did you see the announcement where Jerry Brown's talking about it, and of course Sergey Brin's there in his Google glasses.  I guess he wears them all the time now.  And it's just strange as heck.  I mean, it feels like it should have been Arnold Schwarzenegger.  Then it would have been like, okay, "The Terminator," I get it.



STEVE:  Right.



LEO:  But it was a weird picture.  I'll see if I can find that.



STEVE:  So the news is that Arizona, Hawaii, Florida, and Oklahoma for some reason are also currently considering similar legislation.  I am curious about why Florida and Oklahoma and Hawaii and Arizona.  But, you know, I guess..



LEO:  Well, they're going for every state eventually.  That's the idea.



STEVE:  Yeah, yeah.  And I've been meaning to mention that I'm still on my stair climber reading "Kill Decision" by Daniel Suarez.  And, oh, it is just terrific.



LEO:  He's great.



STEVE:  So when you get through with "Zero Day" and "Trojan Horse," Mark Russinovich's books, if you haven't picked up "Kill Decision," I'm just really enjoying it.  It's great writing.



LEO:  Very nice, Steve Gibson.  I just wanted to pass along before you - I know we probably want to do a SpinRite and everything.  But Radu, as I mentioned, the guy who discovered the IEEE flaw, is in our chatroom.  And he just passed along, he said, here's the tweet, this is the site that he announced this on.  And he said to me and to Squarespace, "I want to say I'm a happy customer."  Slashdot could not bring this IEEE log down that he created.  And look at all the bandwidth, all of a sudden it's 74,000 page views at the peak, 60,000 - yeah, yeah.



STEVE:  So that's cool.



LEO:  That's really great.  Radu, it's nice to have you as a Security Now! listener.  They're doing big things.  Can I also mention Teespring real quickly?  I just want to - there's only a few days, there's like two weeks left on this unique T-shirt - and we will send you one, Steve, by the way, because I think it's in all the hosts'...



STEVE:  What is it?



LEO:  This is just something a little different that we're doing.  We have a T-shirt store and everything.  But it turns out that there is - if you do one-of-a-kind designs that are for a limited time, people really love that.  So we are going to start doing this.  This was a user-submitted design.  And it's got all the - you can't tell, but all the names of the shows make up the TWiT logo.  That's on the back and the front, it just subtly says TWiT.tv.  And we're selling this, we're going to raise quite a bit of money, we're trying to raise enough money to buy a new streaming box, which is about a $20,000 streaming box.  And so far we've sold 1,054 shirts.  So we're a good way along.



There are a few, let me see, it says here, 16 days left.  So a little more than two weeks left.  If you want the shirt, Teespring.com/twit.  And we've reached our goal, so we know we'll be printing them.  You get to choose between two very high-quality 100% cotton shirts, American Apparel and Fruit of the Loom.  So you get to choose.  And we have all sizes.  So this is what we're - yeah, I think you can buy one in Switzerland.  But this - I think international, as well.  This is something we're trying a little different.  This is a different manufacturer.  They do very high-quality silkscreen shirts.  Little more pricey, but I thought I'd pass that along.  Teespring.com/twit.



And I think we would love to do a Security Now! shirt at some point.  So if you have a design that you'd like to submit for a Security Now! shirt, email Glenn with two N's at TWiT.tv with your design.  And we picked this one from a bunch of user submissions.  So it's kind of fun.



STEVE:  Yeah, that'd be cool, Leo.



LEO:  Yeah, Security Now!, we should have a Security Now! shirt.  Maybe a TNO shirt.  Wouldn't that be fun?



STEVE:  Ooh, ooh, that's perfect.



LEO:  Wouldn't that be good?



STEVE:  That's perfect.  Yes.



LEO:  Actually we don't even need a design.  In simple black letters, Trust No One.



STEVE:  That's it.



LEO:  I love it.  Anyway, thank you for letting me interrupt.  Go right ahead.



STEVE:  No, actually the first question is a...



LEO:  Is a SpinRite?



STEVE:  ...is from a listener about SpinRite.  So I figured I would kick off our Q&A with that.



LEO:  Simplify things.  Hey, I downloaded all those source fonts already from Adobe.  I have a font folder that I keep on Dropbox.  So whenever I set up a new computer I have the fonts that I like.  And among them I have a number of programmer fonts - Inconsolata, Droid Sans, Monaco.  But this one looks really nice, looks better than...



STEVE:  Consolas is a very nice one.



LEO:  Consolas is - Inconsolata is a free version of Consolas, yeah.



STEVE:  Ah.



LEO:  All right.  Starting with our questions.  And our first question from Dustin B. in Seattle, Washington.



STEVE:  Wait.  Which Q&A are you reading?



LEO:  Oh, wait a minute.  Number 360.  Holy cow.  This is from July.  That would explain why the notes didn't...



STEVE:  Yeah, because I cannot pronounce the name.  I was going to saddle you with the pronunciation of our listener in Norway.



LEO:  Oh, you know what?  I've got them sorted in ascending, not descending order.  Let's go.  Let's do today's questions.  How 'bout that, Leo?  This is from - oh, you're right.



STEVE:  Yeah.



LEO:  Okey-dokey.  Okey-dokily-dokey.  Maybe somebody in the chatroom...



STEVE:  I'm not reading that.



LEO:  ...can help me with this one.



STEVE:  Sounds like a great guy.



LEO:  Irvelive Sturevirpe in Stian Skarsb Solheim, Norway, posts a terrific question - I hope, Odd Inge, I hope I did that justice.  Odd Inge's our regular Norwegian listener - about SpinRite's Level 1 operation:  I am currently running SpinRite on a SATA drive, connected directly to the motherboard, that has been drastically slowing down lately.  I started a Level 1 scan, and after a couple of analyzed sectors the read speed went down for about 10 minutes.  When it picked up again, SpinRite had marked the sector as recovered - green "R."  Now, this is Level 1.  So I was wondering, does this mean the sector's successfully been recovered, or that a problem was found and can and will be fixed by running Level 2+ at a later time?  If it has indeed been recovered, how did it do it, since Level 1's not supposed to write any data to the disk?  Long-time SN listener, utmost trust in SpinRite.  Just a little bit confused, says Irvelive Sturevirpe in Stian Skarsbo Solheim, Norway.



STEVE:  So I ran across this when I was going through the mailbag for the Q&A.  And I thought, well, I'll just answer that question as my mention of SpinRite for the week.  What happens is a Level 1 scan we've talked about before because it would be good, for example, with SSDs, for recovering SSDs where you do not want to be writing necessarily to SSDs.  It also is the quickest way of running SpinRite on a drive where there's a problem.  Essentially, SpinRite runs forward at full speed, just simply reading every single sector from the drive until and if it has a problem.



Now, it's possible that, when SpinRite asks the drive to read a sector, that the sector, first of all, could read perfectly, which would result in no change.  It's also possible that the drive could, when asked to read a sector, see that enough correction, that is, enough error correction is necessary that it's outside of the drive's safety margin or comfort factor.  So the drive would, on the fly, recover the data, that is, apply error correction, then move that sector somewhere safe and lock that spot on the drive so that it cannot be used, and return the data.  At which case, again, SpinRite would show no problems.  It helped the drive to do that, that is, running SpinRite on the drive was beneficial.  But you still wouldn't see anything.



Where you see something like this green "Recovered" is where SpinRite asks the drive, or encounters in its reading, a sector which will not read, that is, the drive attempts to read the data and says I can't.  It is unable to, even with error correction, to successfully read the data that was originally recorded there.  Well, so it returns a "This sector won't read," a sector error.  Well, other software gives up.  SpinRite's job is not to give up.  So what it does is it, with caching, with the drive's own internal caching disabled so that that doesn't get in the way, it reads a randomly chosen sector on the drive, which pushes the head over to some other sector.  Then it returns to the sector that it is trying to read.



So what that does is it moves the head a random distance and direction from the target sector and then brings the head back.  So the chances are that the head - because we don't have zero friction, we have low friction, and we have friction working together with the servoing going on.  But the chances are the head will end up in a slightly different position.  Just a little bit different.  Or the sector we're coming from will be rotationally in a different place.  So we end up getting onto the target track at a different location, so things have settled differently.



The idea is, though, that we keep asking for this sector over and over and over, giving the drive essentially every possible opportunity to read it.  And then the idea is we just need it one more time.  The drive has said, can't fix it.  We say, are you sure?  Are you really sure?  Are you really, really sure?  And not just redundantly asking, but also asking in slightly different ways each time because we're arriving at that sector in a different way each time.  Finally, and this is what - I can't pronounce his name, Irvelive.



LEO:  Irvelive.  I'm just making it up.



STEVE:  What he saw and what so many of our users find is that, yes, SpinRite, by being really patient and persistent, gets the drive to read the sector just one last time.  The drive says, oh, my god, I've got it.  I was able to correct it.  It sees that it was probably at the limit of its ability to perform error correction to recover the sector.  But that's fine.  That's all it needed was one last success.  Then, on that read, it does what it did before.  It marks that spot as bad, don't use that anymore, grabs a spare sector out of its spares pool, puts the data there, and reports to SpinRite, I got the data.  Here it is.



So what SpinRite sees is that it got sector error, sector error, sector error, and sector error many, many times, and then finally a successful read.  So the data got recovered.  It puts a green "R" there and moves on.  So we are doing a read-only scan of the drive at Level 1, but still able to perform data recovery and repair when we hit spots that need it.



LEO:  Interesting.



STEVE:  Yeah, it's cool.



LEO:  Thank you, Irvelive.  Cal in the U.K. has our next question.  How do you keep up - I get this question a lot - with all the security news?  Steve, I was wondering how you keep up to date with security news, if you could recommend some good sites?  I try to keep up with tech news, and only find out about the security stuff if tech blogs cover it or from your show.  I feel there must be some good security news sites out there.  I'd like to know what you read.  And I wish you'd make an OPML or something of this.  Be very handy.



STEVE:  My approach has evolved over time really as a consequence of my increasing use of Twitter.  I used to be on my own, essentially, operating without the benefit of the incredible dragnet of listeners that we have who make sure that I know what's going on.  And so my strategy really has evolved.  My main go-to, it's not a site, resource is the SANS Security Institute.  It's possible to subscribe to their mailing list.  And they send out a couple times a week various types of news.  And they do a compendium, very nicely organized, of what's happening.  So they're very active in tracking what's going on.  And so I was relying on them almost exclusively.  I mean, I would sort of - we have Brian Krebs, and we have other security columns and things.  But there wasn't anything really very organized for me except the SANS Security Institute was just - it was my crucial resource.



And now what's happened is, thanks to SGgrc on Twitter, we've got all of these listeners who themselves have all these resources that they're checking.  I mean, I see Slashdot.  I'll get duplicates often, and I sort of smile because I know then, like, where the source of that was, and our listeners are keeping tracking of that.  But I get the benefit of the concentration of all of our listeners seeing something that they know would be interesting to me and to other listeners of the podcast, who just make a mention, @SGgrc, and I read my feed and then go and pursue that.  So...



LEO:  And then we just all listen to you, and it makes it very easy.



STEVE:  Everybody listens here, yes.



LEO:  I was just looking because, you know, I have a fairly long list of things I peruse on my Google Reader list.  And I was just looking at what I read.  And I do, SANS is great, and also Krebs on Security, we love him.



STEVE:  Yup.



LEO:  He left the Washington Post, but he has his own blog now, and it's very good.  Schneier on Security, you were just talking about Bruce.



STEVE:  Yes.



LEO:  And then there's a SecurityFocus site that I also - from years gone by, used to follow SecurityFocus.  So those four are pretty good sources of information for me.  But Security Now! is the best.  If you just listen to this show...



STEVE:  Well, we do a lot of filtering.  There's stuff that it's like, eh, doesn't quite make the cut.  And I try to make those decisions and make them correctly.



LEO:  Very nice.  Always good to know.  Question 4, Mr. G., question 4 is from Andrew Stevenson in Dorset.  And he very kindly provides the pronunciation, Dorset, U.K.  Software firewalls?  What's the point?  A friend said to me the other day, why do you run a software firewall when you already have a "rooter"?  That's how they say it in Dorset.  That got me thinking, and I wanted to hear what you thought about having a software firewall installed as well as having a router/rooter, which contains NAT and firewall technologies.  I personally have a desktop machine that never leaves the protection of my home network.  I have a feeling that having a software firewall is a good thing in terms of security, as relying on a single form of defense is never a good idea.  I also feel the fine-tuning of a software firewall and IDS, Intrusion Detection System, also makes me more secure.  Also that the software firewall is protecting me from other nodes on the local network - aha - rather than just incoming Internet traffic. 



STEVE:  Exactly.  My feeling is that our software firewalls are unintrusive enough that they're just not a problem.  We have interfaces, like the operating system has interfaces that allows it to ask for inbound - to deliberately ask to allow inbound traffic when and where it wants; and that the rest of the time, having the protection of dropping packets which are not expected and are unwanted is a good thing.  I mean, really a firewall sounds like a big deal.  All it is is something that looks at some characteristics of data arriving on the wire and decides whether to pass it on upward into the computer or just say, eh, don't think we need that.  And so it's sort of impressive-sounding.  But in implementation it's not that big a deal.



So I absolutely feel that, since it's not something that requires constant maintenance and tending, it's just not in your way any longer.  I mean, I absolutely like the idea of operating behind a NAT router.  That kind of border protection makes lots of sense.  And Leo, you said "Aha" when you read his comment about protecting us from other machines inside our protected perimeter, which is a very good point.  Many of the state-of-the-art malware tries to look for local machines that it's able to infect on the LAN.  So having our machines keeping their defenses up, essentially individual little islands which selectively allow data in, I think that just - that it makes sense to have a layered security model where local individual firewalls form another layer of protection.



LEO:  Is it enough to have just the Windows firewall?  Or do you want to go out and - well, you were the guy who discovered and really promoted ZoneAlarm way back when.



STEVE:  Well, yeah.  I was promoting firewalls before they were in the operating system.  And I recognized as Microsoft began picking that technology up themselves that third-party firewalls were endangered, just as third-party antivirus is now endangered because ultimately Microsoft is going to move those technologies into the OS.  So that has happened.  And of course Mac has a firewall as part of its technology, as does now Windows.  So, yeah, I just don't think that firewalls represent enough of a problem that there's any reason not to have them.  They're there.  Just leave them on.



LEO:  And use the operating system built-in.  That's sufficient.



STEVE:  Yup, I really think so.



LEO:  All right.  Here's a complicated one from Tom Ribbens in Belgium.  And just as a setup, last time we talked about the fact that the British, like, retirement system or something has an entire /8 block of addresses, which they apparently don't use publicly.  Now...



STEVE:  More than one 256th of the entire Internet's address space.



LEO:  And of course, as you all know, with the current system, the IPv4 system, we just are - we've run out, in fact.  We are out of addresses.  So we'll have to move to IPv6.  But in the meantime, a significant number, millions of addresses, are being kind of, well, it seems, misused by the British trust:  Steve, I thought your discussion last week about the 51.0.0.0/8 - this address space we talked about - was completely off.  You said, "Well, all they have to do is change the 51 to 10," which is of course an internal designation.



This is not as simple as you might think.  This would take weeks of planning and preparation and will cause issues along the way.  And what for?  When the IANA still had blocks of IPs to give to the RIRs, I believe they were crunching through them at the rate of two /8s a month.  That would mean, even if we got that /8 back, it would only move the problem away for a couple of weeks.  Seeing that there is no way any sizeable organization could renumber their whole network in two weeks, this is not a viable trade off.  Even if we would find 10 such companies who could give back /8 blocks back - and I think there are probably that many - it would still only help for another half year.



You know just as well as I do that the real solution is IPv6, and that adoption will only happen when everybody is forced to adapt.  It might cause a little mayhem when it really will be absolutely necessary, but delaying it another year is not going to help a thing because we'll hardly be better prepared, as there's almost no incentive currently to do so.  Tom Ribbens.  I think he's right.



STEVE:  Well, yes.  I guess the point was that there has  historically been a huge amount of waste.



LEO:  Right.



STEVE:  Because we thought, oh, 4.3 billion IPs, we'll never use all of those.  And so, early on, huge blocks were being handed out very easily.  So the way I view this is sort of a - is a struggle with tension between competing interests and the need to implement IPv6.  The problem is people who already have allocations of IPv4 IPs, they want to keep them.  They've had them for a long time.  They figure that they're entitled to do so.  And they probably have a good point.  They could make that case convincingly.



At the same time, we need to move to IPv6, but it is a pain.  I mean, it requires the replacement and upgrading in some cases of entire networks and switches and routers within a company.  And you could also argue that any company that already has IPv4 is disinclined to move away from four over to six.  IPv4 addressing will never go away.  I mean, probably never.  It was first - it will continue to be supported.  New allocations at some point will have to be IPv6.  But at the same time, looking at huge blocks of unused IPv4 does create some tension because it would be easier to reuse that than it would be to make the move to IPv6.



So first of all, I mean, the one area where I disagree with Tom is the rate of consumption.  It is no longer the case that /8s are being consumed at the rate of several a month.  Remember a /8, as I mentioned before, is a huge chunk of the Internet.  It's about a 200th of the Internet, of the entire address space.  That's massive.  So today, now that we know IPv4 IPs are so scarce, they are being managed far more carefully than they were in the past.



So I just sort of see this as a set of competing pressures.  There is pressure to better use existing IPv4 space.  There is pressure to move to IPv6.  And we are running out of IPv4 space over time.  Yet people who have large allocations of IPv4 that they are not using, there's some argument to be made for freeing some of that up to release some of the pressure.  But, yes, ultimately, new people are going to have to be using IPv6.  We'll get to a point where there will be no more IPv4 space.



LEO:  Yikes.



STEVE:  Yeah.



LEO:  Yeah, I mean, and it seems wasteful.  I guess you could go back and forth on this.  And there's a large camp of people that say, well, look, we've just got to have the pain, or it's not going to happen.  And I'm not sure I disagree with that.  Because, I don't know, I think what's going to happen is you're going to have ISP NAT.  We're never going to go to v6 at home.  It's going to be the ISPs who do it all.  And we're actually...



STEVE:  Yeah...



LEO:  Go ahead.



STEVE:  Well, imagine that a company said to another, a squatter, we'll pay you X amount of money for a chunk of your IPv4 space that you're not using because it's easier for us and more cost-effective for us to do that than it is to move our infrastructure to IPv6.  So that may happen.  I did see some dollar signs associated with the value of IPv4 space.  And it was stunning.



LEO:  Well, yeah.  Especially as it gets more valuable as there's less of it.



STEVE:  Yeah, I just think that what we'll see is future, like, existing companies that have been around that have IPv4 probably get to keep it.  Now, if they're offered chunks of money, where it makes sense for them to move, well, maybe they'll choose to give up some.  But new allocations will probably, by virtue of the fact that there won't be a choice, will be in IPv6.



LEO:  Question 6 is Chad Jacobson, Burlington, Vermont.  He wonders about LastPass.  He's quoting the transcription from Elaine of Episode 369.  Quote:  "I brought up IMDB, the Internet Movie Database, which I poke around from time to time.  And this was an app on my iPad.  Same experience under Firefox, for example, in Windows.  And it prompted me to log in with IMDB, Amazon, Facebook, or Google.  And I thought, Amazon?  What?  And sure enough, if I click on Amazon, I jump over to Amazon, LastPass sees that I'm being prompted to log into Amazon, it does that for me, and I'm back to IMDB, having logged - and it knows my name."  You were talking about OATH.



STEVE:  Right.



LEO:  The ability to use a trusted third-party for logins.



STEVE:  Actually, OAUTH.



LEO:  OAUTH.  Right.  This isn't OATH, this is OAUTH.  As an iPad owner and LastPass Premium customer myself, my first question is were you browsing in the LastPass Tab when this automatic login took place, since to the best of my knowledge LastPass does not, unfortunately, integrate directly into Safari or any other browser on either the iPhone or the iPad.  I frequently forget to start my browsing sessions within LastPass on my iPad, and should I need to log in somewhere I am forced to "move" my session over to the LastPass app or copy over my very forgettable LastPass-generated passwords into my browser.



You may have covered my second question in a past episode, but why can't LastPass be integrated directly into iPhone and iPad browsers?  Would Apple need to give away the keys to its iOS kingdom to make this happen?  Does the nature of iOS make it functionally impossible?  Or is it the functionality of LastPass that makes that level of integration unfeasible?



My thanks to you and Leo for what is without a doubt the finest technology podcast, sorry netcast, available.  I will continue to consume every episode as long as you are willing to produce them.  Chad Jacobson, also a very satisfied SpinRite owner.



STEVE:  So...



LEO:  Question 1 first, the iOS question, yeah.



STEVE:  Yeah, a couple things.  I tried to recreate that on my iPad and didn't see what I remember seeing.  So I may have misspoken, and this was the behavior I had in Windows with Firefox.



LEO:  Well, and I'll tell you what might have happened.  If you pick Facebook or Twitter, the iPad preserves, iOS preserves your Facebook and Twitter - Twitter for a while, and Facebook since iOS 6, credentials and does the login for you.  So Amazon would not have done that.



STEVE:  Right.



LEO:  But had you said, oh, let me use the Facebook login, the iOS will, my experience has been, will do that for you automatically.  Once you verify Facebook and Twitter connections on the iPad or iPhone, it will log you in to other sites through those places.



STEVE:  Okay.



LEO:  So that's maybe what happened.



STEVE:  Yeah.  For what it's worth, I feel like Chad and I are on exactly the same page, and probably many of our listeners are.  And that is this annoyance that iOS and iOS's Safari mini browser is unable to integrate with LastPass.  This, of course, is by Apple's design.



LEO:  You bet.



STEVE:  They do not have a Safari plugin ecosystem and don't want one.



LEO:  And you can see why they don't want one.



STEVE:  Yes.



LEO:  It's a security issue, absolutely.



STEVE:  Yes, absolutely.  And so I similarly use LastPass Tab when I'm needing to log in somewhere, and I have no idea what my password is on many obscure websites.  LastPass knows what it is, and so I have to switch over to that browser and happily use it to log me in.



LEO:  It's its own browser, it's just it's using the WebKit, it's using the...



STEVE:  It's using the same technology.



LEO:  ...same stuff.



STEVE:  Yup.  It's just...



LEO:  I've got, you know, I have what - if you're a Pro user, LastPass Tab is a future.  And I keep forgetting to use that.  But I probably should make that my default browser almost.



STEVE:  It's really nice.  I mean, they did a nice job with it.  I'm really happy with it.



LEO:  It's basically the same as Safari.  The only issue is, of course, iOS does not allow you to change default browsers, either.



STEVE:  Exactly.



LEO:  You have to remember to launch it each time.



STEVE:  Right.



LEO:  And his second question - oh, yeah, you answered it, which is why doesn't Apple allow that.  Well, that's why.



STEVE:  Yup.



LEO:  Tony Wall in Port Dover, Ontario wants to know about Tomato:  Steve, I bought a new router with USB ports in the hope of streaming media from my hard drive to an Xbox.  Well, even with tech support we couldn't get the Xbox to read the hard drive.  So after searching around I came across the open source Tomato firmware.  After flashing the router, everything worked great.  It's a nice upgrade to the OEM firmware.  My question is, as it's open source, how secure do you think it is?  Thanks for a great show.  You and Leo do a wonderful job.  P.S.: Love the Honor Harrington series and Mark Russinovich books, so keep those suggestions coming.  I would add to Tomato DD-WRT, which is another open source router firmware that many routers support.



STEVE:  Yup, there's DD-WRT, which actually has wider compatibility with router hardware than any other of the third-party firmwares.  And it's very feature rich.  Tomato firmware is not quite as feature rich as DD-WRT, but has a very friendly user interface.  There's OpenWrt.



LEO:  That's the one.  DD-WRT's older, yeah.  Open is the new one, yeah.



STEVE:  Right.  And it's meant to be an open platform for add-ons.  It does not have a native GUI itself, but X-Wrt adds one to it.  Then there's FreeWrt, which is a fork of OpenWrt that's more sort of aimed at developer experimentation, but not so friendly.  It's command line configuration only.  If you wanted to set up a public controlled hotspot, there's one called Chillifire, which turns a router into a for-pay or free public access hotspot with the kinds of controls that you might want.  And then there's finally one called Gargoyle, which does not have lots of features, but it does offer lots of bandwidth management, like band management quotas and network access rules.



So there's a bunch of different firmwares available.  It sounded a little bit like Tony hadn't encountered this before and wanted some assurance that, for example, Tomato, which is oddly named, is a good one, and it absolutely is.  You and I, Leo...



LEO:  Love it.



STEVE:  ...have heard about it for years and know of it and recommend it.  So I would say you can absolutely use that, and really any of those, with confidence.



LEO:  Colleen put Tomato on a lot of our old Linksys routers, and we do a Know How episode on how to flash your router firmware.  I think we used, I can't remember, I thought we used OpenWrt.  Anyway, Know How 3 has that, TWiT.tv/kh, and Episode 3 will tell you how to do it.



Michael in Europe raises a very good point about a fundamental OAUTH weakness and how someone might steal an  unwitting person's logon credentials:  Steve, while I'm sure OAUTH is a great solution for avid Security Now! listeners, I'm worried about the millions of less tech-savvy computer users like my mom, who come across OAUTH and get used to it.  Wouldn't it be easy to put up a number of malicious websites and online shops that leave the impressions of forwarding users for authentication purposes to a faked Facebook, Amazon or Google site, then just grab their logon credentials?



If the faked authentication site looks real, I'm sure many less security-aware users wouldn't even recognize that the fake OAUTH page is sitting on some domain other than Facebook, Amazon, or Google and readily fill in their user name and password.  In the case of Amazon, the password thief could be out doing his shopping in a matter of minutes.  Of course, one could try to educate people to pay attention to the domain that they're forwarded to when using OAUTH, but that doesn't seem to be a working solution for people that are already challenged with the many do's and don'ts of using a computer.



LastPass could be a solution, as it probably wouldn't readily fill in your login credentials on a faked OAUTH Facebook password or Amazon or Google site, but that'd require use of LastPass in the first place, which one can't really expect from millions of Internet users that might be easily tricked with this scam.  What are your thoughts?  Keep up the great work.  Michael.



STEVE:  [Sighing]  That is really a good point.  Consider what the - the beauty of OAUTH, exactly as we were just talking about, for example, when I had the experience of logging in to IMDB, is it offers you a menu.  And we've always, you know, we're seeing increasingly often "Log in with your Facebook ID."  So more and more sites are doing that.  People are saying, oh, yeah, that's what I do.  I log into sites with my Facebook ID.  And so they click on that.  Well, and you bounce over to the Facebook login and into your credentials there.  And then you submit that, and you bounce back.



Michael's point is that the taking you to that Facebook site is under control of the site you're logging - the primary site you're logging into.  So what if it takes you instead to Faceback.com, which is a domain they own, and present you with the Facebook.com lookalike login page and acquire your Facebook credentials, just like that?  So here, I mean, this is a classic instance of where ease of use is a really great feature.  But it's abused because, I mean, the very ease of use gets us accustomed to it, and we stop really paying attention to see where we are.



And I think this is, I mean, mark my words, this is going to happen.  We will see somebody, once OAUTH becomes popular, people are going to create fraudulent bounce sites that you get taken to in order to steal those popular credentials.  It's foreseeable.



LEO:  They're already doing it.



STEVE:  And I don't see any way around it.



LEO:  It's easy enough to create a fake Facebook site and get people to go there by clicking a link in an email or a text message or whatever.  I mean, that's...



STEVE:  Well, but remember, here they control where you go.  So you say, yes, I want to log in with Facebook, and you're blinked over to a site, assuming that it's Facebook, that looks like Facebook.  How many people are going to carefully look at the URL to make sure that that's in fact where they are?



LEO:  Right.



STEVE:  It's going to get abused.



LEO:  Jeff Horning in Indianapolis suggests maybe it's time to revisit the question of periodic password changes:  Guys, thanks for all you do to make our cyber world more secure.  I think, with some of the topics you've covered recently, perhaps it's time to revisit the periodic password change option.  Here's my Top Five list of occasional change rationales:



No. 5, your phone and tablet display it as you type.  Most people don't change this setting.  No. 4, when email accounts are hijacked, the hijacker does not have to make his presence known.  He's watching your online accounts, contacts, et cetera.  He assumes you are using this password elsewhere.  Only changing it can kick him out.  No. 3, in corporate settings it's very easy to have your password seen when you enter it several times a day.  No. 2, hopefully you're listening to Steve Gibson and will make a better password now than you did years ago.  No. 1 reason for changing your passwords from time to time:  Mat Honan.  I know everyone railed against this last time it came up, but I think most of the argument against it boiled down to convenience.  Keep up the good work.  Thanks for having Mark Russinovich on.  Love his books.  Jeff Hornung.



STEVE:  So this was interesting.  I'm still, I guess, somewhat dubious about the need to change a really good password just because a month or two of use, or maybe a year, has gone by.  But Jeff's point is that there is some level of leakage or potential leakage, and that changing those passwords periodically makes some sense.  And of course we now have management technology like LastPass that allows a password change to immediately propagate and take hold on all of our devices.  So the impact on us is much lower than it would have been before.  So I think that's sort of worth considering, the idea that, well, we're not having to manage our passwords to the degree that we did.  And there is some potential leakage of even a really good password.  So, yeah, I mean, I guess I'm still not hugely moved.  But I can certainly see Jeff's point.



LEO:  We'll leave it as up to you, listening at home, as to what you wish to do.  But I think what we were talking or railing against was these kind of mandatory, you must change your password every three months.  Dropbox, just for reasons I don't know why, made me change my passwords, which was not a minor inconvenience because I use Dropbox on a lot of machines, et cetera.  And in fact what was ironic is, because I knew I was going to have to enter it on mobile and so forth all over again, I made it a much easier to remember password because I had a LastPass-generated password.  And I thought, well, if I'm going to have to enter this 20 more times everywhere - fortunately I did not have to enter it because the token was not invalidated by the new password.  Which seems to me a flaw.



STEVE:  Yeah, that's odd.



LEO:  So I did create a new password, but I didn't have to reenter it on most of my mobile devices.  They already had a token.



STEVE:  Right.  You were still logged in with the old password.



LEO:  Seems like Dropbox kind of dropped the ball on that one.  They should have invalidated the tokens, shouldn't they?  Otherwise, what's the point?



STEVE:  Yeah.



LEO:  So I'm kind of doubly angry at them.  Vern Mastel at the Bismarck Public Library, Bismarck, North Dakota shares some very real-world experiences with antivirus solutions:  I admin the Windows network for a medium-size public library.  The system has more than 200 computers of all varieties, from Windows 2000 to Windows Server 2008 R2.  All machines - Windows 2000, wow.



STEVE:  Yeah.



LEO:  All machines - it's like Steve Gibson.  All machines are patched on schedule - except for Windows 2000 - have unused or unneeded ports and services closed or disabled, have commercial antiviruses.  But still, still, still in the past three years I've had plenty of encounters with malware infections on staff machines, always as a result of drive-by-downloads from hostile web sites. 



For many years I used Symantec antivirus products.  They failed repeatedly.  I have tried others with similar results.  Licenses are expensive, several thousand dollars a year, lots of money out the window.  I've taken the opportunity, when faced with compromised machines, to test all the various malware detection and removal tools I could get my hands on.  My success rate with this approach is zero, 100 percent failure.  Usually the tool finds nothing wrong, when it could actually be run.  And when it did, it was unable to do more than simply scuff up the malware.  That's a good way of putting it.  It was like shooting a pistol at a tank.  I always end up formatting and reloading the computer.  I no longer waste my time testing.  I simply go directly to the wipe-and-reload.



Of all the different software products we have on our computers, antivirus/antimalware products are the only ones I can't actually test.  Sure, I can feed EICAR files to the AV, but that's hardly a definitive test.  Out in the real world, my real world, it's a total bust.  I read all the published test reports about how well the commercial products work, but I no longer believe them because I have never been able to reproduce their results.  I cannot get a list of web sites, say 10 or 20 known to be malicious, and then use sacrificial machines to test the functionality of the antivirus/antimalware.  Instead I'm just burned over and over.  



I have contacted all the major "anti" vendors about this.  None of them will cooperate.  "Trust us, our products work.  That'll be 2,250, please."  And by that I mean two thousand, two hundred fifty bucks.  "Oh, and yes, we do take credit cards."  Here's a challenge for you.  If you were in a situation, how would you test an antivirus product?  Thanks for listening.



He's got a good point.  You can't test it in the wild very effectively.  I mean, you can only test it with these fake - EICAR is a kind of a synthetic test that's a virus bundle.  Which all the antimalware companies know what's in there, so...



STEVE:  So they make sure they pass that test.



LEO:  We're going to pass that one.



STEVE:  Yeah, I mean, I really sympathize with Vern.  I remember there was a period when a good friend of mine who's really at the expert level with computers, you met Bob when we were up in Vancouver that time.



LEO:  Oh, yeah, yeah, yeah.



STEVE:  He just got a bee in his bonnet once because some friend of his got their machine infected, and he was determined he was going to remove this malware.  And he just kept calling every couple of hours and asking what I thought and asking if I'd heard of this file and so forth.  And, I mean, he really knew Windows inside and out.  And he was never able to root this thing out of the machine.  It had just dug itself in and hidden parts of itself and renamed critical files and, I mean, it was just - it was impossible to remove it.  So I got a kick out of Vern's comment about just scuffing up the malware and being unable to get rid of it.



And I don't want to say that AV is a scam.  It's not that, certainly.  I know that it provides benefits for people, or I know that it can.  But when Microsoft began offering their own solutions, it was easy for me to say, I'm just going to use that.  I'm going to use Microsoft Security Essentials.  It's continuing to score well and get good marks, and it's there.  And Microsoft doesn't want Windows infected, and I never bet against Microsoft on things that they really care about.  They generally end up winning in the long run.  So, and you and I, Leo, have historically been not big users of third-party AV.  We just really watch our behavior.  And of course Vern doesn't have that opportunity because he's...



LEO:  He knows people are going to behave badly in a library. 



STEVE:  Yup.  He's got a 200-machine network of miscreants that are going to constantly cause a headache.  So I can sympathize.  And I really get his frustration.  I don't know, I don't think there is a solution.  I think it's accept the fact that these Windows machines are just prone to this kind of attack.  And maybe he's...



LEO:  Well, in an unusually harsh environment.  And so that's part of it is that.  And also, I mean, get rid of the Windows 2000 machines.  They're not being updated.  So, I mean, they're past end-of-life.  So Microsoft is not fixing security exploits.



STEVE:  Way past, yeah.



LEO:  So I think for all Windows 7 machines he probably could with some certitude lock them down a little bit better than - this is a harsh environment.



STEVE:  Yeah.  The harshest.



LEO:  The harshest, right.  Were they public computers as well as staff computers?  I wasn't clear.



STEVE:  Yeah, well, he said medium-size public library.  He mentioned staff machines.  But I would...



LEO:  Yeah, but maybe he's, I mean...



STEVE:  Unless it's a huge, I mean, 200 machines, that's got to be some carrels that are publicly available.



LEO:  Yeah.  So that's absolutely the worst-case scenario.



STEVE:  Yeah.



LEO:  Because those are inexperienced users who really don't care.



STEVE:  Yeah.  And in fact...



LEO:  And so they're doing any kind of weird stuff.



STEVE:  ...they may very well be going to the library to do their...



LEO:  Bad stuff, yeah.



STEVE:  ...shady downloads and...



LEO:  Their porn collections, yeah.



STEVE:  Exactly.



LEO:  Now, I do think Microsoft SteadyState, which unfortunately Microsoft stopped making, but will be part of Windows 8, and the Faronics Deep Freeze, those are used frequently in public computers and work quite well, I think, where you just basically, every day, you start fresh.



STEVE:  You start over, yes.



LEO:  You reboot it, and you're just like you were.  And that would be, to me, the best solution on those computers.  Obviously not so good for staff computers.  I don't understand why people just don't like it when all your data gets deleted each time, but...



STEVE:  Yeah, they're picky, you know, Leo.



LEO:  But for the public computers - and maybe he is doing that.  Maybe these are only the staff computers that are really a problem.  I would like tomato basil soup, thank you very much.  I was just being asked a question, and that was the answer.  You know what it means?  It's time for lunch.



Time to say goodbye to Steve Gibson of GRC.  He is the creator and the guy behind the best hard drive utility ever made.  People sometimes say, oh, come on, Chkdsk or Norton Disk Doctor.  You don't understand.  You don't understand.  Steve invented SpinRite before these programs came out.  He was the original.  And since he wouldn't license it to these guys, they invented their own reverse-engineered, not-so-good version.  There's one and only one.  SpinRite, baby.  GRC.com is the place to get it.  You can also find free stuff, lots of it.  In fact, Steve's really a Good Samaritan.  He gives away a lot more.  This is the only thing he charges for.  Although are you still working on this encryption solution thing you were going to do?



STEVE:  Eh, it's there.  I've got to - I need to get a bunch of the things that I've almost finished, finished.  And then it's time to get back and give SpinRite some time and catch it up with some things that have occurred...



LEO:  Oh, interesting.



STEVE:  ...since 6.0 was finished.  So I'm going to do a 6.1, which will be free for all users of SpinRite because I feel it's my responsibility to keep it current.  And then I'll look around and decide what makes the most sense, once I've got SpinRite current.



LEO:  As long as you keep doing Security Now!, I don't care what you do with the rest of your life.



STEVE:  I'll be right here every week, my friend.



LEO:  I just want to see you here on Wednesdays.



STEVE:  Absolutely.



LEO:  11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC.  Watch live at TWiT.tv.  Radu did.  But you can also listen after the fact.  On-demand versions are available in a variety of formats.  In fact, this show is available in more formats than any other.  There's a transcription that Steve pays for and gets done, and that's on his website, as well as a 16Kb audio version, which is the smallest multimedia version of the show.  We have larger, higher quality audio as well as video available on TWiT.tv/sn.



STEVE:  Yup.



LEO:  Hey, Steve.  Great show.  Do we know what we're doing next week, or is it a question?



STEVE:  You know, I've had near field technology...



LEO:  Oh.



STEVE:  ...on my mind a lot lately.



LEO:  Yeah.



STEVE:  So I think we need to talk about the technology of near field because it's being adopted in phones and in laptops, and it makes me nervous.  So let's maybe take a look at whether that's justified.



LEO:  Very timely because NFC, well, Apple decided not to put it in the iPhone.  But it is in an increasing number of Android phones.  It's in my Galaxy S3 and...



STEVE:  I've got it in my BlackBerry.



LEO:  Yeah.  So NFC, which is a variant, a near field variant of RFID.



STEVE:  Yup.



LEO:  And we've done an RFID show, haven't we?  [SN-278]



STEVE:  Yeahhhh [SN-278].



LEO:  So maybe we need to, yeah, how does this stuff work.  It's a fascinating...



[Talking simultaneously]



LEO:  'Cause these things are passive.



STEVE:  Yes.



LEO:  But from inductance they get, I mean, it's really a clever hack.



STEVE:  Yeah, it's cool.  They're like little transponders.



LEO:  I have - this is an NFC tag which Samsung sells, but other companies sell these.  And if you look on the back of it, it's circuitry.



STEVE:  Yeah.



LEO:  It's really kind of cool.  All right.  There's memory on that.  That's amazing.



STEVE:  There's nonvolatile memory.  There's counters.  It's powered by the - it's passive and powered by the reader.



LEO:  Isn't that wild?



STEVE:  Yeah.



LEO:  Anyway, that would be a good topic.  Well, if you want to do that next week, I'm all ears.  But no matter what...



STEVE:  I think we're going to plow into that and figure out what's going on.



LEO:  Good.  Make sure you tune in next week and every week to Security Now!.  We'll see you next time, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#372	

DATE:		October 3, 2012

TITLE:		NFC - Near Field Communications

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-372.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with just a tiny bit of security news (it was a very quiet week in security), Steve and Leo take the podcast's first-ever comprehensive look at the emerging and increasingly popular NFC (Near Field Communications) technology, which is now present in tens of millions of cell phones and other mobile and fixed-location devices.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, the Explainer in Chief, and he's going to talk about NFC chips.  They're in many new smartphones, but not Apple's iPhone.  What is it?  How does it work, and what are the security implications?  Near Field Communications, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 372, recorded October 3rd, 2012:  Near Field Communication.



It's time for Security Now!, the show that protects you and your loved ones online with our man, Steve Gibson, our Man on the 'Net, Steve Explainer in Chief and guy at GRC.com who gives us so much great stuff.  Hi, Steve. 



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  Good to see you.  We've been talking before the show about sci-fi, our favorite topic.  And coffee.



STEVE:  Yup.  Movies, debates, politics.



LEO:  Politics.  It's like, this is all our favorite stuff:  red wine, politics, coffee, and movies.  Sci-fi.



STEVE:  Yeah, there you go.



LEO:  There you go.  That's all you need in life.  And then you throw in a little Security Now!, and you're set.



STEVE:  You've got the day covered.



LEO:  So last week you said you might talk about NFC today.  Is that our topic?



STEVE:  Yes, that is our topic.  I have been reading about it since then.  Actually I'd started a little bit before then, also.  I've completely satisfied all of my curiosity.  I know everything I need to know about it for now.  And by the end of this podcast I imagine that all of our listeners will feel the same.



So it's interesting.  We'll set it relative to the other sort of environmentally competing technologies. There's of course WiFi, Bluetooth, RFID, even IRDA, kind of.  And here's NFC.  So how does that fit into this spectrum of connections and communications between our devices?  What are its problems?  What are its promises?  I mean, I have to say, now that I have really come up to speed and get a good sense for where we are at this moment, I appreciate more than I did a week ago how odd it is that it wasn't part of iPhone 5.



LEO:  Oh, interesting.



STEVE:  Because, I mean, the industry, the rest of the cellular phone industry has left Apple behind in NFC.  I mean, virtually all the other phones have near field communications.  And this makes the iPhone conspicuous in not having it.  Now, it's true that we're at the early stage of the adoption curve.  And people have various theories about why Apple chose not to do this, like that it's hard to do radio in a metal case, except, well, the phone is a radio, so I don't buy that.  I also read someone saying, well, Apple doesn't want to be the leader in this.  They would rather wait till things settle down and not be a first mover.  It's like, well, okay, maybe.  I just don't really get it.  But at the end of this podcast we will all know what it is and sort of have that whole question mark resolved for the time being.  And from then on we'll just be tracking the mistakes that everyone makes in implementation.



And in fact I'm going to kick off with that because our old friend Charlie Miller, who we know as the great Pwn2Own multiple-time winner, and he wrote the "Hacking Mac OS X" book, he gave a presentation on hacking near field communications at this most recent Black Hat 2012 Conference a few months back.  So, oh, and I just tweeted, by the way, for anyone who's interested, I just tweeted a link to his presentation's PDF.  So for anyone who wants to delve deeper than I'm going to, that's a great place to look at hacking near field from that end.  And we have very little news, a little bit of news which I'll wait until we get started. 



LEO:  All right.  And then NFC, the subject of the day.



STEVE:  Yes, exactly.



LEO:  And I will be interested in the security issues because if, well, if we're going to start using it for payment, that's going to be big issue.



STEVE:  Yes, baby.



LEO:  All right.  Let's do the news before we get to NFC.



STEVE:  Well, there wasn't much that happened.  As we know,  some weeks are so busy we don't have a chance to talk about anything else.  And every so often we run across a week where almost nothing happened, which is, I guess, from a security standpoint probably a good thing.  We talked last week about the expectation that the NIST, the National Institute for, now I've forgotten...



LEO:  Standards of Time?



STEVE:  Standards of Technology?  Anyway, NIST...



LEO:  I'm sure the chatroom will tell us momentarily.  The National Institute of Standards and Technology.



STEVE:  That's right.  That they were on the verge of choosing the hash from among the final winnowed-down contenders.  And they did that yesterday, on October 2.  They did not choose Bruce Schneier's Skein.



LEO:  Aw.



STEVE:  As I was sort of just hoping they would because I know and like Bruce.  However, they did choose one that was co-designed by someone we know of because he was also the co-designer of Rijndael, which was chosen to be the next-generation AES, the Advanced Encryption Standard cipher.  Now, we're not sure how to pronounce this.  It's...



LEO:  Keccak.



STEVE:  First of all, you could just say SHA-3, SHA-3, which is like saying AES instead of trying to remember how to spell Rijndael, which actually I have a macro now in my brain which spells it for me when I put my hands on the keyboard.  But K-E-C-C-A-K.



LEO:  The press release says it's "ketch ack," or "catch ack."



STEVE:  And that's what I've seen is catch, C-A-T-C-H, phonetically, again, C-A-T-C-H and then A-C-K, catch ack, which looks good enough to me.  Anyway, so a team of cryptographers chose this.  It is very, very fast.  In their work they're getting a byte of hash for every 12.5 cycles on an Intel Core 2 CPU.  But it also is very friendly to hardware implementations which are able to run it even faster.  And I have not looked at it deeply yet.  I think that I probably will because we've talked about other hashes, and this is going to be at some point adopted.  But as we said last week, there doesn't seem to be any hurry towards it because this was started, what, eight years ago in '04, when we believed that AES-2 might have some long-term problems.  So the NIST decided to be ahead of the game this time and have a replacement hash ready.  And it turns out SHA-2, the SHA-2 family of hashes, like SHA-512, for example, that we were talking about last week, is still holding up very well and seems plenty strong.



Anyway, Wikipedia wrote, "Keccak uses the sponge construction in which message blocks are XORed into the initial bits of the state, which is then invertibly permuted.  In its largest instance, the state consists of a 5x5 array of 64-bit words, so 1600 bits total.  Reduced versions of the algorithm are defined for smaller power-of-two word sizes 'w' down to one bit," which would give us 26 bits of total state since we have a 5x5 array of bit sizes.  So 5x5 obviously is 25, and we had a one-bit thing.  That'd be kind of cool to have a one-bit hash.  I've got to look at that.  Anyway, "While smaller state sizes can be used to test" - of course I guess it wouldn't be hard to guess which the hash was.  Anyway, "While smaller state sizes can be used to test cryptanalytic attacks, intermediate state sizes" - for example, a word size of 4 with 100 bits of state, or a word size of 32 with 800 bits - "also provide practical, lightweight, alternatives."



So what all that means is that we have a new hashing standard whose word size is dynamically variable.  And what excites people about this is that it is extremely different from the existing SHA-2 family.  So cryptographers like that because they explain, if it turns out that the SHA-2 family do develop some sort of problems, or, that is, we learn something about them that we don't now know that weakens them, this Keccak, which has now been awarded SHA-3 status, it's so different that any problems SHA-2 has, SHA-3 absolutely will not have.



So anyway, that's our news for the week.  We now have a next-generation hash standard.  The feeling is there's no big hurry to implement it.  I'm sure people will do hardware implementations.  There will be referenced software implementations in all the various languages, so you could choose whatever you like.  And perhaps because it is faster than SHA-2, if there's some reason, for example, in a closed system, where you're the only one who is using the SHA-3 results, you might just go ahead and choose to use it, where its speed or its scalability are of use to you.  Whereas, for example, the existing SHA-2 family have the advantage of already existing universal adoption.  And so, for example, you could send somebody a file and say the SHA-512 hash of this is the following, and they're able to reproduce that, and you know that they're able to do that.  Whereas right now we have zero adoption level of the successor.  But we have chosen it.  So that's cool.



LEO:  You know, I thought the other thing I found interesting in their description of this, they said it seems unlikely, the difference in design and implementation from SHA-2 means that it seems unlikely that any attack that attacks SHA-2 would then be useful attacking SHA-3.  So they intentionally chose something that deviates sufficiently from SHA-2 that one attack couldn't theoretically attack both.  Somebody would have to come up with two different ways of attacking.  Which is clever.



STEVE:  And when we discuss it, as I imagine we will at some point, it will doubtless seem like serious propellerhead-level technology.  But to the cryptographers, what they really like about it is that it's extremely simple.  That is, they think of it as extremely cryptanalyzable.  So it's not like it's some random bizarre mess that might have unexpected behavior which isn't obvious on its surface.  Instead, it is an extremely transparent clear construction, which makes the cryptographers very comfortable that they can see what it's doing.  They understand how it works and why.  And they're able then to represent that it looks like it's going to be very secure.  So anyway, we have our next-generation hash.  We don't need it.  But we do have it.



LEO:  Yay.



STEVE:  And nothing came onto my radar in the security space besides that this week.  I'm sure I could have dug around and found some things, but there wasn't anything that seemed very important.  So that's all I have on that side.



LEO:  You know what, it's okay.  Doesn't have to have an hour's worth of tech news every week.



STEVE:  In keeping with that spirit, I thought I would, I mean, I know all of our listeners know about SpinRite and how it operates and what it does.  So I thought I would just share a nice tweet that I saw come through my feed.  Someone whose handle is @TALK_HARD tweeted:  "My main HD crashed in the middle of the night!  Thank God for SpinRite and @SGgrc!!!  Recovered the entire 1.5TB drive OS and all!"  So thanks for sharing that, @TALK_HARD.



LEO:  All right.  Now let's talk about - I'm putting my box away.  Let's talk about near field communications.



STEVE:  Okay.  So probably the best way to introduce this is to summarize a bit of the dark side.  I mentioned Charlie Miller at the top of the show.  The title of his talk, which he gave at the recent Black Hat 2012 Conference a few months back was "Don't Stand So Close to Me."



LEO:  [Laughing] I don't think this is what Sting was thinking about when he sang that song, but all right.



STEVE:  No.  "An Analysis of the NFC Attack Surface."  And I should preface this by saying, what Charlie looked at, to his credit, is the current state of implementation.  So I'm largely going to talk about the technology of NFC because that's where we are today.  But there's nothing fundamentally insecure about NFC.  As we have seen so many times, it's the way it was implemented which is the problem.  Now, having said that, there's, as our listeners know, there's a fundamental tension, I guess maybe is the best way to put it, any time you have radio because you have variations in distance.  We've got famous uses of Pringles potato chip cans to create focused-beam WiFi that allows much greater ranges than people were anticipating.  So the idea of something wireless immediately creates some tension which we need to do the right thing with.



But so in the preview before his talk, Charlie put together a couple paragraphs to sort of tease his presentation.  He said:  "Near Field Communication (NFC) has been used in mobile devices in some countries for a while and is now emerging on devices in use in the United States.  This technology allows NFC-enabled devices to communicate with each other within close range, typically a few centimeters.  It is being rolled out as a way to make payments, by using the mobile device to communicate credit card information to an NFC-enabled terminal.  It is a new, cool, technology.  But, as with the introduction of any new technology, the question must be asked what kind of impact the inclusion of this new [functionality] has on the attack surface of mobile devices.  In this paper, we explore this question by introducing NFC and its associated protocols.



"Next, we describe how to fuzz the NFC protocol stack for two devices, as well as our results.  Then we see, for these devices, what software is built on top of the NFC stack.  It turns out that, through NFC, using technologies like Android Beam or NDEF content sharing" - which I'll define and explain later - "one can make some phones parse images, videos, contacts, Office documents, even open up web pages in the browser, all without user interaction.  In some cases, it is even possible to completely take over control of the phone via NFC ... stealing photos, contacts, even sending text messages and making phone calls.  So next time you present your phone to pay for your cab, be aware you might have just gotten owned."  So that was the introduction.



LEO:  That's depressing.  I had higher hopes for this.



STEVE:  [Laughing] It really is.



LEO:  Wasn't that the idea, though, that this is an RFID with a near field, a very limited range?



STEVE:  Yes.  So that is exactly what it is.  Probably the way to characterize this best is to think of this as almost contact where you're using radio to replace actual connections.  Probably many of us have seen traditional smart cards where on the backside of the card, or sometimes on the front, there's a little sort of a pad of gold contacts.  And so you slide your card into a reader, and it comes into contact with those contacts on the card.



Well, contacts are problematical.  In engineering terms, they're actually expensive.  It's one of the reasons, for example, that we're seeing a movement towards serial devices rather than parallel devices.  Original hard drives were the so-called "parallel ATA," the PATA.  New drives are "serial ATA," SATA, because even though parallel would allow you to move more data across channels in parallel, it turns out that our technology's gotten so fast that interconnection ends up being a greater problem than speed.  And even the PCI bus is a serial bus rather than a largely parallel bus, as the original PC buses were.



So this is a step sort of one step further, to remove the electrical contacts from the interface and just do it over radio.  And exactly as you said, Leo, RFID was the precursor technology for this kind of application space.  Yet NFC is deliberately designed for much shorter range.  When I drive through the toll road transponder, I've got the little transponder in my window.  That's an RFID transponder that is being read at a distance of, what, maybe two or three meters from my car windshield.  And many people are familiar with those toll road-style transponders.



The range for near field is on the order of an inch, 2.54 centimeters.  So that's, like, 2.5 centimeters is one inch.  And even in Charlie's paper he talks about having experimented with this.  And in the real world the maximum range is, he says, two to three centimeters, so that's right in this, like, one-inch region.  The term "near field" comes from the original expression of the way electromagnetic radiation radiates.  The traditional radio that we're used to operates in what's called the "far field."  This was all laid out back in the mid-1800s, in the 1860s, by a Scottish physicist and mathematician named James Maxwell, the so-called "Maxwell's Equations," which are really - they're hairy partial differential equations which describe how electromagnetic propagation works.



It turns out that there are different properties of propagation which apply when you are within only a few wave lengths of the radiating surface, the antenna, as opposed to when you are many, many wave lengths away.  One way to think of it is that, if you're really far away from an antenna, even though that antenna has a physical size, it looks more like a theoretical point source to you, so that the wave fronts are coming more in a coherent fashion.  But when you're very close, then you're able to sort of feel the physical distribution over the span of the antenna.



So there's a very different set of properties between near field and far field.  And this involves a complex interaction between electrostatic fields involving charges and electromagnetic fields involving a magnetic field.  So to sort of place this on the spectrum of things, near field operates at a relatively low frequency.  It's right in the middle of the shortwave band.  You'll remember from your licensing, Leo, that short wave is between about 3 and 30 MHz.



And the near field spec - and all of this has been ratified and unified.  There's an NFC forum that maintains the specifications.  There's about 160 companies that are now members and signed on to support NFC-compatible stuff, whether it's phones or passive tags, NFC tags or whatever.  But there's a good set of unifying standards to keep everybody talking on the same, literally on the same frequency, but also with compatible protocols.  So NFC is just about right in the middle of the short wave band, which runs between 3 and 30 MHz.  It's at 13.56 MHz.  By comparison, for example, Bluetooth is around 2400 MHz, which also is 2.4 GHz.  WiFi is around the same place as Bluetooth and also at double that, at about 5 GHz.



So of course WiFi was designed to replace LAN wiring.  Bluetooth was designed to replace cell phone cables.  And similarly, NFC was designed to replace sort of the existing contact smartcards.  So the technology involves a coil antenna, some sort of printed coil, and typically one chip over on the tag side.  You can have, in the way near field functions, there's normally a master and a slave, the master being the controlling party in this two-party communication.  Near field is always a 1:1 pairing, that is, a 1:1 relationship.  There's nothing, for example, like a LAN where you have multiple devices all communicating at once, nor even in Bluetooth where you have the so-called PAN, the Personal Area Network.



In near field, again, the way to think about this is they tried to design it so that it was very much like having a smartcard with contacts, but we removed the contacts.  So everything about this is designed to be in physical proximity, but not an electrical connection.  Instead, it's a short distance radiation connection.  So, for example, they have this notion of a - they call them in the forum, and formally defined in the spec, they call it a "Smart Poster," where at some point in the future there may be a poster hanging up on a wall, and there will be the sort of the near field logo, which people over time will get to recognize, sort of a stylized "N" that looks a little bit like a lightning bolt.  And that will be your cue that underneath that "N" on the poster is an NFC transponder.



So it has no batteries.  It just sits there waiting to receive power from someone's cell phone, typically.  So you would essentially touch your cell phone to the poster.  You don't actually have to physically touch it, but it's just sort of easier because you've got to get about that close to it.  And the field, the radiated field from the cell phone's near field master, essentially powers up the chip in the transponder.  And so this 13.56 MHz frequency provides power to the chip.  The chip then modulates the power in its coil to essentially put a load on the transmitter.



So the transmitter can sense that it's being loaded down because its magnetic field has coupled with the magnetic field of the transponder in the poster.  And by altering the load that the transponder puts on its own coil, the transmitter is able to sense that, and they're able to communicate.  Communication can be bidirectional, and it can be simultaneous, and there is in the specification a means for dealing with collision.  So if, for example, there was - I don't know, I mean, collision is not something you would encounter often because the distance of this whole system's operating is so sort.  But they do have collision avoidance approaches in cases where you had two transponders too close to each other.



So the first mode of operation is that, where you have an energizer and a passive source of information, essentially.  And, when energized, the passive source of information gives up what it's got, whatever it might be.  And, for example, in the case of a poster, in the so-called "NFC poster spec," you receive a little burst of information which actually moves at a pretty good rate. With a 13.56 MHz carrier, the information is set at 1/128th of that, which of course we know is 2^7, so that's a nice power of two.  Which means that the tag is able to clock its data slaved off of the receiving signal.  So it's sort of a self-clocking format, which is good for making these tags passive and non-battery powered and very inexpensive.



But, for example, when it's energized, the tag actually comes up and is in an idle state.  And then there's a command-response protocol which has been defined.  So this is all much more sophisticated, again, sort of next generation from what we have from the early RFID tags, which are much simpler and simply send back a static fixed serial number to identify themselves.  Here the tags are able to be field programmed.  You can actually buy paper rolls of these things that are sticky on one side that have, for example, in one case, 144 bytes of nonvolatile memory which can be selectively made read-only so that you can put data into this through the field and then set write-only bits on all or a portion of this data.  And then, through a series of commands, you're able to later query the tag for its contents, but have no permission to modify it.  So there's that first mode.



Then there's also the mode where you have a device pretending to be a tag, that is, it might be an active device which is not actually a passive tag, but it's pretending to be one.  So the interaction is exactly the same as in the case where it actually was a passive tag.  And then in the third instance you actually have a peer-to-peer relationship where both devices are actively generating their own local near RF field, and then they come into physical proximity with each other and are able to initiative a handshake and exchange data.



So what do we do with this?  Well, for one thing, we have, for example, this Smart Poster notion, which is one of the predefined specifications, where a burst of data might contain a title and a URI, that is, a URL-style universal resource string, which we're used to from Internet URLs, containing a reference to a web page, or an image on the 'Net, or some other sort of addresses accessible to the device that is receiving the information.  In this poster format they talk about a so-called "action record," where the device you are pinging, querying, suggests what action should be taken given the URI that it has sent you, and there's an icon record so that it might also present on the screen some sort of information that the user would be given and take advantage of in order to sort of define what it's doing.



So that's sort of the whole scope of what near field is.  It is short physical proximity, on the order of an inch.  There have been some experiments where they have beamed power at a tag that was further away and had the tag modulate their beamed field and receive it.  So we have some of the problems that we've got with any time you remove electrical contact and switch to radio, you're making some assumptions about the radiated power of the thing that is powering the device and your ability to sense its loading down of your field.  So distance is somewhat fuzzy.  But itself, the near field spec just says this is the frequency we operate at, here's the protocol for the way these devices communicate, and on top of that people can put whatever they want.



So one of the other application areas, aside from the so-called Smart Poster, is this notion of using a near field communication to bootstrap into a more potent communication.  For example, we've talked about the problems of establishing a passphrase on a WiFi hotspot.  If you've got a very complex, crazy passphrase, it can be difficult to enter that into another device.  If instead your WiFi router came with a near field-capable radio as part of it, then you could, for example, get your cell phone onto that WiFi router just by tapping the cell phone against the router.  And so the idea would be that, in that application, they would exchange the information over a bandwidth-constrained, because I don't know if I mentioned that it's about 106Kb per second, so it is dramatically slower than WiFi or Bluetooth.  But the idea is, I mean, that's all the speed you would need for a Smart Poster to send you a URL or to perform some simple credit transaction with a near field terminal.



But the idea would be, in the mode where you have a WiFi hotspot, you would tap two devices together.  They would exchange information about the other much more capable protocols, which then come into service as you pull the devices apart.  And that's one of the frequently mentioned applications for this is - in fact that's the way the Android Beam functions is, that you've got two Android phones which don't yet know about each other.  You tap them together.  They use NFC to handshake and agree upon crypto-level data which they then use to encrypt and exchange files over their WiFi connection because they've got a much more capable WiFi radio, capable of much higher bandwidth and much greater operating range.  But you want that to also be secure.  So by briefly bringing them together, you essentially synchronize them, and then you pull them apart and establish the communication that way.  So it's a cool technology, Leo.



LEO:  You know, the thing about Apple not adopting it, the only reason I was hoping they would adopt it is because it would obviously jumpstart it; right?



STEVE:  Yes, yes.



LEO:  But I think that it is new, and nobody's using it yet.  So, I mean, very few.  Peet's uses it, a few places like that, Peet's Coffee here in San Francisco.



STEVE:  Yeah, and as I mentioned, I have it in my BlackBerry phone, which I've had for about a year and a half.



LEO:  That's interesting.



STEVE:  It's like, okay.  It's nice that it's there.  I have it turned off.  And that's one of the other things that Charlie's takeaway from his presentation was - so what Charlie found was not surprising.  It's very much like the exact same domain of problems that we've seen over and over, which is that sometimes the people who are implementing this don't get all the details right.  There's nothing fundamentally secure or insecure about near field communication.  It's just a short-range means of exchanging relatively low bandwidth, that is, 106Kb per second, data between two devices, one of which may be completely passive and have none of its own local power source.  Yet you can still write to it in an EEPROM sort of fashion and read back from it.



But what happened was some of the early implementations, for example, didn't require any user interaction.  And that's his main takeaway is, yes, it's less convenient if you have to acknowledge a near field event, but so much more secure if the user is required to accept, to look first at what is about to be done and then say, okay, yeah, that looks like something I want to do.  And some of these early implementations for the sake of, oh, how sexy it is that you just bump it up against a poster or you tap two devices together and this all sort of happens by magic, with no user intervention required, as we well know, the flipside of that is going to be problems with security.



LEO:  So would you - well, I mean, I don't know.  So you would use it if it were widely available, or...



STEVE:  So I would have it off.  I would have the radio off all the time.  This parallels our recommendation for Bluetooth.  You'll remember, Leo, that time I came up to do a show with you in Vancouver, and it was on the whole Bluetooth security and pairing, and I had an application I brought with me that showed us all the Bluetooth radios within range, and virtually everyone in the studio had their Bluetooth enabled on their phones.



And this was at a time when Bluetooth was still not really solid.  I mean, it's gotten a lot more secure, mostly because focus has been put on the security aspect.  But there were ways early on that Bluetooth could be used to suck people's address books and contact lists and calendars and things out of their phones.  So back then the advice was, if you don't know you're needing it, turn it off.  Keep it off all the time because, well, and if nothing else, you're saving power because power is a scarce resource on a phone.  So keep your Bluetooth off unless you're using it.



Now, of course, where we've got, for example, a law in California forbidding people from using their hold-it-in-your-hand handsets, there has been a huge jump up in Bluetooth being used to communicate with the little in-ear headsets.  And so I imagine it's on a lot more often.  What you definitely want to do is turn off pairing so that it's not sitting there broadcasting itself and trying to hook up with every Bluetooth radio in the area.  But I would say the same advice applies for near field.  On my BlackBerry I've got it...



LEO:  But it's a lot shorter range; right?



STEVE:  Yeah.  Oh, I mean, it is.  It's one inch.  It is going to be absolutely difficult...



LEO:  Yeah, the attack surface, there's no magic that you could get to it from across the room, or is there?



STEVE:  Well, that's the problem with radio is there's nothing - it doesn't absolutely drop off.  It sort of fades out.  And it fades out very quickly.  But we've seen situations where somebody with a focused antenna can beam power over a much larger distance and establish a radio link where it wasn't expected, where the assumption was that you're okay.  I remember you and I talking about Bluetooth; and, like, there was a window of opportunity during Bluetooth pairing where an eavesdropper had some advantage.  And you and I on this podcast years ago talked about going out into the middle of a parking lot where you could see all around you...



LEO:  I could find my car.



STEVE:  ...that nobody was within 10 meters, or 30 feet, which is the nominal range of Bluetooth in order to do your pairing, so that you didn't have to worry, just during that brief moment, anybody being able to eavesdrop on you.  So this is a lot better.  I think there's no question this is going to take hold.  This is going to get traction.  People are going to like it.  Again, people like convenience.  And so the convenience factor is going to drive this forward.  It creeps me out just because I - and I'm sure it does some of our listeners because we've seen over and over and over how many ways there are for these things to go wrong and that, when faced with a choice between security and convenience, initially the industry chooses convenience.  And it's only after it gets burned a few times it backs off and says, oh, okay, I guess maybe have to ask before we do that.



LEO:  So maybe Apple's wise to wait.



STEVE:  I just - I'd like to have it in the phone.  Leave it off.  Turn it off by default.  But have it there so that, I mean, it just seems like a bullet point missing.  I don't know when they are going to do iPhone 6.  Maybe that's already in the works, so they've got it coming soon.  But, boy, I think it's 40 million devices now have near field.



LEO:  Wow.



STEVE:  And all of the new smartphones do except coming from Apple.



LEO:  Yeah, certainly my Sun Galaxy S3, the Galaxy Nexus have NFC.  I'm surprised your BlackBerry does.



STEVE:  Yeah.  I wonder if - do you know if the Nexus 7 does?  I don't remember seeing it.  I don't think it does.



LEO:  I don't think so.  That's interesting because that's a tablet, not a phone.



STEVE:  Right.  But still, I mean, I think...



LEO:  HTC does not apparently put it in their One X.  The new Lumia 920 will, I know, for the Windows Phone folks.  So I don't know, I mean, that's a big number, but I think that it's certainly far from universal.  Nexus 7 does, according to Didao [ph] in our chatroom.



STEVE:  There are some beginnings of security protocols.  One of the things that I encountered when I was looking at this is that RFID had absolutely no provision for encryption, but NFC does.  So we're not seeing it deployed yet.  But, for example, I can imagine a scenario where future laptops will have an NFC logo on their, like, front surface down by the touchpad, in front of the keyboard, and you might authenticate by bringing your phone to your laptop briefly.



LEO:  Oh, yeah, wouldn't that be neat.



STEVE:  Which is not a difficult, exactly, not a difficult thing to do.  And so we begin to get aspects of multifactor  authentication that way, too.  I mean, I think we're going to be seeing more of near field in the future.  I'm sure this is not the last podcast we'll be discussing it.  Unfortunately, any future podcasts will be probably talking about what went wrong rather than how it works.



LEO:  Right.  NFC, the horror, the horror.  That'll be some future date.  Episode 472, perhaps.  Considerate's saying in the chatroom that according to Wikipedia the distance record for detecting Bluetooth is 1.78 kilometers.  So for a 30-foot, nominally 30-foot.  So you make the point exactly.  That's, you know.  Of course it has to do inductance, which is more difficult than just a radio.



STEVE:  Yes, that is true.  Because it is near field, the field falls off very quickly.



LEO:  But so does RFID; right?  RFID is an inductance-based system.  And that works great, you know, you go through a toll booth, that's...



STEVE:  I think it was 10 centimeters was the number I saw in the forum for, like, their maximum theoretical range.  And so, what's that, about...



LEO:  It's not far.



STEVE:  ...4.5 inches or so?



LEO:  2.54 centimeters to the inch.



STEVE:  Yeah.



LEO:  So whatever.



STEVE:  Oh, yeah.  So 20 - wait.  Yeah, so I don't know.



LEO:  Divide by two.



STEVE:  Four or five inches.



LEO:  By the way, correction, apparently the HTC One X does have NFC.  Somebody has one in the chatroom, says no, no, mine has it.



STEVE:  I really do think it's on its way.



LEO:  Majority of new smartphones, yeah.



STEVE:  Yeah, I think Apple's decision not to include it, I don't understand it in the iPhone 5.  But this is going to be - I think this technology is going to take hold.  And we're going to see it used a lot.  I'm not so sure I'm a fan of bumping it up against random posters because that just seems...



LEO:  We have an NFC chip on the wall as you come into the Brick House.  We have a guest tile, and you tap it, and it'll check you in on Foursquare.  It doesn't, by the way, doesn't do the check-in all the way.  It just launches Foursquare, says you're here, and then says would you like to check in.



STEVE:  Nice.



LEO:  Yeah.  And I think that's probably how most people will implement it.  That's using Samsung's built-in software on the phone.



STEVE:  Yeah.  One thing we've not talked about yet is QR codes.  That's also on my list of things to - of, like, technology to...



LEO:  That's kind of the competing the technology for this.



STEVE:  Yeah.  And of course that's optical as opposed to radio.  And to me that seems a lot - actually I'm seeing QR codes all over the place now.  They're beginning to get some traction.



LEO:  I saw a gravestone with one.



STEVE:  [Laughing]



LEO:  I kid you not.



STEVE:  You are here.



LEO:  Yeah.  I don't know, maybe it pulls up a page with his life story.  I don't know.  I didn't take a picture of it.  I should have.



STEVE:  No kidding.  Was it etched or...



LEO:  Yeah.



STEVE:  Wow.  Well, there's a geek.



LEO:  Well, and it's also somebody who has a lot of faith in the technology.  Like 50 years from now are people going to be able to read QR codes?



STEVE:  On my headstone.  Yeah, that's a very good point, Leo, yeah.



LEO:  Steve Gibson is the Explainer in Chief.  There's actually a Tumblog, "WTF QR Codes."  Thanks to Jesse in our chatroom for this.  Like, why is there a QR code here?  And there's lots - so it's cute.  It's like - let me see if - so people are putting them everywhere.  Here's one, fish on a grate.



STEVE:  I guess that's one of the cool aspects of the QR code is, because it is optical, it's even lower technology than a passive near field tag.  And all phones now have cameras.



LEO:  Just need camera software, yeah.



STEVE:  Even the iPhone 5.



LEO:  Yeah.  Yeah.



STEVE:  It is a neat technology.  I'll just remind our listeners that I just tweeted the link to Charlie Miller's presentation, which I think is 40-some pages and lots of neat pictures and diagrams and technology.  He spends much less time on how it works that I just have and much more time on what he did to break it, which is, I guess, I mean, it's certainly of interest to our listeners and the topic of the podcast.  But I just sort of shrug a little bit.  It's like, yeah, well, it's not NFC's fault.  It's that the people who did it made some mistakes and, more importantly, never put in a confirmation.  Do you want to do this?



LEO:  Right.



STEVE:  And I think that's just crazy.



LEO:  But that's implementation specific.  You could, I mean, for instance, you use Google Wallet, it will give you a PIN.  So that's something the app should do.  But again, well, maybe - no, because if you don't do it in the app, if you don't require it, then you could hack it silently.



STEVE:  Right.



LEO:  Yeah.  Steve Gibson's the Explainer in Chief at GRC.com.  That's where you'll find him.  His Twitter handle is @SGgrc.  When you go to GRC.com, pick up a copy of SpinRite.  You never know when you might need it.  It's the world's best hard drive and maintenance and recovery utility.  And, you know, it's Steve's bread and butter.  So, yes, let's everybody buy it.  But there is a lot of free stuff there, including 16Kb audio versions of this show for the bandwidth-impaired and full transcriptions, which Steve pays for, at the Security Now! pages there.  And of course his show notes.  We also have show notes on our wiki, thanks to some guy whose name we can never remember, but I will find it out for next week.  We also have full quality audio and video versions available on the TWiT page, TWiT.tv/sn.  



STEVE:  I'd also remind people that a side effect of Elaine's fantastic transcripts is the entire textual content of all 371, soon to be 372, podcasts are searchable.  And when I encountered Charlie Miller's name in the Black Hat Conference, I thought, Charlie Miller, I'm sure we've talked about him.  So I went over to GRC.com/sn.



LEO:  See?  Yeah, search right through it.



STEVE:  And in the search field I put "Charlie Miller," and bang, there was a complete chronology of all of our discussions of Charlie.  So I was able to remind myself exactly what it was that Charlie had done in the past and why he was so familiar to us and our listeners.  So it's very handy.  If something comes up that you sort of think you remember hearing about, you can just go over and quickly find the references to it.  It's really handy.



LEO:  I love the Internet.  Speaking of which, I found an ABC article that says "Digital QR codes offer interactive cemetery experience.  Funeral directors are seeing an increase in demand for gravestone bar codes."



STEVE:  No kidding.



LEO:  That is just...



STEVE:  Wow.  That's...



LEO:  ...crazy.  Crazy.  We do this show every Wednesday, 11:00 a.m. Pacific, that's 2:00 p.m. Eastern time, 1800 UTC, on TWiT.tv.  Tune in live.  We can interact through the chatroom.  And as you can see, I use the chatroom a lot to flesh out the show, so to speak.



STEVE:  Yes, and GRC.com/feedback.  We'll have a Q&A episode next week.  Let me know what's on your mind, what you're curious about, any questions that the NFC technology brought to mind, and we'll talk about them next week.



LEO:  Thank you, Steve.



STEVE:  Thanks, Leo.



LEO:  See you next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#373	

DATE:		October 10, 2012

TITLE:		Listener Feedback #152

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-373.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with the latest security news.  We'll talk about Microsoft's Second Tuesday Updates, which happened yesterday.  And then we answer your questions:  10 questions, 10 answers, coming up on Security Now!.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 373, recorded October 10th, 2012:  Your questions, Steve's answers, #152.



It's time for Security Now!, the show that protects you and your loved ones online with Mr. G., Steve Gibson, our Explainer in Chief.  He's the host at GRC.com, the inventor of, well, the coiner of the phrase "spyware," the inventor of the first antispyware.  He's also the author of SpinRite, the world's best hard drive maintenance and recovery utility.  A very good day to you, Mr. Gibson.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again, as always.



LEO:  A Q&A episode today.



STEVE:  And before we began recording I mentioned to you something that Elaine had mentioned to me, that, well, it's belated and then some, but we sort of let an anniversary of the podcast slip by unnoticed, unmentioned, unobserved.



LEO:  This must be our third or fourth year by now.



STEVE:  [Choking]



LEO:  [Laughing]  Well, let's see.  Let me do the math.  Modulo 52.



STEVE:  [Still choking]



LEO:  You and I can do that because you've only missed one show per four, so it wasn't your idea.  We made you miss a show.



STEVE:  Oh, and believe me, I've never been forgiven for that, Leo.  That was...



LEO:  Who does not forgive you for that?



STEVE:  The listeners.  Oh, they were quite upset.



LEO:  Oh, come on.



STEVE:  Well, it's just that we had - we'd never missed a week.  And I like that kind of absolutism.



LEO:  I know you do because you're an engineer.  And it's like, perfection is the only option.



STEVE:  It's either true or it's false, and it had been for a long time.  Suddenly, never again.



LEO:  So missing one episode is as good as missing 500, really, from your point of view.



STEVE:  Anyway, at one point we were talking about our anniversary, which slipped by in August.  We ended our seventh year and began Year Eight, which we're already well into.



LEO:  Episode, what, 364 would have been the seventh year.



STEVE:  There's a lot of controversy about that, Leo.



LEO:  Did we begin with one or zero?



STEVE:  You can't do any kind of a 52 thing.  You've got to just look at the date.  And that's what Elaine did.  She said, "Your first podcast was on August" something or other [August 19, 2005].  And another one of those went by.  It's like, oh, well, I guess that would be the end of the seventh year.



LEO:  Happy Anniversary, Mr. Gibson.



STEVE:  Leo, we're going strong.



LEO:  Wait a minute.  We finished seven years.  We're in our eighth year.



STEVE:  Yes.



LEO:  Jiminy.



STEVE:  Yes.



LEO:  Jiminy Christmas.  Wow.



STEVE:  And we just haven't run out of anything to talk about.



LEO:  We've said this before, but you were very worried when we began this that there would not be enough.  And we only did a half-hour show when we first started.  We're now doing four times more each week.



STEVE:  I know.  It's freaky.  I look back at the early podcasts, and I think, whoa, 29 minutes?  Really.  Okay.  Wow.



LEO:  So it's almost four times longer, and we still haven't run out of stuff.  So there was considerable misjudgment on the amount of horror that lay out there on the Internet, waiting for us to reveal it.



STEVE:  Yes, the horrors just keep on coming.



LEO:  The horror, the horror.



STEVE:  Speaking of which, well...



LEO:  Go ahead.  Go ahead.



STEVE:  We have interesting news.  This is a Q&A episode, our 152nd Q&A, Episode 373.  So I think we've got a good podcast for everybody, as always.



LEO:  All right.  Let's get the security news here.



STEVE:  Okay.  So we are here on, what is this, the 10th of October, meaning that we had our second Tuesday just yesterday.  Microsoft did a relatively small update.  There were seven updates, which fixed a number of security issues in Windows Office and SQL Server.  Interestingly, the big problems were not in IE and Windows, as is usually the case, but some sort of an exploit that affected Office and their Server products.  That was the only thing that was rated critical, which was a remote code execution problem somehow involving RTF, Rich Text Format, files.  So, as always, keep Windows updated and you'll be okay.  And then they just had five other miscellaneous security things, privately reported vulnerabilities.



Interestingly, RSA - the inventors, well, the pioneers of early asymmetric crypto and famous RSA - have been warning of an impending attack on online banking.  In a post from, I guess it was actually last week, their head of cybercrime communications, Mor Ahuvia, wrote:  "In one of the most interesting cases of organized cybercrime this year, a cyber gang has recently communicated its plans" - now, they've been monitoring this quietly and sort of in the same way that Brian Krebs has established himself and is sort of part of that underground so he can see what's going on.  "A cyber gang has recently communicated its plans to launch a Trojan attack spree on 30 American banks..."



LEO:  Oh, great.



STEVE:  Yeah, "as part of a large-scale..."



LEO:  Don't mind the grinding.  I'm just making my coffee.



STEVE:  Okay.



LEO:  I'll turn off the mic.



STEVE:  "...as part of a large-scale orchestrated [crimeware] campaign.  Planned for this fall" - so coming to you before the holidays, "the blitzkrieg-like series of Trojan attacks is set to be carried out by approximately 100 botmasters," who therefore are independently running about 100 bot networks.  "RSA believes this is the making of the most substantial organized banking Trojan operation seen to date."  And remember, this is RSA blogging this.  This is not some random nobody.



They said:  "By investigating the group's forum-post announcement and analyzing the Trojan, RSA has managed to link the cyber gang's weapon of choice to a little-known, proprietary, Gozi-like Trojan" - that's G-o-z-i - "which RSA has dubbed 'Gozi Prinimalka.'  Derived from the Russian word meaning 'to receive' and alluding to a Trojan drop point, the word 'Prinimalka' appears as a folder name in every URL path given by the gang over the years to its [crimeware] servers.  According to underground chatter" - which RSA has been monitoring - "the gang plans to deploy the Trojan in an effort to complete fraudulent wire transfers via man-in-the-middle manual session-hijacking scenarios."



And we've talked in the past about how that works, where if you've got something that has infected your local machine, as these Trojan bots would, then they're intercepting your browser's communication to your bank prior to it being encrypted and sent over the 'Net.  So this is not a man in the middle decrypting your SSL communications.  This is a man just on the other side of your keyboard and screen, closer to you really than the middle, but...



LEO:  Man over your shoulder, really.



STEVE:  Man peering, exactly, cyber-wise over your shoulder.  And they said:  "Previous incidents involving this Gozi Trojan, handled by RSA and other information security vendors, appear to corroborate the gang's claims that, since 2008, their Trojan has been at the source of siphoning $5 million from American bank accounts.  Gozi Prinimalka's similarity to the Gozi Trojan, both in technical terms and its operational aspects, suggests that the HangUp Team - a group that was previously known to launch Gozi infection campaigns - or a group closely affiliated with it may be the troupe behind this ambitious scheme."



LEO:  Wow.



STEVE:  "If successfully launched, the full force of this mega heist may only be felt by targeted banks in a month or two.  The spree's longevity, in turn, will depend on how fast banks and their security teams implement countermeasures against the heretofore-secret banking Trojan."



LEO:  Not to put it down or anything, but $5 million in five years is not like, I mean...



STEVE:  Correct.



LEO:  It almost sounds like the scheme in "Office Space," where they were skimming pennies off the top kind of.



STEVE:  Well, and remember, too, that they don't have any control over whom they infect and over the quality of the...



LEO:  So it's hit or miss, yeah.



STEVE:  Right, it's hit or miss.  The Trojan may not be able to intercept the bank that that particular person who is infected by it deals with.  And they may not have much money to lose.  So, I mean, if there's not anything in their checking account except low-level transactional amounts, that's all they're able to get.  So anyway, what RSA is talking about is they're seeing the chatter in the forums as these groups organize.  And apparently they're actually looking for, quote, "investors," unquote, who would be fronting the money to build the backend infrastructure to accept the payments and process them once they've been transferred.



LEO:  Oh, yeah.  Sure, they need a fence.



STEVE:  Yes, exactly.



LEO:  So to speak.



STEVE:  Crazy.  Oh, also Adobe, Monday of this week, a couple days ago, did an emergency out-of-cycle update to Flash, fixing 25 security vulnerabilities.  And an hour later, Microsoft released news of their update to the Flash player which is now bound into IE10.  Because, with Flash having been such a success in the security space, why wouldn't you just build it right into your browser?



LEO:  Now, it's built into Chrome, but it's sandboxed.  It automatically updates.  Well, see, this is the problem, Steve.  I mean, we may not like Flash, but everybody needs it and uses it.  So they're going to install it eventually.



STEVE:  Right.  It's probably going to - you're right.



LEO:  So better to do it this way.



STEVE:  There are still enough sites on the 'Net which require Flash that you're going to end up with it in your browser.



LEO:  I mean, I wish it would go away.  But it's here to stay.  Not to stay...



STEVE:  Yeah, well, I mean, and anyone with an iPad is annoyed by their lack of Flash, frankly, on the iPad because you're away from your main machine somewhere, being mobile, and you come to a site that is just dead without Flash.  So it's like, okay, well, I wish we were migrating to HTML5 more quickly.  But anyway, so...



LEO:  Same with Java, too, by the way.



STEVE:  Yeah, it's true.  That's absolutely right.  And so Microsoft has been in the past criticized for their lack of speed.  In this case they were only 60 minutes lagging Adobe.  So one can hope that, if they're going to have Flash bundled in, they'll be taking responsibility for it, as they seem to be doing now with IE10, and being much more quick about updating.



And in another little blurb, this got past me a few weeks ago.  And I meant to bring it up, but then I think that someone else must have tweeted it to me.  I went, oh, that's right, I forgot to mention this.  Okay.  Every fingerprint reader on laptops everywhere comes from the same company, UPEK.



LEO:  UPEK.



STEVE:  Yeah.  I mean, I'm a big Lenovo user for my laptops, and I like the fingerprint scanner.  We've talked about how nice it is to sort of drag your finger over the little capacitive reader, and it logs you in and unlocks the BIOS, logs you into Windows and so forth.  And it's like, oh, look, we've got multifactor.



Well, a security company, ElcomSoft, just noted back in August that there was a problem with UPEK's software because, when you're setting it up and giving it the ability to log you into Windows, you need to give it your credentials.  Now, the assumption is - and unfortunately that turns out to have been all it is - is that they would do something secure with those credentials.  Turns out they're stored in the registry, not very well encrypted.  ElcomSoft did not disclose any details, but they put out a warning that, for what it's worth, anyone using any biometric fingerprint reader with UPEK software - and I remember when I saw this it was the Who's Who of laptops.  I mean, all the laptops.  And there was Lenovo of course listed, and all the other ones because this is the company that cornered the market on fingerprint software, and nobody else seems to have thought it was worth competing with them.



So last week a security researcher, Adam Caudill, he described himself on his website - he blogs.  And in his description he says, "I'm a software developer, pen-tester" - meaning penetration tester - "and manager.  I'm currently located in Southern Virginia.  I write about development security and anything else that I find interesting, from Microsoft's .NET stack to Ruby, security and exploits, and even a little about photography and lasers."  So he blogged:  "On August 28th, ElcomSoft announced that they had determined a method to extract Windows passwords from the registry of users of UPEK's fingerprint readers and Protector Suite software," and he says in parens, "(UPEK is now owned by AuthenTec, which is now owned by Apple).  What they didn't announce..."



LEO:  Apple Computer?



STEVE:  That's - I didn't verify that.



LEO:  Apple doesn't even have any fingerprint reading hardware.



STEVE:  Isn't that interesting.



LEO:  That's bizarre.



STEVE:  But AuthenTec does other things.



LEO:  They must do other, oh, yeah, yeah, that's kind of - that name sounds familiar.



STEVE:  Yeah, it does.  He says:  "What they didn't announce was the technical details of how they did it.  Myself," he writes, "and Brandon Wilson have been working to recreate their research - and we have.  We have not been in contact with ElcomSoft, so this is an independent rediscovery of this vulnerability."  Of course they also knew where to look from what ElcomSoft wrote.  He says:  "ElcomSoft has committed to not release details, which I understand.  But given how likely it is that others will determine this technique, I believe that this information should be available to penetration testers and auditors so that these insecure credentials can be identified."  Adam then goes on to describe this in detail.



So it's AdamCaudill.com.  Just go there and look at his blog if you're interested.  I'll give a brief summary of what he found, and that is that there was crypto applied.  But UPEK says, and he found, that they just sort of made up their own.  And we always know that's never a good idea.  They have what they call AES-56.  And it's like, wait, there is no such thing as AES-56.  Well, there's AES-256, of course.  Well, what they did, apparently, because they operate on an international scale, they needed to comply with international export restrictions, or they needed their software to be able to operate within countries that legislatively restrict the security of software.  So even though it's not a problem, for example, in the U.S., they have one solution global.  And what they did was simply pad all of the other 200 bits of AES-256 with zeroes, drastically weakening the crypto.



LEO:  That's moronic.  That's actually moronic.



STEVE:  Oh.  And so...



LEO:  I mean, it would have been better to us - oh, that's just moronic.



STEVE:  So it'd be better to do anything.  I mean, you could...



LEO:  Anything.



STEVE:  3DES, for example, would have, I mean, this ends up being...



LEO:  Is it because they don't have hardware to do the calculation?



STEVE:  No.  The only reason, the only rationale that makes sense is that they did this for export restrictions, in order to comply with export restrictions.  Because there is legislation in some jurisdictions which state that you cannot use crypto greater than 56 bits because the powers that be within those regions are able to crack that.  And so what ended up happening was that, without even understanding all of this, Adam and his buddy Brandon knew where to look because ElcomSoft had provided enough breadcrumbs for that, and they just independently cracked it.  So on his blog posting he provides all the details.



So the takeaway, of course, for our listeners is that we should not overly rely on the security of these fingerprint readers; but, more importantly, in providing this information to the fingerprint software to allow it to log us into Windows, we have inadvertently dramatically weakened the security of the system because this is now widely known.  And so if malware gets into our machine, it will know where to look to see if we happen to be on a laptop with a fingerprint reader and UPEK software, and they could grab the key and then decrypt it and get our Windows credentials, which there otherwise isn't a simple way to achieve.  So this is not good.



So it's a classic - what I liked about this as a lesson for our Security Now! listeners is this is a classic case of a bad implementation of a potentially secure technology where the implementation results in greater weakness than if you had never used it in the first place.



LEO:  Well, we saw that a couple of weeks ago where they were storing passwords in the clear in the registry; right?  So this is the second flaw.  I don't know if it's the same company, but the second flaw with fingerprint readers.



STEVE:  Yeah.  This is, well, this is in the clear.  Well, this is not, I'm sorry, this is not in the clear.



LEO:  Not in the clear, but it's just stupid encryption.



STEVE:  Yes, exactly.



LEO:  Just badly encrypted.



STEVE:  Weak, roll-your-own encryption.  And the point is that you end up with worse protection because you now have your Windows logon credentials, badly encrypted in a way that everyone understands, sitting in the registry.  That's normally never the case.  So essentially you told the software how to log you into Windows, and it's not protecting that from anything that had access to the registry.  So any malware that got into your system could look to see if this was there and acquire your Windows credentials that way.  So that's not good.



I guess if this is of concern to someone, then what you have to do is stop using UPEK's fingerprint reader software.  I would check in with AuthenTec and look for updates or news.  They're not saying anything.  People have asked AuthenTec what they think, and so far no official response from them.  So until this gets fixed, what you would want to do is change your Windows password, your logon credentials, and don't tell the UPEK fingerprint reader about it.  Disable its logon because...



LEO:  It cannot be trusted.



STEVE:  ...you don't want to use that anymore.  Yeah, you can't trust it.  You can't tell it what your new credentials are.  And then once this gets updated - it's got to be updated.  I would imagine somebody's working on this now.  And then you can move forward.



LEO:  Dr. Mom wonders, because fingerprint readers are routinely used in things like pharmacies and hospitals to keep unauthorized people from taking medication, if this applies to other fingerprint scanners.



STEVE:  No, it would just be Windows with this UPEK software.  In fact, I mentioned before the podcast, Leo, that I was helping a neighbor who needed some medical care yesterday, and I was watching the security in ER.  And I thought it was interesting when the nurse...



LEO:  Of course you were.



STEVE:  ...when the nurse, she dialed in the automated IV metering.  And I watched her scan her badge and have her thumb scanned in order to take responsibility for, essentially log into the fact that she had just been the person who set this up.  So it's like, oh, interesting, cool.



LEO:  Right.  Yeah, that's, I think, what Dr. Mom's talking about.



STEVE:  But no problem, just Windows.



LEO:  Just Windows.  As long as they're not using Windows with Internet access.



STEVE:  And I did run across a nice note from a listener who ended up posing a question that I thought our listeners would find interesting.  Robert Osorio in Lady Lake, Florida, he said - the subject was "Another SSD/SpinRite testimonial."  He said, "Steve, just to let you know that you can add me to the list of SpinRite users who have found SpinRite useful for reviving SSD drives.  I'm an IT consultant and have been using SpinRite for a couple of decades.  I have an older Intel X25-M" - which is very nice - "SSD drive that was the boot drive for my main workstation.  I recently upgraded to a much faster SSD and relegated the old Intel drive to a laptop.  However, in time, I started getting OS issues that, on a spinning drive, would have indicated bad sectors and would have had me running SpinRite on it immediately.  Since this was an SSD, I thought all I could do was update the firmware, which I did.  And it did help for a while.  Or I could just write off the drive.



"Then I heard you mention on a recent podcast that running SpinRite Level 1 on an SSD could help, so I gave it a shot.  It made a dramatic difference, and now this drive is running smoothly once again.  I have now run SpinRite Level 1 on all my SSDs and will continue to do so on a regular basis for preventative maintenance."  He says, parens, "(I religiously run SpinRite Level 4 on all my spinning drives every six months or so, as well.)  I did want to get a clarification from you, and I'm sure other listeners would appreciate this, as well.  You recently read a testimonial from someone who recovered an unreadable Flash drive using SpinRite Level 2, and you indicated that was a valid procedure.  Am I correct in assuming, then, that it's okay to run Level 2 on an SSD or Flash drive for preventative maintenance?  Or should I use Level 1 for preventative maintenance and Level 2 for data recovery only?



"My concern is avoiding excess writes, which would prematurely wear out the memory cells, thus your admonition against running Level 4 on solid-state media, since it performs aggressive writes.  Reading from your documentation, it appears that Level 2 is only performing writes if it recovers data from a damaged sector and then has the drive relocate it.  As such it seems that Level 2 is not much more aggressive on writes than Level 1 and should be safe to use on a regular basis on SSDs.  Thanks again for a great product and a great podcast."



And Robert's exactly right.  The difference between Level 1 and 2 is that Level 2 will perform some pattern testing on the area, so doing some writing, if it runs across a problem.  And that's probably more useful on magnetic physical drives than on SSDs.  So I would advise using Level 1, which is sufficient on SSDs, where you want a read-only process.  Level 2 makes more sense on magnetic drives where you want maximum speed and just a read pass over the drive, and then SpinRite will do more work with testing the surface if you end up with a problem at Level 2, which it does not do at Level 1.  Level 1 is meant to be just a read permission-only pass.



We'll remember that a week or two ago I read a note about SpinRite recovering data even when it was run at Level 1, but that was the drive essentially doing the recovery, not SpinRite.  And with SMART drives now that can happen.  So again, Level 1 for SSDs, Level 2 for hard drives.  And it's great to see more evidence that SpinRite can be useful on SSDs because of course that's where the world is headed at some speed.



LEO:  Yeah.  It's good for you.  Yeah.  Good.  Well, I'm not surprised.  I mean, I guess it just means that there's certain things it couldn't do.



STEVE:  Well, the fact is, SSDs actually share a surprising chunk of hard drive technology.  There is error correction going on because those cells unfortunately are - or I guess, well, yeah, unfortunately are being downsized to the smallest degree possible, or downsized to the greatest degree to make them as small as possible in order to get the highest density to be competitive.  So it's the same kind of problem where hard drives are less than completely reliable, purely due to competitive pressure to squeeze as many bits as possible into the smallest cost possible.  In the case of SSDs, what that means is that the size of the tank which is storing the charge which is remembering whether that's a one or a zero bit, they've just made that incredibly small.  And so they've made it so small that you are then relying on error correction to sort of pull you out of the gray area.



There's gray unfortunately now designed into these SSDs because they figure that's the right tradeoff to make.  And so to something like SpinRite - well, actually there is nothing else like SpinRite, so SpinRite is able to make a read pass over the SSD, show it that, okay, this is becoming too gray, essentially, not clearly black or white, but a little too gray.  And so then the SSD controller says, uh-oh, and will either rewrite that data to strengthen it; or, if it doesn't look like it's safe, it'll essentially map that out and map in new space.  So, I mean, it's very much like the way hard drives have evolved.  They just don't spin.



LEO:  Right.  And that's one of the reasons they're fast.



[Talking simultaneously]



STEVE:  ...calling it SpinRite, Leo.  I don't know how I could change the name.  Even though nothing is spinning, it sounds right.



LEO:  Yeah, no, SpinRite, it's SpinRite.  It's SpinRite.  Are you ready, Steve?



STEVE:  You betcha.



LEO:  You've got your thinking cap on.  Let's go to our questions, as proposed by Steve Gibson, who's collected them from his feedback form at GRC.com, starting with Carl Bolstad in Seattle, Washington.  He declares - and I'm happy to hear this one - Carbonite wins.  Thank you for putting this one in.  Hi, Steve and Leo.  I've been enjoying the Security Now! podcast since the beginning.  I'm about three months behind right now.  I've also been a Jungle Disk user, like you, Steve, until recently.  When I had to reinstall Jungle Disk because it wasn't working anymore on my XP machine, I discovered it wouldn't install at all.  So I went to the website to post a help ticket and was shocked at all the complaints not getting any response from the Jungle Disk staff.  It got sold; right?



STEVE:  Yeah.



LEO:  To Rackspace.



STEVE:  And what happened was what we worried was going to happen, apparently.



LEO:  Just fell off the face of the earth.  So I started looking for a new online backup solution.  Luckily for me you'd recently done a podcast on exactly that.  I tried several of the ones you recommended.  By the way, that's a great show, where you just list all of the cloud storage solutions pros and cons.



STEVE:  And go through them all, yeah.



LEO:  In the end I just couldn't resist Carbonite's plan of just backing up all the user files on the internal drive without worrying about how big it may be or how much your backup will be costing this month.  It's less than five bucks a month for everything.  It's such a relief to know that everything's backed up.  The only time I'll have to worry about it is if my hard drive fills up.  Thought you and Carbonite might like to know.  Thank you, Carl.  Thanks for the great podcast.  It's amazing it's still relevant and entertaining after all these years.  Carbonite, of course, is one of our sponsors, and I'm sure they'll appreciate that.



STEVE:  Well, and I did, I've also, the thing that caught my eye not only was that he appreciated the cloud storage podcast we did and that he chose Carbonite and his rationale for doing so, but I have had a bunch of people complaining about Jungle Disk.



LEO:  That's sad.



STEVE:  Our listeners.  Remember it was Dave, I remember he called himself "Jungle Dave."



LEO:  Jungle Dave, that's right.



STEVE:  And he was the founder and creator and evangelist.  And I'm sure it was good for him that he was able to sell Jungle Disk.  But, unfortunately, it doesn't seem that it's been good for some of its long-time users.  So I was sorry to hear that.  But there are alternatives now.



LEO:  Yeah, do listen to that show because everything has a - there's pros and cons on all of the things.



STEVE:  Yes.



LEO:  And Carbonite's a sponsor.  It's not necessarily the right choice for everybody.  Some people prefer pay-as-you-go.  Some people want to have external drives.  And there's all sorts of things.



STEVE:  Yeah.  And we know that we do not have a homogeneous set of users.  We've got all kinds - varying skills, various needs, varying configurations.  Some people want to get things remotely.  Some people want web access.  So there is a spectrum of different solutions available.



LEO:  Our next question from Scott Reeves in Phoenix.  He shares his OAuth/Facebook login idea:  I heard last week's Q&A where you discussed your concerns with the Facebook login spoofing, and I had an idea.  What if Facebook combined their login with a CAPTCHA of several of your friends' faces?  Hey, that's a good point.  They know our friends, don't they.  People could instantly recognize friends' faces, in theory, and it would be very difficult for bad guys to spoof.  I don't think it'd be much of a burden on users to recognize their friends as long as it wasn't somehow taken as a product endorsement.  Thoughts?  Hey, I like that idea.



STEVE:  It's a cool idea.  I mean, this follows on the very valid point that I think was raised, that one of our listeners raised, probably the last Q&A we did, was where the point was made that what's becoming very much in vogue is when you go to a site and it says, oh, would you like to log in using your Twitter ID or your Facebook ID or one of the other accounts that you probably frequently use.  And so, because it's such a simple and easy thing to do, rather than create a new account in that other place, people are doing that a lot.  They just say, yeah, I want to use my Facebook login.  So that's the danger is that you're clicking on that site.  It's bouncing you over to Facebook to authenticate.  And the problem comes that, if that site were malicious, it could easily bounce you to a Facebook clone login and then capture your authentic Facebook data.  And so what Scott noted, and I was put in mind of, Leo, I think it was your BofA, remember years ago when they were, like, showing you some picture.



LEO:  SiteKey.  They still do it.



STEVE:  Okay.  And the problem there is that you're having to provide them with that or choose from among a grid of, like, puppies or kittens or whatever.



LEO:  You choose, yeah, yeah.



STEVE:  Giraffes.  And here Facebook does have information that they could show you that you could expect them to be able to show you.  Now, this is a good idea.  And I like this.  The problem is that, again, it's the nave user that we're trying to protect themselves from.  And I just don't, I mean, this puts me back in mind of recognizing that there is always going to be a tension and a problem between convenience and security.  And this notion of one click bounce to another site, it is really convenient.  But I don't think there's a way to make it secure.  What Scott suggests is a nice idea.  And again, it's worth doing things that improve security, even if we can't get to a hundred percent.  And I don't think we're going to get to a hundred percent.  But it's neat to make it better.



LEO:  Yeah.  No, we're never going to get to a hundred percent.  You can think of man-in-the-middle attacks and stuff like that.  Keith Takayesu in Ottawa, Canada wonders about breaking passwords into bits:  Steve, I love your show.  Thought you might be interested in this article.  It's from the MIT Technology Review:  "To Keep Passwords Safe From Hackers, Just Break Them Into Bits."  And it's a long URL.



STEVE:  Yeah.  A number of people picked up on this and were tweeting it to me.  So I bet you Ars Technica and other people also picked up on the story.  So it's probably around a bit.  This actually is what I was referring to at the top of the show about RSA having developed something that they call "distributed credential protection."  And the short version of it, I mean, it is deep crypto.  But the idea is do not store - it's exactly what it sounds like, distributed creden- distributed - I'm tripping over this - distributed credential protection.  So do not store all of the information about a person's credentials, like their login password credentials, on a single machine.  Arrange to spread it around so that, in order to obtain all the credential information, you would have to attack multiple different servers.



And they even talk about, in their description of this, RSA's description, that you could have the credentials stored on different OS platforms so that, again, even if there was a vulnerability that affected one OS, it wouldn't be applicable across their distributed protection suite.  And there's additional technology which apparently changes the way the credential is distributed among its different nodes over time.  So if you attack one of these nodes that had part of the credential, and then later attacked another node, the fact that it hadn't all been done at the same time would also prevent it from working.



Now, RSA has applied this for their own use, and they're going to be offering it on some terms for sale in the future to enable companies to better protect themselves.  I'm a little skeptical about what this will really mean in the real world.  I mean, this is cool technology.  And in fact we've discussed something like this many, many moons ago.  I remember when we were talking about, like, it was how could you control access to information by a group of people where you want more than one person to be required to access something.



LEO:  Yeah.  It was like, if I die, I'll give half my password to my attorney, the other half to my...



STEVE:  Yes.  And, for example, say that you had three people, and you wanted access to require any two.  So you would take a really long password, and you'd break it into three pieces, and you'd give the first and the second piece to the first person, the second and the third piece to the second person, and the first and the third piece to the third person.  So each of those people is missing one of the important pieces, a different important piece.  Yet any two of them are able to reform the entire unbroken password.  So we've talked about this kind of thing.



I'm glad, actually, because I'm sure that RSA has got patent protection on this.  The good news is enough similar things like this have been done before that RSA is not going to be able to corner the market on this approach.  And yes, I think this is a good thing that they've done.  But look at the companies that are still just storing things in the clear or still saying, oh, no, you can only have a 10-character password, and it has to be all lowercase.  I mean, we have a long way to go before we even need something like distributed credential protection.



It's nice to know that it's there.  And for high-value login, for example, certificate authorities that really want to protect themselves, there are certainly instances of companies that are looking for the best protection available.  And I would imagine this would make sense for them, whereas so many other companies just haven't even woken up to the idea.



LEO:  Yeah.  Interesting.  Question 4, Michael Walther in Berlin - oh, a famous German name, wonder if he's related to the Walther PPK - wonders:  No NFC?  Are you sure?  Bist du sicher?  From what I found out so far about the A6 chip in the iPhone 5, I'm pretty sure it does have NFC.  It's integrated in the A6 chip, waiting to be released via software, thus giving Samsung a harder time to clone it. Just my two cents.  Yeah, it's not - so there's some - he's got it wrong.



STEVE:  Okay.  I thought maybe you would know.  I poked around and looked to see if I could find any confirmation of that rumor, and I didn't.



LEO:  First of all, it's not - so the deal is that Apple is using a custom fab that's based on an ARM v7s platform, but it's completely custom fab.  So unless he has a very good inside source at Apple, because I think this is probably guarded like Fort Knox, about what they put in the chip is not a standard ARM implementation.  So is he basing that on a standard ARM implementation?  Because I don't see where he would get that information.



STEVE:  Yeah.  It caught my attention and my imagination because I love the idea of it being there, but unimplemented, so that at some point it could be in a future...



LEO:  Does it need to be implemented at that level anyway?  I mean, isn't it just software?



STEVE:  No, there would have to be a little radio somewhere. 



LEO:  Yeah, not in the system on a chip.  It would be a separate thing.



STEVE:  It would be asleep right now.  And then of course the other counterargument to that is, as the Samsung commercials are making very clear at the moment, Apple really does like to drag its users forward phone by phone by phone.



LEO:  It's your parents' phone, is apparently what Samsung wants you to think.  



STEVE:  Yeah, and so the fact is Apple may very well at some future time add NFC and use that as the reason to upgrade to iPhone, what, 9, 10, whatever they are at that.



LEO:  Yeah.  I mean, I don't - A, I think he's just mistaken about the capability of the chip.  I certainly don't think we could know.  But it needs to have some more hardware put in there, including a radio, which is not in there.  So even if it were in the chip, they'd have to make an iPhone 5S or a 5N or something with a radio.



STEVE:  Yeah, and actually, as we discussed last week, NFC requires a short, small-wire loop antenna.  And it has to have an electromagnetic field to radiate.  It has to be a multiturn wire loop per the spec and per the frequency and radiation characteristics.  And there's no way, there's no obvious way to conceal that.  So anybody who did an iFixit take apart deal...



LEO:  It's been torn apart, yeah.  There's no antenna.  There also is the issue of this being an aluminum back.  And of course NFC does not go through metal.  So Samsung and others have plastic backs...



STEVE:  In order to solve that problem.



LEO:  ...in order to solve that problem.  So in fact, once people saw the case, they said, oh, I guess Apple's not going to do NFC.  We knew this because - I guess you could put it at the top or the bottom where there's still...



STEVE:  Oh, you can also - you could bump faces rather than bump butts.



LEO:  Right.  You can do...



STEVE:  Because, you know, I mean, it is a radio.  The phone itself is a radio.  So...



LEO:  Right, there's ways to get signals out, RF out, yeah.  That's a good point.



STEVE:  Right.



LEO:  Anyway, there's no transmitter.  There's no radio.  There's no antenna.  So there's no way they could just flip a software switch and make this thing NFC capable, sorry.  Bad news.  Russell in London with a tip for Verizon users.  Oh, you know what, I just heard about this.  And I am shocked.  I'm so glad he brought this up.  Colin Weir, our streaming engineer, or, no, I'm sorry, it was Josh Windisch just told me this.  Verizon customers have 30 days - I hope that you've looked into this because maybe it's just Snopes worthy.  But according to the rumor going on the 'Net, Verizon customers have 30 days to opt out - to opt out - from Verizon selling your web history and device location history to marketers.



STEVE:  Now, I am a Verizon customer.  So I went to www.vzw.com/myprivacy.  What I found was a page that said "Customer proprietary network information settings.  Verizon Wireless and its affiliates (the Verizon companies) provide services to you."



LEO:  Holy cow.  This is the default is on.  It's...



STEVE:  Yes, it is.



LEO:  Oh, my god.



STEVE:  "In doing so we may collect certain information that is made available to us solely by virtue of our relationship with you."



LEO:  Holy cow.



STEVE:  "Such as quantity, technical configuration, type, destination, location, and amount of use of the telecommunications services you purchase.  This information and related billing information is known as Customer Proprietary Network Information (CPNI).  The Federal Communications Commission and other regulators require the Verizon companies collectively to protect your CPNI.  In order to better serve your communication needs and to identify, offer, and provide products and services to meet your requirements, we need your permission to share this information among our affiliates, agents, and parent companies (including Vodafone) and their subsidiaries."  So on that page, after I logged in, it showed my two cell phone numbers, one for my BlackBerry, the other for my iPhone 4.  And both of them were set to "Okay to share my CPNI."



LEO:  Geez.  Mine was, too.  I just went there.  I've never seen it before.



STEVE:  Yup.



LEO:  Holy cow.



STEVE:  Yup.  So anyway, for any of our Verizon listeners, vzw.com/myprivacy will get you to a login page.  Log in and then, if you choose to say don't share my CPNI, you can select that and save that setting.  So thank you, Russell.



LEO:  Apparently this has been going on for a while, although I had not heard of it.  Now, I just got a Verizon iPhone, so I wouldn't have known about it until now.  But I've had a Verizon account for years.  So apparently they've been doing this all along.  That's shocking.  That's just shocking.  It's not, I mean, you know, it's one thing, I think Facebook and Google, which offer free services and need to monetize, that's one thing.  I'm paying a hell of a lot of money to use this Verizon service.  They make plenty of money off of me.  And for them to...



STEVE:  And selling your location.  It's like...



LEO:  Horrible.  Wow.  Well, I just decided not to - I was waiting on the Galaxy Note 2 because I wanted to get a Verizon one.  Nope.  Although I wonder if AT&T is doing the same thing.  Maybe Verizon is to be praised for at least telling people they're doing this and giving them a way to opt out.



STEVE:  Giving you an opt out, yeah.



LEO:  Does anybody know?  By the way, relevant mobile advertising right below it is defaulted on "It's okay to use my demographic info for banners"?  I mean, there's stuff you may want to look at here.  At least it's all on one page.



STEVE:  Yeah.



LEO:  Business and marketing reports, okay to use my information for aggregate - I guess aggregate's okay.  I don't know.  I'm going to opt out of it all as long as I can.  I'm paying these guys.



STEVE:  Yeah.  I think, if nothing else, expressing our sentiment is a useful thing to do, saying, uh, no.  You get 100-plus bucks a month from me.  That's more than you need.



LEO:  Don't sell stuff.  Yeah, don't sell my stuff to make more.



STEVE:  Yeah.



LEO:  Good.  Let's see, AT&T.  The chatroom has given me a link for AT&T, too.  It's a longer link, not as easy.  "Customer proprietary network information restriction request."  They're doing the same thing.



STEVE:  Yup, CPNI.



LEO:  CPNI.  You have to complete and submit a form to restrict AT&T's use of your customer proprietary network information.



STEVE:  Oh.  And lick the stamp.



LEO:  Yeah.  Yeah.  So you know what?  Kudos to Verizon, because both Verizon and AT&T are obviously doing the same thing.



STEVE:  Yup.  Well, and that means probably everybody.



LEO:  Which means everybody is.  Which means really we should praise Verizon for at least giving us a checkbox.



STEVE:  Yes.  And letting us do it online.



LEO:  And sending us an email.  Yeah.  Holy cow.  That sucks.  And you have to do it for each of your AT&T numbers, by the way.



STEVE:  Yeah.  Actually, in the case of Verizon, it says all cell phone numbers.



LEO:  They show you them all.  But on AT&T I have to know my numbers, go through them, and one by one check them.



STEVE:  Multiple stamps to lick.



LEO:  Rethink possible.  "We were unable to match the account and zip code."  Oh, they are evil.  Evil, evil, evil.  Oh, it's not your phone number.  It's your customer ID.  Go ahead and try to find that.



STEVE:  Oh, yeah.



LEO:  Holy cow.  Thank you for bringing that one up, Steve.  Shocking.  And Russell in London.  Wonder how Russell in London knows?  Maybe it's London U.S.  Maybe it's New London.  I don't...



STEVE:  It just said London.



LEO:  London, I presume England.  He's an expert on U.S. privacy issues.  Lance Reichert, who is re-crossing the Adirondacks, wonders about hashing speed improvements.  That's what happens when you go on long walks.



STEVE:  Well, and you've got to get back to the other side, so.



LEO:  Announcing new faster secure hash!  A couple of months ago you were discussing hashed storage of passwords, emphasizing that proper storage used hundreds, if not thousands, of rounds of hashing to make the generation of rainbow tables prohibitively expensive.  This made sense.  But in the Security Now! episodes both before and after the announcement of the new SHA-3 algorithm, it seemed that its chief benefit was that it's faster than the existing SHA-256.  Surely the fact that Keccak has little in common with SHA-2 is a good thing, but have we stepped backwards as regards throughput?  Lance, professional nitpicker and itinerant engineer.



STEVE:  So this gave me an opportunity just to, first of all, address Lance's point and to expand a little bit on the issue of strengthening that aspect of password testing.  We've sort of gone beyond the point where what Lance points to is a problem.  I think it is a very good thing that we have a strong, chosen, standard, agreed-upon, next-generation hash, which also has the benefit of being faster to implement in hardware and running faster and every bit as securely, we believe, as our current standard.  We've solved the problem of speed by replacing iteration with, well, by using iteration in order to deliberately slow the process down.



One of the tools that many people use is a tool called "bcrypt," the letter "b," c-r-y-p-t.  Bcrypt is often cited as a solution because, by design, they start with a very slow process.  They actually use Blowfish, which was Bruce Schneier's invention.  That predated Twofish, which predates Threefish and, you know, Red Fish, Blue Fish.  And the reason they chose Blowfish is that it has a very slow key setup phase.  So remember that, with all of these symmetric ciphers, before you can actually do any encrypting, you've got to feed in the key.  And it's normally expanded to create a much larger array of bits which are then mixed in as the cipher iterates in order to perform its crypto function.  In the case of Blowfish, that's a very slow process.



So bcrypt is deliberately designed to strengthen password hashing.  But the cool thing about it is it's designed to be scalable from the beginning so that, as machines get faster, as GPUs get faster, as we continue this obvious evolution towards ever greater speeds, you can simply and easily turn up the number of iterations in a smooth fashion.  Now, you don't need bcrypt to do that.  You can use any iterative secure hash.  And what's cool is that there's nothing to prevent you from storing the iteration count along with the hash.  So, for example, so what's stored in the database is here's the hash that resulted from here's how many iterations.  And so that doesn't weaken security at all to say this is how many times we iterated the user-provided password in order to result in this hash.  Which means that it's trivial for servers to scale themselves up so that, as they get faster, and as the technology evolves, we just iterate more.



Now, it's true that, if you have a faster hash, that iteration count needs to scale appropriately.  But who cares?  You're basically tying up your machine for a certain amount of time, which is a burden for the good guys because you have to do that every time you need to authenticate.  But that's much less often than a bad guy who's trying to do millions and billions of guesses of a password, who then has to iterate all of that many times for every single guess.



So anyway, it certainly changes the iteration count for hashing, if we get a faster hash.  But at this point we should be, and for all intents and purposes are, we're past the point of not iterating when security is set up correctly, so it really doesn't matter.  We just iterate more on a faster hash.



LEO:  Speaking of hash, I'm just going to grind some more...



STEVE:  You grind away, Leo.



LEO:  This is really cool.  I have a...



STEVE:  I love the idea of a hand burr grinder.



LEO:  Well, you know, it is.  And it looks like it's ceramic in there, I mean, it's beautiful.  It really is beautiful.  And there's a certain - and it smells good.  There's a certain joy - should we send one to Steve?  Steve, we're going to send this down to you.



STEVE:  Oh, cool.



LEO:  You already have, well, we'll send it down.  You can do the ad next week.  I shouldn't have probably opened this because then we could have sent it as a gift box.  But we'll repack it up.



STEVE:  Hey, I don't mind if it's regifted.  That's fine.



LEO:  Mmm, it smells good, too.  I mean, that's kind of - yeah, I like that.  That's cool.  Speaking of hash.  Ricardo in Brazil wonders and worries about the NFC threat we talked about last week:  Steve, I was very concerned about what you said.  You talked about NFC being a new surface of attack for mobile phones - true.  But I think you left out an important characteristic of NFC, which is to potentially replace all the contactless cards, that is, the standard credit cards we may already have in our possession - payment cards, corporate facilities entrance badges, transport cards, and so on.  The interesting thing about NFC is the presence of a "secure element," which is a microprocessor with an application behind it that interprets commands coming from the reader and acts upon it, even by rejecting the command should there be a failed mutual authentication.



So my question:  Considering that smartphone mobile NFC is just replacing something that has already existed, which is acknowledged to be completely insecure, is the possibility of using the handset as a reader/P2P device the main new threat?  Or will this card emulation, with new players like Google, or maybe even the mobile phone companies that are not used to operating within a secure environment, posing a threat to the existing well-established ecosystem?  He makes a good point.  I mean, you're handing your credit card over to people.  This is at least there's a PIN number, and there's a little more security involved; right?



STEVE:  Yeah.  I think that, okay, so...



LEO:  So is the problem then - what he's saying is, is the problem the technology, or the people who will be in charge of it? 



STEVE:  I think he's also saying that he's sort of assuming that there's a way to put your existing contactless cards or replace your existing contactless cards with a phone-based NFC system.



LEO:  I think that's the intent.



STEVE:  And so, yes, I think we do have a new threat because we are now, as we predicted we would be, we're talking about threats to smartphones, which are in the background, in the same way that there are threats to regular PCs.  So that has happened exactly as we knew it was going to.  And so, for example, there's no way for malware to infect a contactless credit card.  I mean, it can't get in there.  It's not prone to attack.  Yet if you assume that responsibility with your NFC-enabled smartphone, so that it has your credentials, then we need to be really, I mean, really careful with the way this gets implemented.



So my concern is - I don't have any problem with the technology.  But then we almost never do.  We look around in the history of security problems is the technology being just what it is, technology.  And it's always the implementation.  Sometimes there are protocol errors.  Most of the time it's...



LEO:  It's implementation errors.



STEVE:  The designers forgot something or missed something or didn't see a backdoor.



LEO:  You know, maybe I'm foolish, but I like Google.  I think that Google is really engineering focused.  These are smart people.  So far they have not made any, and correct me if I'm wrong, security blunders a la WEP or UPEK.  But so in some ways I would trust them to do an implementation of NFC.



STEVE:  Now, I did look at Philips's chips.  Philips has a line of chips.  It was a Philips chip they called the NTAG203 was a little, itty-bitty chip that was in the paper NFC labels that I had that I showed last week.  And so that sort of got me into the Philips zone.  And they actually have crypto available in this form factor.  So although this NTAG203 didn't have active cryptography, it had the ability to lock regions of the EEPROM so that they were, after once written, they could not be rewritten, they could not be changed, they could only be read.  But and so this particular NTAG203 chip did not have this higher level, what I think he's talking about, the so-called "secure element."



It does look like we will be seeing NFC devices in the future that may actually be performing more crypto.  And I think that's all good.  Except that doesn't solve the problem of smartphones still needing to be implemented correctly.  And I agree with you.  I think Google, so far they're doing a great job.



LEO:  Yeah.  I look forward to it.  I think just the idea of replacing pieces of paper and plastic in my wallet with something a little more digital on my phone, I just like the idea.



STEVE:  And I think we're going to go through a rough patch, as we always do.  But, yeah, being able to wave your phone at the gas tank and have it say, oh, I know you.



LEO:  I'm ready.  I'm ready.



STEVE:  Go ahead and fill up.



LEO:  Yeah, and the way Google Wallet works is it does ask for a PIN.  So it's two factor.  You have to have the phone, and you have to have the PIN.  That's more than my wallet.  Lose the phone, it's not like losing your wallet.



STEVE:  Yup.



LEO:  Stephen in Glasgow, Scotland shares his recent NFC experience:  I think I know of a problem with NFC.  When I first got my Galaxy S3 it would quite often beep for no apparent reason.  Every time I put it in my jacket pocket or on my table, it would beep.  Then I noticed it was when I put it on my table resting on my wallet that it was beeping.  I felt like an idiot for not figuring it out.  Some of my newer credit cards have RFID chips inside for the new contactless payment systems.  We don't have these in the U.S. yet; or, if we do, they're in very limited areas.



STEVE:  Yes.



LEO:  One of the problems I had, when you go to Europe it's hard to buy gas because our credit cards are dumb, and you need a smart credit card to buy gas.  And the Galaxy S3's reader was shouting out, "Hey, I found a tag."  And sure enough, when I downloaded an NFC app from the Android store, the beep would then be accompanied by the card info displayed on the screen when I put my S3 near my wallet.  If these phones are going to go crazy when we put them near a wallet with RFID cards, no wonder Apple is holding back.  As far as I can see, there is no way to tell Android to ignore a tag.  And even if you could, would that use battery as the RFID tag in your wallet was constantly shouting out, "Hey, hey, I'm here," and your phone listened to the details before ignoring it again?  Love the show.  That's a great question.



STEVE:  Yeah.  And again, I don't have a Galaxy S3, but I would be surprised if in the configuration...



LEO:  Let me look.



STEVE:  ...you didn't have the ability to turn off NFC.



LEO:  Oh, yeah, you certainly do.



STEVE:  And so what I would tell everybody, no matter what phone you have, if you are not actually using NFC on a daily basis, absolutely turn it off.  Just turn off the antenna.  Turn off the receiver.  You'll save power, and you will clearly be more secure.  If you do use it, then it's not going to be convenient to be flipping it off and on all the time until someone writes a little app that makes it easy to do that.  And, boy, I really hope that we're going to see people implement a physical verification that you want a near field transaction before the phone just goes off and does it because we sure do need that.



LEO:  There will definitely be that kind of thing.



STEVE:  Which actually leads us into our next question, surprisingly.



LEO:  Ah, which is Brian in Michigan.  He notes that NFC attacks are trivial with many current implementations:  I was a bit shocked at your "benefit of the doubt" about NFC.  There is no doubt because I would think it would be almost trivial to attack.  Here is my quick scenario:  Several of the implementations will automatically go to a URL in an NFC tag without any user interaction.  There will be browser vulnerabilities to browsers in the phone.  The attacker places several NFC tags that have been crafted to send victims to their attack site.  They head to the airport, subway, or any other crowded location at peak traffic time.  They "accidentally" bump into people.  Most phones are in pockets, so it's the target height of the tags for the attack.  The victim's phone goes to the attack site while never even leaving their pocket.  The site takes over the phone to copy contacts, send premium SMS messages, destroy data, or whatever else they feel like doing.  I may be a bit overreacting, but I feel NFC has all the security problems of QR codes - which can do the same thing - but with the added attack of not needing line of sight.



STEVE:  Yup.  And I think Brian's right.  I mean, again, this is why there's so much temptation on the part of the "gee whiz" people, ooh, look at this, just wave your phone past the poster, and then automatically, whoop, look, automatically takes you to the website.  And it's like, oh, I know, but Brian's scenario will come to pass if we let things be that easy.  You have to back off and say, oh, my NFC radio is off unless I'm using it, which is, like, first choice.  Or it prompts me for do you want to go to this site and waits for permission before it does so.  I just don't see a way around that.



LEO:  Well, that's an app-specific implementation.  I was trying to look at the Samsung TecTiles, but I don't have it installed yet.  I redid my phone.  But I'm sure that, for instance, Foursquare doesn't automatically check you in.  It just takes you to that point.  I'm sure that what it could do and should do is say, here's a URL, do you want to go to it?



STEVE:  Yeah.



LEO:  Now, if the phone is locked - Tinfoil Hat says, as far as I know, Android NFC does not take action if the phone is locked.  That is correct, by the way.  You have to unlock the phone for NFC to work.  I do know that for a fact.



STEVE:  Yay.  That's a very nice...



LEO:  That's sufficient.



STEVE:  Yes.



LEO:  I mean, my phone is always locked when it's off.  I press the Off button, and it locks it.  So don't worry about it.  You have to open the phone, unlock...



STEVE:  Well, do...



LEO:  Do worry about it.



STEVE:  Do worry about it.



LEO:  But, I mean, it's got it implemented in a way that is better than that scenario.



STEVE:  Yup.



LEO:  Nathan Cooprider in Bedford reminds us that Russinovich gives us answer to AV problem in Episode 371:  In Listener Feedback #151, our last Listener Feedback episode, Vern from the Bismarck Public Library - remember this? - shared his continuing frustration with all traditional antivirus products.  You and Leo expressed sympathy, proposed some incremental improvements.  But it seems like you felt a complete solution did not exist.  But actually, Mark Russinovich actually mentioned and endorsed a solution when he was on the episode before.  He calls it "whitelisting."  I like whitelisting in general.  A default-deny approach which only allows authorized apps will complement AV and address the issues Vern raises.  By the way, this is what Apple's doing in OS X Mountain Lion.  Whitelisting is the future of security as AV continues to falter.



I'll confess I'm a little biased here, since I work for Bit9.  Our security product, Parity, provides the best whitelisting solution for endpoints and servers.  But we aren't the only ones in this important space.  He gives the link to his Bit9 v7.  Be happy to help you with any research into this area, or set you up with people in our company who could answer questions, as well.  Whitelisting has arrived and works.



STEVE:  Well, I saw Nathan's note, and I thought that we really - we sort of skipped over that and didn't really give much attention to it.  And it's not something we've ever talked about before.  While Mark was on the show I related the analogous situation, which Mark thought was actually a really good analogy, which was to firewalls, where in the beginning firewalls were to allow everything and deny specific protected ports.  And we realized, oh, we're not good enough to do that.  Stuff gets through.  So now everybody is a deny everything and allow only those things through that we know we need to, which is the whitelisting approach as it applies to networking traffic.  And Leo, I agree with you.  This is the notion of the, I've forgotten the word, where you have someone tending a museum.



LEO:  Curation.



STEVE:  Curation, yes.  The curated model, where you have, like, corporate IT says these are the apps that we're going to allow you to run on your system, and we're locking it down.  So...



LEO:  Corporate IT or Apple Computer.  That's exactly what the App Store does.



STEVE:  Well, and isn't Microsoft aiming there, too?



LEO:  I think so.



STEVE:  I'm seeing some grumbling.



LEO:  Not as dramatically.  But there is an app store.



[Talking simultaneously]



STEVE:  ...completely wide-open frontier.



LEO:  Right, right.  There is an app store.  But right now, if you upgrade to Mountain Lion on your Macintosh, you have new security settings that give you - now, the default is not the most draconian setting.  But you have the option to - there's three options.  You can say I will only allow applications downloaded from the Mac App Store.  I will only allow applications downloaded - so that's fully curated; right?  Apple curates.



[Talking simultaneously]



STEVE:  Yes.



LEO:  Of course there's the argument does Apple, can Apple fully curate.  But that's the presumption.  Certainly it's better than just wide open.  The second choice, which is the one I've made, and it's actually very easy, is not onerous at all, and it does have some security, is Mac App Store and identified developers.  Apple has a certificate they give developers that they approve of.  And I think that is a great middle ground.



STEVE:  Yup.



LEO:  And you do have the choice of, yeah, you download whatever you want any time.  But this is the same - now, Apple is fully curated on the iPhone.  And without jailbreaking there's no way not to do that.  Android is curated by default, but you can check a box that says allow third-party sources.  So this is nothing new.  The mobile platforms are already doing this.  As is Microsoft on Windows Phone.



STEVE:  I do think that someday we'll look back and remember the days when you just ran whatever software you wanted to and held your breath.



LEO:  Yeah.



STEVE:  Because it's just, as we've become increasingly dependent upon our systems, as we wire this all more deeply into the social fabric, we'll become - well, and as bad guys continue to be more and more aggressive about taking advantage of what used to be a free and open environment, we're probably going to have to be more conscious of the threats that exist.  And I wouldn't be surprised if we see whitelisting becoming more and more relevant.  And I have to say also, completely random, Bit9, when I saw Bit9, I thought, you know, I think there was a Bit9 graphics card for the Apple.



LEO:  Oh, that sounds familiar.



STEVE:  For the Apple II.  I think, you know, I just, like, oh, I bet you that that's the same company...



LEO:  You think?



STEVE:  ...because I think they were in Massachusetts, he said.  I tried to Google Bit9 Graphics because I was curious.  But, I mean, this was, what, 30 years ago.  So it's been a while.  But I absolutely remember Bit9 Graphics, and I wouldn't be surprised if it was the same company.  If Nathan is listening to this, maybe he can drop me a note and say, yes, that's us, we're still here.



LEO:  What's the history of Bit9?  Isn't that interesting.



STEVE:  Yeah.



LEO:  Yeah.  They're now in security, for sure, but maybe they were doing other stuff.  That happens all the time.



STEVE:  Hey, I was doing light pens once.  So things evolve.



LEO:  That's right. That's why you know Bit9.  They are in Waltham, Mass., so maybe it's the same.  Steve, we've come to the end of our Q&A.  Thank you so much, as always, for making this show possible.  We couldn't do it without you.  Steve not only spends a lot of time preparing the show and answering your questions, but he also makes, on his own, 16Kb versions available, audio, for people who just want the smallest possible file size, and pays to have it transcribed.  And Elaine does those great transcriptions.  Those are both available on his site, GRC.com.  And if you want to thank him, well, just buy a little SpinRite while you're there.  That's where you'll find the world's finest hard drive maintenance and recovery utility.  Now for SSDs, too.



STEVE:  Yay.



LEO:  Yay.  He's also got lots of free stuff there, lots of security programs, information, diet information, "The Sugar Hill."  People have been asking, when are you going to do Sugar Hill Part 3?



STEVE:  Leo, I get so much of that.  We're going to have to do that.  I've been continuously in ketosis now for six months, and it's the best thing I've ever stumbled into.



LEO:  You're looking so thin.



STEVE:  We need to come back and revisit that.



LEO:  And Dr. Mom is now steaming once again.  Doesn't take long.  Sorry, Dr. Mom.  What else?  Just lots of great stuff.  Visit GRC once in a while.  That's also where you can ask questions, at the feedback form there:  GRC.com/feedback.  You should also watch the show live because it's more fun that way.  You can talk back.  And as you can see, I refer to the chatroom, I use information from the chatroom.  It's really great.  By the way, the chatroom's saying that the graphics company was Number Nine, not Bit9.



STEVE:  Oh, that's correct, yes.



LEO:  Very good.  See?  See?



STEVE:  Very good.



LEO:  That's why you've got to watch live.  We do it 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC, at least until our summertime goes away.  Then we'll be at a different time, but for now 1800 UTC.  On Wednesdays.



STEVE:  And are we losing you soon for...



LEO:  Next week I'm going to see Madonna.  But I'll still be here on Wednesday.



STEVE:  Oh, that's right.  So, yes, Sarah was talking about you not doing...



LEO:  It's iPad Today I'm going to miss.



STEVE:  Right, right, okay.



LEO:  No, and then I'm going away for a few weeks in November.



STEVE:  But not till November.



LEO:  But that's November, yeah.



STEVE:  Okay.



LEO:  And so I'll be back next Wednesday to do the show, 11:00 a.m. Pacific, 1800 UTC.  You can get it after the fact, though.  On-demand versions always available of all of our shows.  Because really that's how we started.  We flip-flopped it.  I mean, really it was originally on demand, and you can watch us do it live.  Now I want people to think, watch it live or get it on demand.



STEVE:  And look at where our listeners are, as evidenced by their locations that they talk about in the mailbag.



LEO:  All over the world.



STEVE:  I mean, they're global.  So many of them, Leo, I'm sorry to say, are asleep right now.



LEO:  No, I know.  And one of the things we do is we try, and we're trying, we're getting better and better at this, to do reruns.  What we want to do is be 24/7.  But we're live at some eight-hour juncture.  But then repeat.



STEVE:  While we're awake.



LEO:  While we're awake.  And then repeat and repeat.  So that, if you tune in at any time - we are not quite perfect at this yet.  But the theory being, you tune in whenever it's appropriate for you and just watch for eight hours, you'll get everything.  And if you do that every day, you won't miss a thing.  You laugh, but there are people who do that.  Dr. Mom is...



STEVE:  You'll get no work done, either.



LEO:  I don't know.  Yeah, exactly.  So we've decided to make this as convenient as possible because I know that, if it's not convenient to watch or listen or participate, then you won't.  So I hope you will.  Thank you, Steve.  We appreciate it.  You're the best.  Seven years down, seven more to go.



STEVE:  Absolutely.



LEO:  At least.



STEVE:  You betcha.



LEO:  Well, it was so easy doing the first seven, I could easily see going another seven.  I mean, this first seven went by like that.



STEVE:  I didn't even notice it passing, Leo.  It's all good.



LEO:  Yeah.  I don't know if I'll do a third seven, though.  I haven't re-upped for three terms.  I'll let you know.  Hey, thank you, Steve.



STEVE:  We'll take it one seven at a time.



LEO:  One seven at a time.  That's good.  I like it.  Seven-year terms.  There's something about seven that's good.  Thank you, Steve.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#374	

DATE:		October 17, 2012

TITLE:		ECC - Elliptic Curve Cryptography

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-374.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's most important security news, Steve and Leo wind up their propeller-cap beanies right to the breaking point of their springs in order to obtain enough lift to examine and explore the operation of ECC - Elliptic Curve Cryptography - the next-generation public key cryptography technology.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson calls this episode a "propeller-head" episode.  Get your thinking cap and your beanie on because we're going to talk about how something called "elliptic curve crypto" works and why you might start seeing it on many devices.  That's next on Security Now!. 



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 374, recorded October 17th, 2012:  Elliptic Curve Cryptography.



It's time for Security Now!, the show that protects you Now!, with this guy right here Now!, the Security Now! host and Explainer in Chief, Mr. Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Too much coffee for you, Leo.



LEO:  Now!  Triple tall latte.  So I decided - you drink the big cups; right?  The venti quinti, and you put a lot of shots in it.  But I realized I don't want all that milk, so I just put a lot of shots in a small cup.



STEVE:  It was so funny, yesterday Starbucks, my Starbucks was demoing their new machine, which just came out, the...



LEO:  The Clover.  Did you get your Clover? 



STEVE:  Oh, no, no.  It's a little - it's a consumer pod-based thing.



LEO:  Oh, that's right, yeah.



STEVE:  The Verismo or something like that.  It's trying to sound verasic [sic] or something, I don't know.  Anyway, and so they were like, I was walking around, and they said, would you like to try a latte from our new Verismo?  And I said okay.  And they said, "But it's not six shots."  It's like, oh, okay, well, maybe we'll use three of them lined up or something.  It was a little disturbing.  They have a little pod.  It's a pod.  We've seen pods before.



LEO:  I'm not impressed.



STEVE:  Pod of espresso.  They had a pod of milk.  And I was looking at it...



LEO:  No.



STEVE:  ...thinking, okay, wait a minute, how did a latte come out of this little pod of milk?  Then, because I got my curiosity up, I did some research, and it's powdered, finely powdered milk.



LEO:  No, no, no, no, no.



STEVE:  And it's like, eh, don't think so.



LEO:  No, no, no.



STEVE:  And it's $200 for this little pod-based system.  And it's what they're pushing now.  They have a bigger brother that's got three times the tank size.  Then it tells you when the water's getting low or the used pod storage tank is getting full and so forth.



LEO:  I am extremely happy with my Breville Dual Boiler.  I have to say, I am getting the best coffee out of that.  And the Vario, the Baratza Vario Grinder.  I mean, I spent a lot more than 200 bucks on it.  But I am - it's the best coffee.  And now when I drink Starbucks or even Peet's, it's like, wow, I miss my coffee.



STEVE:  Yup.  That's the way to be.



LEO:  It's nice when you can get some really good espresso out of your own home machine.  But that's not what we're here for today.



STEVE:  No, indeed, it is not.



LEO:  What are we here for?  I see something that worries me.



STEVE:  Yeah, it should.



LEO:  Elliptical curve cryptography?  You're kidding me; right?



STEVE:  We've been doing a bunch of softball episodes for a while.  They've been interesting, but they haven't been very challenging.



LEO:  Steve's going to throw the high heat today, kids.



STEVE:  So, yes, we need to wind up our propeller beanies' springs right to the breaking point in order to get enough lift for this.  This is something important that we've referred to from time to time.  We have never done a, okay, Explainer in Chief mode, how does this work?  And that is Elliptic Curve Cryptography, ECC.  And we have an acronym collision, of course, because ECC is near and dear to my heart as Error Correction Code, that I've been living with ever since the beginning of SpinRite.  This is a different ECC.  This is an alternative technology for public key crypto as opposed to private key or symmetric crypto, which we've talked about extensively.



We've also talked about the typical RSA-style crypto, the famous, you take two prime numbers and you multiply them in a modulus field, in a finite field, and the point being that we're relying on the difficulty, as far as we know, of factoring large numbers into primes, that is, the difficulty of determining prime factors.  We're relying on that hard problem for all of the protection that we get from existing sort of standard RSA-style public key crypto.  And the problems with that type of crypto are several that we've talked about.  One is, primarily, it's slow.  Which is to say it takes a huge amount of work for a processor to perform the operations needed because the actual protection is relatively weak.  That's why we need, like, 2048-bit keys in order to get state-of-the-art protection, so if the protection level is weak, so we compensate for that by making the keys long.



Elliptic curve cryptography has been around already for a couple decades.  It's not like it's a brand new invention.  But it's coming into vogue because we're becoming more interested in performance and in lower power applications.  There are some things coming up I can't talk about that I needed to lay some groundwork for.  And we need to understand what...



LEO:  What do you mean, you can't talk about it?



STEVE:  Well, I'm - there's some things - no, no, no, not my stuff.  It's other people's work, some products that are in the works that will be using elliptic curve cryptography, and that's a good thing.  So I thought, let's - we've referred to it.  We've never plowed in.  And, oh, boy, fire up your coffee pot, Leo.



LEO:  Is this going to involve math?



STEVE:  Oh, this is going to - yeah.  What I'm going to - okay.  That math is so hairy that I'm going to describe it visually and kind of clearly.  The point is not to turn us all into cryptographers who could go home and start writing code.  The goal is to get an understanding of it, sort of coffee table-style understanding, in the same way where I can say we take two big primes and we multiply them; now it's hard to take them apart.  There's a one-way function there.  ECC has something - and that's known as a trapdoor function in cryptography.  Elliptic curve cryptography has that, too.  But it is not as easy to describe.  But the flipside of that is we get much more strength.  We get something, for example, with 256 bits of, that is, a public key of just 256 bits, we get the equivalent of about 3,000 bits of prime factor crypto, that is, the standard RSA crypto.  So much smaller keys, much faster operation.  That means smaller packets and easier use.  There's implementations for 8-bit chips, 8-bit micros.  So there are things that it can do that sort of the traditional public key crypto can't.  But it does it because it's a lot more involved.  So that's the...



LEO:  [Laughing] And that's where we come in.



STEVE:  And I think I can explain it.



LEO:  Before we go to the heavy math - actually, it's not going to be that.  If you listen to this show, you're smart.  We know that.  You wouldn't listen to the show if you weren't.  You'll be able to figure this all out.  But meanwhile, what's going on in computer technology news, or security news?



STEVE:  Not too much.  We had a big patch from Oracle, our friendly providers of Java, the language many people love to hate, hate to love, have no choice but to love.  And many people write to me saying, Steve, I know it's a bad thing, I understand how dangerous it is, but we've got to have it.  So for those of you who've got to have it, Oracle just fixed 30 security holes in their various Java packages.  They are now at - if you have moved to major v7, they are now at Update 9.  If you are still at major v6, they are now at Update 37.



Now, Apple is independently updating Java.  But after the catastrophe they had earlier this year with hundreds of thousands of Macs being compromised as a consequence of a known hole that they were slow to patch, they will likely - I think we will probably be having an update from Apple's Java shortly.  Nothing so far.  This was just yesterday, so what's that, October 16th, that they released this major 30-security-hole update.  So you can go to Java.com, check your version.  If you need it, the advice is never probably going to change, which is, if you know you don't need it, remove it, if you have it.  If you're not sure if you need it, then you probably don't, so remove it.  And only if you know you need it should you keep it, in which case you definitely want to keep it up to date.



It is the most routinely exploited entry point for malware.  It's just - it's getting less attention because it's not the browser itself.  It's right up there with Flash in terms of being an exploit target for hackers.  So both of those things being add-ons, large add-on libraries to the underlying browser technology.  So it's important to keep it updated.  And I have not seen - I'm a little bit behind, and I'm waiting because I'd like to sort of see when this thing's going to update.  And I have it disconnected from my browser, so I'm not in danger.  And I've got NoScript locking down my browsing.  And I generally don't go anywhere on the Internet that's sketchy.  So I'm, like you, Leo, am generally keeping myself pretty safe.  But it is a way for bad guys to get in, so time to fix it.



LEO:  Yeah.



STEVE:  We talked, was it last week, I think it was just last week, maybe the week before, about the UPEK fingerprint software disaster.



LEO:  Last week, yeah, yeah, yeah.



STEVE:  Yes.  And the good news is they were relatively quick in addressing the problem.  They're doing a little bit of finger pointing.  But I found a blog posting...



LEO:  Wait a minute.  Wait a minute.  Our software is totally broken, but it's not our fault?  Well, who can they point a finger at?



STEVE:  Yeah, well, okay.  So here's what they said.  And this is Miroslav Buran.  He wrote, "AuthenTec takes security seriously, which is why we contacted ElcomSoft shortly after their recent blog post which claimed that Protector Suite stores Windows passwords insecurely."  Now, let's remember that, with just that information, that claim, what we shared last week was an independent researcher who also cracked it.  So it wasn't apparently that difficult.  Anyway, going on with the blog posting, "AuthenTec evaluated ElcomSoft's claims after they provided relevant information to the company.  Based on the findings of our team, ElcomSoft confirmed passwords stored in Protector Suite were not 'barely obfuscated' as written in their report."  Okay.  So AuthenTec is saying it wasn't as bad as they said.  Okay. 



"ElcomSoft has reverse-engineered the AES key-generation algorithm in Protector Suite and written code that uses this information to unlock the AES-encrypted storage."  Now, okay, wait again.  We know that this wasn't - they're saying "AES" like it's some badge of honor.  We know that it was dramatically watered down AES-56, which doesn't really exist in the world.  They just zero-padded it in order to weaken it, apparently so that it would meet 56-bit maximum key length export requirements.  So it's like, okay, well, so, yes, all this is true, but it's not like what AuthenTec had was AES in any standard strength.  And then their final butt-covering is, "Any tool that uses this code maliciously must be downloaded by a user and given administrator rights to be effective..."



LEO:  So there.



STEVE:  Well, of course that's true for everything, "making it no more or less potent than widely available keyloggers in harvesting personal information."  And that's not true because the login process is specifically protected from eavesdropping with all of that extra stuff that Microsoft does that, for example, keeps - there's no keylogger running at the time that you're logging in, and it is very well protected.  And what a reverse-engineering of AuthenTec's insecure technology yields is information at rest access.  And being able to access information at rest is vastly more effective than having to try to get something going by.  So it's really not comparable.



Anyway, they said, finally, "In order to protect Protector Suite users" - okay, now I guess they're saying they need protection, even though what they've said before was, well, it's not really that big a problem - "in the event that ElcomSoft makes this code more widely available," which is not the concern anyone really has because ElcomSoft isn't likely to do that, they don't need to, other people have independently broken it - they said, "AuthenTec has created an update to Protector Suite with a hardened version of our AES key-generation algorithm."  We don't know what that means.  "You can download the update from the link below:  support.authentec.com/PS" - as in Protector Suite - "update2012."  So that's all run together, one line, support.authentec.com/PSupdate2012.



Now, I have been unable to get to the support.authentec.com site all morning.  Fortunately I already had this text grabbed and saved, or I couldn't have grabbed it for the podcast.  So I don't know what their problem is.  But maybe they're under attack.  Who knows.



LEO:  [Indiscernible].



STEVE:  Yeah.  Then they said, "Latest version of Protector Suite 2012 including the hardened AES encryption can be found in the download section of the support site:  support.authentec.com/Downloads/Windows/ProtectorSuite.aspx.  Users of Protector Suite with the Store To Device option available and enabled would not be affected, as keys are stored on the fingerprint sensor and are unique to each PC."  So what that says is we wish that everybody was storing their keys in the sensor.  But apparently store-to-device option is not always available or enabled, and in which case we store them insecurely in the registry.



So this is an unsatisfying response from a security company.  As we know, the proper response is tell us everything about what you're doing.  If you cannot tell us everything about what you're doing, then we have no reason to believe that it is secure or that even you think it is secure.  So they're still hiding what they're doing.  Still, whatever they've done, presumably, is better than what they were doing before.  So if you are a laptop user, if you are using UPEK's fingerprint software, and UPEK has been purchased, as we know, by AuthenTec, then I would certainly suggest having the 2012 update running.  So there is something now for people to do.  Still it's not very satisfying for a company that is attempting to provide very  mission-critical security technology.



LEO:  I just - it sounded like a non-denial denial.  And I just, like, come on.



STEVE:  Yeah, yeah.



LEO:  Take responsibility.



STEVE:  This is not the right way to handle this at all.  Blaming the people...



LEO:  Who discovered it.



STEVE:  ...who found the vulnerability and then accusing them of maybe releasing it in the future, so that's why you're going to increase your security.



LEO:  Loathsome.



STEVE:  Instead of just fixing it.



LEO:  Yeah.



STEVE:  Now, I wasn't sure we were going to have a podcast today, Leo.



LEO:  You said that.  And I'm puzzled because you are the man.  You've never missed one.



STEVE:  Never missed one.



LEO:  What could possibly, possibly make you want to miss a show?



STEVE:  Came very close.



LEO:  [Laughing] I've got to know.  What is this magic thing?



STEVE:  One of my favorite authors, one of this podcast's favorite authors, Michael McCollum at Sci-Fi...



LEO:  Ah, Sci-Fi - go ahead.



STEVE:  ...scifi-az.com, his web page right now, if you go there - maybe you should go there before anybody else does, Leo, if you want to show this...



LEO:  Hold on, everybody stop right now.  We have a habit of bringing stuff down.  Okay, got it.



STEVE:  Scifi-az.com, you'll see a picture there.



LEO:  "Euclid's Wall," Michael McCollum.  What is that?



STEVE:  "Euclid's Wall."  Well, Michael sent me his manuscript when he was the only person who had read it.  I have since been in communication with him...



LEO:  Brought it down.



STEVE:  ...and he and his wife are reading it.



LEO:  Eh, just killed it.



STEVE:  Okay.



LEO:  You're just - I'm glad I pulled it up before you did.  Dead, dead, dead.



STEVE:  I couldn't put it down.



LEO:  Really.



STEVE:  It is really fun.  There are so many fun things about it.  First of all, I was a little worried because it had a three-masted sailing, I don't know what you'd call it, a galleon or, I mean, like the Nina, the Pinta, the Santa Maria-style big...



LEO:  Ahoy matey, yeah.



STEVE:  ...ship on the front cover.



LEO:  Right on the front, yeah, yeah.



STEVE:  And I thought, okay, you know, I don't know, what is this going to be?  And in the prologue, two PhDs basically destroy the world.



LEO:  That's not good.



STEVE:  Now, I would never give away anything important, so that is not an important thing to know because you learn it in the first two pages.



LEO:  Oh, okay.



STEVE:  That sets us up for a really interesting sort of adventure story set further in the future.  This is 2087.  Two PhDs think they have discovered an infinite source of energy.



LEO:  Oh, no.  Not the old black hole infinite source of energy problem.



STEVE:  Exactly.  And it doesn't turn out quite the way they...



LEO:  Oh, dear.  Sucks the whole darn Earth right in there.



STEVE:  Well, no.  But I won't talk about what it does.



LEO:  It's not good, obviously.



STEVE:  But suffice to say it shakes us back to almost no civilization.  We then pick up the story a hundred years hence, where there are things like techno archeologists.



LEO:  Right, digging this - trying to figure out how did they make these things.



STEVE:  Who are digging - uh-huh.  And little really intriguing bits of stuff that have survived.  And anyway, I don't want to say any more.  I don't know how soon Michael is going to have it available.  He publishes - I don't know if he'll publish in print as he has his other novels, or eBooks, which he has both on his site and on Amazon through Amazon's Kindle.



LEO:  I like this genre.  Did you ever read a book called "Earth Abides"?



STEVE:  No.



LEO:  Guy wakes, well, a guy goes up on a hike into a mountain.  And when he comes back, everybody's dead.  Some disease hit.  He got a little bit bit, but he survives.  Kind of like "The Stand," where a disease wipes out civilization.  I love that kind of story.



STEVE:  Well, this has got romance and good character development.



LEO:  Sounds great.



STEVE:  And the really - Michael always sets up really intriguing problems, which is why I've, I mean, he wrote the Gibraltar Earth series.  Just everything he's done I have enjoyed.  And anyway, so the point is I just couldn't stop reading it.



LEO:  You couldn't put it down.



STEVE:  I could not stop reading it.  And I finished it last night, fortunately, and so we have a podcast today.  Otherwise, I don't know.



LEO:  Is it a long book?



STEVE:  No.  I got it from him middle of last week, and I had a lot of things going on with me, and I apologize for not having been able to get to it.  And so mostly I read it over the weekend and yesterday and really enjoyed it.  So I can't recommend it yet because...



LEO:  Can't buy it yet, yeah.



STEVE:  Can't buy it yet.  But he said coming next month.  I don't know - that's what his web page says right now.  So it will be soon, so we're not teasing people too much.  But anyway, it was very fun.



LEO:  Can't wait.



STEVE:  Oh, and his other ones, for example, have been trilogies.  This one wraps it.  So this is not - I would have a different position if I was left with a cliffhanger because, as we know, it's so annoying to, like, read something, and then it's like, oh, god, now I've got to wait for...



LEO:  Hate it when that happens, yeah.  Good.  I can't wait.  That's exciting.  I'm going to have to go get a copy.



STEVE:  Now, many people have asked for a third part of our Over the Sugar Hill series, Leo, which I think we should do, but I wanted to formally make a call for our listeners' experiences.  It's been more than six months for me.  It's been more than six months for everyone.  So there is a feedback page on the health-related research pages at GRC, GRC.com/health/lowcarb.htm, or actually /health/feedback.htm.  I would like to have - I don't want to just relate my own history and yours.  I would love to have our listeners give us a larger sampling of their experiences either way - good, bad, tried it/fell off of it, tried it/loved it, and so forth.  So I wanted to formally make a call for people to send me their experiences, let me know if I could use their name or not.  I'm happy to keep it anonymous if they'd rather that.  It's a little more fun if we have a name attached, but I certainly understand if somebody...



LEO:  They're afraid Dr. Mom will find out and...



STEVE:  [Laughing] And so...



LEO:  Don't want that to happen.



STEVE:  And so we will come back to the topic and have a much broader base of experience to share.



LEO:  Good.  Can't wait.



STEVE:  I got an interesting question from - I'm not sure he's a listener, actually, because it just sort of - it didn't specifically say.  But he asked a question about SpinRite that I thought our listeners would find interesting.  His name is Allan Levene.  And he said, "We work in the VDI" - the Virtual Desktop Infrastructure - "and SAN space.  Can you let me know how many read/writes your Level 4 SpinRite product does in an hour on a 500GB disk and, if different, on an SSD?  I know that you" - oh, he is a listener because otherwise he wouldn't know that I only recommend Levels 1 or 2 on SSDs, which of course we've been discussing recently, so Allan is probably listening to this.  "But some expensive ones are claimed to have a very long life in spite of whatever you throw at them.  I'd like to find out if that's true."



Okay.  So I wrote back, I said SpinRite's surface analysis/pattern testing strategy has evolved significantly since the early days of MFM and RLL drives.  When drives switched to PRML encoding - which is what they use now, that stands for Partial Response Maximal Likelihood, which gives you a sense for how far out into voodoo weeds...



LEO:  I don't want to hear "likelihood" when it comes to my hard drive.



STEVE:  Exactly.



LEO:  There might be data there.



STEVE:  Partial Response Maximal Likelihood.  The bits are truly so close together that they are now interacting with each other.  So the drive looks at what it gets back when it's reading and chooses the highest likelihood of what was written that would result in that being read back.  I mean, that's how far out we have gone.  I mean, it really has become amazing that these things work at all.  Anyway, and so what's happened is there are several stages of processing between what I would call the "user data," that is, the data we think we're storing on the drives, and what actually is written.  There was, for example, back in the early days, you will remember, Leo, there was something called "write precompensation."



LEO:  Yeah.



STEVE:  And what happened was, at a certain cylinder of the drive, write precomp would be engaged.  And what that meant was, think about it, as you go to successively inner cylinders that have a shorter circumference, but you're storing the same number of bits on each cylinder, that is, on each track, if the track is further in, it's got an actual lower circumference.  It's a shorter track in terms of its linear measurement.  Which means the bits are pushed closer together.



Well, it turns out that, when you read back bits of differing polarity which are close together, they read back as closer than they actually are.  That is, they appear closer than they were written because they are influencing each other.  So write precompensation, it precompensated for essentially sort of that bit attraction by writing them further apart on purpose so that, when they read back, they would be in the position that they were to be expected.



So this gives you - that's the old days.  But so that's an example of some algorithmic fudging that was being done in order to allow more bits to be stored.  Well, we're now decades past that, where maximal likelihood is the domain we're in.  The point is that SpinRite once knew how to write patterns that were so-called "worst case patterns."  Those were patterns which deliberately used the knowledge of what was difficult to read in order to make it harder for the drive to do its job, thus those were patterns that SpinRite used for testing the surface and testing the whole reading/writing channel.



Well, there's no way to know today what we tell the drive to write and what it actually does write because there's several stages, about three or four stages of preprocessing that go on.  There's a process called "whitening" where, no matter what we write, we end up with a 50-50 statistical probability of bits, and all kinds of prewriting encoding in order to put down flux reversal patterns that again have the maximal likelihood of being read back.  So this notion of pattern testing has really gone away.  Consequently, what SpinRite does is something that is simple and fast because the other thing that's happened, of course, is that drives have gotten huge, so you just can't afford the time of doing 30 different test patterns on a drive.



So SpinRite reads the data, inverts all the ones to zeroes and zeroes to ones, writes that back, then reads that and verifies that it got back the inverted data.  Then it reinverts it, or, that is to say, rewrites the original data and then rereads it to make sure that it could read that back.  So it says, okay, there's no way to know what's actually being put on the drive.  We've going to verify that, at the data level, we can write ones and zeroes to every location in terms of the users' data, and we will use the tremendous capability of the drive to recover whatever it's got back to our data and use that.  If there's a problem, the drive will see it and then will relocate that data to safety, as we've described in the past.



So consequently, SpinRite writes exactly twice the size of the drive while it's running, if you're running in the Level 4 pattern-testing mode, where it's actually writing to the surface, even if it was able to read it without any trouble.  So SpinRite reads the surface, recovers the data, then does its dual inversion, flipping all the bits from zeroes to ones and ones to zeroes twice, and verifying that the drive was able to read that back in each case, which again shows the drive if it's going to have a problem with that area in the future.



So if you had a 2GB - 2GB! - a 2TB drive, SpinRite would write 4TB of data.  In the case of Allan's question, a 500GB disk, it would write 1TB worth of data, essentially writing every sector on the drive twice.  So that's the answer to the question and another little bit of peeking under the covers at how SpinRite works.



LEO:  This is good.  You put this all together, you have a pretty good idea.  Very impressive.  Lot of energy, obviously.



STEVE:  Lots of technology under the cover.



LEO:  All right.  Beanies on.



STEVE:  Okay.  So we've talked many times about symmetric cryptography, where you have key lengths of 128 bits, 192, 256.  AES, our current symmetric encryption standard, is that.  It's very fast.  It's used for so-called "bulk" data encryption.  And things like RC4 is another example of, in that case, a stream cipher which is used for performing bulk encryption.  So we have those which use private keys or secret keys which are able to encrypt and decrypt at high speed.



We also famously have public key cryptography, sort of the flipside, where instead of using one key, which is used typically with either one or two algorithms, you may have, for example, in the case of RC4, it produces a bitstream which we exclusive OR with the data in order to encrypt it, which means we do the same thing to decrypt it.  We produce the same bitstream over at the decryption end and exclusive OR it again, which turns all the bits back into what they originally were.



There's an example of one algorithm that is used to do both encryption and decryption, or typical iterative crypto like AES.  We did a podcast on exactly how AES works, where you take the key, you run it through a so-called key expansion in order to create lots more bits than the key has, and then you successively run your decrypted data through an iterative process that uses chunks of the derived key bits each time, and you run it through, like, 11 or 14 or however many times the cryptographers determine is necessary to sufficiently scramble the data.  And every time through that iteration it takes a unique input combination and maps it, essentially, to a very difficult-to-track output combination, yet in a single iteration doesn't do it enough that you couldn't figure it out.  Thus they run it through enough times that the relationship between bits is lost from what you initially put in and what you initially get out.  But that means that decrypting it, you can't do the same thing.  You have to literally reverse the process.



So with a cipher like AES, that is to say Rijndael, you decrypt with a different approach.  You run it sort of backwards in order to get back what you put in.  So that's the whole symmetric side - relatively fast, a secret key.  You use the same key, but either the same or different algorithms, depending upon the way the cipher works.  With public key cryptography, we have a whole different model, and elegant in its own right, where we have typically a private key and a public key.  And it doesn't have to be, the other key doesn't have to be public, but the idea being that one key is used for encrypting or enciphering to produce something unpredictable given an input and you get an output.  And only the matching key, the key that was made - typically these are made as a pair.  One is kept private; the other is made public.  But again, only the other key can be used to undo what the first key does.



So that was a huge breakthrough for crypto because, until that time, there was the whole problem of, well, if I have a secret key cipher, like we've talked about first, like AES, how do you get that to the recipient securely to allow them to decrypt what you've encrypted?  So there's a whole communication problem.  You need some sort of a secure channel to get the secret information.  With public key cryptography, that problem is solved because you can just pick a big random number, and you can encrypt it with your recipient's public key and then send it publicly because only somebody who has the matching private key, and presumably the recipient would be keeping it secret, is able to decrypt what you encrypted with their public key.



So this is the foundation of all of our modern crypto that we've talked about.  And the idea is the public key technology cryptography, as I mentioned at the top of the podcast, it works, but it works in a fundamentally different way, where we rely on some sort of a difficult problem, but it's sort of a softer domain.  That is to say, for example, with traditional public key crypto like RSA style, where we rely on the difficulty in factoring the products of large primes, well, it's the largeness of the primes that creates the problem.  If these were small primes, then their product would be small, and computers are so fast these days, that it wouldn't be that difficult.  We have spent a lot of energy on coming up with ways to produce prime factorizations of numbers.  So it's not that that is difficult so much as it is time consuming.  And we've never, despite all the time and attention we've given to it, we've never found a way to short-circuit essentially what is brute force.



So the strength we get from traditional prime factorization style public key cryptography arises from the size of the factors, the size of the numbers.  But the flipside of that is the keys must be big.  So everything must be big numbers.  And so what that means is, when we're dealing with big numbers, then processors still have word sizes much smaller than those big numbers.  And we're talking about 2048 bits.  But the processors are down at 32 or 64 bits typically.  So that means they have to do everything in multiple chunks, and they have to handle multiple precision math and really hairy stuff.



So what that means is that that cryptography is not applicable for bulk crypto.  That's why we use the clever approach of choosing, as I mentioned before, we choose a random number.  We encrypt that using the public key technology, send that to someone who can decrypt it.  Now we've essentially managed to share a symmetric key which we can then use for performing our bulk crypto.  And that's basically the way SSL and many of these other hybrid protocols function.



Now, everything's fine, except that it's difficult to put this kind of very processor-intensive technology on a smart card or on an RFID tag...



LEO:  Ah.



STEVE:  ...or on a near-field chip.  Did I hear you go "Ah," Leo?



LEO:  Yeah.  Now I'm getting it.  Why do we need another one?  Well, because this one is computationally intensive.



STEVE:  Yes, exactly.



LEO:  So we need a way we can do it less expensively.



STEVE:  Exactly.  And what would be really cool is if we had a technology that was public key crypto that was lightweight enough that we could use it with near field technology.  That is, something like printed on a piece of paper.  The weakness, as we discussed when we were talking about near field stuff, is that it's just basically giving you a serial number, like an RFID tag.  And now there are better solutions for that.  But we're never really talking in terms of serious crypto.  For future applications it would be nice if we had stronger, that is to say, really good public key-style crypto for something that could be powered, I mean, that is computationally simple enough that it can be powered off of a pulse of electromagnetic radiation rather than needing heat sinks and fans to keep it cool while it's doing its work.



Well, enter elliptic curve cryptography, ECC.  It's an entirely different way of solving this, essentially giving us the same feature.  And because it's got nothing to do with prime factorization, it's like starting over.  It's like, okay, let's come up with a whole different approach.  So as I also mentioned at the top, it's not my intention to turn us all into people who can go home and write code for ECC at the end of the this.  But I want to give everyone sort of a level of comfort, a feeling for kind of what it means so that it's like, okay, I kind of get that.  Sort of at the same level as, okay, I understand if I take two big prime numbers and multiply them together, then it's going to be difficult to take them apart.  Multiplying is easy; factoring is hard.



So what we have with elliptic curve cryptography is a dip into some kind of hairy math, but not impenetrable.  We just sort of have to say, okay, I'm going to allow this.  So, for example, so what is a curve?  A parametric curve is what elliptic curve cryptography uses.  Now, a simple parametric curve is x = y.  And so if we took a two-dimensional - and this is planar.  This is all just two-dimensional.  So we have just an x and a y axis that are orthogonal on a two-dimensional plane surface.  So the parametric curve x = y is, as we know from our high school algebra, is just a straight line, a diagonal line running at a 45-degree angle because, if x = y on our graph, where we have x = 1, y will be one; or x = 2, y will be two; or x = 3, y will be three.  And all values in between, similarly, x and y are the same.  So this x = y equation describes this straight line on our graph.



Now, if we added a constant, say y = x + 5, well, so now, if x = 1, y = 6 because we have x + 5 = y.  So if x = 1, y = 6; x = 2, y = 7.  So again we have a diagonal line, but it's been shifted upwards by five.  So it's the same 45-degree angle shifted up by five.  Now, if we were to multiply one of these parameters, say y = 2x, well, then when x = 1, y = 2; when x = 2, y = 4; when x = 3, y = 6.  So what's happened is the slope of the line changed when we added that two parameter to the y = x, so it's y = 2x.  Now the slope has increased.  If instead we said y = x/2, which is the same as x(1/2), then the slope of the line decreases.  It's more horizontal.  It's flatter.  And similarly we could do both at once.  We could say y = 2x + 5, which would give us a steeper line, which is also moved up by five.  So we can do both at once.  So this is something we all obviously know from high school algebra.



Now, we can also do something a little different.  We could say, for example, y = x^2, or x(x).  So now we get a different - now suddenly we don't have a straight line anymore.  If x is one, then y equals 1x1, which is one.  If x is zero - we ought to start there, maybe - then y is zero.  When x goes to two, though, y jumps up to four because we have y = 2x2 is four.  When x is three, y jumps up to nine because we have 3^2.  So what we get is a parabola.  We get a curve on the positive side of x which goes up very steeply.  And on the negative side of x it also goes up very steeply because -2, if x is -2, minus two times minus two is positive four.  So thus we get a parabolic curve.  We could then do things to it like add or take factors and so forth.



Okay.  So I wanted to give us a little bit of foundation first, just so we're on the same page, because the equation for elliptic curve cryptography, all ECC, is y^2 = x^3 + ax + b.  That's all there is to it.  So y^2 equals x^3 plus ax (where a is a parameter) plus b (where b, as we saw before, skews the whole thing).  That is sort of the master equation for elliptic curve cryptography.  So what that describes, this y^2 = x^3 + ax + b, it's a complex relationship between x and y.  So depending upon what the parameters are, it can look very different.  The concept, then, is that we have points on this curve which we multiply by themselves.



So think about we have this, if you imagine a two-dimensional surface with some lines drawn on it, and the lines satisfy that equation.  That is to say, so there are continuous curves, but every point on that curve, if you take the x coordinate and the y coordinate, that equation is satisfied for chosen a and b parameters.  So the act of coming up with turning this from that curve to crypto is we have, again, I use the term "trapdoor."  That is, a trapdoor is a one-way function.  It's something which we can do easily in the forward direction, but we cannot do it easily in the reverse direction.  In the case of prime numbers, the trapdoor is it's easy to multiply two primes; it is difficult if you don't know what they are, if you only have the product, to pull them apart again.  So that's the trapdoor function upon which traditional RSA resides.



In the case of elliptic curve cryptography, we have a curve with known parameters, that is, when these algorithms are published, or when the implementation of this is published, the parameters a and b are public.  They're known.  And they are the subject of standards.  NIST has a bunch of ECC curves where they've worked out the details, and the a and b parameters are part of what is described as, given this curve, then this is the one that we will use to perform our encryption.  So the process of encryption is to take a point on the curve and multiply it by itself, that is, through successive addition, where we take a point on the curve and add it to itself.



Well, now, it's like, okay, wait a minute.  It's a point on the curve.  How do we add a point to a point?  Well, this is defined by the mathematicians as something called "point addition," which exists in the field of math for these kinds of curves.  Point addition is defined as taking two points along a curve and computing where a line which passes through them intersects the curve.  So you have two different points on the curve.  And again, this y^2 = x^3 + ax + b curve, two points on there.  So those two points, as we know, again from high school algebra, two points define a line.  So somewhere else the curve intersects this line.  So the point of the line's intersection that passes through our two points that we're adding, where that line intersects the curve, that's what's called the sum of the first two points.



Well, okay.  The problem is how do you start because, if you're starting with just one point, then you have a whole family, essentially, infinite number of lines because there is no second point different from the first to establish a line.  So the mathematician said, oh, that's easy.  We will define the straight line where the two points are the same as the tangent line at that point in the curve.  So we start with a point, and the curve will have some slope at that point.  And so we obtained a tangent line, which is of course the line that runs tangent or perpendicular to, well, has the same slope as the line, our elliptic curve line, does at that point.  And so that defines the line for the first two points which are not different from each other.  That gives us a third point.  Now we've got two points, and we can then draw lines between them.  So if you're still with me...



LEO:  I got it.  It's a tangent.



STEVE:  Yeah.  So we take a point, and we find the tangent angle at that point.  Then we look at where that line intersects the curve, and that gives us our second point.  Now we have that point and our first point.  And they form a line which we then find out where that intersects the  curve.  That gives us our third and so forth.  So this allows us to iteratively sum from a given point some number of times.  In elliptic curve crypto the number of times we do that is the private key.  So we take a random number.  We take a random number that is going to be our private key, and we multiply, essentially - think about it.  If we take the point plus the point plus the point plus the point, well, that's n(p) where n is our private key.  So we're multiplying the point by our private key.



The result of all of that, and you can imagine, like, how constructive, sort of geometrically constructive this is because we're dealing with this wacky elliptic curve and plotting points on it and where lines through the pair of points intersect the curve, and then we jump to there and continue, we do that however many times is required for the private key that we choose, the result is the public key.  And the point is there is no way, you can well imagine, no way to reverse that process.  That is, this is a very difficult one-way process.  The trapdoor function is doing all of that from a given private key is the number of times we move along this curve, computing these points, and the result is the public key.  And it is possible using this math to essentially, well, what we get is the same sort of thing, a one-way function.  We can easily or relatively easily go forward.  There is no known way to go backward.



And the reason we've gone through all this is the bit space that all of this operates in is vastly smaller than the bit space required for factoring.  Factoring is not difficult enough that we can use small numbers.  We have to use huge numbers because we're pretty good at factoring.  This wacky system that we've come up with, with elliptic curves, is understandably or believably difficult enough that relatively few bits gives us equivalent protection.  160 bits of ECC is the equivalent of 1024 bits of traditional prime factorization public key technology.  Remember that 1024 has been plenty strong for a long time.  I only recently, and everybody else moving to extended validation certificates, only recently went to 2048.  And that's believed to be strong forever.  So, I mean, like a long time.  So most of the websites on the 'Net are still at 1024 bits of standard RSA encryption, and they're plenty strong.  We get that equivalent strength with just 160 bits within the ECC space.



LEO:  So why don't we use it for everything?



STEVE:  It's just - it's newer.



LEO:  Ah.



STEVE:  Cryptographers are famously conservative.  I mean, look at here.



LEO:  As they should be, yes.



STEVE:  Yes.  We launched the SHA-3 competition, what is it, eight years ago just because maybe SHA-256 wasn't going to be strong enough.  And it turns out, oh, it is strong enough.  We really don't need SHA-3.  But cryptographers are super conservative.  When I was researching this to get a better sense for where we are, there is an annual - there is a bunch of annual conferences that are held, and there's someone who sort of maintains a state of ECC.  And he said, well, for the fifth year in a row, I'm here to report that really nothing has happened.



LEO:  So this is how old?  Five years old, then?



STEVE:  Oh, no, no, this is a couple decades old.



LEO:  Oh, all right.  So it's not that new.



STEVE:  Exactly.  Really it was probably more than anything the strength of RSA, just the political strength of RSA.  Everyone was enamored of the idea that they got all the press and the attention.  RSA's patents expired in 2000.  The original designers of this put it into the public domain, but there have been some implementation tricks that were patented.  So this isn't - ECC is not as obviously free of intellectual property collision except that a lot of people are taking the position that it is, in fact, that you can do everything you want to do with ECC today with no intellectual property concern.



Dan Bernstein, whom we've spoken of, is a famous cryptographer.  He's got a bunch of ECC stuff on his site and free open source.  It is now, for example, it's in OpenSSL.  It's in the Crypto++ library.  It's in the GNU TLS library.  It's in OpenSSH, the NSS.  The Mozilla Security Suite has had it in their crypto libraries.  Now, remember the way SSL operates during that initial handshake.  This is one of the nicest things about the way SSL and TLS was designed is that the client says, here's all of the crypto suite tools that I know of.  And then the server is able to look among them and choose the strongest of those that it also supports.  So they automatically handshake and negotiate for the strongest means of establishing a relationship.



That means that, for example, when you build an instance of open SSL, and you enable the ECC cipher suites within the protocol, when you connect to a server that has had the same thing done, you'll automatically negotiate a strong ECC connection.  And if both ends support it, you can get by with a much shorter bit string which allows you to essentially short-circuit the long setup time that traditional SSL has when it's forced to use standard large prime public key technology.  So what's happening is this is getting attention because performance is becoming a problem.  People have been pounding on ECC now for a while.  I guess it's less obviously or it's less intuitively difficult to reverse this process.



As of 2009 there is still no proof, actual formal proof of the security of elliptic key crypto, which isn't a bad thing.  It's just a hard problem.  Similarly, there's no proof that we can't factor large numbers into their primes.  We just have - no one has ever figured out how.  I mean, they've gotten better at it.  But still, if they're big, we cannot figure out a way to do it.  We've never been able to prove we can't.  But it seems unlikely.  And we're resting our entire foundation on the fact that we can't.  So the cryptographers are actually more comfortable with elliptic curve crypto than they are with prime factorization crypto.  That is to say, the people that have been looking at this now, they feel better about the strength of elliptic curve crypto in the future than they do about the future strength of crypto relying on prime factorization.  The sense is everybody's a little uncomfortable about how strong that actually is.



And the other thing is that, as people have been working on both, the sense is that the prime factorization problem has been softening at a faster pace than the elliptic curve crypto problem has been.  So the elliptic curve, the people working on it feel it's harder, it's a harder problem.  It's less likely to fall to some breakthrough than factorization is.  And everybody likes the fact that you can, with 160 bits, you can get the equivalent strength of 1024-bit prime factorization-style public key technology.  And so what I think we're going to see is at some point in the future we will be talking about devices which are using elliptic curve crypto, and now we all know what it is.



LEO:  You are masterful, my friend.  I don't understand a word you said, but it is masterful.  It's really interesting.  And it sounds like, in time, it might replace traditional public key crypto.



STEVE:  I kind of think it's going to.  Again, cryptography and cryptographers are conservative.  And we're all glad they are because, when you think about it, there have been mistakes made in the past with the application of these things.  Even RC4, that was famously troubled in its initial implementation with WEP, the Wired Equivalent Privacy encryption used in the first WiFi protocol, well, it wasn't RC4's fault.  The implementers of the RC4 algorithm did some things like not letting it warm up enough.  It generates pseudorandom bit sequences, but you've got to let it churn for about 256 cycles in order for it to have scrambled itself up enough, and they didn't.  They immediately started using the first things that it emitted, and it turns out that what that did is that meant that it hadn't scrambled up the key that it was given.  And so there was a findable relationship between the key and the pseudorandom sequence that was being used to XOR the data, and it fell as a consequence.



So what's nice is that we really don't have any instances of an outright collapse.  We have things like MD4, which, okay, no one ever broke it, but we got so much faster with our GPUs and our computers that it no longer was something we felt comfortable relying on.  It became soft, and so we moved to MD5.  And then that got a little soft.  And so now we're at SHA-1, but new things should use SHA-256.  So what we're seeing is we're getting better at understanding these problems, the problems that we have deliberately erected for ourselves in order to create privacy.  And we're staying, however, well ahead of the, if you'll pardon the pun, the curve.



LEO:  I suspect, just because it's so computationally simple, and we are doing so many new devices that need crypto, that this really will be a great choice.



STEVE:  Yes.  And the idea of having a lightweight, inexpensive technology which can be deployed with strong public key style technology, not just private key stuff - well, for example, all of the dongles that we've been talking about, those are all symmetric key.  Those have a secret in them.



LEO:  And that's insecure.



STEVE:  Yes.  Exactly.  There is a secret in them, and we're relying on the fact that they're just giving us the output from that for the security.  But there's no sort of a challenge, we're not giving them a challenge that they have to then answer to prove that they are who they are.  They're just - we're maintaining a secret at RSA and a secret in the dongle, and we've already seen what happens if RSA is unable to keep their secrets.  So we're going to take a next step here before long, and I wouldn't be surprised if, at some point, certainly within the life of this podcast, which seems to show no sign of...



[Talking simultaneously]



STEVE:  ...we'll be talking about some cool stuff that have ECC in them, elliptic key crypto, and now comfortable with the concept because it's going to be secure enough for us.



LEO:  Very interesting.  Really great stuff.  ECC.  Not the ECC you're thinking of, elliptic curve cryptography.



STEVE:  Yes.  Not error correction code.  That's a different topic.



LEO:  Steve Gibson knows all about that, too.  And he will no doubt, in fact I think he already has talked about that on a show.  We have lots of them, 374 shows in toto, available in two places, one on Steve's site, GRC.com, and he does 16Kb versions of the show and transcripts of the show.  So that's really great, if you want a small, compact way to listen.  We make video and high-quality audio available at our site, too, TWiT.tv/sn for Security Now!.



When you get to GRC.com, though, check out SpinRite, the world's best hard drive maintenance and recovery utility.  You've got to have, if you've got a hard drive, you've got to have SpinDrive [sic].  And lots of great freebies, too, which he's always giving away.  Next week we will have a Q&A, I presume, unless major breaking news happens over the next few days.  And if that's the case, you can ask your questions at GRC.com/feedback.  Steve will pick 10 good ones for next week's - did I say "SpinDrive"?  No, SpinRite.  SpinRite.



STEVE:  And I do want to encourage people, if you've had a story that you think would be interesting for us to share with your Very Low Carb experience, I know people were sharing initially.  I'd like to know how that's worked out over the course of six months.  And we will do a third, I think on a Saturday after your Tech Guy...



LEO:  Yes, that's the best time to do it, yep.



STEVE:  ...we'll sneak one in and let everyone know that it exists.



LEO:  Saturday or Sunday.  Actually might be better Sunday.



STEVE:  Oh, because I thought that collided with TWiT.



LEO:  TWiT is an hour after The Tech Guy.  So we did it last time, I think we did it on Sunday.



STEVE:  Oh, yeah.  We can easily.  Cool.



LEO:  Yeah.  But we'll let you know ahead of time.



STEVE:  Yup.



LEO:  And no, Gyver [ph], we're not going to do a Very Low Carb podcast.  I think we'd run out of things to say.  I think there's a paleo show somewhere, though.  Is it 5by5 or somebody has a paleo show.



STEVE:  Oh, there are several, yes, podcasts.



LEO:  You could go listen to those.  I absolutely encourage it.



STEVE:  That's too much.



LEO:  Hey, thanks, Steve.  Go ahead.



STEVE:  Thanks, Leo.



LEO:  But do you have something else you want to say?  I don't want to interrupt.



STEVE:  No.  No.



LEO:  All right.



STEVE:  Glad you stopped me.  Go have some lunch.



LEO:  We'll have some lunch.  All right, Steve.  Thanks a lot.  See you later.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#375	

DATE:		October 24, 2012

TITLE:		Listener Feedback #153

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-375.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here, and we have 10 questions and answers.  We'll also talk about, yes, yet another flaw in Java.  Oracle says, eh, we're not going to fix that till next year.  Steve has the details, next on Security Now!.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson.  This is Episode 375, recorded October 24th, 2012:  Your questions, Steve's answers, #153.



It's time for Security Now!, the show for adepts, for geeks who know their stuff or want to be adepts.  Our Explainer in Chief is here, Steve Gibson.  I say that, Steve, because - hello, first of all.



STEVE GIBSON:  Hey.  It's great to be with you again, as always, my friend.



LEO:  I say that because I was talking to Shannon Morse, who is one of our newest hires here.  She is going to be a producer and host on Before You Buy.  People know her from Hak5.  And she and Hak5 host Darren Kitchen are doing a new show on the YouTube Channel called TechFeed, which is all about tech.  And they're doing a security show.  And I thought, uh-oh.  But then Shannon explained it's security for real people.  I thought, oh, good.  Because we don't do security for real people. We don't do anything nice and easy.  No, we do everything nice and nerdy.  And this show is for people who really want to understand deeply.  And I think that's not my mom or my grandma or my uncle or my son.  It's people who are really nerdy.  Right, Steve?  I mean, I don't think that's unfair to characterize this.  We try and make it accessible, but...



STEVE:  I have no problem with that.  I think that what's valuable is that there is currently nowhere else to get what we offer.  We got a lot of great feedback, for example, from last week's serious propeller-winding episode on how elliptic curve crypto works.  I mean, like, really a lot of tweets and neat feedback from people who were saying, hey, I actually got that.  And some people were using it to put themselves to sleep.  But mostly it was people who enjoyed having the stuff.



LEO:  Yeah.  So that's really the point.  And I think it's actually the point of TWiT is I don't want to do dumbed-down content.  I want to do content for people who really want to know the actual details behind this stuff.  And I think we've done all right by that.



STEVE:  Well, and that's what interests both of us.  I mean, it really is driven...



LEO:  Yeah, well, that's mostly why.



STEVE:  It's driven by who we are.  And it's like, okay, I can't produce endlessly a show about security for mere mortals.



LEO:  Mere mortals?  Who are they?  Who be they?  Oh, what fools these mortals be.



STEVE:  Ephemeral mere mortals.  Not really sure that person exists. 



LEO:  But I think that if you listen to the show, there's plenty of detail here.  You make it as easy as possible with your transcriptions for people to go back and look at, study, and chew.  And I think this is a college-level course is what this is.  And high school somebody needs to do that.  Somebody needs to do elementary school.  And that's fine.



By the way, this is a Q&A episode.  So that's the other option is, if you don't understand something, literally every other episode you get to ask Steve questions, and he can further explain.  And I think that's really...



STEVE:  Well, and as a reminder for people who are joining us recently, I am sort of assuming that our listeners have been with us for the last seven-and-a-half years.  We're at Episode 375.  And 374 previous episodes are all available online for people to get.  And so there is some assumption, I mean, I don't rely heavily on content we've covered.  I'll often say, I'll mention it, okay, now, we've already talked about public key crypto and how it's based typically on factoring in an episode devoted to that.  So we're not going to go over the whole thing again.  But anyway, the point is there is some assumption that people have been following along.  And for those who haven't been, because they're just joining us recently, that is all available online at both of our websites.



LEO:  Yes, at GRC.com, Steve's home; and TWiT.tv, our home.  I'll not say "my home."



STEVE:  Your domain.



LEO:  Our home.  All right, Steve Gibson.  Security news.



STEVE:  So, okay.  We're now on - you've heard of suicide watch; right?



LEO:  No.  Well, yeah, for people who are suicidal, yeah.



STEVE:  Well, Oracle is.



LEO:  Oh, dear.  Oh, no.



STEVE:  We are on Oracle exploit watch, or maybe it's Java exploit watch, courtesy of Oracle.



LEO:  Oh, Java I believe, yeah.



STEVE:  Yeah.  We've spoken about the Polish security researcher, Adam Gowdiak, before, whose company is Security...



LEO:  Sounds like a joke.



STEVE:  Huh?



LEO:  A Polish security researcher.  There's a joke in there, but I'm not going to do it.



STEVE:  No, no, no, no.  Seriously.  He's a good guy with Security Explorations.  And he reported to Oracle, and we have discussed this already a couple weeks ago, he reported discovering a very bad zero-day vulnerability that affects all versions of Java - v5, v6, v7.  He provided them with demonstration exploit and an explanation of the problem.  And they've essentially blown him off.



LEO:  Oh, come on.



STEVE:  No.  I'm not kidding.



LEO:  We're going to have to get a little new musical sounder:  It's the Java Exploit of the Week Week Week Week.  They blew him off?



STEVE:  Yes.  They said, well, we were unable to get this into the most recent update.  Remember we just had a massive Java update, 109 different problems fixed, in their October refresh.  Well, now they're saying they're going to fix this in February of 2013.  Kaspersky wrote in their Threatpost blog, they said: "The vulnerability and exploit were announced in late September.  Gowdiak's exploit successfully beat a fully patched Windows 7 computer running Firefox 15.0.1, Chrome 21, Internet Explorer 9, Opera 12, and Safari 5.1.7.  The exploit relies on a user landing on a site hosting the exploit.  An attacker would use a malicious Java applet or banner ad to drop the malware and ultimately take over full control of a user's then compromised machine."



So this is as bad as a Java exploit gets.  So being a little bit annoyed, Adam has now explained that he's fixed the problem, which took him, he says, under 30 minutes.  It actually took him 26 minutes to fix the known glaring Java zero-day vulnerability.  And what Oracle is saying is that, oh, they're already in the works testing the February update against all of their different platforms, and it's too late to put this into the release cycle, which is, what, four months away.



And so Adam wrote:  "Code logic is not changed at all.  Minor changes are applied to the code.  None of them influence what could be described as an externally visible scope affecting third-party applications."  So all indications are that this is pure bureaucratic mumbo-jumbo, to be polite, from Oracle.  So the question is, this is not in the wild yet.  This is privately disclosed.  Adam and his group at Security Explorations know what this is.  It's been made public.  We know that there is this problem.  And so now the question is, does Oracle find themselves more or less deliberately compromising users' machines through their reticence to fix this now, or to add this to their - to respond quickly.



LEO:  But they also have other things they're patching.  I mean, it's not like, I mean, they...



STEVE:  I know.



LEO:  Okay.



STEVE:  Yeah.  So they're saying they're holding to their February 2013 release.  So we are...



LEO:  2013?



STEVE:  February 2013.  That's the next time they're going to update Java.



LEO:  Just don't use Java.  Don't be foolish.  Just stop using Java.



STEVE:  Exactly.  This is across all browsers, all platforms, all versions of Java.  This is bad.  And this is a remote, I mean, this is as bad as it gets, a critical vulnerability that allows anyone who discovers it to take over your machine.  So...



LEO:  God.  Now, it has to come in through the browser, or you have to run a Java program directly on your computer; right?



STEVE:  Nope.  Kaspersky, describing it, said:  "The exploit relies on a user landing on a site hosting the exploit."



LEO:  But that's what I mean.  It comes in through your browser.



STEVE:  Correct.



LEO:  Your browser has to execute Java.  Presumably they could manage an exploit by writing a program with code like that in it that you would download and run separately.



STEVE:  Yeah, but, I mean, for example, this could be in injected in an ad.  So you could have a banner ad served up maliciously somewhere.  No, I mean, this is the way people are now getting their machines primarily infected is visiting websites that are taking advantage, I mean, even the fiction that we're reading, Mark Russinovich's approaches to how people get compromised is this because this is how it happens now.  And so here's Oracle, knowing that there's a problem and saying, eh, it's not public, so we're going to wait till February of 2013.



LEO:  Or until it becomes public, which it presumably will.



STEVE:  We just had this huge disaster with the Macs all being compromised, hundreds of thousands of Macintosh machines.  So it's like, oh, okay.  So we are thus on Oracle exploit watch.  We'll see what happens.



LEO:  Oh, geez.



STEVE:  Now, many people tweeted - and thank you, everybody who tweeted - an annoying announcement.  And you probably saw this, Leo.  The headline was covered in many different locations, claiming a tenfold bandwidth improvement through using some algebra.  And, I mean, like a typical headline was "Algebra creates tenfold bandwidth improvement."



LEO:  What?



STEVE:  And it's like, I don't think so.



LEO:  What?



STEVE:  But here's the deal.  It's completely bogus.  Researchers at MIT, the University of Porto in Portugal, Harvard, Caltech, and the Technical University of Munich have come up with a solution which can improve the Internet-using experience of a class of users.  So quoting from, I think this might have been, it wasn't Wired, it was maybe Techworld.  Anyway, all of the stories pretty much used the same boilerplate from the press release that the group that are commercializing this put out.  It says:



"The technology transforms the way packets of data are sent.  Instead of sending packets, it sends algebraic equations that describe series of packets.  So if a packet goes missing, instead of asking the network to resend it, the receiving device can solve for the missing one itself. Since the equations involved are simple and linear, the processing load on a phone, router, or base station is negligible."



So it's like, okay.  Well, listeners to this podcast have enough understanding of technology to probably get or guess what's going on.  First of all, there's no way that you get a tenfold bandwidth improvement.  And in the press release they talk about how they were demonstrating this by playing a YouTube video on a train somewhere, and theirs was just playing smoothly...



LEO:  Oh, please.



STEVE:  ...without problems, while other people around them were having glitch-y, stop-y, unworkable experiences.  So, and I don't mean to downplay what they've done.  This is nice.  But this is not a tenfold bandwidth improvement thanks to some algebra.  What they've done is they've added error correction code.  It's like RAID for WiFi.  And something like this has been done recently.  I want to say that the Steam distribution system does this also because I know that Mark Thompson and I, a couple years ago, he was implementing his own content distribution technology for a group that he was working with.  And so we were talking about this, and he was looking into the code and so forth.  And I've often talked about error correction in the context, of course, of hard drives.



And so it's clear that what they're doing is they're actually adding some overhead to each packet sent, such that, if some are missing, using typical error correction technology, which is not rocket science by any means, they can fill in the missing data.  So, I mean, it's cool, and it's clever, but it certainly doesn't get you a tenfold bandwidth improvement.  And they talk about how, if a packet were lost, what you would normally have to do is ask for it again.  You'd have to send back, oops, we don't have this packet, and get it again.  Now, the streaming protocols already get around doing that.  They'll just skip the packet.  You and I are talking back and forth on a streaming protocol designed to be tolerant of lost packets.



So anyway, so I just wanted to respond to the many people who tweeted saying, hey, can you tell us about this?  First of all, calm down, it's not a tenfold bandwidth improvement.  That just isn't available.  It is, in fact, if you had perfect packet delivery, it would be a slight bandwidth reduction.  Yet in the presence of a certain level of lost packets, then that extra overhead ends up benefiting you, if you're in a situation where your particular use of the Internet is intolerant of a roundtrip delay for dealing with a lost packet, because the overhead you've added to every single packet allows you to compute the contents of lost packets.



So anyway, there's a company, Code-on.org, which is the licensing LLC that's been set up among these parties.  It's an MIT/Caltech startup called Code-On Technologies, where they're making this available.  And I think it's a good thing.  Maybe it'll catch on for certain uses.  But a tenfold bandwidth improvement, no.  I mean, the only way - you'd be hard pressed, actually, to make the system do that.  If you had really high packet loss, then at some point even this system won't help you.



I mean, I guess it could be dynamically adaptive so that, as your packet loss goes up, it starts putting more redundancy into the packets in order to increase the amount of correction, to increase a tolerance for packet loss.  It doesn't, I mean, these problems have been solved all over the place in all kinds of ways.  The dynamics are different here than, for example, on a hard disk drive because here you do have the ability to ask for data again if you are unable to correct it.  On a hard disk drive, once the data has been written, then you lose that data from the write buffer, and you now are required to recover it and correct it when you are trying to read it later.  So things are a little bit different than in a real-time data flow.



But anyway, it's an interesting thing.  But it'd be interesting to see if you could actually demonstrate a tenfold bandwidth improvement.  It would have to be an extremely lossy environment, where you were performing heavy replacement of lost packets.  I don't even know.  To me that just seems like you're really stretching it.



Another little piece of interesting news that a number of our listeners picked up on and made sure I knew about:  A mathematician, Zach Harris, received a spoofed email from Google.  That is, it looked like an authentic piece of email from Google, from some sort of a headhunter, like offering him a job.  And he wasn't interested in the job, but he was interested in the fact that this was clearly spam, but it should have been impossible to spoof it because it was protected with Google's DKIM, the Domain Keys Identified Mail.  We've talked about the technology of DKIM before.  The idea is that the mail is signed with Google's private key, and DNS is used for publishing their public key.  So this is a very nice, simple, sort of straightforward demonstration and application of the use of public key crypto.  That is, you use DNS to publish the public signing key, which is used to verify the signature done with the private key.



The problem is, when Zach, who is a mathematician, took a look at the email headers, he realized that it was a 512-bit public key.  And we all know that's not enough anymore.  And Zach said, he was quoted in an article saying, "I like factoring."  So he factored from the email the crypto that Google was using because he was able to look up, using DNS, look up their public key.  He cracked it.  And then he spoofed his own email back to Google, and it was like between Brin and - is it Serge?



LEO:  Sergey.



STEVE:  Sergey.



LEO:  Larry Page and Sergey Brin.  He faked, he pretended it was him?



STEVE:  He faked an email...



LEO:  Might as well go to the top.



STEVE:  ...from one of them to the other, in both directions, an email that was clearly spoofed.



LEO:  That got their attention.



STEVE:  Exactly.  And what happened was the next day Google's DKIM went to 2048 bits.



LEO:  Wow.  What was his email?  Yo ho ho, dude?  Arrrgh.



STEVE:  So then he looks around, and it turns out that the same weak DKIM keys are currently in use by PayPal, Yahoo!, Amazon, eBay, Apple, Dell, LinkedIn, Twitter, SBCGlobal, U.S. Bank, HP, Match.com, and HSBC.  So what this is - and again, this was - the headlines were ridiculous.  The headlines were "Massive Internet Security Vulnerability."  Okay, no, no.  This is for spoofing email.  And maybe people thought, well, we'll use a 512-bit key because who's going to bother factoring that, just to spoof.



LEO:  It's not a high-value target.



STEVE:  No.



LEO:  Although it is.  I mean, it's not insignificant, either.



STEVE:  The DKIM standard calls for a 1024-bit minimum key.



LEO:  Oh, interesting.



STEVE:  And that makes sense because, I mean, 1024 bits is fine today.  We already know that 512 isn't.  768, which is splitting the difference between 512 and 1024, eh, it hasn't been hacked yet.  There's been no, I mean, that's like where the contests are.  The factoring contests are sitting at - looking for factoring a 768-bit key.  512, as we've already seen, and as Zach re-proved, is no longer strong enough.  We need 1024 bits.  So I imagine everybody will pretty quickly strengthen their antispoofing public key crypto to 1024 bits.



It must be, again, remember these are relatively expensive operations.  Public key crypto using RSA style is expensive.  This is another reason why switching to ECC, elliptic curve crypto, for this sort of application would make sense.  Because mail is being processed a lot, obviously.  There's huge amounts of mail going back and forth.  And this requires a relatively expensive crypto process in order to process email headers.  So that's probably why they were sort of hoping they could get away with a shorter 512-bit key because it would be lower processing overhead.  Doesn't look like that's going to be possible any longer.



LEO:  Interesting.



STEVE:  Because we've got lots of people who like factoring. 



LEO:  Yeah, and know how to do it.



STEVE:  And then lastly, I wanted to point out a story that has been out for the last few days about a surprising compromise at Barnes & Noble.  Sixty-three stores spread all over the country - California, Connecticut, Florida, Illinois, Massachusetts, New Jersey, New York, Pennsylvania, and Rhode Island - were all compromised, having somehow the PIN pads on the checkout registers were compromised.  And we've talked about PIN pad compromises in the past where somebody would maliciously sneak a little radio into the design of the pad.  This surprised people.  This is 63 stores, geographically spread.



When Barnes & Noble informed the FBI, the FBI asked Barnes & Noble not to go public with the information because it wasn't clear whether this was an inside job, whether this was organized crime, what was going on.  And the barrier of secrecy has since been lifted on this so that Barnes & Noble was able to inform the world.



And the takeaway is, if you are a listener, or know somebody who has used the PIN pads at Barnes & Noble stores in California, Connecticut, Florida, Illinois, Massachusetts, New Jersey, New York, Pennsylvania, or Rhode Island, then you should consider seriously - and this is the advice from the FBI and Barnes & Noble - change your PIN.  Because many customers of Barnes & Noble during a period of time, apparently around through the summer, were subject to - and, I mean, this has been exploited.  This was found because people were getting their debit cards, ATM cards compromised, and fraudulent charges were showing up on them.  And they tracked down the common factor among all these people were they had been at Barnes & Noble.  And so this problem was located.



LEO:  This was a hardware hack.  They were able to get some hardware.



STEVE:  Well, and then there's still not full information available.  I tried to dig down, and they're now saying this has happened, but it's not clear whether it's hardware or software.  It would be, I mean, I just don't know.  But they are saying it is the PIN pad.  The stories show a picture of one, as if it's that physical thing.  But it could be, for example, PIN pad firmware, which is in the gray zone.  Is that hardware, or is that software?  Well, it's firmware.  So specifically the word means it's somewhere between soft and hard.



LEO:  It's firm.



STEVE:  Yeah, it's firm.  So last week I mentioned Michael McCollum's newest novel, which I had just finished reading; and, as a consequence, we were able to have our regularly scheduled podcast on elliptic curve crypto.  I read right up to the finish line Tuesday night.  And it is now published.



LEO:  Oh, good.



STEVE:  In order to tweet about it as I did yesterday, I wrote a review on Amazon.  The title of my review was "A Great Adventure Which Unfolds Between Continents, Rather Than Between Stars."  I said:  "I'm a huge fan of Michael McCollum's always terrific space operas.  They rank among my most favorite sci-fi, which I recommend routinely and without hesitation.  They're so much fun that I've read most of them more than once; and, if you haven't yet discovered his Gibraltar and Antares trilogies, don't stop shopping after you have grabbed this latest work, 'Euclid's Wall.'  In 'Euclid's Wall,' Michael brings us down to Earth, or back to Earth, or stuck on Earth after an innocent mistake made by a pair of PhDs in the near future, in 2087..."



LEO:  You know, those PhDs again.  I'll tell you.



STEVE:  "...pretty much ends the world as we know it.  Whoops.  Thus the sailing ship on the book's cover, 100 years post-catastrophe, as humanity struggles to recreate and rebuild pieces of what has been lost.  Lost was the technology required to fly, along with pretty much everything else we take for granted these days.  The whole idea is really quite thought-provoking, and more than a little chilling.



"Into this hauntingly plausible future, Michael introduces relatable and engaging characters, then weaves the sort of clever plot puzzle I've always enjoyed about his novels. Though I finished the book several weeks ago, it has remained with me, a bit haunting, like a recent vivid dream.



"If you have an imagination that's usually satisfied by phasers and photon torpedoes - though you won't find those here - I believe you'll enjoy this voyage on Michael's high seas every bit as much as I did.  I rated this book five stars because I think it deserves every one of them.  I bet you think so, too."



So for anyone who has read Gibraltar or Antares or all of the other things that Michael does, he of course is at SciFi-AZ.com.  And he's got his books - he publishes them himself.  He bought all of the equipment a long time ago to print and bind softcover novels, just because he wanted to be vertically integrated.  But also it's available at Amazon on the Kindle store.  So it's a really fun book.



And while I was going through the mailbag for today's Q&A, I ran across - there was a subject line that I said, huh?  What?  It was "Honor Harrington One Year Later."  Chris Schwanekamp in Columbus, Ohio, wrote.  He said, "In Episode 318, on 9/15/2011, you mentioned the Honor Harrington series; and, based on your enthusiastic endorsement, I started," he says in quotes, "'reading it,' unquote.  I actually listen to the audio books in the car to and from work.  I can't thank you enough, and the others who mentioned it to you as well, for bringing this series to my attention.  It was my very first sci-fi series, and it was simply incredible.  Once I started reading, I didn't look back.  I dropped Security Now! like a bad habit.  I read all 13 books, then broke off and went through almost all the short stories, then back to re-read 'On Basilisk Station' again.  But my favorite book by far was 'Echoes of Honor.'  Book No. 14, 'Shadow of Freedom,' can't get here soon enough.



"I've now started to catch up on all the Security Now! episodes I missed.  But I've got to be honest, you and Leo are a bit of a letdown compared to the Honor Harrington series.  Still, I admit, I've missed you guys."  So I'm glad to have you back.  "This series was life-changing for me, and I'm sure I'll be reading and re-reading these books the rest of my life.  For that I can't thank you enough.  Now, with regard to Security Now!, 'Let's be about it.'"  Which actually is one of Honor's favorite phrases, so it's very much like Picard's "Make it so, No. 1."



LEO:  What is it again?



STEVE:  "Let's be about it."



LEO:  "Let's be about it."



STEVE:  Generally the way she ends her meetings, she'll...



LEO:  "Let's be about it."  "Make it so" is a little more dramatic than "Be about it," but okay.



STEVE:  Exactly.



LEO:  "Make it so" was taken, yeah.



STEVE:  And I've been flooded with really neat health-related low-carb feedback from our listeners, whom I asked to send me their results and experiences of any sort.  And so we will verify that the calendar is free this coming Sunday, October 28th, 2:00 p.m. Pacific time, in which case we will, if it is free, record Episode No. 3 of "Over the Sugar Hill," essentially looking, at six months later, what our listeners have discovered and what you and I have discovered.



LEO:  Now, Dr. Mom fortunately still has some painkillers left over, so...



STEVE:  She can medicate herself.



LEO:  Premedicate.  Giving her a good warning here.



STEVE:  That's good, yeah.



LEO:  So, yeah.  Well, I don't - Chad's not here yet, but I don't anticipate any difficulty doing that this Sunday.  So plan on it.



STEVE:  Okay.  So anyone who wants to listen live, we're targeting at this coming Sunday, October 28th, 2:00 p.m. Pacific time.  It'll of course be a TWiT Special, so you'll be able to grab the podcast any time after that.



LEO:  Yes.



STEVE:  As we have the other things.  And I just did want to mention briefly, since I'm an iPad lover, that yesterday was the big keynote and introduction of the, I mean, anticlimactic iPad mini announcement, as well as a refresh of a number of Apple's other things.  And I think the thing that I like most about the mini, Leo, is that they managed to get very slim margins on two sides, where they don't have the camera or the home button, holding it in portrait mode as opposed to landscape orientation.  In portrait mode it would be the left and right edges.  And so that gives it an overall sort of svelte feeling, which I like.  And it was 9.7 diagonal measure, which is easy to remember because the regular size pad is - I'm sorry, 7.9, because the regular pad is 9.7.



LEO:  Oh, I didn't even think of that.  It's flip-flopped.



STEVE:  Yeah.  7.9 and 9.7.  And it looks like a nice device.  I guess the criticism has been that it's on the pricey side.  It'll be interesting to see how the market judges that because we do have things like the Nexus 7, which at $199 is just a very nice, obviously non-Apple solution.  And as I was saying to you before we began recording, the one thing that chafes a bit is that Apple still bumps the price by $100 as you increase memory size from 16GB to 32 to 64, because EEROM, this nonvolatile memory, just doesn't cost that much.  And for them to gouge us $100 per step does seem much.  And, for example, other companies, high-volume producers like Amazon, have a much lower price increment as you increase the amount of nonvolatile memory on their devices.



LEO:  Well, and Google has an announcement on Monday, in which I think they're going to update the Nexus 7.  Yeah, I think they're doing a - I think, the rumor is, they're going to do a Nexus 10 that will be higher DPI than the iPad 3 or 4.



STEVE:  [Strangling noise]



LEO:  So hold on.  I don't think the price, I mean, 70 bucks more, remember, you're quoting $200 for an 8GB Nexus 7.  It's 250 for a 16GB.  So compare 250 to 329.  That's not - a 70 bucks premium for access to the Apple iOS Store and all of that, I think that that is about as good a price as one would expect from Apple.



STEVE:  Yeah, when you put it that way, I think you're right.



LEO:  By the way, you don't have to order one.  Orders start Friday at midnight, Thursday-Friday at midnight.  And then they'll arrive the following week.  And of course we order one because we have to.  So I'll be getting the WiFi one.



STEVE:  Yeah.  I think what I'll probably do, I won't own one until I make the mistake of walking into an Apple store.



LEO:  Well, that's why - I want to hold it because some people have said - and of course I didn't go to the event, and people who did held it.  And it looked like it was maybe a bit of a stretch for the hand.  I don't know if you can hold that in one hand, even though that's what they're promoting.



STEVE:  Yeah.  And frankly, I'm a little wondering about - I like the thin margins, the thin frame.



LEO:  Thin bezel, yeah.



STEVE:  The bezel.  On the other hand, it's useful that it's a holdable dead zone on the current size pad.  And I find myself, sometimes my hands will wander on the screen and, like, trigger something that I don't mean to do.  So you won't be able to do that on this pad.



LEO:  Well, apparently they've patched iOS to reject accidental touches on the side.  Again, no one knows till they try it.  Somehow it knows when you want to touch it and don't.  Remember, that was a problem with the first Kindle was you'd hold it, and it'd turn the page by accident.



STEVE:  Oh, my god, yes.  It was so annoying because everyone would want to take it from me, but it was all page-turn button.  And I'd be like, uh, okay, hold it right over here in order not to lose...



LEO:  They fixed that.  Amazon did fix that.  So, you know, I'm withholding judgment until I actually hold one in my hands.  I can't tell if it's going to be worth it.  I certainly, I love my Nexus 7.  I like the idea of a 7"  tablet.  I really liked the Galaxy 7 when it came out.  So we'll just withhold.



STEVE:  Yeah.  And for me, I guess we have the iPad 1 resolution that's been reduced in size.  So the pixels per inch increases, yet the overall resolution is still 1024x768.  So it's the same quarter of the resolution of the third-generation and fourth-generation, the newly announced fourth-generation full-size iPad.  For me, I think that's still the sweet spot.  I like having a screen that's that size.  Because, I mean, I use it more than I use any other device.  I just love my iPad.



LEO:  Have you got your Paperwhite yet?



STEVE:  Oh, I was just going to take us there.



LEO:  Okay.  Take us there, baby.



STEVE:  I really like it.  It's interesting because, if you turn the - there was a lot of hype about it.  And I was interested to see, for example, if they actually increased the resolution, if they actually increased the contrast.  Well, they didn't.  They carefully designed the fonts, which absolutely makes total sense to have done that.  But if you turn the light off and hold the two right next to each other, showing exactly the same image, I've done A/B comparisons, there's no difference whatsoever.



So I think - and I remember when they went to, like, the DX versus the earlier one.  They were saying, oh, yeah, we've done much more contrast.  No.  Not much more.  They keep making the frame around it darker so that the background of the eInk screen looks lighter by comparison.  So now the Paperwhite, I mean, don't get me wrong, I love it, but I'm annoyed by bogus claims.  And so with no light on, they are identical gray on gray, dark gray on light gray.



But it's spooky.  As you bring the illumination up, it has the effect of only lightening the background and not apparently lightening the dark print.  And so with that illumination turned up, even just like a quarter of the way or a third of the way, not so that it's a flashlight, but just so that it really does increase the contrast.  And so it's super effective.



And in fact I was only talking about it from a lighting standpoint.  And I gave Jenny hers the day after it came, and she wrote the next morning, and she said the light is not my favorite part.  It's all the other features, the what is it they call it, the "bones" of the book?  I think that's the...



LEO:  The bones?



STEVE:  It's something.  I can't remember the term.  There's, like, they've done something that gives you much  more visibility into the structure of the book itself.



LEO:  Oh, yeah, yeah, yeah.  No.  X-Ray [laughing].



STEVE:  That's right.



LEO:  Yeah, I can see where your mind was going with that.  X-Ray.  Look into the book.  They do that with movies and TV, and it's kind of interesting.  On the Kindle Fire HD, as you're watching a movie, it will pop up in the controls the name of a cast member on the screen, and you can click it.  It will go to Wikipedia.  It's an interesting idea.



STEVE:  Yeah, a nice way of leveraging the medium.



LEO:  Knowledge, yeah, exactly.



STEVE:  Well, again, while going through the mailbag, I ran across a note from Mike Woods in Cheshire, U.K., who was wondering about SpinRite's "double bit flip," which I talked about, I think it was last week.  And I thought, since we're doing a Q&A this week, in the spirit of Q&A, I would share this.  He said, "Hi, Steve.  Thanks for the look under the hood of SpinRite.  Your explanation of the way it flips all the bits twice to test the surface was fascinating.  I have a question, though.  As a satisfied user, I know that, when SpinRite gets to a problem area on a drive, it slows down and can take hours before moving on.  How does that work?  Is it just flipping the bits continuously until they come back the same as they are sent?  Mike."



And so the answer is no.  The bit-flipping that I talked about is what SpinRite does to test the surface and, in modern drives, essentially assist the drive itself in recognizing there's a problem.  Remember that once upon a time drives were dumb.  And so SpinRite had all of the technology in it for relocating defective sectors somewhere else.  It understood the file system.  It knew how to mark the sector bad in the low-level format to prevent it from ever being used again, even if you reformatted the drive.  It understood how to parse everything in the file allocation table and directories and everything so that it was able to essentially dynamically relocate data that had been recovered to somewhere safe and then knit the file system back together with the data moved.



None of that is necessary today because drives have taken over that responsibility.  The problem is, having responsibility and executing on that responsibility are two different things.  As I have said before, it's only when the drive is asked to read the data that it's able to detect that the data can't be or is difficult to read.  And so there's like a gray zone, if you can think of it that way.  If it reads with no trouble at all, then the drive's happy.  If it's unable to correct the data, then the drive is not happy, and that's when it returns an error saying I can't read the sector.  It's only when you're in between that, when there was a problem that required correction, and that the correction was severe enough that the drive starts to get worried that it may not be able to correct it next time, that then the drive is stimulated to relocate the sector to somewhere safe.



So SpinRite's arduous recovery process happens first.  And only after it's able to recover the data from the sector does it then invert that twice in order to see whether there's actually a problem on the physical sector, or whether, for example, today, the track densities are so high that, if you bump the drive while you're writing to it, the head will be jerked off center, and so it could write that track a little bit away from center.  So there's nothing wrong with that location, it's just that some vibration hit it at the wrong time.  So once SpinRite recovers the data, it then does its double bit flip to show the drive whether there's a problem or not.  And if there's not a problem, it'll put it back down where it got it.  If there is a problem, then the drive will say, ooh, it's not safe to put the data here, and it'll handle the relocation on our behalf.  So it's a little complicated, but it all works.



LEO:  Pretty impressive.  Anyway, enough.



STEVE:  Okay.



LEO:  Enough.  Let's get to questions.  10 of them.



STEVE:  Where were we?



LEO:  Where was we?  Starting with Question No. 1 from Patrik Petroff in Gothenburg, Sweden.  I, by the way, just love our international audience.  I just think...



STEVE:  We have a strong international audience, yes.



LEO:  Well, this show especially, I think.  Because, as you said, there's nothing like this anywhere in the world.



STEVE:  Well, and I guess the feedback allows us to get a sense for where our listeners are because otherwise you're just sort of broadcasting to the Internet, and you don't know where everybody is.



LEO:  Exactly.



STEVE:  But we do know.



LEO:  You know, I kind of know, too, because during TWiT and many of the other shows, but TWiT especially, we have live audiences.  And it has now become my stock question.  Okay, who's traveled the farthest?  How many of you are outside the U.S.?  And there's at least two or three international listeners always in the audience, often from Scandinavia.  There was somebody in from Norway yesterday.  Patrik Petroff says:  Hi, Steve.  A small side - by the way, he sounds Russian, doesn't he.  A small side note that you might want to share on Security Now! is the fact that DNSCrypt uses - ready for it - ECC, that thing we were talking about last week.



STEVE:  Elliptic curve crypto.



LEO:  That's what I was trying to remember.  I keep wanting to say "error correction."



STEVE:  Me, too.



LEO:  From the OpenDNS FAQ, Question 4:  "Is this using SSL?  What's the crypto and what's the design?"  OpenDNS is a service, free and paid service that we talk about a lot, OpenDNS.com.  "We are not using SSL.  While we make the analogy that DNSCrypt is like SSL in that it wraps all DNS traffic with encryption the same way SSL wraps all HTTP traffic, it's not the crypto library being used.  We are using elliptical-curve crypto, in particular the Curve 25519 elliptical curve.  The design goals are similar to those described in the DNSCurve forwarder design."  Wow.  I have to say, I love OpenDNS.



STEVE:  Well, and this was in my notes last week.  And since I don't literally read my notes, I just forgot to mention this.  But I saw Patrik's note, and I said, hey, I want to make sure that I remind our listeners that, yes, everything we heard and learned about elliptic curve crypto and the crazy way it works applies to DNSCrypt, which I know we have a huge number of listeners who are OpenDNS fans and users and have been experimenting with DNSCrypt.  ECC is perfect for that.  And the whole point of DNS is that, as we have often discussed, it uses the UDP Internet protocol rather than TCP.  TCP makes sense for establishing a relatively persistent connection.  UDP makes sense for a query and response, which is much lower overhead.



With TCP, as we've discussed when we talked about it, there is first the three-way handshake of a SYN, a SYN ACK, and an ACK.  Then you've established your low-level connection. Then you negotiate the SSL handshake, which again is multiple packets, while everybody agrees on what they're going to do and so forth.  And only after all that can you begin to actually send data.  Well, that would be a huge amount of overhead to put into DNS.



So DNSCrypt uses ECC because you're able to use DNS to get the public key of the DNS domain that you're wanting to get authoritative information from, and then make a single query which is encrypted, and receive a single reply packet which is also encrypted.  So you get authentication and privacy and super-low packet-level overhead; but also, thanks to the efficiency of elliptic curve crypto, it's low-level processing overhead.  So it's just a perfect use of elliptic curve crypto.  And I was glad that Patrik reminded me that I forgot to bring that up last week.  And I knew that our listeners who are OpenDNS users would find that interesting.



LEO:  As are most of us.  Certainly I am.  I love OpenDNS.  It's nice, though, you put your trust in a company, based on whatever research you do, but it's nice to get that reaffirmed from time to time - oh, yeah, they really are state of the art.



STEVE:  They're doing it right, yes.



LEO:  Yeah, I just love that.  And of course we did talk abut the fact of using DNSCrypt some time ago.  David in Durham, North Carolina wonders about practical fingerprint reader insecurity:  Steve, on your last feedback episode you mentioned how UPEK fingerprint-reading software has very weak encryption in the registry for your credentials.  I have a Dell Vostro - I always say Vostro.



STEVE:  Vostro.



LEO:  [Italian accent] I don't know why, but it seems like it should be Vostro.  I have a Dell Vostro 3550 that has a fingerprint reader on it.  I don't use the laptop in a public place very often; but, when I do, or when I take it to work - once in a while I work from home - I've learned how to use the Windows key L sequence - Windows L - when I leave it alone.  I'm also doing these things needed to make sure I don't get any virus infection on the computer.  With that in mind, how accessible is my registry to those that do not have direct access to my computer, physical access, or without a Trojan or virus?  If it's hard to get access to the registry, does it matter that it's not super well encrypted?  P.S.:  I've just checked with Windows 7.  Regedit does require administrative permission to run, even if you're already logged in as the administrator.  You have to escalate.  I guess I'd better change my settings so that I have to at least swipe my finger to run it.  And if that's true about regedit, what, if any, security measures are present for a program to read the registry?  I'm thinking none.  What do you say, Steve?



STEVE:  So this is a great point.  I mean, this is the difference between - and, well, it's the difference between a theoretical problem and a practical problem, which is why I used the word "practical" fingerprint reader insecurity.  The reason this was a concern in the security industry and is potentially a concern for users, or if nothing else you just need to be informed, is Microsoft did the right thing by never storing a decryptable anything, information, in Windows that would allow the reverse-engineering of the username and password.  Microsoft doesn't do it.



So the security event that was a concern was the discovery that this UPEK software was not very difficult to get that from, that is, they were storing the username and password, and you could reverse that to acquire them.  So except for people using the UPEK fingerprint system, that would not be possible.  So it's a different thing to say, okay, so what does that mean?  Well, it just sort of says there's a problem.  But David's right in questioning, well, okay, but practically, how worried should I be?



And I would say probably not very because the danger would be that something malicious gets into your system and then looks to see whether you are using the UPEK software, goes into the registry, gets the data, and is able to decrypt it.  So then the problem is that this malware which you've gotten already gets to know your username and password.  Well, it already is running in your computer, so it's achieved most of what it would want to do with your username and password.  Yes, there are all kinds of privilege-escalation attacks that it could employ if it wasn't empowered to do that.  But hopefully the registry is protected.



He asks about needing privilege to access regedit itself.  It turns out that there's extreme granularity of security in the registry.  Individual items in the registry can have full-on Windows ACL (Access Control Lists) applied to them.  So security is very granular.  So it's not just regedit that you need to have access to.  It's your logon credentials allow you to see and read and alter that information with a high level of granularity.  So it's very well designed at that level.



So anyway, I liked this question because it allowed us to look at, okay, what's the theoretical problem versus the practical problem?  Theoretically, the concern was they were storing data that was your username and password that could be extracted and returned to plaintext.  Microsoft never does that.  So this represented a chink in the armor, essentially.  But in order for that to be valuable, something has to get that data.  And you have to be in the machine already.  So your machine's already compromised, typically, in order for that to be a problem.  And that's probably not a big deal.



LEO:  I always - that's me, by the way.  You're channeling me because I always ask that question.  But how much should I worry about this?



STEVE:  Right.



LEO:  That's always my question.  Taylor in the Greater Seattle Area - must be his phrase.  I can't imagine you saying that.



STEVE:  That's how he described where he was.



LEO:  "I am in Greater Seattle."  He's probably in Redmond, Washington; right?  How can we stay safe?  Hi, I've been listening to your podcasts.  I love them.  They're a great source of information.  They cover a lot of little topics very, very well.  But I'm wondering, if you could set up an ideal install, say of, I don't know, Windows 7, what would you do - what would you do, Steve Gibson - to keep it safe?



Personally I'm using Windows 7 64-bit.  My daily use account is not an admin account.  I have a secondary account for when I need admin privileges with a separate password from my main account.  I use Avast! with scanning set to high sensitivity and its behavior shield set to ask me if it should allow a system change instead of deciding on its own.  I use Firefox, the 64-bit Waterfox variant, and run it within a sandbox - Avast! offers a sandbox that you can use on demand to paying users - with Adblock Plus and NoScript installed.  This guy has double-barred the door.



I do scans every few months with Spybot Search & Destroy, and I make sure not to visit any shady websites.  I've also used ShieldsUP! - that's Steve's online service - to make sure I had a 100 percent "True Stealth" rating.  And if that were not enough, I also use KeyScrambler to prevent keylogging should something somehow get onto my computer.  This guy's worried about something.  I don't know what.



These are all free services, minus the manual sandbox in Avast!.  While it does have a sandbox in the free version, you can't manually tell it to run in a sandbox.  It'll decide based on whether it thinks that thing can be a threat.  So he decided to pay for Avast! so he has the ability to tell it, run everything in a sandbox.  All this has a very, very minimal impact on system resources and responsiveness, but I'm always searching for ways to harden my security.  Do you have any advice for me, or am I good?  Oh, wow.



STEVE:  Well, yes.  Taylor, I think you are...



LEO:  Think you're good.



STEVE:  You are wrapped up so tight it's amazing you can get anything done with that machine.



LEO:  He may have overdone it, even.



STEVE:  No, I respect what he's done.  I know that we have a lot of listeners who are running similarly.  And there are people who could use more security like he's employed, who are unfortunately getting themselves infected all the time because they're not.  The only thing that occurs to me in listening to all that is that you might want to crank up User Account Control to one notch above its default in Windows 7.  It's easy to find it.  You just put "UAC" in the little search term after you click the Start button, where you find stuff.  Put "UAC," and there's one item it'll find, and it'll bring you up that slider which is a four-step slider.  It's normally set, the default is to the next to the highest.  You can knock it up to the highest, if you'd like a little more protection from things altering your system.  And that's the only thing I can really - a simple, easy thing to do if you really want to, if a belt and suspenders are not enough, you'd also like to suspend gravity so that your pants can't fall down by themselves.  That ought to do it.



LEO:  Yeah.  It's going a little farther than I'd go.



STEVE:  Yeah.



LEO:  And I should probably be doing all this because I am probably a target of hackers as a public figure, as are you, in ways that somebody who's a private individual might not be.



STEVE:  Well, there are the active attacks and the passive attacks.  And most people are being affected, I mean, yes, spearphishing is a problem.  Someone sends you email deliberately designed for you to look like somebody you know, look like a service you're using.  I mean, I've gotten some PayPal spam, and I'm a PayPal user.  And it's like, okay, wait a minute.  And then I look, and I realize, oh, they sent this to the email address in my WHOIS registration instead of what PayPal knows me as.  So, yeah, you do need to just be on the lookout.



LEO:  Yeah.  All right.  I have another question for you, Steve, as one might expect.  Michael in Europe, and I mentioned this, the Catch-22 of the friends logon authentication on Facebook:  When I first heard Scott's suggestion on how to handle the OAUTH authentication spoofing problem that I initially raised a few weeks ago, I really loved the idea of showing the user photos of his Facebook friends.



Incidentally, I just wanted to mention this, Leo Laporte speaking now, they do.  They actually do this.  It happened to me the other day.  It said we have three different ways you can authenticate.  You can have a message texted to you.  I can't remember what the three were.  But one of them was identify friends.  And I remembered our conversation.  I said, I can't believe this.  So I tried it.  It's hard because you may not recognize everybody.  And you have to recognize a certain number of them to get in.  Eventually I just gave up.  It's a lot more cumbersome, as you might imagine, to do this.  Anyway, just so you know, Facebook does in fact do this.



After thinking about it for a while, I started wondering:  To show photos of your Facebook friends, doesn't Facebook first have to know who you are?  And if you are currently not logged in, how could Facebook do that safely before you enter your login credentials?  Whoops.  Well, actually no because, when you try to log - well, I'll explain what's going on with Facebook.



Considering that this is supposed to prevent you from entering your credentials on a malicious site, I think this could only work if Facebook or other OAUTH-supporting services would heavily rely on the tracking of logged-out users.  Or am I missing something here?  You, I'm sure, are going to say something, Steve.  But I should point out that you are giving it your email address and then saying I would like to authenticate as this person.



STEVE:  Well, and that's just the point, is that who is authenticating whom here?  What Michael was talking about is different than what you're talking about.  Your experience is you proving to Facebook that you are who you say you are.



LEO:  Right.  Oh, he was talking about an OAUTH situation.  I get it.



STEVE:  Yes.  And remember that we realized there would be a big potential problem, which I really do think we're going to have, with people getting used to the convenience of OAUTH, which is what is the underlying technology that allows that "Log in using your Facebook account" which we're seeing more and more frequently because it's so effective.  It's a much lower friction means of authenticating for so many people who are also Facebook users when they're going to some other site where they haven't been before.  They don't want to create an account just for that visit.  So they authenticate using their Facebook credentials.



And the problem, of course, is that that site takes you to Facebook.  It would be very easy for it to take you to a Facebook spoof site, where you then authenticate to Facebook, or you think you are, but you're not.  So the idea was, oh, make Facebook show you your friends so that you know it's really Facebook that you're authenticating to, which is the reverse model of what you were explaining, Leo, where you're proving to Facebook you're you by selecting your friends from among a grid of imposters.  So, and the point is, Michael's exactly right.  It doesn't work to have Facebook show you your friends because we've already covered exploits of this sort, or this "ilk," if I may use that word, where the malicious site would go to Facebook, pick up pictures of your friends, if Facebook was showing you your friends, and then present them to you, so it'd be able to get around using known friends and having Facebook prove that it is Facebook you're authenticating to.



So Michael's right.  The suggestion that we entertained a couple weeks ago has a Catch-22 problem.  It's funny, too, because I had this itch when we were talking about it.  It's like, something doesn't feel right about that.  But this is exactly the problem.  So, good one, Michael.



LEO:  Yeah, that's a good catch, of course.  And so that's the different situation, as an OAUTH provider it wouldn't be a good choice.



STEVE:  Right.  In OAUTH you're...



LEO:  You know nothing.



STEVE:  The potential exploit is you authenticate to a spoofed site.  So the idea was how to prevent the site being spoofed.  In what you were describing, Leo, it's...



LEO:  I know it's Facebook because I went there.  Unless somebody is in the middle.



STEVE:  Right.  And you're then being asked to prove that you are who you are to Facebook.



LEO:  It was a little onerous, I've got to say, after about the eighth picture.  And about three of them I go, I have no idea who that - now, maybe that's because I have more friends than I ought to.  But it takes pictures, at least the way Facebook's doing it, it says, okay, this person's your friend, and it takes a random picture from their collection, which could be a baby picture.  It's not that easy.  They probably should take the profile picture would be - but even that, many of my friends don't have themselves in their profile picture.



STEVE:  Right, right.



LEO:  So it's, eh, nice, it was a clever thought.



STEVE:  Yeah, the problem with OAUTH, I mean in this mode, is very much like the problem we fall into where the advice for preventing it has been don't ever install software you didn't ask for, that is, you didn't go looking for.  I love that advice because oftentimes, one way or the other, we're being asked to install something.  You go to a site, oh, you know, click this to install this control to get the full benefit of the site or whatever.  Or you're somewhere else, it's like, oh, you need to update your Flash viewer in order to watch the movies here.  Well, that's the way people get themselves zapped all the time.  They didn't go seeking that software.



Similarly, you just made the point, you knew you were at Facebook because you went to Facebook.  OAUTH offers the convenience of taking you there.  Well, being taken there by a third-party site is very similar to being offered software which you didn't go seeking.  So the better way to make OAUTH safe would be to log into Facebook on one page of your browser persistently, stay logged in, then go log in here.  You should be able to bounce over to Facebook, where you're already logged in, and then bounce right back.  In which case you've short-circuited the possibility of having to be asked to authenticate to Facebook.  But again, that sort of blows the whole benefit and the convenience of OAUTH.  So that's not going to work, either.  These problems don't have easy solutions.



LEO:  No, that's why...



STEVE:  Or maybe any solutions.



LEO:  Right, right.  It's thorny.  Kevin Daudt in The Netherlands - see, another international listener - has been thinking about software whitelisting:  I listened to the podcast about whitelisting of software.  I thought it in principle a good idea; but I wondered, what's your opinion about who defines the whitelist?  Comparing software whitelisting like Apple does in its iOS to firewalls wouldn't be the same as, let's say, Microsoft defining what ports are open on your firewall.  Would you lay this power to one company known for excluding software on iOS for other reasons than security?  Wouldn't it be better if the user himself could decide which whitelist to use?



STEVE:  Yeah.  I thought this was interesting because it sort of pulls us forward to the next part of the problem.  It's easy to say, oh, whitelisting is the future.  But then it's like, okay, where does the whitelist come from?  How do we decide?  If the user is in control, then you might as well not have it because it's like...



LEO:  They're not going to do it.



STEVE:  ...oh, I want to run this software.  What do you mean I can't run this software?



LEO:  Yeah, in effect you are in control right now.  I mean, you decide what sites you go to.



STEVE:  Yeah, I just...



LEO:  How's that working out for you?



STEVE:  Exactly.  I think the way we're going to solve this ultimately is we're going to have systems which are more bulletproof, where, I mean, there are many times I'm seeing things in email on my Windows machine, and I say to myself, oh, I'll have my iPad in a few hours when I'm out.  I'm going to open this and poke around then.  I mean, I'm saying to myself, I don't trust doing anything on a Windows platform.  The iPad is safer, as I am using it.  I mean, the fact that it doesn't have Flash or Java, and it's just a little bit of a - it's like having a sandbox.  It's a little bit of containment.



LEO:  Moving along to Chris Ward in Houston, Texas.  He's a little worried about Amazon's eBook ownership policy.  I don't know if you saw this story, but it was kind of a shocker to me, too, and I actually tweeted this a couple of days ago.  So did Cory Doctorow.  I know you've an avid Kindle fan, as am I, Steve, and you read a lot of eBooks.  I'm really disturbed about a recent article about Amazon mysteriously deleting a user's account and, more importantly, all the books on their Kindle without warning or reason.  He points to an article at BoingBoing, where Cory, I'm sure, posted the details.  I'll go there in a second.



Amazon often charges more for eBooks than paperbacks.  I don't know if that's relevant anyway.  But now it appears you don't even buy them.  You are only renting at Amazon's whim.  This is extremely disturbing to me, even though I have backups, and I supposed I could strip out the DRM if it came to that, like many other Security Now! listeners.  But it seems like this move is a huge step backwards for eBooks.  I'm curious about your thoughts.  And, from a security point of view, what is the best way for legal eBook owners to protect those eBooks they have rightfully purchased?



STEVE:  Well, okay, a couple things.



LEO:  Let me - can I summarize the story so that people know?



STEVE:  Yeah, yeah.



LEO:  It was a user, I think in the U.K., I'm trying to remember where, who just all of a sudden got her Amazon library deleted without explanation.  Actually, no, I'm sorry, she's Norwegian.  Her name was Linn.  Her access was revoked without warning.  Her account was closed.  Her Kindle was wiped remotely.  And then I read this on a Norwegian blog, as did apparently Cory and others.  Now, again, because this Martin Bekkelund and his blog doesn't give us the last name of Linn, we can't verify this.  But the emails coming from Amazon said - now, remember, she's Norwegian.  "Your Amazon U.K. account has been closed, as it has come to our attention this account is related to a previously blocked account."  And we can't tell you any more than that.  She asks for more information.  They say we can't tell you any more.  She asks again.  They said no, this is it, we're not going to tell you any more.  Don't try to create another account.  Bye bye.  And she's out of luck.



Now, apparently, according to BoingBoing, there's an update on this story.  Her account was mysteriously reactivated after this article was published.  But it does raise the question, who owns those books?  And if you somehow piss off Amazon, or iTunes, or Audible, and they decide to eliminate your account - now, in the case of Audible they can't erase the Audible tracks.  But you can't play them unless you put them on an iPod or something like that.  So what do you think?



STEVE:  Well, I can speak to Amazon and Kindle because I've looked in years past closely at the way it works.  And there was something that happened to me where I felt I was being unjustly restricted.  I think I had - there was a book that I was reading that had a very low download count.  And I hit the download limit, and I had read it over on a PC that I use, as it happens, with the stair climber.  And I had reset up the machine, and it still thought that other instance of Kindle on the PC existed, so it had - I've never had much success backing down that download limit when you hit it.  Most books I've never had a problem with.  I've got, I don't know, 15 Kindles or something.  And I don't put things on every Kindle.  But anyway, the point is that, out of curiosity, I experimented with Calibre.  And, oh, boy, is that effective.



LEO:  What is it?



STEVE:  It just strips the DRM right off, all of it.



LEO:  How do you spell it?



STEVE:  C-a-l-i-b-r-e.  And it is a general purpose eBook...



LEO:  Oh, Calibre.  Interesting pronunciation.  Yeah, Calibre.



STEVE:  Oh, I thought it was Calibre.



LEO:  Well, it might be.  It's probably a play on "libre," or free.



STEVE:  That's what I thought.



LEO:  But I know about this, and we've always called it Calibre.



STEVE:  Oh, okay.



LEO:  Calibre, I like that, too.  You know what, who knows who's right.



STEVE:  Anyway, so, I mean, it works.



LEO:  It's free.



STEVE:  And I was surprised.  And it's a nice eBook archiving system.  Now, I ended up removing it from my system because I don't use it.  I was just sort of curious, does this really happen, does it work and so forth.  In the case of Kindle, it is also a portable storage device.  You can plug it into a PC or presumably a Mac, although I never have, and there is a Documents folder, and there's all your eBooks.  So it is possible for a user to back up his Kindle or her Kindle onto any other device - the books are relatively small, they're .mobi format - and then restore them.  The books are locked to that device unless you go and remove the DRM, which there are tools for doing, and they're effective.



There was also, I think it was a format conversion I needed, where I needed to remove the DRM for some purpose.  Anyway, something that I owned, I had purchased, and I was like, okay, I feel like I have a legitimate, you know, I'm not stealing this from anyone, a legitimate reason for doing this.  So that technology exists.  It is very disturbing to think that it would be possible for someone's previously purchased product ever to be taken from them.  This is a problem when everything goes "e," and we've got connected devices, and at the publisher's whim these things can be removed.  I mean, we're seeing stories drift out about this happening on iOS devices or Windows 8 and so forth.  So at least in the case of the Kindle, you can back up your library and maintain your own copies.



LEO:  And should, apparently.



STEVE:  Yes.  Exactly.  Very good point.  If you are concerned about this, it makes sense to do it, and it's pretty simple.



LEO:  I think the issue is also this kind of - first of all, we're used to books.  Paper books.



STEVE:  Yes.



LEO:  And nobody who sells me a book can come into my house and take the book.



STEVE:  Right.



LEO:  And say, no, no, we don't like you anymore.



STEVE:  Look behind me on the video, Leo.  You will see walls of books.



LEO:  Right.  But I should point out that Amazon is not selling you a book.  They're giving you a revocable license to read the book.



STEVE:  Correct.



LEO:  So they're not doing anything that they haven't already said to you that they could do if they choose.



STEVE:  Yup.



LEO:  And that's part of the deal.  And so there's this disconnect because we think about books, and Amazon's thinking about DRM data that they rented.  So I'm sure you're violating the terms of service by removing DRM and backing them up anyway.



STEVE:  Well, wait, wait.  Let's be clear.  You can back them up and leave the DRM in place.



LEO:  But then you're still screwed because, if you don't have an Amazon account, you know it phones home and validates.



STEVE:  I don't think it does, Leo.



LEO:  Really?



STEVE:  I think it's locked to the device.



LEO:  Oh, okay.



STEVE:  So if you turned off the radio, then you could restore the book any time you wanted to, to that Kindle, and it would read it just fine.



LEO:  That's good.  And the problem is, of course, there is a doctrine, which is a defense, by the way, not an offense, of fair use that you have the right to back up data.  But it's not a law.  And the DMCA does not say that, and et cetera, et cetera.  But so there is this disconnect between the old way of doing things and the new way of doing things.  I'm not defending it.  I think it's something we've got to be very aware of, and I think you're right, people have got to back up.  But nobody backs up their Kindle.



STEVE:  And you mentioned the DMCA.  And it just sends a chill down my spine when I think about how security researchers have been blocked from researching crypto by the DMCA.  And what condition would we be in if people, for example, were unable to notify Oracle that there were known problems they had found in Java?  You know Oracle doesn't like the fact that this has all been made public and that their dirty laundry is flapping in the breeze.  They would wish that were not the case.  And I just - I hope that we don't legally screw this down any tighter than we have now because we will all suffer, much as we actually do, arguably, from the DMCA.



LEO:  And Calibre will convert it from the .mobi format with the DRM to an unprotected EPUB.  But I think you have to use a special plugin.



STEVE:  Yeah.  And the format conversation is never really very good.  It does what it can.  But, yeah.



LEO:  Most people are just going to say, hey, I've got this.  But I think it's important that they understand that they don't have it.  And if they're worried about this - you may not care if you lose all your Honor Harrington novels.  You've read them all.  I love books.  You love books, obviously.  And I love having books.



STEVE:  Yup.



LEO:  Maybe, I don't know, it's a really interesting issue.



STEVE:  I love having eBooks.  And at some point a while ago I did dump all of my Kindles over to my system's hard drive, as I'm legally allowed to do.  I mean, you just plug the Kindle in, and there they are.  Just drag and drop them; and, bang, now they're somewhere out of the Kindle, safe.  And at any point in the future I can move them back into that Kindle.  Or if some cataclysm occurs that prevents me from doing so, we know the tools are available for removing the DRM under terms that we feel are ethical for us, and we're able to do that.



LEO:  I should also point out that there's some question about, if you have a library of records or books, you can give them to your heirs.  And apparently that's not legal if you have iTunes music or Kindle books.  So there's this whole issue.  If you really want to keep something and hand it down, buy the physical media, I guess.  Pretty old-fashioned, though.



STEVE:  Well, and technically, isn't loaning a book to a friend, isn't that a violation of the publisher's rights?



LEO:  Well, yeah.  And they have this specific little feature that lets you do that in a very limited fashion.



STEVE:  No, no, I mean a physical book.



LEO:  Oh, physical book?  Is it?



STEVE:  Yeah.



LEO:  I don't think so.  Really?  I can't just give you the physical copy?  Sure I can.



STEVE:  I think, you know...



LEO:  Otherwise libraries would be out of business.  Of course you can.  Of course you can.  You think that's illegal?



STEVE:  Remember, libraries have been in trouble before.  They've had to fight for those rights.



LEO:  I do believe that you are allowed to give a book to somebody that you've read and let them read it.  I do believe that is legal.



STEVE:  You can't read mine.  That would be...



LEO:  The chatroom is saying that's first-sale doctrine, and of course protected.  But the problem is now in this digital world you can't, unless the company lets you, and there are very restrictive means of doing that.  It's ridiculous.  It's ridiculous.  No, but the music industry has tried to kill - remember record resale, used records.  They tried and failed.  But they don't have to worry about it anymore.  They've got DRM.  Or not.  I don't know.



Christopher Friday in San Diego, California is an unwitting "joiner."  Oh, dear, that sounds painful:  I opened my Documents folder and noticed something called "Join Me" in the lower left-hand section of the window - it's like "Eat Me," "Drink Me" - where all the externally mounted drives are listed.  I have not authorized any app downloads, nor knowingly accepted any meeting software.  The most recent thing I can remember doing is going to YouTube and creating a personal Google account so I can look at YouTube videos.  I'm very concerned that my computer is now compromised with software designed to let others see what's on my screen.  I never knowingly accepted or used "Join Me."  Has anyone ever heard of "Join Me" being loaded maliciously on a target computer via social networking in order to gain access to personal information?  Thank you.  Christopher Friday.  Does this ring a bell?



STEVE:  Yeah.  Join.Me is like a very lightweight screen-sharing app from the LogMeIn people.



LEO:  Ah.



STEVE:  And it's Join.Me, so they've used the .me top-level domain.  So it's Join.Me.  You can go there and get a token, essentially, then email that or tell it over the phone to a friend, who goes there, puts their token in, and they're able to view your screen.  So the good news is it's not malicious.  Christopher somehow, who knows, maybe he was installing something, and it was one of those, oh, uncheck this box if you don't want Join.Me added to your system.  Which it just annoys me that Java still has that checked for loading all of the Google toolbars or whatever it is they're promoting.  But I would imagine you can go to Add/Remove Programs and cleanly remove the Join.Me agent from your machine, Christopher.  So that's what that's about.  And you can get rid of it.



LEO:  I'm wondering, it could even be, I suppose, a bookmark he might have dragged to the desktop or something like that.  Might not even be anything to worry about.  Glenn Hyatt in Philadelphia, PA wonders about "ECC Keys, How Many Numbers?"  Steve, thank you for your rundown on elliptic curve cryptography:  fascinating, useful.  Seems to me the keys must involve more numbers than you describe.  The public key is a point on a curve in two dimensions; right?  That would be a pair of numbers:  x, y.  Does the NIST standard offer a convention whereby the public key is a single binary string that is broken into a pair of coordinates?



The private key, well, that's the number of times to add the point of origin to itself, as I understood from your explanation.  But isn't the point of origin also a secret?  Is that part of the private key in some way?  I'm glad he's asking these questions.  I don't even understand the question.  Thank you for your laudable work teaching all of us about security over the years.  Glenn Hyatt.  Huh?  What?



STEVE:  Well, okay.  I deliberately simplified this so that we had sort of a visual, conceptual, okay, I kind of know how this thing works approach.  The math gets immediately deep, and it involves things known to number theorists as "Galois fields" or "finite fields" of prime number size raised to an integer number.  And, I mean, it just goes crazy.  But so I didn't want to go any further.  And I have not looked into it at the level required to implement ECC myself because I haven't needed to implement ECC myself.  There's lots of open source software.  Anybody who is really curious, just Google "elliptic curve cryptography," and there are more resources available.  But I figured, okay, I achieved the goal of sort of giving people a taste for it, which is really all I was trying to do, rather than...



LEO:  Thank you.



STEVE:  ...nail it down to, okay, let's go write one during the half-hour podcast.



LEO:  Bless you, Steve.



STEVE:  Or hour-and-a-half podcast.



LEO:  Bless you, bless you, bless you.  Terry Richard, Toronto, Ontario, Canada writes about Windows 8:  Mayday, Mayday, Mayday!  Warning, Will Robinson.  I've been a Security Now! listener since Episode 1.  Great stuff.  Like you, I want to stick with Windows XP until the wheels fall off - maybe they have - XP no longer supported.  I have a computer running Windows XP that's running fine, and I really don't need a new machine at this point in time.  But I read in yesterday's news an article about Windows 8, and the reader comments that went along with it.  The general consensus seems to be this new OS is a disaster.  The recommendation is get a Windows 7 machine while you still can.  Some say they'll wait for Windows 9, but who knows what this will look like.  Actually, I don't even know if there'll be a Windows 9, myself.  But that's a conversation for Paul and Mary Jo.



Even though I don't need a new machine now, is it a good idea to get a new one anyway, on the chance that probable Windows OSes in future will be unsuitable for desktop work?  I ordered two new computers, but I can cancel if you should say something else.



I also have a comment:  As per your suggestion, I read last year the excellent book "Zero Day," re-read it this past week.  The situation described in the book, unfathomable to me.  That much of our infrastructure is connected to the web, that's incomprehensible.



I have some files which I would not wish anyone to tamper with.  I store them on a computer never connected to the 'Net, never has been.  If I could take such precautions, why is it that infrastructure computers are connected to the Internet?  For the sake of convenience?  As an example, nuclear power stations have been around since the '60s, and they weren't connected to the Internet then.  They worked.  Why connect them now?  Well, because they need to download our podcast.



Thank you for the Security Now! podcasts.  The knowledge I have gained from them has in all probability protected my computers from Internet risks.  Regards, Terry Richard.



STEVE:  Okay.  So clearly I feel more strongly about Windows 8 being a steaming pile of we know what I've described Windows as during an early episode of this podcast.



LEO:  But is that due to security issues or just the user interface?



STEVE:  Oh, I just...



LEO:  You don't like the user interface.  But we don't know yet if it's not secure, do we?



STEVE:  I don't like upgrading for the sake...



LEO:  You don't like new, yeah.



STEVE:  Exactly.  I don't like new.  We know what new is from a security standpoint.  It's always bad, just by definition.  I have to say, though, that I have softened my  position on Windows 7 dramatically.  I have been using it a lot recently - not myself, I'm still happily on Windows XP, which has 530 days remaining of support, that is, Service Pack 3.  Windows XP SP3, 530 days remaining.  So that's still good for another year and a half.  But I will definitely move to 7, not Vista, and not 8.  So Terry, I really think what people are suggesting is wise.  I think 7 is the next place to land.  And with any luck, 7 will take me into retirement.  So I do not want to move to Metro and what they have done to Windows 8.  It's just like, oh, my god.  So, yeah, I think 7 is...



LEO:  You know what's interesting, the reviews are starting to come in for the Windows RT Tablet.  And while I did expect kind of a howl of pain from real users, the reviewers have been very positive.  Now, that is not Windows 8.  That's the Windows 8 tablets.



STEVE:  Right, which is...



LEO:  ARM-based.



STEVE:  ...an ARM-based device, right.  And just his second point about why things are being connected, unfortunately, it's sad.  It's because they can.  And as you said, Leo, although it may not be to download this podcast...



LEO:  They've got to get eBay and...



STEVE:  Well, oh, and look, we can manage remotely.  What if the alarm goes off, and I'm in bed?



LEO:  Terrible idea.



STEVE:  Oh, god.



LEO:  Do not manage nuclear plants remotely, please?



STEVE:  Yeah.



LEO:  If you don't want to be onsite, then don't do the plant at all.  Just don't.  If you don't feel safe enough to sit next to the core, don't build it in the first place.



STEVE:  Yeah.  So the answer is pure convenience and absolute sheer stupidity.



LEO:  No requirement.



STEVE:  No.  My god.



LEO:  Jim Schimpf in Derry, PA - is that our last question?  Did I actually get through all of them?



STEVE:  Yeah.



LEO:  He's wondering about crypto in NFC.  We did a great episode.  If you're interested in NFC and how it works, go back a couple episodes.  He says it was a great show, too:  Just listened to it, shows how far behind I am.  Well, that's not that far.  That was just a few weeks.



STEVE:  Yeah.



LEO:  Your explanation, very clear, showed me that it's sort of RFID on steroids.



STEVE:  Yup.



LEO:  As you mentioned, encryption is part of the standard, but not used much yet.  So how prone is the system to interception?  13MHz is a pretty clear frequency, at least in the daytime.  Would an extremely sensitive shortwave receiver pick this up at, let's say, 10 meters?  10 meters away, not 10-meter frequency.  The modulation is above the audio, but it's easy to imagine a hacked receiver could demodulate the signal.  Thanks again for making my commute a complete pleasure.  Jim.



STEVE:  First of all, I think it's 315MHz, if memory serves, or 335 or something.  I don't think it was 13MHz.  That seems way low.  But yes.  Where we need to go, and I hope we go there soon, is to implement crypto in NFC.  We absolutely have the technology with public key crypto enabled by elliptic curve crypto, ECC, to perform communications between devices where they are strongly authenticated and absolutely protected against eavesdropping because that's exactly, for example, what we have with SSL.  When SSL is working, the whole point is man-in-the-middle attacks cannot work.  Eavesdropping attacks cannot work.  It is entirely possible for two endpoints, an NFC-enabled card, a smartcard of some sort, and the reader to freely talk back and forth if they've got public key crypto.  That's the key.  You have to have that.  And then it doesn't matter if you broadcast what you're doing or if somebody receives it.  It is in the spec.  As I have alluded to a couple weeks ago, I've got some things - I don't.  I have some information about things that will be happening that are exciting in the near future that we'll be talking about when I'm able to that are going to solve these problems in a cool way.



LEO:  Aren't you a sneaky cove.  A sly cove, you.  Steve Gibson is slyly hanging out at GRC.com, the Gibson Research Corporation.  But he's not doing so anonymously.  Oh, no.  You can go there and ask questions.  Go to GRC.com/feedback, and in a couple episodes we'll answer some questions.  You can follow him on Twitter, @SGgrc.  You can go there and get SpinRite, that would be a good idea, the world's best hard drive maintenance and recovery utility.  Gotta have it if you've got a hard drive.  But there's lots of free stuff there, security apps and password information.  Dietary information, too.  Don't forget, we're going to do a special "Up the Sugar Hill, Down the Sugar Hill" Part 3.



STEVE:  Over the Sugar Hill.  Around the Sugar Hill.  Through the Sugar Hill.  To grandmother's house we go.



LEO:  An update on carb-free living with Mr. Gibson, Sunday, 2:00 p.m. Pacific, 5:00 p.m. Eastern on TWiT.tv.  And we'll make a Special out of that so you can read the first, listen to the first two in preparation and listen to the third after that.



STEVE:  And for everybody who has sent me their stories, thank you very much.  For those who want to and haven't yet, you can just go to the Health page under Research from the GRC Main Menu, and there is a feedback page.  By all means, send me stuff.  I'm reading them all.  And, boy, Leo, I'll just, I'll tell you, it's really been gratifying to see how many people have, you know, the way the information was presented clicked for them.  They understood the science and the why.  And, wow, results have just been phenomenal.  We'll be talking about it on Sunday.



LEO:  Fabulous.  Can't wait for that.  And then of course we'll be back here on Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern, 1800 UTC for the next edition of Security Now!.



STEVE:  The Halloween edition.



LEO:  Oh.  Are you coming in costume?



STEVE:  Uh, okay.



LEO:  I have a costume I'll wear for that show.  I just thought of it.  Perfect.  The perfect outfit for that show.  You can always watch live.  We like it if you do.  But after the fact, too, on-demand versions available in a couple of versions.  Now, Steve on his site, GRC.com, has 16Kb audio, which is tinesy, and the even smaller plaintext version.  He does transcripts, human-written transcripts, so they're intelligible and spelled correctly and that kind of thing.  That's at GRC.com.  You can come to TWiT.tv for the higher bandwidth audio and even video, if you want to see Steve's smiling face.  Although I don't know why anybody would download the video.  People do, though.  Like one in five download video of this show.



STEVE:  Wow.  Cool.



LEO:  They like to look at you.



STEVE:  Ah, there's not much to see here.



LEO:  It is the kind of show you could just listen to and get pretty much 99.999 percent of it.



STEVE:  Yeah, and I do, I'm very conscious of the fact that most of our listeners are listeners.  And so thank goodness, too.  Because, boy, if I had to provide graphics to go along with all this, I'd just never get anything else done.



LEO:  I would love it.  We'd have to have a full-time illustrator.  But that would be great if we did.  Next time.  By the way, I've just been corrected, the UTC time is wrong because we end our summertime here in the United States on Sunday.  So...



STEVE:  Yay.



LEO:  Yay.  So I'm going to, instead of adding seven, I'm going to add eight, and it'll be 1900 UTC.  I hope I did that right.  Is that right?  1900 UTC?



STEVE:  So we're springing forward and falling back.  So we set our clocks back.



LEO:  We fall back.



STEVE:  Ooh, we get an extra hour; right?



LEO:  We get an extra hour.  But of course UTC never changes because it's enlightened.  It's always the same.



STEVE:  UTC and Arizona.  They don't change, either.



LEO:  U.S. is November 4th.  So, no.  Okay.  See, that's what I thought.



STEVE:  Oh.  Oh.



LEO:  That's what I thought.  So now I'm confused.  So I was right, it's 1800.  We'll figure it out by next week because it's November 4th.  That's right, Keith, thank you.



STEVE:  Okay.



LEO:  And that even further confused it because they changed the date.  And now I'm really - in fact, still some software does it wrong.



STEVE:  I know.



LEO:  I don't understand.



STEVE:  And the clocks we have on our bathroom mirrors, Leo.  No, they know.



LEO:  GMT does not change, but British Standard Time does change.  And Universal Coordinated Time never changes.



STEVE:  No.  Although it does die in 2038.  That's going to be a problem.



LEO:  Yes, because it's on UNIX.



STEVE:  32 bits.  Yes, baby.



LEO:  I hope I'm alive to see that.  And then we'll be able to say, "I remember Y2K."



STEVE:  Okay.  You have another podcast to do.



LEO:  I'd better go do it.



STEVE:  I think so.



LEO:  I'm just thinking.  And that's always a mistake.



STEVE:  I'll talk to next week.



LEO:  Thank you, Steve.  We'll see you next time on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#376	

DATE:		October 31, 2012

TITLE:		Fully Homomorphic Encryption (FHE)

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-376.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, after failing to find much in the way of interesting security news, Steve and Leo make up for that by introducing the concept of "Fully Homomorphic Encryption," which allows encrypted data to be operated upon WITHOUT it first being decrypted, and results remain encrypted.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson, the Explainer in Chief, is here to talk about - get ready.  Get your propeller beanies on.  This is one of those special Security Now! episodes.  He's going to explain a new kind of crypto, invented in the late '90s, so it's practically brand new.  Fully Homomorphic Encryption, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 376, recorded October 31st, 2012:  Fully Homomorphic Encryption.



It's time for Security Now!.  Get ready, ladies and gentlemen.  Propeller hats at the ready.  Here he is, our Explainer in Chief, Steve Gibson.  We talk, as always every week, about technology, about protecting yourself, about security, about privacy.  But sometimes we get into the weeds.  And I don't know, but I'm just looking at the title of today's show, and I think this may be a weedy episode.  Hi, Steve Gibson.



STEVE GIBSON:  Well, you know, Leo, we're not going to have you for three weeks.  Tom Merritt and I are going to be doing the next three Security Now! episodes.  So I thought we would leave on a high note, or a wound-up propeller note or something.  We tackled ECC, Elliptic Curve Crypto, two weeks ago, of course.  And I thought, while we're on the topic of esoteric encryption, we ought to take a look at where the crypto world is today.  Everything we've always been talking about is kind of - it's new for us, and it's in use now, but it's kind of old and dusty.  I mean, all this stuff is like, you know, the RSA patents expired a few years ago, so they're 20 years ago.  And even the just-chosen SHA-3 secure hash algorithm, that competition began eight years ago, in 2004.  So what's going on right now?  And one of the things going on right now, one of the things that cryptographers are actively working on is something called "homomorphic encryption."



LEO:  Okay.



STEVE:  Or "fully homomorphic encryption."  And I'll just, before we get into our top-of-the-show stuff, I'll just - I can explain what it is, that is, and what it accomplishes.  And it'll just, like, bend our brains.



LEO:  Yeah.



STEVE:  It is possible; it has now been shown.  It was hypothesized by the RSA guys back in '78, shortly after they came up with the whole "factoring is hard" public key encryption technology.  They posited the possibility of this, the possibility of homomorphic encryption.  But it was an open question.  And just three years ago a grad student stunned the world by doing it.  And what he did was mathematically demonstrated that it is possible to perform operations like standard computing operations - addition, multiplication and so forth - on encrypted data without first decrypting it.  So you encrypt data...



LEO:  Wait, wait, wait, say that again.



STEVE:  I know.  It's amazing.



LEO:  But what?



STEVE:  So, for example, you could encrypt data, send it to the cloud, have work done on it, never decrypting it.  The cloud has no idea what it's doing.  I mean, it knows what the processing is it's doing, but it never sees any result.  No intermediate results.  The all of everything stays encrypted the whole time.  You get your result back encrypted, and only you are able to decrypt the result.  And this works.  So that's the topic of today's podcast.



LEO:  That's exciting.  I don't understand how it could possibly work.  But we'll have to figure it out.



STEVE:  It's extremely cool.



LEO:  And I know we'll find out.



STEVE:  Yes.



LEO:  I was right.  Propeller hats at the ready.



STEVE:  Oh, boy.



LEO:  Oh, boy.



STEVE:  And that may be your costume for today's Halloween podcast.



LEO:  I should point out neither Steve nor I are wearing Halloween costumes.  I wore a trench coat in.  But it's because it's going to rain.  It's a raincoat.  It's not - I'm not - I should have just said, oh, yeah, I'm Inspector Gadget.  There, Steve's got his TWiT fez on.  That's a good costume.  No propeller on it, however.  Nice tassel.  Our show - no, you follow the - you're like a kitty cat.  You can't - a dog chasing its own tail.



STEVE:  It's a homomorphic tassel.



LEO:  All right, Steve Gibson.  We have a little bit, not a lot, but a little bit of technology/security news before we get to homomorphic crypto.



STEVE:  I scrounged around looking for interesting things that happened.



LEO:  Quiet week.



STEVE:  And, yeah, the only thing I could find that I thought would be interesting is in our ongoing following of the infamous Do Not Track header that we've talked about for a couple years now.



LEO:  Yeah.  And the last I heard, Microsoft is still saying IE10 is going to turn it on by default, which means Apache will ignore it.



STEVE:  Yeah, in fact, IE10, I guess, already happened.



LEO:  Yeah.  We have it.



STEVE:  And it did not get pulled at the last minute.  So not only Apache, but now Yahoo! has formally stated that they intend to ignore it.  Their term for it is "signal abuse."



LEO:  Oh, wow.



STEVE:  Since the W3C Consortium said that it is to be off unless users turn it on, Microsoft, feeling that users would turn it on if they understood what was going on, have it on unless users turn it off.  And that's enough for Apache, as you said, and now we know Yahoo!, to say, okay, we're just going to ignore it.



LEO:  Apache maybe is a little controversial.  But Yahoo! is an advertising company, basically; right?



STEVE:  Yes, yes.



LEO:  So that's not too...



STEVE:  And what's interesting is that Microsoft is planning to make IE10 available for Windows 7, and they intend to still leave it set on unless it's turned off by the user at installation time.



LEO:  Wow.



STEVE:  So this will be an evolving story.  I'm proud of Microsoft.  I don't say that.  Have I ever said that?  I don't think so.



LEO:  Wow.  What?



STEVE:  They never do anything that I think they should, when they should.  And they've, like, I'm really impressed.  This is great.



LEO:  You're impressed that they are turning it on.



STEVE:  Yes.



LEO:  But you're not impressed with Yahoo! or Apache for ignoring it.



STEVE:  Not at all.  I think they're on the losing side.  I think this will be a skirmish for a while.  It will end up being decided in favor of the user, which is obey DNT, and IE may get a reputation for being more private because it's got this turned on by default.  And maybe other browsers will follow suit.  I mean, we'll have to see how this happens.  It is, for me, sort of an interesting little political sidebar on the whole "how our security industry is evolving" story.



I'm under embargo for some news that I cannot talk about until next week's podcast.  I will say only, I can say only that there will be a significant update to one of our favorite TNO, Trust No One, cloud storage offerings that I will be able to share with our listeners, and I'm excited about it, a week from now.  And that's all I could find that was...



LEO:  And there's the news.



STEVE:  And there you have it.  Sorry about your commute, listeners.  



LEO:  Well, we're going to get to homomorphic crypto.  And if you are driving the car, some of you, you will find this stimulating, and we'll wake you up.  Others you might want to hold off until you get home.  That's all I'm going to say.



STEVE:  I actually think this is going to be good.  I did want to thank a number of people who said, hey, Steve - this is over the last couple weeks - what happened to the blinking lights behind you?  Because...



LEO:  Wait a minute.  They're gone?





STEVE:  They are, again.  But they haven't been for a couple weeks.



LEO:  Oh, I didn't notice.



STEVE:  And I realized, well, we'd had a brief power outage a few weeks ago, and all three of those little PDP-8s just came to a standstill.  And I'm so used to them blinking that, when they weren't, I didn't notice it.  But people were looking at the video going, hey, the lights have stopped.  And so it was when they said, "What's going on?" I said, oh, that's true, and I started them up again.



And I just didn't want to - I wanted to do a shout-out about the TV series on Showtime, "Homeland."



LEO:  Oh.  I haven't watched it yet.  Is it good?



STEVE:  Oh, my god.



LEO:  Now, the premise of this is what?



STEVE:  Okay.  We're in the second season.



LEO:  This is like Manchurian candidate, kind of; right?



STEVE:  We're about four - yes.  We're about four weeks in.  But last Sunday night's acting - Claire Danes is one of the leads.  And some other random guy who we've never seen before, but he's good, it was an interrogation, pretty much, for most of the hour.  But knowing all the back story and all of what was going on and very complex characters that have been painstakingly created, I mean, and she deserves awards, I think, for the job she's doing.  Anyway, you can get the disks or find it or borrow it or something for the first season.  You really do need to catch up.  But it is just - I don't know where it's going to go.  But it has been a season and a third of real fun.  I mean, just...



LEO:  No spoilers now.  No spoilers.



STEVE:  No.  I'm not.  I don't do that.



LEO:  No, no.



STEVE:  It is really, I think...



LEO:  Because I haven't watched any of it.  But so I should start at the beginning with season one.



STEVE:  Oh, you have to.  Have to start at the beginning, get the first season.  You'll absolutely be hooked.  And this second season is every bit as interesting.  And I have to say, after the first season ended, it's like, okay, now what are they going to do?  And it is certainly the case that a concept can outlive its production.  We saw, for example, "Galactica" went off the rails, like in about season 4 or something, or 3.



LEO:  It's hard.  Four seasons is hard for any show.  Even "West Wing" kind of went downhill after four seasons.  It's hard.



STEVE:  Yeah.  Then you have the flipside, where like "Firefly" gets canceled before even the ones they've produced have been aired.



LEO:  [Growling]



STEVE:  Okay, yeah.



LEO:  So I'm looking, and "Homeland" is not on Netflix.  Let me see if it is - Instant Video, Amazon Instant Video has it.



STEVE:  Oh, good.



LEO:  Or you can buy a DVD.  But I'll just screen it on Amazon.



STEVE:  It's really, really, really worthwhile.



LEO:  All right.  I'm going to watch it.  I'm going to start tonight.



STEVE:  You'll get sucked in.  It is, I'll just say, and this is not any spoiler, she works for the CIA.  She's a field agent with expertise in the Middle East.  And she is also, and this is not a spoiler, she is bipolar, medicated, but secretly because she could never work for the CIA if they knew.



LEO:  Oh, that's interesting.  How interesting.



STEVE:  Oh, and she's playing her character so well.  I mean, it's just - it's really good.  So for what it's worth, if anybody has some time to kill, or likes...



LEO:  Damian Lewis always reminds me of Steve McQueen.  He has that pursed mouth, that Steve McQueen mouth.



STEVE:  Yes, yes.



LEO:  All right, Steve.  I'm ready for homomorphic...



STEVE:  We'll do that in a second because I wanted to share a fun story...



LEO:  Oh, yeah.



STEVE:  ...that I was sent by a listener, James V. in Northamptonshire, England, who caught my attention with a subject like "SpinRite produces the evidence."  Now, you can probably already guess what that's going to be about.  But the details are interesting.  He says, "Hi, Steve.  SpinRite saves the evidence.  Or, if you like, SpinRite catches the criminals.  We use a lot of standalone video recorders on our customers' sites."  He's with a security company in the U.K.  He said, "As you well know, this application treats hard drives very hard, as the 400 H264 images every second are constantly written to the drives."



LEO:  Wow.



STEVE:  400.



LEO:  400 a second.



STEVE:  Maybe he's got multiple cameras.  So anyway, he says, "So we get a call from a customer of ours saying that there's been an incident, and the police are wanting a copy of the images from our security camera system to permit them to investigate.  So an engineer is duly dispatched to the site.  No broadband access for security reasons."  Of course he's a Security Now! listener, so he understands, you just really can't connect, period.  And he says, "On arrival, I receive a worrying phone call from the engineer saying that the DVR is, quote, 'Hot enough to fry an egg on and doesn't work properly.'"



LEO:  That's not good.



STEVE:  "Oh, dear.  The machine is swapped out and brought back to the workshop where we confirm that the machine goes no further than the boot loader.  We poke, prod, and mess with the drive connections until we get the unit to boot.  But guess what.  The evidential images we need are on the drive we had to disconnect in order to get it to boot at all.  One conversation with our IT guy, and he suggests SpinRite.  Now, having listened to the Security Now! podcast, I know how SpinRite has saved the day and saved the pizza.  But can it save the CCTV?  The HDDs are formatted in some form of proprietary Linux configuration by the machine, which locks down the part of the disk used to make it unreadable out of the DVR, both under Linux and Windows.  So we were a little unsure, to say the least.



"The IT guy arrives, plugs the HDD [the hard drive] into a spare desktop and cranks up his copy of SpinRite.  The drive makes some strange sounds."  He says in parens, "(Bearings?)"  Then he says, "Next morning, the drive was a bit warm, and DynaStat had done some business.  I think it said it had recovered some sectors.  So we quit out of SpinRite before it had finished and remounted the drive.  Lo and behold, we could access the images, which were quickly exported to DVD.



"I understand that, thanks to the recovered imagery, the criminals were apprehended and had no choice but to plead guilty in court, both receiving custodial sentences.  The world is truly a safer place with SpinRite.  Without it, there would have been no evidence or conviction.  We also have upgraded maintenance contract with the customer which includes twice yearly HDD checks with, you guessed it, SpinRite.  I'll be purchasing a copy of SpinRite on behalf of our customer today, a bargain at around 60 of our GBP.



"Thank you for SpinRite, and also thank you and Leo and Tom for the great podcasts.  Proof now exists that you make the world a lot safer place.  James, Northamptonshire, England."



LEO:  Northamptonshire.



STEVE:  Shire.



LEO:  Shire.



STEVE:  Are you shire?



LEO:  I'm shire.



STEVE:  I'll bet you are.



LEO:  [Laughing] But you don't say "Worcestershire" sauce, do you?  You say "Worcestershire."



STEVE:  You're not going to be shire of anything after we get through with homomorphic...



LEO:  No, I'm ready to have my brain scrambled.



STEVE:  Okay.  When you're talking about homomorphic encryption, you run across sentences like "The decisional composite residuosity assumption is the intractability hypothesis upon which this cryptosystem is based."



LEO:  Absolutely.



STEVE:  I know.



LEO:  I couldn't agree more.



STEVE:  Put that on your T-shirt.



LEO:  You know, they could write that more clearly.  I think that's intentionally turgid.



STEVE:  [Laughing] Well, okay.  So RSA Lab's glossary definition says, of something called "probabilistic encryption" - this is something we've never talked about before.  Everything we've ever discussed has been deterministic encryption, meaning that, whether it's a symmetric cipher where, under the influence of a key, you put something in, and you get something different out, and there's a way to reverse that.  The idea is, every time you put the same thing in, you get the same thing out.



But early researchers in encryption a few decades ago were concerned that that weakened the system.  That is, if you always got out the same thing for what you put in, didn't that coupling create some weakness in the system.  So what was - and this is a couple decades' worth of work.  There was this notion of probabilistic encryption where your actual encryption algorithm would produce a different result every time you used it with the same data, so that it broke that deterministic aspect deliberately.  And so even if the same data was encrypted, you would get different results.



Now, we know, those of us who have been really paying attention will know that we've solved that problem in other means.  We have the notion of a cipher, like Rijndael, the AES cipher, or any other cipher.  But then what we've done is we've created these block chaining modes where we take a so-called initialization vector, an IV, and that is given a pseudorandom value which can be known.  It's okay if we know it.  In fact, often it's like the first, it's the start of the message, is here's the initialization vector under which we're going to encrypt this block.  And then you take that and mix that with your input, then encrypt it.  Then you take that encrypted output and mix that with the input of the next block and encrypt it.  In other words, you link these together sequentially to create a chain.



So that's the way we solve the problem, which truly was a problem in terms of information leakage because, if you encrypted the same thing and got the same result, then even if someone didn't know what the input was, if they inspected lots of outputs, they could see when things were the same and begin to draw conclusions.



LEO:  So this limits that problem.  But how is it reversible?  That's what I don't get.  Because you don't know - all right.  I'll let you explain.



STEVE:  You're right.  It is tricky.  Okay.  So a whole different approach is probabilistic encryption.  So the RSA Lab's glossary says, "Probabilistic encryption is a design approach for encryption where a message is encrypted into one of many possible ciphertexts, not just a single ciphertext as in deterministic encryption.  This is done in such a way that it is provably as hard to obtain partial information about the message from the ciphertext as it is to solve some hard problem.  In previous approaches to encryption, even though it was not always known whether one could obtain such partial information, it was not proved that one could not do so."



Now, okay.  What that meant is that, notice that in all of the crypto we've ever talked about, we've relied on an assumption.  That is, for example, it has never been proved that standard RSA public key crypto is safe.  It relies on the presumed difficulty of factoring large primes.  But no one's ever been able to prove that it's hard to factor large primes.  We just know it is.  But knowing something and proving it are worlds apart in terms of academic crypto technology.  So what we've done by stepping from the world of deterministic encryption with presumed security is we actually have provable security for the first time.  I mean, for the first time.  That's one of the things this gives us.



So what happened was, shortly after the original RSA guys invented this factoring-based asymmetric encryption, they noticed that there was a property that their approach had, this so-called "homomorphism."  And they wrote, a few months after developing RSA, about sort of this - they posed this question.  Now, homomorphism, look, if we just break the word down, "homo" and "morphic," that means same shape, essentially.  And the concept is that you can apply different processes to the same data and get the same result.  A simple example would be, for example, the way we know that we can multiply A and B to get a result we'll call C.  But we also know we can add the logarithms of A and B in order to get the logarithm of C.  And so those are homomorphic operations, that is, A times B equals C, and log A plus log B equals log C.



So what happened was this idea just sort of sat doing nothing until just three years ago.  And one of the cool things about this is now we're talking about state-of-the-art, leading-edge, bleeding-edge crypto, which has got everybody excited.  Just three years ago a doctoral candidate, a grad student at Stanford named Craig Gentry, wrote a PhD thesis.  And, boy, did he get his doctorate.  IBM Research snapped him up immediately.  So this was in 2009.  He stunned the crypto world by laying out a fully working, fully homomorphic crypto system.



So what that means is, as I said at the top of the show, is he demonstrated - and I'm going to explain enough of this, very much in the same way as I did two weeks ago with elliptic curve crypto, that we'll sort of have a conversational knowledge, sort of a conversational understanding of how this works.  I mean, we're not going to go write the code.  And, well, for lots of reasons.  There are many complexities to doing this.



But what Craig demonstrated in his doctoral thesis was that it was absolutely possible to perform addition and multiplication operations on encrypted data where, at every stage of the way, the data remained encrypted; the result was encrypted; and no one doing that work ever gained any information at all about the nature of the data they were doing the work on.  And when the answer then was returned to the person with the key, they were able to decrypt it.  And the result after decryption was exactly the same as if the same operations had been performed on the unencrypted data.



So this is huge for the future.  This allows - as I'm reading, like, people talking of dreaming about applications.  I mean, for example, corporations could sub out work on their data in the cloud, leaving it fully secured at all times, and have data processing done on the data with never having to trust, I mean, this takes TNO and squares it because they never have to trust anyone they hand their data to.  They can have it processed and returned.  There's actually - the cryptologists have designed search engines where your query is never known to the search engine.  The search engine doesn't know what results it finds for you, yet it sends them back.  And you then are able to decrypt them and get the results of your query with total privacy.  And the really interesting applications are in the utterly tamper-proof electronic voting sphere, where it is possible to get anonymity and absolute tamper-proofing in a homomorphic encryption setting.



So as a consequence of the fact that this is sort of on the leading edge of what's going on, and that I wouldn't be at all surprised if we start hearing more about this in the future, I thought that now would be a good time to bring everyone, sort of give everyone a sense for how this works.



So we need to step back and create some analogies that I will then use to move us forward.  Back in the early days of computing, before digital computers, we had analog computers.  And they were patch boards of analog functions.  Like you could have an adder, where you'd have, like, two voltages or two currents, depending upon whether this thing worked on voltage, whether it considered voltage to be the thing that carried the value, or the current carried the value, but whichever.  It would take two of those and sum them and then produce an output that was equal to the sum of the two input values.  And you could have a divider where you would put in the two values to be divided, and you would get the result from that.  You could integrate.  You could basically perform all the standard operations we're familiar with in an analog environment.



Now, one of the problems, if you patch together a really sophisticated equation, which is what early analog computer pioneers did, one of the problems is that you would accumulate errors because, as your inputs moved through more of these stages, each stage introduced some error.  Could be really, really small, but still it was non-zero.  Just due to, for example, temperature in the room could cause some drift in the amplification of the adder, or even though they'd worked to trim the component tolerances to be exact, the two inputs to the adder might not have exactly the same signal strength in effecting the output.



So, well, and even simple components like resistors, capacitors, transistors and, back in the day, tubes, there was something in tubes called "thermionic noise."  But just thermal noise, just actual noise from the physical electron movement in the devices introduced some errors and noise.  So the problem was this was additive as the signal moved through a patch board of these modules, additions and multiplications and integrations and divisions and so forth.  And so there was a limit to how much computing you could do before you had a problem with the famous signal-to-noise ratio, that is, the signal being the actual result and the noise being the uncertainty created by the fact that this was all sort of the best we could do, but not certain.



And in fact it is arguably the fact that digital systems don't have any of this problem which has allowed digital technology to take off the way it has.  As we know, in a digital system, as compared to an analog system, in an analog system we've got a continuously varying voltage.  In a digital system we decide instead we're going to tolerate some imprecision in the exact specification of a value.  That's known as quantization.  In return, though, we're going to get absolutely noise-free processing.  Noise cannot creep in because at every stage we're dealing with either, famously, a one or a zero.  And each stage of our system sort of reasserts the one-ness or the zero-ness so that even values that are not quite one or zero, when they're being put in, they come out strongly one or zero on the output.



So, okay.  So I wanted to kind of create that picture in everyone's mind of a network of processes that are a little noisy, and the depth of the network that you can create is limited because at some point too much noise accumulates.  Because, bizarre as it sounds, this bears directly on probabilistic encryption.



Imagine a simple cipher, a simple encryption where you have a single dimension.  Think of it maybe like a rope with knots along it.  And these nodes, or knots, represent values that are well understood because of their position.  And that the act of encrypting is choosing a node along this line and then deliberately adding some noise.  That is, shifting the location a pseudorandom amount away from the proper location.  So we deliberately add some noise to the location that we're choosing for a value.



Now, the key in this system, the cryptographic key, determines where these nodes are located.  They're not all uniformly positioned.  There is a complex calculation for where these nodes are located so that only somebody with the key knows where the nodes are.  Now, we have this notion already of addition from, like, you take two values, and you sum them.  So imagine that we take, we create two of these quantities with some noise, and we add them together to get, like, on this timeline, on this linear scale, to get their sum.  Well, that's going to fall somewhere.  And notice that the noise that we added to each of the terms being summed, the noise sums, as well.  So that our final position will be a function of both of the input terms and both of the noise terms, the pseudorandom sort of fudge factors, the noise that was deliberately put in.



Well, as long as that's not too much, as long as there's not too much noise, our sum lands on this scale.  And if this is sufficiently large, and we have a sufficiently large resolution, then that result doesn't mean anything to the person carrying out that operation.  That is, all they know is they received a couple values, and they added them, but there's no meaning to it because the meaning is a function of where it falls relative to the nodes, sort of the location markers on that scale.  And that is only known to the person holding the key.



So you sort of see how it's possible to, by deliberately adding noise and having a scale which is not known to the person doing the work, but which is known to the person receiving the answer, that it's possible to sort of subcontract the work of doing the addition.  And the person doing it knows they've added a couple numbers, but they don't know anything about the actual underlying data.  Well, that's a 10,000-foot sort of sense for how this probabilistic encryption operates.



The actual work that is done is not done on a one-dimensional line, or even a two-dimensional plane, or even a three-dimensional space.  It's actually done in abstract algebra called a "lattice."  And these are N-dimensional interconnected spaces where the dimensions are, like, 512 dimensions, or 2048 dimensions, or larger.  So they're something you can - we can visualize a cube in three dimensions, and you can envision, okay, like in four-space you'd have families or sets of cubes at the different - in a series of node locations and so forth.  So mathematically you can represent this, even though it's arguably rather difficult to visualize it.



And so the way these systems actually work in these lattices is that the work being done is moving a point through this hyper-dimensional lattice with noise so that the processes that are available are addition and multiplication, although it's been shown that we can do anything that we want to with just those two operations.  So that's, from a theoretical math standpoint, that's sufficient.  And the problem is that this system that I've described so far is homomorphic in that it satisfies that criteria.  But the problem is this noise accumulation because, as you do operations on data that is deliberately noisy, as I said in the case of addition, you are doubling the noise when you add two factors together.  In multiplication, you are squaring the noise when you multiply two factors together.  So noise gets out of hand very quickly, and very much in the same way as with an analog computer, where you can only go so many stages, and the noise begins to overwhelm the signal.



The way this system works is, once we're done processing, and we're at some location in this hyper-dimensional lattice, the answer, that is, the actual decrypted result, is the node we are closest to.  And so you can see that - and that's going to - and so our movement through this N-dimensional space has been deliberately noisy to obscure any actual values.  And we need to then determine which final node in this 8,000-dimensional lattice we're physically closest to.  So the point is that, as we do these processes, the noise accumulates, and that limits how much work we can do.



Well, a fully homomorphic system has no limits.  That is, by definition, the definition of a fully homomorphic encryption system is one where you can perform any operation, that is, of arbitrary complexity.  And this is Craig's invention.  I mean, this amazing insight he had was he said, wait a minute, is it possible to perform a reencryption of the data in this process?  That is, essentially, can this homomorphic encryption perform its own encryption?  Because, if it can, that is, if there's time to perform this encryption without its own noise overwhelming it, then it's essentially able to reencrypt the data and zero out the noise.  And initially he was unable to do it.



But by using much larger word lengths and a more complex topology, he was able to trade that off for the number of operations needed such that he was able to perform a reencryption of the data itself without noise getting in the way.  And as soon as he was able to do that, he had a fully homomorphic encryption system that can perform any operation that we know of in computation while keeping the data encrypted, and never allowing this noise to get out of control because, after some number of steps, then essentially the data is reencrypted, never returning it to plaintext, but sort of re-zeroing out the noise so that it never overwhelms the system.



And, now, to give some sense for why we're a ways away, his fully homomorphic encryption - he has four classes of system sizes.  First of all, I should say that IBM Research snatched him up, and he's continuing to work on this.  It's been three years since his paper was published.  After it published, it shocked the crypto world and got everybody excited because they didn't know what they were going to do for their summer.  And they began playing with this.  So there have been lots of variations, lots of ideas.  I mean, basically this is an active area of current crypto research.



So at IBM he has built one.  He has implemented this.  And he was originally thinking that he would use one of the IBM crazy Watson hyper-computer deals.  Turns out they were able to implement this on a much more modest system.  He has four sort of scales of the system.  He has a toy system which is - he calls it 2^9, which is to say, it is a 512-dimension lattice.  A small one is 2^11.  A medium one is 2^13, and a large one is 2^15.  And that being, you know, beginning to be practical security.



But to give you a sense for why we're a ways away is implementing this system on standard technology computers, and this is why I'm not worried about it in the long term, we're going to fix our computers, if we're interested in this, to do it.  But, for example, the somewhat homomorphic encryption system, not the fully, but the somewhat, just in the toy implementation, using a 512-dimension lattice requires a bit length for its processing of 200,000 bits.  So incredibly long word lengths.  The public key used in the fully homomorphic encryption system is 17MB in size, and it takes 2.4 seconds to generate the public key using the fastest available standard machines.  The large size fully homomorphic encryption system, that is, the one that is 2^15, which is 32768-dimensional lattice, requires two hours just to generate the key, which is 2.3GB in size.



So what we have is an entirely different way of encrypting and treating data.  And it has almost none of the characteristics we're used to thinking about when we talk about standard deterministic crypto, whether it's symmetric or asymmetric encryption.  Its process is just not suited for the way our current standard computers are structured, with 64-bit word lengths.  These things need, actually this somewhat homomorphic encryption of the large size, 2^15, uses a 13 million bit integer to do its work.  So we need a completely different technology of computing in order to work with this.



The feeling is, this has a huge future.  We're at the beginning of it.  And as cryptography always does, it will get faster.  It will get better.  People will come up with shortcuts.  They'll come up with other ways to do things.  This notion of noise in a lattice is only one of a number of nondeterministic encryption schemes that have been proposed.  There are some others.  There are some that use greatest common divisors.  There are some that use large families of simultaneous equations where some statistical probability of individual equations being incorrect is, like, is a hard problem to solve.  And so there are, like, very different approaches that are being explored.



I'm excited because this opens up something, like, completely new in the field of crypto research.  And behind it will be tomorrow's applications that will work in a way which is completely foreign to the way we're used to thinking of things.  And one can imagine, 20, 30 years from now, people will say, well, wasn't crypto always done this way?  And it's like, uh, no.  What we used to have was really stupid by comparison.



LEO:  [Laughing] Big improvement.



STEVE:  Yes.



LEO:  All right.  I understood zero of what you said.  But I trust that it all made perfect sense.



STEVE:  Well, the idea is that there is...



LEO:  What's the executive summary for Leo?



STEVE:  [Laughing] It's that, if - let's see.  If your data has noise, and you know how much noise it has, and you want to operate on it, as long as you don't do too much, then the noise doesn't overwhelm the signal.  And then you can remove the noise.  And that's useful because you can give the noisy data to somebody else, have them do the work, and, because it's noisy, they don't get any information from it.  Yet the work they do is useful to you because you know how to extract the noise from the signal.  Or, wait, the signal from the noise.  So there's the even more condensed version.



LEO:  Good [laughing].



STEVE:  And my goal here...



LEO:  I'm trying to decide whether to pretend I understood that or just go, no, I...



STEVE:  My goal here, as with elliptic curve crypto, is not to turn us into homomorphic crypto people, but just so that - I'll bet you...



LEO:  No, it's good.



STEVE:  ...a year from now it'll come around, and someone will say, oh, yeah, Google just added homomorphic encryption.  It's like, oh, well, we know what that is.  That's Podcast 376 on Halloween of 2012.  Go back and listen to it.  And you still won't know what it is.



LEO:  Hey, did you have an opinion - we talked a lot about it during the week, and I think there's probably not much to say about the hack of, what was it, three million-plus Social Security numbers in South Carolina?



STEVE:  Yeah, I saw that.



LEO:  Yeah, I mean, there's nothing much to say.  They decided not to encrypt the data.



STEVE:  Yeah.  It's unbelievable.



LEO:  And the rationale was, well, you know, it's hard [laughing].



STEVE:  Yeah, well, it wasn't encrypted yesterday, and it was just fine.



LEO:  Yeah.  So we didn't need to...



STEVE:  And it's still not encrypted today, and we assume it'll be fine.  Well, that assumption got broken.



LEO:  And then, of course, they go on and on about how sophisticated the international hacker - I love the - the international hacker was who - amazing what the skills this person showed to get - to steal our data.  Oh, well.  There's nothing much to say.



STEVE:  Some secretary clicked on a link.  I mean, that's what brought RSA down was some administrative assistant clicked a link in email, and that was the entre into the RSA network that allowed them to steal all the private keys.



LEO:  Yeah.  I guess the only silver lining is I would hope that CTOs in every other state are looking at South Carolina and going, god, I hope that doesn't happen to us.  Maybe we'd better encrypt our data.  But I feel so sorry for the three million South Carolinians who now their - now, some encryption was done apparently on the credit cards that they used to pay their taxes.  But none on the Social Security number and personal information.  So they're giving each and every one of them a year's free...



STEVE:  Credit report.



LEO:  ...credit report [laughing].



STEVE:  Which is, you know, that's nice.  But identity theft, boy, I'm sure you've heard the horror stories, Leo, about how difficult it is to get back your identity once it's been stolen.



LEO:  Well, and the governor of North Carolina said that she, in fact, she and her husband have suffered identify fraud, and it was a very painful thing, and she knows how we feel.  So that makes me feel better.



STEVE:  I wonder if they would have a philosophical objection to homomorphic encryption in South Carolina.



LEO:  I don't know what it is.  But, look, God did not intend for probabilistic encryption solutions.  It's clearly written that deterministic solutions are the only approved stand.



STEVE:  And you know, Leo, if we had done this on April 1st, no one would have believed this podcast.  They would have thought, Steve, that is the best darn...



LEO:  What a fake.



STEVE:  ...April Fool's Security Now! podcast we have ever heard of.



LEO:  Oh, lordy, lordy.



STEVE:  Right down to the name.  They'd go, how did you come up with that?



LEO:  Come on, you made that up, didn't you.



STEVE:  Oh, god.



LEO:  Steve Gibson's at GRC.com.  That's his website.  That's where you can get SpinRite, the world's best hard drive maintenance and recovery utility.  You can also get lots of free stuff there, all sorts of information, not the least of which is health information.  If you go to GRC.com/health, you'll find links there to all the books and to our most recent Sugar Hill episode.  We did a third episode on Sunday.  That's also a TWiT Special, I think No. 143.  But I'm sure you have a link on the website there, as well.  And 16Kb versions of this show.  It's for the people who are bandwidth-impaired.  Transcripts, too, which makes it, for a show like this, kind of important.  You can go over it line by line.



STEVE:  You can line your birdcage with it.



LEO:  No.  I think in fact this would be a great exercise for people who want to strengthen their brains.



STEVE:  It will be an exercise for Elaine, that's for sure.



LEO:  Elaine's going, ohhhh.  You can follow Steve on Twitter, @SGgrc.  And, well, we do this show every - I won't be here next Wednesday.  But normally every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time.  That is going to be 1900 UTC next Wednesday because we go off summer time.



STEVE:  Yay, we fall back.



LEO:  Yup, 1900 UTC.  However, Tom Merritt will be hosting for the next few weeks as I head Down Under for a cruise, a geek cruise.  So I won't see you till after Thanksgiving.  Have a great Thanksgiving.



STEVE:  Will do.  Yourself, too, my friend.  Have a great trip.



LEO:  See you in December.



STEVE:  And we'll talk to you in four weeks.



LEO:  See you in December, Steve.  See you in - is that weird, or what?



STEVE:  It is.



LEO:  See you in December on Security Now!.



Copyright (c) 2012 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




