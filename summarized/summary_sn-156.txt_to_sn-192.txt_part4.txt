GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#156

DATE:		August 7, 2008

TITLE:		Listener Feedback Q&A #47

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-156.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 156 for August 7, 2008:  Listener Feedback #47.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, everybody's favorite show about protecting yourself online with our security guru, Mr. Steve Gibson from Irvine, California.  Shaky Irvine, California.



STEVE GIBSON:  Well, yes.  The earth is not moving at the moment.  So that's a good thing.



LEO:  It was, you know, I was watching you on video.  We didn't have the ability to broadcast the video because of some technical issues last week.  And you were shaking around pretty darn good.  I mean, it looked like the Starship Enterprise when they hit an asteroid belt.



STEVE:  It was serious.  In California, especially Southern California, we're sort of accommodated to earthquakes.  It's not such a big deal.  I know that I've talked to people sometimes - we haven't had a lot of earthquakes for a long time, too.  But I'll talk to somebody who's, like, from the Midwest, where the ground is a lot more stable.  And they just...



LEO:  It freaks them out.



STEVE:  They experience, yeah, exactly, they experience one, they're like, okay, I'm moving home.  This is wrong.



LEO:  But we don't have tornadoes, hurricanes.  You know, there's always something.  And Mother Nature never lets you get scot-free.  And those of us who live in California and have been through a few of them, we're just, you know, it's just - you were very - I was so impressed.  In fact, that's why I left it in the show instead of editing it out because, you know, oh, we're having an earthquake.  You rode it out and said, okay, let's get going.  You didn't pause a beat.  It's very impressive.



STEVE:  Ah, well, been through a few.



LEO:  We've got a Q&A show.  And it was apparently - they called it a moderate quake.  It was 5.8, but it wasn't...



STEVE:  Well, the thing that was the saving grace, apparently, is that it was a much deeper quake than normal.  It was five-plus miles down instead of being up near the surface.  And if it was near the surface, even that size a quake on the Richter scale would have been a serious event.  But being down that deep it smoothed it out a lot so it wasn't as sharp as it would have been had it been much nearer to the surface.  So that's a good thing.



LEO:  Yeah, thank goodness, yeah.  And as you pointed out last week, it's great to release that tension.



STEVE:  Got to have a tension release every so often.



LEO:  Every once in a while, as we all know.



STEVE:  Keep us all sane.



LEO:  We're going to do a Q&A session.  We've got some great questions from listeners around the world, as usual.  Any news in the tech - there was a big security flaw, wasn't there, Steve.



STEVE:  Yeah.  The big - it's been a relatively calm week, thank goodness, because this DNS problem that we discussed in detail last week has really been causing problems.  There are still a large number, as of this day - we're recording this on the first day of August.  More than half of the servers being tested by the various testing facilities are turning up still vulnerable.  And...



LEO:  Wow.  More than half?



STEVE:  More than half.  A little - it's 53, I think, 53 percent was what I was seeing.



LEO:  That doesn't seem right.  Holy cow.



STEVE:  Well, and what's going to happen is the problem is there are just so many DNS servers.  And there are arguably some that are - they're not going to be big targets, but they're important targets.  And so I think we're going to see the major ISPs will be under so much pressure to fix this that they're just - they're going to have to do it.  But there's been a lot of reluctance shown.  It's like, oh, well, do we really have to do this?  And the good news is that consumers who are able to see that the DNS they're using can be too easily spoofed are really raising a ruckus.  On last week's show notes, that is, the show notes for Episode 155, I've got three links now to three testing facilities that are available.  And I'm working on my own.  By the time we record our next episode I imagine GRC's DNS spoofing tester will be online.



LEO:  Oh, neat.



STEVE:  It'll be another facility, very much like ShieldsUP!.  I'm going to do a whole bunch of really cool stuff that nobody else is doing.  So I'll be certainly telling our listeners about that as soon as it's online.  And I just figure this is a big problem.  DNS spoofing is a problem.  This has raised sort of the - it's put back in play the whole problem of spoofing.  As we know, these problems have been there for a long time but just haven't been given much attention.  So this focuses the attention.



And one of the problems that people are discovering is that NAT routers, which so many DNS servers are behind, are derandomizing their random ports.  So even when you apply the DNS patch, if you're behind some sort of network appliance which is not allowing the random outgoing port assignment to survive NAT translation, you lose the randomness.  So that's creating some new opportunities.  So it's turning out to be a problem.  But what I wanted to tell people was if anybody is using the RealPlayer, any RealPlayer version prior to 11, some serious security vulnerabilities have recently been addressed and discovered in earlier versions.  So absolutely make sure that you update your RealPlayer to version 11.  That's really the only new news of the week.  Also an interesting issue with DNS spoofing relative to testing sites arose because people realized, wait a minute, if sites can be spoofed, and my DNS server can be spoofed, then how do I know that I'm going to a real DNS testing site through...



LEO:  Oh, that's a good question.



STEVE:  ...through my spoofed DNS?



LEO:  Right.



STEVE:  Because one of the first things you would expect bad guys to do, or something they could certainly do, would be to set up a fake testing site to say, oh, don't worry, your DNS is...



LEO:  No problem.



STEVE:  No problem.  Your DNS is fine.



LEO:  It's working great.  You're safe.  You're fine.  Don't worry.



STEVE:  And the point is, I mean, it's a perfect example of a real security issue because if your DNS has been spoofed, then you can't trust the lookup.  And if you can't trust the lookup, and you're using a domain name to get to the testing site, then you don't know that you've really done that.  So there is an IP address for the OARC site.  The IP address is 149 - actually they made this URL easy to access.  It's just the IP address 149.20.3.33/test.



LEO:  So if you use the SnipURL, for instance, if you used any English language domain name, that could be spoofed.  But if you enter in the IP address directly...



STEVE:  Then nothing in your system is going to your DNS server.  It's directly connecting to that IP address.



LEO:  The browser says I don't need an IP address.  You just gave me one.  Fine.  In fact, that's a fast way to go to any site, if you know the address.  But the problem is that's why they did this thing because nobody remembers those dotted quads.



STEVE:  Right.  And in fact what I'm going to do is I'm going to take people back to a dotted quad when they come to GRC.com, if they're going to run the test, just to sort of - so that if they copy the link and share the link, if they write it down, if they make a shortcut, it'll automatically be giving them the IP address just as an extra level of confidence that they're able to know that they're really at GRC.  And I'm going to run it over a secure connection.  So again, they'll have that, as well.



LEO:  So having that certificate really also gives you some reassurance.  But you can't...



STEVE:  I can't use the certificate with the IP address, though.  So it's going to have to be one or the other because the certificate is the domain name.  And the domain name wouldn't be in the browser, it'd be the IP address.  And who knows what random firewall, I mean, ZoneAlarm has gone so hyperreactive now, it might block you from using an IP address.  I mean, they've just really gone overboard.  So but it'll be available, and it'll be a suggestion for somebody who wants to absolutely know they're actually talking to GRC, and they haven't been spoofed.



LEO:  I noticed when I enter the IP address that it does resolve to a name.  So maybe the certificate would work at that point.



STEVE:  Ah, so in their case they're, yes, so they're seeing it come in.  And also is it an HTTPS?  Because I think OARC is running over SSL.



LEO:  It's not actually.  It's just an HTTP.  And then you get a very long, what looks like a hash number, followed by et.dns-oarc.net.  So I don't know what they're doing there.  Maybe that hash is of some security significance.



STEVE:  Well, I just figured that, since DNS spoofing is an issue - I delayed getting involved in doing my own for a while.  I mean, I'm deep in the middle of dealing - of wrapping up this third-party cookie thing.  But it's like, well, it would just be good to always have it there.  And who knows, someone, an ISP might fall back and regress and stop port randomization, and no one would know it.  So one of the things that GRC is doing, I'm becoming a little proactive about this.  I'll be testing DNS spoofability all the time for everyone who comes and notifying anybody if their DNS server...



LEO:  Oh, that's nice.



STEVE:  Yeah.  So it'll just be happening in the background and transparent.  And I'll be doing the same thing with third-party cookies, just to let people know, yup, they're still turned off.  So...



LEO:  It's funny, it tests - apparently because I'm using OpenDNS I have, you know, my DNS goes through OpenDNS.  But it could still see that I'm on Comcast.  So it tests my Comcast DNS servers as well as my OpenDNS servers.  OpenDNS, great.  Comcast still poor in the source port randomness.  But the transaction ID randomness is great.  What does that mean?



STEVE:  Well, so with source port randomness, it says "poor," I'm really - I'm a little annoyed with that test because you can't get a worse rating than poor, even if all the queries come from a static port.  It ought to say "horrible" if you've got it all coming from one port.  So how many different ports did it come from in that test?



LEO:  Unique ports 24.



STEVE:  Okay.



LEO:  And the range, let's see, number of samples, 25; unique ports, 24.  They're not sequential.  The scatter plot looks pretty random.  So I'm not sure exactly what they're seeing here.



STEVE:  Right.  And so it'll also show you how many bits of entropy is available.



LEO:  Bits of randomness only 10, and maybe that's why it's saying "poor."



STEVE:  Yeah, that's definitely why.  And so it sounds like something is going on.  And this may be - this is a perfect example of what a lot of ISPs are still putting out is they're not super random ports.  They're within a restricted range.  And that's generally indicative of some sort of post-DNS server processing that's limiting the randomness of the outgoing port.  And who knows how...



LEO:  And they're doing some sort of weird stuff in there in addition to the DNS?



STEVE:  Probably, yes.



LEO:  Yeah, okay.



STEVE:  Yeah, because if they - I mean, if they had applied the full patch, they would be generating ports over the entire 65536 or 65535 port range.



LEO:  Oh, I see.  It's definitely not.  It's 16916 through 17815.



STEVE:  Right.  So it's within a restricted range.  And of course what that means is an attacker can see what range you're currently generating.  And while it's not as easy as if you had a static port, it certainly restricts the guessing and hugely improves their opportunity for penetration.



LEO:  Yeah, well, that's too bad.  Nice try, Comcast.



STEVE:  Yeah.  Well, again, we need their customers to know what's going on in order to put pressure on them to get this fixed.  I also mentioned last week that I believed that the DD-WRT version of firmware was vulnerable, and it's confirmed it is, and there is a patch.  So I wanted to let anybody who has been, like, flashing their routers and is running DD-WRT, I'm sure if that someone, you know who you are, that there is an update to solve this problem for individual end-user routers.  Again, I don't think it's a huge issue because I would be surprised if end users would be targets.  It makes much more sense to attack an ISP and thereby spoof everybody who uses that ISP's DNS server.  But there are certainly - you could imagine situations where this kind of tool becomes readily available, where individuals could get targeted when they upset somebody in a blog or in an online forum or something.



LEO:  Yeah, yeah.



STEVE:  We've seen lots of little, in the past, DoS attacks on individuals.  So you could certainly imagine individualized spoofing attacks aimed at just a single person for one particular reason.



LEO:  You know what's a real problem is IRC chat because it's pretty easy to figure out what somebody's IP address is in IRC.



STEVE:  Right.



LEO:  That's usually published.  And of course that's where people get in flame wars all the time.  And it's where all the script kiddies hang out.  So it's really kind of a perfect storm of evilness.



Hey, I want to read a poem that you sent me that is just really cute.  Well, I don't know if you can hear it, Steve.  The lawn blower brigade has decided to camp outside my window.  I hope that's not bugging you.



STEVE:  No, it's quiet at this end.



LEO:  They show up at this hour of the morning every morning.  Or not every morning, every week.  And they stand outside my window.  And I think they do a little kind of precision routine.  They march in and out.  Oh, it's just amazing.  However, a little noisy.  So I just want to warn you.  But let me read this.  This is from a blog called Rational Survivability, a guy named Hoff.



STEVE:  He did a really good job with this.



LEO:  Christofer Hoff wrote this.  It's called "The DNS Debacle in Poetic Review."  I'm going to put on my Orson Welles voice for this one:



"A few months ago

Kaminsky discovered a flaw.

It was with DNS,

It was nasty and raw"



Actually maybe I should have used the Dr. Seuss voice here.  Now can you hear them?  Here they come.



STEVE:  Now I - there they come.



LEO:  I apologize.



STEVE:  We'll just cover it up with the poem.



LEO:  I'll talk really loudly.



"He decided than rather

to disclose all at once

he'd instead only tell people

who'd fix it in months



So some meetings were had

and work soon began

vendors wrote patches

coordinated by Dan



Fast forward some time

out the closet it came

some researcher types

got into the game



Dan's rules were quite simple,

that in 30 days

he'd present during Blackhat

and we'll all be amazed



A bunch of big egos 

called Dan on a bluff

said his vuln was a copy

of 10 year old stuff



So Dan swore them on handshakes

and details were provided

and those same cocky claims

soon all but subsided



It seems that Dan's warnings

weren't baseless at all

Said the same skeptical hackers

'the risk isn't that small!'



So Blackhat was nearing

the web didn't break

then out came a theory

from our friend Halvar Flake



No sooner had he posted

and described the vuln's guts

than Matasano's blog surfaced,

kicked the web in the nuts



It said 'Halvar's right!'

we'll no longer keep quiet.

The post's ripple effect

caused a nasty 'net riot



The blog quickly was pulled

but the cat's out of the bag

the arms race began

since there's no longer a gag



Meanwhile the issues

of honor and trust

rehashed the debate 

of when disclosure goes bust



So Dan's days of thirty

we never did see

thirteen is OK 

but I issue this plea



When researchers consider 

how to disclose and thus when

will you think of the users?

How it might affect them?



This ego-fueled rush

to put your name on a vuln

has a much bigger impact

than you might have known



If the point here is really

to secure and protect

then consider what image

you really project



In this case the vuln.

is now in the wild

an exploit is coming

DNS soon defiled



The arms race has started

and the clock now is ticking

If you haven't yet patched

you'll soon take a licking



I'm not taking sides really

on the disclosure debate

but rather the topic

of patch early or late



What good is disclosure

if the world couldn't cope

with the resultant attacks

if we've all got just hope?



There's two sides to this issue

both deserve merit 

but Dan's rep has been smeared

I say let's just clear it"



That's Christofer Hoff.  What a great poem.



STEVE:  Isn't that perfect?  This is wonderful.



LEO:  And so is vuln, v-u-l-n, obviously short for vulnerability, I guess that must be what researchers use.  Don't want to waste a syllable.  Not if you can help it.  Wow, that's great.  Well, we'll put a link to that.  That's from rationalsecurity.typepad.com.  That's his blog, Rational Security, or Rational Survivability, he calls it.  Actually he says it used to be called Rational Security, but security's dead, don't you know.



STEVE:  Right, right.



LEO:  That's great.



STEVE:  So one other little issue, a twitch has arisen during all these patches.  It turns out that the first round 

of updates to DNS is causing an undisclosed performance problem on DNS machines.  Paul Vixie, who's still very involved in the 'Net and DNS, has written formally acknowledging that there is a known problem with the first change.  But his recommendation was, look, do not back out to the vulnerable DNS.  We're going to fix the performance problem next.  But we had to get the main problem fixed first.



So that makes me think that a little something more is going on than we know so far because just outbound port randomization, unless their algorithm for doing that is somehow funky, I mean, I guess I could imagine if you were on a single port, lots of things are easier than continually allocating new outbound, setting up new outbound ports with sockets and sending packets out and getting them back and coordinating it all.  So they might just have a rather first-pass implementation of DNS query source port randomization, and they're going to work on improving the performance hit.  And this is only in really, really, really busy servers.  I mean, those servers that are doing, like, on the order of 10,000 queries per second are, like, they're having more trouble than they were before this change.  And so a lot of admins are saying, wait a minute, this is really hurting our DNS performance.  And so - and Paul says, look, he implores them, keep the new patch in place, we'll get you another one soon that fixes this performance overhead.



LEO:  Is it just the overhead of calculating the random numbers, or generating the random numbers?



STEVE:  It's - without looking...



LEO:  That shouldn't take much time.



STEVE:  No, no.  It wouldn't be random number generator.  That's instantaneous these days.  But it may be just, who knows what the algorithms are, what kind of data structures they had and what they now have.  Certainly over a long period of time the performance of DNS has been tuned.  If it had been highly tuned and optimized for one particular strategy, like a fixed port, then you could imagine that suddenly changing that to random ports will require a bunch new code.  Well, that bunch new code hasn't had a great deal of time to be hand-tuned and optimized to bring its performance back up to where years of performance tuning had honed the prior approach.



LEO:  That makes sense, yeah.  It's just new code.  It's not been optimized well.



STEVE:  I would guess that's what's going on.



LEO:  Yeah, that makes a lot of sense.



STEVE:  In something completely off topic, except it's a topic near and dear to our hearts, I watched the new, recently released, like two days ago, "Stargate" direct-to-DVD movie "Continuum" last night.



LEO:  And?



STEVE:  I loved it.



LEO:  Oh, I'll have to get it.



STEVE:  I have to say I'm a "Stargate" fan, boy.  I loved  "Stargate."  I watched all 10 seasons of "SG-1."  I'm now in the middle of, what are we, fourth season or fifth season of "Atlantis."  I mean, I'm craving sci-fi.  And so "Stargate" is, you know, it's generally a fun source.  But this was a - it was a time travel theme movie.  I love time travel sci-fi.  And this was really well done.  We didn't get to see as much of Jack O'Neil as I was hoping we were going to.  But he did show up for a couple little cameos.  But it was a great movie.  So I just wanted to tell our sci-fi enthusiast listeners that I recommend "Stargate: Continuum," the recently released DVD, which is a two-hour "Stargate" movie.  I recommend it without reservation.



LEO:  I've never seen "Stargate."



STEVE:  Well, Leo, then you're just - it's too...



LEO:  You're stunned.  



STEVE:  Too late for you.  It's too late.



LEO:  No, can I go back and watch the year - this is exciting to me.  I now have 10 seasons to watch.



STEVE:  Oh, and, I mean, it's really good.  I don't really  mean to get off on a whole "Stargate" rant.  But it is, it's very clever because they built a complete mythology.  The writers really cared about it.  It's a huge story arc.  There's lots of neat bad guys.  The concept of the stargate is wonderful, that stargates are wormhole anchors.  And so they're able to establish wormholes between paired gates.  And they do all kinds of neat things.  I mean, they really keep within the mythology.  So it's possible, as happened for example in "Star Trek," where we end up knowing how fast the food recyclers work and all kinds of mundane trivia, I mean, it's one reason you just can't watch this movie.  This movie wouldn't mean anything to you without understanding who all the people were and remembering past episodes and all that.



So for a "Stargate" person, this is a spectacular movie.  But I recommend the series without reservation.  It went through a little kind of a rough spot maybe halfway through.  There was, like, maybe one or two, or maybe a half of a bad season.  But overall, I mean, it's just spectacular.  So, I mean, "Stargate" is great.



LEO:  Well, as you can hear in the background, the marching brigade is marching on.  But...



STEVE:  Well, turn off your mic, and I will tell us - I'll read a SpinRite story.



LEO:  Would you do that?  I'm just going to - I'm going to cut my mic because this is ridiculous.  They're literally, like, they're out - I don't know why they're blowing right out my window.  Apparently there's a few extra leaves there.  I don't know what's going on.



STEVE:  Okay.  So this is from Jarvis Weezy, who sent us a note on - it's dated July 30th, so just a few days ago.  Now, the subject threw me off because the subject was "713 Days, 20 Hours, 25 Minutes, and 23 Seconds/SpinRite Success."  And I'm thinking, oh, my goodness, is that how long it took?  Was he running SpinRite for 713 days?  The good news is no.  I guess he was - just put that in there to get my attention.  So he starts his note by saying, "8/15/2006 was the last day I actually turned on the computer with this drive in it.  It was running XP MCE 2005," which is Media Center Edition 2005.  And he says, parens, "(It had a disk I/O error in the system event log and was now completely dead.)"



Then in his next paragraph, "7/29/2008 was the day SpinRite allowed me to boot this 500GB SATA drive that hasn't been used in two years."  He says, "Usually I listen to a TechNet session, but one day last week I clicked over to Security Now! on my iPod podcasts.  I listen most during my commute to work on BART."  So I guess he's in Northern California.  "So I've been trying to catch up on the content that's available and keep hearing about SpinRite.  Now, me being from the old school, I was very skeptical of software fixing hardware problems.  So when it came to my drive I was curious and started Googling SpinRite.  Originally I caused the damage by not securing the drive on those green rails Dell has because I had quite a few drives occupying them, and I happened to move the computer while it was on and heard a bang as the drive moved to the front of the case and remembered I had not yet got the rails on that drive.



"So sure enough, the drive made that horrible clicking sound, and Hitachi Diag said the drive was toast.  Note that I didn't have some of my stuff backed up.  Some of it was, but a lot of it wasn't.  When this drive was purchased two years ago it was a little more expensive than the $99 they go for now.  So I switched back to the original Dell drive and moved to Vista eventually.  I intended to save my money until I had enough to send the drive off to one of those recovery places.  But after hearing of the three-month recovery stories and the drive that took flight from the second story, I somewhat skeptically decided to give SpinRite a try.



"So I started SpinRite this morning, and off to work I went.  I came back to find the green "complete" screen.  Apparently it had finished around lunch or so, as the last partition was around 11:30.  So I expected to have some access to the drive.  But I did not expect every sector to be recovered.  Every sector SpinRite found a problem on, it recovered.  Not only was I able to recover data, but this thing now boots.  I am now able to access music I forgot I had.  I'm able to now access videos that I forgot I had, DVD compilations for 'Def Poetry Jam.'  Now, as MCE tries to do god knows how many updates and virus programs ask for renewal, I am looking at all these programs I legally bought as a student that haven't been used since I went off to Vista.  And to think I was waiting all this time to save money to send the drive off to a data recovery service, when instead I paid $89 for SpinRite.  Priceless.  And you know, I sent a text message to my best tech friend, and he said I should have just asked him because he would have told me about SpinRite right off the bat.  I am a believer.  Jarvis, MCSE, MCSA, MCP, Security+."



LEO:  Holy cow.  He's got the certs.  That's great.  Hey, we got some Q&A for you.  Are you ready?



STEVE:  Let's do it.



LEO:  You got your beanie on, your thinking cap?  These are questions from Security Now! listeners.  You can just go to Security Now! - I'm sorry, GRC.com/securitynow, and you can ask your questions there.  Starting with Sunnz in Canberra, Australia, with an interesting password question.  He says:  Hello, Steve.  I read about and saw your Perfect Password Page, and think it's great for things like WPA.  However, for less than important things, say my Facebook account password, do you think it would suffice simply to use a sentence?  For instance, "My dog is 12 years old and he runs very fast!"  Perhaps with no spaces in between?  Most sites don't seem to like spaces in passwords.  It does contain upper and lower case, number, and symbols.  And of course it's easy to remember.  I imagine this is not prone to brute force attack, thanks to its length, and whole sentences aren't available in a dictionary.  The advantage, of course, is that a sentence is easier to remember than something random.  One step further would be to make an intentional unique grammatical mistake that only you know of, or a spelling mistake, or both.  I guess that would prevent rainbow table attacks, if an attacker were to generate sentences and use that for brute force.  What do you think?



STEVE:  Well, I think it's an interesting question.



LEO:  Actually I do the same thing.  I mean, I use - in fact, for my PGP password I use a phrase.



STEVE:  There are two things.  First of all, the fact that it's easier to remember is a bit of a warning sign.  I mean, if it's easy to remember, then that means something is weaker from some angle.



LEO:  It's not totally random, which is the best.



STEVE:  Well, and, for example, if anyone glanced at it, they could quickly acquire it.  That is, if they saw it written down, if they maybe even, like, watched you typing it and caught most of the letters, they could fill in the gaps just using semantics and grammar.  So it's certainly, I mean, I like the approach.  I think it's very strong in general.  Obviously the longer the sentence, the better.  There are so many words that could be combined in so many ways, so many possible sentences, that sure, it's not as strong as something from GRC's Perfect Passwords Page, but it's certainly better than a short phrase, which just doesn't contain enough entropy.  A long sentence is going to have a lot of entropy in it.  Not as much as random characters at the same length, but still a lot.  I would just note that other humans could acquire it if they had any exposure to it much more quickly than they could something that was random that they had no experience or no - nothing that they could quickly map it onto.



LEO:  All right.  Yeah, because I use that.  I figure...



STEVE:  Yeah, it's good.



LEO:  Yeah.  I mean, you could, I guess, do a brute-force attack.  But it would be very difficult because there's different - there are so many words.  And there's punctuation.



STEVE:  Well, and the other thing is, who's going to know that this is what you're doing?  Any useful system is going to turn whatever you put in into a hash.  Hopefully it's not storing your ASCII and comparing it because that's the worst thing that a system can do.  The right thing, as we know, in security is to immediately hash that into a fixed-length token, which is also easier for databases to handle because that cannot be reversed.  So nobody would know that that's what your password was.  They wouldn't know that it wasn't a few characters or eight.  So I think it's probably a good idea.



LEO:  Very good.  So, good.  I'm going to continue to do that.  I am Sunnz in Canberra.  No, no, I'm not.  Aaron Feickert in North Dakota wonders how safe his private key is:  Steve, you've talked several times on your netcast about PGP public key encryption.  I'm wondering how secure my private key really is.  I use it to encrypt all my offsite backups, and I like to carry it on a USB drive with me so it's only in one place.  I'm worried about what could happen if it fell into someone's hands.  The private key has a passphrase.  But is there any risk of an evildoer somehow breaking my encrypted backups if they got the key?  That's a great question because I don't particularly protect my private key.  Should I be?



STEVE:  Well, I love the question.  First of all, PGP has been written using state-of-the-art philosophy of security.  So, for example, in the case of the PGP use of a passphrase and a public key, the passphrase is hashed and is used to encrypt the public key just using symmetric encryption so it's very fast and lightweight.  So the attack on the passphrase would be guessing all possible passphrases, hashing those, and applying them to the public key, which is probably more feasible than just brute-forcing the hash.  The hash is going to be long.  It's going to be 160 bits.  You're just not going to be able to brute force that and use that to try to decrypt the public key.  So the public key is - oh, I'm sorry, I'm saying public key, and I mean private key.



LEO:  Private key, right, right, right.



STEVE:  Yes.  I was sitting here staring at the text, seeing PGP public key.  Yeah.  So in an asymmetric encryption system where the public key is known to everyone and is used either to encrypt something that can only be decrypted by the person with the matching private key, or is used to decrypt something which will only succeed if it was encrypted with the person's private key.  In both cases the strength of the system is that it provides extremely good security and authentication because you're able to publish the public key.  Everyone can see what Aaron's public key is.  And they know that, if they're able to decrypt something successfully using his public key, then the only way it could have been encrypted is the use of the matching private key.  Okay.  What this means is that keeping the private key secret, the unencrypted private key, the actual private key, keeping it secret is crucial.



Now, to protect the private key when it's not in use, when it's being stored, as Aaron has it on his USB drive, the private key is further encrypted using the passphrase that he was asking about.  So the strength of the passphrase and the, well, keeping the private key private are both important.  If you absolutely protected your private key so that it was inaccessible to anyone, then someone could argue, look, no one can get it.  My key management is so good, no one can get my key.  Therefore I'm not going to encrypt it.  That is, I'm not going to encrypt it with a passphrase because I don't want to.  And you could say, okay, fine, as long as it doesn't get loose, and you're sure your key management is that good, don't bother.  On the other hand, encrypting it with a passphrase absolutely obscures it so long as the passphrase is long and is not brute-forcible.  So that's the point of attack.  Brute-forcing the passphrase would decrypt the private key if somebody had access to it.



So if it's on a USB drive, those are inherently moved around.  We've told lots of stories about unscrupulous people saying, ooh, look, a USB drive, I wonder what he's got on it, and sucking the contents out.  So if your private key is ever going to leave in any way your own really good protection, then by all means use a passphrase.  And the way PGP implemented it is as good as it gets.



LEO:  So I see that iTunes sells "Stargate," all the seasons.  Should I just start with season one and go right through?



STEVE:  It's a great series, Leo.  I mean, actually, I would start with the original movie.



LEO:  Oh, okay.



STEVE:  The original movie was - did you ever see that?



LEO:  No, I haven't seen - I don't even know what "Stargate" is.



STEVE:  Oh my god.



LEO:  Is that "Stargate Atlantis"?  What is that original movie?  What's that?



STEVE:  It's just "Stargate."



LEO:  "Stargate."  I'll find that.



STEVE:  The movie was called "Stargate."  It is a great, fun movie.  And it was the basis for the series.  They continued the mythology.



LEO:  You know, they're all - I'm really pleased.  They're all on iTunes, so I can put them on my iPod, yeah, make it easy.  Sorry, a little digression there.  Brad Pliat- let's see.  Okay, let me see if I can do this.  Pliatsiosis.  Pliatsios.  Bryan says - he's from Melbourne.  He's waiting for, oh, boy, GRC VPN:  G'day, Steve, I've been listening since the beginning of Security Now! and jumped on the Hamachi bandwagon with the hope to move to the OpenVPN solution you were always promising.  While Hamachi was bought out and other options like Back to My Mac, GoToMyPC, GoToMeeting have come up, I'm still hoping you'll eventually get to a roll-your-own solution.  Not only for the preference not to route my traffic and rely on another party, for security reasons and of course because most servers are homed in the U.S., but also to set up access to my home network through the local community wireless network where the Internet services are not suitable as it's a private network.  Kind regards to both you and Leo.  Eternal thanks for geeking it up.



STEVE:  Well, I just wanted to respond to Bryan and anybody else who feels similarly.  As you'll remember, I was planning to put together an OpenVPN set of how-tos.  And I've got OpenVPN working.  It's certainly possible to make it work.  But boy, is it a pain.  And it turns out that doing it right really requires - there's so much - it's like a Swiss army knife product.  It's so general and so capable that the configuration file, I mean, I remember the first time I looked at the config options.  It's just like, oh my goodness, how many months is this going to take?  And there were problems on earlier versions of Windows that don't allow bridging of network adapters, which you need in order to get OpenVPN working in the right way.  There's problems where you get network collision ranges if your network at home is in the same range as the network where you happen to be VPNing in from.  Then because it's routing table based it screws up the routing tables.  I mean, as I really got down to trying to make this thing work - oh.  And the other thing they don't tell you is that when you make your own SSL certificates, as you have to, using OpenSSL, all of the content of your certificates is sent in the clear.  So those all want to be null fields.  I mean, there's just - it got so involved that I finally said, okay, wait a minute, this is dumb.  I'm just going to do one.



So I've mentioned it briefly before.  It is my main project once I get finished with this DNS testing facility and once I get the cookie system launched.  I'm going to be plowing into a product called CryptoLink which will be GRC's first formal commercial security product.  And it's going to be sort of everything.  It'll do NAT traversal, it'll be Hamachi-like, it'll be able to run in an easy-to-use mode behind NAT routers where GRC will provide the connection.  Or in a Trust No One mode, I call it TNO, where you're able - you're a little bit more technical savvy, where you set up your router at home to be the server end of the link and so forth.



So anyway, I don't know when.  I never know when.  But it is absolutely the next thing I'm going to do, as soon as I get these other little loose ends finished up.  I needed to get the menuing system online, that's done; and then get the cookie system finished, that's done.  And of course we have a little pause here while I do the DNS testing system because I think that's important, too.  And then CryptoLink is next.



LEO:  That's exciting.  I'm really glad to hear that.



STEVE:  And you remember that I ran through with you, Leo, confidentially, three pages of bullet points when you and I were having dinner once in Vancouver.  And your mouth was hanging open.



LEO:  I love the - oh, what you're - yeah.  It's brilliant.  It's really great.



STEVE:  There's a bunch of new stuff that no one's done before.  So I'm excited.



LEO:  And, you know, it's interesting, with all the free security stuff, you've never done a commercial security product.



STEVE:  No.



LEO:  So I think this will be more than welcome.



STEVE:  I'm excited.



LEO:  Yeah.  Peter Chase in Columbus, Ohio has an idea to avoid using spoofable DNS:  Guys, if I obtained the actual IP address for each site I visit, and incorporate them into each bookmark, wouldn't that be quicker and more secure than to go to those websites using a DNS lookup?  That's what we were just talking about.



STEVE:  Yeah, exactly.  It came up in the issue of direct IP access to the DNS testing sites.  So it's interesting.  I mean, he's saying, okay, what if I look up the IP addresses of these important places and put them in the bookmarks instead of the domain name?  We sort of touched on this last week.  First of all, that would avoid spoofing.  You would be going - your browser would be connecting directly to the site.  I can't say for sure that you wouldn't have some side effects.  For example, there is something called multi - it's not multi-homing.  I don't remember the name now, Leo, I know the technology, where a bunch of different websites all live on the same IP address?



LEO:  Virtual hosting?  Virtual hosting service?



STEVE:  Virtual hosting, yes.  The idea is that when your browser makes a query it connects by IP.  But one of the headers in the query is the domain name that is in the URL you're using.  So some systems do not give different websites each their own IP.  Instead, many websites share an IP, and they depend upon the browser including this extra information, saying, well, I know I want this IP, but this is the host that I want at that IP.  Which allows multiple web domains or websites to live on a single IP.  That's still rather common.  It is a way of conserving IP addresses.  It's generally used by hosting services who set up inexpensive websites, and you don't get your own IP.  And in fact, sometimes you can pay extra from such a company if for whatever reason you really want to be on your own IP address, like for example you want to offer other services than just web because only the web has the ability to use this hosts header to disambiguate which site you're wanting to access at that IP.



So my point is it's not a universal solution, that is, to use just an IP address, because that wouldn't work at a site that had multiple domains on a single IP.  On the other hand, you could try it.  And if it works, it's probably going to keep working, at which point you could build it into your bookmark.  The other problem, of course, is if they change their IP, then you would not - your bookmark would break because it wouldn't automatically be using the indirection, basically an indirect pointer, that DNS also provides and that you are using something that doesn't change, meaning the name, and the IP it maps to may change.  On the other hand, that's what you're wanting to avoid because it might be a malicious change in the IP that you're trying to keep from happening in your case.  So I would say, if somebody's really concerned, if for some reason they don't feel comfortable or are unable to switch to a fixed DNS server like those offered by OpenDNS, then, yeah, you could use an IP address, but there are some caveats.



LEO:  Very good.  And very interesting, yeah.  The problem of course is the trouble that you'd have to take.  But I guess you'd only do it once to find all of those addresses.  You could just do a ping, I guess.  That's what I usually do.  Is that the best way, you think, just to say "ping yahoo.com," then write down the address?



STEVE:  Yes, that's a very good point.  I was going to say nslookup is a command that we all have in our machines.



LEO:  That would work, too, yeah.



STEVE:  But you're right, the ping command does resolve the domain name into the IP.  And then it shows you, pinging this IP, blah blah blah, and that allows you to pick up the IP address.



LEO:  Somebody should write a little utility to do that because you're going to want to do it frequently because, as you point out, these things change.



STEVE:  Actually I have one, it's called ID Serve, and it's available on GRC.com on our freeware page.



LEO:  You're kidding.  That's great.



STEVE:  Yeah, it's a cute little, nice little GUI.  You just stick the URL in.  And basically the idea, it was - I originally wrote it to ID the servers so you could see what kind of server people were running back in the days when IIS, Microsoft's server, was so horribly broken and insecure.  There was a threat just even using some remote system that was using IIS.  So ID Serve identifies the server that some remote place is using.  In the process it shows you a nice little color dialogue box says, you know, what's going on.  And among that information is the IP address of the...



LEO:  What we really need is something that will go through my Firefox favorites, or bookmarks, or my IE favorites, and just replace them all with the ID, with the IP addresses.



STEVE:  IP addresses, yeah.



LEO:  Shouldn't be - that wouldn't be a hard thing to write.  I'll work on that on my vacation.



STEVE:  Oh, god.  When you're not busy catching up on 10 years of Stargate.



LEO:  I'm downloading the movie right now.



STEVE:  Oh, it's so good.



LEO:  I'm excited.  Scott Griswold in New London, New Hampshire is worried that he didn't need his football:  Hi, guys.  Love the show.  Recently while paying for a transaction on GoDaddy.com I decided to use PayPal.  I had my trusty PayPal security key at the ready.  I was very surprised when, after entering my password, the transaction was authorized without prompting me for the secure, six-digit code.  I received a confirmation email that payment was made, and I immediately went directly to PayPal.com to verify the payment made.  Yeah, it was.  Is this standard practice for PayPal to not require the security key when paying through a third-party vendor?  It always asks me for it when I log directly into the site.  Can you enlighten me as to what's going on here?  Thanks so much.  Keep up the great show.  Boy, I've never had that happen.  I've always had to use the security key.



STEVE:  Ditto.  So I'm mystified.  I wanted to just share this with our listeners so that they know this happened to Scott, apparently.  I was thinking maybe if he was actively logged onto PayPal just before, his logon session may not have expired.  And then if he came in on the same browser in the same session, then, you know.  But I don't know.  Maybe there's a bug over at the PayPal end of things.  I'll be interested to see if any other users report similar behavior.  If so, I'll let our listeners know.  But I just thought that was an interesting little oopsie.  Yeah, because I've never had it not ask.  Anyone who has the football kind of like gets ready.  The first thing you do is you go find it before you're going to buy something because you know you're going to have to come up with it.



LEO:  Got my football here, I'm ready.



STEVE:  Exactly.



LEO:  Matthew Justice in Austin, Texas asks just the right question at the right time:  Dear Steve, I've been looking for a solution to store my passwords online, but for some reason I don't trust any of them.  Since you're such a great programmer, I'd love it if you'd write a solution.  You could even charge for it.  Maybe something that uses, oh, a GPG key?  By the way, GPG is GNU Privacy Guard, which is the open source version of PGP.  That's what I use, by the way.  Any thoughts?  Thank you for all your hard work over the years.  You got something like that?



STEVE:  Well, what's interesting, and when I said he asked the right question at just the right time, just that morning, yesterday morning, I got a demo from a friend of mine of a password management solution that he is absolutely in love with.  It's called Password Safe.  It's open source, multiplatform - Linux, Mac, Windows.  And from what I saw, I am very impressed.  I've not done all the due diligence to plow into it.  But one of the things that I love about it is that it's able to connect to a shared resource, a drive share, or I'm thinking through Jungle Disk to Amazon's S3 service, as long as it's running.  But it looks like it's got very comprehensive sort of enterprise scalability for managing passwords.



So I will do a full episode on it because I was very impressed.  It does automatic form filling.  And my guess is they probably did everything right.  From what I saw, everything looked like it was done right.  But I haven't looked under the covers yet.  I'm going to.  But I thought in the meantime we'd just let our listeners know about Password Safe.  If you put those two words into Google, first link is passwordsafe.sourceforge.net, where the project lives.  And again, it's very nice looking.  And the guy that showed it to me is a very savvy, security-aware IT guy.  And he and his company have been using it successfully for some time, and he just really loves it.



LEO:  I like the idea of it being, as you know, of it being open source.  That's really great.  Peter Fleischman in New York wants to be less nebulous about NebuAd:  Is there a way that the hosts file could be modified to block NebuAd? By the way, I love your podcast.  You and Leo are providing a really valuable service.  Let's refresh people.  NebuAd, we spent some time taking about it, and Phorm.  These are the things ISPs are using to customize ads.  Based on where you surf they actually follow you around.  And since your Internet service provider knows everything you do, they can really keep track of every move you make, much better than something like DoubleClick. 



STEVE:  Yes.  In the case of NebuAd, I referred to it briefly when we talked about it and the fact that what NebuAd is doing is injecting their own packet, injecting a packet containing some HTML code at the very end of pages which come up.  So when the backslash HTML tag that closes the page appears, NebuAd's technology triggers and basically spoofs one packet into the stream.  And, I mean, it's not hard to do, but you have to really want to do this because it means you need to - we've talked about TCP protocol and sequence numbers.  You need to be tracking the connection and emit a packet that looks like it's a continuation of that same connection.  So, I mean, it's certainly doable.  It's not rocket science.



But what they're doing is they're injecting a packet that contains a JavaScript invocation.  And the key is it's pulling JavaScript.  The packet itself doesn't have the script.  It's pulling it from a site called a.faireagle.com.  So all you would have to do is use your hosts file to preempt your computer's lookup of that domain name.  I would say use both a.faireagle.com and just faireagle.com and just use a hosts file to aim those at your own machine, 127.0.0.1, the so-called "local host" address.  And then everything will work fine.  That script simply will not be able to find "faireagle."  It will not look up "faireagle" in DNS.  And no - except that you've still got a little extra debris at the end of your pages, it will be neutered, dead debris, and you're not trackable by NebuAd.



LEO:  We should mention that everybody, all the ISPs have decided not to use NebuAd, at least as far as we know.  It might even be illegal in England now.



STEVE:  Actually the reason I mentioned it specifically was that somebody who posts in our newsgroups is under an ISP using NebuAd in the United States.  So it is...



LEO:  Oh, that's terrible.



STEVE:  It is online, and it is happening.



LEO:  You don't want to say the name?



STEVE:  No.  All anyone needs to do is just do a view source of a web page, and you'll see a reference to "faireagle" at the very end of the source view.



LEO:  Now, I suppose that they could change their server, and then you'd have to find, you know, have to block something else in your hosts file.



STEVE:  Yes, exactly.  And that's the problem with this is, I mean, the annoying thing about the hosts file is it does not allow wildcards.  It'd be so nice if you could do *.faireagle.com or *faireagle.com so that anything that was left of the asterisk would match.  But the hosts file only does exact matches.  So we don't have the ability to do that.  I'm sure there are other tools around that could do this kind of preemption, and it's looking like such things might become more popular.



LEO:  I'm just looking through my source code, a view in source, just to make sure.  Wow, that's really scary.  Fortunately it doesn't look like Comcast is using it.  Although, you know, it's possible...



STEVE:  Well, Comcast got slapped hard for - the next time they trickle into messing with people's packets, they're going to be thinking twice.



LEO:  It might be a good reason to go to Comcast now because they got slapped by the FCC.



STEVE:  Right.



LEO:  Darrell Duffy in Coos Bay, Oregon - beautiful part of the country - has a micro question:  Steve, I'm a long-time listener to Security Now! and waiting for an opportunity to use SpinRite.  Perhaps I have one.  My friend has a Nikon camera, a D70 - very nice camera, I use it myself, as well - and purchased a 2GB Microdrive with it.  He's noticed errors over the past few days, then went on a trip to look at some real estate.  He took a few hundred pictures in a day of various properties.  And when he stopped by at the end of the day the pictures didn't all come off the Microdrive.  It kept tossing errors and going offline.  Only one or a few pictures would come off the drive each time before an error occurred.  We noticed that moving to Windows XP rather than Windows Vista allowed more pictures to be recovered since XP did not read the drive to update the file data when a list display was used.



I understand you've said that SpinRite does not work on USB thumb drives.  I understand why that is.  I wonder about Microdrives.  The Microdrive has a CompactFlash format with a 3/4" diameter hard drive actually inside the CompactFlash.  I wonder if SpinRite would help recover this drive to get pictures from the drive.  I gave my buddy a 4GB CompactFlash card to replace his 2GB Microdrive, but asked him to hold onto it in case SpinRite could recover it.  Love the Security Now! show.  Hey, that's a great question.  It is a drive in there, not a flash drive.



STEVE:  Yeah.  And the first time I heard about this I'm thinking, oh, come on.



LEO:  How could they put a drive in there?



STEVE:  A drive in the same form factor as a little CompactFlash?  But sure enough, I mean, there's a little spinning magnetic platter.  And, I mean, 2GB, 2GB.



LEO:  I think it actually predates the CompactFlash in that form factor.  I think that was the first thing that happened was the Microdrive, as I remember.



STEVE:  Phenomenal.



LEO:  IBM.  They're brilliant.



STEVE:  In fact, that would make sense, too, because the Compact Flash has an IDE interface on it.  I have a - one of the crazy boxes that I'm running OpenVPN on that I was talking about before - I built a diskless FreeBSD system because I just wanted to.  It's where I'm running BIND 9 locally.  And it's my little - my own network's UNIX machine.  And all I had to do was it boots from a CompactFlash and then doesn't use the CompactFlash at all.  I turned swap files off, and my VAR directory tree in UNIX is mapped to RAM.  I have two RAM disks, so I copy things over at boot time so nothing is ever writing to the CompactFlash.  And I've marked the root partition and the user partition both as read-only so nothing can write to them because we know you don't want to burn out your EPROM.  So it is certainly possible to do that.  But what was cool was a simple little bracket just adapted the IDE connector to the CompactFlash.  It emulates an IDE drive.  So it makes sense, Leo, that the microdrive would have predated the CompactFlash.  Otherwise why would they give it an IDE interface?



But anyway, to answer Darrell's question, absolutely.  We've had a lot of customers report success using SpinRite on Microdrives.  And they tend to have a problem because it is a delicate little bit of mechanics.  And being so small it drops.  It can easily be mistreated.  So, yeah, SpinRite will probably recover it.



LEO:  Very cool.  I love that idea.  I think that they're phasing those out.  I don't think you see as many of those as you used to.  Because they do top out at 2GB.



STEVE:  And I was just going to say, in this day and age, who would use a spinning mechanical flaky thing when you could get a solid-state CompactFlash that are just not expensive anymore.  But of course the point is it's not that he doesn't wish he'd been using a solid-state drive.  He did use a Microdrive, and he wants the photos that it contains.



LEO:  I think that originally it was those were larger capacity than the Flash, CompactFlash.  And they were faster.



STEVE:  Ah, right.



LEO:  They were faster.  But now of course we've got CompactFlash that's bigger and faster than any drive, so - amazingly enough.  Technology is so cool.  I love it.  I just love it.  Jonathan Kemp in Leicester, England defends third-party tracking cookies:  Dear Steve and Leo, I work for a company in the U.K. that provides a free service to travelers.  I'm not including the name as I'm not after a shameless plug.  We rely entirely on affiliate advertising, and one thing that is becoming and will continue to be an issue is cookie blocking and cookie deletion, an increasing trend.  In order for a lot of services to remain free, tracking cookies have to be accepted, otherwise companies like mine will be losing out on revenue we rely on.  This is the other side of the argument, of course.  I'd love to hear your views on this as I feel there is a fashion in deleting cookies pushed by big Internet security companies without users considering or understanding the repercussions for affiliate publishers.  After all, this will eventually have a knock on effect on users looking for free services on the Internet.  Keep up the good work.  And I'd add to that, really, because I have a little dog in this hunt, blocking banner ads, which you can easily do.  And these are free services that are paid for by advertising.



STEVE:  Yeah.  I included this because his viewpoint had never been entertained here.  I'm very anti-tracking, anti-third-party cooking - cookie.  Third-party cooking.  Actually I enjoy third-party cooking.



LEO:  You live on third-party cooking.



STEVE:  I'm Mr. Restaurant.  So, but I thought his position ought to be represented.  There was a discussion we had, really interesting discussion in our newsgroups many years ago, back when I was entertaining the idea of basically building a filter for browsers.  And one of the options we were considering was ad blocking, blocking ads completely.  And the ethical question was, is it okay?  Is it okay for users to block ads?  And both sides were represented, and I think both sides were represented well, the idea being, okay, wait a minute.  If I go to a web page, am I implicitly agreeing to accept everything the page offers?  Why can I not be selective?



And the argument you bring, Leo, is a good one.  It's like, okay, wait a minute, web pages depend upon advertising in order to survive.  So don't users have some obligation to see all the content?  And of course then I say, well, okay, I have TiVo.  Why do I love TiVo?  Two reasons.  It allows me to watch things asynchronously, in sort of the same way I love email and newsgroups because I don't have - I'm not live chatting.  I don't have to be watching television when it's being broadcast.  But also, frankly, the commercial-skipping is to die for.  Okay, well, as a viewer of broadcast television, don't I have an obligation, if I'm getting this free TV, to sit there and endure the commercials?  And is it okay for me to get up and go pee in the middle of the show?



LEO:  Yes, it's okay.



STEVE:  In a commercial break.  No, no, it's not okay, I have to watch the commercial.



LEO:  There are even some people who think I should click on a banner once in a while, or I should buy something just to support the show.  I don't think you need to do that.



STEVE:  Yeah, so, I mean, I guess my point is these are interesting questions.  And they're not cut-and-dry.  They have two sides to them.



LEO:  I think we love the free stuff we get.  For instance, I looked into podcasting, there were three ways we could do this show.  We could do it listener donation based, which is the way I'd prefer to do it, in fact that was my original plan, but not enough people donate.  Only about 2 percent of our listeners donate.  Of course we don't flog it, but I don't want to flog it.  So that's one way.  Another way is to charge a subscription fee.  And frankly, in the states at least, we're so used to getting free content, television and radio, that nobody wants to do that.  And I've noticed a lot of shows that have tried that have failed, including Ricky Gervais, who had the most popular podcast in the U.K., it was at 400,000 downloads, went paid and it was over.  And he went back to the free model.  So I think we have to do advertising based.  That's what everybody's used to in their media from the mainstream media.  And you just hope that people, you know, fortunately the ads work on our shows.  But we're very careful.  We choose products that we like, that we think our audience would like.  We try to do the ads relatively unobtrusively, with some content in them.



STEVE:  And my hope is that the quality of the content, the quality of the show allows it to carry, to justify, the advertising support that we need in order to be able to put the quality into the show.



LEO:  I have to tell you, though, I've in recent weeks received - because we now have three ads in the show, which is, by the way, the max we'll ever have.  But I've received several emails from people saying I'm not going to listen anymore, it's too many ads.  Which cracks me up because if you listen to commercial radio or watch commercial TV, there's five times more ads.



STEVE:  Yeah.



LEO:  I don't understand.  I guess people don't watch any commercial TV, either.  We just have to, you know, this is how we have to support ourselves.  These shows used to be very cheap to do.  They're not so cheap anymore.  It's a great question, you know?  And but then there's also the line between third-party cookies and NebuAd.  How far are you willing to go?



STEVE:  Right.



LEO:  Where does it become a privacy violation?  Bobby Clark in Berea, Kentucky brings an important new Google Mail feature to light:  Steve and Leo, Google has added a setting inside of Gmail for always use HTTPS.  Yay.  With that set you don't have to put https://gmail.com to be guaranteed a secure connection while on Gmail.  I noticed that the other day.  That's great news.



STEVE:  Yup, I just wanted to make sure all of our listeners knew that there is that setting, which they can turn on.  And mine's on because - and just the other day I was talking about Gmail flipping back to non-secure if you came in non-secure.  It would briefly make you secure and then switch you back.  Now you can say absolutely always.  And that makes it unspoofable.  The bad guys cannot spoof Gmail, that is, the DNS spoofer guys, because your browser will check Gmail's certificate on an SSL connection.  And if it's going somewhere else, all you have to do is make sure HTTPS is up and running.



LEO:  Yay.  I've been using a Firefox plug-in called Customize Google to do that.  But now it's just a setting.  It should have always been a setting.  I'm not sure why they didn't do that before.  All right, let's get on with our very Exciting, Fantastic, Wonderful, Extra Special News of the Week.  This is from Brian Scallan in London, U.K.:  Hi, Steve and Leo.  I wonder if Amazon has been listening to the podcasts in which you mention how the market is ripe for a competitor to PayPal?  I'm excited about this, too.  They've just launched a rival, Payments.Amazon.com.  Thanks for the great show.  I immediately took a look at that.  What do you think, Steve?



STEVE:  It looks very good to me, Leo.  I'm an Amazon fan.  There's hardly a day UPS doesn't pull up with something from Amazon.  And of course I'm a happy Kindle owner.  And by the way, my replacement Kindle came promptly.  I moved stuff over.



LEO:  Well, that's good news.



STEVE:  I switched my account over.  I sent the one with the broken screen - that I broke - back.  And it was a completely good experience.  So let's hope this thing, I mean, Amazon's got enough of a name that I can imagine sites that support PayPal adding an Amazon.com purchase button, much as sites are also doing for Google.



LEO:  Well, I would love to replace PayPal for our payment system.  We get a lot of complaints about them.  And as you know, PayPal ripped me off.  So I'm anxious as can be to replace PayPal.  My only concern is you have to have an Amazon account to use this; right?



STEVE:  Correct.  You do.



LEO:  Yeah.  So you don't have to have a PayPal account to pay us through PayPal.  You can use a credit card.



STEVE:  Oh, interesting.



LEO:  Yeah.  In effect, PayPal is really just providing us with merchant services.



STEVE:  So it sounds maybe a little bit like Amazon is trying to push people into this to expand their overall buyer base.



LEO:  Sure.  Once you're - you've already got an account, just buy something, you know?  And I imagine - I can't imagine many people who listen to this show aren't Amazon members except for we have a huge global audience.  And while Amazon certainly has a global presence, I think in Australia, the U.K., Sweden, they may not be the same presence.  For instance, in Canada, Amazon only sells books.  So they're not as popular.  And they're more expensive.  So I think that, I don't know, this is a tough one for me.  I'm thinking maybe we just get a merchant services account and let people just use a credit card.



STEVE:  Well, and again, as we've said, PayPal needs competition.  I'm glad that another major potential competitor has stepped up.



LEO:  Yes.  Yeah, it can only be good to have some competition.  Finally, our last question, sad to say, our Cool Tip of the Week.  Ryan Morris in Niagara Falls, the Ontario, Canada side, says:  Dear Steve, last year my friend went to the University of Waterloo and could not use any routers at school.  We were talking about the University of Pennsylvania, right, just like that, last show.  I told him to get a Mac, though he is a pure Linux user.  I then explained to him that you can use a Mac as a router.  If you have a Mac computer plugged in, you can turn the WiFi radio into a hub.  It's very easy and in the settings.  Then it's as easy as connecting to a regular WiFi router.  And yes, you can add a password.  The only downfall is your Mac has first priority to bandwidth - that's okay - and whatever is left is spread out.  Also it can work in reverse by connecting over WiFi and turning the Ethernet port into a hub.  Love the show.  Ryan.  P.S.:  SpinRite is the only piece of software I ever bought, and I have a ton of software.  Ryan's a little pirate.  But he didn't pirate your stuff, and I think that's - and you don't secure, you don't put any DRM on it or any copy protection or anything.



STEVE:  No.



LEO:  That's a really good example of, I think, when you treat people like thieves, they act like thieves.



STEVE:  It works for people, and they appreciate it.  And how many people have we heard say this is the best $89 I ever spent?



LEO:  Yup.  I should point out that, yeah, you can do that with a Mac, but you can do it with any computer.  Linux does it just fine.  It's called - what is that called, an "ad hoc network."  Right?



STEVE:  Yes.  Yes.



LEO:  So, but you need two connections, one to bring the Ethernet in, or the Internet in, in this case he's used Ethernet; and then the second connection to distribute it, which could be Ethernet or, since many machines have both Ethernet and WiFi, this is a great way to do it.  You set up an ad hoc connection.



STEVE:  And ad hoc as opposed to base station, where you've got two computers connecting to each other as opposed to a base station and a computer.



LEO:  Right.  So, yeah.  And I know Windows with Internet connection sharing effectively does the same thing.  It's a little harder because of all the finicky bits.  But you could totally do that.  So that's a great tip.  Steve, we've run out of time.



STEVE:  Well, and you're off to the airport.



LEO:  Well, not exactly the airport.  I'm off to San Francisco, not to the airport.  I'm going to do a radio show in San Francisco, the Ronn Owens Show at 11:00 on KGO.  And then I'll be back.  We're going to do some Giz Wizzes because next week I am taking four days off.  We've doing a drive up with the family to the gold country and take some time in the woods.



STEVE:  Oh, cool.  Well, I did want to mention I love getting questions.  The questions get to me by people who go to GRC.com/feedback.  So there is a link to that at the bottom of the Security Now! page.  But you can go directly there.  If you've got something to say, GRC.com/feedback.  And I love to hear from people.  Every time I go and pull notes, I get on the order of 450 new submissions.  So I apologize to people, sometimes I see them, and they say this is the fourth time I've written and you've never - it's like, I know, I'm so sorry, I mean, I get so much mail.  But that's what drives these Q&A episodes.  I do respond and read everything I'm able to.  So it's really sincerely appreciated.  So thank you, everybody, for your feedback.



LEO:  Well, and while you're at GRC.com make sure you check out SpinRite, of course, Steve's great program, the ultimate disk maintenance and recovery utility, and all of the great freebies he's put up there - ShieldsUP!, Shoot The Messenger,  DCOMbobulator, and don't forget Wizmo.  Love Wizmo.  Really useful little doohickey for your - I think the best way to describe it actually is "doohickey for your Windows."  It does so many things.  Does everything but give you a hickey.  It's all there at GRC.com along with transcripts of this show, 16KB versions for the bandwidth impaired.  Check it out today.  GRC stands for Gibson Research Corporation.  Steve Gibson, always a pleasure.  Thank you for...



STEVE:  I was just going to say, there's one other thing that I forgot to mention that your reminding me about the freeware reminded me of.



LEO:  Yes?



STEVE:  Years ago I was doing a little work, you remember, I told you about it confidentially, for the government, a communication system, a new type of communication system for the Internet.  And I wrote, in research, I wrote something I called DNSRU, DNS Research Utility.  And it is, as far as I know, the only really comprehensive DNS benchmarking tool ever.



LEO:  Very cool.



STEVE:  Well, and it's funny because it's been kept alive in the hearts of the people in our newsgroups.  And when I mentioned that I was going to be doing this DNS spoofing test, someone said, uh, Steve, could we have that back?  Because it's funky, I never finished it because I used it for all the information that I needed.  And at the time I had an expiration in it so that you had to hold both shift keys down when you launch it in order for it to - in order to, like, bypass the, hey, this copy's too old, you probably ought to refresh yourself with a new one.  Except there is no new one.



Anyway, I'm going to dust it off and change it around a little bit because it had some stuff in there that wasn't about DNS benchmarking.  But it's got really a cool DNS benchmark.  And since people are looking at doing things like maybe changing DNS servers, or checking to see, remember that the performance of DNS is critical because it's the first thing your browser does to look up an IP address for anything it's doing.  So faster DNS does mean a faster overall experience on the Internet.  And so I will be adding before long a permanent addition to our freeware, which is going to be this really cool DNS server benchmark.



LEO:  Oh, that's excellent.  So we'll look for that, too, at GRC.com.  And we will look for you next week, Mr. Steve Gibson, every Thursday.  Come rain or shine or even vacation, Steve Gibson's here with the latest security news.  Thank you, Steve.  We'll see you next time.



STEVE:  Talk to you then, Leo.  Bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#157

DATE:		August 14, 2008

TITLE:		DNS - After the Patch

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-157.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo follow-up on the recent industry-wide events surrounding the discovery, partial repair, and disclosure of the serious (and still somewhat present) "spoofability flaw" in the Internet's DNS protocol.  They also examine what more can be done to make DNS less spoofable.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 157 for August 14, 2008:  DNS Problems Continued.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!.  Steve Gibson is here.  He's the security guru.  And in times like these it's good to have a friend like Steve.  Hello, Steve.



STEVE GIBSON:  Hey, Leo.



LEO:  I mean, times like these, I'm not kidding, it seems like the bad guys are winning.



STEVE:  We have no problem coming up with weekly content, let's put it that way.



LEO:  Oh, man.



STEVE:  There's lots of material.  I deliberately didn't tell you something when we were doing our pre-start-of-roll chat.



LEO:  You holding out on me again?



STEVE:  Again?



LEO:  What's up?



STEVE:  First time I've ever held out on you, Leo.



LEO:  You know what, it's funny because right before we do this show I do a podcast with Roz Savage.  As you know, she's rowing across the Pacific.  And she's been holding out on me for six weeks.  We knew her electric water maker had broken, but it was all going to be okay because she had a manual water maker.  She told me today, well, yeah, actually that broke six weeks ago, too.  And it was like, what?  She said, well, I didn't want anybody to freak out that I was going to die of thirst.  I said, but you're going to die of - she said, no, we're almost...



STEVE:  What's she been drinking?



LEO:  Well, when she rowed the Atlantic, it was a race.  And the rules of the race required that you use ballast that was drinking water, potable water.  So fortunately she...



STEVE:  You mean, like, safety rules.



LEO:  Safety rules, basically.  So they're, you know, plastic, kind of like bota bags.  And...



STEVE:  Clever.



LEO:  Yes.  And so fortunately she had adhered to that rule, even though she's not racing this time, and had that, and she's been drinking it.  But she said it was going to get a little dicey towards the end there.



STEVE:  Well, and a little stale-tasting, too.  I think, you know, drinking your ballast doesn't really sound very appealing.



LEO:  No, it doesn't sound - she said, yeah, it tastes a little rubbery.  It doesn't sound good.  I mean, it's clean, but it doesn't sound so good.  Anyway, what's your big surprise?



STEVE:  My big surprise is just to note that being Episode 157, and being that there's 52 episodes per year, and three times 52 is 156...



LEO:  Wow.



STEVE:  ...this is the beginning of our fourth year.



LEO:  Holy moly.  Happy anniversary.



STEVE:  Yay [trumpeting].



LEO:  And you have not missed - am I correct to say that you have not missed a week in three years?



STEVE:  Never one.  Never have we missed one.



LEO:  He's the Cal Ripken, Jr., of podcasting, ladies and gentlemen.  Unbelievable.  Wow, that's really great.  Our fourth year.



STEVE:  Yup, we're into year number four.



LEO:  I can't believe that.  That's really kind of amazing.  I think I proposed this to you when we were in Toronto.  You were visiting Call For Help as a guest.



STEVE:  Oh, I remember the moment.  I remember where I was standing when - you were over on the set.  Sort of if you think of the three locations in sort of a triangle, where you and Amber would do the opening, and then there was the place you went to do the...



LEO:  Home base place, right.



STEVE:  ...Call For Help stuff, yeah.



LEO:  And then Andy's set was the other set, point of the triangle, yeah, yeah.



STEVE:  Exactly.  And so you were at the corner of that triangle of three.  And you said, "What would you think about doing a security podcast?"  And I remember, well, first of all I said, "A what cast?"



LEO:  Yeah, because at that time I was only doing TWiT.



STEVE:  Yeah.  And I remember thinking, like, later, it's like, oh, I hope he doesn't bring that up again, you know.  Because, I mean, I just had no concept of what it was or what - and I remember thinking we're going to run out of stuff to talk about.  I've got maybe three weeks' worth.  You know.  But here we are in year four and going strong.



LEO:  Oh ye of little faith.



STEVE:  And with a long list of stuff to talk about still.  Actually the list is growing in the same way that, like, SpinRite testimonials, there are more coming in than I'm able to read, like on a weekly basis.  So it's like, okay, we're not running out anytime soon.



LEO:  Well, thank goodness.  Well, maybe not thank goodness.  But the hackers seem to be keeping ahead of us.



STEVE:  They are.  And frankly, Leo, I mean, this has been - it's been great for SpinRite for me to have a forum where I could tell people about it.  I mean, I even notice, as I mentioned to you before, you're using it now as a verb, which really says, I mean, and this has been my lifeblood for the last 20 years, so it's important to me.  So I'm more than happy to trade everything I know about security for helping to have our listeners understand that there is salvation when their hard drive dies.



LEO:  Well, bless you, Steve Gibson.  You know, I ran SpinRite actually last night because I've been having these kind of flaky results on the recording machine.



STEVE:  Really.



LEO:  Yeah.  But - and this is not the first time I've run it.  Remember I mentioned this before because it's a RAID 0, and it's been giving me these weird error messages.  And it bluescreened on me in the middle of TWiT on Sunday.  So I ran it all day Monday, nine hours.  Didn't find any errors, though.  I ran the number four; right?



STEVE:  And you ran it on the drives separately?



LEO:  No.



STEVE:  Oh, see, you really - I think you have to pull it out from behind its RAID configuration.  SpinRite will allow you to do that.  It doesn't modify the drive contents at all.



LEO:  Okay.



STEVE:  And I would run it on each drive separately because it could be that the controller is masking the errors from SpinRite.



LEO:  That must be it.



STEVE:  And it's definitely the case that SpinRite's not really talking to the drive controller itself, it's talking to the RAID controller.  So there's a bunch of magic that SpinRite does in terms of, like, at the low level of the ATA interface, where like it turns off retries, it turns off ECC, it's able to penetrate and get much, I mean, much more intimate relationship with the drive.



LEO:  That's what happened.  Okay, good, okay.  Because, yeah, what I get when I boot up, the RAID controller says there's an error on the first drive.  But I see no errors in SpinRite.  Second time I've run it.  That's what I'll do.  So I'll SpinRite the drive individually.  Okay.  I'll do that.  That's tonight I'll be doing that.  I'll let you know how that works out.



STEVE:  Cool.



LEO:  Yeah.  See, it's nice to have friends in high places.



STEVE:  Well, at least knowledgeable friends.



LEO:  I did want to ask you, actually, and I should probably ask you this off the show, but I'm going to do it anyway and put you on the spot.  You know we're making the ultimate gaming machine.  It's one of the things we're giving away, really fun, we've been having such a blast doing it.  Have you been following this?



STEVE:  I've heard some of it, yes.



LEO:  Colleen is building this amazing box.



STEVE:  She's a kick.



LEO:  She is.  I mean, you know, when you get somebody, a girl who can weld and build, and then she, you know, she's never built a water-cooled system, but she of course understands fluid dynamics very well.  And so she's done all the research, and she's come up with a really great design.  She had her own skateboard design company.  I mean, she kind of knows how this stuff works.  I mean, she did the 3D rendering of these aircraft aluminum skateboards.  Anyway, but what I would like to ask you is if we could - if I could get you to donate a copy of SpinRite to this.



STEVE:  Oh, in a heartbeat, of course, of course.



LEO:  Because you know why we really need it, we're using VelociRaptors, those new 10,000 rpm drives.  They're the fastest drives out there.



STEVE:  I would just give each of those drives to SpinRite before you even start your install and setup.



LEO:  Great idea.



STEVE:  There are a number of people who run SpinRite on drives just, I mean, even though it's new, they just run it so that SpinRite has a chance to just thrash it to death - hopefully not to death.  But you'd rather it then than later.



LEO:  Well, yeah, yeah.  You know what, I should have done that with the TriCaster because we only had one drive.  The new drive that I put in, I should have done that.  I will.  That's another thing.



STEVE:  Good preventative maintenance.



LEO:  We're going to have a SpinRite party tonight, baby.  I'm going to SpinRite everything in the house.  But that's kind of the great thing.  So thank you, that's a very nice offer.  I'm going to try to get all of our sponsors to donate hardware and software for the winner because, I mean, they're already getting an $8,000 computer.  But it's nice to, you know, I mean, they need SpinRite.  They've got these - and it's going to be in RAID 0.  They need it.



STEVE:  Yup.



LEO:  They need it.  All right, Steve.  Let's take a little look at the tech news.  But before we do, what are we going to talk about today?  We do have a topic today; right?



STEVE:  We've got a great topic, actually.  We're going to  basically talk about the "DNS - After the Patch" is what I would title this podcast.  As we all - we've talked for several weeks about this major vulnerability that was discovered by Dan Kaminsky back in February, and secret meetings which were held in Microsoft's campus in March, which resulted in virtually all DNS servers that were on the Internet having the ability to be patched, that is, patches made available to mitigate the window of opportunity of DNS spoofing exploits.  Well, there's been a lot of news since then because, well, in fact one Russian researcher has successfully exploited a fully patched, much more secure DNS server, BIND 9 with all the latest stuff, because it's harder to do; but the question is, is it yet hard enough to perform a DNS spoofing exploit, a cache-poisoning exploit, which we talked about in detail two weeks ago.



So we're going to talk about what has happened since and some interesting further steps that can be taken.  I'm going to touch on the ultimate, like, potential solution, which is something called DNSSEC, or DNS Security, which has been churning along for nine years and still hasn't gotten off the ground.  I'm not going to go into it in detail because that's a topic for an entire episode all by itself.  DNSSEC is very powerful, but it's got some real problems.  And then finally we're going to end up with, okay, like, we've used the term "hack" before.  What I'm going to describe is a way of further strengthening DNS that is like the ultimate hack.  It's like the definition of the word "hack," which we're going to have a lot of fun with, so...



LEO:  That sounds cool.



STEVE:  ...lots to talk about.  Lots of security news, as well.



LEO:  All right.  Well, let's start with the news.



STEVE:  Oh, yes.  Mac OS X got a major, an important update.  So I just wanted to mention that to Mac users.  When I turned mine on this morning it said, oh, we've got new stuff.  We've got an iTunes update and a big security deal.  And it had to do the whole shutdown sort of secret repatch the OS level kind of thing.  So it was a big deal.  So that happened.  Also we're recording this Tuesday the 12th.  This is the second Tuesday of the month, and this is a mega Patch Tuesday.  So by the time our listeners hear this on Thursday this will be old news.  But I wanted to make sure, as always, that they pay attention to this.  This is a 12-bulletin major security update from Microsoft.  Many critical vulnerabilities, remote code exploit, buffer overrun, rah rah rah, you know, standard routine.  So don't ignore this one.  This is a big one.  I haven't seen them all because, you know, we're recording this on the day.  I did try, I did ask Microsoft to give me an update try, and they said nothing yet.  It's like, okay, fine.  Well, later today it'll definitely be something.  So I wanted to mention that.



Also, in other security news, we've talked about in various contexts the controversial actions that Comcast was taking, this so-called "deep packet inspection" where they were selectively dropping BitTorrent connections, which got them into trouble.  The FCC voted three to two against Comcast's doing this.  I thought it was interesting that there were two people who thought this was a good thing.  It's like, okay, well, at least we got the majority.  It was three to two.  And what the FCC ruled was that Comcast violated federal policy by throttling Internet traffic for subscribers using BitTorrent filesharing software.  Now, Comcast rebutted, saying that this FCC network neutrality stance is just a policy statement and not an enforceable rule.  However, then the FCC went further and said that Comcast had a motive for its action.  Comcast was just saying, well, we were trying to, like during periods of high traffic use we were just trying to, like, let everybody have a fair share.  But the FCC said, wait a minute, you've got a motive because users downloading video files through peer-to-peer clients, specifically BitTorrent, could be perceived to be taking business away from Comcast's paid video-on-demand service.



LEO:  Exactly.



STEVE:  So it's like...



LEO:  It's anti-competitive.  What they're doing is anti-competitive.  They do the same thing in some, well, a Canadian ISP does it with Skype.



STEVE:  Right.



LEO:  Totally anti-competitive.  It's not about protecting the network.



STEVE:  And so fundamentally the people who have observed this have said that the problem was selective enforcement against BitTorrent specifically.  That is, it wasn't that Comcast was, like, throttling back all high band uses of anything.  They were targeting the BitTorrent protocol and deliberately blocking that while allowing other potential high bandwidth applications to just move through without any throttling at all.  So anyway, so I guess the point is that ISPs have rights to enforce terms of service.  But they can't, you know, the Network Neutrality guidelines say you can't selectively enforce bandwidth limitations.  You've got to do it across the board.



LEO:  Although, and while this is a victory, it wasn't really, I mean, it was - they didn't even punish them.



STEVE:  Right, exactly.



LEO:  There was no penalty whatsoever.  So...



STEVE:  It was just, you know, we're watching you and don't do that please.



LEO:  Don't do it.  And of course Comcast has said, but we never did.



STEVE:  Uh-huh.



LEO:  We don't do that.



STEVE:  Now, in the other really big news that came out of Black Hat, of course we've been talking about, pre-Black Hat conference, we were talking about Kaminsky's presentation, which I'm going to go into in detail when we get into the heart of our show.  But in other security news I wanted to let all of our listeners know that I'm aware of the presentation by two guys, there were two security researchers, one with ISS, IBM's Internet Security Systems, and the other from, interestingly enough, VMware.  These guys have put together a very meaty paper.  It's a 50-some-odd page, I think 54-page paper where they demonstrate how to bypass Vista's security, this much-heralded ASLR, the Address Space Layout Randomization that we've talked about before, and DEP, the Data Execution Prevention, which were like the big deals that Vista was adding to beef up security beyond XP.  So two weeks from now we're going to - that'll be the topic two weeks from now, given that nothing else more horrible happens in the meantime.  And the title of that one will be "Vista Security Bypass?"



So I just wanted to let our listeners know I'm aware of this to prevent everyone from having to go to GRC.com/feedback and tell me, hey Steve, Vista security has been bypassed.  We're going to look at that.  There is some - there are two sides to this, and we're going to take a balanced position rather than going all crazy and saying the sky is falling, you know, how serious is this, how does it work, what does it mean, and is this really a problem sort of deal.  So we'll take a look at that in depth in two weeks.



LEO:  It would be a shame.  I mean, Vista has actually been much, much, much more secure than XP for the last 18 months.  I'd be very sorry to hear that it wasn't as secure.  So we'll look forward to that a couple weeks hence.



STEVE:  And that's a perfect, a perfect segue to my further saying that, yes, and it's one of the arguments against this being a big deal is that this isn't suddenly - this doesn't suddenly make Vista a lot less secure.  Vista's more secure for many reasons, sort of a whole landscape of things that were done better.  But the question is, how much less secure does this make it?



LEO:  Right, right, right.



STEVE:  And, finally, I got a really nice note from a Security Now! listener.  Neil Abrahams in the U.K. wrote about his experience, actually his whole experience with GRC, which no one has ever really mentioned explicitly before.  He said, "Hi, Steve and team.  Kudos at the speed, quality, and easy of use of SpinRite 6.0.  By day I'm an IT consultant, so naturally I'm looked to by the family to sort out the problems.  I got a call from my virtual father-in-law" - and I'm not quite sure what that is.  But he's a computer guy, so he has a...



LEO:  Maybe he's virtually married.  I don't know.



STEVE:  He has a virtual father-in-law - "saying the family laptop could not boot up, and that they had tried the recovery options such as safe mode, last known good configuration and so forth, those boot-up time options in XP.  On receiving the laptop I immediately removed the drive and inserted it into my USB drive caddy so I could access photos and documents that had not been backed up before moving on to fix the Windows installation.  I ran into the first problem when my desktop would not recognize the drive.  I also checked it on my laptop, and still no drive was recognized.  By this point I assumed the drive was physically damaged and that I couldn't recover any data whatsoever.  To check that theory I put the drive back into the laptop, the original laptop, and booted into its BIOS to check that the drive was being recognized, and sure enough it was.  Having been a ShieldsUP! advocate and then becoming a Security Now! listener when it first began, I immediately thought that if the drive could be seen by the BIOS, then SpinRite could fix it."  And of course that's proper logic.



So he says, "I logged onto GRC, purchased and downloaded my first copy of SpinRite 6.0, and installed it to my USB flash drive.  I plugged the USB into the laptop and booted that into the SpinRite program.  I chose the Level 2 option, and 20 minutes later it had finished.  On reboot, Windows started up and I was able to log on and back up the data, albeit very slowly.  The service and quality of the website in terms of" - and he's talking about GRC's website - "in terms of simplicity, ease of payment, and download facilities is what makes GRC a world-class business.  In less than five minutes I was running the SpinRite recovery and had the problem resolved in 20.  Smiles all around from everyone.  Cheers.  Neil Abrahams in the U.K."



LEO:  That's neat.  It's not an easy thing to do, to make a useable website.  And nowadays, I'll tell you, the pros get involved in this.  And you did it all by yourself.  I think that's great.



STEVE:  Yeah, you know, I wanted it to be mine, so...



LEO:  I'm the same way.  I'm the same way.



STEVE:  So NIH.



LEO:  Yeah, we're very old-fashioned, you and I, in that regard.  There were some other, you know, you could probably have done a whole show on DefCon.  I mean, there were some other things.  Did you see the Medeco lock hack?  That was amazing.  You know, these Medeco - they're, like, twice as expensive, these Medeco locks, because they're unhackable.  And for some reason there's something about software hackers that they really like a little hardware hacking and lock picking as, you know, kind of a relaxation?



STEVE:  Right.



LEO:  Did you ever do that?  They have lock-pick contests and stuff?



STEVE:  Oh, I can pick a lock.



LEO:  Yeah, see, I knew it.



STEVE:  I had my youth.



LEO:  It's funny, I find it fascinating, it's very, very common among geeks that they did safecracking and lock picking, too.  I don't know why that is.  But anyway, these Medeco locks are - I'm sure these Medeco people hate DefCon.  Hate it.  So they showed how you could just get a low-res picture, you know, use your camera phone to take a picture of somebody using their key.  You don't have to have a great picture of the key.  And then they show how you can blow it up and use it to cut out a credit card and actually open the door with this credit card.  I mean, it was kind of pathetic.  I thought, boy, that's, I mean, this is what's interesting about technology has really advanced the abilities of hackers.  And then there was another presentation which the folks at the MTA must hate, how to hack the Boston subway cards with a cloning attack so you can ride for free forever.  And of course...



STEVE:  It really is those kinds of things and the diversity of them are one of the things that make DefCon so fun is it's just...



LEO:  It must be fun.  Have you ever gone to that?



STEVE:  Nope, I never have.  I have certainly read the reports that come from it, though.



LEO:  You and I should - maybe next year we can sneak in.



STEVE:  That'd be cool.



LEO:  We don't have to sneak in.



STEVE:  I don't think we have to, no.



LEO:  No, we don't have to sneak in.  Patrick Norton used to go all the time.  He said, I'm not - I said, bring a laptop, and you can call us.  He said, are you kidding, I'm not bringing a laptop to DefCon.



STEVE:  I remember him saying that, yes, yes, yes.



LEO:  Yes.  Those guys are crazy.  I'm not getting online there.



STEVE:  Unh-unh.



LEO:  So thank goodness that two weeks ago, Steve, you gave us an update on how DNS works because then - actually it was more than - that was four weeks ago.  Because then we talked about this DNS flaw and how it worked and the presumable fix.  Well, now the fix is broken.



STEVE:  Well, okay.  Yes and no.  We, as we really covered clearly and carefully two weeks ago, DNS was literally never designed to be secure.  Like all the original protocols, it was designed just to work.  And back then just the fact that it did work was a miracle.  I mean, they couldn't believe that, like, this whole notion of autonomous packet routing was as robust as they designed it to be, where you just stick a packet on anywhere on the Internet with a unique destination IP and it just finds its way there kind of all by itself with the help of routers bouncing it from one router to the next, and it ends up at its destination.  So DNS was so insecure - and I don't even like to use that word because it was just never - security was not part of anyone's thinking back then.  And I remember reinforcing that by saying, you know, SSL, the really cool layer on top of TCP that the Netscape guys added, it didn't exist in the beginning.  There was no way to encrypt communications on the original Internet.  That was an afterthought.



And similarly, DNS had no, virtually no spoofing protection because the servers at the time would open one outgoing port and would use it for emitting all of their queries, meaning that all of the responses would come back to the same port, and the 16-bit transaction ID was just a counter that counted up linearly to help the server determine which, when replies were coming back, to help them match up the replies with the queries.  So the fact that it used a fixed outgoing port for its queries and that it used a linearly increasing counter meant that faking or spoofing replies was child's play.  So because that was a hole that was just too big, one of the early improvements in DNS was simply to change that 16-bit counter into a 16-bit pseudorandom number.  So that value would be jumping all over within a 16-bit space which we know is 64K, or 65536, in an unpredictable fashion, hopefully unpredictable.  In fact, there were some pseudorandom number generators that were not sufficiently unpredictable.  And so another attack was getting a few queries from a server and using those to sort of lock onto its pseudorandom number generator and again being able to spoof replies and poison the DNS cache and produce all kinds of mischief that we know follows from DNS cache poisoning.



So what happened in - what Dan's realization was - and I should mention his Black Hat talk was everything we expected it was.  There was nothing that he revealed that hadn't already been independently reverse-engineered just from the knowledge that there was a problem, which I think is really interesting.  All he had to say, as he did in early July, was there's a big problem, we're not going to tell you what it is, wait a month, and I'm going to let everybody know in Las Vegas.  Well, a couple weeks later everyone had guessed.  And just by virtue of the way the 'Net works, people improving on each other's guesses, they figured it out, built a proof-of-concept, released an exploit, and it was possible...



LEO:  It's pretty amazing how the 'Net works that way.



STEVE:  It really is.



LEO:  You can't, you know, people think it's kind of like the old days, you can keep a secret.  You really can't.



STEVE:  No.  And in fact, all it took was just people knowing there was something.



LEO:  Right.



STEVE:  And so they thought, hmm, what could it be?  And you think it could be this?  And someone will say no, because of that.  And okay, how about this?  Oh, now that's interesting.  How about maybe if you made it green, then it would work better.  So, I mean, it just, you know, it just happened.  And this thing was born with Dan saying nothing.  Now, Dan's talk did evidence, however, that he had been thinking about this a lot longer.  So, and as sort of the buildup to this, he pushed the limits of what it means for DNS to be broken, as badly broken as he discovered it was in February.  And, I mean, it really was badly broken.  It's cool, when you think about it, that this - cool in a certain twisted sort of way - cool that something this bad hadn't been independently discovered until something was known to be wrong, and then it was found.  Because, I mean, it turns out that when HD Moore added this exploit technology to his Metasploit framework, and making it very command-line run-able, you could basically poison an arbitrary domain on an arbitrary name server in 10 seconds.



LEO:  Now, wait a minute, you just said somebody's name and somebody's Metasploit.  What are you talking about?



STEVE:  HD Moore is the guy, the hacker, who maintains the Metasploit Framework, which is a very mature, sophisticated, growing over time framework that hosts exploits.  And so it sort of - it just provides an easy way of, like, adding a small bit of code to do the work side of an exploit where the rest of the foundation is sort of there.  And so this is - there are traces of the Internet, sample runs of giving a command to take over, to, like, poison the name cache on a DNS resolver.  And you see it running, and you see it saying, okay, doing 10,000 queries, testing; doing 10,000 queries, testing.  So what he would do is he would blast a bunch of queries, send a bunch of spoof responses, and then ask that name server, the targeted name server, for the record he was trying to replace, see whether he'd succeeded.  And if not, do it again.  And it would take, like in one case, like, 13 iterations of this over the course of maybe 10, 15 seconds, and it would say "success."  And you would see that that server was now returning the fraudulent, deliberately inserted, replaced record from its cache.  So that was 10 to 15 seconds.



We knew that the best we could do was to use source port randomization, as I described two weeks ago, to essentially give us more bits.  The idea is if all we can do, if the source port is fixed, then the only thing the attacker doesn't know are the 16 bits of transaction ID.  So you just guess a lot.  And because there aren't that many combinations of 16 bits, you're going to get a collision.  So, and the collision meaning that you guessed the transaction ID of an outstanding query that that server is waiting to have a reply from.  You pretend to be the replier, the authentic replier, and your malicious reply is accepted as being valid.  So we want more bits.



So what they did was they said, okay, well, we can't change DNS.  We can't change the protocol.  But we need more bits.  So they said, oh, let's use source port randomization.  That'll give us a bunch more bits, depending upon the specific configuration, as many as another 16.  You actually lose some because many systems can't allocate ports down in the so-called "service area," the first 1,024 ports.  And other configurations just have problems randomly allocating UDP ports all over the remaining space.  For example, Microsoft's DNS server reportedly now, the new updated version, allocates about 2,500 ports.  It, like, preallocates them, and then those it uses.  Well, 2K is 11 bits.  So that's giving us essentially an additional 11 bits on top of the 16.  So we get, what, 72 bits total.  So that's a lot more.  It makes the attack - it makes the old attack 2,000 times harder.



LEO:  But not impossible.



STEVE:  But, yes, that's the point is we want more bits.  We're getting as many bits as we can within the existing framework.  So what happened was late last week a Russian physicist, Dr. - looks like - I had to practice his name.  I have been practicing it.  And now I look at it...



LEO:  I had the same issue on the radio.



STEVE:  E-v-g-e-n-i-y.



LEO:  Evgeniy.



STEVE:  Evgeniy.  And it looks like Polyakov, maybe

P-o-l-y-a-k-o-v.



LEO:  Sure, that's good enough.  Polyakov.



STEVE:  Anyway, he blogged on Friday that he had used two machines on a gig Ethernet, so closely coupled to the name server, meaning a ton of queries and replies.



LEO:  Far more than you would in any normal circumstance.



STEVE:  Well, and difficult, arguably very difficult across the Internet.  But it took him 10 hours.  In 10 hours he got a collision on a state-of-the-art, recently fully patched, version 9 of BIND that had source port randomization and strong transaction ID pseudorandom number generation.  So a state-of-the-art BIND took him 10 hours.  So his point was that, okay, that's hard to induce that across the Internet because of the number of packets required.  But a compromised trojan operating inside of an organization or inside of an ISP has that kind of intimate connection to the DNS server, meaning that an overnight or over weekend, meaning sort of like when no one's really paying attention, attack could succeed.  And so basically we're seeing a proof of concept that, yes, it's no longer 10 seconds, it's now 10 minutes, and only on an intimately connected environment where you've got a lot of bandwidth available.  And the people that have been countering this argument say, yeah, if you saturate a gigabit Ethernet, people are going to notice.  You got lights blinking and wires smoking.



LEO:  It's not exactly a surreptitious attack.



STEVE:  It's not very subtle, no.  So but that has spawned, then, some follow-on dialogue.  I did want to respond to a couple things.  I wanted not to forget to tell our listeners that I've got a bunch of links on this episode's show notes.  And actually they're online right now, Leo, so you can tell Dane and Tony that they can grab them and move them to your site also.  I've got a link to Dan's - the PowerPoint presentation that Dan used, Dan Kaminsky used at the Black Hat conference, and also a link to this Russian physicist's page where he describes it, and all of the follow-on blog replies, which make an interesting read, as well.  And there's one other link, I can't remember what it was, but I think there were three there.  So I've got stuff up there on our show notes for this week that people may find interesting.



One of the things that Dan Kaminsky said I sort of take issue with, but he has a point.  And that is, he talked about how even SSL, our much-beloved Secure Sockets Layer protocol that we depend upon for authenticating and encrypting our connections, we authenticate inasmuch as we check the certificate of a site we're connected to to verify that this is really them, and we know that it completely scrambles our communications so we're not - no one can - no man in the middle, nobody intercepting our traffic or listening passively to our traffic is able to obtain the data that we're sending in the clear.  So Dan, I think trying to make a little more of a deal, big deal about DNS than is warranted, was saying that SSL depends upon DNS.  That is to say, everything depends upon DNS.



Well, okay.  Where I agree with him is, the point is, yes, that's true.  Nobody uses IP addresses.  I mean, obviously I don't mean that in an absolute sense because we were talking last week about how using an IP address to access a test to see if your DNS was poisoned would be a good thing to do because you can't spoof an IP address.  On the other hand, IP addresses are too static.  And so there are problems associated with using an IP address, aside from the fact that they're hard to memorize and nobody - people know GRC.com and TWiT.tv.  They don't know our IP addresses.



LEO:  Right, right.



STEVE:  Exactly.  So technically he's right.  My argument is that, if DNS had been spoofed, then the bad guys who were trying to spoof your connection and to whom you were connecting, if you believed you were setting up a secure connection to a remote site that had been spoofed, well, your certificate protects you from that.  That is, the fact that you're able to check the remote site's certificate and verify that it's really them.  And we talked about, you know, for example, spoofing sites simply would not bring up an SSL connection during logon, whereas a legitimate site would do so.  So technically you are protected from spoofing as long as you're aware that you need to have a secure connection and you check to make sure that the certificate you've received is really theirs.



Now, where Dan is right is that, okay, well, what about the way they got their certificate, or the way you got your updates to your certificates or your root certificates, for example.  I mean, his point was since ultimately, like ultimately ultimately ultimately everything is relying on DNS, this notion of root of trust is subverted, the idea being that a certificate authority is a trust root.  It's something you - I'm trusting VeriSign or Network Solutions or GoDaddy to really check to make sure that these are valid certificates they're issuing.  And so we've talked about certificate chains.  Well, that's a chain of trust where at each step you have enforceable trustability.  Therefore when you get to the end of the chain, as long as all the links are trustable, then the result is trustable as long as the root is trustable.  So he's saying, okay, except that ultimately all of those things that came before relied on DNS.  And if DNS is not fundamentally trustable, then nothing else can be.



And so it's like, okay, granted.  Except that we have to assume, I mean, I do assume that when Microsoft is sending me a certificate batch update, we know that their updates are encrypted, and we know that they're digitally signed, and we know that that can't be spoofed.  So it's like, yes, pedantically everything relies on DNS.  Practically, while this is a bad problem, I wouldn't go so far as to say that SSL is compromised by DNS being compromised.  That, I mean, it requires a little too much stretching from theory to reality.



LEO:  Well, so this - but I have to say these kinds of attacks often are just the precursor to a fast - remember it took for a while a long time to do WEP.  And then they got faster and faster and faster.  Does it seem reasonable that they might get faster?  Or is it just really, I mean, you've got so many bits now.  What is it, 71 bits.



STEVE:  Well, and so that's where we're going to go next with this discussion is the fact that we've done well, the question is have we done well enough.



LEO:  Well enough, okay.  A clever hack coming up, I take it.



STEVE:  Well, not yet.  We're going to - we have a few other things that are interesting things that people are discussing.  So first of all, someone has proposed that queries be - and actually the engineering term is "debounced," which I think is sort of a funny, is a funny term in this case, the idea being that you double query.  You make a query, and you get the response.  But you don't trust it until you query again.  And the idea being that simply querying again and requiring, essentially debouncing or despoofing the query, if you got a different answer because you got the right one either time, either the first or the second time,  then you say, whoops, wait a minute, this is suspicious, and then you engage some, like, deeper querying logic where you look to see if there's a lot of replies coming in, or you issue more queries and do some majority voting sort of approach.



And the argument against that I thought was really interesting because it tells us a lot about where DNS is in the world.  Okay.  Double, just doing two queries would obviously double the amount of DNS traffic.  It would double the load on the resolvers, those doing the querying, and on the authoritative name servers, those providing the authoritative records.  We don't have a hundred percent spare capacity in our DNS network today.  So we don't - we can't even double the number of packets that we're sending.  DNS servers are so busy, and their links are so near saturation, that they are more than half full.  They are more than half capacity.  And so even something like double querying we cannot do.  There's just - there isn't the capacity in the existing Internet DNS to allow for that.



So that automatically rules out the next idea, which was, okay, this whole problem is from spoofing, and UDP protocol is infinitely spoofable because nothing prevents you from putting whatever source IP you wish into an outbound packet.  Well, okay, not having raw sockets prevents you, but UNIX systems and Linux systems do allow full raw sockets and allow the programmer to build any packet that they wish and send it out on the line.  So with those limitations, UDP is absolutely spoofable, where TCP is not.  As we've talked about and understood TCP protocol, the whole overhead of that three, the so-called three-way handshake, where we send a SYN packet to the place we want to initiate a connection, they send a SYN/ACK back, which is their SYN and acknowledging ours, and we send a final ACK back to them acknowledging their SYN.  So that three-way handshake, three packets that establishes counting for the packets that will follow, then you can send a query and receive a reply.  Then you've got to say I'm done now, so you send a FIN packet, and they respond with a FIN/ACK.



Well, that's, if you count all those, three to initiate, two to shut down, plus two in the middle for the query and the reply, you're at seven packets.  So you've gone from two packets, a simple UDP query and reply, to a seven-packet exchange.  Now, there's actually a way to save one because it's a little-known fact in the TCP protocol is that you are able to send data with your first ACK.  So that would cut out - that means that when the querier is sending its ACK back to the server, it could include its query with that if the stack at the receiving end was fully TCP spec compliant.  And it's not clear whether they are or not, so it's generally not done.  But even then you're at six packets, which is three times the number of packets required to make your normal UDP query and replay.  So that's even worse than, you know, using TCP is worse than just double querying.



So, finally, the issue of DNSSEC comes back up.  Now, DNSSEC is the acronym for DNS Security.  This is a very complex, very sophisticated sort of next-generation secure DNS which has been bubbling along, simmering for about nine years now.  And it just - it never seems able to get off the ground.  A couple times the various groups have attempted to ratify it and lock it down and say, okay, this is what we're going to implement.  Then they start looking at the implementation cost in the real world and inevitably back off again and say, oh, wait a minute, that means that if the root server changed its private key, it would have to send out 22 million copies of its public key, you know, that kind of thing.  I mean, it's like, oh, okay, that's not good, how do we fix that?



So the problem is, DNSSEC is what we're going to end up with ultimately because on the level of pedantic purity Kaminsky is right, that everything relies on DNS ultimately.  And if we don't have a strong foundation of trust, nothing we build on top of that non-trustable foundation can by definition be trusted.  So there's work towards DNSSEC.  And we're going to give it a complete episode because it's very sophisticated.  But here's the fundamental problem.  It is a public key technology, the idea being that it signs, DNSSEC signs, for authentication purposes, queries.  Or you sign responses to queries so that the receiver of the response is able to check the digital signature of what it's received from the authoritative name server to verify its correctness.  Interestingly, they do not encrypt the data.  So it's sniffable.  But the presumption is, all this is is an IP address, so everyone - and that's public information.  So let's not spend any time encrypting what is already publicly known.  So it is, however, authenticated and digitally signed.



Well, digital signing requires a public key process which has substantial processor overhead.   So in addition to making the packets a little bit larger, both the sender and receiver, the sender would have to generate the digital signature; the receiver needs to verify it.  And so again we're talking about substantial new overhead added to an existing structure.  And for that reason it just - they can't get off the ground.  John Markoff, writing for The New York Times recently, noted that several governments, Sweden and Puerto Rico, have adopted DNSSEC.  And the United States, our government, is likely to deploy it, at least for the .gov domain.



LEO:  Yeah, in an official capacity, where you have lots of money and a real strong need for security.



STEVE:  Exactly.  And essentially, I mean, if this were something you were doing from the beginning, this is the way to go.  So you can imagine a smaller infrastructure, like you may have in Sweden and Puerto Rico, or just determination.  They say, we decided this is important.  We're going to implement this.  And so it means replacing the existing iron with much stronger iron, and maybe in fact adding hardware accelerators for SSL, I mean, sorry, for PKI, Public Key Infrastructure acceleration, so that you're able to offload some of this in the hardware.  I think it is clear that we're going to see an increasing market for hardware acceleration of public key operations moving into the future because this is the way to secure things where your traffic is eavesdroppable, where it is possible for someone to see what it is you're sending.  As we've discussed before, public key technology solves that problem.  So there is one really, really clever solution that we'll talk about next.



LEO:  The clever hack solution.



STEVE:  Oh, this is a hack.  This is a hacker's hack.



LEO:  So what is this - I'm excited.  I'm dying to hear this hack, this workaround.



STEVE:  This is the galactic hack.  I don't know if I can think of something that is more a hack, more sort of like, oh my goodness, but clever.  And so, I mean, this is the definition of a hack.  And it works without any additional overhead, without any additional packets, without any additional anything within the existing infrastructure of DNS.  So, and remember that, as I said toward the beginning of the show, what we want is more bits.  The idea being, we want the query that the resolving name server sends out to contain more entropy, more bits of randomness which the responder will be able to easily send back, such as the matching query ID and the matching port number, but also something else.  What more could it possibly send back within the existing definition of DNS?  Okay, get a load of this.  This is hack of the year.



LEO:  All right.



STEVE:  It's referred to as the 0x20, or the 0X20 hack.



LEO:  Is that the hex?  Is that, like, hex 20?



STEVE:  Yes, that's hex 20, 0x20.



LEO:  Just space; right?



STEVE:  Actually, that's very good, Leo, hex 20 - wait a minute.



LEO:  Yeah, it is.



STEVE:  Yeah, hex 20.  But it refers to the 20 bit because that is the difference in an ASCII representation of text between uppercase and lowercase.



LEO:  Right.  You add that bit, and it's uppercase.



STEVE:  For example, 41 and 61 are the hex for upper and lowercase A.



LEO:  Right, right.



STEVE:  The difference being that 20 bit.  So get a load of this.  The DNS spec, the original RFC that everybody wrote to and coded to and follows, says that case is not significant, but it will be preserved.  Meaning that - and you'll notice this.  You could do GRC.com in all uppercase, or GRC.com in all lowercase, or GRC.com in any random combination of upper and lowercase, and you'd get to GRC.com.  And I notice that, like, TWiT.tv is capital T, capital W, lowercase I, capital T; right?



LEO:  Right.



STEVE:  And that works.  The point is, case doesn't matter.  But in a DNS query and response, case is preserved, meaning that when I issue a query, the response I get comes back with the same case of the alphabetic characters as I issued.  Yet the authoritative name server that is checking to see if it's got a match within its records, it ignores the case, doesn't care if the alphabetic characters are upper or lower, to find a match.  That gives us more bits.



LEO:  Oh.  That is clever.



STEVE:  Oh my goodness, isn't that just incredibly cool?  What it means is that the querying server can randomly upper and lowercase all the alphabetic characters in its query.  So, you know, we've got www.domainname.com.  So we've got, okay, www, there's three; com is three more alphabetic characters.  Plus however many alphabetic characters are in the name.  And more if you are several - if you have several domain, dotted domain names.  All those characters can have a random case.  They will go to the resolver that will - I'm sorry.  They will go to the authoritative name server that will ignore your wacky casing that you've done.



LEO:  Right, because it's case insensitive, yeah.



STEVE:  But it will return your - it will return in its reply, it returns the same case that you sent it, which means you can - you the querier, who is trying to be spoof-resistant, can verify...



LEO:  Oh, if it's the same one you sent.



STEVE:  Yes.



LEO:  But wait a minute.  Numbers, dotted quads are all the same case.  How would it reply in a different case?



STEVE:  Well, okay.  The idea is in the query goes the domain name...



LEO:  Oh, in addition to.  Okay.



STEVE:  In addition to.  So the domain name - basically the response echoes the query and adds the answers.  So you get back what you queried as part of the answer.



LEO:  Plus the dotted quad.  But now if somebody's in the middle, if they're doing a man in the middle, they're going to see your randomly capitalized query.  So can't they just copy it back?



STEVE:  Oh, Leo, DNS is completely hosed by man in the middle.  Man in the middle...



LEO:  Oh, this doesn't protect against that.  This - okay.



STEVE:  No, no.  In fact, man in the middle is a single query attack because if you're able to see the query and block the reply, you simply respond because you know exactly...



LEO:  Whatever you want, right.



STEVE:  Exactly.  So and then...



LEO:  Okay, all right, all right.  So this only is good against cache poisoning.



STEVE:  Well, this is good - well, and which is the problem that we're trying to solve.  This is good against a third party trying to guess queries in order to spoof replies.  What this means is the query is now much more difficult to guess by the number of alphabetic, you know, two to the power of the number of alphabetic characters in the name being queried.  So, for example, there could easily be 10 alphabetic characters - www and com gives us six.  Seven, eight, nine, 10, so even a four-letter domain would give us ten additional bits.  Well, 10, that's another 1,024 possibilities.  So we've just added 10 bits of difficulty, looking up www and a four-letter domain, and many domains are much longer than that.  So it's just, I mean, that is a hack.  I mean, it's like, it's ugly, but it works.



LEO:  So that's just something you obviously have to patch the DNS servers to do.



STEVE:  You don't have to patch the authoritative name servers.  That is to say, they're already programmed to echo the incoming packet's case and ignore the incoming packet's case.



LEO:  Oh, so it only would have to be the querying servers you'd have to change.



STEVE:  Right.  So, I mean, just as we - we just changed the querying servers this month so that they would do reliable source port randomization.  So we would just need to change them again if the decision were made or if anyone wanted to make the decision, or you could imagine this would be, you know, all this stuff is open source, in the case of BIND, for example.  So you could have a BIND compile time flag saying I want this server to employ the 0x20 hack, and then your build of your BIND would issue queries with random alphabetic case on all the alphabetic characters, thus making itself far more difficult to spoof.  And the beauty is it would automatically work with all the other servers on the 'Net that don't need to be changed.  So this is something that individual, for example, BIND users, companies, ISPs, end-users, could easily do when this is an available compile-time or run-time option of BIND that just makes that one server much more resistant to spoofing.



LEO:  Easy thing to add.  But it would be a patch.  You'd have to change the send, and you'd also have to remember that and the query and look at the result and make sure that they matched.  But that's an easy compare.  That's pretty fast.



STEVE:  Right.  So we're talking, exactly, we're talking additional code.  Already obviously there is code which verifies that the incoming port and the incoming transaction ID match up with what's expected.  So you just increase the expectation to verify that the incoming reply had case of its alphabetic characters that matched what you sent out, which is what you were expecting.  Right now, no servers, as far as I know, care.  So all you need to do is to add that they care about matching returning response case, and then randomize your outgoing case, and you've got a much harder to spoof server.  Just you.  You don't need anything of anybody else.  Your server is now substantially more difficult to spoof.



LEO:  I really like that.   So...



STEVE:  It's so cool.



LEO:  Is there any move to do this, to implement this?



STEVE:  It's too early.  This is just hot on the wires right now.  People are beginning to talk about this.  It's like, hey, you know, why not?  It's more bits.



LEO:  I'm presuming that there's some sort of a process where people would want to vet it and think about it and really see, oh, does this really work, would it really solve the problem.  And of course always with fixes like this there's always some physicist named Evgeniy Polyakov who's going to come along and say, oh, yes, but we just do this.



STEVE:  Well, okay.  So counter arguments.  What about, like, all numeric domain names?  Okay, well, fine.  I don't know of any that I've typed in recently.  But sure.  This is the amount of protection is a function of how many alphabetic characters are in the lookup because it's only those whose case you can change.



LEO:  I have a domain name, for instance, 8888AskLeo.  That's the phone number for the radio show.  But there're still six alphabetic characters in there plus the dotcom, that's nine.  And plus if you do www, that's 12.



STEVE:  Yes.  And it's like, okay, it's free.  These are free bits.  These are bits that nobody was thinking about.  It's like, wait a minute, the case bits.  They're preserved, and they don't matter.  So let's make them matter in terms of matching on the verifying the response because they already don't matter over at the query end where the name server, the authoritative name server ignores the case, as we already know.  You can put in capital GRC.com or lowercase GRC.com.  The query typically goes out with that case preserved, and it comes back the same way.  It just hasn't mattered until now.  We make it matter, and then our own use of DNS is much more difficult to spoof.  That's just a tremendous hack.



LEO:  It is, I mean you say it's extra bits.  I mean, it's not exactly bits.  I mean, I guess it is if you were going to try to brute force it, it's quite a few bits.



STEVE:  Yeah, well, your replies would then have to...



LEO:  To be case sensitive.



STEVE:  ...be randomly upper and lower casing all of the ASCII also and hope that you get a collision.  And, well, so now you've got to get a match of port number and transaction ID; and every single character, every ASCII character in the query doubles the difficulty.  So if that's 12 ASCII characters, that's doubled 12 times is 4,096 times more difficulty.



LEO:  That's good.



STEVE:  So, yeah, it's really cool.



LEO:  It's helpful.  Wow.  That's neat.  Somebody's really kind of thinking out of the box there to come up with that.  I like that a lot.



STEVE:  And it's, yeah, I mean, and the thing I like about it, too, is again, when this is implemented in BIND, I know that in our own user groups we've got a lot of people running BIND.  And they're not happy, for example, maybe their NAT router is messing up source port randomization so they still feel too vulnerable.  They could compile a version of BIND with this on, with the 0x20 hack turned on, and just them get more spoofability protection, and nobody else needs to change anything else on the Internet.



LEO:  Wow.  That's really neat.



STEVE:  It is neat.



LEO:  That's really neat, yeah.  Steve, you've done it again, my friend.  You've come up with a very interesting show all about DNS and potential flaws.  It's as you said before, it's a seesaw battle back and forth always.  Nobody gets the upper hand forever.



STEVE:  That's true.  But people are now worrying, after hearing the Russian physicist hacked his own local server on a gig-E in 10 hours, it's like, okay, DNS is too important for us not to do something.  Now, if nothing else, this whole drama over the last month could provide necessary steam for DNSSEC.  That is, ultimately incorporating public key technology into DNS will really strengthen it.  I mean, make it as strong as it arguably needs to be.  But the problem is it's been so expensive in terms of the overhead that DNSSEC brings, that it just hasn't happened yet.  So the least that'll happen is people are thinking, ooh, you mean that it's still not fixed?  It's better, but it's still not fixed?  And it's like, yes, it's not ultimately fixable.  All we can do is raise the bar.  So using case in the query names raises the bar substantially.  For example, it raises it more than Microsoft's own port randomization change did.  Because reportedly they only preallocate 2,500 ports.  They're only giving us another 10 bits.  We can get that much using case sensitivity easily.



LEO:  Wow.



STEVE:  So it's a good thing.



LEO:  Yeah, it is a good thing.  And next week we're going to do a question-and-answer session.  But the week after, let's talk about DNSSEC, why don't we?  Is that what we want to do next time?



STEVE:  No, remember, week after next we want to talk about the interesting presentation at Black Hat where these guys have bypassed Vista's much heralded...



LEO:  Oh, that's right, we've got to do that.  Then we'll do DNSSEC later.  But I think that's worth talking to.  Yeah, we don't want to get too DNS heavy.  And I think this Vista thing is more - see, the thing about this DNS is it's not an end-user problem.  There's nothing you can do about it except to encourage your ISP to do it.



STEVE:  Oh, oh, oh, but Leo, I mean, the reason I wanted to spend another episode on this is the end-users are really freaking out.



LEO:  Rightly so.



STEVE:  I mean, it's not something they can fix, but it's something they want to understand and, for example, have their general level of spoofability awareness raised.  It's like, wait a minute, is this really eBay.com?  I am going to actually check my security certificate rather than...



LEO:  Nobody's doing that.



STEVE:  ...just assume it's okay.



LEO:  I'm not even doing that.  And these exploits are in the wild now.



STEVE:  Yes, yes.  This is now being actively exploited.  There is, out in the blogs, there are all kinds of reports of these tools being employed against weak servers.



LEO:  Wow.  Oh, the bad guys, they are bad.  But Steve Gibson is here  There's no need to fear, Steve is here.  His website is GRC.com.  Great security stuff there.  He's working on a new security program that's going to be very cool.  I look forward to that.  But you can also find ShieldsUP!, Shoot The Messenger, DCOMbobulator, and even Wizmo, a great little gadget for your desktop, XP or Vista, all at GRC.com.  SpinRite of course is the obvious choice there.  It's a must-have, the must-have hard drive maintenance and recovery utility.  I'm going to have a SpinRite fest right after the show today.  



STEVE:  Yes, it sounds like you are, Leo.  That'll be great.



LEO:  A lot of spinning to do.  And you'll also find 16KB versions of the show and transcriptions, too, at GRC.com.



STEVE:  I will remind our listeners that GRC.com/feedback is where to go to send me questions, which I scan through in preparing our every-other-week Q&A episode.  So GRC.com/feedback.



LEO:  Our first Q&A episode of our fourth year, Ollie.



STEVE:  Of the fourth year.



LEO:  That's unbeliev- mind-boggling.  You know, it's funny, too, because we are dealing with much more sophisticated stuff as time goes by.  Things like this DNS stuff is pretty sophisticated.  But...



STEVE:  That's cool.



LEO:  ...that's what we do.  Thank you.  That's what Steve does.  I just sit here and go, oh, yeah, I think I understand.  Thanks, Steve.  I really appreciate it.



STEVE:  Thanks, Leo.  Talk to you next week.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#158

DATE:		August 21, 2008

TITLE:		Listener Feedback Q&A #48

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-158.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 158 for August 21, 2008:  Listener Feedback #48.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, time to protect yourself and your systems and your Internet.  And here he is, ladies and gentlemen, the star of our show, Mr. Steve Gibson.  Hey, Steve.



STEVE GIBSON:  Yay.  Hi, Leo.



LEO:  It's good to talk to you.  Steve is, of course, the guy behind SpinRite and many other wonderful security programs, as well, like ShieldsUP!.  And he was the guy who first discovered spyware and let the world know about it, actually wrote the first spyware program but quickly passed it on to the folks at Ad-Aware, let them do the job.  And he joins us every week to talk about the latest in security.  This is a Q&A week, isn't it.



STEVE:  It is a Q&A week.  I've been having a ball for the last couple weeks coding a set of pseudo DNS name servers for GRC's forthcoming very, very high-quality DNS spoofability test.



LEO:  Oh, cool.  Oh, cool.



STEVE:  So it's going to be extremely nice.  I'm real - I've just been having a ball.  It's like there's nothing I like better than just keep my head down in the code and...



LEO:  You love coding, don't you.



STEVE:  I do.  It's just - it's just perfect.



LEO:  I've done - I've been, you know, I'm learning a language called Lua which is a very nice little scripting language, very similar to Python or C.  But it's used in - it's so lightweight, and it's very easy to embed into applications, so it's used in a lot of applications as their scripting language.  So it's kind of a handy thing to know.  And it's in World of Warcraft, for instance.  It's in - I started using it because of a program I use on the Mac, VoodooPad, that uses it.  But now I'm kind of into it.  And yeah, it is fun, it's fun to write little dippity-do programs.  And a scripting language is very good for that because you have an interpreter, and it's very easy to test your stuff out.  And it has some nice little features that make it fun to write.  So I understand how you feel.



STEVE:  Yeah, it's just - I just love it.



LEO:  I regret, in a lot of ways, there are a few things that I would have liked to have done in my life, and one of them is be a coder.



STEVE:  But your path was different, Leo.



LEO:  My path was different.  And I probably wouldn't have been very good at it anyway.  So there.  You know what I'm really...



STEVE:  I actually disagree.  I think you've got a very logical, very, you know...



LEO:  You're kind.



STEVE:  No, I'm serious, I think you would have been good.  And you're good at this, too.  So this is what we need you for.  I'll write the code.



LEO:  Yeah.  You write the code, and I'll...



STEVE:  You create the TWiT zone.



LEO:  All right, now, Steve Gibson, I have 100 - I'm sorry, this is 158.  I have 12 great questions for you.  But before we get to those, I do want to find out if anything has happened in the world of security since we talked last.



STEVE:  Well, the good news is no, not much.



LEO:  Hey, I like that.



STEVE:  Last week we had the, you know, one of the grand mal Windows patch, second-Tuesday-of-the-month updates in a long time.  I mean, like a long list of all critical security problems that Microsoft was patching and did patch.  And I noticed, too, there seemed to be some stray ones that kind of came along later.  I think twice after I did the full update myself on Tuesday afternoon, I was alerted twice more between then and now that, oh, here's a little something else.  It's like, okay, I guess this one wasn't cued up when I did my manual restart and check, or who knows what.  Maybe they were just fixing some things.  But anyway, it was, you know, last week was a big one.  This week things have been relatively quiet on the security front.  The one interesting sort of news item that I saw and I thought was sort of interesting was that Congress is beginning to understand about the problem of ISPs doing deep packet inspection and...



LEO:  Oh, hallelujah.



STEVE:  ...and being involved in spying on their own customers.  And in rather startling congressional testimony they - actually it was the questionnaires they sent out to - but under the congressional stamp, so you want to tell the truth on these.  Almost all of 30 major connectivity providers, ISPs, confessed to Congress that at one time or another, and maybe even now, they were doing surreptitious monitoring of their customers' traffic without their customers' knowledge or permission or even mentioning it in the license agreement.



LEO:  Some of them admitted to using NebuAd, even.



STEVE:  Yeah, I think at least two of them said, oh, yeah, we tried NebuAd, and we're not doing it now, but we're looking at this in the future.  And they said, but, you know, we would like to make it an opt-in thing.  Like...



LEO:  Well, that would be okay; right?



STEVE:  Oh, absolutely.  I have no problem with that at all as long as people have that opportunity.  The good news is the EFF folks, the Electronic Freedom Foundation...



LEO:  Electronic Frontier Foundation.



STEVE:  Frontier Foundation are, like, on top of this and financing educating Congress and doing what they can to keep this thing from spiraling out of control.  And what I think Representative Markey is...



LEO:  Yeah, Ed Markey, yeah.



STEVE:  Ed Markey, who is, like, big on privacy, he's making noise about working to pass a law next year that would require opt-in.



LEO:  Good.



STEVE:  And if we could have that, that would be spectacular.



LEO:  Well, I think that would be good for everybody, including the industry, because the industry can, you know, most people are going to opt in if you give them a reason to opt in.  So the industry just is upfront about it instead of sneaking around and doing it; right?



STEVE:  Yeah, exactly.  And it was funny, speaking on that, I saw another little thing where there were some strong cautionary advisories sent out to people traveling out of the U.S., and I think the timing was - it wasn't coincidental that it was relative to the Olympics in China.  And that is in basically just warning people to take your electronics and the data on them very seriously relative to security, that in other countries that don't have even the fundamental constitutional privacy rights that we do in the U.S., your hotel room can be searched.  You can be asked to hand over any electronic device you've got by a customs official who can dump the contents of it.  And in some cases you can be prevented from bringing into a country encrypted data.  They just say no.



LEO:  Wow.



STEVE:  Yeah, wow.



LEO:  So if they say - if you have something encrypted, they're just going to take it off.  I mean, they're just going to say turn around, you can't...



STEVE:  Yeah, if we can't read it, you can't bring it in.



LEO:  Wow.



STEVE:  So, you know.



LEO:  That's one way to handle it, though, rather than saying you have to unencrypt it for us.



STEVE:  Yeah, exactly.



LEO:  Say sorry, you want to leave your laptop with us, you can come into the country.



STEVE:  And then also, following on from last week's discussion, remember we were talking as you were getting ready to head off to Podcast Expo, you'd had some problems with RAID 0, and we were talking about the importance of not running SpinRite in front of the RAID controller, but rather running it on each of the drives individually.



LEO:  Right.  And I haven't had a chance to do that yet.  But, yeah, I've got to do that, yeah.



STEVE:  I got email from someone, actually I ran across this as I was catching up on my mailbag in preparation for today's Q&A, some guy named Doug Sauer, he said, "Steve and Leo, thank you for your podcasts.  The DNS discussions are so important at this time.  Unless we are paranoid freaks, many IT professionals tend not to believe the evil of the hackers out there today."  He says, "Okay.  One of my home systems has a three-drive RAID 5.  This system is four years old now, still running fast enough because I bought an Intel board with dual 2.2GHz Xeons back then.  The RAID reported that I had lost a drive two weeks ago."



Now, of course since he's in RAID 5 he's running three drives.  So that means he's got the space of two drives, so that any one drive could fail, and he would lose no data.  So essentially that's more efficient, for example, than a pure mirroring where you get exactly 50 percent of your total drive space.  Here he's got one drive essentially acting as a parity drive so that any one of the three can die, and the RAID keeps on going.  But in this case it said oops, a drive just died.  And he said, "So I pulled the bad drive bay out and ran the bad drive on a freshly purchased copy of SpinRite.  Presto.  Disk fully recovered.  I also separately ran each of the other two drives, and SpinRite found and repaired errors on each of them, as well.  I will now be imaging to an external drive and coming up with an upgrade plan.



"I was not going to send a letter to you as I imagine you get so many accolades.  However, your last podcast with Leo you advised him to do a drive at a time on his RAID 0.  For once in my life I was just one small step ahead of Leo.  This temporary state of euphoria prompted me to write to both of you.  I appreciate both of you and your service to us as listeners.  I forwarded off all the podcasts relating to DNS to all my team members.  They're a big help as the DNS issue continues to unfold.  Thanks again, Doug Sauer, Indianapolis, Indiana."



LEO:  Very cool.



STEVE:  So thanks, Doug, for your note.  Really appreciate it.



LEO:  Glad to hear that.  All right.  Let's get to the questions.  I've got them.  You ready?



STEVE:  I'm ready.



LEO:  Ready to answer some toughies?  Well, I shouldn't say they're tough.  I don't know.



STEVE:  Well, they're interesting and illuminating.



LEO:  Illuminating.



STEVE:  Just what we always look for.



LEO:  You picked them, so I figure you must have something to say about them.



STEVE:  Yeah, I'm pretty ready.



LEO:  Paul Sargent starts us off from the U.K.  He wonders whether debouncing is really double trouble:  Hi, Steve.  I was listening to your Security Now! podcast Episode 167 on the continuing DNS vulnerabilities.  At one point you stated that the idea of debouncing spoofed DNS by requiring two identical query results had been aired but discarded because this would double the number of packets required for each lookup.  Is that really true?  The key point is to only allow changes to the DNS when they've been validated with a second query and reply.  Each DNS server holds a cache of results from previous lookups.  So it will only generate a new request in one of two cases:  One, it hasn't seen the address before, boom, then you're going to ask again; or, two, the TTL, the time to live, has run out on the cached result.  In this case a single request would be generated.  If the result is the same as the cache, no second request necessary.  If it has changed, then it would be verified with another request.



So what he's saying is you'd only have to make that second request if something seemed out of the ordinary or was a new address.  Assuming that DNS records rarely change, the number of additional verification query packets related to TTL expiration would be very low.  The question then becomes, how often are DNS lookups a complete cache miss, that is, no record exists, expired or not, because that's the only case when the 2x increase would occur.  Is that often enough that you get a cache miss?  Is it still a problem?  So is he understanding the idea of debounce properly?



STEVE:  Well, kind of.  First of all, I liked his clever notion that, if a DNS name server had an entry in its cache which it was going to verify by asking again, then if it got the same answer, and we know that, I mean, the whole concept of DNS is that it's a distributed database, so chunks of the current mapping between domain names and IP addresses are able to float around on servers that only periodically check in to see if there's been any change.  So that's a really  nice tradeoff.  It means that there's no, like, sort of central server that bears the brunt of everyone asking questions.  But the tradeoff is that you don't get instantaneous updates in the event that an IP address changes.  So, for example, I know you and I, Leo, have from time to time needed to change the IP address of a domain.



LEO:  Right.



STEVE:  And there's this notion of it needing to propagate through the Internet.  What that really means is that all spread around the world are, in locations where people have accessed a domain recently, there is a slowly expiring copy.  And as long as it's not yet expired, then when questions come to that server, they'll be answered from the cache rather than going back and having to re-resolve it immediately.  So it's a clever, beautifully clever solution.  So he's noted that, in the event that a name server has some data in its cache, when it sees that it's expired it could only make a single query in order to verify that what's there is still current.  And if the result it gets back is different, then that raises its suspicion that, oh, wait a minute, maybe I need to check this a few more times to increase confidence that I didn't get a spoofed response.  So, I mean...



LEO:  Well, that makes sense.



STEVE:  Oh, absolutely.  I mean, he's right about that.  The one thing that this misunderstands, which is why I really liked the question, is that what it was that Dan Kaminsky realized was that you could force servers to make queries rather than waiting for their caches to expire.  That was the brilliant gotcha that occurred to him.  It used to be, I mean, if you - like three months ago, before this whole DNS spoofing nightmare arose, you could put DNS spoofing or spoofing DNS or something into Google, and you'd get pages and pages and pages.  I mean, this notion of spoofing DNS is not new.  But everyone believed that you had to wait for the server's existing cached record to expire, and then you could make - as soon as it expired, it's not going to replace it all by itself.  It's going to wait for a query.  And then, upon receiving a query, it checks the record to see if it's expired, thereby launching its own query out to resolve that name.



So the idea would be you would, you know, you bad hacker person would sit there, wait for the record to expire - because when you ask the server, it tells you how much time there is left remaining on that record.  And that's a cool thing, too.  If you think about it, it has to because then you might be caching that record, and you don't want to start at eight hours again.  You want to understand how stale the record is so that your own cache will expire at the same time that the cache of the source of that record was.  So anyone asking a DNS server - you can tell I've been living in DNS for a couple weeks, and I've really got this stuff now on the tip of my tongue.  Anyone talking to a DNS server, querying it, knows how much longer it'll be before one of its records will expire.  So they're able, as soon as that happens, that's when they launch their query to it, knowing that it's having to launch a query out, and then they rush their spoofed response back in.  That's the traditional way.  And that limited you to one shot at replacing a record, only every TTL interval.  Which is typically one day.  A standard Internet time to live for DNS is a day.  So once a day you had a tiny window of opportunity.  Clearly this wasn't a huge problem.



What Dan realized is you could ask it for a bunch of nonexistent machines in a domain, forcing it to constantly ask upstream for that domain's name server if this machine exists.  And you could sneak in a response to that request that carried replacement name server records.  And of course that's the nature of the attack.  So Paul was right that, if we didn't have what Kaminsky realized happening, then you could do verification essentially in a cost-effective manner, only duplicating some queries if a domain was asked for that was not in the cache, and then only again if a verification that the IP had not changed from what was in the cache came back with a different answer.  So I think Paul was clever, but that doesn't solve the problem that we've just had.



LEO:  Could you rewrite the way DNS works so that you couldn't ask for these multiple updates?  I mean, isn't that a bug, too?



STEVE:  Oh, yeah.  I mean, there's all kinds, well, I'm sure right now, Leo, there are firewall vendors, you know, corporate firewall vendors madly adding code to their firewalls, and they'll have new bullet points on their new brochures in a month saying "Special next-generation DNS spoof-proofing for your corporate DNS server."  So there's all kinds of things you could do that would, I mean, make it really obvious that, you know, here comes a flood of responses in response to one query?  Okay, that's wrong.  I mean, it stands out like a sore thumb.  But right now nothing is aware of that.  So I'm sure there are - doubtless firewall vendors are madly rushing to get theirs to market first because essentially one query goes out and 10,000 come in.  It's like, okay, maybe I'm going to ask that question again.



LEO:  Something wrong there, yeah.



STEVE:  Something's wrong.



LEO:  Yeah.  Good, all right.  On to Question 2.  An anonymous listener asked a great question.  Is IP whitelisting a secure method of limiting access to a website?  Hi, Steve and Leo.  IP whitelisting.  I'd like to run a private company wiki, but located offsite using PBwiki.  I want to make access for our users easy, no user or password required, so I can use PBwiki's whitelist feature.  So you essentially say - you make a list of IP addresses that are allowed to log on, they just log on automatically.  All traffic for a business account at PBwiki runs over SSL.  So if I were to whitelist only our company's IP addresses, would this be a secure way of limiting access and keeping everyone else out?  Thanks for a great show.  I've been a listener since Episode 1.



STEVE:  The answer is yes.



LEO:  Even with spoofing?  Oh, because he said SSL.



STEVE:  Exactly.  Well, and remember now that wiki access is going to be over a web page, and web page is TCP based.



LEO:  Right.



STEVE:  So even without SSL you are unable to spoof an IP.  Nobody at a different IP is able to obtain a connection because your connection attempt will be checked against a valid IP range.  And even if you sent a SYN packet in from a valid IP range, that is spoofing your source IP, so that that incoming SYN packet to the wiki site carried the IP address of the corporation, well, when it acknowledged that, it would go to that IP.



LEO:  Oh, that's right, of course.



STEVE:  It would go to the corporation.  So...



LEO:  So spoofing the incoming packet's not going to work.



STEVE:  Correct.  The only vulnerability, and it's not a big one, is some sort of a man-in-the-middle attack, that is, even SSL won't prevent you because we're assuming that any browser that's using SSL is going to be connecting.  So if somebody, like, in an ISP or anywhere in the line of your traffic were able to, outside of your corporate enclosure, were able to get into your traffic, that is, so that they were able to receive IP packets bound for the corporation, that would allow them to create a connection that would be validated by the IP whitelisting.  But that's - we're essentially saying, well, sure, you'd have to be an ISP.



Well, ISPs have access to all of our traffic anyway.  I mean, Level 3 has access to all of my traffic.  I mean, I'm protected myself for the things that I do between home and my network at Level 3, you know, SSH and so forth, and a secure VPN.  But technically anybody in the line does have access.  So IP spoofing certainly protects any random person anywhere on the Internet from being able to make a TCP connection to a web server like for using a wiki.  But it doesn't protect you in the case of an ISP.  And, by the way, if you were to use a username and password, well, that could be sniffed, except an SSL connection would encrypt a username and password.  So that's one place where SSL would make sense.  If he was using SSL and was concerned that somebody that had access to his wire might be reading the company wiki, then that's where using a username and password, or just a passphrase or something known only to corporate individuals, that would not be sniffable by somebody doing a man-in-the-middle attack because you can't break into an SSL connection.



LEO:  Yeah, yeah.  Very good, and very simple.  So it's safe.  IP whitelisting would be safe.



STEVE:  Yeah, it's a good solution.  In fact it's one of the things I use.  There are some ports that are open at Level 3, TCP connections, which it was impractical for me to block or to run SSL over.  So I have some filters at Level 3 that give my IP range here at home special rights, using the IPs to get special access to Level 3.  And it's not spoofable.



LEO:  Very cool.  Would you recommend not having passwords?  Or wouldn't you just have passwords too, just to be belt-and-suspenders?



STEVE:  Well, I guess, again, it's like anything in security is here's the tradeoff.  He says he wants to make it easy for his company people to access the wiki, where he'll just give them a URL, and they'll just, bang, there it is, no logon required.  That's really good because he can't give me the URL and have me access his wiki.  I can't.  I'm not at his IP.  I have no access to his traffic.  So it's a tradeoff.  All he has to understand is that an ISP or somebody carrying his traffic could put a browser there and intercept his traffic and get access to his corporate wiki.  That's probably not a big problem based on what's there.  He just wants to keep it private.  It doesn't sound like it's state secrets.  But if, knowing that, he decides, okay, it's worth using a passphrase and SSL so that absolutely nobody outside of our corporation is able to access the wiki, and in which case you might then remove the filtering because that way an employee could access the wiki from home.



LEO:  It looks like it's just local.



STEVE:  Exactly.



LEO:  Oh, home, yeah, home.



STEVE:  Yeah, I was going to say yeah because, I mean, that might - somebody might want to be able to access the corporate wiki from home.  The IP filter absolutely blocks that; whereas, of course username and password would permit it.



LEO:  Right.  Stroker in Florida poses some interesting questions about DNS:  Hi, Steve.  Regarding DNS, why does a domain's name servers need to be able to change their IP numbers at the top level domain name server?  When we register a new domain, we specify the domain name server's IPs at the registrar; right?  So why can't we just make the registrar the only place to change the domain's DNS IP numbers?  Then we only need to make the registrar-to-TLD DNS name server connections secure, like via IP numbers only.  As to the SSL worry, why should we - do you want to answer that, or should I move on to this second part, do it all...



STEVE:  They're all kind of related.



LEO:  Okay.  As to the SSL worry, why can't certificate authorities use IP address only, no DNS?  Certificate authority IPs could be included in the CA list used by the browser.  That's the Certificate Authority.  I suppose the CAs depend on DNS for traffic leveling, that is, bandwidth distribution using multiple IP numbers.  There must be another way to do that.  I think financial institutions and other mission-critical sites should be required to allow access by IP number.  I have tried such access, but most are using traffic leveling so that I could not access them directly by IP number.  That's interesting.  Couldn't they just distribute a range of IPs among their customers when giving them out?



STEVE:  That's practical.



LEO:  When you visit our bank, go to 192.168.1.4.  That's your number.  Couldn't they do some kind of redirect at the server or use some other means to distribute the load besides IP distribution?  This is some random thoughts.  Thanks for your time and efforts.  Maybe you should explain what he's proposing here.



STEVE:  Oh, I'm going to.  There were sort of a number of misconceptions embodied in the questions, and Stroker was not the only person to have them.  I ran across this a bunch of times.  So I sort of wanted to clarify some things.  There were a number of people who maybe were confused by me last time or the time before, talking about the nature of DNS spoofing and SSL certificate verification.  That is, there seemed to be this sense, and this is what Stroker was referring to in the second part of his question, saying, well, why don't certificate authorities use their IP addresses?



The belief, I think, that I saw among several people was that there's a connection being made to validate and verify a chain of authority, a certificate chain, at the time that an SSL connection is made.  That is, so you're not only connecting to a foreign site, but you're also at that time connecting to VeriSign or GoDaddy or whoever has issued the certificate.  And so I wanted to make it clear that that's not the case.  Your computer and specifically your browser comes with it built in, all of these certificate authorities, the so-called "root authorities" which are signing the certificates you get from websites when you attempt to connect to them.  So when you initiate a connection over an SSL connection to a secure website, your browser gets the certificate from the other end and then verifies its digital signature, verifies that it has been signed by one of the certificates in your own local cache of certificate authorities.  So there is no connection being made constantly to some other remote certificate authority.  So that doesn't need to get changed.



The other thing, in the first part of his question he's asking, when we register a new domain, we specify the domain's name server IPs to the registrar.  And he says, so why can't we make the registrar the only place to change the domain's DNS IP numbers?  What he's saying is, why can't - because the real problem, the power of the attack that Kaminsky realized was that when responding to a bogus machine request for a domain like xyz123.google.com, if you could respond to that request and get it in, then that response could contain replacement name server records that would replace the records in that name server for Google.com.  That was the whole power and the horror of what Kaminsky discovered.  And so Stroker's saying, wait a minute, why not disallow that?



Well, okay.  The problem is that that would require far more accessing up the domain name space.  Essentially what he's saying is, why not disallow caching name server records?  And essentially all of our, you know, the bulk of our caching would disappear.  We absolutely depend upon caching, as I was mentioning at the beginning of this Q&A, in order for the system to operate.  So name server records have TTLs, time to lives that expire, as do address records, and MX records for mail and, you know, basically that's the whole structure of the system.  So it's true that disallowing name server caching would prevent this particular problem.  But the whole architecture of DNS would collapse because it's near the edge as it is with all the caching we've got.  And if we disallowed caching, then it just wouldn't work.



LEO:  Congratulations.  You cured the disease but killed the patient.



STEVE:  Exactly.



LEO:  Well done.  Bravo.  There are a lot of cures like that, even in medicine.  Moving on to Question 4, Olle Lindgren from Sweden wants to blend his threats.  Who doesn't?  You were speaking about Kaminsky's DNS findings - and we have been, quite a bit - and how it didn't break SSL.  That, of course, is correct.  But imagine the blended threat if an SSL certificate was issued on a vulnerable Debian system.  In that case the private key corresponding to this certificate would be quite easy to guess.  Because of the - I presume that's because of the Debian randomizing issue; right?



STEVE:  Right, where they thought they were improving it, and they just badly broke it.



LEO:  The private key could be used to authenticate the server, but also to cryptographically sign content, that is, software updates.  Together with DNS cache poisoning, it becomes quite a nasty threat.  At least three large OpenID providers and one major bank have been using weak Debian certs.  Ooh, that's bad.



STEVE:  So let's describe how this works because this is a great question.  And we've never explicitly talked about blended threats.  So this is a great opportunity.  I mean, I have a perfect example.  So, okay, so here's the problem.  Debian was discovered some time ago, and we talked about this at the time, to have bad certificate randomization code such that, if you generated a certificate request on a Debian system, the random number in the request had very low entropy, very easy to figure out.  So that request would then go to a company like GoDaddy or VeriSign, Network Solutions, anyone who issues secure certificates.  They would sign your request and send it back to you.  So now you have a website running that is able to accept SSL connections from users' browsers.  And as we have said before, SSL is a prophylactic around spoofing because if you have a secure connection to a remote website, like for example we've used the case of PayPal, a secure connection to PayPal or even Gmail, if you use HTTPS to get to Gmail, you're able to check the certificate on the secure page and see that it was actually issued to Google.com or PayPal.com.



So here's the problem.  If the site you wanted to spoof had their certificate generated by a Debian system, you could independently crack their certificate because their certificate is not secure.  And in cracking their certificate you get their private key.  And that's the thing it absolutely must protect.  And getting their private key, because it doesn't have much entropy, it's easy to get their private key.  Then you could make your own certificate, essentially; and, okay, so now you have the ability to pretend essentially to accept an SSL connection to this bad website.  The problem is you don't have any way to get people to come to you.  Thus, DNS spoofing.  So if you spoof DNS, then anybody trying to get to the valid site instead gets your IP.  They go to your server, which has a valid certificate for that site, and bingo, you've got an SSL connection.  And there, I mean, nothing we know, unless you happen to have memorized the IP address and was, like, checking the IP address your browser was connecting to...



LEO:  Oh, I do that all the time.



STEVE:  Nobody does that.  So that's what a blended threat means.  It's the idea of taking sort of like two small problems that individually aren't such a huge problem, but when you put them together you get something that's much more than the sum of the two.  And so this would be, if you did something like this, you'd have a complete bulletproof spoofing of whatever site had a weak certificate to begin with.  And you'd mix that with DNS spoofing in order to bring people to you who were saying, oh, look, I really am at PayPal because I right-clicked on my page, and I checked my security chain, and everybody signed it, and the certificate's valid, so I'm going to type in all my personal information.  Oops.



LEO:  Oops.  That's what I do.  Yikes, scary thought.  Very scary thought.



STEVE:  So Olle was right.  That's definitely a blended threat.



LEO:  Trevor Harrison, Vancouver, British Columbia wonders, how do IP addresses work?  One thing, Steve and Leo, you didn't mention about DNS is how does the IP address know where to go - oh, this is a great question - to find the right computer.  I know it goes DNS to IP to NIC.  But how does everyone in the world know the IP address of a NIC?  Also, related to this, even if you have the correct domain and the correct IP address, couldn't the NIC somehow be spoofed and redirect the IP address to the wrong computer on the Internet?  How does it work, Mr. Steve?



STEVE:  That was a great question.  We sort of covered this when we were talking about routing in - probably in our first year of Security Now!.  But that's what routing is.  The idea is that IP addresses are assigned in blocks.  You know, at Level 3 I've got an IP address for GRC.com which is, you know, starts off 4.97.142.whatever it is.  Most of the people in that building or in that region of Level 3, their IP addresses also begin with 4.79.142.  So the idea is that routers scattered around the Internet, they may know, for example, anything that starts with 4 goes over in this direction, and anything starts with 5 goes in that direction, anything starts with 6 goes in that direction.



And so the idea is they send the traffic sort of in the best direction they can based on what they're connected to because all routers are connected to multiple other routers.  And they have a routing table whose sole job is, when a packet comes in, the routing table is checked, and that just tells it, okay, send that packet out of that connection, that interface, toward another router because the routing table says somewhere off in that direction is the IP, the actual endpoint.  So when that packet arrives at that next router, it's got its own routing table which is different from the previous router's routing table because this one says, oh, these are the places I'm connected to.  When packets come in, where should I send them?



And so it's just that.  Essentially the packets get closer and closer to their destination.  And as they do, more bits from the front of the IP address, starts off just being 4, then it's 4.79, that gets it much closer.  And then 4., maybe it's between 0 and 128 goes over here, and between 129 and 255, that goes over here.  So it sort of successively breaks down the IP address using more and more bits from the start of the IP address toward the back until you finally get to the router just in front of you that says, ah, I actually am connected to that IP, to that particular machine, so that's where it sends the final packet to.



LEO:  It's basically how a zip code works.  Right?



STEVE:  Yes, it's very much - zip codes are also hierarchical.  And in fact that's one of the things, again, one of the brilliant things about the way the Internet was built.  And Trevor last asked couldn't the NIC somehow be spoofed and redirect the IP address to the wrong computer on the Internet.  Well, it's an interesting question.  It's not exactly the NIC that would be spoofed, it would be the router.  And of course that's another whole class of successful attacks is you do what's called BGP spoofing.  BGP is the protocol that routers use for exchanging this routing information among themselves.  And there have been attacks where, for example, a BGP protocol uses TCP.  So it's a theoretically non-spoofable connection except that early versions of the TCP protocol did not do a very good job about randomizing their initial sequence numbers, the sort of the 32-bit number that sort of starts the numbering for all the bytes that follow.  So there were weak sequence number randomization.  And in fact, in the beginning, they weren't random at all.  They just kind of kept going linearly upwards because you didn't want them to wrap around or that could cause some confusion.  So it was sort of better not to have them completely random.



So there were attacks that actually had people, like they would contact the router themselves.  That would initiate a connection that would allow them to read the router's current TCP initial sequence number, very much like the attack, when you think about it, on DNS, where you would make a query and get the current transaction ID and then send a bunch of responses with successive IDs, back in the day when those were linear.  So similarly you could guess what the communication would be with another BGP server and essentially splice into their TCP connection and load false routing tables, causing packets to go where you want them to.  So that's another class of attack on the Internet.  Not something we've talked about before, but it's been there, it's been done, and security has been improved in order to make it harder to do.



LEO:  Put that on your list of shows we would like to do is a show about routing and how it works, and a show about BGP and how it works.



STEVE:  Yeah.



LEO:  I think both of those would be great subjects.  We've never talked about routing, have we?  Maybe we have.



STEVE:  Yeah...



LEO:  That's pretty fundamental.  We must have done a show on that.



STEVE:  I think we did a "How the Internet Works."



LEO:  Yeah, okay, sure.  So I refer you back to that, many moons ago, Trevor.  Tim, who's hiding in Houston with his iPhone, says how secure is my phone?  Steve, I've downloaded many podcasts, but whenever I get a new episode of yours I always listen to it first.  As the title suggests, my question involves iPhone security.  My question is simply, or maybe not so simply, how secure is the iPhone?  It has Bluetooth, which I leave off unless I'm using it.  I use WiFi when I'm at home and work, but I usually leave it on.  It often sees other open networks.  Is there any security risk to leaving the WiFi on all the time?  Can someone hack the phone while it's in my pocket?  For that matter, how secure is it when I'm on the 3G or edge network?  I'd ask about joining one of the open networks, but I think I already know your answer to that.  I guess he means open WiFi networks.



STEVE:  Right.  Well, the answer is radio is bad.



LEO:  Well, that's all a phone is.



STEVE:  Next question.



LEO:  And anything you say here is true of any smart phone, with WiFi and stuff like that.



STEVE:  Exactly.  I'm not singling out the iPhone at all.  Radio is bad.  I mean, it's necessary.  I'm not saying we don't all use it.  I do.  I've got WiFi here.  I've got it wrapped up in a WPA encryption with a passphrase from hell that I got from GRC.com/passwords.  So I'm as secure as I can be.  But several times during the history of this podcast we've talked about vulnerabilities in, for example, Intel's WiFi drivers.  There was one not even that long ago where it was found that down in the actual packet processing, way down at the bottom, the first place the packets go when it comes hot in off the aerial, off the radio antenna, had an overflow.  So before encryption and decryption, before authentication, before anything else, it was possible to simply broadcast a malformed, deliberately malicious bit of radio noise and take over a machine.



So that isn't saying anything about specific phones or PCs or anything.  But we know how difficult it is to make truly, truly bug-free software.  And if a bug of this nature occurs down at the very first stages of data processing on WiFi, then you've got a serious problem.  And it means that, if this were found, somebody could easily be broadcasting malicious packets in a public place, taking over any, for example, if a problem were found in the iPhone, I don't know that any exists, but if there were one that were discovered, they could broadcast a malicious packet which would take over your phone.



LEO:  You do have to explicitly join a WiFi network on the iPhone.  Does that protect you?  No.



STEVE:  No, no.  In the case of this Intel, all you had to have was your radio on.  And it was receiving stuff, and the kernel-level driver was processing it.  And there was an exploit for that that was - that came out.  So all you had to do was just receive the packet, even with no connection to the network because all the network connection stuff is way back further upstream, behind encryption, behind authentication, behind the TCP stack and all that.  This was right down, the first place that the bits went after they turned from radio bits into electron bits.  Well, I guess radio bits are electron bits.  But still, into digital bits.  You know, bang.  There was a buffer overflow opportunity.  So radio is bad.  I would say turn off WiFi.  Besides, it consumes power.  As I understand it, the iPhone has no power to spare.



LEO:  Yeah.  It's one good way to save.  If you're not - and I turn off "Ask to join WiFi networks," but I think you're absolutely right.  Turn off WiFi, turn off 3G, you know, anything you're not using you should turn off anyway.



STEVE:  Yeah, and turn off Bluetooth.  I mean, he is keeping Bluetooth off, and I'm glad for that because we know that there have been problems with that, as well.



LEO:  But again, in general, well, I mean, there are problems with Bluetooth even if there isn't an exploit, if you just leave it open.



STEVE:  Yes, if you leave it discoverable.



LEO:  Right.  But in general these are exploits that require errors in the programming.  It's not like, except for that Bluetooth discoverable issue, it's not like this is kind of part of the natural, normal nature of things.



STEVE:  That's correct.



LEO:  Yeah.  But there are always holes.  That's the problem.



STEVE:  There always seem to be, don't there, Leo.



LEO:  Yeah, they just don't - they don't go away.  Let's see.  Let's move on to Question 7, Bill Richardson - former governor of New Mexico?  No no no no, he's in Fort Worth, Texas - was surprised by the results of his sleuthing.  He says:  Hi, guys.  I've been a faithful listener for almost two years, enjoy the show and look forward to it every week.  Thanks for an informative, insightful, deep dive into security.  On with the story.  Long ago I changed my static DNS entries in my Linksys home wireless to the IP addresses of OpenDNS - something I do also.  So during the recent discussions of DNS vulnerability I thought I had little to worry about.



However, the other day I fat-fingered a web request and got a Charter Communications "not found" result page.  Wait a minute.  Confused by this, I began to research.  My router settings had not changed, and my client machine's IP config showed DNS set to the router IP and the two IP addresses of OpenDNS.  Yet when I went to the DoxPara test page I found my DNS server was vulnerable to DNS cache poisoning, with all the requests being sent out over a single port.  Lastly, I searched ARIN, which is the - what does that stand for?  



STEVE:  Used to know [American Registry for Internet Numbers].



LEO:  Anyway, Whois, and found that of course the IP address identified by DoxPara is owned by Charter Communications.  Well, that's - huh?  That's interesting.  I guess that's who's hosting his site.  My questions are many.  How could Charter intercept these?  Oh.  Maybe they don't own his site.



STEVE:  Exactly.



LEO:  How could I stop them from intercepting my DNS requests and use a security-aware DNS service?  What are my options?  So let me recap to make sure I understand.  He's using OpenDNS, so theoretically all his DNS should go through it.  But for some...



STEVE:  Well, let's say he's configured to use OpenDNS.



LEO:  Ah.  And he's configured properly, it seems.



STEVE:  Yes.



LEO:  For some reason Charter is intercepting these.  What's going on?



STEVE:  Yes.  Yes.  



LEO:  Yes.  Yes, he said, yes.



STEVE:  This is a problem.  This means that, okay, and think about it, DNS is over UDP, that is not connection oriented and that has no TCP connection.  And his ISP could do anything it wants with his packets.  So they are receiving DNS queries coming from his network, out of his router, with a destination IP on the packet of OpenDNS.  They know that it's a DNS query because it's aimed at port 53, which is a universal DNS query port.  All DNS servers are listening for incoming UDP and TCP traffic on their port 53.  Charter, for whatever reason, perhaps for the purpose of intercepting and putting up their own advertising page, they're ignoring the destination IP of his DNS packets and changing them, rewriting them to their own.  So that...



LEO:  Oh, man.



STEVE:  ...no matter what he does, no matter what DNS configuration he uses at home, Charter is ignoring the destination IP, rewriting his packets on the fly so that they go to their DNS server.  And if he, as he says, "fat-fingered," which I think means typo...



LEO:  Mistyped it, yeah.



STEVE:  Mistyped it.  Then instead of his browser being told there's nothing at that IP, he's given an IP, his browser is given an IP of a server that Charter is running that brings up their own interception page for whatever purposes they choose.



LEO:  Usually advertising.  VeriSign did this for a while, and it was very...



STEVE:  And, boy, they didn't do it for long because it really pissed people off.



LEO:  A lot of ISPs do that.  And they say, well, we do it as a convenience, we have a much better page.  And it's true, if you don't do that, then you get that stupid Internet Explorer page saying I can't get anywhere.



STEVE:  Okay, well, two things.  First of all, you said many ISPs do this?



LEO:  Yeah.



STEVE:  The only way to do it is rewriting DNS.



LEO:  Ah, interesting.  Of course, yeah, of course.



STEVE:  So that means all the ISPs that are able to present their own page are doing so by preventing you from going to the DNS server you have asked for.  And secondly you'll notice that he ran the test at DoxPara, and it said all your requests are coming from one port.  So not only is his ISP screwing up his deliberately configured-for-security DNS, but they're aiming it at an insecure server.



LEO:  They're doing a bad job.



STEVE:  Exactly.  They've got a spoofable server, and they're forcing all of their customers to use their misconfigured spoofable server.



LEO:  Is there any way to find out if your ISP is redirecting?



STEVE:  Not quite yet, but GRC...



LEO:  A traceroute?



STEVE:  GRC will be telling you soon.



LEO:  Oh, really.  And how are you going to do that?  I guess you could compare what you expect to see - hmm.



STEVE:  Yes.  I'll be making it very clear about the IP and the reverse lookup of the IP where we see queries coming into our test.  So you would instantly see that this was a Charter Communications DNS server, not OpenDNS.



LEO:  Wow.  That's sad.  So even a traceroute you wouldn't necessarily, well, you can't trace the DNS requests, can you.



STEVE:  Well, a traceroute is, well, exactly.  A traceroute, let's see, what would it do?  There's many trace - there are many ways to do a traceroute.  The idea...



LEO:  ...packets, but you don't see the DNS requests go.



STEVE:  Well, the way a traceroute works is that you deliberately send out packets with very short TTLs, times to live on the packets themselves.  And you incrementally increase the TTL.  So the packet hits the first server.  It decrements the TTL, which we have sent out as 1, decrements it to 0.  Which prohibits it from forwarding it to its destination.  Instead, it sends it back to you with its IP as the source of that returned packet.  You receive it, and inside that is the beginning of the packet you actually sent.  So you know what you sent, and you know where it bounced.  Then you send a packet out with a TTL of 2.  So it goes to the first server, then decrements the TTL to 1, forwards it to the second router - I'm sorry.  The first router, that decrements the TTL from 2 to 1, which forwards it to the second router, which decrements it from 1 to 0.  That prohibits it from forwarding the packet.  So it bounced it back to you.  And that's how you're able to build a trace of the direction the packets are taking and the sequence of routers that they visit.  So what would happen would be this thing would bounce its way over to Charter and end because the packet would have a TTL, probably pretty low.  Since Charter is your own ISP, the packets you generated would hit the DNS server quickly as opposed to heading off across the Internet over many more hops to get out to, for example, the OpenDNS server.  So a traceroute, if you knew to do it, would be suspicious, but you'd have to suspect that first.



LEO:  There's a UNIX command called "dig" that does DNS diagnostics.



STEVE:  Oh, it's worth noting also, Leo, that you would specifically have to do - you'd have to have the power to do a traceroute of DNS traffic.  That is, most traceroutes will just use, for example, ICMP packets, which would not be redirected.  So ICMP would go on its merry way, heading off for OpenDNS.  Only a UDP packet bound for port 53 that you were using as the traceroute payload would have its destination IP rewritten and then get rewritten and aimed at Charter's DNS server.  So it'd be a pretty sophisticated thing to do.  But certainly doable.



LEO:  Interesting.



STEVE:  Easier to go to GRC once I get that service up.



LEO:  I can't wait till you get that up.  That's going to be fantastic.  That's a very good use for that.  That's not - that wasn't your primary intention, though, was it?



STEVE:  Well, no no no, I've got...



LEO:  It's a side effect.



STEVE:  ...a much better statistical system built than anyone has before.  And it's coming alive.  And I'm excited.  And this is an example of why this problem has not gone away.  I decided to invest in the time of creating a permanent facility, much as I have for ShieldsUP!, for DNS because these kinds of bogus things can happen where people can get into your DNS business and end up rerouting you to a spoofable server, even though you've deliberately configured one not to be.



LEO:  Wow.  When I run that better DNS search that you gave us last time, I think it was snipurl.com/...



STEVE:  The one that goes to OARC's site.



LEO:  Yeah, dnstest, I think.  Snipurl.com/dnstest.  But I would get results back from both Comcast and OpenDNS.



STEVE:  And you're a Comcast user?



LEO:  Yeah.



STEVE:  What must be happening, there are a number of things have happened.  I've got a preliminary test up that the people in our newsgroups have been using.  And, for example, some of them have received responses from as many as 15 different name servers.



LEO:  Yeah, I got two different - three different name servers responding.



STEVE:  Yeah.  We're going to spend an episode talking about this once I have this up so people will be able to see what's happening.  There are all kinds of things that are going on.  For example, some of our early testers were reporting, wait a minute, I'm seeing IPs that are not the ones that I configured.



LEO:  Right.



STEVE:  It's like,  well, yeah, because what's happening is those, the IPs showing up in the test, are the IPs of the server that actually issued the query out onto the public Internet.  But it can also often be that you are - that the IPs you configure, for example, your ISP's IPs, they could go to a pair of servers that are forwarding the requests to a pool of servers in some sort of a round robin fashion.



LEO:  That is what's happening because I go to San Fran Comcast and then go to Salt Lake City Comcast.



STEVE:  Okay.



LEO:  So they have some pool somewhere.  But I also go to OpenDNS, so I'm very confused.



STEVE:  We will resolve your confusion, my son.



LEO:  I can't wait, I can't wait.  That's going to be a very valuable tool.  Let's get a listener from Heidelberg.  This will be fun.  His name is David.  He "hosts" an interesting idea, a little pun from Steve Gibson.  I've been listening to the podcasts for several months, and I love them.  After hearing Peter Chase's idea of avoiding spoofable DNS by using IP addresses in browser bookmarks instead of domain names - which is something we've talked about a little earlier - I think it would be better to use the hosts file.  However, if Internet site IP addresses changed, that would pose a problem.  So why couldn't the hosts file be updated automatically?  Suddenly sounds like he's setting up a DNS server.  It could help block ads, map domain names to IP addresses, throw malware off the track.  An application/service or other automated method that updated the hosts file could be very useful - perhaps dangerous - and better than something that will go through my Firefox favorites or bookmarks, say, or my IE favorites, and just replace them with all the IP addresses.  It's not a silver  bullet.  I find it interesting, and I would like to hear your comments.  Keep up the great work.  I mean, this is how DNS was born, basically; right?



STEVE:  Well, yeah, it is.  I mean, it is the case, I mean, I could see an interesting piece of software that is sort of aware of spoofability problems, that periodically it opens up your hosts file, reads the hosts file, and goes out to verify and possibly update any entries you have in your hosts file to keep it synchronized with reality.  Basically it'd be like setting up a little sort of custom DNS interception system where you put www.doubleclick.net in your hosts file.  And the question is, okay, the problem is, if DoubleClick.net changes their IP, then your hosts file is obsolete.  So imagine a little tool which would itself be a DNS resolver, driven by the current contents of your hosts file, whose job is to keep it current.  I think that's kind of cool.



LEO:  Yeah.  But isn't that, I mean, isn't that kind of what DNS is doing is it's keeping a master list and a matching list?  In fact, that's what you do with OpenDNS.  You can have it block porn sites if you want.



STEVE:  Right.  So all you're really doing is you'd be - the benefit of this would be, if you don't trust an external source of DNS, but somebody wrote something that was, like, really anti-spoof, I mean, it is absolutely possible now to write an anti-spoofing, an anti-spoofable DNS server, simply by issuing a query and seeing how many responses you get, as we said earlier.  I mean, so it's - or to, like, start, if you're just you, and you've got a small hosts file, there's no reason not to start at the root servers, who are based on IP addresses.  They have domain names.  But, you know, you can't look them up unless you already know them.



So you could imagine a little DNS resolver that marches down from the root servers to the com servers to the domain servers to the machine level, and itself follows the DNS step by step, which makes it unspoofable.  It's not caching.  It's getting authoritative information at every step in the DNS chain.  And that would allow you to have an absolutely unspoofable hosts file of sites that you cared about that your system would refer to first and nobody could screw with them.  And they'd be kept current.



LEO:  Very clever.



STEVE:  If I had more time, I'd write one.  But I'm a little busy right now.



LEO:  You're busy doing other things.  Let's see, Question 9 is from Derek O'Harrow in Reading, England.  He suggests another blended threat.  We've got to do something on blended threats.  This is very interesting.  Hi, Steve and Leo.  In Security Now! Episode 155 you talked about SSL and the fact that it cannot be faked.  So sites like PayPal can be relied upon because they force you to use SSL and a certificate.  However, in a previous Security Now! you talked about the root certificate authorities and how many of them there are.  Wouldn't it be possible for Mr. Russian Hacker to spoof a domain and then, using one of those other more dubious root certificate authorities, create SSL server certificates for PayPal.com but with a different signing authority?  In this way, couldn't a hacker pretend to be even an SSL-secured site?  And wouldn't the web browser client happily accept this without question, eh, eh?  Thanks for the fantastic podcasts and for ensuring we never miss a week, including earthquakes.  Well, we've talked kind of about this, haven't we.



STEVE:  Yeah.  This is actually another one of the questions that sort of misunderstands the way SSL works.  We have, as I said, I think it was a week or two ago, I'm going to do just a whole podcast on SSL, how the protocol works, to make it very clear.  Because we've talked about the certificate side of SSL, but never really about the way the protocol works.  So what Derek was asking was couldn't you spoof the domain of the certificate authority, which is really the same question that was asked earlier in this podcast, and wouldn't that then allow an otherwise invalid certificate to be seen as valid?



Okay, well, you don't have to spoof the domain of the certificate authority because your browser already has a huge number of certificate authorities.  In fact, that's been my anguish is how many there are, and we just trust every single one of them because even one of them issuing a certificate maliciously or mistakenly compromises, well, compromises our ability to trust the real owner of that certificate.  So if there were a dubious root certificate authority whose certificate was already in our browser, as so many of them are - not dubious root certificate authorities, hopefully, but legitimate ones - and that dubious authority issued www.paypal.com certificate to Mr. Russian Hacker, then yes, now he's got a maliciously issued or mistakenly issued or somehow he got himself a valid certificate for PayPal.com.



Normally that's not a problem.  But again, in threat blending we take not a big problem, I mean, not good, but not a big problem, and the DNS spoofing, which certainly can be a problem.  We put them together, and we end up with a much bigger problem because that would then allow Mr. Russian Hacker to set up secure connections to www.paypal.com.  The browser would connect happily.  Presumably, if it was one of those extended validation certificates, all the green lights would turn on, too.



LEO:  See, I was going to ask you about that.  So the EV certificate does not fix this problem.



STEVE:  No, it does not.  It's just harder to get one, hopefully making it more difficult for Mr. Russian Hacker to get one.



LEO:  Right.  Yeah, because he has to provide all sorts of information, personal information and whatever, fingerprints and stuff like that.  He's not going to do that, I would think.



STEVE:  Well, I'll tell you.  I mean, I had an experience, very good experience, actually, with GoDaddy two weeks ago.  I needed a wildcard certificate for the first time ever for my first...



LEO:  What's that?



STEVE:  That's like *.GRC.com.



LEO:  Ah, okay.



STEVE:  That is to accept secure connections.  Because my first approach at doing this DNS spoofability test that I'm building, it used a whole bunch of browser queries over SSL because I wanted people to be able to use SSL connections with GRC specifically so that they could avoid spoofability problems.  You know, we talked about, okay, well, how does it make sense to go to a DNS test if the DNS server you're using might be broken and spoofed, and then the test would be spoofed.  So the idea was, okay, we're going to let people come in by IP or by SSL.  And in fact I was going to force people to switch over to SSL and not allow them to have a non-SSL connection to GRC.  But if I then had lots of assets that the web page was pulling, those had to be SSL.  And the way this worked was it pulled them all from different machines at GRC.com in order to force DNS lookups.



So anyway, I needed a wildcard certificate, *.GRC.com.  Well, the good news was I had it in five minutes.  GoDaddy is very nice, was very quick.  But the extent of their validation was sending email to the email address registered on my domain.  And this was all automated.  So they sent it to my Whois email address, which came to me, and I clicked a link that I received in the email, that I was expecting.  It went back to them, verified it, I got an email certificate.



Now, not long ago, in the last couple weeks, we have heard of Whois database entries getting changed.  Remember, that was just in the last month or so there was a Whois entry change.  Which means all that Mr. Russian Hacker would need to do with an automated certificate issuance like GoDaddy has is get his email address into the domain record of the person he wants to spoof.  And then he says, hey, I'm PayPal.com.  They verify through automation, send email to that record, he gets a certificate, bang.



LEO:  Wow.  But that's the non-EV certificate, and that's how it's been all along; right?  I mean, that's why we need an EV certificate.



STEVE:  Because it certainly is - we hope it is not going to be a five-minute automated email loop verification.  Otherwise it's back to the drawing board.



LEO:  Right.  Matthew is an intense listener in Fresno, California who's been thinking about DNS spoofing:  Steve and Leo, I was listening to Episode 156 while I was driving to work, and I heard Steve mention that the DNS vulnerability cannot spoof your email logon.  Got me thinking.  Our listeners are always thinking.  One, if I was a hacker, and I was spoofing, say, https://mail.gmail.com, couldn't I also spoof VeriSign.com and have my fake Gmail certificate authenticate to a fake VeriSign, but authenticate correctly if I created a fake Gmail cert from the fake VeriSign?  Two, if I were a hacker, and I don't care about the contents of your email, couldn't I just redirect the logon pages of the webmail sites and capture the username and password?  As a hacker, I don't care if I can get your email, I just want your credentials.  Browsing the most popular webmail services I've found that going to http://mail.google.com and http://mail.yahoo.com redirects you to their SSL site for authentication.  But going to http://hotmail.com does not.  So if I could duplicate the look of the Hotmail page and redirect the DNS traffic, I can capture more than enough information.  Thanks for a great podcast.  I listen intensely to it every week.  So he's thinking.  Is he thinking right?



STEVE:  Well, again, this shows that there was a little confusion in the way certificate chains are authenticated.  And that is that many of our listeners, that's why I wanted to really pound this point home, many of our listeners were believing that there was, during SSL authentication, that there was some sort of communication back to the certificate authority.  And so I want to just make sure everyone gets it that that is not the case.  In the last couple months, for example, Microsoft sent out to Windows an SSL root certificate update package.  And so that's the only way these things get into our systems is that they come in with the browser or as part of a secured, signed, authenticated update.  So those root certificates then statically authenticate any certificate from a remote site with no further communication to Microsoft or VeriSign or GoDaddy or anybody else.  So that part is not the case.



However, for example, his discovery that Hotmail.com does not use secure authentication, that's important because it means that they would be a perfect target for a DNS spoofing attack where somebody would set up a fake Hotmail account and acquire the credentials of everybody trying to log into their Hotmail account while that spoof was in place because he would not then need a Hotmail.com SSL certificate, which is more difficult to get.  Unfortunately, as we learned from the prior question, not as difficult as we would like it to be.  But they would just leave it over a standard HTTP connection and happily collect username and passwords.  And in fact could turn around and open a connection to Hotmail and be a man-in-the-middle attack, essentially, capturing that, grabbing the Hotmail page that the user expects to come up, and forwarding that back.  And we've talked about browser-based man-in-the-middle attacks before using, as long as you don't need security, that is, SSL, DNS spoofing is a perfect entre to a man-in-the-middle attack.



LEO:  Wow.  So you're saying it is doable, but it's a little more difficult than one would imagine.



STEVE:  Well, it's another example of why Gmail and Yahoo!, that do redirect nonsecure authentication to a secure authentication mode...



LEO:  Right, that's why it's the way to do it, yeah.



STEVE:  They're doing the right thing, yes.  And assuming that Matthew is right, and Hotmail doesn't, that's really bad on Hotmail's part.



LEO:  Kind of odd.



STEVE:  Because of just all kinds of problems.



LEO:  Isn't it possible that it's one of those situations where your...



STEVE:  If you had a cookie, for example, he might have a cookie on his machine.  And if it recognizes in your incoming connection a cookie which has not yet expired, it might treat you with less security.  Of course the problem there is you're not over SSL, so your cookies can be sniffed.  Because cookie snarfing is another problem.



LEO:  See, now, I'm looking at this.  I just logged in.  So first I went to HTTP Hotmail blah blah blah, logged in.  Now, presumably that login, even though it doesn't say HTTPS, is a secure login.



STEVE:  No.



LEO:  No?



STEVE:  I mean, it would have to say HTTPS.



LEO:  But remember we have those pages where the submit is secure but the page itself is not?



STEVE:  The page you get to would have to be secure.



LEO:  Okay.  The page you get to would have to be secure.  But now I'm in my mailbox, and it is HTTP.  It's not S.



STEVE:  Sounds bad, Leo.  I hope someone didn't just grab your username and ID on the fly.



LEO:  Well, I can view the source, right, and see if it's a secure submission.



STEVE:  Yes, if you go back to the submission page and then, like, just do a search for HTTPS, and you ought to find it in - you ought to find the - or it could be using JavaScript, who knows what...



LEO:  It is, you know, and it's all obscured because it's one big long JavaScript.



STEVE:  Then the way to do it would be to use a browser monitor tool, a wire...



LEO:  See, but no user's going to do that.  I mean, you're just going to assume it's Microsoft, it must be secure.



STEVE:  Sounds bad.



LEO:  All right, let me try again.  So I'm on a regular HTTP page.  You're saying when I press the - give them my password and credentials, and I give them the sign-in button, I should then be dumped into an HTTPS page.



STEVE:  Oh, and if you hover your mouse over the button, does the URL of that button show up down below in the browser bar?



LEO:  No.



STEVE:  Okay.



LEO:  And I am now - oops, I gave it the wrong address.  And now, okay, I gave the wrong password, and it did go to an HTTPS page.  So presumably...



STEVE:  It does sound like they've got some mixed in there, yes.



LEO:  I mean, c'mon, this is Microsoft.  They couldn't be that...



STEVE:  Okay.



LEO:  Forget I said anything.  Number 11.  Isaac Church in Loomis, California worries that his characters are being ignored:  Hi, Steve.  I'm a Wells Fargo customer, and as I happened to notice, they accept passwords that technically are not correct.  As long as the first part of the password is correct, the characters that follow are ignored.



STEVE:  Can you believe this?



LEO:  But it's well - okay.  This might not be a serious security threat.  But as a programmer it bothers me since wouldn't it make it easier for an attacker to correctly guess my password?  Wouldn't it?  I'm also curious if other banks have this issue.  Thanks for the great show and software.  So, what, they have, like, a seven-letter password, and if you put in 12 it just ignores the last five?



STEVE:  That's what it sounds like.  It's like, oh, my goodness.  Now, okay, this means a bunch of things.  This means that they're not doing a hash, or if they are, they're only hashing on the first X characters.  It probably means they're storing the password, and that they're only paying attention to - okay.  I don't know if he's added characters after he defined his password or if he used a longer password and then he changed the end of it and they didn't care because they're only recording or checking the first N number of characters.  Now, that's really disturbing.



LEO:  That is extremely disturbing.



STEVE:  And so, and of course the true threat of security, first of all, anybody who's doing this you wonder, okay, who wrote this, and do I trust anything else about the site if this is how they start off?  But then of course the issue, the true issue of security is how big is N?  If they're only using the first N characters, where is that threshold?  Is that eight?  Is that nine?  Is that, as you were suggesting, seven?  Which we know really quickly becomes too short for security.  So, you know, this is very disturbing.  I almost hesitated making this public.  But I thought, well, our listeners need to know, especially if they're Wells Fargo customers.  Maybe some of them can start messing around with their passwords and seeing what N is and definitely complain to somebody.  That's bad.



LEO:  That's just bizarre.



STEVE:  Yeah.



LEO:  That is just bizarre.  We're going to get to our 12th question, in which Russell says, "I am not a pirate," in just a second.  It's nice, you know, that when we talk about security all the time and how badly implemented it is, to know that there are people out there who are like you, that just take it really seriously and do it right.  And so I just - I'm just glad that they're part of the show.



STEVE:  Yeah, I met those guys at the...



LEO:  They're cool, aren't they.



STEVE:  ...RSA conference.  They were seriously UNIX people.



LEO:  You want somebody who is really, you know, you don't want somebody who's, like, the guy who wrote the Wells Fargo login.  You want somebody who's, like, really paying attention here.



STEVE:  Yeah, we got most of it right, and we don't want customers complaining that they can't log in, so a guess is good enough.



LEO:  You've just got to wonder. 



STEVE:  He got started on the right foot.  He just kind of fell off the track halfway through his password.  So we'll let him have that one.



LEO:  He's the code monkey.  He's going to let the manager write the login page.



STEVE:  Come on in and manage all your money.



LEO:  Question 12, Russell McOrmond in Ontario, he's in Ottawa, in Canada, the capital, the nation's capital.  He says:  I am not a pirate.  In the last Q&A episode someone mentioned that SpinRite was the only program they had bought in a long time.  Leo commented that this person must be a pirate.  Well, SpinRite is also the only program I have bought in more than 15 years, and I am not a pirate <grin>.  Instead I'm a user and commercial support person for Free/Libre and Open Source Software.  FLOSS, baby.  I've purchased CDs and manuals over the years.  But given that licensing is royalty-free, I have not "bought" any of this software.  All of it is perfectly legal.  As it happens, I'm the policy coordinator for CLUE, Canada's Association for Open Source.  It's at Linux.ca.  Thank you, Russell.  One of the hardest messages to get across to politicians is that charging royalties for software is not a necessity, but only one narrow business model among many.  I just thought I'd add this.  Thanks for the great security show.  Russell, you are right on.  You are right on, and I apologize to open source advocates everywhere who have not purchased anything but Security Now! in 15 years.



STEVE:  Well, SpinRite.  And I really - I thought that was neat.  I really appreciate that, you know...



LEO:  That he bought that.



STEVE:  Bought SpinRite.



LEO:  There's no open source analog, that's why.



STEVE:  Yup.



LEO:  The one and the only.  And Steve, will you do us this favor, put it in your will that the day you pass on, that SpinRite goes open source.



STEVE:  Okay, but it's all Assembly language.



LEO:  That's okay.  I think there's somebody out there who could figure it out.



STEVE:  I think that's true.



LEO:  In fact, I think there's somebody out there who can't wait to get his hands on your source code, who's dying to look at your source code.



STEVE:  Actually, SpinRite is so stable and generally my major versions have many years...



LEO:  Few and far between, yeah, yeah.



STEVE:  And GRC's running so smoothly now that I could even see, after I'm in my grave, Greg and Sue could really...



LEO:  Just keep it going.



STEVE:  ...easily continue on, and they ought to because, you know...



LEO:  You know, what's going to happen at some point, and we're seeing it already, SSD hard drives, their hard drives are going to change in such a way that SpinRite doesn't make sense anymore.



STEVE:  True.  True.



LEO:  I mean, if everybody goes SSD, then we won't need SpinRite.



STEVE:  Yeah, the drive technology is maturing at such a rate that it's going to be tough for solid state to catch up.  But we know ultimately it will.  And, I mean, look at the prices of hard drives, Leo.  It's just, I mean, it must be that the manufacturers are saying, uh-oh, we have such an investment in spinning magnetic platters that we want to make sure people keep buying these, so we're going to sell you a terabyte for $125.  It's like, oh.  Well, in that case, that's a good deal.



LEO:  I just bought the new VelociRaptors, two of them, for our ultimate gaming machine.  They're so cool.  They're so tiny.  I just, it's amazing.  And they're 300GB, this big, you know?  I mean, it's mind-boggling. 



STEVE:  And you're going to run SpinRite on each of them...



LEO:  Before...



STEVE:  ...at Level 4 before you put them in.



LEO:  And we're going to ship a copy of SpinRite with it so that they will never have trouble.  And I just bought, for 98 bucks, 500GB drives, these eSATA drives.  98 bucks for 500 gigs.



STEVE:  Wow, wow.



LEO:  Unbelievable.



STEVE:  Fast, nice.  And what manufacturer?



LEO:  I don't know.



STEVE:  But there they were.



LEO:  It's all a commodity.  I don't know.



STEVE:  Good price.  Good price.



LEO:  I don't know what's inside.  You know, the enclosure says "Cavalry."  But I don't know what kind of drive.  Nowadays it's all kind of commodity.



STEVE:  Yeah, just plug it in, and it goes.  It'll be Western Digital in the...



LEO:  Yeah, almost certainly Western Digital, yeah.



STEVE:  They're still the rock-bottom price.



LEO:  Yeah, and good drives, though; right?  Not bad drives.  I know you like Hitachi.  But WD is fine.  Well, we're out of time, I think, and out of questions, so I think maybe time to wrap this up.  Next week, Steve, what do we want to talk about?



STEVE:  Next week we're going to discuss the other really interesting presentation from Black Hat which was this supposed complete defeat of all the much-heralded security benefits of Vista.



LEO:  Oh, boy.  Vista, is it safe.



STEVE:  Address Space Layout Randomization, ASLR; and DEP, Data Execution Prevention.  The question is, how easy is it just to bypass them?  And apparently the Vista security bypass is a reality.



LEO:  It's so good to have somebody like Steve in our back pocket who can look through these presentations with a technical eye and judge them on their merit.  Because otherwise, you know, I mean, The New York Times is not going to know.  They're just going to report that this guy says it.  They're not going to know enough to figure it out.  And frankly, I can't look at it and figure it out.  So thank you, Steve.



STEVE:  Yeah, it's a 54-page report.  And I'll be doing my homework between now and then.  But I will figure it out, and I'll give our listeners the complete rundown.



LEO:  Thank you so much.  Steve Gibson is at GRC.com.  That's where you'll find 16KB versions of this for the bandwidth impaired, the low-quality but still audible versions.



STEVE:  The low quality.



LEO:  You can find a crappy version that's there.  No, no, but it's there for people, it's a small, small, small file.  And also transcripts, which are very high quality thanks to Elaine.  And she edits out all my ums and uh, hey...



STEVE:  But she leaves in my [trumpeting].



LEO:  How does she spell that?



STEVE:  I think she says [Steve plays trumpet].  Doo-to-doo.



LEO:  She was a court reporter.  I guess when you're a court reporter you have to do those things.  [For the record, I studied court reporting, never got my license.  Elaine]



STEVE:  Oh, and she does, like, excruciatingly detailed biomedical reporting, I mean, stuff where every single syllable matters.  [Again for the record, that's transcribe, not report.  Elaine]



LEO:  And the doctor goes doo-to-doo, you'd better get it in there.



STEVE:  And, you know, she gets a copy of the Q&A because she insists on spelling everyone's name right, you know, all of our listeners.



LEO:  [Trumpeting].



STEVE:  I wonder what she does when you do one of your accents.  Leo says...



LEO:  In Russian.



STEVE:  ...[in bad Italian accent]...



LEO:  Bad Italian accent.



STEVE:  Or actually I have to say my tech support guy, Greg, who listens to Security Now!, he says, you know, "Leo is really good with those accents.  He ought to just keep it up throughout the entire question."



LEO:  No.



STEVE:  And there were several here where I noticed that you started off...



LEO:  No, I do a little bit, just a flavor.



STEVE:  Sort of fade out pretty quickly, so.



LEO:  Flavor.  A little flavor.



STEVE:  Greg's request has been heard, so...



LEO:  All right.



STEVE:  ...I did my job.



LEO:  I get equal, maybe more requests saying knock it off, Laporte, it's not funny.



STEVE:  You've struck a nice balance, then.



LEO:  Don't forget, if you go to GRC.com, to get your copy of SpinRite, the ultimate, the only, the one-and-only, the only program worth paying for, hard drive maintenance and recovery utility, and all of Steve's great free stuff like ShieldsUP! and all that great stuff.  And soon to come, some neat new stuff.



STEVE:  New cool stuff.



LEO:  Steve, we will see you next week on Security Now!.



STEVE:  Talk to you then, my friend.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#159

DATE:		August 28, 2008

TITLE:		Vista Security Bypass

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-159.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss some recent revelations made by two talented security researchers during their presentation at the Black Hat conference.  Steve explains how, why, and where the much touted security improvements introduced in the Windows Vista operating system fail to prevent the exploitation of unknown security vulnerabilities.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 159 for August 28, 2008:  Is Vista Safe?  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now! Episode 159, the one I've been waiting for for some time.  Ladies and gentlemen, may I introduce you to our majordomo of security, the king of lockdown, Mr. Steve Gibson.



STEVE GIBSON:  Yay.



LEO:  Host of GRC.com, Gibson Research Corporation, creator of SpinRite, and a guy who's really done a lot to forward the idea of security.  He's the guy who put Microsoft's feet to the fire over raw sockets.  He discovered spyware and coined the term.  And on and on and on.  Of course also the creator of ShieldsUP!, which is, as of right now, the most used test of firewall security in the world.  Hi, Steve.  How are you today?



STEVE:  Hey, Leo.  It's great to be back with you.  And we've got more goodies coming.  I'm working, I'm just having the time of my life writing code.  There's nothing I like better.  So I'll have another chunk of code result ready for our listeners here in another week or two.



LEO:  Oh, that's exciting.  That's really exciting.



STEVE:  That's going to be very, very cool.  This week we're going to talk about what we mentioned, I think, first two weeks ago, and then reminded people of last week.  There was a presentation other than Dan Kaminsky's, believe it or not.  Dan, of course, told us about what his discovery was earlier this year on DNS spoofing.  There was another presentation which I'm not - let's see.  The actual title of the paper was "Bypassing Browser Memory Protections."  And I call it "The Vista Security Bypass."  So that we're going to talk about.  I've got a bunch of security news.  And, Leo, the SpinRite testimonial to end all SpinRite testimonials.  In fact, I'm a little concerned that no one will ever again bother sending one in after they have heard this one.



LEO:  Wow.



STEVE:  I mean, I really - I still want them, folks.  But this one, nothing I could say could prepare you for this.  It came in over the weekend.  Greg, my tech support guy, sent it to me.  And as I'm reading it I'm thinking, oh my goodness.



LEO:  Wow.  Can't wait to hear that.



STEVE:  Believe it or not...



LEO:  Go ahead.



STEVE:  That is not too much of a buildup, believe it or not, so.



LEO:  Okay, I'll be the judge of that.  I don't know, that's a pretty big buildup.



STEVE:  That's fine.  I accept your judgment.



LEO:  We are going to talk about Vista and is it really safe or not, is it really locked down or not, and what does this discovery mean.  So, you know, it's funny, I don't know if you noticed, but I came in this morning, this is not a Patch Tuesday, I got an update, a critical update this morning.



STEVE:  Yeah, well, Microsoft - remember I mentioned last week that some seem to be drifting in a little bit late.  It was confirmed that Microsoft messed up some of the patches from the first shot on Tuesday.  And so they were amending them and making some further changes.  So, yes, there have been - some other things have been drifting in more recently.



LEO:  I didn't look - it didn't require a reboot, but I didn't look and see what it was.  So in other words, others may have gotten that last week, it's just they're kind of rolling them out slowly?



STEVE:  Yeah, yeah.  The big, well, there's a couple interesting things.  The potentially most interesting news of the week was a story that was picked up by a number of computer journals.  I don't know if it's made the popular press because I know that InformationWeek, ZDNet, and the Register in the U.K. picked it up.  There was a Polish security researcher by the name of Adam Gowdiak, G-o-w-d-i-a-k.  He claims, and Nokia has since confirmed, that he found two serious security vulnerabilities in the Java mobile technology J2ME, which is deployed on Nokia Series 40 handsets, of which there are more than 100 million.



LEO:  Wow.



STEVE:  Now, you'll remember last week I said radio is bad.



LEO:  Yeah.  Anything broadcast is risky.



STEVE:  Any, yeah, radio is bad.  I mean, yes, it's useful.  Yes, we use it, you know, because it's so handy and so potentially beneficial that it's like, okay, well, how bad is it?  Well, in this case Nokia's very unhappy.  This guy actually was holding them and Sun ransom to the tune of 20,000 euros.  He wanted 20,000 euros from each of them, which is just shy of about 3,000 U.S. dollars at the moment, before he would tell them what he found.  But he told them enough.  Apparently there are remotely executable exploits in more than 100 million Nokia Series 40 phones.  Those tend to be the low-end handsets that are using that particular run of the Java system.  Which, if you know the phone number, you can, without any permission required or knowledge from the handset's owner, you are able to install and run any code remotely that you want.  So that's not good.



LEO:  That isn't good.



STEVE:  That's not good.



LEO:  Matter of fact, that's terrible.



STEVE:  It's terrible.  So Nokia's scrambling around, running around, trying to figure out how they can mitigate it, what they're going to do.  I mean, this is in 100 million low-end handsets.



LEO:  Unbelievable.



STEVE:  So, you know, this is what happens.  And again, I did smile a little bit because I thought, well, okay, this is bad, but so is radio.  I mean, it's just - it's risky.  So the other news, and when I saw this I checked, Opera is getting a lot of updates.  And there's another one.  So anyone running Opera, check your little, under the Help deal, check for updates.  And you'll find, if you're not already on 9.52, that there is now 9.52 ready for you.  On the Windows edition that update fixes seven flaws, five in the Mac, and six in Linux.  So there's a bunch of stuff.  They've been - most of what they fixed they've revealed.  But they're being coy in one case where there's some sort of a cross-site scripting vulnerability - we did a whole episode on Security Now! a while  back on cross-site scripting - that essentially allows various sorts of exploits to be pulled off with the benefit of stuff from the browser getting into a website and confusing the code that runs on the website in a way that allows you to, like, get your credentials messed up or spoof who you are to another site and so forth.  Anyway, it's a bad thing, so you definitely want to get that fixed.



And one last little bit on the DNS flaw that I've picked up, I thought was very interesting.  The DNS flaw that we've spoken about now for several weeks is, Dan says, is actively being exploited, although there's not a lot of people talking about it.  It's the kind of thing now that ISPs are not going to be probably anxious to blab about.  But in the case of a Chinese, a large Chinese ISP called China Netcom, there was an exploit against their name servers that I thought was rather clever.  And that is, somebody is injecting mistyped domain names, similar to Amazon or Google or Microsoft or those.  And if you think about it, everything we've been talking about was the notion of overwriting valid domain names with something else.  Well, there's nothing to prevent you from injecting, like making up domain names that don't even exist in, for example, in the dotcom servers.  The same spoofing attack would allow you to deliberately create every kind of misspelling of Microsoft that you can imagine someone might make, and just stuff an ISP's name server with all those misspellings.  And in this case, in every case they direct your browser to an IP that brings up a page which attempts to exploit all the most recently disclosed and fixed, but still maybe not patched in, for example, Chinese machines, which we know tend to lag behind the patch levels of Western machines, just as a consequence of the machine's heritage and software and so forth.  So I just thought that was an interesting twist on, I mean, they're using the Kaminsky approach of jamming records into a DNS server.  In this case they're not replacing valid ones, they're filling the server up with all kinds of mis-typings.  So that someone makes a typo, and rather than getting "Sorry, we couldn't reach that site," they are exploited.



LEO:  Right.  That makes sense.  And this isn't really a new idea.  People have been exploiting typos for a long time.  You mistype Amazon you're sure to get something else related or an advertising site or something like that.  But this is a new switch, a new thing on it.  They're really kind of, that's right, amazing.  Boy.  I have a security story that I just saw that I thought you might be interested in.  And there's nothing you could do about this but shake your head.  According to eWEEK, a laptop sold on eBay contained personal information about more than one million customers of the Royal Bank of Scotland, American Express, and NatWest.  Information included historical data related to credit card applications - and you know what's on a credit card application - and data from other banks.  They wouldn't say more.  It's just stunning.  Just stunning.  Sold on eBay.  A former employee sold the computer earlier this month without removing the information.  It was an employee of a third-party archiving firm.  So these...



STEVE:  Ooh, no kidding.



LEO:  Yeah, yeah.  Isn't that good?



STEVE:  I wonder what it was doing on a laptop?  I mean, why would - because if they're a third-party archiver, then they're archiving...



LEO:  It shouldn't be on a laptop.



STEVE:  ...highly, yes, highly confidential information on behalf of their clients.  And, oh, boy.



LEO:  According to the Daily Mail, it was being held by a company called Graphic Data.  They're an archiving firm.  They copy paperwork.  Oh, I know why.  They scan the paperwork.  This is paper that they scan in.  Maybe the laptop was being used to do that.



STEVE:  An intermediate, ah, that's still...



LEO:  It contained names, addresses, mobile phone numbers, bank account numbers, sort codes, credit card numbers, mothers' maiden names, even signatures.



STEVE:  Everything you need.



LEO:  Every - it's a kit.



STEVE:  Can you say "identity theft."



LEO:  It's a kit.  Thank goodness the person who bought it said, whoa, and didn't use it.



STEVE:  Yeah.



LEO:  Unbelievable.



STEVE:  Okay, Leo.



LEO:  I'm going to calm down.  I'm ready.  But wait a minute.  Okay, go ahead, do that, and then we'll do the - then we'll talk about Audible.  I don't want to keep people in suspense any longer.



STEVE:  Okay.  Now, the subject line, it's like, okay, maybe this is a little over inflated.  Subject says:  "SpinRite 6 Saves 8 Lives."



LEO:  Okay.



STEVE:  It's like, okay.  "Because of the nature of this email and what it contains, I would like to stay anonymous.  Thus the email address I used."  Actually this was sent - and I won't even read that because he might not want to get a response.  "You can use this on Security Now!, though there are no names, and the geographical location is not important.  Just know it is terrorist country."



LEO:  Oh.



STEVE:  "We are 50 miles from the safe zone and have to cross a quarter-mile deep by 10-mile wide danger zone containing land mines.  But we aren't really sure where they are.  We have two injured men, one who can't walk and has to be carried on our backs.  We take turns doing this.  Here is the story.  I am part of a six-man team deep into terrorist country on a rescue/snatch-and-grab mission."



LEO:  Holy cow.



STEVE:  "It has been 10 days, and we made it 45 miles on foot to our destination, where we had to complete the mission, then cross the quarter-mile danger zone lying somewhere ahead in the next five miles.  We started out with three Panasonic Toughbooks, the tablet PC style, and one was quickly shot by small arms fire three..."



LEO:  Even a Toughbook isn't going to survive that.



STEVE:  Oh, no.  Get this.  Half the screen did.  Anyway, "One was quickly shot by small arms fire three days into the mission, and the screen was hit.  Even though it still worked on half the screen, we trashed it" - that is a Toughbook - "and took the hard drive out of it for security reasons.  Another one was used to defend against an attacker with a large stick in his hand.  But the laptop still worked, or so we thought.  It was powered on at the time of using it as a club to hit someone over the head, and the hard drive was damaged.  The third one was lost when we had to egress quickly, leaving us with only one laptop, the one used as a club with an unknown-to-us damaged hard drive."



LEO:  Holy cow.



STEVE:  "On the rescue, like most missions of this nature, to say they don't go as planned is an understatement at best.  We were down to one laptop for the mission, and we badly needed it for communication and GPS navigation.  Although we have handheld GPSes, in the infinite wisdom of the people in command of this, the solar panels we used to charge everything only worked for the laptops and radios, not the handheld GPSes.  So they were out days ago.  So we completed the first half of the mission.  Now we had to get back.  That's when the problems arose."  It's like, oh.



LEO:  That's when they had problems?



STEVE:  So far this is business as usual.



LEO:  It probably is for these guys.  You think this is legit?



STEVE:  I do.  You'll see.  There's a lot of facts here.  And this is a SEAL team, he mentions in a minute.



LEO:  Oh, my goodness.



STEVE:  "So 30 miles into the trip back, the laptop crashed, locking up.  And when it was rebooted, we got the 'Please insert boot media' message, and we were screwed.  We had the hard drive from the other laptop that was damaged three days into the mission.  And since it was from the same model laptop, it worked fine when placed into the last surviving machine.  At first.  Then it gave us the BSOD."  Of course, the infamous Blue Screen of Death.  "Now, remember, there are eight of us - two men injured, one who has to be carried, and the other six of us.  This mission had to be completed.  A SEAL never leaves a man behind, even if they are dead.  So we kept moving because we had to.



"One of the men knows of a village two miles from our current location that might be able to help.  We go there, having no other choice in the matter.  We have to have that GPS, or we have to go at least five miles out of the way closer to enemy soldiers, or cross the mine field with no GPS to guide us through the safe parts.  Not good.  At the village, we find someone with satellite Internet."  He says, parens, "(This is where the small size of SpinRite is a blessing.)"



LEO:  Yeah, no kidding.



STEVE:  He says, "And we use a VPN to try to communicate with command to let them know what the problem is.  But we can't establish an uplink since we're getting such low bandwidth."  Well, he's going to be needing CryptoLink here before long.  But for the moment, we don't have that.  So because they're getting such low bandwidth, they cannot establish an uplink.  "And we didn't have the cables we needed to plug in the satphone and use its modem.  So we had to call command and let them know what the problem was.  There was nothing that could be done.  We weren't even supposed to be in this country in the first place."



LEO:  Oh, man.



STEVE:  "So I decided to try to buy SpinRite."



LEO:  Did he have a credit card with him?



STEVE:  "And try it right there on the spot."



LEO:  Oh, my goodness.



STEVE:  He says, "I am the geek in the bunch.  So the others, two of which are 'jocks,' don't believe it will work.  We didn't have a credit card of any kind, or anything else that might identify us, of course.  So we asked the owner of the house, and he said yes; but 100 U.S. dollars was the max he could spent a month and had already spent most of that on supplies for their store.  So we were screwed again.  Or were we?  I went to a dangerous, illegal, underground pirate site and found an illegal copy.  Sorry, GRC."



LEO:  At least he tells the truth.



STEVE:  "At the satphone's very low data rate, it took eight minutes to download the pirated copy of SpinRite."  And he says, parens, "(Sorry about stealing it, but it was a life-or-death situation, and I bought it later.)"



LEO:  I'm sure you don't mind, Steve.



STEVE:  Of course not.



LEO:  In fact, had you known, you would have sent it to him immediately.



STEVE:  I've been wondering if we need to put on the eCommerce system an emergency SEAL rescue team free discount button.



LEO:  Wow.



STEVE:  So, he said, "We had blank CDs, so using SpinRite to create a boot CD was no problem.  I booted the machine with SpinRite, ran it at Level 4 on the 20GB hard drive, and it found about 12 red U's and recovered 10 of them.  After nearly four hours of repair, SpinRite was finished.  The computer booted up correctly, and we were able to use it to navigate across the minefield to safety."



LEO:  Oh, my goodness.



STEVE:  "Later we learned that the enemy was only two miles behind us and surely would have caught us if we had to slowly navigate the minefield, probing for mines while covering the quarter-mile distance, or if we had to go completely around the minefield.  There is no doubt that, had we been captured, we would have been tortured and killed for sure.  So SpinRite 6 saved eight lives that day, in my opinion.  Thank you for your great product."



LEO:  Yeah.  Okay.  You're welcome.



STEVE:  "It is now an unofficial piece of the toolkits many SEAL teams have with them on every mission, purchased by the team leader since the higher ups don't want to buy a site license for whatever reason.  It is run on every single computer we use before we leave, and any hard drive having even one red 'U' is discarded and replaced after we get back, just to be sure this never happens again.  The IT guys here know about this and have been pushing this for some time now, but it just 'isn't in the budget.'  Well, now maybe they'll reconsider that.  Again, you can use this on Security Now!.  I have left out names and locations on purpose.  Please don't try to guess the location or anything like that on the show, but you can talk about it."



LEO:  Wow.  You think that's real?



STEVE:  I don't know.



LEO:  Wow.  Somebody has a very good imagination if it's not.



STEVE:  Yeah, and lots of details and so forth, so...



LEO:  Man.



STEVE:  Yeah.  I mean, it certainly, I mean, a lot of the information, you know, Panasonic Toughbooks, obviously they needed them for communications and navigation, so they had redundant Toughbooks.  They had three.  And as he said, these things don't go - they never go the way you expect.  And, you know...



LEO:  That's the truth, yeah.



STEVE:  ...plan got shot.



LEO:  Every plan is immediately just thrown out when you...



STEVE:  And he had to "El Kabong" somebody with another one.



LEO:  That's amazing.  I just checked.  Somebody in the chatroom sent me a link.  The Navy does use Toughbooks.  So, I mean, I'm sure they have mil-spec stuff.  But...



STEVE:  Yeah, and wouldn't you think maybe solid state drives would make sense in this case?



LEO:  Would they be more resilient to use as battering rams?



STEVE:  Yeah, I mean, you've got to bonk someone over the head, it wouldn't hurt a solid state drive.



LEO:  No moving parts.  But then they couldn't use SpinRite, so...



STEVE:  Well, they wouldn't need SpinRite.



LEO:  Okay.



STEVE:  I mean, I'd rather that they stayed alive.



LEO:  Yeah, no kidding.



STEVE:  Oh, my goodness.



LEO:  What a story.  That is very dramatic.  And if it's true, thank you for sharing it with us, and thank you for your contribution.



STEVE:  Well, and I presume the person who wrote this, hopefully truly a Navy SEAL, will be hearing his story read by us, since he clearly is also, as he said, he's the geek in the squad and a Security Now! listener, so I thank him for the mission, and I am sure glad that it worked out.



LEO:  That must make you feel pretty good.



STEVE:  That's very cool, yeah.



LEO:  Your software was used to save lives, eight lives.



STEVE:  Now, as I said, I still want to hear from people whose photos we save.



LEO:  Holy cow.



STEVE:  Because that matters, too.



LEO:  You know what, I thought you were building it up too much, you know, there's no way you could live up to what you - but you were right, you couldn't possibly build that up too much.  That's an amazing story.  Thank you for sharing that with us.



All right, Steve.  It's time to get to work here.  We have a lot of people who heard about this presentation at Black Hat.  Or was it at DefCon?



STEVE:  It was Black Hat.



LEO:  DefCon follows Black Hat, but Black Hat's like the more serious one for security professionals; right?  And DefCon is kind of open to the public.



STEVE:  Yeah.  And this was, okay, this is an extensive paper.  I'm going to run through and summarize essentially what these guys have done.  Their work, however, is very solid.  I first picked up on this from a little blurb that someone sent me from Bruce Schneier's log where he had picked up on this.  And he said this is big.  There were some follow-on where people were sort of pooh-poohing it, saying this really isn't that big a deal.  But once again, this demonstrates in my opinion that Bruce gets it, as he always does about security.  This is big.  This is still sort of leading-edge fringe capability.  But that's the way these things always start, and they always evolve.  I'm going to read just the introductory paragraph from this paper to give our listeners a sense for the content of this.  It says - because again, this is serious, corporate-level, really beautifully put together work.



"Over the past several years Microsoft has implemented a number of memory protection mechanisms with a goal of preventing the reliable exploitation of common software vulnerabilities on the Windows platform.  Protection mechanisms such as GS, SafeSEH, DEP and ASLR" - all of which I'll explain in a second - "complicate the exploitation of many memory corruption vulnerabilities and, at first sight, present an insurmountable obstacle for exploit developers.  In this paper we will discuss the implementations and limitations of all aforementioned protection mechanisms and will describe the cases in which they fail.  We aim to show that the protection mechanisms in Windows Vista are particularly ineffective for preventing the exploitation of memory corruption vulnerabilities in browsers.  This will be demonstrated with a variety of exploitation techniques that can be used to bypass the protections and achieve reliable remote-code execution in many different circumstances."



LEO:  Oh, boy.



STEVE:  And they have done that.  So stepping back a little bit, first of all, I wanted to remind our listeners, or maybe those who have been listening since Episode 67, meaning they never heard 66 - 66 was our episode entitled "Windows Vista Security."   And we laid out during that podcast - that netcast.  I'm going to try to use the word "netcast" from now on.  I see you're using it uniformly, Leo.



LEO:  Well, I'm not using it uniformly.  I use "podcast" all the time because that's kind of colloquial.  But I do prefer it because what are we doing on the TWiT Live thing?  It's not a podcast.



STEVE:  Right.



LEO:  It is a netcast.  So I just like the idea better, you know.



STEVE:  So anyway, on Episode 66 we sort of basically covered in very good depth and detail the two main new features in Windows Vista:  DEP, which is Data Execution [Prevention], and in fact I have mentioned that in some subsequent podcasts, so if you just did a search on the Security Now! page or search GRC in our own little built-in search tool for DEP, Data Execution [Prevention], you'll find our references to that in Security Now! podcasts.  The other mechanism is ASLR, Address Space Layout Randomization.  Both of these are intended to go a long way toward thwarting exploitation of various types of vulnerabilities.



Now, over and over and over, the problems we see in vulnerable software are problems with pointers not being checked, or the very common buffer overrun problem where essentially some software allocates a certain amount of buffer space, sort of dynamically, that is, the code jumps into the routine, and it wants to read something or get something, fetch something from outside.  So it will allocate some buffer space.  Many times it's on the software stack, which is a variable size sort of scratchpad area that software is able to use.  And then the program will say, give me the data that I'm expecting.  Well, programmers typically say, oh, they know what expected data size is.  And very, very careful programmers will go to some lengths to limit the amount of data that they copy into the buffer.  But, I mean, it only makes sense.  If you say, okay, I'm setting this much space aside, then I want to bring the data into this buffer.  And naturally you don't want to bring more data into the buffer than the space you've made available.



Well, it turns out that, for whatever reason, this is probably the most common of all vulnerabilities is an attacker will find an instance in some vulnerable code, a particular function or some way of invoking a function and giving the code data that it doesn't expect, data that it isn't prepared for, data that causes it to behave in a way that allows other data that the malicious hacker supplies to be put somewhere in memory where it wasn't intended, and then after that to cause that code to be executed.



So basically what we have is an ongoing cat-and-mouse game with Microsoft and the developers of Windows versus the bad guys.  And so one thing gets done, someone figures out - a bad guy figures out how to exploit something.  Microsoft looks at the exploit and says, okay, we're going to fix that.  Well, so all the patches we're constantly getting, these things that are every second Tuesday of the month, all these patches, these updates are specifically new problems of exactly this sort that have been found in specific instances of Windows.



The problem is, Windows is so vast and is so large that it's - well, and frankly so capable.  Many of these things are resulting from the flexibility that Microsoft has often deliberately, sometimes inadvertently, put into Windows.  For example, and we've talked about this in many episodes of Security Now!, it's possible for a browser to invoke an ActiveX control that never was useful in a browser context.  That is, it isn't something that you would normally expect a browser to load.  But Windows will do it for you.  So if anywhere else in the system an ActiveX control, which is really just sort of a specific type of DLL, if a vulnerability is found in one of its functions, then someone can create a web page that tells that to load and give that function some data that it isn't prepared to accept the way it's given.  And that will allow them to inject their own code through the Internet, through the browser, into this vulnerable object which has been found in Windows, anywhere in Windows, essentially.  And due to the fact that there's this vulnerability, they can end up running their own code, thus take over the system remotely.  That's a remote code exploit.



Okay.  So for years Microsoft was in this, okay, look, we're going to fix everything that we can find that's wrong.  The problem is, they're always playing catch-up.  That approach is always reactive.  Microsoft finally began to get actively proactive, first with XP, further with Service Pack 2 of XP, and then again with Vista.  By, essentially, by incrementally making these things harder to exploit.  And so as you heard in the beginning of this paper, what these research hackers have done is to carefully look at the various mitigation efforts Microsoft has implemented over time and looked at, okay, how do we get around those?



So, for example, Data Execution [Prevention], DEP, what it does is it is a technology available in microprocessors since 2004, that is, it's a software technology, but it relies upon a feature called the NX bit, the No eXecute bit, which was not available in flat memory model, which is what Windows runs in ever since Windows 3.1.  The 16-bit versions of Windows were segmented model architecture.  In the segmented architecture you could mark segments as non-executable.  But due to sort of a design oversight in the Intel architecture, in a flat-mapped  memory model, which is what we have in 32-bit Windows, you are not able to mark individual pages of that memory as non-executable.  So we had to wait for another generation of microprocessors from Intel that would offer the - well, and AMD - that would offer the so-called NX, the No eXecute bit.



And so the idea with DEP is that only the memory that is expected to have code in it would be marked as executable.  And so data memory, like for example the stack that I was talking about where you allocate buffer space and variables, well, you don't run buffers, you read and write them.  You don't execute them.  So those are, you know, three different operations:  read, write, and execute.  So the stack would be marked No eXecute, meaning that any attempt to overwrite the stack, to overwrite a buffer and execute on the stack would immediately result in the processor terminating the - or in the operating system receiving notification of this violation.  And the OS would just terminate the process instantly, bang.  Just the attempt to execute that instruction, the first instruction that attempted to be executed in that space would never complete. 



LEO:  What does that look like to the user?  Do they get a blue screen?  Do they get...



STEVE:  What they get is a sort of annoying warning.  And in fact, anybody who has tried to turn on DEP - there are four ways that DEP can run.  And this is one of the problems with its actual implementation in the real world.  And we talked about how Microsoft has an opt-in policy for DEP rather than an opt-out policy.  And of course we talk about opt-in and opt-out relative to cookies and spying and everything.  And this is sort of similar.  The idea is that you can, if you turn your OS - if you boot it with DEP in opt-out mode, meaning that it is normally on, but you opt out specific things, every so often you get dialogue boxes.  In fact, I got Internet Explorer itself - I'm sorry, Windows Explorer itself gave me a DEP error just yesterday because on my laptop, I mean, I try to run with DEP enabled.  And I can vouch for the fact that it's painful.  There are programs that are not DEP compatible.  Thus in XP and even in Vista the Data Execution [Prevention] that is so valuable is opt-in.



Now, programs can be assembled with the so-called "NX compat flag," meaning that when they are assembled and linked, they can have a flag built into them that says, I am DEP compatible.  So Microsoft has been very good, to their credit, threw out all of the OS components and even their own applications to rebuild them after checking to make sure that they were DEP-friendly with this NX compatibility flag.  So Windows itself is running with DEP enabled, as are Microsoft's apps.  The problem is, there's a lot more in Windows than the code that comes from Microsoft.  And many other vendors, the vendors of many critical components, for example, like Flash from originally Macromedia, now Adobe, and even the Sun virtual machine.  Their technologies, especially in the case of Java, Java has, deliberately has readable, writable, and executable memory because of the way it operates.  So it's a big target.  And so many of these third-party things, which you could pretty much depend upon, you know, Flash player is installed in the high 90 percentile of Windows machines so you can count on it being there.  So as I mentioned that DEP operates in either - you can either have it completely off, in opt-in, which is a little more secure than off completely, but not much; in opt-out, which is certainly more secure, there you're saying by default anything that isn't marked specifically compatible, we're going to assume it is, but if it blows up on you, you know, when you get an annoying dialogue box that says, oop, DEP execution error, Windows is terminating the execution of this application.  And it's like, oh, okay.  I mean, and again, it happened to me in Windows Explorer the other day.  So it's not quite as DEP friendly as Microsoft was thinking.



And then the fourth is always on, which is to say, DEP is on, it is enabled, nothing can turn it off.  Well, it'd be wonderful if we could run our machines that way.  The problem is, they won't run that way.  There are known programs that have to have DEP disabled.  And so part of the problem that these guys have talked about is the fact that there are, even in this day and age, using the latest versions of everything in a contemporary Windows system, Windows Vista, the most recent service pack, running the latest and greatest, there are enough programs that have - well, and Vista by default is, remember, is opt-in.  So there are enough programs that have not yet deliberately marked themselves as DEP enabled, that Vista will not enable DEP for them since you have to explicitly ask for it because there are just too many incompatibilities still.  Because those programs are not enabled that way, there are plenty of opportunities for exploit even though we're at Vista Service Pack 1, and Microsoft talks about how powerful DEP, Data Execution [Prevention], is.  It turns out it's not really.



LEO:  It would be if you could leave it on and it would run all the time on every program.  It is an old habit of programmers to put code in the data areas, which is essentially why DEP doesn't work for these guys; right?



STEVE:  Well, it's, frankly, I mean, it's...



LEO:  It's a bad habit, but it's a habit.



STEVE:  Well, actually it's very useful.  There have been - there are situations where you actually need to execute data.  I mean, that's what interpretation is.  A good, fast interpreter can actually execute some of the data that it's reading.  Back in the old days of Windows, back before we had display acceleration, where we didn't have a so-called "hardware blitter" that would blast rectangles around the screen, which is so important for these, you know, everything in Windows is a rectangle of some sort.  Microsoft's original GDI, the Graphics Display Interface code, it would look at the job it was being asked to do.  And so much of it is repetitive and involves loops and counters, when you're moving data around, and you're having to, like, shift the bits by strange amounts in order to cause them to be bit-aligned on the screen, the original GDI actually built the blitter on the fly on the stack and then ran it.  It executed it.  So there Microsoft went, I mean, they were going to all kinds of trouble to make Windows run at an acceptable performance on an old 4.77MHz PC, an old 8088 or 8086.  And they had to pull out the stops.  So there are times when executing on the stack, or executing data that is deliberately variable, is very useful.  And when you think about it, technically, anything coming over the wire is data.  You know, so if something downloads into your browser and says hey, I'm an ActiveX control you just loaded, would you give me permission to run, it's like, well, okay, that's data, but we're executing it.  So...



LEO:  Right, right, okay.  So you make a credible case that there are times.  And as an Assembly language programmer, is that something you do a lot?  Not really.



STEVE:  I'm not - I can't think of a place where I have.  But...



LEO:  So we're not going to see the end of it?  I mean, doesn't functional programming or, I mean, don't more modern programming techniques make it less necessary to do this?



STEVE:  Well, it's certainly dangerous.  And you're right that we're moving toward an era where DEP will be turned on, where there will be increasing pressure on people.  Certainly after this paper has come out where these guys demonstrate clearly the exploitability of Flash, which is not DEP compatible, it's like, okay, Adobe, if you want your code in my machine, you make it safe.  Because we've seen a bunch of Flash exploits here in the last few months.  And, you know, this wouldn't be possible if Adobe would do the work.  I don't care how hard it is, it's certainly possible to code around this.  That is to say, I guess to answer the question you were asking, Leo, is it absolutely necessary to execute data, and I would argue no.  It is possible for an application to explicitly - you're able to use something called VirtualAlloc, the virtual allocation commands in Windows.  If you want to allocate executable pages, you can.  But you could set it up so that the software knows it needs to execute something that is in data, so it explicitly sets itself up with permission to do so.



Basically this is laziness.  In this day and age, for Flash still not to be marked as DEP friendly when it is in a highly vulnerable environment, it's not like it's something down on your tray, it's in your browser.  And we know what a target browsers are just by their very nature.  I mean, in fact, the whole focus of this paper was specifically browser vulnerability.



Now, another thing that has been done that Microsoft did to further complicate things is this ASLR, Address Space Layout Randomization.  One of the key things that hackers do is they're able to use code that's already in the system.  They, like, they look at the disassembly of Windows, and they say, oh, look at this, this code, if I jump into it right in this weird spot, where it was never designed for anyone to jump in, I can get it to do some work for me that I need done.  And so, for example, sometimes the first thing that a malicious hack will do is it will jump to somewhere in Windows in a way that Windows was never designed for and execute a little chunk of code that then hits a return instruction that comes back to where it came from.  So the hacker, the malicious exploiter, has just gotten somebody else's code, Windows code typically, to execute on their behalf in a way that Windows never intended.  Then maybe they jump somewhere else, and they make something else happen.  They don't even have to supply their own code.  They just use code that's already in the operating system that's known to be in a specific location.



And that's the key of Address Space Layout Randomization.  Microsoft figured, okay, we're getting hacked all the time because we always load Windows in the same way.  We load ntdll.dll, then we load csrss, you know, we stack these DLLs in a specific, totally predictable fashion.  Therefore we're setting ourselves up as a target.  Let's randomize the layout so that literally every single time the system boots, the main core Windows DLLs load in a different place.  So it's no longer possible to have a fixed pointer, which you know is going to point at a useful piece of code that exists in Windows, it's going to be in a different place every time.



Now, the problem is the details, of course, the implementation.  What Microsoft has done is they take an 8-bit value from the timestamp counter.  All Intel processors have an instruction, which I do use all the time, called rdtsc, Read Timestamp Counter.  That is, it's a screamingly fast counter.  It literally is a counter of the clock, which means three giga counts per second.  And so, I mean, this thing, there's just so much variation with the rotation rate of the hard drive, keyboard clicks, mouse clicks, there's no way that the same count is going to be pulled from this little counter which is screaming at three giga counts per second.  So Microsoft pulls the eight bits from the counter, multiplies it by 64K, and uses that - oh, except they never use a value zero.  There was a bug in the first version of Vista where it would use - where if it got a zero, it just made it a one, which meant that there, I mean, this is a small bug, but it meant that there was twice the chance that you would be at the location one versus two through 255 because you turned a zero into a one.  They fixed that so that they completely smoothed out the statistics of what value you were going to get when you pulled this value and multiplied it by 64.  So they multiply by 64K, and that sets - that value is added to that executable's preferred load point in memory.  So essentially, as Windows now boots, in Vista and in Windows 2008, but not in XP or 2003, so in Vista and Windows 2008, as it loads it's randomizing these things.



Okay.  Here's the problem.  Address Space Layout Randomization only works if everything in the machine is randomized.  That makes sense.  I mean, you don't want any code to be in known fixed locations.  Turns out that only newer executables, that is, EXEs and DLLs that are explicitly marked as ASLR compatible will be randomized because Microsoft also learned the hard way, no doubt during the early testing of this, that there was code that expected to be loaded where it said it wanted to be loaded.  Individual executables contain what's called the Image Base Address, which is where they want to be loaded.



Well, it turns out that, unfortunately, some programmers have made their own programs dependent upon the load location that they specify, and they don't work if you load them anywhere else.  And, unfortunately again, as is the case for Data Execution Prevention, this is the case for tons of non-Windows components, that is, non-core OS components, which is what Microsoft has successfully randomized.  But that leaves a wide-open field of other things that are very popular, known to probably be in the system, and can be invoked through the browser.  So anything, for example, provided by ISVs - ActiveX controls, browser extensions, protocol handlers for browsers, and especially image parsers or codecs are generally not yet ASLR compliant, so they won't be randomized.  And again, a hacker who knows nothing about your computer can inject something into your browser that will cause it to cause something else to load in a known location, and that could be exploited.  And again, these guys demonstrate that.



LEO:  That's pretty incredible.  So what do we do?



STEVE:  Well, essentially this is a wakeup call.



LEO:  Yeah.



STEVE:  For, again, it's a cat-and-mouse game.  This is a wakeup call, I would say, for developers everywhere.  For example, when I'm developing my forthcoming VPN product, CryptoLink, I will absolutely always be linking it with ASLR enabled and with the NX compatibility flag enabled all throughout development.  So that if at any point I do something which is position dependent or writing into its own memory, I'll instantly know and go, whoops, and fix that.  So that when I ship the product it will fundamentally be as secure as it can be.  I certainly don't want my own code to be exploitable by some malicious hacker somewhere through the web browser.  I mean, I can't imagine how that would happen, but this is the way these things happen.



So really it's now - it's like Microsoft has done really everything they can.  When you look at the details - and I skipped over tons of details.  But Microsoft, I take my hat off to them, they have really bent over backwards to thwart every possible exploit mechanism based on looking at exploits, and not only just chasing after them reactively, but now really getting proactive.  The problem is, Windows is a rich environment that runs - it's extremely heterogeneous, with bits and pieces coming from all over the place.  And it really is necessary now for all of the other players to work with Microsoft, to work, I mean, they don't need Microsoft's permission.  They just need to turn these things on, take the time to stop being lazy about this and get their stuff to work so that these latest protection measures can be employed.



LEO:  All right.  So but again, there's nothing - in the interim is there something to worry about?  Are these exploits in the wild yet?  Are we...



STEVE:  Well, okay.  This was a theoretical paper that said, okay, you guys are so impressed with DEP and ASLR - and, I mean, there's other things too that I didn't talk about.  Structured exception handling, stack cookies, heap spraying, there's just all kinds of stuff.  Oh, I have to say this, though.  Get a load of this.  Okay.  We know with IE7 that it's much more secure than 6 was.  One of the nice things about IE7 that I really appreciate is you get a pop-up notice when any ActiveX control that you haven't seen before is downloaded, and the web page you're visiting wants to run it.  Well, Microsoft is so fond of their new .NET framework.  And because it's supposed to run in a sandbox, very much like Java does, and be safe, they said, oh, we don't need to warn anybody about .NET.  So they don't.  And it's exploitable in the same way that ActiveX has been.  But we get no notice and no warning, no pop-up in the default configuration of Internet Explorer.



The good news is you can go in and turn off .NET permissions.  So one takeaway from this, the good news is .NET doesn't have much penetration today.  I'm not aware of anything browser-wise that runs it.  But it is, as a consequence of this paper, these guys demonstrate .NET silently exploiting Internet Explorer under Windows.  So I would immediately turn off .NET execution in Internet Explorer.  Just say no to that.



LEO:  Wow.  I mean, that turns off a lot of stuff.



STEVE:  Well, .NET?  No, I'm not sure that it does.



LEO:  Doesn't Silverlight rely on .NET?



STEVE:  Oh, darn.



LEO:  It turns out, I mean, the Olympics are over, thank goodness, but I think that turns off a lot of stuff.  I may be wrong.



STEVE:  I've got it turned off, and I haven't run across anything so far.  But you're right...



LEO:  Well, for sure Silverlight, yeah.



STEVE:  Oh, I guarantee you Silverlight is, I mean, that's a classic Microsoft .NET, oh, here you go, give this a try.  I mean, and it'll be exploited tomorrow.



LEO:  Well, just as Flash was.  I mean, in some ways that's kind of similar, isn't it.



STEVE:  Yes.  And again, the problem is that Microsoft assumed, as they always do, that they're not going to have any problems.  They have never not had any problems.



LEO:  It's very clear that in security you should assume the complete opposite, that you absolutely will have problems.



STEVE:  Yes, exactly.  I mean, you have to.  So essentially the OS is providing the tools.  Now, to answer your question, Leo, one thing users could try is what I have tried.  And that is to switch your Windows to opt-out so that rather than...



LEO:  Opt out on DEP.



STEVE:  On DEP.  So and you do that with a boot.ini switch.  We've talked about DEP in length, in detail.  And in fact my little SecurAble freeware app shows you instantly whether your processor supports the NX hardware bit, which is necessary in order for hardware DEP to be useful.  There is something called "software DEP" which is, well, I mean, they were unhappy when they first released Data Execution Prevention because at that time there wasn't a huge install base of processors that supported it.  And so they said, oh, well, but we have software DEP, and it doesn't require any hardware.  It also isn't very useful.  I mean, which is - even that is giving it too much credit.  So...



LEO:  I don't even know how you would do software DEP.  Doesn't it have to be in hardware?  And isn't this in the processor?  Doesn't Intel have the DEP processor in there?



STEVE:  Oh, yeah, well, Intel and AMD - since 2004 all processors have had this NX flag.  So it's only really old...



LEO:  Oh, AMD, too, yeah, yeah, yeah.  In fact, AMD I think did it first.



STEVE:  It'll only be really old machines that will not have it.  And so one thing users, I mean, really security-conscious users could do, as I do, is to run with DEP in its opt-out mode, where then by default applications will have it turned on.  As you learn that specific apps are not happy, then you are able to put them in a list of "leave DEP off for only these apps."  And you can then sort of evolve.  It's sort of like the way a personal firewall works, where by default it's blocking everything.  Then you learn, oh, wait, email needs to get out, IE needs to get out, Messenger needs to get out.  So you add exceptions to the "prevent all" rule so that those things which you know and want to have access to the Internet are able to.  Similarly, with DEP operating in opt-out mode, where it's on by default, you would be learning which apps were not DEP compatible.  So you say okay, fine.  I mean, and you could decide, like, whether you care about this particular app and want to run it or give it permission or not.



And so over time you evolve.  And that's certainly going to be more secure.  But it's not perfect.  I'm impressed with Microsoft having given us now with Vista the tools to make these exploits much more difficult.  It is very common applications like Silverlight, like Flash, commonly used components, or even Media Player, that are invokable by the browser and still not yet safe, that is really now the main target of exploitation.   



LEO:  Okay.  I guess we've got to get ready for a whole wave of exploits on this.  And how quickly do you think Microsoft could fix something like this?



STEVE:  Well, the problem is this isn't Microsoft's problem.  I mean, for example, these guys demonstrate using Java exploits, using...



LEO:  So it's just everywhere.



STEVE:  Using Flash exploits.  Yes, it's people - it's the third parties that have very popular, often-present code that now need to belly up and make their stuff work as well as Microsoft has the core Windows components.  They need to be very careful with Data Execution Prevention and the ASLR randomization.  They need to be compatible with those things so that they, too, will be loading in random locations, not known fixed locations, and that they're less exploitable by malicious code.  Right now those are - essentially, Windows used to be the so-called low-hanging fruit.  Well, basically we ate all of that.  And now we got it all.  It was low hanging, and it was easy pickings.  So now it's the very popular non-Microsoft components, which are lagging behind even Microsoft in taking advantage of the security features that are now in XP and Vista, they need to get going and make themselves secure.



LEO:  Wow.  So sounds like a really pretty big mess out there.  I mean, we all reasonably assumed that these two technologies, and others also named in the paper, would be the panacea, the magic bullet for security.



STEVE:  Well, and just to finish, let me read the conclusion of the paper because it sums it up beautifully.  They say:



"In this paper we demonstrated" - I mean, and they did, they've got code samples - "we demonstrated that the memory protection mechanisms available in the latest versions of Windows are not always effective when it comes to preventing the exploitation of memory corruption vulnerabilities in browsers.  They raise the bar, but the attacker still has a good chance of being able to bypass them.  Two factors contribute to this problem:  the degree to which the browser state is controlled by the attacker. and the extensible plug-in architecture of modern browsers.  The internal state of the browser is determined to a large extent by the untrusted and potentially malicious data it processes.  The complexity of HTML, combined with the power of JavaScript and VB Script, DOM scripting, .NET, Java, and Flash, give the attacker an unprecedented degree of control over the browser process and its memory layout.  "The second factor is the open architecture of the browser, which allows third-party extensions and plug-ins to execute in the same process and with the same level of privilege.  This not only means that any vulnerability in Flash, for example, affects the security of the entire browser, but also that a missing protection mechanism in a third-party DLL can enable the exploitation of vulnerabilities in all other browser components."  And then they finally say, "The authors expect these problems to be addressed in future releases of Windows and browser plug-ins shipped by third parties.



LEO:  So "future versions of Windows" sounds a little bit like it ain't going to happen tomorrow.



STEVE:  Yes.  And the problem is, Microsoft has tried to turn these things on, and they've gotten bitten.  You know, I mean, this is always the case, and this is what we talked about when we first talked about DEP and ASLR, why they were generally off by default.  But Microsoft was sort of creeping forward, trying to have them be on.  Oh, and get this.  You know how Vista 64 is substantially more secure.  For example, they have DEP on for all 64-bit processes.



LEO:  Oh, interesting.



STEVE:  And it cannot be turned off.



LEO:  Oh, interesting.  So that's possible.



STEVE:  But...



LEO:  Oh.  I got excited.



STEVE:  ...IE, Internet Explorer, is a 32-bit process.



LEO:  Turned off, right.



STEVE:  It's a 32-bit process under Win64.  And so it is policy driven.  It's driven by the DEP policy in the system, not turned on and enforced.



LEO:  That's really interesting.



STEVE:  So it's like, okay, Microsoft, get going.



LEO:  Yeah.



STEVE:  You know, fix this.



LEO:  Do other operating systems like Linux and OS X, are they also using these kinds of techniques to protect themselves, and are they also vulnerable?



STEVE:  Well, yeah.  And in fact Address Space Layout Randomization is not a new thing.  Windows is like the last OS to come along and implement this.  This has been around for a long time.  This is a classic case of Microsoft being the big target.  I mean, for example, we're seeing an increasing number of Mac exploits and vulnerabilities now.  I mean, those are happening.  We're getting security patches from Apple at an unprecedented rate compared to the past because hackers have Macs now.  It used to be that they predominantly had Windows machines.  Now they've got Macs, and they're poking around in there.  I mean, fundamentally we're dealing with phenomenally complicated systems.  And complexity is the enemy of security.  Any time it's complex you can't really be sure about every side effect and feature and bug.  And bugs will bite you.



LEO:  Yeah.  Apparently IE8 will have DEP turned on because it's going to be, I guess, a 32-bit process.  But and there's some debate over whether Silverlight uses .NET.  I remember, I was pretty sure it did use .NET.  But...



STEVE:  Actually it's IE8 and - I'm glad you mentioned that, Leo, because I wanted to mention this.  IE8 and Firefox 3 do, the IE8 beta and Firefox 3 both have the NX compatibility flag.  So they are opting in to DEP.  And so that's - I know that there have been some people that have said, eh, Firefox 2 is working just fine for me.  It's like, okay.



LEO:  Oh, no, get Firefox 3, yeah.



STEVE:  Firefox 3 makes a lot of sense, if only because the developers developed it with DEP on.  It's been vetted with DEP on.  And it marks itself as DEP capable.  And so all versions of Windows, from Vista forward, will turn DEP on in Firefox 3, and you want that buffer overrun protection for anything that might be going on in Firefox 3.



LEO:  So your recommendation is to use the opt-in setting of DEP now.  Is that right?



STEVE:  I would - it's a mix...



LEO:  In booting?



STEVE:  It's a mixed blessing.  I mean, it will cause you some problems.  It's why Microsoft didn't set it up that way.  They would love to have Windows be more secure.  But there are things that will cause problems.  And in fact in this case where even Windows Explorer gave me a DEP execution error yesterday, I just restarted it and it was fine.  It was, you know, Windows.



LEO:  It doesn't crash, it just restarts.  You restart.



STEVE:  Well...



LEO:  It just says you can't do that.



STEVE:  Okay, right.  All of Windows does not crash.



LEO:  No.  The program stops.



STEVE:  Yes.  Just Windows Explorer, I clicked "yes," it shut down, and of course Microsoft saw, oh, look, Windows Explorer is no longer running, that's bad.  And it restarted it for me.



LEO:  Right.  That's not so bad.  And when it comes to securing your computer, there's one guy.  There's the man, Mr. Steve Gibson from GRC.com.  He saves lives.



STEVE:  How did I know you were going to use that segue, Leo?



LEO:  I'm the king of segues, baby.  Yes, I am.  So Steve, it's really great to talk to you.  I'm glad to get this particular subject out of the way because I think there's been a lot of questions in the community, even in the expert community, what does this mean?  Does this mean we have to freak out?  Is Vista no longer secure?  What do we do?  Where do we go forward?  And at least understanding what was a very technical talk.  It really helps to kind of get some understanding in there so...



STEVE:  Yeah, it's not big news.  It's mostly just sort of a wakeup call.



LEO:  Yeah.



STEVE:  It's a reality check that says, okay, these things are available, but they are not being taken advantage of universally.  And it's not until they are that we'll be increasingly safe.



LEO:  Are and can be.



STEVE:  Yeah.



LEO:  I mean, it's not - in many cases we can't.  And that's kind of frustrating, too.  Okay, Steve.  Hey, it's great to talk to you.  Next week we've got a Q&A session.  How do people get their questions to you?



STEVE:  They want to go to GRC.com/feedback, where there's a form they can submit.  And by all means, I love people's questions.  It's great to get them, and then it helps us build a really great Q&A episode every other week.  So...



LEO:  Yeah, yeah.  While you're at GRC, don't forget you can get the 16KB versions of the show there.  You can get of course the transcripts that Elaine does, all the show notes.  It's all available at GRC.com, along with SpinRite, the program that saves lives.  Saving more lives every day.  It's an amazing program, the ultimate disk maintenance and recovery utility, GRC.com.  Also a lot of free security stuff, as I mentioned at the beginning of the show, including ShieldsUP!, Shoot The Messenger, DCOMbobulator.  And watch for some new stuff coming soon.



STEVE:  Thanks, Leo.  Talk to you next week.



LEO:  Take care.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#160

DATE:		September 4, 2008

TITLE:		Listener Feedback Q&A #49

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-160.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 160 for September 4, 2008:  Listener Feedback #49.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show where we explain how the Internet works and why it's so very dangerous to be out there without protection.  Steve Gibson's here from the Gibson Research Corporation.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be back with you again.



LEO:  The king of security; creator of SpinRite - the ultimate disk recovery and maintenance utility - and many great free security tools like ShieldsUP!; and of course long-time host of this show, now entering our fourth year of security podcasting, or netcasting.



STEVE:  Yeah.



LEO:  So today is a Q&A.



STEVE:  We have a Q&A.  It's been a very quiet week, thankfully, on the security front.  I have a couple things to talk about that are just little tidbits about security, a very short SpinRite mention, following up on - actually it's sort of related to last week's...



LEO:  That was a wild story.  Man.



STEVE:  That was, yeah.  We heard from some people who were skeptical about its reality.  And, you know, I just read what we received.  And so I leave it up to people to judge for themselves.  But, I don't know, it seemed to have a lot of facts.  Either the guy was a very, very competent creative writer, or it was true.



LEO:  So any big security updates?  Any Windows updates?  Anything going on out there?



STEVE:  The big news of the week, of course, is Google's new browser. 



LEO:  Chrome.



STEVE:  Yeah.



LEO:  I've been using it.  I like it.



STEVE:  Yeah, well, we have - there was a ton of people who wrote in.  They went to GRC.com/feedback.  And I want to continue to encourage people to do so and really to thank everyone who does because I get a lot of great ideas and tips and pointers and a sense for where our listener base is and what they want to hear about.  Everyone wants to know what I think about the security side of Chrome...



LEO:  Of course, yeah.



STEVE:  ...and what Google has done.  So, of course, this is only a couple days ago.  I have had no chance yet to take a good look at it.  In fact, when I got your email, Leo, saying hey, I got back early from the airport, you want to do our recording now, I was just in the process of creating a new VMware box...



LEO:  Oh, you are paranoid.



STEVE:  No, it's not that as much as I don't like to install things that I may regret installing.  Because Windows is way better, XP now is way better than earlier versions of Windows in removing the junk that gets installed.  But it's like, eh, it's just sort of wear and tear on a Windows system.  So for something that I'm not at all sure I won't immediately say, oh, I'm glad I didn't install that on my actual hard drive, I just stick - it's so easy to create a little VMware world and stick it in there and use it there.  And there are places where it turns out you have to.  For example, when I was working on all this cookie stuff that I'll be returning to once I get the DNS stuff put to bed, Firefox 2 and 3 cannot coexist on the same machine.  And interestingly enough, Firefox 2 and IE have cookie interaction.



LEO:  Oh, that's really surprising.



STEVE:  There's some cookie collision.  It was, like, bizarre.  I thought, what...



LEO:  You didn't expect that, yeah.



STEVE:  You know, I thought it was my problem.  But anyway, so I've got little VM worlds for everything because in many instances you need different versions - in fact, I've got IE 5, 6, 7, and 8 also in different VMware because, again, IE can't - different versions of IE won't live in the same machine, either.  So it's very useful.  But anyway, that brings me to a point.  So just to wrap up the issue on Chrome, we absolutely will do an episode.  The early news is there are some problems.  Naturally, unfortunately, Safari remains - Apple Safari remains the only browser to, by default, have third-party cookies disabled.  Google's are enabled.  It does provide you with the option.



However,  the guys in my newsgroups immediately determined that - using my not-yet-public cookie analysis system - that Google is also subject to what's called "cross-context leakage," meaning that it does not block outbound cookies, it blocks them inbound.  Which is really not what you want because it means that if you were to get a cookie in a first-party context, like you went to a site, like for example PayPal redirects you through DoubleClick and then back to PayPal, well, in that redirection hop you have a first-party relationship briefly with DoubleClick, during which time, if you allow first-party cookies as you typically do, you would get one.  Then, unfortunately, both IE and Safari and Chrome, they block incoming third-party cookies, not outgoing third-party cookies.  Which means that then, even though you've said I want third-party cookies blocked, when you are at other sites you're leaking DoubleClick third-party cookies, which...



LEO:  That's not good.



STEVE:  ...is not what you intend.  So, and I also noted - I haven't even gotten it loaded yet.  But I quickly, from the initial comments I saw in the newsgroups, there is no site whitelisting/blacklisting for, like, cookie handling and maybe other provisions.  Again, I haven't looked at it closely, but that...



LEO:  No, and even the setting for third-party cookies is a little odd.  It says...



STEVE:  Yes, it's got some strange wording.



LEO:  It says restrict how third-party cookies can be used.  Not block third-party cookies.  And then it doesn't give you a policy, doesn't say how to edit the policy.  It just says, you know, restrict how they're used.  Well, I don't know what that, you know, what does it - what restrictions am I placing on it?



STEVE:  The most compelling concept is that they are talking about sandboxing.  They're saying that individual tabs are - they essentially create browser instances per tab so that, first of all, if a tab crashes, you don't crash the whole browser.  And that does happen in IE where it's like, oh, now I'm hosed, and I've got to shut down all of IE.  So that's good.  But they are also talking about restricting what the code in this window can do.  I mean, they're using the term "sandboxing."  So the question is, okay, what does that really mean?  The other thing that I liked is, in fact I just read when I was going through the notes for today's Q&A, someone talked about - in fact it was a comment about Chrome, hey, I like how quickly it launches.  He said, I don't ever launch Firefox because it takes so long to start up.



LEO:  Yeah, Chrome just pops up, wow.



STEVE:  And I was thinking, what?  And it turns out, then he confesses, he's got so much add-on gunk...



LEO:  It's the extensions, yeah.



STEVE:  Yeah, he's loaded so many extensions in Firefox that it's slowing it down.  And he says, I don't load Firefox unless I know I'm going to be surfing for at least 15 minutes.  Otherwise, you know, it's not worth waiting for it.



LEO:  Or take out something.  That's not a fair comparison at all since no extensions exist in Chrome at all.



STEVE:  Well, but there will be add-ons and plug-ins.  And they comment that the sandboxing could be defeated by plug-ins and add-ons that would be crossing that boundary.  So that's something to be concerned about.  But also apparently there's some sort of process monitor where you can see how much RAM each of your different pages and/or plug-ins and add-ons are taking up.  So they're enforcing some accountability so you can say, oh, look how fat that page is versus this page.



LEO:  Oh, even more than that.  According to the comic book, anyway, you can say, if a process fails or causes a problem, you can say who did it, which you can't do in Firefox.  And that will really help in eliminating the buggy extensions.



STEVE:  So at this point...



LEO:  And it's multithreaded.  Which you ought to love.  You've got that four-way Xeon that doesn't do anything.



STEVE:  Sitting around, give me something to do.



LEO:  Well, hey, I think a multithreaded processor, I mean, that's where you're seeing a lot of the speed improvement.



STEVE:  Yup, yup.  So we got Chrome, and we'll be doing a comprehensive analysis of it.  I wanted to mention that a number of different news outlets covered the increasingly good news for people, which is increasingly bad news for the likes of NebuAd and Phorm.  NebuAd has lost their CEO.  He wandered off to go somewhere else.  But they've apparently also lost all their customers.



LEO:  Ah-ha.



STEVE:  Like, yay.



LEO:  Couldn't happen to a nicer bunch.



STEVE:  And Phorm's stock has fallen 75 percent since its peak, which was 11 days after their announcement.  Everyone figured out what was going on, and it just collapsed.  So it's like, good.



LEO:  That's encouraging because people who say, oh, get over it, privacy's dead, you're never going to be able to have privacy ever again, there's an example of, if people are aware of it and stand up and say we don't want this, we can actually defeat this stuff.



STEVE:  Yes.  And, I mean, and again, it's a perfect example of, okay, no one would have a problem with this if it was opt-in.  That is, if people voluntarily signed up in return for some benefit to them.  Instead this was all on the benefit of the publisher that was going to be getting higher ad revenue on the promise that the advertising would be more tightly targeted, and therefore they could get a higher dollars, CPM dollars.  So anyway, the good news is these guys are falling on hard times fast because there's enough awareness now and enough concern about privacy and security that they can't, you know, they couldn't sneak around under the cover of darkness and get away with this.



And then lastly, I did want to mention to anyone else who's using VMware, when I fired my VMware workstation up, it said, hey, it's been a while since we checked for updates.  Actually it's been a while since I fired it up, so it hasn't had a chance to check for updates.  When I did, I found there had been a change.  I was using 6.0.4.  We are now at 6.0.5.  And one of the things that they have done, it was a security update largely.  There were three major things.  But one thing they did I really liked.  It wasn't a bug fix.  It was a policy fix.  They are setting - VMware is now setting the so-called "kill bits" on all of their ActiveX controls.  So in VMware they are using ActiveX controls as just part of their object glue for their solution.  But they recognized proactively that, much as is the case for all ActiveX controls, and we've discussed this on a number of instances in the past, IE can be asked to invoke ActiveX controls that exist, even if they were never designed to run in IE, in order to exploit any behaviors, not even necessarily any problems, but behaviors.  And you might imagine that VMware has some powerful ActiveX controls.



And so they said, okay, we're just turning on all the kill bits on all of our controls because none of them were ever meant to be used in Internet Explorer, so we're going to prevent them from being used in Internet Explorer.  Which as a policy is brilliant, and everyone should do it.  I mean, anyone producing an ActiveX control which is not intended to be an add-on or a plug-in to any browser, ought to go to some lengths to make sure theirs can't be exploited.  It just - it makes sense for them.  They'll avoid the bad press of being part of some exploit.  And it certainly makes sense for any end users who would like to be using these controls safely.



LEO:  Yeah.  Yeah, absolutely.  Do you have any - you mentioned at the beginning, and I want - is this a good time to bring up the SpinRite thing?



STEVE:  Sure.



LEO:  Because, you know what, we're subject to this kind of mail all the time, you know.  And you never can really validate that it's true or not.  So as I'm listening to you last week I'm thinking, boy, this is a really amazing story, but who knows if it's true.  Did you have people write in saying, hey, I was a Navy SEAL, this couldn't be true?



STEVE:  No.  I heard both ways.  Some guy who was just Mr. Sour Grapes wrote to the office, and Sue forwarded it to me, saying oh my god, how gullible could you possibly be?  I'm not going to believe anything you ever tell me again.  And it's like, okay, well...



LEO:  There was no evidence either way.



STEVE:  Thank you for your email.  Actually I didn't bother responding to him because, you know, he's made up his mind.  Yeah, I mean, there was no evidence either way.  Our listeners know, based on the testimonials that they have written and that I have read, that it's entirely possible.  I mean, it could have happened.  It's not...



LEO:  Oh, sure.  Yeah, there's no question about that.



STEVE:  I mean, you know, the space station has a copy of SpinRite because they've had problems with their laptops when they're in orbit, and it's a little hard to send the drive to Fry's or to go pick up another one.  So, I mean, it works.  We know it works.  And it would be very cool if this were true.  I hope it was true because I would love the idea that it was helpful in the field.  And I mean "in the field."



LEO:  Yeah, really.



STEVE:  Really in the field.



LEO:  Yeah.  Well...



STEVE:  My email that I got this week, it was written by someone who heard us last week, and the subject was "SpinRite Saves Many Lives."  And this is way toned down.  I don't think anything will be the same as last week's.  But he said, "Hi, Steve.  Yes, SpinRite saves lives.  Or saved lives.  I work for a large medical group, and we have lots of doctors who read X-rays from their homes after hours.  One day last week one of our doctors called me and stated that his computer would not boot up and was stuck in the Windows screen.  He was going to need it the next day to read X-rays from home for a large hospital.  So I started SpinRite on his machine before I left for the day.  Like magic, when I returned it to him the next day, it was up and running perfectly.  You saved me many hours reloading Windows and various programs with tricky configurations.  I called the doctor to let him know how great your program is and how much time you saved me.  Thanks again, Steve."



LEO:  Well, there you go.  See?  It does save lives.



STEVE:  So, well, a little less dramatically this week than last week, but yes.



LEO:  It cures broken bones.



STEVE:  It does.



LEO:  Well, that's great.  And, you know, there's no way of knowing one way or the other whether a story like that is true.  And, you know, we're not gullible, but we don't have any reason not to believe it, either, so...



STEVE:  Well, yeah.  And we could call it well-written fiction.  I don't want anyone else to do that.  Please do not send...



LEO:  Do not make up stories.



STEVE:  Do not make up fantastic-sounding SpinRite stories.  You know, then I'll start being suspicious.  So I'm not soliciting that at all.  I would rather - all I want is real testimonials from real life.  I think next week I'm going to tell how SpinRite saved 200 kittens.  So that's...



LEO:  Is that a true story?



STEVE:  Yeah, yeah, yeah, I have it.



LEO:  Oh, we're getting out of control now, I've got to tell you.



STEVE:  Okay.



LEO:  Speaking of reading, Steve, I'm going to - you have to listen to these as I read them to you.  How about that?  And answer these questions.



STEVE:  You're going to be audible, Leo.



LEO:  You're going to be an auditory listener.



STEVE:  Yeah, you're definitely audible.  I'll be an auditory listener.



LEO:  Auditory listener on this one.  Question numero uno from John Skauge in Bergen, Norway.  He says he's not SATAsfied with SATA.  See, there's a visual pun you might not get if you just listen to it.  Hi, Steve and Leo.  Love your show.  I've been listening to it every day when I ride the bus to work since May of this year.  I've had two new Samsung SpinPoint F1 1TB SATA2 drives.  One of these drives crashed after a week of normal usage.  The other one lasted longer but started to disappear from the system, at random it seems.  I also have two Samsung 250GB drives which work fine, something SpinRite also tells me.  Now one of my 250GB drives has started disappearing from the system as well, but SpinRite reports surface scanning level 4, which I also used on the terabyte drives, to have no faults on either of the 250GB drives.  Currently both drives seem to work after restarting the system a couple of times.



I recently upgraded my machine.  My setup, except for my hard drives, is a Thermaltake Toughpower 850-watt power supply - wow, 850 watts - and an Asus Geforce 9800 GTX with 512MB of VRAM.  Could the new power supply be responsible for the behavior of two new drives, or just bad luck on my part?  My old PSU was a Tagan with 480 watts of power.  Why are my drives disappearing, he asks?



STEVE:  You know, it really does sound like a power supply-related problem.



LEO:  Really.  As opposed to, say, an OS problem?



STEVE:  Yeah, I mean, I'm not sure, when he says his drives are "disappearing," what he means.  I mean, I've had - I mentioned to someone else that I had been unimpressed with the design of SATA connectors.



LEO:  Yeah, they fall out really easily.



STEVE:  And, yes, wouldn't you think in this day and age, Leo, well...



LEO:  A locking connector, please.



STEVE:  Well, now, of course the tradeoff was that the SATA, the connector spec was designed to be hot-swappable.



LEO:  Right, right.



STEVE:  So they're hot-plug connectors, the idea being that you don't need a case or anything else around the drive.  Basically you just - you put the drive on rails or you use a case where the drive just slides in with a little, you know, a minimal enclosure around it.  And so the drive itself plugs into the back plane where you're going to have your RAID or whatever.  So they were, you know, they were trying to come up with a low-cost solution.  But I'm very unimpressed with the SATA connector that was designed just in the last couple years.  It's like, oh, please, guys.  You know, and you're right, why couldn't you do it - when you have a cable connection, why not have some optional latches on the side so that a cable plug to a SATA drive would lock in and hold itself?



LEO:  How hard is that, yeah.



STEVE:  Because I agree, they're just not very stable.  So that was my first thought.  But when he talks about restarting the computer a few times...



LEO:  That shouldn't fix it if it's a connection that's bad.



STEVE:  One of the things that people should be aware of is that, you know, he's got some high-speed, large, 1TB SATA2 drives.  These contemporary drives are using more power than older, slower drives.  And it can be that if power supplies are not beefed up in concert with increasing - for example, this GeForce 9800 GTX, that's probably got a couple hard drive connectors on the back of it, too, because it can't get enough power just from the motherboard.  You know, the higher end of graphics cards, as I'm sure you know, Leo, they have their own hard drive connectors on them.



LEO:  Oh, yeah.  We had to buy a 1,200-watt power supply for UGM.  1,200 watts.  That cost as much as a PC.  It was 600 bucks.



STEVE:  So he's got a really high-end card that's probably got a couple hard drive connectors on it just for the video card.  And it sounds like he's got four drives.  He had a pair of SATAs and a pair of Samsungs.  So it may very well be that his power supply either was or is, you know, not footing the bill.  And these things are all made now in Taiwan or China.  They're certainly checked initially.  But you could also just have a bad, you know, like from the factory, an infant mortality problem with a power supply.  Which is it's got, you know, high hum or bad regulation on the 5-volt or at the 12-volt line.  His motherboard may be pulling a lot of power, too.  So I would, I mean, this seems like something not about the drives but more like, you know, something the drives need.  And what they need is power.



LEO:  That's interesting.  Huh.  I've also seen the operating system lose drives.  We get complaints all the time about Windows losing drives.  So, yeah, who knows, with that one, who knows what it is?  But it doesn't sound like there's anything wrong with the drive itself; right?  I mean, that's the result of that SpinRite test.



STEVE:  Yeah, right, exactly.  And if you power it down and up a few times, and then the drive comes back, it's like, okay, well, now, you're also restarting Windows a few times, so Windows is coming back.  So maybe Windows has forgiven the drive.  It just - it is difficult to know.  But certainly we sort of take power for granted.  And with graphics cards that now need two hard drive connectors of their own, and motherboards that are becoming more and more power hungry, where you've got that extra yellow cable to give it [indiscernible] 12 volts, it's the case that power is becoming really important.  We're just sucking a lot of it.  And heating our rooms, too.



LEO:  Yes.  I've got the AC on high today.  Man, this stuff generates a lot of heat.  A lot of heat.  And now a public service announcement from Spencer B. in Utah, USA:  Hey, Steve and Leo, I've been getting about five emails a day from GreetingCard.org.  The URL in the message links directly to an EXE file called "e-card.exe."  I know this is a huge problem.  I thought it would be a good thing for you guys to know about it.  Love your netcasts, listen to them devoutly.  Keep up the great work.



STEVE:  I wanted, I mean, this is certainly an obvious thing for all of our listeners.  But I thought it was just worth reinforcing, not so much for the people who listen to this netcast/podcast, but for them just to take a moment to make sure everyone they know and care about sort of thinks about this.  I know that greeting cards are - unfortunately, it annoys me because my mom and some less tech-savvy friends of mine...



LEO:  Yes, me, too.



STEVE:  ...are sending me these things all the time.  And what pisses me off, frankly, is they're putting my email address into some third-party site that sends me the card.  They're not sending it to me directly.  They're like, oh, you know, would you like to send a card to Steve?  It's like, yes, I would, here's his email address.  Well, of course now the greeting card website has my email address, which is something that I guard and tend to treat as my private information.  I don't want it spread around because that's of course how spam happens.



But more importantly, some of these cards, they really are nice.  I mean, they're really beautiful Flash animations.  I mean, it's like, okay, I can understand why somebody sent me this.  It's an impressive, nice piece of work.  The problem is this concept of greeting cards is becoming popular.  And so an evil site like this GreetingCard.org, or that may just be a completely made-up site, but someone pretending to send email that is a greeting card sends you this link, and you're had success with it for the last ten times you've opened a greeting card, suddenly you click on this and, bang, you're infected with whatever malware this EXE file is installing on your machine.  So...



LEO:  Do we know it's malware, or just presuming because it's an EXE file that it's malware?



STEVE:  You're right, we don't know it's malware.



LEO:  I mean, it could be a greeting card.



STEVE:  Get out your copy of VMware and fire it up, yeah.



LEO:  Right.  I mean, on general purposes I don't even, when my mom sends me these e-greetings, I don't open them.  I'm sorry.  You know what really bugs me is not merely that she's sending me this link in an email, which as we know is bad, but also that she's given my email address to some other third party without permission.



STEVE:  Yup, yup, yup.



LEO:  I try to educate people on the radio show about this, but I have not high hopes.



STEVE:  It's worth also mentioning that there is a very high level of email now, just spam, which is reputing to be a misdelivery of a package, FedEx in particular, but also DHL and UPS, where the email says we attempted to deliver a package to you.  Please click this link to open the invoice so you can see the details, who it was from and so forth, and we can arrange to reschedule delivery.  And it's catching a lot of people who are like, oh, no, I missed a box of something?  I want it. Again, it uses an emotional hook, something people, like, oh, someone sent me something, I need that, instead of something we don't care about, like...



LEO:  These guys are really good at social engineering, at tricking you into doing something you don't want to do.  It's just really the - it's the sad state of the world.  And you've just got to educate everybody you know.  I just say, you know, don't open attachments, don't click links in email.



STEVE:  Yeah.  And I tell my friends not to send me anything.



LEO:  Yeah, exactly.



STEVE:  Please don't.



LEO:  Exactly.  Lil Banchik, like that Lil Banchik in Long Island, New York, wants to know how long to wait:  Steve, I've heard you say over and over, nothing is secure until people have had time to pound on it, to discover weaknesses.  With Google's new browser, how long - again we're back to Chrome - in your opinion would be long enough, especially since the fine print in the EULA states that Google is allowed to install updates and patches at any time without warning.  How long?  How long, Steve?



STEVE:  Well, part of what Chrome is doing is interesting because Google has said that they will be providing the browser with a continually updated list of bad sites.  So they're going to have a blacklist, essentially, in Chrome.  And Chrome will be pinging Google for continual updates to that.  And of course they're going to be doing security patches and so forth.  So that's good.  You know better than I, Leo.  I mean, I know from our listeners this is immediately on everyone's radar.  So in general is Chrome succeeding?  I mean, has it been...



LEO:  Well, everybody wants to use it.  You know, of course, it just came out yesterday.  We're recording this on Wednesday.  It came out Tuesday.  I downloaded it, everybody downloaded it, there's some really obvious great things in it.  Although I think people are really concerned about the EULA, particularly the part about the EULA which says, even though you retain copyright, we retain the right to do anything we want with content you post using this browser and to distribute it to third parties.  So that would mean, I guess, your email, your blog posts.  That's a little scary.



STEVE:  Content you post with this browser?



LEO:  Yeah.  Isn't that a little creepy?



STEVE:  Wow.



LEO:  You want me to read it to you?  This is very creepy.  Now, of course, I think - and I'm going to give Google the benefit of the doubt.  This is the kind of language they put in EULAs to protect themselves against being sued by somebody who says Google, stop caching my data, because these things happen.  But it says you retain copyright and any other rights you already hold in content which you submit, post, or display on or through the services - in other words, Chrome.  By submitting, posting, or displaying the content you give Google a perpetual, irrevocable, worldwide, royalty-free, and nonexclusive license to reproduce, adapt, modify, translate, publish, publicly perform, publicly display and distribute any content which you submit, post, or display on or through the services.  Furthermore, you agree this license includes the right for Google to make such content available to other companies, organizations, or individuals with whom Google has relationships for the provision of syndicated services and to use content in connection with the provision of those services.



STEVE:  See, now, you're using the term "services," though.  Are we sure that that's not their online web-based things to which people would be posting content?  Because there I could see everything you've said makes sense.  If it's like, you know, Google Calendar or some blog where you're posting content to a Google-hosted web facility, as opposed to through the browser, using the browser as a conduit.



LEO:  You know, I'll have to go back and look at the part of the EULA where they define services.  And it may be that they are - I don't see why that would be in the EULA for Chrome, however.



STEVE:  So explain to me, what do you think the excitement is?  I mean, we have Firefox and huge adoption of Firefox.  And it's popular and been pounded on.  We're at v3, and 3 looks good.  What's the attraction of another browser?



LEO:  By the way, "services" refers to Google's products, software, services, and websites.



STEVE:  Wow.  That's nuts.



LEO:  Everything.  Everything.  The attraction is several fold.  I think, you know, we had this debate yesterday on MacBreak Weekly.  And Merlin Mann was very adamant.  Why do we need another?  But let me tell you why Google's doing, I mean, one credible reason that I think shines some merit on Google is that they want to have a browser that does really, really well on cloud computing.



STEVE:  Yup, on Google sort of stuff.  Because clearly we know that so far basically all of their services have been hosted through other people's browsers, through IE, Firefox, and Opera.



LEO:  Right.  So if you use Google Docs, or you use Gmail, or any, frankly, any JavaScript-based web application, it runs much better in Chrome.  They are using a very, very fast JavaScript engine.  It's the fastest one out there.



STEVE:  Ah, interesting.



LEO:  It also is the only browser I know of that's multithreaded.  So that speed is not phony.  It's real speed.  And it also has built-in Google Gears, which means when you're not online these cloud computing programs like, say, Google Docs, still can be used, still persist.  And of course that's very important.  So all of these things they feel - I think they could credibly say, look, we just don't feel other browsers do a good job of this, and we want Google Docs to succeed, so we're going to make the browser that this stuff needs.



STEVE:  Well, I do know that it looks pretty clean.  I mean, it just has a nice, simple, clean...



LEO:  Beautiful.  It's Google, yeah.



STEVE:  ...interface.  I really like that.



LEO:  But then many others point out, yeah, but what is Google's real business, it's advertising.  Google is essentially creating a giant spy on your system.



STEVE:  That's a concern, too, yes.



LEO:  That's a completely legitimate concern.  So, you know, I'm torn over this.  And I have to say that EULA is just - might be the thing that puts me over the top.  I think they put it in there because they don't want to get sued over caching, which they have been before.



STEVE:  And depending upon where the SSL happens, I mean, if you're using an SSL connection, then even though you're using their browser as the portal, I guess they could scrape it off before their browser encrypted what you posted.  I mean, they certainly could.  But I don't know, I mean, that does seem a little too all-encompassing, too sweeping as it's written right now.



LEO:  Yeah, I see these EULAs all the time, and people are always complaining about them.  It's not at all uncommon to have these kind of blank, you know, the lawyers are going to say, look, we're going to protect you against all exposure, so you'd better put all this wording in there.  But what they don't realize is some people do read the EULAs.  And in this day and age, all it takes is one person with a blog to read the EULA, and everybody knows about it.



STEVE:  Yeah.  Well, all of our listeners do now.



LEO:  They do now.  Ryan Sullivan, attending college in New York, wonders about the campus network security:  Hi, Steve.  I'm a freshman in college - I guess he's just going to school now - an avid listener, so of course I want to make sure I'm secure on my college network.  Yes.  I don't know much about my college network other than it's a Cisco network.  Everyone has to use their college email address and password to log in via VPN over IPSec/UDP to get access to the Internet on campus.  I would assume this is a good way of keeping unwanted people out, even though it's single-factor authentication, especially since my college makes us change our passwords every 60 days.  But what I'm more concerned about is the other students on the network.  I go to a very high-tech college, so most students know their way around computers very well.  I want to know, how can I be safe on my college network?  Is there any way another student already on the network can do anything to me or get any information on me?  Or am I just being paranoid?  Thanks for an amazing show.  Keep up the great work.



STEVE:  I thought this was a great question because it leverages a lot of what we've talked about and learned over the years of the podcast.  First of all, I'm impressed with wherever it is he's going.  He doesn't tell us where he's going in his note.  But essentially this means that every single student must have presumably the Cisco VPN client installed on their, you know, the computer in the dorm room or on their laptop, and that literally all the traffic, all the student traffic, at least, crossing the Internet on the campus network is encrypted.  So Cisco's got good, state-of-the-art VPN technology.  It means that in order to get on the campus network at all, you need to log onto their VPN client that establishes an encrypted connection to a back-end VPN server which is the way you're able to get out then onto the Internet or onto the campus's own Intranet.



So the only vulnerability is, because all the traffic is encrypted completely on the 'Net, the only vulnerability is, as he says, as Ryan mentions, the single-factor authentication which is occurring at his laptop.  So it's his laptop that he wants to protect.  I would say use, for example, a power-on BIOS password.  It's somewhat annoying, but it is stronger than using a Windows password.  And you probably want to use a Windows password also because it is the laptop which could get, for example, a fellow student could install a keystroke logger in order to capture Ryan's authentication as he's typing in his username and password.  And that would allow somebody else to pretend to be him.  And it very well may be that the campus is logging the network activity per student based on their log-in credentials.  So you want to probably prevent someone from being able to impersonate you to the rest of the people on the campus.  But the only real point of vulnerability that I can see is at his laptop and his own log-in credentials.  It's, again, it demonstrates strong security policy that the campus is also enforcing a 60-day password change.  I mean, that's...



LEO:  Yeah, that's amazing, yeah.



STEVE:  I mean, it's teaching all of the students good security practices, which is good to see.  You can imagine when they eventually wander off into the corporate world, if someone says, oh, yeah, we never bother changing our passwords, it's like, what?  You don't change them every 60 days?  We did that when I was a freshman.



LEO:  Yeah, even in college.  I think what he's saying, though, is it's that age-old issue of when you're on a network, if other people can get into your system.  In other words, because you're on a shared network, don't they have unusual access to your hardware?  Or does a VPN prevent that?  So when I go to a hotel - we talked about this the other day.  And I used the hotel's network.  Everybody else in the hotel, unless they've done something special to segment it, can see that I'm there.  And anything I'm sharing is visible to them.  They're on my Intranet.  



STEVE:  Yes, if you don't have encryption.  But the VPN...



LEO:  Because we're using VPN it's safe.



STEVE:  Exactly.  You have encryption from you to the VPN server.  Now it's not clear at that point, once it becomes decrypted, then is there visibility to other laptops or other machines on the network?  It might well be, for example, that you could still scan the network.  Your scan would go through the VPN tunnel, come out the other end of the VPN tunnel, and then start sniffing around for IPs.  I mean, it's a function of, like, where have they installed NAT?  Is there NAT also going on so that everybody is also behind a implicit NAT router?  So again, you're able to get out into the public segment, but then not back into individual private connections.  So there's more that we don't know about how this is set up.  But at least the traffic, no raw packet sniffing would function on the segment of the network that the students and faculty have access to because all of that, by virtue of policy, is going to be encrypted.  And that's really great.



LEO:  Makes sense.  Martin Nothnagel in Berlin, Germany mentions that Microsoft is determined:  Hi, Steve.  I'm a longtime listener.  I just want to drop you a short comment.  In the last episode you and Leo talked about DEP, and that after Microsoft providing the base for secure software it is now the responsibility of the ISVs - the Independent Software Vendors - to develop DEP-compatible software.  I just want to bring to your attention that Microsoft has some ways to force these vendors to use DEP.



For instance, the Windows Logo Program Requirements and Policies state - this is that thing, if you want to sell software that says, you know, "Certified for Windows."  In the category of image printer drivers, the requirement is printer driver components run with Data Execution Protection enabled and with UAC, User Account Control, enabled as a non-administrative user.  So in this example, to get that Windows Logo Certification, printer drivers shipping in 2009 or later must be able to run with DEP enabled to become a driver signed and certified by Microsoft.  It is a long-term process, but Microsoft is slowly tightening the thumbscrews.



STEVE:  Yeah, I liked this.  And I had forgotten to mention that, that Microsoft is, for example, that policy you just read is effective June 1, 2009.  So everyone has plenty of time.  That's a year from now.  But Microsoft has made it very clear that, you know, everybody get your act together.  If you want us to sign and certify your drivers - and as the OS tightens up, of course, signed drivers is going to become a requirement also.



LEO:  Yeah, it already is in Vista 64-bit, yeah.



STEVE:  Exactly.  So, I mean, this is a good move.  And I was wondering if, you know, didn't this mean, or does it mean that, long-term, Windows will end up being more secure than the open source platforms?  And because the open source platforms by definition don't have these kinds of enforced requirements.  And I think that, while that may happen, in general Microsoft is just educating the world.  They're raising the bar, and if nothing else they're finally setting an example for some things that can be done right by policy.  It's always necessary to excuse them for making mistakes.  Anyone can make mistakes.  Microsoft has made plenty of them.  But still, they're saying, look, this is the way things need to be done.  And so you can imagine that the non-Microsoft OSes are incented then to say, oh, we have that, too; we're doing that, too.  We're working on enforcing these policies and technologies which are clearly beneficial to security.  Because it would be bizarre, frankly, if Windows became the most secure operating system in the world.



LEO:  But not a bad thing.  I'm all for it.



STEVE:  Not a bad thing.



LEO:  I'd vote for it.  It's only right, if it's the most used operating system in the world, that it become the most secure operating system in the world.



STEVE:  That would be nice.



LEO:  Don't think I'm rooting against that by any means.  Kashyap in Hyderabad, India - wow, I love it that we have such an international audience - had a request for Security Now!.  He says:  Hi, Steve.  I'm a security professional working in India.  We would be extremely grateful if you could enlighten us in depth on the less known but very effective cross-site request forgery.



STEVE:  Well.



LEO:  Well.



STEVE:  This question, as I was reading the mail, I thought, wait a minute, you know, we did a whole episode on that.



LEO:  We did?



STEVE:  Well, on cross-site scripting, which was the same sort of thing.



LEO:  Oh, it is.



STEVE:  Yeah.  And so I want to take this opportunity to let this listener and all of our listeners, to remind them that GRC now has a site-wide search and a Security Now! search, that is, that you're able to restrict.  And for curiosity, I put GRC.com in.  Right there on the page in the upper right-hand corner was a search box.  I put in "cross-site scripting," hit the Search button, and there was, like, PDFs and text pages and references to our podcasts.  I mean, so I just sort of wanted to give people a heads up, not about this topic, but about anything that they're curious about.  You and I now, Leo, have been doing this for 160 weeks.  We've covered a huge range of topics.  Elaine has transcribed them all.  Google has found them all and searched and indexed them all.  And so if you just go, if you're wondering about some topic in security, GRC.com, and just put your question into our search box.  And it will instantly find for you our presentation on those topics, both in audio format and in text format.



LEO:  It's a great resource now.  I mean, with that many shows there's just no end of stuff.  So cross-site request forgery is basically the same as cross-site scripting.



STEVE:  Yeah, it's just a different term for the same concept.



LEO:  Okay, got it.



STEVE:  And we did a beautiful podcast.



LEO:  I remember, yeah.  I remember, yeah.  Terry Voth in Toronto, Ontario would rather WPA than WEP.  Well, who wouldn't these days?  He says:  My son got a Nintendo DS - oh, I see the problem already - probably the biggest driving force in North America to run WEP, since it won't run under any other wireless security mode.  Fortunately the podcasts had me trained well enough to flinch when my - I can just see it - when my son asked me to switch things to WEP.  Maybe if a Pavlovian response describes an involuntary response to a potential reward, we should call a Gibsonian response an involuntary response to a potential security threat.  I like it.  I had a Gibsonian response.



I recalled the Y configuration that Steve suggested - that was with three routers - looked at the two working wireless routers I had, and started scheming on a way that I could get WEP up and running without buying a new router.  And maybe I have it.  All right, so let's visualize this now.  This is let's see how good an auditory learner you are.  All routers I've bought recently, all Linksys, have had DMZs, or demilitarized zones.  That's where you take a part of the network and say, hey, you're just outside the bounds of the router.  Any traffic can come and go.  What if I hooked up my secondary/WEP router to the DMZ port of the primary/WPA router?  If I understand it correctly, nothing from the DMZ WEP will have access to the rest of the network.  We can still use the secondary router's firewall, protecting from the WEP network from the Internet.  The only risk I can see is the neighbor hacking in, using my bandwidth, stealing my son's Pokemon.  Tragic, I'm sure.  But considering my financial and identity information are safe, I think I could live with it.  Any holes I've missed?  So he's saying you don't need to use three routers in a Y configuration.  You could do two.  Is he right?



STEVE:  No.



LEO:  Yeah, that's what I thought.



STEVE:  No.  Unfortunately, first of all, the DMZ port is sort of a - is a new extra feature that some routers have, which is like a lower configuration responsibility for the traditional DMZ configuration.  Now, a real - and all of these are sort of poor man DMZs.  As you stated it, Leo, a real DMZ, short for demilitarized zone, a real DMZ on an industrial strength real firewall is its own interface, essentially on its own network, which is outside of the network that you're wanting to protect.  And there's inherently no traffic flow from the DMZ back into the other interface of the firewall, and those are policies enforced by the firewall.



Unfortunately, these consumer routers have a - they're really misusing the term "DMZ."  All it really means is that unsolicited traffic goes to that port, or to that IP address.  Traditional DMZs have been software-configured in the router interface, the idea being that you may have wanted, for example, to run a web server or an FTP server or some kind of traditional Internet service that you wanted to make available to the outside world.  Well, that inherently means that your router, which would normally block unsolicited incoming traffic - remember that, as we've described NAT routers many times here, the way a NAT router works is that only by traffic egressing from the internal network to the outside is a path created, a little bit of memory in the router that allows traffic returning from the exact same destination to be routed back to the same computer in the private network which originated it.



So the idea is that unexpected traffic, unsolicited traffic, hits the router.  The router inherently has no expectation of receiving it.  That traffic, because it's unsolicited, wasn't the result of initial outgoing traffic that created a return path.  So what - inherently a service, any kind of a service on the Internet is by definition a recipient of unsolicited traffic.  Google doesn't know I'm going to be sending them traffic.  I just do.  And because they're a service, they accept that unsolicited traffic and respond to it.  So the idea was that this so-called "DMZ" was initially set up in routers where you could configure, manually configure one of your machines' IP addresses to receive that DMZ traffic.



Now, it gets a little tricky, though, because you are normally configuring a certain IP to receive unsolicited traffic, saying this computer runs this service.   I want it to receive unsolicited traffic.  The problem is, routers assign IP addresses based on pretty much the order in which machines appear as they're powered up after the router is on.  It uses DHCP to assign them.  So the problem is that, if you configure an IP to receive traffic, you need to make sure that that computer is always at that same IP.  There are ways to do that.  You're able to assign IPs to MAC addresses, the MAC address being the hardware address of the computer's Network Interface Card.  So you bind an IP to the MAC address, and then you bind this DMZ routing to the IP.



Anyway, you can see how complex that is.  Imagine if you simply had a hole on the back of the router that said "DMZ Here."  Well, in that case, all those problems are solved.  You can simply plug the computer into that hole which is the DMZ port, and by virtue of the preconfiguration of the router, it will receive unsolicited traffic.  So you could see that this has become a popular feature on some consumer routers.



LEO:  Oh, so when he says "DMZ port," there really is a DMZ port.



STEVE:  Yeah, exactly.  It's a DMZ port.



LEO:  Oh, because I'm used to doing it, kind of assigning it to the - by IP address.



STEVE:  Exactly.  And so this is a feature that he's talking about.  The problem is, it's not on its own net.  It's not on a separate network.  So you've still got the problems that allow this to be exploitable.  I'll remind people that WEP, the security - the so-called "wireless security" that made Terry flinch when his son said, "Hey, Dad, can we change our home network to WEP because I want to put my Nintendo DS on the network..."



LEO:  His Gibsonian response.



STEVE:  Yeah, his Gibsonian response was, "Uh, I'd rather not, son."



LEO:  No, no, sorry, no, no.



STEVE:  Anyway, so the problem is that WEP is really badly broken.  In fact, that was the last topic, the last show we did on that was really "[Even More] Badly Broken WEP" because now it takes less than a minute to crack the key using freely available software that's available on the Internet.  So anyway, the problem is it's only by performing true subnet separations, where the nonsecure network is on its own subnet, and those two subnets, the secured and the unsecured, are joined by a third, that's the only way to prevent cross-network leakage because there are, again, freely available tools that will allow you to do ARP spoofing, Address Resolution Protocol spoofing, which essentially allows somebody across the street to pretend to be the gateway for your network and receive all the traffic coming to and from your entire household.



So it's really something you want to avoid.  And I don't know of any way to do that securely, and I've spent a lot of time thinking about it, except to have three routers - one that does the Y'ing function, and the other two to just do NAT'ing function - to essentially create one-way valves. And because ARP traffic is always constrained within the local network, ARP traffic never crosses a router boundary unless it's specifically set up to do bridging, which is not something that any consumer routers are able to do.



LEO:  Okay.  The Y solution would solve it, right, the three-router solution?



STEVE:  The three-router Y configuration would.  And I will mention that routers are now so cheap, you know, I mean...



LEO:  40 bucks, another 40 bucks, dude.



STEVE:  Exactly.



LEO:  And there is, and I think this would work, too, Nintendo sells - no, maybe it wouldn't work.  Yeah, maybe it would.  They sell a little USB WiFi key for use with the DS.  And the idea is you plug it into a computer's USB port, and it shares the computer's Internet access with the DS.  So, but I think that wouldn't solve the problem because - no, it wouldn't.



STEVE:  Well, because what you've done is...



LEO:  Connected to the computer.



STEVE:  Well, yeah, you have just created a probably very insecure hotspot wired into that machine.



LEO:  Right into your computer, yeah.  So don't use that, either.  And I presume that any newer hardware that has WiFi is going to support WPA.  The DSes have been out for a while, and that's why it doesn't, I'm sure.



STEVE:  Well, and...



LEO:  Is it cheaper?  Is it cheaper to implement WEP than WPA?



STEVE:  No.  It's just history, really.  Because remember that WPA also uses RC4, which is a very lightweight, I mean, RC4 is a fantastic crypto.  There's nothing wrong with it except that it was done wrong, it was implemented wrong in WEP.  So that, for example, if you just throw away the first 256 bytes of pseudorandom data that RC4 generates, RC4 is a pseudorandom stream generator.  But because it uses mixing within a small pool, that pool doesn't randomize itself initially.  And that allows for bad keys to be created, which are, like, extra nonrandom.  And because we know the beginning of the packet contents, by taking all that together, both the white hat and the black hat security guys have figured out how to just crack it.  But all WPA does is fix those implementation mistakes, so it is not more computationally difficult to implement WPA.  I think that it just wasn't a big enough issue.  And I'm glad that we're making it a bigger issue because, boy, toys like the Nintendo DS need to be able to support the same security that the rest of a security-aware household is running.



LEO:  Edward Hanson in Rexton, New Brunswick, Canada switched to OpenDNS.  We were talking about that the other day because of the DNS vulnerability.  He says:  Hi, Steve and Leo.  Several years ago, as soon as it was available in my area, I upgraded from dialup to DSL for my Internet connection.  I then added a D-Link DI-604 router to the mix after hearing you tout the benefits of routers on Security Now!.  Up till a few weeks ago when I heard your discussions about DNS, my router had been configured to use my ISP's DNS settings.  Since then I've reconfigured it to use OpenDNS.  That's where my question comes in.  For some reason, maybe because it's an old router, the only way I could manually enter the server addresses for OpenDNS was to toggle from Dynamic PPPoE to Static PPPoE.  Does this make my system any less secure?  He also has a question about ShieldsUP!:  Every time I run a test, the site reports "full stealth."  Does that mean I'm completely invisible to and safe from Internet miscreants?



STEVE:  Okay.  First part, dynamic versus static PPPoE.  PPPoE stands for Point to Point Protocol over Ethernet, which is the protocol that DSL often uses.  The very, very first DSL just used static IP address assignment.  I've got a friend who still has five static IPs, and he loves them.  He's never letting them go, he hopes.  And if he were to change anything they would take that away because they're not liking having him tying up five IP addresses when IPs have become increasingly difficult to obtain.  So PPPoE is like - Point to Point Protocol, which is the original PPP protocol, was what dialup used, where you would inherently establish a modem connection and then, over that dialup link, the Point to Point Protocol was defined to assign your machine its IP address and DNS and other services.  So a variation of that is PPPoE, which, rather than using a dialup, it uses an Ethernet connection, thus DSL, but a similar protocol.  So to answer his question, it does not make his system any less secure.  It might make it a little more brittle in terms of the ISP doing something, assuming that it's set to dynamic, and then he's got it set for static.



LEO:  Yeah, that's what I was wondering.  Because if he's using static, he's going to have to put a static IP address in.  It may stop working at some point.



STEVE:  Precisely.  So it's not less secure.  But if it stops working, then he'll have to switch it back to dynamic, get the IP address that is now being assigned, and then switch it back to static, and then put those same values in.  That's what I meant when I said it might be a little more brittle because he could lose his connectivity.  But while his ISP does not have strong DNS servers, I would say it's worth using strong DNS servers until his ISP gets their act together.



LEO:  Yeah.  So it's because it's using Dynamic PPPoE, one of the things it wants to do is not only dynamically set the IP address, but dynamically set the DNS servers.



STEVE:  Precisely.  Essentially, you know, we're going to do a show here on DHCP shortly because we've talked about it several times.  I want to talk about how very comprehensive the DHCP service is.  It does much more, can do much more than just give an IP and DNS stuff.  But..



LEO:  A lot of times, though, you'll have a setting, you know, you can set DHCP.  But then you'll say, I don't know if it's an override, but you can still set the DNS settings.  Who wins in a case like that?  The DHCP server or the manual settings I've put in there?



STEVE:  Oh, your local settings always win.



LEO:  So if you're allowed to put those in, then you don't have to worry.



STEVE:  Yes.  And in fact, for example, many people who've configured Windows systems will be familiar with that dialogue in Windows where you have two separate sections of "obtain my IP address separately" or "allow me to specify it," and then separately you're able to say, no, I'm going to provide my own DHCP servers.  So, for example, other people with different setups are, well, in fact, even Edward, come to think of it, if he's - we don't know that he's a Windows user.  And I don't know whether the Mac...



LEO:  Oh, he could do it in Windows.  He just wants to do it in the router so it applies to all the systems.



STEVE:  Right, right, right, right.  But just so we finish that thought, because you and I just jumped ahead here, even though his router is offering to specify his DNS servers, he can certainly use the Windows dialogue to configure whatever DNS he wants to.  And it will then ignore what his PPPoE connection is providing, and he'll be able to override those settings.



LEO:  Yeah.  Okay.



STEVE:  And the second part of his question was...



LEO:  Oh, yeah, ShieldsUP!.



STEVE:  He's using ShieldsUP!, and it says "full stealth."  He asks, "Does that mean I'm completely invisible to and safe from Internet miscreants?"  Well, let me tell you exactly what it means, and then you can decide about the miscreants.  What "full stealth" means is that, no matter what ShieldsUP! sent to you - I send out a broad spectrum of probes, ICMP, funky packets on illegal ports like port 0 that doesn't really exist.  And some things respond to it.  Some routers will send back a ping to ICMP, even though they are otherwise told to be full stealth.  What I did in the second-generation ShieldsUP! technology was I created a completely wide-open scoop.  And when I'm probing a remote IP, I'm looking for any traffic of any sort coming back from that IP.  And so I'm casting a wide net.  And so the only way you can get full stealth is if, in response to everything that GRC spews at your machine, nothing, not a single packet of any kind or description emerges from your network back to us.  So, I mean...



LEO:  Now, he says am I completely safe from miscreants.  No.



STEVE:  And that's my point, exactly, is that if you're out on the 'Net messing around...



LEO:  You can still mess up, yeah, yeah.



STEVE:  ...somebody can get your IP and, for example, blast your IP with a denial of service attack.  Now, they won't know that you're still there because you are completely stealth.  That is, nothing they do to try to evoke a response from you will function unless you are exposing something, like deliberately.  But even through NAT, any traffic would have to be coming back from the same remote source, so the NAT router would route it back to your system.  So "full stealth" means that for unsolicited traffic you are absolutely invisible.  But again, if you expose yourself and your IP, someone could still blindly flood that IP and hold you off the 'Net.



LEO:  Yeah.



STEVE:  And of course we've got spam, and we've got...



LEO:  Yeah, there's plenty of other ways you can invite people in.



STEVE:  ...all kinds of other bad things that can happen, right.



LEO:  In fact, I would say it's not a particularly common attack that somebody sniffs around and finds a vulnerability on your system and then gets in.  Nowadays, you know, if you open an attachment, you're making the connection.  If you click a link in an email, you may go to a website that now says, oh, good, we've got a port 80 connection going, and by the way, take this, and sends you an exploit.  So there's all sorts of ways you can invite these guys in that this isn't going to prevent.



STEVE:  Yeah.  And in fact I would go a little further and to say mostly what ShieldsUP! nowadays is intended to do, and what full stealth is to do, is to provide you with information.  You know, people may not care about their router responding to a ping or not.  This just tells them whether it does.  And so it's not saying "full stealth protects you," it's just saying "full stealth," that means you're full stealth.  You know, if that matters to you, then we're happy to confirm it.



LEO:  Yeah, it's a part of your overall security strategy.



STEVE:  Profile.



LEO:  But it's not in and of itself sufficient.  You need to do other things, too.



STEVE:  Right.



LEO:  But it's a great start, and it's why we use routers.  Mike Graham in Hopatcong, New Jersey rolls his own DNS with something called TreeWalk.  He says:  Hi, Steve and Leo.  What are you laughing at?



STEVE:  Your stoned voice.



LEO:  Ah.  Should I do that?



STEVE:  Rolls his own DNS.



LEO:  Rolls his own, man.  Hello, Steve and Leo.  I once used a free utility called TreeWalk DNS - I won't keep it up - and installed a local DNS service right on the local machine.  At the time I used it to replace my ISP's crappy service, but discontinued using it when I changed ISPs.  Maybe now is the time to reconsider this and return to using it.  Have you had any experience with TreeWalk?  Would using it help with the DNS security problems that are around?  Also in their forums they said it is not vulnerable to DNS spoofing attacks because only the local machine can access it, so intruders are out in the cold.  It makes sense to me.  See it at ntcanuck.com.  Are you familiar with this program, Steve?



STEVE:  Intimately, because it was developed on our forums.



LEO:  Oh, you're kidding.



STEVE:  It's developed by a couple guys, and it is widely used among the security-conscious folk who hang out in the newsgroups at GRC.



LEO:  Well, I'll be diggety-danged.



STEVE:  So, and just for the sake of any listeners who don't know about, like, real, old, traditional, non-web-based but Usenet NNTP-style forums, we run - GRC runs, I run - a bunch of really worthwhile security groups.  I think the fact that they're not web browser-based tends to keep them more high end and sober, you know, we don't have flame wars and script kiddies and all that.  Anyone with Outlook or any third-party news reader can just - it's news.grc.com is the name of the news server.  I run it on a FreeBSD UNIX server.  It's real INN news, just like the Internet used to use, I guess it still does somewhere.  But anyway, yes, many of the people who hang out there are using TreeWalk.  And they're all - actually they've been doing a lot of beta testing of my forthcoming DNS profiling facility, which will be added to GRC shortly.  And they'll, like, manually configure their TreeWalk DNS, which is just BIND.  It's a nicely packaged version of BIND 9, all fully patched, so it's got port randomization.  But they'll, for example, configure theirs to use a single port and verify that GRC sees queries coming from a single port, meaning that it's not safe, and then they'll switch it back to using random source ports and verify that it's working right.  So by all means, TreeWalk DNS is a very nice way of running BIND.  I would say it's not for the faint of heart.  I mean, BIND is a sophisticated...



LEO:  Oh, yeah, no kidding.



STEVE:  ...sophisticated DNS server.



LEO:  Didn't BIND have this problem, this DNS poisoning problem?  I thought it did.



STEVE:  Well, yes.  But, I mean, BIND are the servers that did get patched just recently.  So it needs - you need to be using the latest version of BIND.  Because in fact remember Yahoo! was way back on BIND 8.  And they said, eh, there's nothing wrong with BIND 8, we're staying with it.  Until Kaminsky came out with his news, and it's like, okay, we're abandoning all of our BIND 8.  We're going to BIND 9.



LEO:  Okay.  So this would - would you have to download BIND to make this work, or...



STEVE:  Well, yes...



LEO:  Because I see the latest version is from 2005, I'm seeing, of TreeWalk.



STEVE:  Then you got me.  I didn't do any homework, just because I know that these guys are on top of this.  So...



LEO:  I wonder if it's just a front-end to BIND, and you still need to download the latest BIND.



STEVE:  That may very well be.



LEO:  That would solve the problem if they did that.



STEVE:  Yeah, I'm running BIND 9 myself in my own little local FreeBSD machine, so I just - I've never messed with TreeWalk myself.  But I know that a lot of people run it on Windows.



LEO:  Well, it's a pain to install BIND.  So if this makes it any easier, that would be certainly appreciated.  Danny Howerton in Ogden, Utah brings us even more bad news about Wells Fargo passwords.  You remember last time when we talked about what a lousy job Wells Fargo was doing.



STEVE:  Wait, it gets worse, Leo.



LEO:  So I think what - the last time it was truncating them?  It would only allow you to use a certain length?  Anyway:  Hey, Steve.  After hearing about the poor password practices of Wells Fargo the other week, I was tempted to do some further testing with the way it works, since that's my primary bank.  I found out the passwords are also not case sensitive.  What?  What?  I called up Wells Fargo, got transferred to their technical department, where the guy confirmed that in fact they're case-insensitive passwords.  He said he would submit a ticket to their security team...



STEVE:  That'll work.



LEO:  What kind of security team do you have to submit a ticket to get them to do case-sensitive passwords?  He said he would submit a ticket but doubted it would get changed unless a lot of people request it.  This is where you come in.  If we could spread the word and get enough feedback to  Wells, we could possibly change this.



STEVE:  Okay, so this is a classic example.  This has got to be - now, you've seen the warnings on secure log-in sites that say, "Warning:  Passwords are case-sensitive."



LEO:  Yes, as they ought to be.



STEVE:  As they should be because, for example, using random case or case that, like, first, third, fifth, or first, fourth, sixth, you know, whatever, you could easily use case-sensitivity to take a short phrase and give it much more robust security.



LEO:  What was it you said last time, it's like another eight bits of encryption or something like that?



STEVE:  Well, it depends upon, yes, essentially, every character whose case you change doubles the strength of the password because it adds a bit, an effective bit of complexity, meaning that you have to try the password with that character low case, then try with it uppercase.  And so if it's case-sensitive, and you've got a nicely long password, but then you also play some game with the case, maybe you uppercase the vowels and lowercase the consonants, you know, you make up your own rule.  I mean, it's a nice way of strengthening a password.  Well, clearly some people were having problems logging into Wells Fargo.  So what did they do?  Oh, we'll make it easier for them.  And in the process they make it easier for the bad guys.  Now you don't have, I mean, non-case-sensitive passwords are just similarly weakening the log-in.  And remember what we heard before was that they don't even care if there's extra stuff added to the end.  And the question was, how many characters do they consider significant?  How many are they saving?  So just, you know...



LEO:  It's like an eight-character, all uppercase password.  That's ridiculous.



STEVE:  Yeah.



LEO:  That's just ridiculous.  There's no reason for that.



STEVE:  And again, it is them buckling to the common consumer who is unable to log in.  But you ask yourself, how upset will the common consumer be when their password is stolen and their bank account emptied because Wells Fargo's password policy is so poor.  All you have to do, I mean, it's time to start training people about case sensitivity in passwords.



LEO:  Unbelievable.



STEVE:  The real benefit.



LEO:  Steverino, are you ready?  The Savvy Observation of the Week.  [Tim] Knittel of Lexington, Kentucky says:  Hi, Steve.  In Episode 156 a listener asked if he could bypass DNS by directly entering the IP address of the websites he wants to visit.  This approach won't protect him from the DNS spoofing vulnerability, however, for a number of reasons.  Really.  Well, that's interesting.  First, not all websites use relative links to navigate among the pages.  So you could enter in 192.168.1.1, but when you click the link it's going to come back to you as example.com/mylink, not 192.168.1.1/mylink.  A good point.  In fact, my site does that.  You could come in via an IP address, but we're going to rewrite the address for subsequent pages to be TWiT.tv.  Second, all external links on the page will not be IP based.  That includes subdomain links.  So continuing the example above, a link might be coolstuff.example.com, even if you enter an IP address.  You click that link, bye bye.  Third, only the web pages that his browser loads are user-controllable in this fashion.  All his other applications will use domain names - email, newsgroups, RSS readers, podcast catchers, Windows Update, et cetera, et cetera, et cetera.  Nothing you can do to stop those programs from using DNS lookup because they do it automatically, transparently, without your knowledge or intent.  In fact, this includes the browser itself if the browser is configured to automatically check for updates.  Oh, of course, didn't even think of that.  His point is DNS is just too integral a part of computing now to be successfully on the 'Net without it.  So you're not doing yourself any good by entering in IP addresses.  We should have mentioned that, actually.



STEVE:  Yep, that's why I thought it was a really good point, is that technically I got hooked, I got...



LEO:  You answered his question.



STEVE:  Exactly.  I got excited by the idea that you could use the IP address itself.  And yes, you can get to the website.  And frankly, then that first page that you bring up would work.  But if the web, even if that original, if that real website redirected you to a URL, your browser would then ask for that website's domain name, get spoofed, and go to the wrong place.



LEO:  Right.



STEVE:  So you're only safe if you go by IP and you notice that it stayed by IP when you're viewing that page.  Otherwise, as Tim notes, you're back in using DNS.  And I liked his point, though, where he says, remember, everything else uses it, too.  DNS is just too integral a part of computing to be able to use the Internet without it.



LEO:  Yeah.  Good point, [Tim].  We should have said that.  Marc Argent - or perhaps it's Marc Argent - makes the Very Good Point of the Week:  Dear Steve, is there a way of checking a DEP alert triggered by, for instance, Flash, is an attempted exploit or just poor programming by Adobe?  It seems to me that blindly disabling DEP could be a potentially dangerous thing to do.  And I do want to point out, we did some research on Silverlight, and you can turn on DEP and still use Silverlight.



STEVE:  Oh, good.



LEO:  Yeah.  So if I'm using Flash, I've got DEP turned on, and I get a DEP alert, does that always mean somebody's trying to attack me?



STEVE:  Well, this is what I loved about his point was that I too glibly said, oh, turn DEP on, and then start turning it off when you have problems.  And he says, well, okay, wait a minute.   What if that problem is because of an exploit?



LEO:  Because of an attack, yeah.



STEVE:  It's like, oh, yeah, that's a very good point, yeah.  So anyway, I loved the point that he made.  And he asks, is there a way for us to know?  And it would - only by being careful about your observation.  I mean, for example, did you get that when you launched some Flash on a website, in which case I would definitely be suspicious of the Flash that I got from the website might be exploiting a flaw in Flash.  And then I would be inclined not to disable DEP.  I guess for me, and this is why I didn't communicate this well at all, is when I'm using a machine that has DEP on, it's normally not 'Net-based things.  It's just, you know, I'm dragging something around to a tray or firing up an app that's not 'Net based, and it says bang and blows up.  It's like, okay, fine, this thing is not compatible.  But certainly when you're doing anything with the Internet and/or email or running something you got from somewhere else, and that action causes the problem, then you absolutely need to think, wait a minute, maybe this is the whole point.  It's protecting me from what would have just happened otherwise, which is what you want.  You don't want to say, oh, look, here's another incompatibility with DEP and then disable it for that product from ever on.  So I thought Marc raised a very good point that I wanted to make very clear to our listeners.



LEO:  Good.  Thank you, Marc.  And that brings us to the conclusion of our 12 fantastic questions.  We'll do this every other episode.  So if you have a question for Steve, you go to GRC.com/feedback.



STEVE:  And please do.  I really, really appreciate getting the mail.  I will apologize again, as I do every time I talk about this, that I am unable to respond to, or frankly even to read, all the mail that I get.  I checked it this morning to prepare these questions, and there was 450-some submissions from last time I checked it, because I empty it every time.  So, again, I really appreciate it.  I love reading them.  I do read all that I can.  And I find time in spare moments to read more of them.  So please keep them coming.



LEO:  And we should mention that often the question that we read on the air, even though we use somebody's name, is representative of a number of similar questions from a number of different people.



STEVE:  Very good point.  Like, for example, many people wrote about Chrome.  And so we will be talking about Chrome in sufficient, I mean, in all the depth we typically do about anything, as soon as I'm up to speed.



LEO:  Good.  Steve Gibson is at GRC.com.  That's where you'll find the show notes, transcripts of the show so you could read along if you're a - what do you call that, if you learn by reading?  A visual learner?  I guess.  You can also listen to the 16KB versions, which are very small files, good for downloading on dialup.  It's all at GRC.com, as are all of Steve's great free programs like ShieldsUP!, and the one-and-only SpinRite, the ultimate hard drive recovery and maintenance utility.



STEVE:  Yay.



LEO:  If you've got more than one hard drive, you need SpinRite.  It is absolutely true.  Steve, I thank you very much.  A great show.



STEVE:  Always a pleasure.



LEO:  Do you know what we're talking about next week, or is it going to be a surprise?



STEVE:  I've got a list of things.  So I have to choose one from the list.



LEO:  Pick one.



STEVE:  It'll be a grab bag.



LEO:  Great.  Hey, thank you, Steve.



STEVE:  Talk to you then, Leo.



LEO:  Talk to you next time on Security Now!.  Bye bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#161

DATE:		September 11, 2008

TITLE:		Google's Chrome

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-161.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo examine Google's new "Chrome" web browser.  Leo likes Chrome and attempts to defend it as being just a beta release; but, while Steve is impressed by the possibilities created by Chrome's underlying architecture, he is extremely unimpressed by its total lack of critically important security and privacy features.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 161 for September 11, 2008:  Chrome.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that answers your question, the vital question, "Help!"



STEVE GIBSON:  Or the exclamation, I suppose.



LEO:  Yeah, it's not a question, "Help!"



STEVE:  What to do with your Gibsonian reflex response.



LEO:  That's, yes, the Gibsonian response, which we encourage you to have.  That is something one of our viewers coined because anytime he sees something a little scary happen on his browser, he says, "I had a Gibsonian response."  Little red lights flashed, sirens.  Steve Gibson's here from GRC.com, the security guru.  Hi, Steve.



STEVE:  Hello, Leo, great to be with you.  We are airing this on the seventh anniversary of 9/11.



LEO:  Oh, yeah.



STEVE:  September 11, so...



LEO:  A very grave, serious anniversary, you're right.



STEVE:  Seven years, though, have already gone - we're getting old.



LEO:  You know, 9/11 is one of those things, though, like the Kennedy assassination, and we're old enough to remember that, where you will always know where you were when you heard it.



STEVE:  Yup.  In fact, I got a call from the FBI that morning and was asked to help out with some things they needed.



LEO:  Oh, really.  Oh, how interesting.



STEVE:  And the guy, my FBI guy called me and said, "You know what happened," I said, "Oh, yeah."  You know, I had the TV turned on, and several people had called before saying, my god, turn on the television.  So it's like, yeah, big deal.  So, yeah, wow.



LEO:  Yeah, it's certainly something to commemorate.  And it changed the world forever.  Certainly changed Americans' lives forever.



STEVE:  Yup.



LEO:  Also the day after the Large Hadron Collider did not destroy the Earth.



STEVE:  That's a good thing.  Assuming that our listeners - we're recording this on Wednesday...



LEO:  If you're hearing this...



STEVE:  ...and the collider has just been turned on.  Now, yeah, so assuming that this podcast is ever actually heard by any humans...



LEO:  No, because they're not yet colliding, they're just testing.  They're just running them around the track right now.



STEVE:  That's true.



LEO:  No danger yet.



STEVE:  Of course, you know, the sky-is-falling people are saying that it's going to create a black hole that's going to suck the whole Earth into it.  And but the good news is that small black holes evaporate quickly.  And they may actually be, like, zipping around, you know, black holes can get caught by gravitational bodies.  So we might have a few already inside the planet, just sort of zooming around our center of gravity.  And, you know, nobody would really know it.  It's not a big problem.



LEO:  They asked Stephen Hawking.  He said, oh, no, it's not a problem.  But, see, I thought a black hole accretes very rapidly all the stuff around it because of its intense gravitational field.



STEVE:  Well, it does, except that there is also evaporation.  And I used to know, I mean, I remember once I understood the physics of that.  But it's, like, long since gone.  But...



LEO:  Right.  Fascinating stuff.



STEVE:  But I believe Stephen because, after all, he is the person...



LEO:  He seems to know.



STEVE:  ...that Hawking radiation was named after.



LEO:  But, you know, I love it when they do big science like this.  It's arguably the largest scientific experiment ever created by humans.  Just exciting.



STEVE:  Oh, god, and Leo, when you - "Scientific American," earlier this year or late last year it might have been, had this fantastic spread that, like, with huge color photos of the various targeting systems like the endpoint where all of these high-energy photons end up going.  And, I mean, it looks like a real starship.  I mean, it's like - it looks like, literally, the engine room of a big Enterprise sort of warp drive.  It's just phenomenal.  And then in the photo they'll refer to the picture, like the guy on the scaffold.  And you go, what?  And then you look, and if you, like, zoom way in with your eye, you see this little person standing, like adjusting something in this massive thing surrounding him.  It's just, ooh, I mean, it just gives me goose bumps.  It is, like, it is as close to science fiction as science fact has come so far.  It's just - it's exciting.



LEO:  It's really exciting when we do stuff like that.  It's just - makes you proud to be alive in an amazing era.



STEVE:  And it should be able to tell us, I mean, the whole point of this is by creating much higher energy collisions of particles, it will help to confirm existing theories and also raise questions that then the theoreticians will work on solving.  So, I mean, basically it's all about allowing us to get a better sense for what it is that our fabric of reality is built from.  How does it really work?  Is it strings or loops or quarks or who knows?



LEO:  We have a physicist who is a regular follower of our broadcasts.  She's a professor at the University of Toronto of physics, Professor Peet.  She's going to join us on the radio show on Sunday to talk about what it means and so forth.



STEVE:  Very neat.



LEO:  And what the Higgs boson is and...



STEVE:  Will she be on for the whole three hours?



LEO:  Oh, no no no, I don't think - well, who knows?  If there's enough demand...



STEVE:  You going to start at the beginning?



LEO:  We'll start at 11:30.  So it's possible we could keep her for as long as people want to talk about it.  I think this is the kind of thing it's important to talk about, you know?  This is tech.



STEVE:  It is serious tech.  It is mega tech.



LEO:  So we're going to talk a little bit about mega tech.  We're going to talk about the newest browser in the browser wars, a big shot from Google Chrome.  And it's, I presume, a security angle; right?



STEVE:  Well, yes.  That's, of course, that's the angle of our whole show.  And, you know, we discussed it for the first time last week because it had been announced the day  before we were recording.  We record on Wednesdays for publication on Thursday.  And Chrome was released on Tuesday of last week.  And you and I immediately backed away from it due to the problems with the EULA, the End User License Agreement, which was ridiculous.  And the good news is, so many people raised such a fuss that Google, with shocking speed, fixed it.



LEO:  They said, whoops.  They said, our bad, we didn't mean to - that was cut-and-paste.  Now, I'm not sure if I believe that.  But they backed off very quickly, yeah.



STEVE:  And I don't think I believe it, Leo.  I mean, this thing is...



LEO:  They have lawyers by the dozens.  They can rewrite.



STEVE:  And this thing is two years in the making, the browser is.  I have a lot to say about it, and none of it good.  Well, not much of it good.  I am very disappointed.  I'll tell you why when we get into...



LEO:  Good, I can't wait.



STEVE:  Yeah.



LEO:  So, Steve, before we get into Chrome, which I'm very excited about, any updates - you know, it's funny, I booted up - I've been gone for a day.  And I booted up, and all my Windows machines said we've got updates, we've got updates.  So it must be a Patch Tuesday.



STEVE:  It was, yes.  Yesterday was a Patch Tuesday, and it was an important one.  In fact, well, there were four major Windows components that all had patches - Windows Office, Media Player, and Media Encoder.  The Office vulnerabilities were significant because there was a new component that was added in Windows XP.  All versions of Windows from the very first version 1 had something called GDI, the Graphics Device Interface.  GDI, along with user and kernel, are like the three main pillars of Windows.  And of course the whole point of Windows is that it's a graphical environment for...



LEO:  Does every - all calls, all graphics calls go through GDI?



STEVE:  Yes, yes.  GDI is the - well, yes, all graphics calls do.  There are non-graphics calls like memory allocation and things that don't involve graphics.  But, yeah, it is, it's where all the graphics system is located.  And Microsoft added something called GDI+, sort of an additional next chunk of - it's another DLL library of subroutines.  Well, there were four, I'm sorry, five vulnerabilities in GDI+.  And the reason these are of concern is that these are image-rendering vulnerabilities.  And images, of course, are what web pages display.  So people who understand what the vulnerabilities are, it's one of those where, you know, email that is running in the IE viewer, so displaying email that displays an image or using Outlook with the IE viewer or going to a website with IE or even non-IE, any browser that is going to be rendering those images will typically be using this GDI library.  So anyway, very important, as always, it's like it's never not important for people to make sure that they've got these most recent patches for Windows, this being, you know, just having passed another second Tuesday of the month.  Also the news about Wells Fargo login continues.



LEO:  Just to update you, this was an email we got two episodes ago from somebody saying, hey, it's weird, it truncates my password, doesn't use any - what is it, eight characters it uses?  And then...



STEVE:  Well, yeah.  The first report we heard was that extra characters were ignored.  Now, I'm not sure if - no one has, like, done an experiment or reported it that says, look, this is how many it uses.  We do know that you can put superfluous characters on the end that are completely wrong, just random, and you still get to log in.  Then the second report we heard was that not only is the password, the tail of the password superfluous, it doesn't matter, but the password is non-case sensitive, which dramatically reduces the security, but in the name of making sure users are able to log on.  The problem is, when you do that, you're helping the bad guys to log on, as well.  Anyway, I got another report from someone who, after hearing these two, decided, okay, I'm going to play with this myself.  So he reports that, not only is the password not case sensitive, neither is the username.



LEO:  Oh, man.  It's getting worse and worse and worse.



STEVE:  So none of this is case sensitive.  And that would have had to have been deliberate on the part of the programmers because you would need to deliberately remove the case before you stored it.



LEO:  Strip it out, yeah.



STEVE:  Yes.  You would, like, make everything lowercase or uppercase, one way or the other.  And then you'd have to do the same conversion every time you did a comparison.  So it's not a natural thing for something to be not case sensitive.  It is an unnatural thing.  I mean, you'd go to some effort in order to make that happen.  So anyway, that little tidbit...



LEO:  And you would do that because you would like the users to not have to - to make it easier, as usual, the tradeoff between security and convenience.  So if they enter it with a capital "L" for Leo or a lowercase "l," it doesn't matter.



STEVE:  I know.  And...



LEO:  It does make sense for the password, but I guess you'd probably have some - okay, I'm going to be stereotype here...



STEVE:  And it's not like you're logging into TWiT or Twitter or something.



LEO:  This is your bank account.



STEVE:  This is your, exactly, this is...



LEO:  But they're worried that some unsophisticated user will type the password with uppercase and lowercase, not realizing it makes any difference, so they just make it easier.  They don't want the support calls.



STEVE:  And we don't know what the history is.  It may well be that the programmers originally implemented it in a fully case-sensitive fashion, and they got so many redundant calls saying, hey, can't log in, that management said, okay, we've got to make this easier.  This is ridiculous.  Let's, you know, people are not remembering the case of their password.  And so they just, presumably, removed it.  I got a kick out of something that happened, well, a kick only because I'm not a user of Trend Micro's AV.  Last week Trend Micro, the update early last week misidentified a collection of Windows XP and Vista core OS files, quarantined them, and removed them.



LEO:  Ho.  Which means it broke the system.



STEVE:  It hosed people.  There are still people who have lost XP, who cannot get back to XP.  Even going into safe mode doesn't help you because it's some core files that are necessary for safe mode.  And it's not the first time this has happened with Trend.  It also did happen to Symantec a few years ago.  So, I mean, this is sort of the dark side of the heuristic pattern matching is - you've got to wonder, too, how they missed this.  I mean, they run this on their own machines.  Or somehow was it maybe a foreign language version matched and the language they were testing on didn't or something.  But it's, like, really bad when your AV - it's like an autoimmune disease, I guess.  I mean, your AV decides you're evil and quarantines...



LEO:  Boy, that's a [indiscernible] description.



STEVE:  ...the OS from itself.



LEO:  It is like an autoimmune, isn't it.



STEVE:  Yeah, that's where your immune system goes after yourself instead of - yeah, so not good.  And I did want to mention also I got news from my friends at Golden Bow, who are the publishers of Vopt, which is one of my two favorite defraggers.  Vopt I really like, which has always been at major version 8.  I think it's been at 8.1 for a while.  They released version 9, which has some Vista enhancements.  It's been - it's redesigned, and it's very nice.  So that and PerfectDisk are my two favorite optimizers.  They're enough different that I like to use them both sort of for - Vopt is very fast and sort of does a nice, quick, very graphical, you can really see what's going on, defrag.  And PerfectDisk is able to defrag the files that are in use, that is, the page table, hibernation file, directories, basically the system things that normal defragging won't do.  You're able to say "defrag at boot," and then when you restart the machine it jumps in before Windows gets going and defragments all of those core things that don't tend to fragment by themselves, so you don't have to do it very often, but it's just nice to have something that'll, like, set that up once for you when you're setting up a new machine.  So...



LEO:  I'll tell you how old that is.  I remember Jerry Pournelle recommending Vopt, that's where I first heard about it, in his users column, Chaos Manor, in Byte magazine.  It's probably 15 years ago, a long time.



STEVE:  Yup.  Golden Bow's been around a long time.  They're a good company, nice technology.  And I was just - there hadn't been much action or motion with Vopt for a long time.  So I was sort of wondering, well, I guess it's sort of not going to be changing.  But I got the news last week that it had gone to version 9.  And so I just wanted to point that out to people because I've mentioned it before.  I know that there are listeners of Security Now! who have adopted Vopt, and so I wanted to make sure they knew there was a new one.



LEO:  Yeah, that's a good...



STEVE:  And then I promised last week that I would share a short little SpinRite blurb with our listeners about SpinRite saving 200 kittens.  It turns out that was a little misquote.  But, well, but not much.  The subject line of this email is "SpinRite Saved 200 Hungry Cats."  And so the author, Marius, says, "Hi, Steve.  Hi, Leo.  I want to give some feedback for the fabulous SpinRite.  I'm working in an animal shelter.  We have got a special database to control the feeding and to control food orders automatically.  During the weekend our computer broke down, and we were unable to determine whether there had already been food orders for all the animals.  Because of the fact that we're very low on money these days, a double order was impossible.  After I asked some technically skilled guys, my friend Paul told me that there's SpinRite.  The order was no problem because your site is designed very well.  After I purchased SpinRite and got it instantly, I was able to recover all the data on the computer, and I saw that we had not placed the food order.  I was able to complete everything, then purchased a new hard drive as a precaution.  200 hungry cats and dogs are thanking you, Steve and Leo, and so do I.  SpinRite saved these animals" - oh, okay - "saved these animals, and I'm very happy to announce that I'll try to listen to Security Now! from now on, too.  But I'm not a technical guy.  Thanks for this brilliant program in the name of the hungry animals.  Yours, Marius."



LEO:  The hungry animals say, "Thank you, Steve."  Hungry animals.



STEVE:  The hungry animals thank us for SpinRite, yes.



LEO:  That's great.  That's great.  Chrome is a good name.  You know, I was thinking about the choice of names.



STEVE:  You know where the name comes from; right?



LEO:  No.



STEVE:  "Chrome" is the jargon which is used by browser designers to refer to all of the UI outside of the page.



LEO:  How interesting.



STEVE:  So they refer to that as the "chrome" on the browser.



LEO:  Right, that makes sense.



STEVE:  Like the skin.



LEO:  And by the way, this is a very chrome-free browser.  So it's kind of ironic.



STEVE:  It is.  It's minimal.  It's minimal chrome, exactly.



LEO:  Yeah, yeah.



STEVE:  Well, and that's one of the things I like about it.  We were talking just the other day that I like small devices.  I've got this little OQO, which is a cute little handheld ultra-mobile Windows machine.  The screen is 800x480, so I don't have lots of screen pixels to waste on superfluous UI.  And so running full screen in the browser, and a browser that isn't taking up a lot of the screen, is really nice.  But where, you know,  we talked about the EULA, and then I was aware a couple days later that Google had fixed the EULA.  It's like, okay, well, that's good.  And I had mentioned to you that prior to the podcast starting I was in the process of installing Chrome in a VM, in a VMware virtual machine, just to give it a place to live so I could watch it and not have to install it on my main system and then remove it with all of the wear and tear that creates.  Well, but I didn't really take any action until - that is, you know, further action with Chrome.  And with the EULA being the way it was, that of course put me off of it completely, though they have fixed that.



But I happened to go to one of my pages which is not yet public.  It's the whole cookie region that I've been working on, which I suspended work on while I'm working now on this very comprehensive DNS profiling facility, which I expect to be announcing in two weeks.  And so anyway, I went to one of my cookie pages.  And this is a page which is basically advocating for third-party cookies being disabled by default.  The only browser that does that in the entire industry, and this is inclusive of Chrome now, is Safari.  Safari has cookies disabled by default.  And on this page I show, of all the visitors who come to GRC, how many people have cookies enabled.  And it's a huge number, I mean, a huge percentage.  It's like 80-some percent, I think.  And then I show the power of default settings by showing what Safari's setting is.  And it's always been down in the low, like, just a little over 10 percent.



But when I happened to go to that page - oh, and this is all real-time statistics that update continuously.  Every Sunday night the prior week's summary is made current so that I'm able to see changes over time and not just accrue forever.  So I'm able to see, like, we're always looking at what the last week's stats are.  Well, suddenly it was - Safari was showing as 54 point something percent.  And it's like, whoa, wait a minute, that can't be.  Nothing has changed in Safari.  And then I immediately clicked on what it was because I remembered that Chrome was based on WebKit, which is the same open source HTML rendering system that Safari is based on.  So my hunch was that my cookie tracking system was misrecognizing new Chrome users as Safari users.



LEO:  Oh, interesting, huh.



STEVE:  And that since Chrome had third-party cookies enabled by default, I was suddenly believing that Safari had gone bad.  And but the fact that the number was so big shocked me.  It's like, wait a minute, people are really using Chrome?  And so then I went over to my demographics stats page, which is much more comprehensive.  And sure enough, suddenly I have a big - I have a pie chart there that shows the various percentage of browsers of visitors coming to GRC.  And everyone, all of our listeners will know about this as soon as I get these pages finished.  I don't want to talk about it too much, I mean, I don't want to go into detail about all the other things that are there because they're not complete, and we end up with people saying, hey, wait a minute, I clicked this link and it says there's, you know, I got a 404.  It's like, yes, that's just a placeholder for me.



So anyway, the point is that I was quite surprised by the rate of Chrome adoption.  And I thought, okay, if that's the case, then we need to talk about it because there are some things interesting about Chrome, lots of interesting and intriguing good design decisions, or potentially good, from a security standpoint; but some things that are also very annoying to me.   So I did some research, and it turns out that in the first 24 hours of Chrome's release it hit 1 percent Internet penetration, that is, 1 percent of Internet users were giving Chrome a try.  And that peaked about three days later at 1.57 percent in one stat that I saw.  So obviously it didn't take over.  But it did, you know, there were a lot of people using it and, apparently, going to GRC to see what we thought of Chrome.  To give people some sense of the way the demographics are breaking down right now, IE is holding about 70, 71 percent.



LEO:  You just sold a copy of SpinRite, I hear.



STEVE:  I thought I'd muted that.



LEO:  No, I like it.  You should never mute that.



STEVE:  Oh, really?



LEO:  I love it.  That yabba-dabba-do is a little - Steve has all these sounds that he normally mutes in the background.  That means, what, that's a license to SpinRite; yeah?



STEVE:  That's someone's credit card cleared.  Because I have, as they're moving through the eCommerce pages, where you fill out the form, and then you submit that, and you verify before you commit, I have, like, a cash register sound, kaching-kaching, kaching-kaching.  And then when the actual credit card transaction occurs, I have this Fred Flintstone yabba-dabba-do.



LEO:  It's not merely celebratory.  You probably also can use it diagnostically because if you hear a lot of kaching-ching-chings, but you don't hear a yabba-dabba-do, if you start hearing little issues like that, that probably has some value.



STEVE:  Oh, absolutely.  Yes.  I mean, it does.  There is - oh, and I've got - there are other sounds that it makes.  Basically I set up a custom UDP client and server.  And every two seconds my client pings a custom server at GRC's facility at Level 3 to request an update on all kinds of stats.  So a whole stats package comes back that allows me to monitor incoming and outgoing bandwidth and other things that are happening, including the status of our eCommerce system.  So...



LEO:  Anyway, I'm sorry, Fred distracted me, and I'm easily distracted.  Let's get back to Chrome.



STEVE:  Okay.



LEO:  I'm actually going to load my statistics pages because I use Google Analytics on a number of pages.  You know, we get a much more geeky audience.  So our Chrome adoption rate is going to be much higher than the average, I would imagine.



STEVE:  Right.  IE currently has about 71 percent market share.  Firefox is at 20.



LEO:  This is not your server.  This is global.



STEVE:  No, this is global.  These are stats people from...



LEO:  It's reversed on my server.  It's exactly the opposite.



STEVE:  Well, and actually at GRC it's very much similar to that.  Firefox is about half.  And I think it slightly edges out IE.  We still get a lot of IE.  But really a disproportionate share compared to the Internet in general, which is not surprising because Firefox users, I mean, NoScript is super popular, which is what I keep preaching, is that JavaScript is not safe.  And so, yes, it's useful.  But it's like radio, it's bad.  And so you have to have it sometimes, but you don't have to have it all the time.



LEO:  You also get probably a lot of business users buying SpinRite or going to ShieldsUP!, and that may skew you a little bit more towards IE than, for instance, TWiT.



STEVE:  Oh, that's a good point, too, yeah.  I don't really know the demographic of the ShieldsUP! users.  But so IE at 71; Firefox at 20; Safari, Apple's browser, and this combined Windows and Mac, is at somewhere between 6.1 and 6.3, depending upon who you ask.  And Opera, surprisingly, is as low as 0.75.



LEO:  You want to hear my numbers?



STEVE:  Yeah.



LEO:  For TWiT.tv.  And again, a geeky audience, right, so it's going to be a little different.  Firefox 60 percent; IE 20 percent; Safari 14 percent...



STEVE:  Mac, of course, yeah.



LEO:  Yeah.  Chrome, 2.41 percent.



STEVE:  Wow.



LEO:  And this is in the last, looks like the last - since August 10th, so the last month, 30 days.  So if I actually -if I go since Chrome came out, let me just look at the week, it's going to be much higher Chrome percentage.  And then Opera at 2.27 percent.  So it's interesting, the disparity, really.  I'm just - I'm curious.  Let me just look at the last, say, when did Chrome come out, the 2nd; right?



STEVE:  Yes, Tuesday before last.



LEO:  Right.  Let me go the 2nd through the 10th and see what Chrome is.



STEVE:  Chrome has fallen, by the way.



LEO:  Oh, really.  Yeah, it's 8.8 percent in the last week for me.



STEVE:  Wow.



LEO:  And you know who it took market share from?  Firefox.  Firefox down 5 percent; IE only down about a point and a half.



STEVE:  Well, now, that actually speaks to some of the points that I'm going to be raising because I've - well, and I want to just finish, that 'Net-wide, Chrome peaked at 1.57 Internet-wide and then began to drop and is now down to, at last note, 0.9 percent.  So there were a lot of people who gave it a test drive, who thought, oh, I want to see what Google has done.



LEO:  Sure, sure.



STEVE:  And this is my main complaint is that, as the famous old expression is, you only get one chance to make a first impression.  And I sort of wonder who Chrome is targeted at because it was clear to me that it would be Firefox users who were - that is to say, those who are, were first of all, willing to move from IE.  There's been a lot of conversation over the week about Web 2.0 and AJAX application handling because one of Chrome's main features is that they say that it has an extremely strong, very fast, brand new JavaScript engine, their own JavaScript engine, V8, made by some guys, I think a team in Denmark, as I recall.  And sure enough, if you benchmark their JavaScript versus others, theirs wins.  There are JavaScript benchmarking suites and sites.  And Chrome does win.  However, in overall page-loading performance, it is not speedier, for example, than Firefox or Opera.  So that's a problem.



Now, one reason is, one of the benefits of Chrome is that they are launching - and I've checked a lot of this out now.  They really are launching an entirely separate process, a Windows process for every page.  So there is process creation overhead with creating a new page.  It's not bad.  But it's two things.  It does take some time, and it does take some memory.  At the moment, Chrome is a bigger memory hog even than IE8, which is now in Beta 2, and IE8 has been criticized as being a memory hog.  There was one reviewer who opened a standard 10-page set of tabs and, whereas IE8 consumed - are you sitting down, Leo?



LEO:  Yeah.



STEVE:  324MB to open those.  Chrome was a little more than that.



LEO:  Yeah, but everybody has several gigs.  I mean, come on, that's not...



[Talking simultaneously]



LEO:  ...point out that when you're testing beta software, frequently there's code, as you know, left in beta software that takes more memory.  Beta software is not tuned for memory usage yet, or speed.



STEVE:  Well, okay.  Maybe.



LEO:  They might even have the symbol tables in there and stuff.  I mean, there's all sorts of stuff that could be still in there.



STEVE:  It's not in there.



LEO:  Oh, okay, all right.



STEVE:  I looked.  I think that what we are going to have to accept is that we're moving to a next generation of browser.



LEO:  Well, that's right, that's right.



STEVE:  I think that IE8 and Chrome are both aiming, I mean, certainly this is where Microsoft's direction is, and we know that's where Google's direction is, they are aiming at the browser becoming the OS.



LEO:  They're, well, they're an application platform at least.  I don't know, I don't think you'll be deleting files and moving files via Chrome.  But it's an application platform, for sure.



STEVE:  I wouldn't be surprised if someone does some wacky [indiscernible]...



LEO:  Plug-in for file management?



STEVE:  Okay.  But in any event, what I mean, and I don't mean the OS in that sense, I mean as where you run applications.



LEO:  Yeah, an application platform, right.



STEVE:  Right now we run applications on top of the OS.  And clearly Microsoft and Google are both aiming toward this whole, always connected, we rent your applications to you, and you're going to be running them in the browser.  So a strong JavaScript interpreter, and in fact Chrome apparently goes further.  They do some sort of byte code compilation.  They say they're compiling into real machine language.  So it's probably, I mean, there's been a lot of work done in virtual machine architectures over the years.  And there are systems where they will compile on the fly, the first time they run across byte code they compile it in a just-in-time fashion into real machine language; and then next loop-through, next time they execute it, it's much faster.  You still have an intermediate language translation overhead and intermediate language sort of expression overhead as opposed to something where a compiler is able to crank on it for some length of time to produce natively optimized code.  So it's never going to be as fast.  But it is acceptably fast.  And we have machines getting much faster.  And to your point about how much memory these systems have today, I mean, you're certainly right, Leo.  So what if it takes a third of a gig?  I will say that I completely crashed Chrome running it in a 256MB virtual machine.



LEO:  Oh, my, yes.  So, but I think that that's the way, that's the trend of all software, and certainly all application platforms and OSes.  You assume more memory space.



STEVE:  However, it crashed.  I mean, it didn't hang.



LEO:  That's not good, yeah.



STEVE:  It just disappeared off the screen, and then it would not restart because...



LEO:  Now, I'm wondering how much RAM does Word take up, or  Excel take up?  When you're running a native application, it takes up a lot of memory, too.



STEVE:  I don't think they take up...



LEO:  About 300 megs.



STEVE:  300 megs is a huge amount of memory.



LEO:  You're biased because SpinRite runs in, like, 20K.  So you...



STEVE:  I'm just saying that it is going to have a problem on lean machines.  There are 500MB machines that people are using today because once upon a time half a gig was a lot of memory.



LEO:  Well, and I also want to point out, I'm looking in the chatroom, there are people who have 20 tabs, there's a guy who says I usually have 20 tabs open, 12 tabs times 3 rows, 15 to 25 tabs.  There are people whose workflow has a lot of processes running in their browser.



STEVE:  Okay, so, now, the reason that Google has done this is twofold.  They recognize that if a browser is going to be an enterprise-ready tool, that is, if literally, if you would be using it as your word processor, then you can't be 15 pages into creating a document and have some other tab that you briefly switched over to to do something hang your whole browser because you've got 15 pages of work in one of these tabs.  So, and frankly, when this thing just disappeared from my screen yesterday, I wasn't very impressed with its collision-handling capabilities.  But, again, it is beta.  We recognize it's beta.



So the idea, though, is by launching separate processes, they keep them independent.  And Google's focus from the beginning has been that these things, that individual processes run in separate tabs so that, if one dies, it's just like an app dying in Windows.  An application dies, and of course that happens, or locks up and, you know, happens from time to time, especially if they're poorly written, you just - you close it or kill it, using Task Manager if you have to.  But inherently you've got your other applications are unaffected.  Similarly, the other tabs in Chrome would be unaffected.  So there's that.



Also Google makes the point that there is inherent memory fragmentation, it's known as "heap fragmentation," within the context of a process.  So within a single process one of the things that happens is there's all kinds of memory continually being allocated and deallocated.  As you surf around, and a page is loaded, the page contains all kinds of GIF and PNG and Flash and all kinds of other images.  Well, those all acquire memory from the process, within that process's space, while you're looking at the page.  You then go to another page, and those chunks are freed.



Well, all these chunks are different sizes.  And so what happens is the operating system searches for a free space large enough to fulfill a requirement, and it sticks something in there.  Then, for example, say something else comes along that's smaller.  Well, so it fits it into a smaller space.  Then something else is removed.  It is exactly analogous to fragmentation of a hard drive.  When you think about it, the reason hard drives fragment is that new files are added, file sizes change, files are deleted, an old version is turned into a .sav and a new version is created.  So there's constant churn on the hard drive.  And all users are familiar with the way their hard drive looks when they view it in a good defragger.  It's just all chewed up.  It's all fragmented.



Well, the same thing happens to memory.  What happens over time is - and in fact heavy users of Firefox are familiar with this phenomenon because it's something that has afflicted Firefox to somewhat greater degree for whatever reason, just architecturally, than IE, is Firefox will start getting really slow.  And you'll have to literally shut it down and restart it in order to, like, get it going at normal speed again.  And that's due to fragmentation.  So...



LEO:  Modern operating systems, memory managers handle that.  They make sure you don't get fragmentation.  Why is it these browsers can't do that?



STEVE:  Well, modern operating systems actually don't.



LEO:  They don't?



STEVE:  Well, no.  The containment of this is per process.  And so it's the process that has the fragmentation.



LEO:  So the application, or the page, has to handle that.  Or the JavaScript or something.



STEVE:  Well, what - the advantage of this per-process model in Chrome, and I have to - I should mention that IE has gone to the same thing.  IE8 is also a process per page, for many of the same reasons.



LEO:  Oh, interesting, yeah.



STEVE:  So we have that in IE8 without having to go to Chrome for it.  The point is that, by having individual pages be processes, you get the robustness of them not crashing each other, hopefully, unless the whole browser crashes, as mine did yesterday.  But it also means that when you leave a tab or close a tab, that process, even though there might have been fragmentation within it, all of the memory is released because, for example, the heap structure is a per-process heap.  So it's per process allocation that this is being done.  Essentially it means that the fragmentation that you will have is per tab rather than per browser.  And so just closing a tab which is becoming a problem, if you happen to be, like, surfing in one tab all day long, which it sounds like most people aren't doing, they're jumping around between tabs, and tabs have a life of some length of time much less than the time they're using the browser, so...



LEO:  So an operating system is kind of at the mercy of the application that's running.  If an application has memory leaks, or it doesn't release memory properly, then it can't help the fragmentation.



STEVE:  Correct.  And in fact there is this notion in modern high-level languages like JavaScript...



LEO:  Garbage collection, yeah.



STEVE:  ...there is something, I was just going to say, the garbage collector.  Again, Google designed it so that they have a more - they're able to have a more aggressive garbage collector in their JavaScript engine than other JavaScripts are able to because theirs is able to track the usage of pointers which point to these temporary objects with a finer degree of precision, essentially, than other JavaScript engines.  And the last benefit is security.  By running pages in their own process, you get the benefit that the OS already brings to interprocess isolation.  Now, that's sort of an oxymoron, as we know, because interprocess isolation could be and should be arguably much better under Windows than it currently is.  There is not sufficient interprocess isolation.



And Google makes a point of talking about how add-ons to Chrome can weaken the interprocess or, in this case, the intertab isolation and also the isolation of the tab with the OS.  Google is deliberately working to sandbox the operation of the pages running in the browser.  They have a model where you're either user or sandbox.  We could think of it a little bit like NAT routers.  We know how, for example, the big, bad Internet is outside of our NAT router, and we don't allow unsolicited traffic into our protected local network.  Well, similarly, the model that Google has adopted is sort of like a NAT wrapped around individual browser pages where the page is unable to make an unsolicited access, an unsolicited request outside of itself.  It's only the privileged OS on the outside, the user space, that is able to communicate inward.  And the app is only able to respond to external requests.  It's not able to initiate any communication itself.  So that's, to the degree that that succeeds, that's a nice model.



My problem with the browser is that it is, well, to say it is feature-lean is an understatement.  And this is where I wonder who they're trying to sell this to.  I don't mean "sell" literally, because it's free.  But we know that Firefox users love the features of Firefox which IE lacks, and IE is slow in adopting these things.  Like, oh, gee, tabs, for example.  But also simple security features.  For example, okay, get this.  Chrome, like all contemporary browsers, offers to save your passwords.  And you can turn that off, but it's on by default.  The problem is, it will also show your passwords.  But there is no provision for a password to protect the passwords.  Meaning that anyone can sit down at your Chrome browser, I mean, other than you - your kids, a coworker, anyone - and look at all of your passwords, and which displays all of your usernames and passwords in the clear, and write them down.  There is no provision for protecting that.  Plus, for example, in Firefox you're able to create - and Opera - to create a master password which will protect access to those.



LEO:  You know, it's funny, I noticed that.  My, what do you call it, the Gibson alarm went off...



STEVE:  A Gibsonian response.



LEO:  Yeah.  I noticed that it was saving my passwords, but it didn't ask me for a password to protect it.  And I was wondering how they store it.  So they store it in the clear?



STEVE:  Well, it's you click a button to say "Show Passwords."  And...



LEO:  I guess it would have to.  If you don't give a password, how else are they going to do it, yeah.



STEVE:  Yeah.  Well, so, okay.  So there's that.  And absolutely no scripting management of any kind.  You can't turn it off.  I mean, even IE lets you turn it off.  Even, I mean, and Firefox, and Opera, I mean, everybody...



LEO:  Well, remember, though, this browser is designed for JavaScript.  I think one of the ways I use it, I don't use it as a day-to-day browser.  What I've done is that I've taken, like, Gmail and made that be a separate application running in Chrome on my desktop.  And again, that's not safe if it's saving the Gmail password.  But at least, I mean, you know, that's kind of how I'm using it.  I'm not using it to browse randomly.  And I suspect that's the intent; right?



STEVE:  So I recognize that they wrote Chrome to have an application for running JavaScript.  But again, who is their customer?  Because it is a huge benefit for people running Firefox.  And as I said, even IE you're able to do, like, per-site handling in IE and in Firefox and in Opera.  There is zero per-site features in Chrome.  There is nowhere in there can you say I want to whitelist a site or blacklist a site.  There is no provision for that kind of granularity.  And the cookie handling could not be weaker in terms of privacy.  Now, we know that, you know, they bought DoubleClick, the king of third-party cookies.  So that's a bit of a concern.  You've got three settings for cookies, which is wide open or completely closed, which we know is just impractical, you just can't do anything with the 'Net that way.  But no whitelisting.  You can't say "closed except for these sites."  I mean, again, even IE, the least privacy-concerned browser, supports that.



LEO:  How is its third-party cookie handling?



STEVE:  Well, it's bad.  That's the third setting is restrict - quote, "Restrict how third-party cookies can be used."  Well, no one's really even sure what that means...



LEO:  Right, right.



STEVE:  ...in the first place.  But we do know that, unfortunately, and maybe this is a consequence of their WebKit heritage, they are equally bad as Safari in that they block, when you turn on "Restricting third-party cookies," it blocks them coming in, but not going out.  Which means that you have this problem with what's called "cross-context leakage," meaning that if you were to go to PayPal and click on a link at PayPal, since PayPal loops you through DoubleClick, your browser visits DoubleClick, it's there in a first-party context because it actually pulled up a DoubleClick page through a redirect.  That allows DoubleClick to put a cookie on your browser in a first-party context.  Then it bounces you back to PayPal.  Now, wherever else you go, not PayPal but anywhere that is serving DoubleClick ads, because a DoubleClick cookie snuck into your browser, slipping through in a first-party context, even though you said I want to block third-party cookies, it's sending them out.



LEO:  Now, a couple of people in the chatroom saying, well, Steve, you're being unfair because this is version 1.0, don't compare this to Firefox.



STEVE:  And I said you only get one chance to make a first impression.



LEO:  Well, and I'd also point out it's version 1.0, but you are competing against version 3.0 of Firefox and version 8 of Internet Explorer.



STEVE:  I see.  And Google knows nothing about browsers.  Google has never seen a browser before.  They don't know how they work.  They've never seen Firefox or Opera or IE or Safari.  These are newbies over there at Google who really don't understand the way the web works.



LEO:  Obviously not.  So you're right, they should have known better, yes.



STEVE:  It's nuts.  I mean, it is nuts, Leo.  And if nothing else, look at the adoption rate.  Almost, well, 1.57, 1.6 percent people used it.  And I and a lot of other people said, okay, well, no thank you.  I'm not using something that is by default storing the passwords I use for logging on and giving me no ability to protect that storage from somebody who might have access to my browser at any time in the future.  I mean, that's crazy.  It's just crazy.



Also no provision in cookie handling for distinguishing between session and permanent cookies.  Even IE, again, you're able to say, look, I don't mind session cookies, that is, cookies that are persistent only while I'm using the browser, as long as you throw them all away at the end.  Other browsers provide that.  No provision for handling sites individually.  I mean, I truly - I don't get what they're thinking, who they're aiming this at because IE users, who we might say, okay, are just not going to move away, and they're not clued in to security and privacy, so they just stay with IE, well, they're not apt to use some other browser.  They're not going to move from IE.  People who do, do for a reason, because they want these additional features.  And Chrome doesn't have any of them.  I mean, any of them.  It just boggles my mind.  Oh, yeah, I just - and no scripting management, weak cookie handling, I don't know, I'm just...



LEO:  Well, I mean, obviously...



STEVE:  Oh oh, oh, oh, and they call that thing at the top the "Omnibox"?



LEO:  Yeah?



STEVE:  I call it "Omnispy."



LEO:  Why is that?



STEVE:  It is a real-time keystroke logger.



LEO:  So here's the deal on that, just to explain.  As you type in a URL or a search term, it will supply - it goes out to, by the way, not necessarily to Google, whoever your search engine of choice is, and gets - kind of prefills it with suggestions.  Firefox has been doing this for a while.  You consider that keystroke logging.



STEVE:  Well, I was curious how it worked.  So I turned on a packet capture.  I fired up Wireshark, turned it on, and then, as I typed keys into the Omnispy box at the top of Chrome, as I began to, it initiated a connection to Google, and every single key I typed in, it sent that keystroke back to Google.  And it's like, again...



LEO:  Well, that's how it works, right, it's telling - it's sending the keys - Firefox does the same thing.  It sends the keystroke to Google.  Google then provides completion in real time from that keystroke, or those series of keystrokes.



STEVE:  Right.



LEO:  I mean, it's not like you're entering a password there.



STEVE:  Well, I just wanted people to be aware...



LEO:  And, by the way, you can turn that off.  [Indiscernible] you can turn that off.



STEVE:  You can turn it off, but it's on by default.  And maybe it's convenient.  Many people have said they're a little unnerved by having a single box instead of a URL and a search area separately.  I sort of like the idea from a conserving space.  And it's like, okay, I'm not too worried.  But again, people need to understand that what they type in there, even when they're typing in a URL, certainly it's the case that when you go to Google and you enter a search phrase into Google's page, obviously they know what you've entered.  This moves that boundary all the way up to your keyboard, when you're typing even a URL you know.  So if you type in a URL you know, that you would like not to be watched typing - now, you do have the advantage, however, of using the Incognito window, which is a nice feature of Chrome, where that feature is not available, and what you do in that window stays in that window.  No cookies are written permanently, no caching is made permanently.  So it's a simple way of doing something, you know, the example they give, Google gives, is buying a secret present for someone, and so your spouse won't look at your cache of your browser, if they're apt to do that, or look at your history and see what sites you've been at.  So none of that is saved.  People out on the 'Net are calling that the "porn window" because it doesn't maintain any history of what you've done.  So that's a nice feature.  And that is also a feature in IE8.  So IE8 will have something...



LEO:  A porn window, yeah.



STEVE:  Can't remember what they call it.



LEO:  Private browsing, private searching, probably something like that.



STEVE:  They've coined a nice term for it.  But now I have to say one of the cool things that I like is the notion of dragging tabs between windows.  For people who are browser-centric, and it really sounds like you've got some people, for example, you were talking about it, who have 30 tabs open in three rows, these are browser-centric people.  I know that sometimes I'll have an IE window open with a bunch of tabs, and I'd like to, like, keep a couple of them.  The idea of being able to drag them into a different browser instance, literally dragging tabs across browser windows, and then close the one that I no longer care about any of the tabs that are left, I think that's a cool feature.  And someone's getting it.  Is it - either Firefox, oh, I think it's Beta 2 of Firefox 3 is adding that kind of cross-window tab handling, which will be a nice thing.



So the thing I like about it more than anything else is I like the reloading your page little worm, the little worm turning thing.  I dislike...



LEO:  I don't even remember that.



STEVE:  Oh, it's a cute little thing.  I'm annoyed when the page is still loading indication is not really clear.  And I used to like it in the old IE where it was the spinning globe.  You could easily see that the globe was still spinning, and so you could be doing something else waiting for the page to get finished.  And then in Vista and/slash IE7 they've made it just that little glint that sort of moves around in a circle.  Well, in Chrome you've got almost - it's almost a 180-degree of a circle, sort of like it looks like a little worm which is, like, spinning around.  And it's interesting because it goes backward slowly when it's looking up the IP of the site, until the page begins to load.  And then it starts running forward again.  So that's my favorite feature.  Other than that, I'm not very impressed.



LEO:  Well, let's summarize both the security and the usability flaws of Chrome in just a second.



STEVE:  Oh, oh, oh.  And they've already had problems, which we'll talk about.



LEO:  All right.  And the problems people are...



STEVE:  Security problems.



LEO:  Security issues that are coming up.



STEVE:  Yes, already, in less than a week.  Okay.  While we're on...



LEO:  So security issues, as well, now, for this thing?



STEVE:  Yeah, yeah.  While we're on science fiction, though, if listeners are sure they will not read the book, then there is a Pak Protector entry in Wikipedia - Pak Protector.  You might have fun going and looking at it.



LEO:  But don't do it if you're going to read the book.



STEVE:  Yes.  It is a spoiler.  It will completely spoil the bok because, like many of Niven's things, it's one of the reasons I really like the way Larry writes, is there is a - you have no idea what's going on, even though you think you do.  It is a total surprise.  And the revelation of the reality of what's happening is, I mean, it's the reason you read the book.  So do not, do not Google...



LEO:  Don't spoil it.



STEVE:  ...anything about "Protector" if you think you might be interested.  I recommend the book.  Again, I own the paperback...



LEO:  Here, I'll read you the summary.  "Phssthpok the Pak had been traveling for most of his thirty-two thousand years.  His mission:  save, develop, and protect the group of Pak breeders sent out into space some two and a half million years before...



"Brennan was a Belter" - already I'm confused - "the product of a fiercely independent, somewhat anarchic society living in, on, and around an outer asteroid belt.  The Belters were rebels, one and all, and Brennan was a smuggler.  The Belt worlds had been tracking the Pak ship for days - Brennan figured to meet that ship first...



"He was never seen again, at least not by those alive at the time."  And if that's not enough to get you going...



STEVE:  And again, it is just - it is a fun - again, I own the paperback.  It's not very thick, so I don't think it's - I know it's not a big book.  But it is...



LEO:  It's a seven-hour read.  That's a fairly normal-sized book.  That's not too small.  Oh, I'm putting it on my list right now.  I'm just...



STEVE:  Really, it's good, Leo.



LEO:  I love Larry Niven.  I loved Ringworld.  The whole Ringworld saga is just so inspiring and exciting.  I'm adding it right now.  You see, this is so cool.  So I've got a credit, I just check it right here, and [indiscernible], it's going to download right now.  I'll have it on my iPod for walking home tonight.



STEVE:  Okay.  Second topic on the science fiction front is last night a new series aired which was really fun.  It's called "Fringe."



LEO:  I saw a big billboard for it.



STEVE:  It's J.J. Abrams' new series.  You know he's working on the next Star Trek movie that we're going to have, that's going to come out next summer.  He of course is behind "Lost."  He was behind "Alias" with Jennifer Garner.  And a couple other successful series.  This is very X-Files-like.  And I loved it.  It is re-airing - the reason I bring it up is it is re-airing on Sunday.  It's on Fox.  So anyone who missed and think they might enjoy an X-Files-like sci-fi, I was just very impressed with the show.  I thought it was tremendous.  And of course...



LEO:  "Fringe."



STEVE:  "Fringe" is the name.  And of course we have "The Sarah Connor Chronicles" has restarted also.  Its first episode was on Tuesday, the second season of that journey with Terminator mythology.  So that was neat.



LEO:  So let's talk about some of the flaws people have discovered.



STEVE:  Well, yes.  I was smiling to myself about our listener whose question we read last week when she asked, hey, Chrome is new, and I listen to you guys, so I've learned that you can't ever claim anything about security preemptively.  How long should I wait before I trust it?  And I grinned because there were already problems found.  I mean, immediately.  Several bad ones.  There was a couple - there was a way that a Java JAR file could be downloaded and executed without users' intervention.  Bad.  And there were some - a buffer overflow found in misformed URLs.  And a little bit annoyingly, some other problems that they have fixed but refuse to document.  And that's of a little concern because it's an open source project, and we would expect them to be not hiding what it is that they're doing.  But in this case they were not being forthcoming with what things they fixed.  I mean, the good news is they fixed them quickly.  Chrome does keep a part of itself running all the time, even if you're not using the browser.  And every few hours it phones home to see whether there's anything important has happened.  And now...



LEO:  Now, it's getting phishing site information.



STEVE:  Yes, it is doing that.  Both phishing and malware are coming in on the fly.



LEO:  Malware search strings, not malware itself.



STEVE:  Right, right, right, right, right.



LEO:  Let's not imply that there's malware being imported here.



STEVE:  Yes.  It's acquiring phishing and malware site lists, essentially.  And so it uses that to protect people, bringing up a big, wait a minute, this is a known malware site, are you sure you want to go here warning message if you attempt that.  Anyway, so the takeaway is that it's brand new software.  It's going to have problems.  I like the architecture.  I like the potential of the architecture from a security standpoint.  I think we have to acknowledge that browsers are getting bigger.  IE8 is going to be big.  Chrome is big.  And I don't expect to see them shrink.  So it's just they're going to be RAM-hungry things that are running applications in themselves, rather than applications all running separately.



LEO:  Right, right.  And so in summary, Chrome is underfeatured.  Its privacy controls leave much to be desired.  Doesn't offer...



STEVE:  There are none.



LEO:  There are none.



STEVE:  Yeah.  It just doesn't have any.  They just forgot that somehow.



LEO:  Left that out.  Well, I mean, their business is advertising.  I'm maybe not surprised.  Furthermore, there are security issues, potential security issues.  On the other hand, it's speedy and lightweight and, you know, I'm pretty much sticking with it as a way to run Google's applications.



STEVE:  Well, and certainly that is one of their targets.  Now, you might argue that add-ons are the way that these missing features could be produced.  And certainly it is Firefox add-ons, for example, NoScript and others with really nice ad-blocking features and so forth, which are very popular among users.  So you could say, okay, well, Google has said that they're going to be making an API available for add-ons.  Unfortunately, they've also explained that add-ons will have the problem, or the capability, of being able to breach the containment of the Window tabs.  So to the degree that they're able to create containment, the add-ons are powerful enough to cross that boundary.



So I would argue that it makes much more sense, if you really care about security - and nothing Google has done so far really demonstrates to me they care about security or privacy - if they do, give us all the features in the native browser so that we don't need to add potentially insecure or security-violating add-ons in order to make up for what the basic browser doesn't have.  And it's not like they have to mess up the UI a lot.  Have an advanced line on a menu somewhere that most people won't bother going to, but which people like myself and you, Leo, and Firefox users would find everything that they want hidden in the advanced line of a menu option.  I mean, it's not hard.  It's just missing completely.



LEO:  Yeah, yeah.  Well, there you go.  That's kind of a manifesto to Google to make your browser better.



STEVE:  Yeah.  I'm just - I'm unimpressed.  Again, I don't know who they're aiming it at because, as you said, they borrowed market share from Firefox, and then they quickly gave a lot of it back because Firefox users must have just said, wow, I can't do anything with this.  I don't have any of...



LEO:  Yeah, I think last week everybody tried it, you know, all the geeks tried it.  I doubt very many people are using it as their sole browser anymore.  Certainly not after listening to this.  And especially since there are many good quality choices that give you much more security.  It's not like you need this browser.



STEVE:  Well, exactly.  I mean, Firefox has a huge market share.  It's half of the people who come to GRC.  It's more than half of the people that go to TWiT world and Leoville and all of your domains, Leo.  And so clearly that's a mature solution which also has a really, really strong - I can't think of the term.



LEO:  Security model or...



STEVE:  Ecosystem is what I was looking for.



LEO:  Ecosystem, yeah.



STEVE:  it's got a huge ecosystem and add-on feature set that lets people really make the browser work the way they want it to.



LEO:  Right.  Yeah.  No, I'm sticking with Firefox.  I'm using it right now.  And on both Mac and Windows that's what I use.  Although I have to say I'm happy with IE7, too.  And I'll look at IE8, depending on what you say.



STEVE:  How it comes along.



LEO:  How it comes along.  Steve Gibson is the host and majordomo of GRC.com, a great site for your security needs, for ShieldsUP!, lots of great utilities.  Of course the fantastic SpinRite, the world's best disk maintenance and recovery utility, a must-have for everyone.  GRC.com.  When you get there you'll find 16KB versions of this show for quick download, if you don't mind a little audio quality loss.  You'll also find transcripts which have actually no audio quality but are much easier to understand sometimes.  A lot of people read along while they listen.  And Steve's show notes, too.  That's all at GRC.com.  Next week, a question-and-answer session.



STEVE:  Yes, so I wanted to remind our users, GRC.com/feedback will take you to a web page where there's no scripting required, and you're able to send questions and comments and thoughts to me, which I will peruse prior to and while I'm preparing next week's Q&A stuff.



LEO:  Very good.



STEVE:  And the week after, we're going to do one of our deep propellerhead shows.



LEO:  Oh, I love those.



STEVE:  We're going to do DNSSEC, the languishing but clearly important DNS security spec and model, and talk about exactly how it is and how it works.  Probably by that time I will have my DNS work finished.  And one of the things it will show you is whether your ISP's DNS servers are supporting right now DNS security.



LEO:  Ah.



STEVE:  And lots of other cool things, too, Leo.



LEO:  Very good.  Thank you, Steve Gibson.  We'll catch you on the flip-flop.  Take care.  Have a great week.



STEVE:  Talk to you then.



LEO:  See you next time on Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#162

DATE:		September 18, 2008

TITLE:		Listener Feedback Q&A #50

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-162.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 162 for September 18, 2008:  Listener Feedback #50.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show where we help you, yes you, protect yourself online, learn about privacy implications, and just generally get to geek out on computers with the king of security himself, Mr. Steve Gibson of GRC.com.  He's like the Parkay/butter boy.  He's got his little crown on.  And - or is it Chiffon?  I think it's Chiffon.  Hello, Steverino.  How are you?



STEVE GIBSON:  Leo, great to be back with you, as we have for the last 162 weeks.



LEO:  It seems like it's only been 161.



STEVE:  They just fly by, don't they.  



LEO:  They fly by.  And...



STEVE:  Although last week has been a rough one.  Even today the market's down again below where it was on Monday because of the AIG scare.



LEO:  You know, we're very fortunate.  In fact, this show in particular is very fortunate because, despite the economic downturn, advertisers have continued to support the TWiT network to the point where we're pretty much sold out.  And we got approached by another company that wants to advertise on your show.  And I had to say, you know, we've got three spots on here, and I can't put any more on.



STEVE:  Now, Visa was doing a relatively short buy; right?



LEO:  When Visa leaves, we will have a new - and you will like this advertiser.  I will run it by you, of course, as I always do.   You get the right of approval.  But I don't think you'll have any trouble with this company.



STEVE:  Well, good.



LEO:  In fact, I think you'll be - oh, I'm going to say the name:  VeriSign.



STEVE:  No kidding.



LEO:  Yeah.



STEVE:  Oh, cool.



LEO:  And I think it's really because of the focus that you've put on what they're doing with their secure log-in technology.



STEVE:  Actually I've got an email from one of the VeriSign guys, Gary, that I haven't yet even gotten to read.  I've got it open...



LEO:  I bet that's what it's about.



STEVE:  It may well be.  A bunch of news on their end, so.



LEO:  Yeah, but I think we've had to tell them yes, but you'll be waiting a little bit.  We have, well, you know, people love you.  You have been - Astaro's been with us for more than two years.  Audible's with us for more than a year.  Visa, who knows, they may not ever want to leave.  And so I can't complain.  I'm very happy.  And despite the economic downturn, the good news is we're going to keep going with this show and all the shows on the TWiT network, as long as the advertisers and the audience continue to support us as they have.



STEVE:  And there is no sign of us running out of any material.  I have some - I am saving for the last some horrific new revelations about Google's Chrome browser.



LEO:  Oh, interesting.



STEVE:  Yeah, yeah, yeah.



LEO:  So what have we got?  This isn't a Q&A episode.



STEVE:  Yes, it is.



LEO:  It is.  All right.



STEVE:  162 is -  and actually it's our 50th Q&A episode.



LEO:  That's kinda neat.



STEVE:  Yeah, so you're going to want to fire up your email and grab a copy of the PDF.



LEO:  I will.  So, Steve Gibson, you want to save the bad news for later, or do you want to deliver it right now?



STEVE:  No, no, we've got plenty of bad news.



LEO:  Oh, gee.  Oh, god.



STEVE:  Throughout the entire show.  I did want to mention that there was the Apple OS X 10.5.5...



LEO:  Yes, came out.  



STEVE:  ...has just been released.



LEO:  33 fixes.



STEVE:  I know, a huge number of things.  Even the ability to - they fixed - there was a way that users could log in without a password, or change another user's password.



LEO:  What?



STEVE:  Oh, yes. 



LEO:  Oh, my goodness.  I didn't know about that.  Wow.



STEVE:  So a ton of vulnerabilities, arbitrary code execution problems, denial of service, and some DNS cache poisoning.  So they've addressed that which we knew they were - we were hoping they were going to.  And so they have...



LEO:  Yeah, they did a fix in January which didn't fix it.



STEVE:  Right.  Right.



LEO:  So it's a good thing they came back.



STEVE:  And they also did some fixes for some of their stuff, some of the open source components that were really not their problem; but, you know, it's in their system, and they're shipping it, they provided it, so they've got to take some responsibility for it.  Also in the bad news category I wanted to alert people, there have been some huge problems under Windows after the iTunes 8 update.



LEO:  Oh, Blue Screens of Death.



STEVE:  Yes, Windows is Blue Screening of Deathing...



LEO:  Oh, I like that.



STEVE:  Blue Screening of Deathing...



LEO:  A little participling, but that's good.



STEVE:  Blue Screen of Deathing, yeah, just one "ing."  Blue Screen of Deathing.  It's caused by a newer version of a GEAR add-on.  You know that GEAR is a well-known provider of drivers for CD and DVD burning.  And so in this newer version of iTunes, Apple is installing a new ASPI module, GEARAspiWDM.sys.  And that's apparently the source of the BSODs.  They don't occur until you plug in your iPod, which invokes the driver to jump in and help out, and then your system BSODs.  Not good.



LEO:  Wow.  Wow.  Now, does GEAR come from Apple, or does GEAR come from somebody else?



STEVE:  Well, GEAR is from a company called GEAR.  They're a German outfit.  And in fact I own - GEAR Professional is their writer because I think I mentioned to you in my main media machine I've got four burners.  You were chuckling over what do I need four burners for.  I said, well, you know, I only have to burn one quarter as many times when I'm doing a little short...



LEO:  I don't even know what you're up to, and I don't...



STEVE:  It's for production.



LEO:  You don't burn your own SpinRite disks.



STEVE:  No, no, no, no, no.



LEO:  No, people download that.  They burn them, yeah.



STEVE:  It's just, you know, when I want to share things, like, you know, like for example there was - some friends of mine missed both first and second shots of the first episode of "Fringe."  And by the way, I should say that we got a ton of email from people thanking me for aiming them at "Fringe."  They very much liked catching the repeat of it last Sunday.



LEO:  We're getting a lot of requests to do a Security Now! sci-fi show.  And I can't figure out if the requests are because they want us to stop talking about sci-fi on Security Now!, or that they like it so much they want us to do more of it.



STEVE:  For what it's worth, I do get a lot of feedback from people who want to hear more.  I guess the same sort of stuff you're talking about.  I mean, there are a lot of people who would not have seen "Fringe," they wrote, had I not mentioned it and said, hey, I think this is worth checking out.  And so they were glad they hadn't missed it.  So that was cool.  I also, since I last talked to you, Leo, actually it was the day after we last spoke, I was joined for coffee at 5:30 in the morning by Stina Ehrensvrd.



LEO:  Oh, you're kidding, that's great.



STEVE:  Yeah, she was down at the DEMO show, which was at the beginning of the prior week, beginning of week before last, or, well, no, last week...



LEO:  She's the creator of YubiKey.



STEVE:  YubiKey at Yubico.  And it was really fun.  We spent a couple hours, and I got a complete update on what's going on.  They're doing fantastically.  I had known from email that I shared with her, which I mentioned on the show before, that there was a lot more free, open source stuff being done, which is all available for download at their site, Yubico.com.  But also they've lined up some venture capital.  So they're going to make the next step forward in going from a generic chip to their own custom chip.



LEO:  Oh, that's neat.



STEVE:  And, well, what's significant is it will dramatically lower their cost, which they intend to pass on to customers.  So it's going to bring the cost of the YubiKey down dramatically because they'll be able to bring their own costs substantially down.  So that's going to be neat.  The other thing that - there were two things that I asked her if I could share with our listeners.  The first is that they're getting ready to start growing the company.  And she asked me if I knew of any good, like, "suits" sorts of people.



LEO:  She's tired of wearing the suit.



STEVE:  She's just not a suits person. 



LEO:  No.



STEVE:  And but she needs some...



LEO:  This is why we love her, by the way.



STEVE:  Yeah.  But, you know, to grow forward she needs, like, sales and marketing type people who are familiar with the tech industry.  And I said, well, you know, I'm sort of a hermit down here in Southern California, I said, but Leo may know people.  And I said, but even more so, our listeners are people.  So...



LEO:  I figure if you listen to the show, you're probably a good candidate for this job.



STEVE:  Well, I mean, exactly.  You know security.  You know the product.



LEO:  Obviously you'd have some business experience.  They're looking for operating people; right?



STEVE:  They're looking, yes, for operating and also - not really so much on the tech side.  I think they've got that well covered.  But operating and business development sorts of people because there are things that I cannot talk about that are in the works that are very exciting.



LEO:  Oh, neat.



STEVE:  That I'll be able to talk about when Stina says this can be discussed publicly.  But I should say that it's just lots of good stuff is going on.  It's very clear that the people who see this understand it.  She mentioned, in fact, that she ran across the ex-editor-in-chief of PC Mag, and she only remembered his name as Michael.  I said, oh, Michael Miller.



LEO:  Michael Miller, yeah.



STEVE:  Of course.  And I told her I have a long history with Michael.  He was my editor.  He edited the TechTalk column for most of the eight years that I was at InfoWorld.  And anyway, so he apparently came by where she was sharing a booth with someone.  And she was sort of holding it up in the air and saying, do you have an interest in authentication.  Anyway, Michael, to his credit, because he is a techie also...



LEO:  What's he doing now?  Is he...



STEVE:  I don't know.  I guess he's no longer editor-in-chief.  But I think he's still writing a column.



LEO:  He's paying attention, obviously, because he's...



STEVE:  Yeah.  And he was present for the DEMO conference.  So but, you know, again, Michael instantly got and understood what this thing was.



LEO:  That's really neat.  Of course he would.



STEVE:  Yeah, so anyway, so things are really happening for them.  So I did want to mention, if you are a listener, or you know somebody who's technically savvy and maybe looking around for the right kind of opportunity - up on the peninsula because they are moving, she is moving her family and herself and the company, essentially, to Northern California, just mostly to be in the middle of where all the action is, and all kinds of talent pool.  So that's happening.



And, finally, they're going to do - and she hasn't figured out all the details yet.  But she's going to host a contest with a number of different categories focused around most innovative applications for the YubiKey.  And I have agreed to be a judge on the panel for coolest, neatest ideas for the YubiKey.  So that may also be something that our listeners would be interested in, cooking up an idea and entering that.  The contest doesn't exist yet.  I would imagine like a month from now.  And she's considering maybe announcing the winners at next year's RSA conference.  Where she will have a booth of her own this year.  As we all remember, she didn't last year.  I met her, or I bumped into her, at the top of the escalator when she was looking around for someone who would understand what they had done, so...



LEO:  Very cool.  Well, that's nice to hear.  She seems like a very nice person.



STEVE:  Yeah, and I just really wish them well.  I think it looks like they've got something good that is going to go.



LEO:  I might as well mention that we're looking for somebody to - nobody in a suit.  But we are looking for somebody who lives in the Petaluma area, the Northern California area, who can commute and come to our office, because we can't do this long-distance, to edit audio for us and work with us in audio and video editing.  And if you - you don't have to have any skills in that area.  If you're comfortable with computers, just email Dane.  It's jobs[at]twit[dot]tv.  



STEVE:  Now, what about Tony?  I thought he was the...



LEO:  Tony's full-time.  We're going - so Tony's going to move more toward the video side because we want to start putting out video.  And that's a full-time job, believe it or not, to get video out the door.  So Tony will go more to the video side.  And then we'll have somebody doing audio, as well.  So, yeah, we have to expand a little bit.  It's expensive to do all this stuff.  But, you know, we've got to jump while the iron's hot.  Advertisers are asking us for more products.  So we'll give it to them.



STEVE:  And will this mean more shows?  Will you be doing...



LEO:  I can't do more shows.  No.



STEVE:  Your schedule is already full; right?



LEO:  It's already full.  We're going to do more video.  We're doing a lot of video.  For instance, we're going to do interviews with Will Wright coming up, Neal Stephenson coming up.  I have some very interesting interviews, all that we kind of do ad hoc in the studio with people who show up, like from "Red Dwarf," Bob Llewellyn played Kryten in 

"Red Dwarf," he was great.  So we want to start putting these out because, if you don't see them live, chances are you're not going to see it at all.  So we want to put them  out as something you could download.  And the only thing holding us back at this point, we've got a bandwidth commitment from the CacheFly folks, which is wonderful.  We've got advertiser commitments.  But we need an editor so we can put - because, you know, it's hard to put - as you know, video is a little bit more complicated than audio.



STEVE:  Yup, yup.  Well, that's cool.  And there's someone who participates over in the newsgroups, at GRC's newsgroups, who captures the stream weekly.  And in several instances there have been people who have really wanted to watch the stream.



LEO:  I did not think this would be a video show.  But seeing you somehow makes it easier to understand what you're saying.



STEVE:  It's my creative work with my hands.



LEO:  It's the hands.  So while we always offer the audio, and that really is our primary medium, for those who want to see, say, things like Steve, because we do have video of you thanks to Skype, we'd like to offer that, as well.  Just as an alternative way to download it.



STEVE:  Cool.  Well, in my last little blurb before we plow into our questions, a listener - Ki Il Song, I think, is how I would pronounce his name - his subject was "SpinRite Does It Again."  And he says, "I'm writing this while listening to the latest episode of Security Now! on my Mac.  I'm a loyal listener of Security Now! and most of the TWiT network of netcasts.  They're entertaining, informative, and infinitely more enjoyable to listen to on my commute to and from work.



LEO:  There you go.



STEVE:  I don't know if this is a good thing, but there are many nights that I fall asleep listening to one of the many TWiT netcasts.  Keep it up, Leo and gang."  So he says, "The reason I'm writing this email is because of my recent experience with SpinRite.  My 75-year-old uncle became a widower approximately four to five years ago.  For almost a year after my aunt passed away, he was lost and depressed after losing his wife of almost 50 years.  One day, one of his closest friends told him that he needed to get over it and move on with life.  He proceeded to give him a laptop, an Internet connection, email, and a digital camera."



LEO:  I think that's a great idea.



STEVE:  It was really neat.  And he says, "Can you believe it?  A 70-plus year old learning how to use a computer, digital camera, and email.  He became so obsessed with his camera/computer/email that he would never go anywhere without the camera.  He would take pictures of everything from flowers, landscapes" - and I love this one - "and pictures of old pictures and events that he attended, and then emailed these to his friends all over the world.  He also became the resident photographer for our family.  He had over 50 gigs of photos and videos that he had taken over the past several years."  Well, you know where this is going.



LEO:  Yup.



STEVE:  He says, "Last week my uncle called me and told me that his laptop was broken.  It wouldn't boot up.  I went over to his house and saw that the Windows boot screen was in an infinite loop.  I tried to see if I could go into safe mode to fix the problem from there, but it wouldn't even get into safe mode.  It had the same result as normal mode - infinite loop at boot screen.  I told him I would take his laptop home and see if I could fix it.  So I took it home, booted into SpinRite, and ran it for several hours.  It came up with several errors the first round.  Excited, I booted into Windows and, voila, it worked."



LEO:  It's kind of fun, but it's true, you are happy to see errors when you run SpinRite because that might explain why you're having problems.



STEVE:  Exactly, it's fixing things.  And he says, "For a safe measure, I ran SpinRite again to see if it would find any more errors.  It found no errors the second and third times.  At that point I called my uncle and told him that his computer was fixed and his library of photos and videos from the past several years were saved.  Thanks, Steve."



LEO:  Yay.  That's a nice story.  I liked it.  I like hearing that.  Steve, I have in my hand 12 fabulous questions, written by...



STEVE:  Little do you know.  We actually have really good stuff this week.  I'm really pleased with these.



LEO:  Better than usual?



STEVE:  Well, there are sort of some themes.  There's a strong Wells Fargo theme.  There were a lot of people who wrote in about various pros and cons of Wells Fargo.



LEO:  Yeah, some people, I have to point out, some people did say that they thought it was okay.  But we'll get to that.



STEVE:  And in fact one of those that you forwarded to me is here also.



LEO:  Good.



STEVE:  And, yeah, it's just some great, really good stuff.



LEO:  Let's start with Vic Thompson.  He's in Newcastle, Australia.  He says he heard our tip just in time:  Steve, I'm a retired, as in unpaid, medium-level geek and an avid listener to the "netcast."  He says "I say that for Leo."  A friend of mind was about to commit his PC to the deep after a major dismemberment of his OS by at that point an unknown event.  Even though he managed to get it back to working order, the Sword of Damocles remained hanging over his head, and he still was going to load the PC into his boat, although without concrete overshoes.  Then I caught up with the latest Security Now! episode, and all was explained by your mention of the Trend Micro problem.  That's what bit him.



STEVE:  Yup.



LEO:  Wow.  There's very little notification anywhere about this, so you were the only light on the hill for us.  I am not only a SpinRite owner, but also a SpinRite advocate to all who will listen, and even to those who will not.  Thanks for the great pod, oops, netcast.  Vic Thompson, Newcastle, Australia.



STEVE:  Vic was one of a number of people who mentioned that this, like, clicked in their heads.  The Trend Micro update, as you'll remember I mentioned last week, caused a bunch of problems for people because it false-positive identified Windows's own OS file as being, due to heuristic pattern matching, as being malicious.  And it sequestered them, and then Windows would no longer boot, even in safe mode.  And it caused a ton of problems for people.  So I did want to - I wanted just to reiterate that, to thank Vic for his note.



LEO:  What's the solution?



STEVE:  It's bad.  You need to use somebody else's computer to go to Trend and pursue a solution involving getting those files back out of jail somehow.  I didn't pursue it all because it didn't hurt me, and no one that I know or love.



LEO:  And presumably Trend has updated their viruses, their antivirus, to not do that anymore.



STEVE:  Yeah.  And in all fairness, actually this is the second time Trend has done this, but it also did happen with Symantec once a few years ago, that they did the same thing.  So, I mean, it's risky.  It must be that they're checking different language versions.  Because it's hard to imagine how they wouldn't be able to check their own Windows system to make sure that it didn't bring it to its knees.



LEO:  Well, yeah.  And this is why many antiviruses don't do the job they used to do, because, well, any antivirus should be hesitant to quarantine Windows system files; right?  I mean, you're killing the baby to save the patient.  And...



STEVE:  Although the problem is, due to the fact that viruses name, malware deliberately names files with overlapping names, it might put in - so it might very well put a malicious code under a different directory with the name of a valid Windows file.  So you can't use...



LEO:  Or attach itself to an existing Windows file.



STEVE:  Sure, exactly.



LEO:  So this is - but this is what I'm saying.  Most antiviruses now will just say, hey, it's a Windows file, I'm not going to touch it, but you've got a problem here.  You've got to figure it out.  But, see, Trend just said, nah, I don't care.  I'm doing to kill the patient.



STEVE:  Because automatic is just so wonderful.  We don't want to have to train our users or have them take any responsibility.



LEO:  Opher.  Hello, Opher.  Our old friend Opher writes to the Daily Giz Wiz frequently.



STEVE:  Oh, no kidding.



LEO:  Yeah.  Opher Banarie in Laguna Niguel...



STEVE:  Oh, right.



LEO:  Pardon me?



STEVE:  I was going to say, he's the guy who also wrote to you, trying to get the note to me.



LEO:  He wrote to me first.  He says he's got some good news about Wells:  First, when I log on and put extra characters at the end of my password, it's rejected.  This is contrary to what your listener said last week.  Secondly, as reported by others, it is true that neither username or password is case sensitive.  But no one has mentioned that, after failing three times to log in, the session is terminated, and the userID is locked out.  That happens to me in a lot of sites.  It drives me crazy.  Because it often takes me four tries.  I'm speaking for myself, Leo, now.  It often takes me four tries to get the password right.  In order to regain access, you need to provide the ATM card number and PIN and answer a security question.  Then you need to assign a new password.  As a result of this stringent lockout policy, while the lack of case-sensitive username and password is an issue, I think the site's plenty secure, says Opher.  If Steve wants to discuss Wells Fargo any further, please ask him to include that lockout feature and any security problems it may expose.  I am not an employee of Wells Fargo, just a happy and, I believe, secure customer.



STEVE:  Well, this is really good news because a lockout policy is super important.  And as Opher believes, and he's certainly correct, it shuts down any attempt at doing password guessing, where you're just...



LEO:  You can't do a brute force if you only get three chances.



STEVE:  Right.  I mean, just not feasibly.  Now, somebody else write, and I didn't have space to include it in today's Q&A, but he had been experimenting with Wells.  And apparently it's the first 14 characters of - I don't know if - I'm not sure if it's username or password and/or password.  But at least password, the first 14 characters are significant.  And after that 14, any additional characters are ignored.  So it is still the case that extra characters are ignored, but not until you've got 14 that are not ignored, which we know is a long and fundamentally secure password, yes.



LEO:  That's pretty good.



STEVE:  Or at least potentially secure password.  But I did, you know, with all of the bashing we've been giving Wells over the last few weeks, the fact that they do a three-strikes-and-you're-out lockout and then require the user to go through much greater hoops in order to prove that they're really themselves or, well, maybe, Leo, it is the case that that really does mitigate the problem a lot.



LEO:  Yeah.  Almost all my financial institutions do that.  They'll lock you out if you keep guessing.  I know that because I almost always have to guess.  What I hate is one of them makes me call them.  Two of them do what Wells does, which is, okay, well, we're going to have to go through some more hoops for you to reset your password.  I don't mind that, if I could stay online.  But when I have to call them, that's just a pain.  And then, you know, I've been using BofA, and when I turned on - I have quite a few BofA accounts, Bank of America accounts.  I hope...



STEVE:  It'll be Bank of the World.



LEO:  Yeah, they own everything now.  What's nice is I've set it up, it's not a requirement, but they encourage you to set it up so that each time you log in, it sends a passcode to your cell phone, very much like the football, a one-time log-in passcode, to guarantee that it's really me.  That makes me feel so much better when it does that.



STEVE:  Yeah, in fact we've talked about using a cell phone loop to provide an additional factor in multifactor authentication.  I think that it makes tons of sense.



LEO:  Yeah, I turned it on in all my accounts.  It drives our bookkeeper crazy because she has to call me...



STEVE:  Well, it actually works both ways, too, because if your phone starts ringing with authentications, and it's not you, then you also have affirmative knowledge that somebody is trying to log into your account.



LEO:  That's a very, very good point, yeah.  No, I think every high-security application should use some form of, what do you call it, two-layer authentication.



STEVE:  Yeah, multifactor authentication.



LEO:  Yeah, I just think it just really makes a huge - it's just - of course I only know that because I do this show with you.  I don't know if everybody knows that.  Just makes me feel better.  Jon Kuhn in - go ahead.



STEVE:  Well, and that is directly what Yubico and the YubiKey are doing, too, because if that system were widely deployed, as hopefully at some point it may be, you could just stick it into a USB port and touch the little button, and it would shoot out some characters that absolutely prove it's your YubiKey.



LEO:  I like that.  Then somebody would have to get me, my YubiKey, my log-in, and my password.  Ha ha.



STEVE:  Yeah, good luck.



LEO:  Good luck.  Jon Kuhn in Ann Arbor, Michigan has discovered that Wells Fargo is in bad company.  Oh, boy.  After hearing about Wells Fargo on the Security Now! podcast, I decided to try out all of my GRC Perfect Password-derived passwords, all of them alphanumeric with upper and lower case.  I found that Chase, Citibank, Vanguard, and my credit union all have non-case-sensitive passwords.  Just thought you might find that interesting.



STEVE:  So Wells Fargo is sharing the doghouse with these other people.  But given that they've got lockout provisions, and I imagine that our listeners may now be curious to poke at their - deliberately log in incorrectly and see what it takes, verify in fact that anyone trying to guess their passwords will be shut down very quickly and then have to go through the extra reauthenticating hoop-jumping in order to get their account reactivated.  Which, again, it certainly does mitigate the problem of passwords being non-case sensitive.



LEO:  There's got to be a reason they're doing this.  Is it possible that some older computers or older...



STEVE:  Matter of fact, if you keep reading, we will come to the reason.



LEO:  Ah.  I like it.  I like it.  Steve is always way ahead of me.  Brent McLaren in Ajax, which is near Toronto in Ontario, Canada, brings up a very good point.  It's a point about case-insensitive banking passwords.



STEVE:  Speak of the devil.



LEO:  He says:  Hi, Steve.  Been listening to Security Now! since Episode 1.  I really enjoy the show.  Me, too.  Even though I work in IT and spend my days working with security and networking technology, I've found your insight and ability to explain complex topics very valuable.  So I just wanted to pipe in on the topic of case insensitivity for Wells Fargo's online banking log-in.  I know that for my bank the password used for online banking is shared with telephone banking.  As a result the password has to be limited to alphanumeric passwords with no case sensitivity.  It's also limited to six characters.  I believe this is one of those tradeoffs between security and usability that is necessary.  Having separate passwords for the different channels would be beyond confusing to people.  That's a very good point.



STEVE:  Isn't that a good point?  I liked that because you could imagine trying to explain to somebody that you've got, you know, what a circumflex is or...



LEO:  I don't think there's a circumflex on my phone.  Yeah, you're right.



STEVE:  Or the pound sign.  What?  Well, it's that number sign, the thing, you know, I mean, so if passwords were really complex, it could be difficult for them to be used, the same password to be used, essentially repurposed through different venues with the same institution.  And so it's like, okay, that makes some sense.  You could imagine that trying to explain your password over the phone to somebody could be a problem, much more so than you typing in some strange concoction with shift keys and so forth on your keyboard.



LEO:  And I actually remember that I got started in online banking with Bank of America in 1984 or something with phone banking.  And so I think that probably it's the same system it's been all along.  In fact, and this is what made me ask the question earlier, I remember it was almost a TTY the first time I started doing online banking.  A black screen would come up with white letters on it, all uppercase.  The menu structure would be, you know, type "1" for this item, type "2."  I mean, it was very primitive.  And I bet you it's the same back end.



STEVE:  It may very well be that they just stuck a web server on the front of it.



LEO:  Yeah.  It's looking better than it used to, I have to say.  But for a long time online banking, for me, was that.  It was like a TTY.  David Townsend in Wimbledon, U.K., worries about his employer:  Hi, Steve.  I live in the U.K., work for a large blue-chip computer consultancy.  We have a timesheet and expense system that is used globally by the company over the Internet, feeds directly into our central billing system.  The site, not SSL.  And to make matters worse, there's no password expiration, no lockouts after X attempts, and the passwords are not case sensitive.  I've written to my company formally two times, but my concerns have fallen on deaf ears.  The company believes that, because it has not been hacked yet, they are completely safe with HTTP, and my concerns are just scaremongering.  I feel ashamed to actually be working for this company with such a lax attitude to security, especially since the company is involved with IT development.  Do you think my concerns are real threats here?  What are the risks the company's exposing themselves to?  Could the HTTP traffic be sniffed?  Are there other concerns they'd need to be aware of?  I'm hoping, if you answer this, that I'll have some real evidence to go back to the company with and get this changed before we are attacked.



STEVE:  Well, our listeners, any listeners who've been listening for 162, or 161 previous weeks, know a lot about this.  And of course David, who is a listener, knows...



LEO:  He knows.



STEVE:  ...that he has absolute cause for being concerned.  And clearly he does.  The question I think is, in order to sufficiently understand the threat model of the system, we have to know how is the system really being used.  That is, if you assume that somebody unauthorized is going to have access to this, what is the consequence of that?  He's saying that it's their timesheet and expense system that's directly tied into central billing.  So the question would be, if somebody maliciously had access to this, what does it mean?  The response he seems to be getting from the company's IT people are that there's not a problem.  To quote him, he says they are completely safe because they've never been hacked.  Well, the world is full of people who are, well, they're not safe because they've never been hacked, but they have a false sense of security because they have never been hacked.  And it takes a company losing millions of employee confidential information or credit card information that's sold on the Internet or one of these horrific events to realize that its reputation has been damaged, and to say ouch.



He actually, in his letter, provided me some additional information that he asked me to keep confidential about the system that they're using.  I did some research, and it's a third-party tool, not the company's own tool, which apparently provides this level of insecurity.  So it's not just this one company that's using this.  This is a tool that is globally used widely.  And so all the companies that are using this particular Internet-based timesheet and expense system are exposed.  Which to me, given the fact that the security at the log-in - this is a freely available public server.



I went to this website and looked at the front end.  It was from there that I figured out what the package was that was running behind it.  And I then went to that company and explored them a little bit to see who this was and how pervasive this was.  So, and it's a well-known, successful company that has incredibly insecure log-in policies.  I mean, it's irresponsible.  Like I would say first of all the company that David works for has got their head buried in the sand.  But more importantly, this is a commercial product being offered by a  company, certainly at some expense to their clients, that has zero log-in security.  So it's definitely a bad idea.



LEO:  You know, the temptation, I think, for employees like David is to prove it by logging in insecurely and demonstrating how easy it is to hack.  And I've got to warn people about that.



STEVE:  I was just going to say.



LEO:  This happened again, that a guy who got so frustrated with his company's security policies that he hacked in and got some password information and then sent it to the president and said, look, I've been telling you about this.  Look, see what I got?  And of course he's going - he went to jail.  In fact, our good friend Randal Schwartz did the same thing at Intel some years ago and was arrested and tried for hacking.  Companies don't take well to having their nose rubbed in it, let's say.  So be careful about how far you go to prove the point.



STEVE:  So just to answer his question, that site, and the same log-in page for everyone else using this company's timesheet and expense system software - and, you know, I don't have it in front of me.  I ought to tell everyone the name of that company because they deserve to be in the doghouse.  Although I guess that would expose anyone who had access to them to - we'd be making it obvious that these people are really attackable.  So it would be better to send them a private email and say, look, this is just not okay.  They are exposing all of their clients.  The fact that this does not require SSL definitely means that this can be sniffed.  If in any situation there was wireless, then anyone with a wireless system could be logging all the traffic, seeing people log into this timesheet and expense system, capture their log-in, and then do, I mean, the only thing we don't know is what level of mischief someone could get themselves up to.



So in summary, this is the question I would ask David to pose to his company's management.  And that is to say, it's very much like the analogy I draw with WiFi.  When I try to explain why wireless is so dangerous, I say, okay, plug a wire into your wired hub and run it out the front door to the lawn, and then stick a stake in the lawn with a sign that says "Free Internet Access." 



LEO:  That's good.



STEVE:  I mean, they're doing the same thing with wireless.  So do you want any random stranger, 24/7, to be able to plug into your hub in your home and see what's going on?  So similarly, David ought to pose the question, okay, here's the worse case.  Is there anyone that you would really be unhappy giving free and unfettered access to the timesheet and expense system?  I mean anyone.  Because essentially, depending upon the exposure that people logging into the system have - and he says this is used globally by the company over the Internet, which means random people of this large blue-chip computer consultancy are sitting in Starbucks and random WiFi hotspots, logging into the timesheet and expense system.  There's no question then that that log-in is sniffable and open and is compromisable.  So this company needs to ask itself, what damage could somebody do who has access to the system, because that's what they're making possible.



LEO:  Yeah, wow.  Very scary.  Moving on to our next call here.  Or it's not a call, it's a question from Anonymous - he says I don't want this to be public, but I like to use the PPP, Perfect Paper Password system.  But I'd like to generate passwords that follow certain rules.  For instance, I want to say must be mixed case, must contain at least one digit.  Is that possible with the web application or with the EXE application?  That's sometimes a requirement of some systems.  I run into that all the time where it says, well, I like your password, but you've got to put a digit in it.



STEVE:  Well, I loved the question.  The reason I made it anonymous, I actually know who this is.  But he sent it to GRC, to Greg, our tech support guy, which Greg forwarded to me.  So he didn't intend me - I don't know that he intended me to make this public and to read it.  But I wrote him a lengthy reply because I thought it was sort of an interesting question for our listeners, from a theoretical security standpoint.  So here we've got the Perfect Paper Password system.  Now, as it was designed, that's a one-time-only system.  So the individual tokens are short.  And certainly they're not correct, they're not appropriate for long-term static password use.  But in the final evolution, I think it was the third major revamp of the Perfect Paper Password system, which we remember was Even More Perfect Paper Passwords, we allowed them to be any length.  So you absolutely can use both the online, web-based version or the EXE, with the appropriate command line options, to make really good, really random, really long passwords.  You can make them as long as you want, basically use it as a random password-generating - or string generator.



So then the idea of saying, oh, but they have to - what if they have to have mixed case?  Then can that be enforced?  Or what if they have to have some digits?  And, okay, well, frankly, that lowers the security.  I mean, it actually does.  And that's the point.  That's the reason I wanted to add this to this week's Q&A, is the reason that those sorts of requirements, like mixed case, must have several uppercase characters or lowercase characters, must contain at least one digit, those are enforced on passwords generated by people because people don't generate high-quality random passwords.  They use all lowercase because it's easier for them, deliberately, or they won't use any digits so their passwords tend to be in dictionaries or would be prone to brute-force attack; whereas salting them with a couple digits, forcing some digits in, breaks brute force attack possibility.



But taking a system which is generating highly random, I mean, really, really, really high-quality random passwords, and then imposing on it some such rules, reduces the strength because an attacker who knew which rules were being imposed would then reject passwords that broke those rules.  And essentially you are, by imposing those rules against a system which is already generating really high-quality passwords, ends up lowering the security of the system because you're discarding a large subset of passwords, forcing a smaller rule set on them.



So I just thought - that's essentially what I told the person who wrote.  And he actually replied, and he says, I understand what you said, thank you for the explanation, but I wanted to use these in systems that enforce those rules.  And it's like, well, okay.  So put something, manually change the case.  And if it happens you get a long password without a digit in it, then put some in.  You can, with the Perfect Paper Password system, you're also able to specify the alphabet.  So you could specify an alphabet with upper and lowercase alpha.  And also, if you wanted to make sure you had numbers, you could put in 0-9, 0-9, 0-9, that is, if you specified those three times you'll get - then digits are three times more likely to occur than they otherwise would.  And essentially what that means is that you'll tend to have, in a sufficiently long password, it'll be extremely rare that you get one that doesn't have digits in it.  On the other hand, the Perfect Paper Password system also generates them endlessly.  So you could just cross out the ones that don't obey the rules that you need and keep the ones that do.  Which is probably the right solution.



LEO:  Very good.  Let's see here.  Carl Schweitzer in Hilbert, Wisconsin says, why is it all just 0s and 1s?  Why aren't there any 2s in there?  Dear Steve and Leo, this is a topic that's been brewing in my head for some time, and I'd like for you to help answer some nagging questions for me.  It all started many episodes ago, when the two of you were talking about the ability for someone to scan the residual information on a hard drive and detect the original bits that were overwritten by new data.  Regarding this first part, I was wondering what type of equipment would you have to use to detect the residual magnetic field on a hard drive?  Specifically, is it small enough to be contained in a standard hard drive case?



Outside of this thought process, I've been trying to adapt a bug into a feature.  Well, if the answer to the first question allows it to be possible, could you manufacture a hard drive to write over data and still detect it, essentially doubling the capacity of a drive?  Also, if current hard drive heads can detect these fields effectively enough, could some smart programmer create new drivers to double the capacity of existing drives?  Thanks a lot for the great show.  It really gets one thinking.



So let me explain what Carl is saying.  Since you can theoretically read erased data, why don't we just record double the data on a hard drive and use that technique to read both?



STEVE:  Well...



LEO:  Can you use baby words?



STEVE:  It's not as crazy as it sounds.



LEO:  Really?



STEVE:  Well, there are, and we mentioned this before, there are multilevel flash RAM storage.  There are, because flash storage is trying to grow in density, one of the tricks that's being used in flash storage is to store analog values in the individual cells so that, rather than just having an individual bit cell be either fully discharged or fully charged, they're deliberately storing multiple levels of charge in the cell and essentially storing more than one bit per bit in the cell.  Now, it works there because the tolerances are sufficient that you are reliably able to determine what the charge is in the cell, essentially by dumping the charge out of the cell.  You transfer the charge out of the cell.  In the process of doing so you're able to see how much charge there was.  And with sufficient resolution you're able to create a multilevel charge per bit cell in nonvolatile memory.



The problem with hard drives are many.  Mostly this is an extremely unreliable process, more than anything else.  It's more than theoretically possible to determine what data was on the drive before.  But it is far from reliable enough that you could count on that happening.  The only way that that would be feasible would be if you really cranked up the error correction technology such that large chunks of areas and individual bits that couldn't be determined could be corrected across.



The problem with doing that is that error correct technology essentially works by correcting bursts of errors, that is, groups of bits that you cannot determine, because that tends to be the way errors occur.  There's a physical defect on the hard drive.  That physical defect is larger than many bits.  So many bits are swallowed by that.  Therefore you need an error correction system that's able to straddle across the entire dead zone created by the physical defect on the drive.



LEO:  I think your physical defects just - my microphone just fell over.  Sorry about that.  Clonk.



STEVE:  So the nature of trying to recover individual bits from underneath, essentially that have been deliberately overwritten by super strong bits, is that you would scatter your inability to recover across the drive.  Error correction, burst-style error correction wouldn't be feasible.  And you end up with so much overhead trying to correct that, that it's better just not to try.  So bottom line is, I mean, you could theoretically do it.



One of the other problems would be the technology would radically slow down your storage.  You'd read off the most recently recorded data.  Then you'd have to switch into a mode where you're struggling really hard over a great period of time to subtract that massively strong signal from the signal you're reading in order to ascertain what was there before.  I mean, it's just - it's not practical or feasible for any number of reasons.  It makes sense in the narrow case of forensic analysis where some agency on a governmental scale desperately needs to know what was underneath the most recently written data.  But it's just not practical on a daily basis.  Besides, just wait a week, and the drives will double in size all by themselves.



LEO:  Well, they are doing tricks that involve kind of layers and so forth.  So it's not so crazy as all that, really.



STEVE:  Yeah.



LEO:  Yeah.  Carl Schweitzer - oh, no, that was him.  Blake in Minnesota wants to get a better handle on Windows security:  Hey, Steve and Leo.  I was just listening to a Security Now! episode from a couple of weeks ago.  And I wanted to inquire further about what you said about Vista/XP security.  That was last week.  You mentioned other OSes being more secure than Windows.  In fact, it seems to be conventional wisdom and seemingly a "fact," according to most people.  I seem to think that while Windows sees by far the most action concerning security vulnerabilities, it is also under the most frequent attack by far.  Actually I disagree, but I'll explain why in a second.  Just thought I would ask to know what you thought about this, seeing as security to me means more than just how many vulnerabilities are found per week when comparing two software products.  I think the ratio of bad guys attacking Windows is so large compared to other OSes, comparing the security of them is much more complex than most think.  Am I way off base on this one?  Sorry this got a little long.  Thanks for all you guys do.  Signed Blake.



STEVE:  So what do you think, Leo?



LEO:  Well, I have to say that what you're overlooking is,  yes, of course there are far more Windows, what is it, almost a billion installations of Windows out there.  But don't you think web servers get attacked an awful lot, too?  And they're running Linux.  I mean, they're the ones, they're actually the ones in many cases, Linux or BSD or some other UNIX form, they're the kind of presenting face of a lot of computers to the outside world.  Many Windows machines, most Windows machines are probably sitting behind routers.  So if you want just the face of attack, I think a lot of it is going against UNIX variants.  Do you agree?



STEVE:  Yeah, although in that particular instance it's not the OS itself that's being attacked, not the core OS.  Typically it's an insecure...



LEO:  Server, yeah.



STEVE:  Well, it's an insecure application like PHP.  And so it's code.  It's like it's higher level code running on a web-exposed surface of the server.  One of the problems, I think, that Windows has is that it's never staying the same.  That is, it's inherently evolving.  Microsoft is continuing to mess with it and add new features and services.  Now we have the whole new .NET thing, a whole new API that was added after we already had an existing Windows API because they said, oh, no, we're going to make it better in a whole number of new ways.  Well, they still have the old API.  They still have support for the 16-bit API and for DOS.  And now we have .NET, and who knows what's going to come next.  I mean, now we're looking at an increase of Java applications and JavaScript being run by clients on Windows, like the example we talked about with Chrome last week, Leo, where you're running Google Mail in a Chrome application window.  So I wanted to bring this question up because it is something that comes up a lot.  And the question is, what's more secure?  I would argue that the thing that is targeted least is probably more secure effectively.



LEO:  Effectively, right.



STEVE:  Yes, effectively.  Now, I mean, one of the benefits of Windows is that it's being pounded on all the time.  Problems are being found all the time, and they're being fixed all the time.  The problem is, though, then, that it's constantly changing.  Microsoft is also introducing new problems all the time.



LEO:  Every patch has the potential to introduce a flaw.



STEVE:  Well, and Leo, look, just try running Windows Update.  You have to reboot and run Windows Update when you install XP because the security patches have security patches.  And then once you get them patched, they've got patches.  So, I mean, it just proves the fact that Microsoft's updates are buggy and are introducing new problems that then need to be fixed.  So, I don't know, I mean...



LEO:  I think it's often said that FreeBSD is the most secure, only because it was designed to be secure from the ground up.  Windows...



STEVE:  Do you mean FreeBSD or OpenBSD or Net...



LEO:  Oh, now I'm confused.  There's Free, Open, and Net, and I can't remember which one is the considered...



STEVE:  Open is generally...



LEO:  Is it Open?



STEVE:  Yeah, I think Open is generally considered to be massively secure.



LEO:  Written intentionally to be secure.



STEVE:  Yes.



LEO:  So I think when you - see, Windows was not because security wasn't an issue when - let's say we're running on the NT code base.  We're not running Windows 98, obviously.  But even when NT was designed it wasn't really the issue.



STEVE:  Well, and frankly, there was security, I mean, NT was designed with security in mind from the beginning.  And the original architecture of NT was much more secure than what Microsoft has devolved it into.



LEO:  That's right.



STEVE:  Remember that NT had a strong client-server model.  There was the kernel, and then there were the user EXEs, remember that User32 DLL kernel and GDI were all operating in user space.  But that wasn't high enough performance.  Microsoft wanted more performance.  Well, there was, I mean, deliberately not high enough performance in the beginning because the original architects wanted to separate the kernel from applications running in user space.  Microsoft said, oh, look, if we just move GDI down into the kernel, we'll have many fewer kernel/user space transitions, and we'll get a performance boost because, you know, we want the system to be snappy.



Well, what did we hear last week?  GDI+ that was added to XP was a source of a huge number of vulnerabilities.  And those vulnerabilities were much more serious after Microsoft moved that code into the kernel than they would have been had it stayed outside.  So you could argue that Microsoft is, in this case, is their own worse enemy.  Whereas decisions are being made, for example in the case of OpenBSD UNIX, I mean, where security is first, they're doing nothing to lessen it, Microsoft just can't help themselves because they keep believing that the next thing they do is going to be secure even though nothing they've done so far ever has been.



LEO:  Well, they also live in a different world.  They have to work with businesses.  They have to, you know, it's a different environment.  I'm looking at the OpenBSD site.  It says only two remote holes in the default install in more than 10 years.  I'd have to say that's a pretty good record.



STEVE:  That's phenomenal.



LEO:  Yeah.  So I guess we'll give them props for that.  But it's a different environment.  You can, you know, you're not customer driven.  You're security driven.  So you only do those things that make sense from a security point of view, and customers be damned because...



STEVE:  Well, but there's also - I've always given Microsoft the benefit of the doubt when it comes to bugs.  Anyone can have bugs.



LEO:  Yes, of course, yes, yes.



STEVE:  I mean, we wish there were fewer of them.  My big complaint with Microsoft is over policy.  Because, for example, for so many years it was their policy to run services by default.  And even today I'll install XP in a system that has never seen a wireless card, has no WiFi at all, yet wireless zero configuration service is running by default.  Why?



LEO:  Yeah, yeah.  No reason for that, yeah.



STEVE:  I mean, it's nuts.  And similarly, remember we were talking about kill bits.  I've been thinking about this some more.  This notion that VMware in their update last week flipped the kill bits, that is, enabled the kill bits of their ActiveX controls, that was such a great policy from a security standpoint.  All ActiveX controls ought to be marked as not executable by IE unless they are explicitly known to be IE required, rather than the other way around.  As it is now, it's called a "kill bit" rather than a "live bit."  It ought to be the "live bit" instead of the "kill bit," and it ought to be off normally and only turned on if you know that this is something that Internet Explorer could be expected to use.  Instead, we've given IE access to all the ActiveX controls in Windows.  I mean, that's just dumb.  I mean, that's clearly, on its face, that's, like, wrong.  But that's not the way Microsoft thinks.



LEO:  Right.  But I'll defend them because they have a different imperative.  And their imperative is much more complex.  They don't want to piss people off.  They've got to make the vendors happy, the independent software vendors happy.  They've got to make business happy.  And that's...



STEVE:  Yeah, hence we end up with things like UAC that bug people to death so much that they just - they abandon Vista, go back to XP.



LEO:  They turn it off, yeah.  But it's a difficult situation.  I mean, I think that they have a very difficult issue that they have to face.  And it's, you know, it's nontrivial, their issues.



STEVE:  Well, and complexity is the enemy of security, as we've often said.  And once upon a time DOS was three files.  Now no one knows how many files.



LEO:  That's a lot.  Thomas Paulsen in Nordland, Norway shares his clever security and usage restriction solution involving OpenDNS:  Hi, Steve.  I'm a proud owner of SpinRite, longtime listener of Security Now!.  My Top 10 list of favorite netcasts consists of all Leo's publications - thank you, Thomas - with Security Now! in a definite No. 1 position.  My jaw dropped to the floor as you detailed the recent DNS spoofing attacks.  I was amazed at the creative solution to adding entropy to DNS requests by using capital letters.  Well, mixed case; right?  The jaw again dropped as I heard the SEAL team get out of a real tight spot using SpinRite.  The show you produce is, in my humble opinion, entertainment at its finest.  Thank you.  Thank you, Thomas.  So here's his OpenDNS story:



I work as a senior consultant in IT, and one of my clients is a private high school.  They run a network for their students on a separate ADSL line, and they're using a Cisco Pix 501 for security.  We've got to get them moved to Astaro since the Pix is being phased out.



STEVE:  Yup.  I thought the same thing when I read that.



LEO:  The network is all wireless, with somewhere around 10 Linksys APs - access points - providing network access on campus.  They have a policy for students that only "normal" Internet access is permitted.  But budget restraints and lack of IT knowledge has kept them from enforcing the policy.  Students take advantage of this, of course, and use the network for heavy downloading and peer-to-peer filesharing, rendering the network mostly unusable for the rest of the student body wanting to surf the web or download email.  Aware of services like Websense, which the Cisco unit supports, they've been unable to afford any subscription services - oh, we've got to get them Astaro - and their limited knowledge of the firewall has kept them from blocking traffic selectively.  Anyway, many peer-to-peer clients use the HTTP port or dynamic ports, so blocking them on the protocol level would be an exercise in futility.  Or they use encryption now and all sorts of stuff.



So as I was driving down to see them I was listening to Security Now!, and OpenDNS was mentioned.  I had, of course, heard about it previously and was using it on my home network.  I then started wondering, hey, maybe OpenDNS would be usable for what my client needed.  I got so excited I had to stop my car and jot down a quick plan.  As I later tried to explain this to my client, I got that glazed look you often get when the level you're explaining something is 10 notches higher than the recipient is able to process.  So I assured him this would save them some serious bandwidth, and I got the go for setting things up.



I created an account with OpenDNS for the high school and set up the official static IP address of the school as the network in the OpenDNS dashboard.  This is, by the way, a really nice feature of OpenDNS they introduced not too long ago that lets you configure your machines by IP address.  I then configured some other options, blocking categories of sites like peer-to-peer, anonymous proxies, a few others.  I then went to work on the firewall and configured it with just three simple access rules:  1.  Allow UDP port 53 to only the OpenDNS DNS servers.  Is 53 DNS?



STEVE:  Yup.



LEO:  Okay.  So in other words you couldn't use another DNS server.



STEVE:  Right.



LEO:  Allow http, https, smtp, pop3, imap, ftp, ftpdata to any network.  Otherwise, drop all other packets.  By the way, that is pretty much the way I would configure any router; you know?  This setup would make sure that the only DNS servers allowed were the OpenDNS, should some students try to mess with the IP configuration of his or her computer, which they would inevitably.



STEVE:  Of course.



LEO:  Yeah, first thing I'd try.  Also, the only port protocols that would be usable were the approved major Internet ports.  The results were immediate and dramatic.  The hit count on blocked networks was ticking away feverishly, and bandwidth usage came down dramatically.  Oh, those students must have been really miffed.  Oh, man.  The stats that OpenDNS give you are an additional boon.  This is really a nice feature, by the way.  And this is all free, which I love.  You can quickly see if there are false positives among the domains being blocked and tune them accordingly.  I realize this isn't a foolproof situation, but it really gives the high school a great layer of control over the students' Internet usage, all for the great price of free.  Again, thanks for a great netcast.  And thanks for a great solution.  That is really awesome.  I think that's a very clever solution.



STEVE:  Well, I wanted to share this with our listeners because I could just imagine how many other listeners might have applications for this sort of solution.  The configuration of the firewall is very simple.  You allow UDP port 53 only to the OpenDNS servers.



LEO:  The only place it can go.



STEVE:  So as you mentioned, Leo, what that prevents is it prevents any students from configuring a different, explicitly configuring a different DNS server for their machines.  So what that means, of course, is that they have to use OpenDNS.  Then by using the DNS dashboard, which is configured based on the source IP of incoming requests, that is, he configured the dashboard to the school's public IP address, so that tells OpenDNS who is asking, which allows OpenDNS to apply restriction rules on which types of sites by major classification, like peer-to-peer, transparent proxies and so forth, which ones it will respond to.  So suddenly many of the games that the students were playing are shut down completely.  We know, sure, you could use an explicit IP if you knew it.  But we've talked about the problems of doing that.  Because as soon as you go to a site that, even by IP, more often than not you're bounced around, and you're back into domain names.  And again, if it's something that OpenDNS won't be willing to look up for you, then there's nothing you can do.  And then finally he simply allowed just port 80 and 443 and 25 and 110 and...



LEO:  The obvious canonical report-through ports.



STEVE:  Yes, basically web, email, and FTP, to allow the students to surf the 'Net to sites that are fine, and to transfer files, and to do email.  So, and this is what the school's policy always was.  But of course the students weren't abiding by it because they're, you know, they're students.  That's what they're going to do.  So I thought this was - and as he said, it's simple to establish the firewall, the OpenDNS service that is part of the filtering solution works beautifully, and it's simple to configure and free.



LEO:  It's just really excellent.  I have to say I've been using this for some time.  I have a home configuration and an office configuration, which is by IP address.  You can totally control what you're doing, blocks domains and so forth.  I have to say this is - OpenDNS is providing a very valuable free service to users.  And you combine that, I mean, you need the firewall to make sure people are forced to use it.



STEVE:  Precisely.



LEO:  Yeah.  But I just think this is an excellent choice.  So good, yeah, thank you for sharing that with us.  That's very, very cool.  Let's move on to our next call here.  Ben Jaques in Des Moines, Iowa, wants to know what "fixed" means.  In the last Security Now! you said that Google had "fixed" the EULA, but what does this mean?  Repaired.  Could you please explain in the next Security Now!?  Thanks.



STEVE:  They had a broken EULA.



LEO:  A broken EULA.



STEVE:  Got their EULA fixed.



LEO:  Yeah, it does sound like an operation of some kind, doesn't it.



STEVE:  Your uvula.



LEO:  Yeah.  This is the Chrome - we were talking about the Chrome EULA, which - now, I haven't looked to see what they've changed.  But they immediately apologized.  They said, our bad, we used boilerplate language, and we will fix it.



STEVE:  In fact, one of the main Google guys who was blogging, I guess he was initially sort of snide, and I think sort of snotty in his first responses.  And he later apologized, which I thought was very nice.  And he said, I should have understood that we were really wrong, and I want to apologize for the nature of my initial reactions upon having people being upset with the way we were behaving.  You'll remember that when we first talked about it two weeks ago, when Chrome first appeared, their standard boilerplate EULA, the End User License Agreement, EULA, it stated that they owned the rights to anything you did with your browser.  Like, I mean, any data that you posted anywhere using the browser as the interface to Web 2.0-style sites.  And my reaction was, well, okay, so no one is ever going to use this browser.  I mean, it was ridiculous.  It was ludicrous.  And immediately they said, whoops.



And it may well have been an oversight, despite the fact that this browser has been in the works for two years.  They said, our bad, what we meant to say was that you retain the copyrights to anything you already had the rights to.  So you're giving us nothing that is yours.  Any copyrights you have, you retain.  And so it's like, oh.  Which is why last week we began to entertain the idea that maybe Chrome had a future.



LEO:  Huh.  Which that idea will quickly be - you will be disabused of in moments.



STEVE:  Oh, yes.



LEO:  Yeah, they just took that paragraph out.  It didn't say we assert copyright.  It just said you keep the copyright, but we get to do anything we want.  We get a non-exclusive license to reproduce, adapt, modify, translate, publish, publicly perform, publicly display, and distribute any content that you create with the browser.  But that, you know, I have to say in their defense, that's exactly the kind of boilerplate you see.  It was in, if you've ever - you've signed it a few times, the TechTV release form basically says that.  We reserve the right to use your likeness and anything you do on here in perpetuity, in all media ever conceived of in any time and any place in the future.



STEVE:  Wait, wait, wait.  Did I...



LEO:  You signed it.



STEVE:  I signed that?



LEO:  Several times.  Yeah.  It was kind of surprisingly broad.  And a couple of people said, whoa.  But that's pretty typical.  And all it's saying is, look, we're going to do an interview with you.  We want to be able to use this.  And we may, some day there may be some virtual cube presentation we'd like to do that we never heard of, so we'd like to be able to do that.   And by the way, they still retain those rights.  And G4 Comcast now has them.  I don't know what they're going to do with it.  But I don't, you know, none of us have any rights to anything we did on TechTV.



STEVE:  Right.



LEO:  That's pretty typical.  And I think that that just leaked in because they just - they were too lazy to write a new one.  Or maybe, as some people think, they thought they could sneak it by, and then...



STEVE:  No, I don't - I can't even imagine that.  It was so bad.  I mean, it said so clearly, we own everything you do.  It's like, uh, yeah.



LEO:  So it's fixed.  They took that paragraph out.  Corby in Reno, Nevada shares his different view of Google's Chrome browser.  "Browser" in quotes, I might add.  Hi, Steve.  Not for a second do I think Google is trying to compete in the browser market.  How could anyone compete with Mozilla?  Rather, Google is making a new platform to deliver their web-based apps.  I think that's basically what I've been saying.  I'm sure they're finding that the current browsers are too limited for what they want to do.  They don't need to be concerned about all the issues about Chrome that you  mentioned in your recent episode.  We'll have the Firefox browser running side by side with Chrome as a Google app machine.  It might look like a browser.  That's just a side effect.  Soon their apps will have APIs that only Chrome will know, and only Chrome will be able to run them.  I disagree with that.  I don't think they're going to do that.  That would be crazy.  And if we thought Microsoft once had a monopoly, just wait till Google controls the apps and the data.  Call me paranoid.  We've seen this cycle before.  But it's going to be coming at us faster and bigger than ever.  You think that's going to happen?



STEVE:  I don't think it's going to happen.  But, I mean, I wanted to share Corby's view.  I think the problem is that it is a browser rather than being a simple app machine.  And so it does need to offer the features that contemporary browsers have.



LEO:  Because people will use it that way.



STEVE:  Well, they will.  I mean, and they'll get bitten by its lack of security and privacy features unless they're very careful.  I mean, I think it's very clear that - and by the way, Chrome's share has continued to fall.



LEO:  Oh, interesting.



STEVE:  As people have uninstalled it.  And, well, for what good that does, and we'll cover that in the next question.  But it's unfortunate that, in my opinion, that it's not, as is, a highly useful browser.  You know, everything that they were doing in terms of the work they've done with the security model profiles it as wanting to be a mainstream web browser.  So, I mean, certainly there is a problem if their apps won't run in non-Chrome browsers.  I can see that Google wanted their own, wanted to own a platform that their future apps are going to run in.  I don't understand how it forces other browsers to follow if their apps run in the other browsers without any modification.  So, I mean, it is sort of a - it's a strange animal, in my opinion.



LEO:  Yeah.  I'm looking to see if it's changed, the browser usage has changed.  You say - you're seeing a drop-off,  huh?



STEVE:  Yup, I did see below 0.9.



LEO:  Let me - I have to select, let's see, just this week, let's try.



STEVE:  Oh, I see, your own TWiT browser usage.



LEO:  Yeah, because of course our audience is really sophisticated.  So I would imagine that they would be very quick to try it, but that it would drop off.  Yeah, it's now 7 percent.  Which is down a little bit, but that's still a fairly large percentage.  8,000 people still using it.  Firefox 56 percent, Internet Explorer 18 percent, Safari 13.9 percent, Chrome 7 percent.  So it's down a little bit.  But not, you know, oddly enough, not as much as it is globally.  So I think our audience, they like this stuff.  They like to use the latest greatest, don't they.



STEVE:  Yeah, just wait.



LEO:  Steverino, are you ready?  The "Bad Chrome-Osome," from Richard Chao of Fullerton, California.  Steve, when I installed Chrome, it apparently also installed some plug-ins into my Firefox 3.  What?



STEVE:  Uh-huh.



LEO:  Then, after I uninstalled Chrome, the plug-in and files remained in the Mozilla Firefox directory.  I was able to disable the plug-in, but when I went into the Mozilla Firefox program files in the C directory to remove the folder called Chrome, it broke my copy of Firefox.  This is not good.  Firefox was easy to remove and reinstall, but I'm worried about IE.  Have you heard anything about whether Chrome installs files in IE or not?



STEVE:  Yup.



LEO:  This is another reason to avoid Chrome.  I was never asked by Google if I wanted a Chrome plug-in, it just did it.  Wow.  This is the first I've heard of this.  What's the story, Steve?



STEVE:  It's bad.



LEO:  That's terrible.



STEVE:  I remember you - I was thinking how you chuckled when I told you I had just created a VMware container.



LEO:  Yeah, you were right.



STEVE:  Well, I'm glad.  Get this.  When you install Chrome, with no notification at all, it installs plug-ins for Firefox 3 and IE.  It instantiates a browser helper object, an ActiveX control for IE, an add-on under Plug-ins called Google Update.  It also runs a Google Update service in your system and deliberately leaves all of that in place after you remove it.



[LEO:  Hi, this is Leo.  I'm going to interrupt here because - this is somewhat after the show was recorded.  After the show was recorded, Steve did a little more research and was able to verify that Google Update does remove itself from the PC, not immediately, but some time after Chrome has been removed.  In fact, Google says this in their own Help documents at the Google site.  So he's going to test this more extensively.  But perhaps it's not as bad as it seems.  Also want to let you know that we found out, thanks to our chatroom, that the Chrome folder that our correspondent removed in fact isn't Google Chrome, but Firefox Chrome.  It's a critical part of the Firefox user interface.  So removing that Chrome folder from Firefox will, yeah, it'll disable Firefox because it is part of Firefox.  And even if you haven't installed Chrome, you'll have that folder.  In any event, I wanted to let you know that it may not be as bad as it seems.  But Steve is going to take this next week to do some research.  And we will get you the update on what Google is doing with Chrome, what Update is doing after it installs itself.  And frankly, I asked him to also maybe take a look at some other applications, like Apple Safari, that may in fact have exactly the same behavior.  All right.  We now return you to our show, which is already in progress.]



LEO:  Well, we're going to do more research on this and get back to you next week with more about exactly what this is doing.



STEVE:  Yes.



LEO:  All right.  Hey, thank you, Steve Gibson.  Fascinating stuff.  Go to GRC.com to find out more about what is going on in your world when it comes to security.  GRC.com, you've got the show notes there.  You've got the 16KB version of the show.  Of course you've also got all of Steve's cool stuff like ShieldsUP!, his many free security programs and utilities, too, like Wizmo.  And let's not forget, of course, the crown jewel in the operation, SpinRite, the world's finest disk maintenance and recovery utility.  It's all there at GRC.com.  And I want to take a look at what exactly is going on.  Apparently Google's Updater is installed by a lot of other Google applications, as well.  This is something that's kind of part of a Google package that you automatically get.  And again, this is, by the way, what Aureate said is, well, we can't uninstall Aureate.  It might be installed by other applications.



STEVE:  Yeah.



LEO:  So their Chrome probably says, well, we don't know if you've got Google Earth installed, or Google Toolbar; so we can't uninstall these updates because you might have other things.  I have to say, if you're using Google at this point, you might want to reassess your association with Google.  I certainly am.  Thank you, Steve.



STEVE:  Talk to you next week, my friend.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#163

DATE:		September 25, 2008

TITLE:		GoogleUpdate & DNS Security

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-163.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo wrap up the loose ends from last week's final Q&A question regarding the self-removal of the GoogleUpdate system following the removal of Google's Chrome web browser, then discuss the operation and politics of upgrading the Internet's entire DNS system to fully secure operation.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 163 for September 25, 2008:  DNS Security.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, a chance to talk about the world of security as it applies to technology.  Steve Gibson is here.  He's the guy at GRC.com, Gibson Research Corporation.  They do...



STEVE GIBSON:  It's really not our listeners' chance to talk about it.  It's...



LEO:  It's our chance to talk to you.



STEVE:  ...our chance to talk about it, and their chance to listen.  So, yeah.



LEO:  There he is, Steve Gibson, always precise.  You can tell he's an engineer.



STEVE:  Leo, I listen to you.  That's the thing.



LEO:  Now, that's true, too.  Nobody else listens to me.



STEVE:  I pay attention.



LEO:  But, yeah, that's actually your chief virtue and charm is that, like most engineers, you're very precise about your choice of words, and you try very hard to accurately represent the facts.



STEVE:  When you program in Assembly language, you have no choice.



LEO:  It's that or nothing.



STEVE:  No room, comma, dot dot, semicolon, so forth.



LEO:  So a lot to talk about today.  We do have tech security news.  We have some corrections to make.  We're going to talk about Chrome because you've done now your analysis of Chrome.  We also - we're going to talk about DNS security, you said.



STEVE:  Yeah.  I had promised to talk about it weeks ago when we were talking about the whole DNS spoofing problem.  And so I did some sort of catching up.  And I discovered that there's more interesting things happening on the political side than really on the technical side.  So I want to sort of talk about sort of the notion of the technology a little bit about DNS security, but what it really means to have secure DNS because it enables all kinds of other stuff that would be really good to have.  But there's also some problems because turns out only one person can own it.  And we've got a big, complex globe.



LEO:  Yes.  And...



STEVE:  You can imagine that would be a problem.



LEO:  ...it's not just the U.S. that gets to decide this stuff, either.



STEVE:  Well, but as I'll explain, there can only be one owner.  And no one really is happy with the U.S. being that person.



LEO:  So what's in the news?  I notice I just got a Windows update all of a sudden.  Is this the second Tuesday of the month?  No.



STEVE:  No.  Interesting.  I didn't check mine, either, nor have I seen anything written up recently.  That's interesting, too, because there have been some complaints recently raised about Apple's nonsynchronous pushing out of updates.  Apple is releasing updates whenever they feel like it.



LEO:  Well, so did Microsoft for the longest time, until there were so many updates they couldn't do it that way anymore.



STEVE:  Well, actually it was the corporate guys who said, look...



LEO:  You're killing us here.



STEVE:  We can't have these kinds of interruptions on an ad hoc basis.  We just can't have them appearing at the door and needing to stop everything and figure out what they mean and how important they are.  So it was really, you know, end users don't care.  But it was the corporate IT guys...



LEO:  Oh, they care a little bit if they happen every day.  But hackers don't wait, either.  I mean, that's the problem.  They don't wait till every 30 days to release attacks.



STEVE:  It is true that, to the degree that Apple is pushing them out the moment they're ready, as we know, that reduces the size of the window of opportunity for exploits. So on the pro asynchronous update-pushing side, that is, the Apple approach, you could say, well, yes, but it's minimizing the opportunity for exploitation.  On the con side, though, now we're seeing, as Apple is trying to get themselves more into a corporate environment than before, and as Apple's market share is increasing, this is becoming a problem.  And corporate IT people are pushing back on Apple, saying, look, look what Microsoft does.  We like that.  We'd like it if you did that, too.  So, but we have been seeing Microsoft falling out of this second Tuesday of the month routine.  There have been, like, little patchy patches coming out where they've made a mistake, apparently, with their initial update and then made a fix and then put it out again.  So I've been seeing the same sort of thing you have, Leo.



I wanted to say at the top of the show that we've been getting a bunch of people trying to submit stuff to me, to Security Now!, who have been sending email to GRC.  Well, that works, but we've got a place for it to go.  And I realize, as I've been seeing this swell of people saying how do I send something to you guys - and in fact Leo you have forwarded things to me that people have tried to send - that we haven't been saying, I haven't been saying "GRC.com/feedback."  So I wanted to make sure that everyone knew to submit things to Security Now! that sort of go into that bin, GRC.com/feedback.  And that stuff, it's a web form that you can drop your text into if you've written it ahead of time.  It's as anonymous as you want it to be.  I don't, you know, I like to have names and locations so that we can sort of give a sense when you're reading the questions on our Q&A episodes where people are, who and where, it sort of makes it more personal and fun.  These are real people, not disembodied text streams.  But I just wanted to make sure everyone knew GRC.com/feedback was the way to submit things to us.



Last week we, in one of our - in last week's Q&A I read a question from someone that caused me to sort of raise some alarm about the uninstall behavior of Google's Chrome browser.  The first time - and it's funny, too, because I even mentioned how skeptical I was of this initially.  But when several people talked about it being the case, I then took a look at it myself.  And the issue was that upon removing the Chrome browser, there was stuff apparently deliberately left behind, namely all of the GoogleUpdate infrastructure which Chrome brings along with it, which is used for maintaining the currency of any of Google's code base, whether it's their desktop search or their web browser toolbar or the Chrome browser.  And in this instance I had set up a clean virtual machine that had never seen any Google code at all, installed Chrome, removed Chrome, and sure enough, there was all this stuff left behind.  There was essentially GoogleUpdate.exe was still invoking itself in the Run key of the registry, so that it would always arrange to be running all of the time.  And that continued for hours after Chrome had been removed.



So I verified that behavior on the show last week, and I said I'd be looking into it more deeply, but this looked like a problem.  Not long afterwards, that VMware session was still open on one of my monitors on the side, and I happened to glance over, and it was all gone.  I mean, completely perfectly beautifully removed from the system.  So it's like, okay, wait a minute.  Did I push something, or did I do something?  So I immediately retraced my steps, recreated the experiment, and sure enough, removing Chrome, this stuff was left there.  I restarted the system, the virtual machine, a few times.  I watched with a packet capture, and I saw Chrome phoning home to the mothership and exchanging, through an XML dialogue, exchanging a bunch of gobbledy-gook...



LEO:  You can't tell what it's saying, can you.  I mean, is it - it's not obvious what they're saying.  You can't say, oh...



STEVE:  Right, it's not English.  Not any English that we know.  And so finally, so I immediately sent email to you guys there saying, whoa, we need to head off the alarm bells from last week because I don't understand exactly what's going on yet, but it looks like it's removing itself, for some mysterious reason, maybe on some criteria based on its conversation with Google, or I don't know what.  So the most...



LEO:  That's the interesting thing.  You can't tell.  It's like not a certain number of reboots or something.  It's just...



STEVE:  Yes, it's not.  And then I thought, okay, as I was about to say, my most telling experiment was that I installed Chrome, and then I shut down that virtual machine's connection to the Internet so that neither Chrome nor GoogleUpdate could phone home in any way.



LEO:  Okay.



STEVE:  Then I removed Chrome.  And instead of getting the popup screen, oh, ow, please tell us why you are leaving us, I just got a "could not display this web page."  And I said, okay, good.  And now neither could GoogleUpdate phone home.  I just wanted to see whether it was disappearing on a schedule, if it was disappearing when it had permission to leave, that is; and, specifically, if it had been abandoned, if it was left behind on your machine, was there any scenario that would keep it from removing itself.  Well, for one thing, if you kept it from running, then it wouldn't remove itself, although it has many ways of running because it does install plug-ins into all the browsers it can find to keep its hooks into your system.  But if you just do the normal thing, that is, you uninstall Chrome and, literally, wait a while, even with no connection to the Internet, it tries to phone home; it can't resolve the domain name that Google is using for that purpose.  So after a few hours it goes away.  It just cleans itself up and says, okay, I guess there's nobody here who needs me or wants me anymore, so I'm leaving.  And it does.  Now, I've got to say I have no problem with that.  It'd be a little nicer if it noticed that it was the last piece of Google code in the system and went away.  I don't know why it couldn't do that.  But I would imagine maybe the Google guys have some reason, or maybe they're thinking you're going to reinstall afterwards, they don't want to...



LEO:  Yeah, they want to give you a chance, yeah.



STEVE:  They want to give you a chance to change your mind.  I don't know what they're thinking or why.  Or maybe they want some final chance to do some final, after-removal reporting back to...



LEO:  Yeah, there may be some reboots, too, that need to go on.  I mean, it's odd that it wouldn't be - I could see how it would be after one reboot it might go away.



STEVE:  I tried once, multiple times, none.  It just seems to be based on time.  And not even seeming - I didn't even - I didn't watch the time.  Because normally I would look up, and it had taken some opportunity to disappear between then and the time I had looked before.  So it's hard to keep track of it.  Who knows.  But the point is, it is not the case, and this answers the question from last week, not the case that Google leaves stuff forever in your system.



LEO:  And we should reiterate, and I said this - I should explain what happened.  So those of you who saw it live saw us go on and on and on about this.  And then, before we put out the podcast, Steve emailed me back with saying, wait a minute, hold on, it did seem to uninstall itself.  Let's do some research and come back next week.  So I essentially cut it out.  I didn't want to scare people without having the facts in front of us.  So I cut out most of that discussion.  And I did say this, but I want to reiterate this, that the Chrome folder that our correspondent saw, and this is confusing, is not Google's Chrome, but it's what Firefox calls its UI.  So it's a bunch of JAR files for the Firefox UI.  So, yes, deleting that Chrome folder does break Firefox.  But you do stand by the points that Chrome does install something into - a browser helper object into Internet Explorer.  It does install a plug-in into Firefox.



STEVE:  Right.



LEO:  And it does install the GoogleUpdater.  It does phone home with stuff we don't know what it's saying.  The only thing we correct is - and I think that, because I cut that part out, I don't think it's a major correction.  But the only thing that we correct is that the updater does uninstall itself after time.  It leaves itself on there initially.  But after some unknown amount of time it uninstalls itself.



STEVE:  Yes.  And I did - and maybe this was also something that was removed from the podcast.  I did listen to what you had edited, Leo, and it sounded much better to me.  Of course it sounded like...



LEO:  And in the case of - I absolutely want complete transparency here.  So we talked about it after the video so that people understood who had watched the video.  I hope people stayed tuned for it.  And then I just, you know, in this case I feel like it's as if a newspaper had an article, something in the article didn't fact-check out, took it out before publishing it.  And I feel like that's what we did.  But because we broadcast live, people saw the sausage being made.  So I just want to make it very clear exactly what happened so that you guys understand.  And I just didn't feel like we should publish it with something that we didn't understand yet.  And now we're coming back and explaining it.



STEVE:  Oh, absolutely.  And the fact that we have the listener base of the podcast is substantially larger than the viewer base.



LEO:  Absolutely, yeah.



STEVE:  Yeah.  We did also mention, or there was some - I agreed certainly in talking to you that I would take a look at Apple, too, because there were some people in the chatroom during the podcast that were upset, saying, well, I mean, Apple does the same thing.



LEO:  Which is no excuse, obviously.  It's...



STEVE:  Exactly.  I mean, I feel that very strongly.  So I don't care what Apple does.



LEO:  We'll call them on that, as well.  That doesn't make it okay.



STEVE:  I did take a look, though, through a Safari install and remove.  And Apple operates differently.  I actually like the way Apple's update functions more than Google's.  Apple Update functions by registering a task scheduler job to run, in my case, late Saturday night once a week.  So only - so nothing is running in the system all the time, which I like a lot more than Google Update sitting there as a process.  I mean, I try to avoid...



LEO:  Too many programs do this, and it slows your system down eventually because you have all these processes sitting there.



STEVE:  Yes, and essentially everyone seems to think that they own your system and have a right to come in and stomp around on it, which is really annoying for someone who is trying - for any users who are security conscious and want to have some sense for what all this gobbledy-gook is that's running in their system.  It slows your boot.  It's burning up some RAM resources.



LEO:  And it impacts reliability.  And it makes it very difficult to detect spyware because you see all these processes running, and you don't know what belongs to what.



STEVE:  Yes.  To GoogleUpdate's credit, I will say that it is not big.  If it were hundreds, well, not hundreds of megabytes - well, yeah, that, too.  But, I mean, if it were really big and running all the time, that would be a problem.  But in my case it was about 183K.  Which is...



LEO:  That's tiny.



STEVE:  It's, yeah, compared to the amount of RAM these days it's tiny.



LEO:  It generally seems to be the case on OS X, and I think it's true on Linux, that programs - the kind of default way of doing this is that Chrome would check on start.  It wouldn't keep something running all the time.  But when the application runs, it would check for updates and then download updates.  And most Apple applications work that way.  They download updates only when they're run.  They don't stick stuff in the background.  And I think that's true on Linux, as well.  It's just kind of not done.



STEVE:  Well, and so we've heard, and this may just be anecdotal or initial industry stuff, I remember hearing that Google was looking often to, like, GoogleUpdate was checking hourly to see if there was anything new.



LEO:  Now, in their defense, what they're checking for, they say, is new phishing pages, new secure - they're looking to update their phishing thing.  And I think Internet Explorer 7 does something similar; doesn't it?



STEVE:  I have not looked closely.



LEO:  I think it does update its database of malware sites.  And god knows there's new ones all the time.  So maybe you could make the justification.  Seems to me, though, it should be doing that when it's running.  I mean, if you only run Chrome once a month to run Gmail or something, why do you want something running in the background every hour, updating Chrome?



STEVE:  Right.  And again, this can also be, in my opinion, covered by the fact that they're in beta mode, that this is a beta.  Lord knows how many years it's going to be labeled "beta," given Google's reputation or penchant for leaving things in beta forever.  But anyway, I did want to mention that what Apple does is it installs the Apple Update, which it does not remove when you remove Safari.  It does, however leave it in your Add/Remove Programs listing.  So if you install Safari and remove Safari, the act of installing Safari does bring Apple Update along for the ride, but does not take it out.  Now, again, I don't know if next Saturday night, when Apple Update runs, if it would notice that Safari had left, and then it would remove itself.  I didn't check that.  But I did see that there were two separate entries in Windows Add/Remove Programs files listing, one for Safari and a separate one for Apple Update.  And you just click on that and remove it, and it goes away.  So they're operating very differently.  I like the idea that Apple Update's independent updater is not running all the time, and it runs weekly, which seems fine to me.  And as you said, Leo, certainly when you run Safari, Safari can check to see if there's anything...



LEO:  That's a good time to do it.  Maybe they do it because they want to speed up boot, you know, browsers, you want them - look how fast Chrome pops up and is ready to go.  And that's probably why they don't want to do that on startup.  But that's the price you pay is that your machine is always doing it every hour, whether you want it to or not.  So on the balance, now, knowing what you know about Chrome, are you still concerned about its security and about whether people should install it?



STEVE:  Oh, yeah.  I'm not at all concerned about the GoogleUpdate behavior.  I think that's entirely acceptable, especially as a beta.  If it had left the stuff in the system forever, then even as a beta I would feel that's unacceptable.  But this is just fine the way it is now.  However, I still feel the same way about the browser being too feature-lean.  It's unacceptable for it to, by default, to offer to save website passwords and provide no facility for the owner of the system to protect those from prying eyes.



LEO:  That's a real problem.



STEVE:  I mean, that's just nuts.  And, frankly, I know that Google wants this to be a platform for running JavaScript applications and sort of the Web 2.0 model of things, the  browser as the application platform.  But it is, I mean, all the vulnerabilities we run across today are scripting driven.  They are enabled by scripting, by going to malicious sites that use scripting in order to cause something bad to happen in your system.  Okay, I said "all."  I shouldn't have said "all" because there, for example, we just had image-based vulnerabilities with GDI+ in Microsoft's last update.  So there was a non-scripting vulnerability where just showing an image would cause, could cause a remote code execution exploit.  So it's not the case that absolutely all, but 99.9 percent of what we've talked about in the last year have been script-driven exploits.  So the idea that there's no way to disable JavaScript at all, let alone site-specific disabling, which IE offers natively and which the NoScript plug-in to Firefox allows, just the idea that it doesn't have it, it just - it can't compete in the browser world.  And some people have said, well, it's not really a browser, it's an application platform.  Well, yes, it's a browser.  I mean, of course it's a browser.



LEO:  When it comes to security, if you're using it on the Internet, I mean, I guess if you stuck with Google applications only, these would be less important.  Of course it'd have your password, your Gmail password visible.  I don't know if you really want that.



STEVE:  Yeah, that's true.  And you talked about wanting to keep it around as a better platform for running Google Mail, for running Gmail, which I think makes absolute sense.  I just think it's not ready yet to be someone's only browser.



LEO:  No, no, no, no.



STEVE:  And my real big news, well, for me, I've switched to  Firefox, Leo.



LEO:  What?  And why, Mr. Steve Gibson?  Because I've had this battle with you for now nigh on four years.



STEVE:  As long as we've known each other, actually.



LEO:  You've always been an IE user.  Now, to your credit, I've always used you as an example of how you can use IE safely.  And you do that.  But why did you switch?



STEVE:  I just think that Firefox has become mature enough.  And, frankly, there is a fabulous ecosystem of plug-ins that surround it.  So I've spent some time in the last week - I just made the decision.  I like the way it looked with Firefox 3.  I liked the security improvements that they went - in going from 2 to 3.  Firefox is one of the only browsers, I can't remember if it's the only - we'll be talking about privacy-related issues of browsers before long.  But it's at the top of the pile of privacy enforcement.  It really does a good job.



LEO:  Well, except that its third-party - do you think its third-party cookie support is now acceptable, or blocking?



STEVE:  I wish it were - I wish third-party cookies were disabled by default.  But they're not.  That's my only complaint because it does block - it blocks outbound cookies, which is outbound third-party cookies, which you want, not blocking inbound third-party cookies, which unfortunately the WebKit-derived browsers, specifically Safari and Chrome - oh, and IE, which is not WebKit derived, but IE also - they block incoming but not outgoing, which is wrong, the wrong approach to blocking and filtering cookies.  So but more than that, if you add a couple simple plug-ins like NoScript - and people have been jumping up and down about it, I mean, I've been hearing so much about it, I thought, okay, I've got to find out what this is.  Time to give up on IE, Gibson, and switch.  And I have switched.



And finally it took - after a couple days I realized when I was clicking on links I was still getting an IE instance.  And finally I said, okay, time to switch over to Firefox full-time.  I mean, so Windows Update will still run IE in order - because, you know, it will only run in IE, which is just fine.  I'm doing all my surfing on Firefox 3, and I'm very happy.  And using NoScript with scripting disabled by default, and then you selectively enable it for those sites that need it, I mean, that's the way to surf.



LEO:  And I should point out that Steve is the opposite of an early adopter.  But that's - I think anybody who is really concerned about security, that's the way it should be.  I mean, you only recently moved off of Windows 2000 to Windows XP.



STEVE:  Yeah.



LEO:  And Vista, well, Vista is way off in the future.  Vista is maybe never.



STEVE:  I wanted to mention, since we had talked about the large Hadron Collider recently...



LEO:  Oh, bad news there, huh.



STEVE:  It's shut down.  Yeah, there was a - I loved it, too, because what it literally had was a coolant leak.  And I thought, this is the Enterprise.  Because we were talking about how it's like a starship when you look at the photos of this thing.  And of course they were always having coolant leaks.  That's bad on a starship.  But it turns out it's just as bad on a superconducting magnet.  When you get a coolant leak on a superconducting magnet, all kinds of things melt; and you get helium, I think it's helium that was leaking into the internal chambers.  Anyway, they are now shut down until spring because the electricity costs so much, and the rate, the cost of electricity goes up in the winter, that they're now shut down until next spring, when they are able to afford, well, they have to make repairs and then afford to fire this puppy back up again.  So not...



LEO:  [Sighing].



STEVE:  I did also want to mention in my little own errata section that I was really delighted when I happened to go back to the Kindle's online shopping area, looking at newspapers, and the Financial Times is now available.



LEO:  You read the Financial Times?



STEVE:  It is, in my opinion, the best of the financial-oriented newspapers.  I've been reading The Wall Street Journal a lot.  And then I added The New York Times to - I already had the L.A. Times I was looking at.  But I even have my own little county's - the Orange County Register, of all things, is available now.  There's a much-expanded collection of newspapers.  And I have to say, for any of our listeners who know the Financial Times, I've been now comparing them side by side during this last week of financial roller coaster. 



LEO:  Oh, I bet that's an interesting read.  Because it's  British.  It's out of England.  Isn't it?



STEVE:  I don't know.  I wouldn't be surprised.  I've sort of sensed some of that in like the way they use the pronouns and things.



LEO:  Little bit proper.



STEVE:  But what I like about it is that it feels like the writers really understand what they're writing about.  Whereas even The Wall Street Journal has a little bit of feeling like, well, we're sort of rehashing what came over the AP newswire, and we don't really understand it.  And what I find is, as a consequence, I understand it better when I read it from the Financial Times than I do The Wall Street Journal.  Which I was assuming was the gospel, essentially.



LEO:  I'm going to defend the Journal because I have some friends who work there.  I think that they do actually know - they have some of the best reporters in the country.  It's a very good newspaper.  I don't read the Opinion page because my politics differ.  But it may be that, you're right, that maybe they aren't covering - I wonder, you know, because they're in the back pocket, aren't they, of Wall Street?  So I wonder if their coverage is perhaps a little less objective than something like the Financial Times.



STEVE:  It might be that.  I'm also seeing that the articles, the stories in the Financial Times are shorter.  The Kindle gives you the word count at the top of each story.  And, for example, this morning I read everything that I needed to during my morning Starbucks coffee sojourn in the Financial Times.  And then I quickly scanned the front pages of The Wall Street Journal, The New York Times, and the L.A. Times.  And there were some interesting local stories.  We finally got our budget signed by the Governator yesterday, which is a good thing for the California budget.  And but nothing really else that I wished I had read elsewhere.  So the fact that the Financial Times is being covered in the Kindle or is now available in the Kindle I think is just really good news that I wanted to bring to the attention of our listeners who, you know, the four of them who might care.



LEO:  Hey, I lent my Kindle to Megan.  She wanted to do a review.  And after two weeks I was on my knees, saying, can you bring my Kindle back?  I miss it.



STEVE:  Yeah.



LEO:  I now do not, you know, in fact I bought a paperback book and started to read it.  And then I said, wait a minute, I bet this is available on Amazon's Kindle.  And I did, and I ordered it, and I put the book aside.  It's just easier to read it on the Kindle.



STEVE:  I know, it's so nice, well, and so universal, too, to carry it around.  And frankly, I mean, books are great to read.  I've read many on it.  But for me, you really get the leverage of the modem, and the articles are just there.  When you're subscribing to newspapers, and they're just there in the morning, it's just so nice.  And in fact I was mentioning to somebody, oh, it was somebody at Starbucks, about the Financial Times.  And he was complaining that it didn't arrive physically until noon for him.



LEO:  What, at 3:00 a.m. you get it on...



STEVE:  Yeah, it's just in the Kindle in the morning.  It's certainly there by 4:40 a.m. when I'm up and rolling, so...



LEO:  I love it.



STEVE:  And in other interesting security-related news, Sarah Palin's Yahoo! email account...



LEO:  She had, what, gov@ - or alaskagov@yahoo.com?  I can't remember...



STEVE:  She had gov.palin and gov.sarah, those two accounts both at Yahoo.com.  And of course it was in the news last week that her account was somehow broken into.  And it turns out what this person did, and we're thinking unfortunately it's the son of a representative, it's pretty much...



LEO:  Oh, you're kidding.



STEVE:  Yeah, the FBI tracked him down.  He used a proxy in order to get some sort of IP coverage, apparently.



LEO:  But he didn't use TOR.  He used a one-step proxy.



STEVE:  Yes, he did.  And it turns out that the IP that he bounced through is handled by the ISP that covers the school that he attends.



LEO:  Oh, he's a kid.



STEVE:  Yeah, he is.  And anyway...



LEO:  Just shows you how easy it was because it was social - it was basically social engineering, wasn't it.



STEVE:  Well, yes.  And the reason this is a really great topic for us, I mean, we're not going to spend the whole time talking about it, of course, but it brings to light an interesting problem.  Essentially he went to Yahoo! and figured out what the account name was, that gov.sarah or gov.palin, or maybe he knew from somewhere, I'm not sure how that was determined.  But there of course was a password that he needed.  So he told Yahoo! that he had forgotten the password and so went through Yahoo!'s password recovery steps, which involves answering a bunch of so-called "secret questions."  The problem is, these were not very hard questions for someone to know the answers to.  One was...



LEO:  If you've been following the story, you know a lot of them.



STEVE:  Well, and in fact you don't even need to follow the story.  I mean, if you arrive late to the party and just Google her or Wikipedia her or do basically any publicly available source of information.  So I think one of the questions was where did you meet your husband, and so that was something that she had chosen probably from a list of standard questions.  And this kid guessed from whatever information he had that she met him in high school.  And he knew where she came from, so he knew what town that was.  He put that in.  One was what is your zip code, and one is your date of birth, both which were available publicly because she's now a celebrity.



LEO:  Right, right.



STEVE:  And it said, yeah, okay, fine.  What would you like to set your password to?  And he set it to "popcorn."  And so...



LEO:  Now, this same kind of thing happened to Paris Hilton with her T-Mobile Sidekick.  And it's because, if you're public figure - and the secret security question was what's the name of your dog, which she talks about all the time.  So if you're a public figure, this information is known.  You can't use the obvious answers to your security questions.



STEVE:  Right.



LEO:  I mean, do you think it's Yahoo!'s fault?  They should have a better system?



STEVE:  It's everybody's fault.  I mean, you would argue, I mean, I have no position one way or the other about Sarah using Yahoo!.  That's questionable, though, whether official business should be conducted in a public, nonsecure forum like that.  There have been partisan people who have been criticizing her, assuming that she was doing this in order to avoid whatever records maintenance is normally - someone in the government is normally subjected to for the sake of maintaining public records for posterity.  I don't know about any of that, and I have no opinion one way or the other.  But what's of interest to our listeners, I think, is this idea that the password recovery questions could essentially be so insecure.  So is Yahoo! responsible?  I don't know.  But certainly we've seen situations where you do password recovery choosing from a list of questions.  There are other ones where you are able...



LEO:  My bank does that.  I mean...



STEVE:  Right.  There are others where you're able to provide your own question.  And I think that's probably more useful.  You can ask yourself a question that only you would know, as opposed to here's a bunch of suggested questions, none of which tend to be very difficult to answer.



LEO:  Well, you don't have to use the right answer, either.  You know, it asks me frequently what was my first pet.  I don't use - first of all, I've never told anybody the name of my first pet.  But in case I do, I'm a public figure, I talk a lot.  In case I do, I don't use that as the name.  I use some other name.  So but then you have to remember it.  It gets complicated.  So...



STEVE:  Security always comes at a price.  The last thing I wanted to mention was actually from the SANS newsletter.  It's something I picked up on last week, but I just sort of moved it over for our conversation this week, I thought was very interesting.  They reported three different instances of - and this is just in the last couple weeks - of employees of one sort or another being responsible for breaches, serious breaches of their own company security.  And I wanted to share these with our listeners because this is something we have not yet, in all this time, spoken about.



The first one was titled "Former Intel Employee Charged with Theft of Trade Secrets."  And it reads, from the SANS newsletter, "Former Intel Corp. employee Biswamohan Pani has been charged with theft of trade secrets for allegedly stealing proprietary company data, including information about the development of new chips."  This is, you know, he's an Intel guy.  Says, "Pani allegedly accessed an encrypted system at Intel and downloaded 13 top-secret documents.  He had resigned from Intel in May and was taking accrued vacation time through June 11th.  The intrusions occurred between June 8th and 10th."  So in the last three days of his - nominally his employment prior to June 11th, when it was finalized.  "Pani had already begun to work for Intel competitor AMD.  The issue was discovered when an employee looked into Pani's access and download history on the system in question."



LEO:  Oh, boy.  Oh, boy.



STEVE:  So there was one.  Then "Countrywide Notifying Customers of Data Breach.  Personally identifiable information of as many as two million Countrywide customers may have been sold by data thieves, according to the mortgage company.  While there have been no reports of the information being used to commit identity fraud, Countrywide is offering two years of credit monitoring to affected customers."  Oh, thanks a lot.  Guess that's better than nothing after the information's escaped.  And of course the customers were notified.  "The data were allegedly stolen by a former Countrywide employee who downloaded approximately 20,000 customer records every week for two years."



LEO:  Oh, this is like embezzling, almost.



STEVE:  This is serious.  Yeah, so this is, I mean, this is long term, 20,000 customer records every week for two years.  Each batch of 20,000 customer records was allegedly sold for $500 U.S., or about..."



LEO:  See, I'm a former Countrywide customer.  So they would have my stuff; right?



STEVE:  Well, two million Countrywide customers were affected by this over the course of two years.  And so this person was getting 2.5 cents for every record that they stole.  And then it says, "It appears that the data were sold to other mortgage brokers."



LEO:  Oh, that's interesting.



STEVE:  Yeah.  So if you've been getting some unsolicited...



LEO:  I get a lot of unsolicited - I get that all the time, I get unsolicited.  But I thought that that was just because a loan is public record or something.



STEVE:  Didn't go off to Russia in this case, Leo, it just went to Countrywide's competitors.



LEO:  You know, he's only getting 2.5 cents.  It's what, like 500 bucks per download.  I guess that adds up.  But still.



STEVE:  500 per batch, yeah.



LEO:  Per batch, yeah.  I guess that's...



STEVE:  Finally, the last story is "Insurance Office Employee Allegedly Used Customer Data to Open Accounts.  Attorneys General in 45 U.S. states have been notified that a State Farm Insurance employee in Surprise, Arizona" - love that it happens to be in Surprise, Arizona, he was surprised - "used customer information to obtain credit cards.  The compromised data included addresses, Social Security numbers, driver's license numbers, and in some cases bank account numbers.  A company spokesman did not specify the number of people affected by the breach.  Police are investigating.  All affected customers have been contacted and offered one year of free credit monitoring."



LEO:  Surprise.  Surprise.



STEVE:  So this really speaks to an issue that, as I said, we've never directly addressed. and we certainly will at some point, and that is that we've talked about the notion of, I mean, all the security that we've really talked about has been how to protect from external intrusion, you know, people on VPNs, external passwords, the idea of given that everybody inside is doing the right thing, how do you protect your goodies from any bad people on the outside getting in.  And these three stories I thought so perfectly demonstrate that there's a big problem, and in fact it has been argued this is the bigger problem, than dealing with bad guys on the outside who don't know your secrets.  And that is dealing, you know, protecting your secrets from your own employees who have access.



LEO:  I think that's almost a given that most jobs are inside jobs; right?



STEVE:  Yeah.



LEO:  Yeah, I mean, I think that we've been saying - I've been saying that about hacking for a long time.  You know, they're always looking to the outside guy.  And pay a little more attention to the guy inside because that's who really has all the information.  Things like letting this guy quit, go on accrued vacation time, and not canceling his account to the secret servers?  That's just bone-headed.



STEVE:  And he already had a job at AMD.  So, I mean, and we're of course completely speculating here, but he might have realized, wait a minute, I've got my accrued vacation time, technically I still have access because I'm really still an employee.  And so who knows what pressure he was subjected to, either by AMD or his own ethics or lack of, I mean, it's impossible to guess that.  But...



LEO:  And we should probably mention that he's almost certainly broken the law and broken his employment contracts.  And there will be some price to pay for this.  I mean, it's not a - he's not going to walk away from this.



STEVE:  No, no, no.  I mean, this is 13 top-secret documents to which he had access while an Intel employee.



LEO:  I think that's a felony.  I may be wrong, but I think that's a felony.



STEVE:  It's way bad.



LEO:  Wire fraud.



STEVE:  Yeah.



LEO:  Okay.  So our topic of the day is DNS, and in particular how difficult it is to do DNS security.  Before you do that, do you want to - do you have any SpinRite letters, anything else you want to talk about?



STEVE:  I did have one really nice, fun, happy story.  And this...



LEO:  From a Navy SEAL or a...



STEVE:  No, this is a Marty Sasaki.  He wrote - he's in Arlington, looks like Arlington, Massachusetts.  And he just said that - the subject was "Happy With SpinRite."  He says, "I've been looking at SpinRite since I first heard about it on Tech TV," Leo.



LEO:  Oh, my goodness.  Oh, my goodness.



STEVE:  But, he said, "I couldn't justify spending the money on it until today.  My system died.  Can't tell whether it's a motherboard or a CPU problem.  And the system is old enough that getting replacement parts is almost impossible.  So instead I got a new motherboard, CPU, and RAM, as well as a new SATA disk drive, a Serial ATA disk."  So, he says, "Time to copy over the PATA, the Parallel ATA disks.  I kept having problems doing the copy, trying both PartitionMagic and GParted.  It would always get a ways into the copy, then fail.  So I figured I had a hard drive problem.  I downloaded SpinRite and fired it up.  It found a few errors, but it detected that one of the drives was running hot, really hot.  SpinRite would stop, display the temperature warning.  I would let it cool down a bit and then resume.  Finally," he says, "I pulled the drive out of the case, mounted it so that I could blow a fan across it so I could get the data off of the drive.  I probably would have figured it out eventually, but I saved myself hours, maybe days of playing around by getting SpinRite.  I've got a couple of flaky disks around that I'll check out next.  Perhaps they're still usable.  Thanks."



LEO:  I've had that happen, too, where the - what do you set the temperature for, default, for SpinRite to complain about the drive?



STEVE:  Boy, I don't remember now.  When I set the spec for it, I did a survey of all the manufacturer specs and used the top end, that is, the high-end operating temperature that they were saying do not use a drive if it's hotter than this.  So I'm not overreacting.



LEO:  It's not a conservative number, by any means.



STEVE:  No, no, no, I mean, it's hot.  And the idea being that I wanted to alert people, and this happens often, where they've got, for example, a case that was working fine.  Then they said, oh, I need more terabytes of data.  So they put higher performance, higher spinning, faster seeking, you know, more power-consuming drives in where they used to have a case that no longer has, as a consequence of that, adequate ventilation.  So they end up with drives - and sadly, nothing else in the system, I mean, there are some add-ons you can get sometimes that will give you something in the tray running that will monitor your drive temperatures.  You know, SpinRite does.



And the other thing is that oftentimes drives run hotter when they're being used.  SpinRite uses the drive constantly.  One of the things that does cause power consumption, and thus heat dissipation, is seeking.  And so if the drive is cool when it's just sitting there doing nothing, and especially in the beginning when you power it up and the BIOS checks the drive's temperature, it says, oh, drive's cold.  Yeah, how long is it going to stay cold is the question.  So SpinRite does constant monitoring of the drive temperature in addition to all the other SMART data, the SMART, the Self-Monitoring Analysis and Reporting Technology stuff, while it's running, and alerts people if the drive is getting too hot when they're running SpinRite.  And it's generally something you need to pay attention to, as this guy did.  He finally arranged to run a fan over the drive to keep it cool enough in order to get SpinRite to fix the drive so that he could do his data transfer.



LEO:  You know, it's funny, I could have written that letter.  We had a computer that's been flaky for two years.  And Colleen - I said, you know, we should really SpinRite this drive, and Colleen did.  And it was overheating.  And it's because it's in a Shuttle case.  And I think the Shuttle case is a little tight.



STEVE:  Yes, Shuttles actually have a big problem with adequate ventilation for the hard drive because it's underneath the floppy, and there is no real forced ventilation across the drive, you're right.



LEO:  So she had it open.  It was kind of funny.  She had it open and a fan, like a table fan, blowing at the drive so that she could finish the SpinRite.  But now we know we need to leave the case open and maybe have a fan blowing across the thing.  We've actually retired that Shuttle.  It was always flaky, and now I know why, it was too hot.  So that's a useful little informative dialogue.



All right.  Let's get back to the matter at hand, DNS security.  We all became aware of DNS security when this big bug that Dan Kaminsky found showed up.  He talked about it at Black Hat.  People were stunned to find out that their Internet service provider wasn't providing secure DNS.  It seems like we fixed the problem.  Is it fixed?



STEVE:  Well, no.



LEO:  Oh, great.



STEVE:  We've hugely mitigated the problem of DNS spoofing.  But we haven't fixed it in the sense, for example, that we use SSL right now for really creating uneavesdroppable and authoritative connections to remote servers. As we know, SSL uses a certificate-based system, both to create an encrypted connection between two endpoints and to allow us to authenticate that we are connecting to a known remote server.  So that, for example, PayPal gets a certificate which has been signed by someone whom we trust.  And often VeriSign or Entrust or any of these certificate authorities, they go to hopefully significant lengths to verify that this is really PayPal that they're giving the certificate to.  Then PayPal has the certificate on their server which our browsers connect to and verify that the certificate matches the domain name.  Thus we get authentication of the endpoint that we're connecting to, as well as, thanks to the SSL protocol, we get encryption which protects it from being spoofed.



Now, the DNS system, the Domain Name System that we've talked about now several times, is a really flexible distributed database.  It can contain much more than just DNS.  And this is one of the really interesting ideas about how DNS could grow in the future if only it were more secure.  Right now it's - you could argue, well, it's secure enough to look up IP addresses, especially where we add then an optional layer of SSL security to verify the identity of the remote endpoint to reduce the spoofing problem.  But we know that there are still things that occur, like phishing attacks, for example, where users are misled to go to the wrong site.  That's not a failure of DNS, although the problems that Dan found, the idea that DNS could be spoofed does make these problems more severe.



What DNSSEC, as it's called, which is the acronym for DNS security, what it offers is, for the first time ever, is cryptographically signed and authenticated DNS records, meaning that when a resolver, a DNS resolver is trying to get the IP for a domain, it could use a system very much like the system we have in place for security certificates.  It could use a system using public key technology, so-called PKI, the Public Key Infrastructure, to provably authenticate the contents of the DNS data that it receives so that it's able to absolutely state that this data is the same as was being offered by the authoritative name server.



Remember that the problem that Kaminsky exposed was that it was possible to do so-called "cache poisoning," meaning that the way DNS operates, it gets its scalability because you're not always having to ask the authoritative server.  You're able to locally cache the information which you once obtain from the authoritative server, so you're not having to bother that authoritative server all the time.  That's really where DNS is scalable, that is, the idea that you're able to cache this data.  So what you want to verify is, if you get the data from a cache, is that the same as the authoritative name server has?  And then you also have the problem that DNS uses no secure connections.  It doesn't even use TCP connections.  It uses UDP packets which, because it's just a query in one packet and a response coming back, they are infinitely spoofable.  So even if you ask the authoritative name server, that is, not a cache, but the actual source of the DNS information for a given domain or zone, as it's called in DNS parlance, even if you ask that server, you'd have no way of knowing that you've got the response actually from the server because it's just a UDP transaction, a packet for a query and a packet for a response.  So even there you would like to have the data that you received digitally signed so that you can absolutely verify that this is information you can trust.



Well, it turns out that essentially the same sort of hierarchical structure that DNS uses for its domain names, where for example you have www.paypal.com - and actually there's sort of a, even after the ".com" there is a root above the .com, where you have a hierarchy.  You've got PayPal's name server that knows about PayPal and the PayPal domains.  Then you've got a level above that is the .com servers that know about the .com domains, that is, all of the domains that are children of .com.  And then above them are the root servers that know about all of the top-level domains, like .com, .org, .edu, .gov, and so forth, .mil, you know, all the domains underneath the root.  So the system that was developed has evolved over, boy, I think we're now up to about 15 years.  It's taken some time.  And the early RFCs, the early documents that defined the first architecture, were found to be defective because they did not scale well.



One of the early concepts was that when a zone, meaning the records in a domain, changed, they needed to be resigned.  The concept was that the parent would sign the children's records.  So, for example, I'm at GRC.  And if I changed some data in my GRC domain, I would have to have them resigned by the parent.  And so the idea was that I would, in the original architecture, which has now been obsoleted, I would have to send those up to the, for example, the .com servers to sign.  And then the .com servers would send signed records back.  And the nature of the cryptographic signature was such that then I could provide those records to third parties, anybody who wanted the GRC records, and they would see that they had been signed by the .com servers, and they would be able to get the public key of the .com server in order to verify that the .com server had signed those using its private key.



Well, there were a number of problems with that.  One is that that would require that the private key be available online, which was a huge concern because, if it was available online, meaning it was sort of like dynamically available, then there's a much greater chance that it could leak out, which would be catastrophic.  But the biggest problem was that this would put a huge burden on all of the parent servers, any parents that had many children, since all of the children would constantly be needing to have their records signed.  That was a huge problem.  So a different approach was created where - essentially using some hashing technology, where instead of needing all of the individual records to be signed, it would be possible for a signature to be signed so that the domain wanting itself authenticated would create a signature, and it would just send the signature up to the parent, that would sign the signature and send it back.



So there has been some evolution of this over time.  But fundamentally what this would mean, if we could get DNSSEC working correctly, that is, get it broadly deployed and supported, it would mean that we would have, for the first time ever, a really, really secure, cryptographically securable distributed database for the Internet, which we've never had before.  DNS has been okay, but with all kinds of problems, and not something you could trust.  It's never been trustable.



Well, when trustability arrives, then we get a lot of things we've needed.  For example, DNS, because of its flexibility, could be used for distributing public keys.  There's never been a good means for distributing public keys.  And that's, for example, been one of the things that has prevented email security from working well.  If I wanted to use secure email on a broad basis, I have to have some way of allowing anyone who wants to either decrypt and/or authenticate the email as having come from me, I need some way of allowing them to have access to my public key.  Well, we could use DNS to distribute public keys, but can't until it's absolutely securable, until we absolutely know that this is my public key, and that that cannot be spoofed.  Otherwise the damage would be too great.



So we have a problem, though, in deploying DNSSEC.  Basically the technology has largely been resolved.  We have a system now which looks like it'll scale.  The problem is that, in the scenario I just painted, we are needing parents to sign the children's hash, that is, the children produce a signature of their current domain and get the parent to sign it.  Well, that means that the parent is using its private key in order to sign data, and that the parent's public key is made available.  Well, that's the way public key infrastructure technology works.  The problem is the politics of this because, in order for GRC to be authenticated, there has to be a chain of trust all the way up to a trusted root, what's called a "trust anchor," some ultimate authority from which all authority emanates, because that root, that is, literally the root servers would have to sign all of the top-level domain, all of the .com and .net and .org and .mil and .gov, and the other countries' top-level domains, like .it and .se and .ru and, you know, and all of the country code domains similarly would have to be signed.



So the question is, who gets that?  What authority runs that top-level root server key?  And unfortunately that hasn't been an issue until now.  But the U.S.'s Defense Department and Department of Homeland Security have said they want to be in charge of these keys.  And unfortunately the...



LEO:  I don't think Russia will like that.



STEVE:  There's a problem, yes, there's a problem with the rest of the world swallowing the U.S.'s unilateral management and ownership of the keys.



LEO:  This has been going on in other areas, as well, with ICANN, for instance, for a while.  I can remember last year there was a move in the U.N. to take responsibility for the domains out of the hands of the - essentially out of the hands of the U.S. Commerce Department.  And now it's even worse if they want DHS to do it.  But there's some resentment among countries like Afghanistan, they're saying why should the U.S. be responsible for this?  Of course we're responsible because we invented it.  But now it's a global system.



STEVE:  Right.  And so, well, exactly, so there's a bit of a chicken-and-egg issue here.  It's like, well, until it became really valuable, no one really cared.



LEO:  Right.  Yeah, we did it.  Now you want it from us; right.



STEVE:  Yeah.  To give you some sense for the complexity at, I mean, the way things are even now, that is, how the whole root zone system operates, I can read a short paragraph that talks about the issue of securing the root.  And it says, "To clearly understand how this proposal will impact modifying and publishing the so-called 'root zone file'" - so there's a single file, ultimately a single file called the "root zone file."  And that contains the addresses of all the top-level domain name servers, that is, all the .com servers, all the .org servers, all of the .edu servers, .gov servers, all of those, and all of the other country code servers are in this top-level zone file.  And understand that, okay, remember that what this is, is this is the IP addresses of the name servers of all of those top-level domains.  And that's in a single file called the "root zone file," or RZF.



So continuing, it says, "So to clearly understand how this proposal will impact modifying and publishing the root zone file, it is best to briefly outline the current process and actors involved.  Currently, change requests from registries are sent to ICANN, specifically to IANA, for processing.  Once it is determined that the changes meet IANA's narrow technical requirements, and they are approved by the ICANN board, the request is forwarded to the U.S. Department of Commerce for review and approval.  If the Commerce Department approves, the root zone maintainer, the RZM, currently VeriSign, edits and generates the revised RZF, the root zone file.  The root zone file is then loaded by the root zone distributor, the RZD, also VeriSign at this time, to the distribution master name server.  Once there, it can be retrieved by the other root server operators located around the world."



LEO:  Sounds like something out of "Tron."



STEVE:  It's, well, okay.  This is the simple way that it is now.  And so the problem is that implementing DNSSEC, DNS security, requires modifications to everything.  I haven't even talked about the details of the technology of this.  But there are real problems.  For example, I've sort of talked glibly about digital signatures and keys.  There are key-signing keys and zone-signing keys, and another record called a "delegation signing record."  I mean, it gets very complicated.  Also, unfortunately, it gets bloated.  For example, in an example I saw, a normal, traditional DNS record was 75 lines long.  And that's a relatively - that's a reasonable zone file, 75 lines long and about 2.3K in size.  The same zone implemented with DNSSEC was expanded from 7[5] lines to 665 lines, and from 2.3K to 27K.



LEO:  But that's still small.  I mean, we...



STEVE:  Ah, except, Leo, that it no longer fits in a UDP packet.



LEO:  Oh, that's not good.



STEVE:  And that's the problem is the original DNS spec specifies that UDP DNS messages can be up to 512 bytes of payload, which ends up being 576 bytes for the total packet.  So 512 bytes.  Now, 512 bytes doesn't sound like a lot.  But it turns out because of the way DNS messages are compressed - there's a compression technology which is pretty clever that just uses simple pointers to end up compressing a very complex set of queries and replies into a couple hundred bytes.  So it ends up being that UDP is entirely practical, single packets, for shooting this stuff back and forth.  Well, suddenly, when you add DNSSEC, that is no longer the case.



LEO:  But what's wrong with sending multiple packets?  Most of our data is multiple packets.  Does that screw something else up?



STEVE:  Well, okay.  There's no provision, first of all, for multiple UDP packets.  Remember that it takes TCP to create the notion of a byte flow which can then flow across multiple packets.  So DNSSEC requires other enhancements to DNS which are identified and have been put in place, and that is extensions that allow DNS to use UDP over much larger packets.  So that's been done.  The problem is you'll remember that, when we talked about this before, the way the existing DNS system is functioning, it is more than half saturated, meaning that all the servers that are currently in use, they have less than double capacity available.  And DNSSEC hugely is more than...



LEO:  Well, it's a hundred times bigger.



STEVE:  It's, yes, hugely more than what we have now.  So this, I mean, it really does represent a massive burden to the infrastructure.



LEO:  Does this mean it's not going to happen?



STEVE:  I mean, it's been trying to get off the ground now for years.  And it's having, I mean, this gives you a sense, as I said, I hadn't even talked about the technical side of this, which is really a problem.  I mean, this really represents problems.  Also we've got suddenly public key operations going on which we know are expensive.  All of this signing and verifying, these are public key transactions which are computationally burdensome.  One of the problems with DNSSEC is that now it becomes much more feasible to launch a Denial of Service attack against DNSSEC DNS name servers.  It used to be that you would flood them with data.  Now you can lead them on a merry chase of trying to resolve DNS records, and they'll collapse because of the computational burden of all the public key work that they have to do.



LEO:  So you've got the geopolitical issue, you've got the technical issue on the one side pushing against it.



STEVE:  And the performance issue and the bandwidth issue.



LEO:  Performance and bandwidth pushing against it.  On the other hand, you've got the whole world saying, but we need a secure DNS system.



STEVE:  Yes, well, exactly.  We need - imagine having a truly robust, secure, hierarchical database so that you could distribute, not just IP addresses, but as I was saying before, even securely distribute public key certificates.  Suddenly then, like who knows how long they would last, but I could have a public certificate that anyone, through a simple naming mechanism - and DNS names are a naming mechanism.  Through a naming mechanism it would be possible for anyone to acquire anyone else's public key and then be able to use that for any number of purposes.  It would be really tremendous.



LEO:  So what do we do?  Lobby our members of Congress?  I mean, what can you do?  Who's in charge here?



STEVE:  They recognize that there is a chicken-and-egg problem, that there would be a lot of demand for this if it existed.  But there isn't demand for it now because it doesn't exist.  There are...



LEO:  Who implements this?  Does my ISP implement this?  Do the backbone servers implement it?  Does the government?  Who would be the decision-maker?



STEVE:  Well, and that's the other problem is that, in order for this to function, every name server, every server in the chain of command, has to have an - there has to be an unbroken, essentially unbroken zone signing from the zone you want to verify all the way up to the root.



LEO:  And you know how well it worked when we moved to IPv6 and everybody just jumped on that bandwagon.



STEVE:  Exactly.



LEO:  Clearly this isn't going to happen, not for a while.



STEVE:  Exactly.  And, now, there is sort of a funky alternative approach which - and the acronym is escaping me right now.  We're in acronym soup today.



LEO:  I think we talked - did we talk about it when we talked about this?



STEVE:  No, it's DLV.  Oh, it's a lookaside approach.  The "L" stands for "Lookaside."  The idea being that ideally you'd like to have a single coherent hierarchy where at every level in the hierarchy you have keys, and you're able to verify - by simply knowing the public key of the root, you can then verify the entire hierarchy yourself, just like by knowing the public key of a certificate authority you can then verify the entire chain of authority all the way down.  However, it's recognized that this effort is stumbling because of the issue of the requirement to have one single central authority, and no one can agree geopolitically who that authority is.  So there is a counterproposal that allows the so-called "lookaside" technology, where somebody like the ISC, they would maintain their own servers.  And so GRC would develop its own public key and private key pair, and we would provide, securely provide the information to ISC, that is, our public key to ISC.  And then GRC would use DNS naming.  For example, it would be GRC.dlv.isc.com.  And so any domain could be subsidiary to ISC - I'm sorry, to ISC.org, could be subsidiary to dlv.isc.org.  And that would allow someone to, first of all, then you would only need ISC's public key in order to verify their signature of GRC's public key in order to get GRC's public key to verify GRC.  So basically it's a mess.



LEO:  It's a lookaside.



STEVE:  It's a lookaside, or lookaskance.  It's a non-hierarchical alternative to the hierarchical approach.  Not as good; but, I mean, still gives you provability.



LEO:  Would it be more robust?  Because the problem with the hierarchical approach, as we've talked about before, you knock out the top, everything collapses.



STEVE:  Well, the benefit of the hierarchical approach is that it scales.



LEO:  It's efficient, yeah.



STEVE:  Yeah, the problem here is that ISC's servers would come under tremendous burden because they would have to field a query from everyone who wanted to verify any domain...



LEO:  Oh, so it's even more vulnerable because, again, you have that choke point.



STEVE:  Yes.  Yeah.  Well, it would be bandwidth vulnerable.  They would be signing, for example in the GRC example, they would sign our public key once and then maintain that as a static record.  So anyone would have to have their public key, and then anyone wanting to verify that would have to be doing a public key operation.  But that would still be the case even in the hierarchical arrangement.



LEO:  You wouldn't need - would you need fewer check-ins with this system?  I mean, does the key stay good?  Or do you still have the same time-to-live issues where you have to update it regularly?



STEVE:  Ah, as a matter of fact we didn't talk about that.  But you have - you still have TTLs.  But then you also have relatively short lifetimes on the keys.  There are two classes of keys.  I mentioned key-signing keys and zone-signing keys.  It turns out that some of them, for security reasons, have to have lifetimes as short as 30 days.  So then you've got to be rolling keys over where you have replacement keys that overlap the valid times of the keys they're replacing.  I haven't gone into the detailed technology of this because, I mean, it's really, I mean, even what I've described is rather mind-numbing.  But the technology of this is even more so.  But they've worked out the details, and it exists, and it's clearly and cleanly described in RFCs.



LEO:  Is there a likelihood that either of these systems will be implemented in the near future?  I think we're just going to stumble along with what we've got.



STEVE:  There is one alternative approach that has been proposed.



LEO:  Oh, boy.



STEVE:  Yes.  Which is...



LEO:  Another one.



STEVE:  Which, well, it involves not relying on a sole signer of the root.  Because remember, and we've seen this before, it's possible to have multiple signers of a single object.  And then you're not - then you're able to decide...



LEO:  Ah, I like that.



STEVE:  ...whom you want to trust.



LEO:  Right.



STEVE:  Okay.  You like it.



LEO:  That's kind of like PGP.



STEVE:  Exactly.  So here it says - again I'm reading from this paragraph because otherwise there's no way to explain it.



LEO:  Well, this could solve a lot of things because you could have - Russia could sign as well as the U.S.



STEVE:  Yes.



LEO:  You don't have this single point of failure.



STEVE:  Yes.  "Instead of a single RKO" - that was the root key operator - "we propose that multiple independent non-governmental RKOs be responsible for generating KSKs" - which are the key signing keys - "and ZSKs" - which are the zone signing keys that I've just talked about.  Just believe, you know, just for now just take it as a fact that they exist.



LEO:  Yes.



STEVE:  "...and transmitting the public portions of these keys to the root zone maintainer for construction of something new, a root key set.  The RKO, that is, the root key operators, would be also responsible for distribution of the public portion of their key-signing key, which is the trust anchor globally.  So once constructed, the root key set would be distributed to the RKOs, the root key operators, for signature over all the key sets.  The signed root key set is then returned to the RZM, which is the root zone maintainer, for inclusion in the RZF, the root zone file.  Each root key operator will then sign a copy of the root zone file using the private portion of their respective zone signing key and transmit it back to the root zone maintainer, who will merge the files."



LEO:  Certainly.



STEVE:  "All of the exchange" - you knew that was coming.



LEO:  Of course.



STEVE:  "All of the exchange of data between root key owners," I'm sorry, "root key operators and the root zone maintainer would occur on secure, out-of-bound channels."  Anyway, the upshot of this is that we would end up with a master root zone file that had been essentially signed by as many participants, nongovernmental participants, as wanted.



LEO:  Yeah.



STEVE:  And then you could use any of those participants' public keys to verify the integrity of the globally master root zone file.



LEO:  Even the Hong Kong Post Office, if you will.



STEVE:  And then no longer be forced to trust, for example, just in any single entity.



LEO:  I like this.  This has worked very well for PGP.  When you create a PGP key, in fact, people even have key-signing parties.  You ask people who know that this is you to sign the key and to add trust to that key.  It's a trust model.  And I think it works very well.  And of course you decide as the user - now, end users aren't going to know who to trust.  End users are going to make that decision, Microsoft's going to make that decision, or Safari, or Firefox.  But they would probably have, in the same way they do now, right, a set of trusted key signers.  Right?



STEVE:  Yes.



LEO:  I think that that seems like a good system.  That seems like it's implementable.  It distributes the burden.  It's global, not U.S.-centric.  Is this kind of a favored system?  It seems like one that could actually work.



STEVE:  Yes.  And that's the direction that we're heading in because, I mean, for now, for a couple years, the problem of who's going to be the sole arbiter of the root has just been a nonstarter.  I mean, it's just...



LEO:  It can't be the U.S.  It just can't.



STEVE:  Yeah.  And we're not wanting it to be anybody else.



LEO:  Right.



STEVE:  So that kind of multiple overlapping signatures is probably the way it's going to evolve.  Right now there are some countries that have their own top-level domains signed and are using DNSSEC.  The problem is that it's not global, that is, in order for me to trust, or any name server to trust any of their children domains, for example, underneath I think Sweden is .se, and I think Sweden does have DNSSEC running at their top level.  So for any of the domains under - for an external name server, random company, random ISP in the U.S. to trust any of the domains underneath .se...



LEO:  They'd check with the domain server, the key server at domain .se, the Swedish...



STEVE:  Exactly.  They would need to have .se's public key, that is, they would have to know it.  And they have to securably know it.  That is, spoofing that becomes a big problem.  That's what you have to absolutely prevent.  So you need a secure way to get the public key of the .se server.  And the problem is, and any other servers that are not the root.  So it makes much more sense if everything descends from the root.  Then all you need is one public key that could be globally known, and some mechanism for updating that periodically because you don't want to have to have it last forever.



LEO:  Okay, good.



STEVE:  So those are ultimately...



LEO:  Sounds like we've got something that could actually be workable for all parties.



STEVE:  It could be workable.  Don't forget, though, we've got computational problems.  We've got DNS server deployment problems.  We've got bandwidth problems.  I mean, there's...



LEO:  So this would sit on top of a DNSSEC solution that would have to resolve the UDP/TCP issue, that would have to resolve the bandwidth issues, things like that.



STEVE:  Bandwidth and computational burden of essentially moving - and for me it's phenomenal to look at how simple the system we have now is.  And what you have to do...



LEO:  It's amazing that it's worked for so long.



STEVE:  Yeah, I mean, it does.



LEO:  You and I have talked about this vulnerability, we don't talk real loud about it, but the fact that these 13 root servers, if they could be DDoS'd for a day, the whole 'Net would go down.



STEVE:  And they've been DDoS'd for short periods of time, and it's a problem.  But that has been - they are actually not physically 13.  There are 13 IPs, but they've got much more hardware behind them.  And that infrastructure has been hugely strengthened over the years so that it's much more difficult to actually mess with them now.  But it's a perfect point is that, for example, I'm running my own independent resolver here.  So I'm not depending upon any ISP's resolver.  And my local DNS resolver knows those 13 IPs.  Those are the 13 root server IPs.  And every so often, not often, it checks in with them to update the record of the top-level domains in order to get that from them.  And so the same sort of thing has to happen in DNS.



And as I was saying before, it's remarkable to me how bad it gets when you really want to apply security to this system.  I mean, it's so simple, relatively, to have DNS work the way it does in this sort of "trust everyone" model and give me an IP for a domain.  When you really, really want it to be cryptographically secure, it's incredibly burdensome for that to be added to the system.  But, boy, with the chicken and egg, you know, once we do, we get something really valuable.  We get a phenomenal ability to have a globally distributed, secure database.  And ultimately I think it's clear that's where the Internet's going to have to be.



LEO:  We've got to do that.  I mean, we can't not do this.  Well, this has been a very interesting conversation.  Of course a difficult one to follow.  But, as usual, you do a great job explaining it.  And I'm watching the people in the chatroom going, what's he say?  What's going on?  What's it all mean?  But we figured it out, I think.  Hey, Steve, thank you so much for making that clear.  And I understand, you know, somebody in the chatroom did mention that the U.S. government has said it's going to deploy DNSSEC, I mean, that that is - that the White House says we're going to do it.



STEVE:  Well, .gov and .mil, I know .gov, I think .mil, those two top-level domains will.  But again...



LEO:  They can do that unilaterally because those are both U.S. domains.



STEVE:  Yes, but not the root.  And so there again, anyone who was - anyone within that system would have their servers configured with the public key of the .gov domain and the .mil domain and would then be able to authenticate any records coming from within that structure, but not outside that structure.



LEO:  Thank you, Steve Gibson.  You're the man.  If I ever need anything like that explained, I'm going to you.



STEVE:  Or just tune in next week for...



LEO:  Another thrilling edition.  Next week we'll answer your questions.  And again, let's underscore this, GRC.com slash...



STEVE:  Feedback.



LEO:  Feedback.  GRC.com/feedback.  Hey, while you're at GRC check out of course SpinRite, the best, the one, the only - I have now a policy that every hard drive that gets deployed at TWiT gets SpinRited before it gets deployed.  And that just gives me a nice feeling to know that we're going to map out bad sectors.  We're going to have much more reliable drives.  And since we're recording all the video now on a new drive every week, I think it's fairly important to do that.  GRC.com.  Get your copy of SpinRite, the world's best disk maintenance and recovery utility.  Also while you're there, lots of free stuff.  ShieldsUP!, lots of free programs like Wizmo.  And let's not forget 16KB versions of this very show, show notes as well so you can follow along, and transcripts, too, thanks to Elaine.  It's all there.  GRC.com.  Steve Gibson, thanks for joining us.



STEVE:  Talk to you next week, Leo. 



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#164

DATE:		October 2, 2008

TITLE:		Sockstress

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-164.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss a class of newly disclosed vulnerabilities reported to exist in many operating systems' implementations of the fundamental TCP protocol.  Two security researchers, claiming that they could not get anyone's attention, disclosed far too much information in a recent audio interview - leaving little to the imagination - and exposing the Internet to a new class of DoS attacks.  They'll certainly get attention now.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 164 for October 2, 2008:  Sockstress.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!.  This is the show which helps you, we hope, understand how security works and protect yourself online.  Here he is, king of security, Steve Gibson, from his fortress...



STEVE GIBSON:  Sometimes it may confuse you, but we try to do our best not to have that be the result.



LEO:  I think that when people listen, and they don't understand, the universal reaction - and I include myself in this, Steve - is that it's our fault, not yours.  You do a very good job of explaining it.  And these are just difficult subjects, and sometimes so difficult that you just, you know, you can't understand it.



STEVE:  The only thing I would wish for, and this is just not practical, would be like a rehearsal of the whole thing.  There are some topics...



LEO:  We can rehearse.  You want to rehearse?



STEVE:  No.  No.



LEO:  It's too much work.



STEVE:  That's my point is that, I mean, there are some things that I've tackled where I have afterwards been unhappy with my own presentation, thinking okay, you know, now that I've done it once...



LEO:  I think that's true.  I think that's true.  Sometimes - and I blame myself in that case because I think I could probably say, well, let me go through this and make sure I understand it.  I'll do that more also.  But Steve, a standing invitation.  Anytime you want to - you say hey, I think I could do that better - I'm here.  I'm here all day, all night.  Sometimes it seems that way.  So just give me a holler, and we'll do it again.  Because I - these are sometimes complicated.  Very complicated.  Now, today we have a kind of a shocker.



STEVE:  We have a shocker.  We're not doing a Q&A today.  Something happened just today, and all of our listeners are going to be writing to us asking, if they're not writing right now, asking oh my god, have you heard about this, what does it mean, blah blah blah.  The other reason I want to talk about it is there's a huge amount of confusion that has already surfaced.  Basically a couple of security researchers are claiming, and I'm believing them, that they have found some serious problems in, they're saying, every TCP stack that they have looked at; and that they are able to bring sites down with essentially a low-bandwidth denial of service.  And if you put "sockstress" into Google, you'll find pages.  This thing just happened today as a consequence of an audio interview that they gave.



What I'm really unhappy about is that they let the cat out of the bag.  They did not handle this in the way Dan Kaminsky did.  As I'm listening to this MP3, I quickly understood what it was.  And I was thinking to myself, okay, stop talking.  Stop talking right now.  Don't say anything more.  But they kept talking.  And...



LEO:  Well, this is what you get from a guy named CrackersChild.  I mean, clearly the guy's not a white hat.



STEVE:  Well, they're - we'll talk about this during the podcast because - and I'm going to explain to people what it is that they've done because the cat's out of the bag.  Anybody who was a packetsmith, who is the kind of person who could implement this, all they have to do is listen to this audio, which is now spread all over the web, and they will...



LEO:  That's terrible.  That's very irresponsible.



STEVE:  It's really irresponsible.  I mean, they...



LEO:  So you're saying the minute they discovered it they just said, hey, here's what we found, instead of going to the vendors and saying maybe work, as Dan Kaminsky did, maybe work with them?



STEVE:  They say they've been playing with this since 2005.



LEO:  Oh.



STEVE:  They say that they are in discussions with vendors but that they haven't been going very far or very well or something.  And then they gave one presentation sometime before.  They're giving another one on the 17th and 18th in Helsinki, and where they're going to demonstrate this.  But already in this MP3, which has been linked from Slashdot, anyone listening to it who could implement this will know how to.  I mean, I could do this in about an hour.  I have no interest in bringing sites down.  I never have.  But there's, I mean, this is easier to do than what Kaminsky found.  And it's more obvious how to do it from what these guys have already said.



So where Dan really did keep a lid on this for three months until the patches were out, these guys have not.  And what they've said means that by the end of the day attacks will be developed.  I mean, it's that easy to do this.  And they're saying they can bring any Windows or Linux or BSD box and routers down.  And based on what they've said, I believe them.  And anyway, that's the topic of today's show:  Sockstress.



And I'm going to, because this is not rocket science, and because they've essentially gotten now a published MP3 audio which anyone who has the ability to degenerate packets and understand TCP, this is all anyone needs.  This is much - they've given the world much more than Kaminsky did.  And remember, it took a week there between the time he told us there was a problem he was going to - I guess it was two weeks because it was going to be a month between the time he let there be known there was a problem and the patches came out, and he was going to release at Black Hat.  And two weeks later it had been reverse-engineered, figured out, and it was deployed.  Well, this is far more critical than a DNS spoof.  This is a serious problem with TCP and what these guys have found, which - and I haven't even verified it.  But I understand from what they've said what the problem is.  And I'm going to explain it during this next hour.



LEO:  So before we get to sockstress - one word, sockstress - let's talk a little bit about last week's show and any security news you have.  Anything going on out there?



STEVE:  Oh, yeah, bunch of stuff.  There was an article that the BBC published, a news blurb that caught my attention.  I thought - I was just kind of thinking, oh, goodness.  Turns out that somebody bought a Cisco VPN router off of eBay that was still configured with the way it had been set up when it was sold.  So he takes it home, plugs in it, hooks it up to his network, and he is connected into the internal private network of the VPN router's prior owner.



LEO:  Oh, whoopsie.  Oh, dear.



STEVE:  So the story reads, "Andrew Mason, from security firm Random Storm, bought some network hardware" - which happened to have been a Cisco VPN router - "from auction site eBay," okay, for, like, less than a pound.  He paid nothing.  He paid, like, scrap money for it.  "When he switched it on and plugged it in, the device automatically connected to the internal network of Kirklees Council in West Yorkshire.  Kirklees Council called the discovery 'concerning'" - it's a bit of a concern, yes - "but said that its data had not been compromised."  So anyway, just a little heads up.  You definitely want to remember to wipe the memory and configuration of anything like that.



LEO:  Is it pretty easy to do?  Must be, I mean, there must be...



STEVE:  Oh, yeah, you just return to factory settings, and it would forget everything it knew.  I mean, obviously it had the IP address and the VPN keys, the security keys for their VPN server, and just linked itself into their network and said, ah, now you're part of our network.



LEO:  Well, you know, I do that - I don't know if this is - I guess it's related, with Secure Shell, with SSH.  It's secure if you set it up so that you just log in, you don't pass a password along, it just recognizes your thumbprint; right?



STEVE:  Yup.



LEO:  But if you give somebody that machine, and you don't erase that stuff, it's just going to log right in, say hello.



STEVE:  Yes, yes, yes, yes, exactly.



LEO:  I'm here.



STEVE:  In two other little blurbs, I wanted to mention that a lot of our listeners wrote in to inform me that Phorm was back, the P-h-o-r-m.



LEO:  Oh, no.



STEVE:  It turns out that BT, British Telecom, is going to fire up another Phorm test, this time with opt-in, which is all anyone wants.  There's still some concern that most users just click "Okay" without reading the text.  But now Phorm has said that they're going to do a test.  They want to find - they're going to select basically at random 10,000 users.  And so those 10,000 people, when they attempt to get on the 'Net, their browser will be intercepted with an intercept page.  This is exactly what I was describing when we were discussing this months ago.  I said, look, this is all they have to do to make it okay.



So their browser, which attempts to get to the 'Net, will be intercepted because of course this is all network interception technology that Phorm is bringing.  And so there'll be a page that comes up and offering them to opt in.  Apparently now Phorm is attempting to promote this service as a benefit to the customers by saying, oh, that we're also going to give you antiphishing protection, that is, if you try to go to - since we're monitoring everything you do, if you go to a site that is a dangerous site, we'll give you some sort of interception warning.  So they're promoting it as we're going to enhance your web security and blah blah blah.  But at least it's an opt-in now instead of it being surreptitiously behind everyone's back.



And you know that our U.S. Congress has raised the alarm and said, wait a minute, folks, we need to look at this whole notion of third parties being involved in monitoring ISPs' traffic.  So Verizon, AT&T, and Time Warner Cable have all stated to Congress that, if they ever do this, they promise to make it an opt-in system and never do it without their subscribers' knowledge or permission.  Again, the problem is that so many people are just used to saying, okay, fine, clicking on anything that comes up that stops them from getting to the page they want to, that they may not read the fine print.  But this is certainly all you could ask for from an ISP.  I mean, you might want them to have another screen come up and say are you sure.  But that seems unlikely.



LEO:  So you're content with this.  You think that this is adequate to make Phorm acceptable.



STEVE:  Well, you know, the problem with Phorm, remember, is that it is really nasty in terms of what it does with cookies.  It inserts their own cookies, in addition to any website cookies, to any place you visit.  So, I mean, it really messes up the computer of any client that filters through a Phorm-using ISP.  But again, people will - I hope they explain that they're using Phorm, that they're, like, saying we're going to be using the Phorm system.  Because the point is it has gotten such bad press in the U.K. that a lot of people would know, well, maybe I don't want to do that.  I don't want to click on Yes.



Oh, and you can opt out.  When you opt out it puts opt-out cookies on your system.  And the question would be then is it going to put an opt-out cookie for every ISP?  If the technology functions as we described it, they would need an opt-out cookie for every ISP.  So even if you opt out, you would still be gunking up your system.  You'd just be gunking it up with please-don't-track-me, please-don't-track-me, please-don't-track-me cookies, instead of this-is-who-I-am cookies.  So the whole idea just is really distasteful.  And it's unfortunate that this is the way they've implemented the technology.



I did see one blurb that said that they've determined, however, that the load on their system from all this filtering would require, in the case of British Telecom, as many as 300 additional servers in order to handle the additional traffic.  I mean, all of this bouncing around and redirecting and cookie insertion and deletion and all that nonsense, I mean, it does pose an overhead.  And that does imply also that customers are going to see some reduced performance.  Because if any ISP needs an additional 300 servers, that says that those servers are busy involving themselves with traffic that they're not having to now, which says, okay, there's going to be some overhead for every single TCP connection you establish with a remote web server.  The only good news is that SSL connections are still safe.  They're not intercepting any sort of secure connections.  So it sort of says get a secure connection every time you can because then you're not being filtered in any way when there's no opt-in or opt-out nonsense.



LEO:  Is that because they can't?



STEVE:  They really can't, yes, they can't.  I mean, the day that our ISPs require us to accept their own certificate authority so that they can terminate the SSL connections and filter that, okay, that's the point where you just say no, that's really not okay.  There are, of course, corporations who are doing this, but that's within their own domain.  I think that's...



LEO:  Well, and ISPs could do it by redirection; right?



STEVE:  Well, no.  ISPs, in order for it to function, they have to terminate the remote connection to the web server and then set up a new SSL connection.



LEO:  A new certificate; right.



STEVE:  So they would have to give us a browser cert that said that their servers are authorized.  It would be a mess.  But it can be done.



LEO:  So in fact that's what Opera Mini does, as I remember.  Opera Mini, we learned, is not secure with SSL connections because, as part of their proxying scheme...



STEVE:  Exactly.



LEO:  ...they do exactly that.  They have their own certificate.



STEVE:  And my last little bit of news, I thought it was interesting that RealDVD has already been hauled into court by Hollywood.  You'll remember that RealDVD was a new piece of software being offered by Real which would allow people to decrypt and copy DVDs to their computers.



LEO:  But, but, but keep the copy protection on it.



STEVE:  Uh-huh.  And Hollywood has said, yes, well, sorry, but you have violated the DMCA, which...



LEO:  Well, technically I guess that's true, yeah.



STEVE:  Yes, they had to reengineer it, and they had to decrypt it in order to then put their own encryption on it.  So their argument was, but this is fair use.  This falls within fair use.  And Hollywood is saying, uh, we don't like it.  So they've sued each other now.  And in fact Real sort of did a preemptive suit, apparently filed a suit looking for a judgment on the fact that this was okay.  And whereupon the Hollywood people said it's not okay, and they sued them for copyright infringement and violation of the DMCA.



LEO:  Now, they may win that case because there's one other, I think, related case, and that was the DVD Jukebox case; right?



STEVE:  And that's what allowed them to think they might be able to get away with it.  But it'll be interesting to see, once this is tested, how it comes out.



LEO:  So this was a device that was a DVD Jukebox but didn't use the disks.  It copied it to a hard drive.  And the judge - they sued, of course.  And the judge said, no, no, this is okay because it's not accessible in any other way, it's just it's on the drive.  It doesn't give somebody access to the data.  They still have to have the disk originally to make it, and they can't access the data in other ways.  I guess the concern would be you'd go out and you'd rent a bunch of movies, copy them over, and then could burn the movie.



STEVE:  Ah, right, right.



LEO:  That would be a concern.



STEVE:  We've had a bunch of security updates.  Firefox has moved from 3.0.2 to 3.0.3 and fixed a number of things.  Mozilla also had a round of updates.  And Java for Mac had a big, 136MB update.  In this case it was fixing two serious vulnerabilities which had remote exploit aspects to them.  So I just wanted to let anyone know who's using Firefox or Mozilla or Java that they're going to want to make sure they're running up-to-date code because those have all had significant fixes.



LEO:  It's amazing.



STEVE:  I did want to mention also, just acknowledge to our listeners that you and I and Dane and Tony and everybody know about the half cut-off of last week's Episode 163.  It caused some confusion, and I heard from a lot of people that they only got half the podcast.  And...



LEO:  Yeah.  Thank you, actually, for bringing that up.  So I guess we inadvertently cut off the upload, and so only half the podcast was there, actually.



STEVE:  Right.



LEO:  And what we do in a case like that, just so people understand, we can fix it, but we are on caching servers.  So AOL uses Akamai as a caching server.  And Steve, actually I'd love to get some insight from you or maybe one of our listeners on this.  You know, I would think in theory a cache - the way a caching server works is there's a primary server, which is what we upload to.  And then when you request it, your request is actually forwarded to a server that's geographically near to you.  That server, if it has a copy of the file, will just serve it directly to you.  If it doesn't, it will go to the primary server - it's kind of like DNS - get it, download it, and then serve it to you.  There are some problems with this, though, because while you would think a caching server would be smart enough to do some sort of hash or MD5 hash or CRC or something to say...



STEVE:  Even a timestamp.



LEO:  Yeah, is this the same file.  Apparently it doesn't.  If the filename is the same - at least this has been our experience.  We can't quite figure it out.  If the filename is the same, it just says, oh, I've got it.  And so if we do - if there's a mistake, which happens frequently, or we cut something off, sometimes the server that's the caching server itself will get a bad copy for whatever reason.  And it will continue to serve that bad copy.  So from time to time I'll get reports.  And it happens, for instance, to the Akamai server in Florida more than others.  So I'll say, when somebody says I got a truncated version, and I'm only hearing it from a few people, I'll say where are you, and they'll say often the same location.  That's because your local caching server happens to have a bad copy.  The only way we can figure out to fix this is to post it a second time with a new name.  So what we do is we append a letter, usually "A."  Unless we make this mistake more than once, just "A."  So it was SN-16, whatever it was, 2A...



STEVE:  Yeah, SN-163 was last week.



LEO:  ...3A.mp3 instead of just 163.mp3.  And in order to do - the reason we do that is then we change the feeds; we change the link on the website.  The caching server now gets another copy with a different name.  It thinks it's a different file, which it is, and will serve you that one.  So if you accidentally - and we fixed it within 12 hours.  I got enough emails the first thing in the morning, I went, whoa.  It happened overnight, unfortunately.  So what we do then is we put up the second version.  But you may have already downloaded the first version.  So that's where the confusion probably comes from with people who got two copies of 163.  Listen to 163A, that's the full version.  163 is damaged.  I do apologize for wasting your bandwidth.  Just it was a mistake on our side.



STEVE:  Also I have a little bit of sci-fi news.  I know that we have a strong sci-fi subculture among our listeners.  So I wanted to mention that Fox's new "Fringe" series continues to be really fun.  I notified our listeners about it beforehand, I think.  And I just continue to enjoy it.  And I also wanted to give everyone a heads-up that the reason Amanda Tapping has left, completely left the Stargate series is that she's moved to a new show that is premiering this coming Friday, which will be the day after this podcast goes live, on Sci-Fi Channel, called "Sanctuary."  And so the two-hour premiere of "Sanctuary" is airing.  The show is interesting from a technical production standpoint in that it is massively virtual.  I've seen a little bit of "Making of Sanctuary" stuff.  They've been teasing us during some other sci-fi shows.  And it's, for example, showed some of the actors standing around in just this room of green screens where everything was matted onto these green screens.  And so all - they're doing all their acting and motion stuff with no scenery at all, which is all added later.  And I know nothing about the show except that I think the sanctuary is a sanctuary for monsters.



LEO:  Uh-oh.



STEVE:  Of varying descriptions.  I mean, like, you know, so this is like where monsters go to seek sanctuary.



LEO:  Cool.



STEVE:  And the plot goes from there.  So it does sound like it could be fun.  And there's another show on the BBC which I've been enjoying, "Primeval," which is also taking advantage of a lot of CG stuff, computer-generated graphics, like for all of the monsters.  And I have to say I'm really impressed with how the technology has evolved so that weekly shows are now able to offer us the kind of things that we used to need to go to feature films to see.  I mean, it's not the quality of high-end feature films in terms of special effects.  But, I mean, it's very passable for a weekly.  And it certainly gives us sci-fi fanatics something more.



And, finally, my last little tidbit is that I just happened to go over to the website of one of my favorite authors, Michael McCollum, who I've talked about for years.  He's the guy at SciFi-AZ.com who does the eBooks and also publishes paperbacks.  He has been really gratified with the attention that I've brought to his work to our listening audience.  And I was just sort of curious.  I go every few months when I wonder what's happening with the third book in the Gibraltar series.  And I was met with some delightful news, reading from his page.  He says, "After a too long gestation period, 'Gibraltar Stars' is well launched and moving steadily forward."  His first one was "Gibraltar Earth," and then "Gibraltar Sun."  I've read the first one twice and the second one once because I always like to start at the beginning and reread the series when a new one comes out so I'm all back up to speed.  And this is just a fantastic trilogy, or soon to be a trilogy.  Right now it's the first two books of the trilogy.  And he said part one of the series is complete.  It's launched and moving steadily forward.  And he says "I am working on Part 2."  And I can't read it, well, okay, this page says, "The Broa have discovered that there are wild bipeds loose in their empire and they are not happy.  This will cause our heroes big problems in the future."



The series is really fun.  Essentially we discover that we, by some coincidence, haven't been noticed by a vast - we, humanity, humans - by a vast sovereignty, I mean, a vast empire of really not very nice aliens who enslave all the races that they encounter.  And by some coincidence our expanding radiosphere hasn't yet touched any of their listening posts.  And anyway, oh, it's just wonderful, you know, space opera.  So I'm delighted that he's working on the third book.



However, he says, "As I have long noted in the FAQs at SciFi-AZ, this website is an experiment.  I've always maintained that people are basically honest, and when they understand the damage done by giving out my books for free, they will not do it.  The purpose of this progress report is to let those of you who have read 'Gibraltar Earth' and 'Gibraltar Sun' know that the end of the series is in sight.  However, if this trading of my" - oh, I'm sorry, I skipped a paragraph.  He says, "And now for the bad news.  Today a reader alerted me that there are unauthorized copies of several of my books on the web."  One of the nice things he's done is he does not copy protect these.  They're in various eBook formats.  But it means that they could be uploaded by people who have purchased them from him and shared, which of course is a bad thing to do.  He says, "I checked, and the postings appear to be the work of two individuals, both of whom probably feel that they are just being friendly users of the Internet and sharing work they enjoyed with others."



LEO:  So he puts - he encodes the PDF with information about who bought it.



STEVE:  Either that, or he's just looking - I don't know that.  Maybe he does.



LEO:  I would.



STEVE:  Yeah, I would.  I mean, that's what I do with SpinRite is I just put the name of the user in the product.  And I say, look, you know, don't share this because that's - I cease to exist if it is shared.  So anyway, so he says, "However, if this trading of my work becomes epidemic, it totally destroys my incentive to put another 5 to 600 hours into the new book or write follow-on books.  If I can't sell my books, it makes more sense for me to become a full-time publisher at Third Millennium Publishing.  If you become aware of people posting my work and have access to them, please explain the damage they are doing and politely request that they take the books down.  The problem with 'trading' creative works is that you can save a few dollars today; but, ultimately, you will kill the goose that lays the golden egg."  And his stuff is not expensive.  And it's really good.  So anyway, I wanted to give another plug to this Gibraltar series.  I am so excited that I'm going to find out what happens next because he has just written a really interesting yarn here that is going to take us in some fun direction.



LEO:  Yeah, you know, it's funny, I read the first one, and I've just gotten behind because of Peter F. Hamilton.



STEVE:  Oh, yeah, that'll slow you down.



LEO:  I'm slogging my way through the Night's Dawn trilogy. I'm about halfway through now.  But it's just long.



STEVE:  Oh, you're reading Night's Dawn.



LEO:  Yeah.



STEVE:  Yeah, well, it does get, believe me, it does...



LEO:  That's a very long story.



STEVE:  Yeah, it is.  And it's fun.  I really liked it.  But I have to say I ended up - I don't mean to spoil it for you, Leo.  But it really seemed to be overly long.  And I thought the first book was the best of the three.



LEO:  Yeah.  I got, you know, I bought it on the Kindle.  So I can't - it's all together, smooshed together.  So it's just like one...



STEVE:  Ooh, big.  In fact, remember that the Sony Reader couldn't even load it.  It crashed the Sony Reader.  I did an experiment when the Kindle first came out and specifically bought it for the Kindle just to see if it would work.



LEO:  It's huge.



STEVE:  Yeah.  But you know how the Kindle shows percentage dots.  You probably haven't seen many of those.



LEO:  No.  I know I'm halfway through because the dots are now almost halfway across.  But, boy, I mean, so that's - it is, it's very, very long.  But, I mean, it's fascinating.  But it's kind of slowed me down on science fiction.  I only, you know, I read other stuff as well as science fiction.  And so I'm not making as much headway as I should.  Hey, we're going to...



STEVE:  Well, I have a - go ahead.



LEO:  You've got a SpinRite story, I'm sure.  And I know we want to talk about stress to my socks.



STEVE:  Well, that's the big topic, yes.



LEO:  So, Steve Gibson, have we got all the errata out of the way?  Anything else we want to talk about?



STEVE:  Well, we have SpinRite.  I actually ran across this report just this morning.  And, in fact, I settled down, and I was reading through my mail bag, all set to do a Q&A.



LEO:  Right.



STEVE:  When I got a note sent to me by one of the people in the GRC newsgroup that was just forwarding me a blurb that had been posted in one of our newsgroups.  We have a group that I named "linkfarm" because it's just - it's where people post links to other things.  And that's where this notice of this sockstress problem came up.  And so as I pursued that I realized - and listened to the audio file - it's like, oh, no.  We have to talk about that today.  So that's when the Q&A got postponed till next week.



But prior to that I had run across this posting that was just sent to me - it's dated the 30th, so yesterday - from someone who called himself Matthew, with a subject "SpinRite Saves a Tech from Himself."  And he says, "Hello, Steve and Leo.  I just have to start by saying how much I enjoy your netcast.  I started listening when it was a mere 32 episodes old and soon went and started from #1, as you often suggest listeners do.  I listen to most of your other netcasts, Leo, and have even branched out to others.  But I always come back to Security Now! as my favorite.  There is something about the quality of this netcast that is just precise.  I have an hour drive to work, which I'm afraid has nothing to do with traffic.  And Security Now!, well, Security Now! and Audible has made a very boring drive very enjoyable.  I actually like getting into the car.



"Steve, you've mentioned often that you do not tire of SpinRite stories.  And while mine is not so much exciting as a Navy SEAL rescue mission or as honorable as saving a family's lifetime of photos, it is my little SpinRite story.  I'm a big fan of SpinRite and have owned a copy for, well, I guess just about two years now.  I work for a local college in Southern BC and spend a lot of time dealing with staff, faculty, lab and student machines with various issues and problems.  My first move is always SpinRite.  When a machine is brought in, SpinRite.  When a client is complaining about their system, I tell them to buy SpinRite.  When it's time for lunch, SpinRite.  Okay, maybe not that much SpinRite, but close.  And that's true of just about any machine I work on.  While I admit a lot of the time the problem is not a hard drive, it makes me feel better running your tool.  It also gives me a chance to do a little research on whatever other symptoms the machine might be having.



"So over the weekend I moved into a new place, after which my own PC would not boot into Windows.  It did that great little trick of an endless boot-crash-boot loop that I know you're familiar with."



LEO:  Ugh.  I hate that.  Yeah.



STEVE:  "In panic, I grabbed my kit of software and tools and went to work.  I tried every trick I could think of - running the Recovery Console, the Repair Windows, reinstalling over top of my current installation.  I tested memory, the sound card, the video card, well, you get the idea.  And yet still the machine continued to boot loop.  Now, I don't have anything really all that impressive on my machine.  I actually reload my PC a lot, so it's not a big deal.  I'm not a torrent junkie.  I don't have lots of data that I can't afford to lose.  I do enjoy a challenge of fixing a problem.  But after four hours of tech time on this machine I decided I would just blow it away and start over fresh.



"So I grabbed my CD case and started flipping through it for my copy of Windows XP.  And suddenly I stopped, staring directly at the SpinRite boot CD.  I looked at it, a bit surprised.  I hadn't even thought of running it.  I laughed at myself and threw it in the machine, started it up, and walked away.  When I came back I found SpinRite had happily finished its task.  So I rebooted the system, and what do you know, it booted straight in.  And there you have it.  Another testimonial of the great power of SpinRite.  Keep up the...."



LEO:  Wow, that's really interesting.  Wow. 



STEVE:  So I got a kick out of the fact that here he is, anytime anyone else tells him, oh, my machine is doing something strange, okay, run SpinRite.  I'm hungry, okay, run SpinRite.  But when it happened to him, you know, he grabbed all of his own tools and thought, oh, okay, I'm going to fix this, instead of just running SpinRite and letting it fix the problem for him.  So...



LEO:  There you go.



STEVE:  Got a kick out of that.



LEO:  It's the same with me, you know, it's the cobbler's kids, you know, you always forget for yourself.  You can do it for your client.  You know what's the right thing to do.  You just forget.  Boot loops.  We have to do a thing on boot loops one of these days.  



STEVE:  Okay.  Well...



LEO:  All right.  Subject at hand is better than boot loops.  It's sockstress.



STEVE:  Okay, so here's the story.  Two Swedish researchers, Robert E. Lee and Jack Louis - actually I had his middle initial, but I took it out because, you know, of course Robert E. Lee is...



LEO:  That's the general, yeah.



STEVE:  Exactly, the famous general in American history.  They have a security research site called Outpost24.  And they're some security researcher guys.  They explain in this audio MP3 - which is now being widely listened to all over the web.  Slashdot picked it up.  It's linked to in the anchor posting on Slashdot.  It starts out in Swedish or Finnish or something-ish.  Definitely not English.  But about four minutes in it switches to English because I guess these guys speak English.  And so the interviewer, who is saying something for the first four minutes that I can't understand, switches over to English.  And then the rest is understandable.



I'm going to put a link to the URL in our show notes.  And I will probably also trim the beginning of it and host the MP3 myself just so that people can listen to it in English from the beginning, and in case the site where it's coming from becomes overloaded.  I don't know what kind of servers or bandwidth those guys have.  But I have a feeling this is going to be a highly listened-to MP3.  And unfortunately there's no doubt that it has already come to the attention of the bad guys, the black hats.



So what they explain is that somebody asked them to do some penetration testing of a large network.  And so they needed to write a large sort of distributed scanner so that they could scan a large network at once.  Well, scanning means that you create TCP connections, if you're doing a TCP scan, like for example ShieldsUP! does at GRC.  Of course, I'm no newbie to scanning.  I know all about how to do massive parallel scans.  That's what GRC does.



So these guys did - they did what they call a "userland stack," which essentially means that - "userland" is the term, for example, as opposed to the kernel, where "userland" means that you're running an application.  So they wrote a TCP stack as an application because they wanted to write a special one rather than relying on the kernel and just opening a connection through the kernel.  The reason they had to do this is that they wanted to be sending out, essentially, so much probing traffic that they would crash their own kernel if they were to do that.  So instead they said, okay, we're going to write our own TCP stack.



Well, now, this is really not difficult to do.  There's tons of source code on the 'Net.  I mean, basically any Linux source is a TCP stack.  And, for example, if you want to check to see whether a remote machine will accept a TCP connection, you just send a SYN packet.  And that's trivial to do.  And, for example, Nmap is an example of a very popular, widely known, application-level scanner which does this.  It implements a userland stack, essentially.



LEO:  Oh, I didn't know that.  I mean, I've used Nmap many times.



STEVE:  Sure.  And so basically all you need is raw sockets.  Here we have again raw sockets.  This is not something which Windows would allow you to do.  But any Linux or UNIX machine or any Windows server would allow you to just generate raw packets yourself.  So you send a SYN packet out, and the far machine sends you back a SYN/ACK, which is acknowledging the receipt of your SYN and sending you its SYN, which you then acknowledge.  And that's the famous three-way handshake.



So these guys said, okay, we want to be testing a whole bunch of machines at once.  So we don't want to need to maintain state.  That is, we want to have so many outstanding scans in progress that, when we get the SYN/ACK back, we're able to, from that, verify that this is a SYN/ACK from a SYN that we originally sent out.  What they call this is "client-side SYN cookies," or "client SYN cookies."  And we've talked about what SYN cookies were once before.  SYN cookies were an innovation, I think in, like, 1999.  I believe it was Dan Bernstein.  Now, this is the same Dan Bernstein who we've talked about recently who realized that there was a problem with DNS spoofing.  Dan is a smart security guy.  And there was a problem...



LEO:  Dan Bernstein or Kaminsky?



STEVE:  No, Dan Bernstein.  Yeah, Kaminsky, of course, is the hacker who realized what the problem was in DNS.  Dan Bernstein is the security researcher who said source port randomization for DNS servers...



LEO:  Oh, he predicted the problem, yeah.



STEVE:  Yes, yes.  And he has his own DNS server that he put together with the highest level of security focus which was never vulnerable to the DNS spoofing problem because, he said, 16 bits of entropy, which is contained in the DNS transaction ID, is not sufficient.  So use that and a random source port and you get 32, which is, you know, makes spoofing enough more difficult that it's probably no longer practical.



So anyway, Dan said, okay, back before this there was a problem with what's called "resource consumption."  The original denial of service attacks exhausted the resources on the machines.  They were not bandwidth-flooding attacks, which is what we have today.  They were resource consumption attacks.  Here's what was happening.  An attacker would send a SYN packet to a server. The server would say, oh, somebody wants to connect with me.  So the server would allocate some buffers to receive the data, and some other management space, basically commit some RAM to dealing with the connection that was in the process of being established.  Then it would send back - it would generate a random number to encode or to contain its sequence number, which it would store in the state tables.  And then it would send back the SYN/ACK.



Well, now, normally what would happen is that the person initiating the connection would respond with an ACK.  But in the case of this being an early form denial of service attack, instead the attacker would just keep sending SYNs.  The SYN/ACKs would come back, or maybe not even back because they could spoof the source IP.  So this person would be sending SYN/ACKs out to random places on the 'Net.  But the point is every single time a SYN packet came into the server, it believed a valid connection was going to be established, so it would allocate a chunk of RAM, and another chunk, and another chunk, and another chunk, and so on.



And it turns out that the early PCP implementations had no protection from this.  And you could simply cause them to consume either all of the machine's RAM or all of the RAM that the stack had been allocated.  And suddenly it couldn't accept anymore connections.  It was busy waiting for the ones that were so-called half open to complete their opening process, which never occurred.  And as soon as you did that to a commercial server that was online, it was in denial of service.  It simply couldn't accept anymore connections.  Sometimes it would lock up the whole system.  Sometimes the stack would freeze or go sideways.  I mean, all kinds of bad things happened when this occurred.



So the notion of a stateless connection acceptance evolved, and it was Bernstein who actually invented this first.  By bizarre coincidence, I came up with the same idea later.  I don't remember when it was.  I think it was I was working on a client for ShieldsUP!, and I was concerned that, by accepting these connections, I could be subjecting myself to a denial of service attack.  And so I independently came up with the idea of a stateless connection acceptance which I called "Genesis."  It was an acronym for something that the folks in the newsgroups came up with, which was neat.



Anyway, the way that works is, the idea is you want a server to be able to accept a SYN packet and send back a SYN/ACK packet, so that it will then wait for the following ACK to accept to complete the three-way handshake.  But you don't want to require it to have to remember anything about this pending connection until the final, that third ACK packet comes back to it.  So what Bernstein cleverly realized is that there's enough information in the SYN packet with the source IP, the source port, the destination IP, the destination port, and the initial sequence number, that there's enough bits of entropy that the server could send an ACK packet back which cryptographically encoded that information in the incoming SYN such that when its SYN/ACK packet came back to the person wanting to establish the connection, if it was a valid person, when they acknowledged the receipt of the server's SYN/ACK, the server could independently verify the information contained in that final ACK of the three-way handshake and get total confirmation of the fact that a three-way handshake had occurred because only it could have generated the SYN that matched the remote port and IP of the person wanting to connect to it.



So essentially this immediately solved the problem of this resource consumption denial of service attack.  So that's what SYN cookies are.  The SYN cookie is the name for the idea of encoding in the SYN packet from the server a cookie, which is actually a cryptographic combination that represents the data that was sent in the original SYN from the client that wanted to connect to the server.  So denial of service attacks, as we know, have not gone away.  They've changed.



LEO:  So is everybody using SYN cookies?



STEVE:  Yes.



LEO:  Oh, interesting.



STEVE:  Linux has it.  Windows has a version where, if it sees this happening, it can kind of switch on SYN cookies.  There are some mild compatibility problems with SYN cookies because there are features in TCP which are conveyed in the initial SYN packet, things like option bytes and window sizes and some things that you'd like to have the server remember.  But if it's going to be in a SYN cookie mode, where it cannot afford to remember anything from the incoming SYNs, then there were some variations later that tried to encode some of the more critical aspects of that in the SYN cookie so that that could survive.  But in general there are some mild compatibility problems.  So you'd rather not have them on all the time.  And in fact Windows adaptively turns them on when it notices that the server might be under a SYN flood condition, if it sees that its stack's resources are in trouble, like lots of half-open connections, as they're called.  It'll hit a threshold, and then it'll switch into a SYN cookie mode where it'll give up those features which it would like have, but which it can't have because it just can't hold onto state after receiving a SYN. 



Okay.  So what these guys did is they sort of did the same thing.  Now that everyone understands what a server-side SYN cookie is, these guys did something similar on the client side.  They would emit SYN packets into this vast network that they were scanning, and they would remember nothing in their own app because when the SYN/ACK came back, that would tell them that it was a SYN/ACK from a SYN that they had sent, and that they would then send the final ACK in order to complete the connection.



Now, what they describe is, and as I'm listening to this audio file from them, I mean, I've explained this in far more detail than they did.  But everything I've explained is completely understood by everyone who really understands TCP and has been around for a while.  So none of this is news.  What they then - so as I'm  listening to this, I'm thinking, okay, stop talking.  Stop the music.  Stop the MP3.  Don't say anything more.  But they kept on going.  And they explained that in their testing they inadvertently started crashing machines, that when they were doing this, machines started - and, like, routers.



LEO:  This is interesting.  So it's just an accident that it was discovered.



STEVE:  This was an accident.



LEO:  Wow.



STEVE:  And these, you know, some machines would become nonresponsive.  And they talked about dropping packets and that, like, in cases where packets were dropping - and, I mean, I instantly knew what it was that was going on.  And it was like, okay, stop talking.  Stop talking.  Don't say anything more.



LEO:  Is this because this was a theoretical possibility that you were aware of?  Or just a light went on for you, or...



STEVE:  No, it's because I really understand how these protocols work.  And I've written some TCP stacks several times myself.  ShieldsUP! is a full TCP implementation; and I've written several, several times.  And I've written DNS servers.  I just finished writing one for this DNS spoofing test that we'll be talking about soon.  And so then they talked about timers.  And it's like, oh, no, no, no, don't you...



LEO:  Stop.  Stop.



STEVE:  Don't talk about timers, please.  And they just gave it away to anybody who understands TCP.  I mean, I'm, you know, unfortunately the world is now full - well, not unfortunately.  I mean, it's a good thing.  The world is full of people who understand TCP.  But the problem is, not everyone's motivation for having an understanding of TCP is the same.  I have never had any interest in bringing down foreign machines.  I could do so easily, but that's not been my goal.  There are people who, now that this has come out, will listen to this audio.  They will know, exactly as I did, instantly, how to do this.



LEO:  So this wasn't an attack that you had thought of before.  It was a different attack, something that you hadn't thought of.



STEVE:  Well, I just - my mind doesn't think about attacks.



LEO:  But in other words, if you had been thinking along those terms, this would have - how obvious would this have been?



STEVE:  This is so obvious.



LEO:  It's pretty obvious, okay.



STEVE:  Yes.  So for example, I'll give our listeners an example of one.  And, okay, so they talk about resource consumption at the server.  They wondered what was going on.  They pursued it.  And they have figured it out.  So they have something called "Unicorn," which was their original scanner.  And then they have something that they developed called "Sockstress."  Sock, of course, is as in sockets, which is the universal term for TCP sockets, which is sort of - a socket is an abstraction of the IP address and the port number and the state of an IP endpoint on the Internet.  So they were talking about timers and about reading the Linux source code and seeing comments in the source code where the original author of the Linux stack, I don't know if that was Linus or who it was, but said okay, now, this is something we want to make sure we don't get too many of.  And so they're thinking, oh, well, it's easy to give the stack too many of those.  And so what they're claiming is, and I have every reason to believe them - as I said, in a couple weeks they're going to be demonstrating this.  They're claiming that they can bring down any server that they have aimed this tool at so far - Windows, Linux, BSD, and apparently routers.  So anything with...



LEO:  That's interesting.  Routers, too.  That's not good.



STEVE:  Well, because routers have open TCP ports.  For example, routers will typically accept BGP, Border Gateway Protocol connections, from anywhere because that's the way they exchange their routing tables.  And so they say in this audio that in some cases it'll only kill one service.  In some cases it will kill the entire machine.  And they said in one case, and this has been repeated in text that I saw in several postings, that the machine would no longer boot after they did this to it.



LEO:  What?



STEVE:  So, okay.  So here's an example.  Remember a while ago there was this notion of tarpitting.  When we had, like, Code Red and Nimda were scanning for vulnerable Windows services, there was this notion of tarpitting.  The idea would be that you would be just a random end-user who would want to hurt the people who were scanning you.  So you would deliberately open ports, and you would run this tarpitting software.  What the tarpitting software does is when an incoming SYN packet comes in, it accepts the connection, just like any TCP stack would, sending back a SYN/ACK.  Then the attackers says, oh, I got somebody here, and it will ACK back to finish the three-way handshake.



Now, what you've established at that point is an asynchronous connection between the two endpoints.  That is, either end can send data to the other.  In TCP there's something called the "window."  And the window is essentially "advertised," is the jargon used.  It's advertised in every acknowledgement packet that goes back to the other end.  What you're doing is there is a field called a "window" which says this is how much buffer space I have at my end.  And so as acknowledgements come in, each of those acknowledgements is telling the receiver of the acknowledgement how much buffer is currently available at the other end.  And that allows that end to send data, saying okay, the other guy has told me he's got 16K.  So I know that I can send as much as 16K without any additional acknowledgement.  And so as data goes out, for example, and acknowledgements are coming back, that window size may decrease because there may be less buffer.



So what this is, it's very clever.  It's part of the original TCP protocol.  And it allows each end to send ahead, that is, to send data in advance of having it acknowledged because each acknowledgement says, well, I'll guarantee you that at least this much buffer is available at the time that I've sent this acknowledgement.  Well, if you send an acknowledgement packet that says I have zero buffer, what happens is that is essentially saying something's happened at my end.  Somebody, the client, has not taken the data out of the stack.  So I'm waiting for them to do that.  In the meantime, you can't send anything more because I've got no buffer.  So it stalls the sender from sending anything.



Well, what the sender does is starts a timer and every so often does what's called a "window probe."  It sends an acknowledgement to the other end in order to get it to acknowledge.  Basically it acknowledges one less than the number of bytes that have been received, which stimulates the side that is claiming it has no space available, stimulates them to acknowledge essentially correcting the sender's knowledge of where they are in the communication, saying wait a minute, you're one byte behind, you really mean this.  In the process, the acknowledgement contains the current window size.  So essentially it's a way for one end to probe the other, asking do you have any buffer space yet.  I've got all this stuff I want to send you.  Do you have any buffer space yet?  The other end keeps saying no.



So in the tarpit system what this would do is, as soon as the connection was established from the remote server that's trying to attack you, the sender would send back an acknowledgement saying I've got no window space.  Well, that would hang the connection.  So the idea would be, if a whole  bunch of people out on the Internet, in the tarpit case, if a whole bunch of people ran these tarpits, then the scanners, the Nimda and Code Red scanners, would end up collapsing because they'd be spewing out SYN packets, trying to find vulnerable systems.  These pseudovulnerable systems would send back acknowledgements saying that, yes, I have a service.  Let's establish a connection.  But, oh, by the way, I've got no buffer space, so hold on.  So what would happen is these Nimda and Code Red scanners would end up collapsing because they would have too many connections in this state where they were valid connections, but they were never able to send any more data, and it just locks them up.  So the important point here is that in order to get permission to send data, they have to set a timer which periodically probes the other end to see whether any buffer space is available.



So with that, with the understanding that's the way TCP works - and TCP has a whole bunch of other timers.  For example, one is dropped packets.  And we've talked about this before.  If a packet is lost, then there's no knowledge because the Internet has permission to lose packets at any time.  If a packet is lost and the sender of the packet doesn't receive confirmation, it'll time out and resend.  And then it times out, like, twice as long and resends again, and then twice as long and resends again.  So those timers are consuming resources.



So it's very possible to establish a connection with a server; and, in doing so, you've established a real connection, that is, you're a bad guy, but you don't have to worry about hiding because, for example, you're in some bot army.  You're a zombie computer that's been taken over.  So you establish a connection with a computer, and you then do things that cause the remote end to consume resources, like timers.  And if you are using a so-called "userland stack," which really means just if you are generating packets yourself, your computer is not actually your computer's kernel, your computer's TCP/IP stack, which would otherwise be similarly vulnerable because, I mean, both ends would be consuming resources.  You're not consuming any resources at your end because you're using this notion of client SYN cookies so that you're not having to maintain all this state.  You encode in the communication the information that you need in order to, for example, continue sending back an ACK saying, oh, sorry, we still don't have any buffers.  Meanwhile you're sending out more SYN packets.  You're accepting the SYN/ACKs and sending back the ACKs saying, oh, sorry, that's a good connection, but we've got no more buffers.  So this is, again, this is a return to the original style low-bandwidth denial of service attack.  And assuming, I mean, so...



LEO:  How many different connections would you have to open to bring down a typical server?  Obviously one's not going to do it; right?



STEVE:  No.  One won't do it.  In one blog posting by Robert Lee, he said that their attack was rate limited to nine packets per second, distributed between 16 different source IPs.



LEO:  That's nothing.



STEVE:  So effectively less than one per second per source IP.  As you said, Leo, that's nothing.  Here's the point, is this is like a dribble attack.  You could just be sending out - you send out SYN packets; you accept the connections; and you say, sorry, we have no buffer space.  And you just keep doing it.  This passes through bandwidth limitations.  It passes through the normal flooding-style denial of service, the SYN-spoofing denial of service attacks, because you're creating valid connections at the other end and then tying up resources at the server's end, consuming none at your end.



LEO:  This is scary.



STEVE:  Yeah, I mean, I'm disappointed because - okay.  First of all, I've just, again, I haven't tested any of this.  I've just articulated an example of how this might be done, which will be absolutely obvious to anyone who listens to this audio who has the capability that I do of understanding TCP and generating their own packets.  And as we've seen with the DNS spoofing and the nature of Internet attacks now, this will be done.  There will be some, I mean, just as a challenge to demonstrate for proof of concept's sake that, oh, look, I can crash any system that I want to.  These guys say that there are different vulnerabilities in different stacks; so not all stacks, that is, not all Windows and Linux and BSD and routers are the same; but that they have never encountered one using this notion of a post-handshake protocol abuse, which is what I would call it.  The idea is you do the TCP handshake in order to get real state now being saved on the server side.  Then you do things that cause it to burn up resources.  And, for example, stalling the connection by sending back a zero window, you know, that's the first one that occurred to me because it is the tarpitting technology that we've seen before, and you can just stall the connection.  And who knows which one, if any, of the servers are vulnerable to that?  But you could also do things, essentially just not letting the connection progress and requiring the system to use timers.  And they specifically mention timers as something that is a limited resource.  And it's understandable that it would be.  But this apparently destabilizes every machine that they have come across in different ways.



Now, given that that's the case, I can't understand why they couldn't demo this to Microsoft and Cisco and, for example, essentially the equivalent of the people that Dan Kaminsky demonstrated his stuff to and make it clear to them why this is such a problem.  They also talk in their audio file about where there are firewalls and, for example, load-balancing systems in front of many servers, which are now common, where there's like a front-end appliance which is doing DoS protection and connection proxying or something, and then doing load-balancing distributing that, if they bring that down, and they have been able to...



LEO:  Sorry about that.



STEVE:  No problem.  If they bring that down, and they have been able to, then of course the whole server farm behind the appliance goes down.  So, I mean, again, as I was listening to this I was just closing my eyes, thinking, no, no, no, don't keep talking.  They're still sort of being coy about it, as if what they've just published in this audio doesn't completely describe to anyone who has an understanding of this how to perform the attack.  It does.  I mean, we will see this in a day or two.  It's just, I have to say...



LEO:  So and is there no, I mean, here I am, running a bunch of websites.  Is there nothing I can do about it?



STEVE:  That's how I feel, too, Leo.  No, there is...



LEO:  It doesn't - and we should say that this is only impacting somebody who runs a website.



STEVE:  Right, very good point.  Now, the reason end-users were so concerned about the DNS spoofing attack was that what that meant was that they could be redirected to a bad site by if their ISP's DNS server had its cache poisoned.  In this case, end-users who are not running servers or any kind of services, who have no exposed ports, are safe.  So, for example, if you use GRC's own ShieldsUP! service to check for open ports - of course that's what I wrote it for all those years ago - and you come back stealth, or you have no exposed public ports, you're okay.  But what this potentially means is that anybody who is accepting Internet TCP connections, which is, I mean, even somebody who is, like, deliberately exposing some connections, an FTP server or a web server or something - not to mention any commercial sites that by definition are exposing these services or offering these services to the 'Net.  Once this stuff gets  out there, it means that any - and given that these guys are not exaggerating.  And I believe what they're saying.  They're going to be demonstrating it, as I said, in Helsinki in a couple weeks.  They can crash the listening service or the stack or the machine, depending upon the nature of the resources that they're able to consume over on the server side.  And they can do so with very little resources at their end.   And that's the key.  You no longer need a bot fleet.  They say in the podcast that a - the example they gave that I read in a posting was this rate limited to nine packets per second.  But they also said in the audio that a single broadband user has plenty of upstream bandwidth to bring down a major server.  I mean, as strong a server as there is.  And...



LEO:  Because this isn't based on flooding the server, which requires a lot more bandwidth than the server has.  This is based on screwing with the TCP stack.



STEVE:  Yeah.  The way you can think of it is the very first denial of service attack was a resource consumption attack using SYN packets.



LEO:  SYN flood, right.



STEVE:  And just the SYN packets would end up burning up connection resources.  So we developed armor against that, the so-called "SYN cookies" and other kinds of stateless connection approaches, so that you were protected from a SYN flood.  Okay, so but the problem was the stack behind, the rest of the stack behind that never got hardened.  So what these guys are doing is they're saying, oh, let's go ahead and accept the SYN - we'll accept the TCP connection, establish it.  Now, by the nature of TCP, the fact that you have to be able to retransmit lost packets, that means you have to have state.  If someone says I've got no window available, you have to probe them, asking to see if they've now got window available.  You have to have timers by the virtual definition of the TCP protocol in order for TCP to function in all kinds of different ways.  So what they've done is they've come up with protocol, TCP protocol attacks on the protocol itself that so far they claim no machine is invulnerable to.  And this is bad.  I mean, and so this is why I said, okay, wait a minute.  I think I got to, like, question #6 of today's Q&A, assembling the questions.



LEO:  And then you said, whoa.



STEVE:  I said, okay, stop, hold on, wait a minute.



LEO:  So, now, this wouldn't be so hard to fix.  I mean, all you have to do is fix the TCP stack to do something with these window requests; right?



STEVE:  Yes.  What will be necessary, and it's unfortunate, again, I just - I don't understand why they went public with this, but they did.  What you would need is you would need to harden the stack so that it has some strategy for dealing with this.  Now, the problem is, first of all, if this was one attacker, if it was one attacker attacking Yahoo.com, well, we've got his IP address.  So it's easy just to immediately blacklist him.  And so, okay, and not only that, but we know who he is.  So you'd be dumb to do this because you're going to have the authorities knocking on your door before long.  But now we're in a different era.  We're in the era of bot fleets.  And so this technology will then immediately move to the bot fleets, where...



LEO:  So it's not the hacker's computer that's doing it, it's the computers they've co-opted ages ago.



STEVE:  Exactly.  And so they've got 10,000 machines.  And no longer do 10,000 machines have to do bandwidth floods.  Now 10,000 machines can just all send out, you know, they do this stateless attack where they send out SYNs, they accept SYN/ACKs, and then they do whatever they do after the connection has been established.  So they can all afford to establish lots of connections into a single server which believes that these are all valid clients.  It's not clear that there's a technology that would differentiate from valid clients because the server is handling lots of valid clients, and here's just a bunch more that are not flooding them with bandwidth.  And the things that these guys are apparently abusing are core requirements of TCP.  Now, what you could do would be to look at hardening the stack, that is, you don't want it to collapse.  You certainly don't want it to crash your machine.  I think that case where Windows or whatever server it was that just would no longer boot, that just has to be an anomaly.



LEO:  Yeah, because, I mean, how would that crash your machine and...



[Talking simultaneously]



LEO:  ...going to have to destroy something.  I mean, it's not.



STEVE:  Yeah, it would have to make an alteration, a bad alteration to...



LEO:  Can't do that.



STEVE:  ...the hard drive.  On the other hand, I could see where, depending, I mean, if this is the case today that TCP stacks are able to bring the machine down, you could imagine that it might have been writing to the swap file and written to the wrong...



LEO:  Overwritten it or something, yeah.



STEVE:  ...space on the hard drive or something.  So anything could happen in that case.  So...



LEO:  Let me ask some questions.



STEVE:  Yeah.



LEO:  IPv6, does this change anything?



STEVE:  No.  And in fact they talk about that they've - the interviewer during this audio gets as worried as we get, although he doesn't understand this nearly as well now as you do and as our listeners do and as I did when I was thinking to myself, okay, stop talking, stop talking, don't say anything more because you're going to - they did, they just gave it away.  He didn't understand because he got confused with what SYN cookies was and so forth.  And, you know, he's not a packetsmith.  But any of the world's packetsmiths instantly know what this is.



LEO:  And what to do.



STEVE:  And what to do.



LEO:  To exploit it, yeah.



STEVE:  Which is the only reason I've been willing to talk about it is that this is...



LEO:  They already know.



STEVE:  ...already out there.  This is not giving anything away.  And I don't even know, for example, that using a zero window size would cause a problem, but I won't be surprised if it turns out that's one of the things that you can do because it's just obvious.  And again, that's the problem is this is obvious.  And anyway, so...



LEO:  So IPv6 doesn't - it uses the same stack, doesn't change anything.



STEVE:  Yeah.  Well, and here's the problem, again, is that IPv6 fundamentally is still using TCP, and TCP has to have state and has to do things intelligently, for example, retransmitting packets when it hasn't heard back after a certain amount of time.  And in order to know how much time it has to have timers.  Now, it might be, for example, there are many ways to do timers.  I've implemented timers in many of my systems which do not consume resources in the same way that, like, dumb timers might.  So it might be that there are dumb things in the current stack implementations that could really be fixed and made much more bulletproof.  But the time then to have done that was before going public with this, rather than now, because none of that work has been done.  And this is going to take a chunk of time.  And if these guys are right, we're talking about anybody with a listening TCP port is vulnerable to having their system taken down until the stack is hardened and fixed.



LEO:  Randal Schwartz is in our chatroom, and he says that OpenBSD, they've already discussed this on the OpenBSD list, and in fact it's not an issue with the OpenBSD stack.  So it is - and we talked about this before as being the hardened version of BSD.  Apparently, if you are running a BSD, FreeBSD or NetBSD, you could copy the OpenBSD stack or, I guess, winsock, whatever they call it, the sock, and be okay.



STEVE:  Well, and we have to hope, then, I mean, that the OpenBSD guys who Randal is quoting know what they're talking about and understand everything about what these guys have done.  Because these guys have not yet said exactly what they've done.  They've not released Sockstress to the world.  And so I guess - so the hope is that the OpenBSD guys have hardened their stack, as I've been talking about, in every way.  I mean, so that OpenBSD can't be brought down.  BSD itself, the Berkeley Standard Distribution of UNIX, was mentioned by these guys.  I don't know which version of variant of BSD they were talking about.  But they have said that they can bring down BSD.



LEO:  Yeah, exactly.  And of course the other BSDs are vulnerable.  But apparently OpenBSD is not.  They do something - they don't actually implement SYN cookies.  They do something else which is kind of interesting.



STEVE:  Yeah, well, there are many - see, and here again we've got to be very careful because what I immediately saw, I mean, Slashdot, that is not known for its rocket scientists, they immediately went off sideways and had no understanding what they were talking about.  This is not about SYN cookies at all.  It's got nothing to do with SYN cookies.  And that was one of the things that confused the interviewer in this audio file was that he got locked, latched onto SYN cookies and what were client-side SYN cookies and blah blah blah.  This is, you know, it's not about what this is.  So it's important for people to understand that this is about abusing the deeper protocol behind the original handshake.  And that seems very clear from the audio that that's what these guys have done.



And so we just have to hope, for example, that the OpenBSD stack is as bulletproof as the OpenBSD guys hope it is.  And it's a perfect example of what I meant when I said "hardening the stack" because you need to, like, look at it from a worst-case vision.  Instead of having comments in your code, as apparently there is in Linux, and this was the example given, where the author says, oh, we'd better hope that not too many of these happen, instead your code wants to say, and it doesn't matter how many of these happen.  We've got it handled, baby.



LEO:  We could have a problem if too many happen.  Let's just hope not.  Hope is not a good security strategy.  So presumably Microsoft, Apple, and all of these guys are working on repaired stacks; right?



STEVE:  Well, that's one of the other reasons I thought this podcast was important was, since the cat is out of the bag, and the bad guys all know about, and Slashdot knows about it, and DSLR, DSL Reports knows about it.  And SANS has a blurb about it.  I mean, I'm hoping it's come to the attention of the people who we need to have fix it.  If not, I know it has now.



LEO:  And not hard to fix.



STEVE:  Well, we can't change the TCP protocol.  But I would say probably not - I don't know what "hard" means.  The problem is you don't want to destabilize your stack by making big changes to it.  But you want to ask yourself, for example, in the case of all these timers or any other kinds of resources that can be consumed, what happens if we've got too many connections in this state?  I think that would be the question.  What happens if we have too many connections in this state?  If it's possible to artificially put a stack's connection into a certain state, what happens if we then have a bunch of these?  And I think that's where the vulnerability is.



LEO:  Okay.  And the patch would not be for end-users anyway, it would be for servers.  It would be for...



STEVE:  Well, it'll be for everybody.  Everybody's stack is able to receive connections.  Normally people don't expose them.  Thank god Microsoft finally put a firewall into XP and to Vista so that there aren't open ports exposed to the Internet.  But what we will - every OS, and routers, I mean, routers are the other problem, too.  Because, I mean, if BGP port is open, as it typically is for routers, and many other routers have other ports open, as well, if routers are vulnerable, if the Cisco stack in IOS or Juniper's stack is vulnerable, then this is a huge problem because routers are easy to find.  A traceroute gives you the IPs of all the routers between here and there.  And it's then easy to attempt to create BGP connections, which any routers that accept that, if they've got vulnerabilities, that allows a router to be brought down.  And that creates large connectivity problems for the Internet.  So, yeah.  Anyway, all of us, every OS that does not yet have a hardened stack needs their stack hardened.  So we will get fixes for all versions of Windows, servers and end-user versions, as soon as Microsoft has them.  And we can hope that's as soon as they fix it, exactly.



LEO:  Hurry up, guys.  Very interesting stuff.  If you want to read this in a transcript, I think it might be helpful to understanding it.  I'm certainly going to do that.  And Steve's got those transcripts online at his website, GRC.com.  That's short for Gibson Research Corporation.  It's also where you find SpinRite, the world's best hard drive maintenance and recovery utility; all his great free security tools, too, like ShieldsUP!; some fun stuff like Wizmo.  GRC.com.  So do you want to do...



STEVE:  Let's just switch and do the Q&A next week.



LEO:  That's what I was going to say, okay.



STEVE:  We'll just sort of slide ourselves back.  I don't see any reason why we have to keep them on even and odd the way they have been.



LEO:  Well, because I'm easily confused.  But other than that.



STEVE:  No, see, Leo, the problem is, even and odd for Q&A, and you've got a three-advertiser rotation schedule.  So that's constantly out of phase, and it's going to get to be a real problem.



LEO:  if people want to ask questions, and I bet you there'll be a few about this, where do they go?  SecurityNow.com, I mean, GRC.com/...



STEVE:  Feedback.



LEO:  Feedback.  I couldn't remember, either.



STEVE:  GRC.com/feedback.  We also have newsgroups at GRC that are active, and I know we'll be discussing it there.  I'm sure this will be something we're talking about in each Security Now! podcast for the next several weeks.



LEO:  Until it's fixed, yeah.



STEVE:  As this issue moves forward because this is big news.  This is not good.



LEO:  Thank you so much, Steve Gibson.  And I really appreciate your willingness to kind of say, wait a minute, this is something we've got to cover; do the research; and come back and be ready to talk about it.  So thank you so much.



STEVE:  Well, I didn't want to change the show's name to Security Then!.  I thought...



LEO:  Now, right now.



STEVE:  Security Now!.



LEO:  GRC.com.  Also 16KB versions there.  And we've started a new service at TWiT which of course could be brought down by bad guys at any time, I presume, since it is a server, although it's not a web server, it's a icecast server, which gives you a chance to listen to the audio wherever you are, even on an iPhone.  Many phones support this.  It's in beta test right now.  I've applied for the name TWiT.am.  But we do audio icecast streaming of the shows as we record them live, and then overnight we do repeats.  So if you can't watch the video at live.TWiT.tv, you'll soon be able to listen to the audio at TWiT.am.  There's details on my blog if you want to start doing it now during the beta test phase.  And I've been listening on my iPhone, and it works great.  It really is, even on Edge, you can go around town, drive around and listen.  It's pretty cool.  Pretty fun.  Steve, thanks so much.  We'll talk again next week, maybe with some good news.



STEVE:  Talk to you then, Leo.  Bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#165

DATE:		October 9, 2008

TITLE:		Listener Feedback Q&A #51

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-165.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 165 for October 9, 2008:  Listener Feedback #51.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers your security online, your privacy online and off, everything you need to know about locking systems down.  Security expert Steve Gibson is our guru.  He joins us every week from his fortress of security in Irvine, California, home of SpinRite and GRC.com.  Good morning, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you.



LEO:  Good you can be here.



STEVE:  Glad that the world is still in one piece.  The market today is pretty much - it dipped down to about -243 at one point this morning, but it's back up a little positive now.  So after yesterday's harrowing 508 point slide...



LEO:  Wow, yeah, no kidding.  It's funny, I was at the gym, working out.  And as the market was going up and down.  And I kind of - I felt like as I was running, I was actually like the little chipmunk, getting the market back on track as it was...



STEVE:  Bouncing on your ball.



LEO:  Yeah, exactly.  It's kind of fun to watch the - I leave the sound off, so I don't exactly know what's going on.  But it's fun to watch the market go up and down as I...



STEVE:  Oh, that's fun.



LEO:  It's funny how, in the gym at least, and I imagine this is true even in bars and other places, CNBC has replaced the traditional golf channel, the news channels.  Everybody wants to see what the market's doing.  It's kind of a big story.



STEVE:  Yeah.



LEO:  It's a fascinating story.  So today we're going to make - I think we are going to make up our question and answer from last week?



STEVE:  Well, yes, we're going to succeed with the last week's interrupted Q&A, finish that.  We've got a whole bunch of good stuff going on.  I have a lot of preamble goodies, and about the first half of the Q&A were not from last week, they are responses to the Sockstress episode that we did.  And we've got a really great last one, like, I don't know, what I called the really bad news or something of the week award.  Someone wrote in and notified something.  And I also - so I want to talk a little bit, I want to follow up at the top of the show about my conversation.  I had a nice telephone conversation with the guys who came up with the Sockstress deal.



LEO:  Oh, good.  Oh, good.



STEVE:  I'll talk about that.  And we've got a lot of weekly news.  None that involves Microsoft, for a change.  Actually it doesn't.  Just all kinds of other stuff.  Some follow-ups from last week, some new stuff, and then our Q&A.  So...



LEO:  So let's get to the news of the day.



STEVE:  Yeah.  Well, first of all, following up on last week, the Q&A, about the first half of Q&A is sort of detailed listener feedback from last week.  So I don't want to preempt that.  However, what I did want to say is that, after we finished the audio and had it assembled, and in fact once your team had edited it and provided it to Elaine for her to begin transcribing, I sort of felt badly just that I had been really tough on Robert and Jack, the two security researchers.  I mean, I don't think I was unfair; but I was, you know, I was really tough.  And so I wrote to Robert a pretty lengthy note explaining that, you know, basically what I had said in the podcast, that I was disturbed that they had said as much as they had in their little interview that they did and, you know, that I'd been pretty tough on them.



LEO:  You gave them more warning than they gave Microsoft, let's put it that way.



STEVE:  And anyway, so I was delighted to receive email back almost immediately saying - oh, and I sent them a link to where they could listen to the audio ahead of time.  I said I'd rather you heard it from me than you heard it from other people what I said because I wanted to give them an early heads-up, just sort of as a courtesy.  And I got email back immediately saying Steve, let's talk.  Jack and I are listening to the podcast now.  I'd like to give you a call when we're through.  And I suggested Skype, and they said, nah, phone's better, and I said okay.  So we set that up.  And they...



LEO:  After all the security news about Skype, they may not trust it.



STEVE:  Well, especially we got some of that today, too, in China.  I'm sure you heard about that.



LEO:  Yes, I did, yeah.



STEVE:  So the podcast was 90 minutes, and I waited for that.  And then sort of wondered, like - oh, and in our email back and forth I said, if you're still interested in talking with me after you've heard the podcast, then by all means you can give me a call.  Well, they did call.  And they were chagrined about what I had said last week because they felt like it further amplified the chagrin they already felt over the fact that this had all become such a big deal.  We talked for a long time.  I talked to both of them.  And essentially - and we agreed to go off the record, so I'm not going to discuss any of the technical stuff that we shared.



But what I can say is that they never really intended this to happen.  They wanted to do their presentation, as they're still going to, at the upcoming conference in the middle of the month, the middle of this month of October.  And it's funny because, after listening to what I did last week, they went back before calling me and listened again to their interview, sort of feeling like, wow, we didn't think we said that much.  And of course there's lots now that has been out on the 'Net in this intervening week that has happened.  Again, lots of misunderstanding and various people, as happened with Kaminsky's DNS issue, guessing, like, what kinds of things might be going on.



So they were - I just wanted to sort of set the record straight.  They feel like it got away from them.  They didn't intend it to.  They're certainly not seeking press.  They're not trying to do any self-aggrandizement at all.  They're really unhappy that this got - like it came to the attention of the RSnake site, which then got picked up by Slashdot.  And then of course that's where I found out about it, and it just went crazy from there.



LEO:  They probably assumed, as many do, eh, it's just a podcast, nobody's going to hear it.  Or maybe they said, yeah, maybe they said more than they had planned to, just as the conversation rolled on or...



STEVE:  That's what I think did happen.  I think as the interviewer sort of seemed to be not understanding it - there was some dialogue I've seen that indicates that he really does know, the interviewer knows a lot about this; so he was just attempting to draw out more information.  So, and for whatever.  The good news is that - and we've had some email correspondence since our telephone conversation.  Everybody who should now be talking to them is talking to them.  So...



LEO:  Good.  So did they not say enough for somebody to implement it?  I mean, I got the impression that you certainly understood enough to say, oh, I could implement that.



STEVE:  Yeah.  And no.  And in fact I've seen now other things on the 'Net that I will talk about in the Q&A section of today's podcast, the first half of our Q&A, where it's clear that people are understanding what it is that they have found.  And...



LEO:  I don't want to tip your hand, but are we seeing exploits already?



STEVE:  No.  Although, in a bizarre turn, because I've been out Googling "Sockstress," kind of trying to track the story and understand what's going on, there are postings in Programmer for Hire sites, trying to hire programmers to write...



LEO:  Please write this for us.



STEVE:  Yeah.  And I'm thinking, okay, wait a minute, you know, sort of like if you're - it's not the case that somebody who could write this would be responsible enough to use it responsibly.  But the idea of somebody saying, hey, I want you to write a really bad Denial of Service attacking tool for me.  It's like, okay.  Anyway, that's out there.  So anyway, I just - I came away with a good feeling about these guys, that they certainly know what they're talking about.  They definitely found something, as I knew they had from what they were saying.  And as you remember, I was wishing that they had said less.  But it just sort of - it got away from them.  And they're unhappy that it generated the attention it did.  On the other hand, it's not clear that they were having success with the major vendors whose attention they wanted to bring it to until this happened.



LEO:  So they had tried to talk to people before the conversation.



STEVE:  Yes.  They had attempted to.



LEO:  Ah, okay.



STEVE:  But the dialogues had not developed.  And apparently they have now.  So...



LEO:  Yeah, I bet they have.



STEVE:  ...that something good came from it.  Okay.  So we have some follow-up news and some new tidbits.  In follow-ups, actually it was somebody in the GRC newsgroups posted a nice little blurb from Google's official Chrome blog.  And it reads, from Google's Chrome blog, "Google Update is automatically uninstalled on the next update check, typically every few hours..."



LEO:  Ah, that's the trigger.



STEVE:  "...after the last Google product using it has been uninstalled.  The Google Update team is working on functionality to allow Google Update to be uninstalled immediately upon the removal of the last app."



LEO:  Okay.



STEVE:  So they've felt the pressure from this delayed self-removal, and they're going to change the behavior so that when you remove the last Google thing from your system, Google Update is taken out immediately, as well.  So, and we talked about it, but there was also lots of other buzz on the 'Net about it.  So it's not - I think it was the person who was posting said, way to go, Steve, thanks for you and Leo bringing this to - making enough of an issue of it that Google had to take notice.  Certainly we probably participated in that.  But the 'Net is a big place now.  And I'm just glad that Google is responding because I think there's no reason they couldn't have this thing see that it's the last Google software that's around and just remove itself, so.



LEO:  Right, right.



STEVE:  And, for what it's worth, as I found, it is not - you don't have to have an update check occur.  You just have to have Google Update try to have an update check.  So whether it's able to contact the mothership or not, even if you have an off-the-'Net machine that was once on the 'Net when it got Google and Chrome and so forth, once it tries to do an update, even if it fails, it says, okay, well, oh, look, there's nobody else here, I guess I'll leave, too.



LEO:  It's getting lonely.  I'm out of here.  I like it.



STEVE:  Also, updating the continuing-to-evolve RealDVD saga, some interesting news.  RealDVD has now been removed from the market.



LEO:  So this is RealNetwork's attempt to create a program that wouldn't, well, from your point of view as a user wouldn't crack DVD encryption.  It has to, of course, to copy the DVD to the hard drive, but then puts its own encryption or protection on there.  And the movie industry sued Rob Glaser and RealNetworks.  And Rob has countersued.



STEVE:  Yes.  Actually it's - I wouldn't say that it has to crack the encryption to copy to the hard drive because, as we know, you can rip DVD files.  DVD files are just files.



LEO:  They just won't play.



STEVE:  They're just encrypted, yeah, the files themselves are encrypted.  But they do copy just fine.



LEO:  But isn't that why the judge said, and the lawsuit, the premise of the lawsuit was, oh, you have to reverse-engineer our copy protection, you have to violate the DMCA to do this?



STEVE:  No, because they - remember, as a player, anything that is a DVD player has to be...



LEO:  Has to be able to do that, yeah.



STEVE:  Exactly.  It's got to be able to decrypt the DVD, the CSS copy protection.  So there's a nice piece on Ars Technica that I'll share with our listeners because it explains exactly in, like, the right language where this got tripped up.  Less than a week after RealNetworks launched its new DVD ripping and archiving product, RealDVD, a court has ordered the company to temporarily suspend its distribution.  A visit to the RealDVD website, which is RealDVD.com, reveals a message from Real stating that the product is unavailable.  "Due to recent legal action taken by the Hollywood movie studios against us, RealDVD is temporarily unavailable," reads the site.  "Rest assured we will continue to work diligently to provide you with software that allows you to make a legal copy of your DVDs for your own use."  From the moment Real first announced RealDVD - this is back reading from Ars Technica - the company was aware that there would be legal questions about the product, but seemed to think that everything would be fine since the company said it had, quote, "licensed the DVD technology for a legal right to play back DVD content."



LEO:  Oh, interesting.  So they had paid for that.



STEVE:  Yes.  And just like there are DVD players, software-based players, as we know, that'll play DVDs.  But you have to have the DVD disk in the machine from which it plays.  And that's the difference.  The same day RealDVD was released, however, the company found itself in hot water with the movie studios.  Real preemptively filed a lawsuit, which is what we did indicate last week, on the day RealDVD was released in response to threats from shareholders, to which the Motion Picture Association of America, the old MPAA, responded with its own lawsuit.  The MPAA claims that Real has violated DMCA anti-circumvention rules with RealDVD, even though that product copies DVDs to a hard drive while leaving CSS encryption intact.  It turns out that the association, the MPAA, is picking a nit with the fact that RealDVD doesn't require an actual disk to be in the drive when decrypting a movie for playback, therefore allowing users to rent, rip, and return movies.



LEO:  Right.  Okay.



STEVE:  By not requiring the disk to be in the drive, Real supposedly makes circumvention of the purpose of the encryption possible.  So circumvention of the purpose of the encryption, even though it doesn't appear to circumvent the CSS encryption itself.  You know, it actually uses - it decrypts CSS, which it has a license to.



LEO:  Well, really that's poor design on the part of CSS.  It should check for a disk, and then they wouldn't have this problem.



STEVE:  Well, it's funny, too, because the executive vice president and general counsel of MPAA says, "RealNetworks' RealDVD should be called 'StealDVD.'"



LEO:  Oh, geez.  These guys.  They have to really learn, this rhetoric does not work.  It does not play.



STEVE:  So it says a temporary restraining order has been issued against Real while the judge takes time to review all the available documents.  A decision will apparently be made as to whether the suspension will remain in place and for how long, a Real representative told NewTV.  Given the tenacity of the movie studios when it comes to copyright infringement, however, the MPAA isn't likely to let the restraining order be lifted without a fight.  At least Real has one thing going for it.  The company managed to have the case moved from the Central District Court of California in Los Angeles (Hollywood's backyard), to the North District Court of California, which may give it a fighting chance against the movie studios.



LEO:  Well, to play devil's advocate, because you know I hate DRM, they do have a point.  I mean, you could use this to effectively circumvent...



STEVE:  Oh, yeah, rip and return.



LEO:  Yeah.  So I can see why they'd want to plug that hole.



STEVE:  Yes.  Now, what's funny is that DVD Decrypter, which is freely downloadable all over the 'Net...



LEO:  Then why aren't they suing them?  You know why, because they're in some other country.



STEVE:  Well, yeah.  And they're, you know, it's software, and it's out, and it's around, and there's no one to sue.  In fact, they did stop its support.  DVD Decrypter was being actively maintained for many years.  And they came down on the guy, and so he said, okay, I'm abandoning this, I'm disassociating myself with it.  I'm not doing anything more.  But, by the way, it works perfectly.  So, and I've taken advantage of it for legal purposes.  I own content.  I've got the original disk.  But sometimes it's nice to be able to repurpose it, in no way that causes lost sales of the DVD.



LEO:  Well, but that's the spirit of the law, but not the letter of the law.  The letter of the law is you can't copy them.



STEVE:  I know.



LEO:  It's a nasty little thing we get into when we start to...



STEVE:  Okay.  In new tidbits...



LEO:  Yeah.



STEVE:  We've got a little - we have some happy news about something we've talked about several times.  We've talked about how the new DHS, Department of Homeland Security, guidelines for the level of search and seizure of electronic media when you cross the border, remember we've talked about it being...



LEO:  Oh, we've talked about it on TWiT endlessly.  I mean, it's just nasty.



STEVE:  Yes.  Well, there is now in Congress, in the U.S. Congress, something called the Travelers' Privacy Protection Act, which is current legislation.  I don't think it's yet enacted, but it's in place, and it's working its way through our various processes, which would require the DHS, the Department of Homeland Security, to establish reasonable suspicion of wrongdoing before searching U.S. residents' devices.  And it would require the Department of Homeland Security to have probable cause and a court order or a warrant to hold the device for more than 24 hours.  So at least the notion of having reasonable suspicion of wrongdoing, it raises the bar way above, you know, like a random strip search of anyone who is carrying a laptop.  And they say, oh, you know, we want to - remember the issue came up because there were people who were using, for example, TrueCrypt to encrypt their drives, and the agents were saying - forcing the passwords to be revealed in order to look through people's laptops and hard drives, which will no longer be legal without a reasonable suspicion of wrongdoing.  That is, they have to have some reason to believe, you know, you can't just be random Joe Citizen and have them say, okay, we want to see what the titles of all your files are.



LEO:  Yeah.  Okay.



STEVE:  And finally, actually two things.  Skype has admitted to the reports that came out the week before.  You remember, and we didn't talk about this last week, but some Canadian researchers found evidence on Skype servers that the Chinese version of Skype was going beyond keyword searching and actually logging the conversations of Skype users whose text Skype instant messages contained keywords, and was logging their names and transactions and IPs and everything.  And so Skype has responded.  And they said, yes, they've acknowledged that they didn't realize logging was going on.  There's a Chinese affiliate that they work for.  TOM is the Chinese company.



And of course this is my great concern with anything like Skype.  It's why I've got the acronym TNO, Trust No One.  Because the fact that these dialogues, these Skype connections are running through a central server means that you're implicitly trusting Skype not to be able to spy on you and eavesdrop, instead of having a direct point to point and not using a third party.  So I just - that's another example of what happens when you do need to trust an intermediary.  I mean, you just can't tell what's going on.  The fact that they're doing a keyword search inherently means they're able to log.  And Skype apparently knew that they had provided them with keyword searching capability.  But in order to do that you have to decrypt.  And if you can decrypt, you can keep records.  So, not good.



LEO:  So let's be clear.  Skype calls themselves are encrypted and cannot be listened in on.  Is that right?



STEVE:  No.  No, this demonstrates it's not true.



LEO:  But that's chat, not calls.



STEVE:  I don't know.



LEO:  I'll tell you the reason I ask.  Garry Kasparov, the former world chess champion and an outspoken opponent of Putin, said I use Skype all the time because it's encrypted, and I know the KGB or their modern-day equivalent would be listening in, so I make sure I use Skype.  And I think there are a lot of people who feel that way.  Especially since we know that the NSA is listening in on some domestic calls, as well, on the regular phone service.  So you think that a Skype - you would not assume that a Skype call is safe.



STEVE:  Oh, absolutely not.  In no way would I make that assumption.  The only thing that you could assume is safe is a point-to-point VPN, I mean a point-to-point encryption where you know everything about and trust the nature of the way it operates, and you can demonstrate that there's no traffic to a third party.  We don't have complete documentation of the Skype protocol.  They consider that proprietary.  They don't want people making clones of what they consider to be their intellectual property.  So, no, I mean, so long as there is a third party involved, the fact that my Skype client is connecting to a mothership, is phoning home as it is - and so is yours, Leo.  You and I have a direct point-to-point connection, but we don't know that the encryption key, the symmetric key used isn't provided to Skype.



Now, the fact is that we do know that our traffic is going between you and me.  So we know that there's no copy of our traffic going to Skype.  So we can, looking at the packet flow, we know that Skype is not participating in that.  So that's certainly a good thing.  It may be the case, though, that because instant messaging is such low bandwidth, and like Skype will hold messages waiting for later delivery, it may be that all text goes through Skype central; whereas audio and video does not.  It goes point to point where it can.



LEO:  Oh, I want to add, a couple of people in the chatroom are saying what's that bill number.  The bill is Senate Bill 3612, for those who want to - the bill on curbing searches at the airports.  Travelers' Privacy Protection Act.  So if you want to send a note to your member of Congress - your Congress Critter, as Cory Doctorow calls them - that's S. 3612.



STEVE:  And tell them yay.



LEO:  Yeah, yay.



STEVE:  Okay.  And one more, you know, this is just too bizarre to be true but is.  Did you hear about the top secret camera from MI6 that was sold on eBay?  Oh, Leo.



LEO:  MI6 is a British intelligence arm.



STEVE:  It's like our secret service, or NSA.



LEO:  Yeah.  So tell us.



STEVE:  There's MI5 and MI6.  And one is internal, and one is external; right?



LEO:  Right, right.



STEVE:  So that way...



LEO:  MI6 is external and 5 is - I can't remember.  I'm trying to remember from my James Bond novels.  I don't know.  I'll look it up.



STEVE:  There was a story that appeared on TechCrunch that the Washington Post picked up.  And it's around the 'Net, so it's easy to find.  A 28-year - and I'm reading from this Washington Post column.  "A 28-year-old deliveryman from the UK who bought a Nikon Coolpix camera for about $31 on eBay got more than he bargained for when the camera arrived with top secret information from the UK's MI6 organization.  Allegedly sold by one of the clandestine organization's agents, the camera contained named al-Qaeda cells, names, images of suspected terrorists and weapons, fingerprint information, and log-in details for the Secret Service's computer network, containing a 'Top Secret' marking.  Once he downloaded the contents of this camera onto his computer, he immediately went to the police to explain the situation.  The police originally treated it as a joke, but within a week anti-terror officers started investigating and demanded that he not talk to the media about the contents contained in the camera.



"Journalist and author Neil Doyle told The Sun that the contents are 'MI6 documents relating to an operation against al-Qaeda insurgents in Iraq.  It's jaw-dropping they got into the public domain.  Not only do they divulge secrets about operations, operating systems, and previously unheard-of MI6 departments, but they could put lives at risk.'  MI6 is currently trying to track down the agent who made the mistake."  Oops.  "If caught, the agent could face serious legal ramifications and face suspension."  Oh, gee.



LEO:  I would hope so.  It's the external - it's the secret intelligence services.  It's the external, obviously.  Holy cow.



STEVE:  Yup.  So we talked last week about the VPN that hadn't had its configuration wiped, and when connected it happily connected, you know, phoned home and connected into some poor company's internal network.  And here is, like, serious images left on a camera, sold for $31 on eBay.



LEO:  Good deal, by the way, on that camera.



STEVE:  Ah.  Yeah.



LEO:  Wow.  Well, you know, I think this is a sign.  The Internet makes all of this stuff so much more out there and doable.  And I think everybody, even the most secretive agencies have to kind of pay attention in ways they didn't have to before.



STEVE:  So I've got two little bits in the randomness grab bag.  Scott in Pawtucket, Rhode Island wrote and said - and I ran across this when I was pulling together the Q&A for today:  "I realize that your mention of the Richard Matheson novel, 'I Am Legend,' and its subsequent film adaptations, 'I Am Legend' (2007) and 'The Omega Man' ('91)," both which you and I referred to last week, Leo, "was a commercial for Audible.  But I thought you and Leo might find this little tidbit of info interesting.  The original film adaptation of 'I Am Legend' was done in 1964.



LEO:  Right.



STEVE:  It starred Vincent Price, called Dr. Robert Morgan in this version, and was titled 'The Last Man on Earth.'  I listen to your podcast as much for the security and technical aspects as I do for the occasional science fiction recommendations."



LEO:  Not so occasional, but all right.



STEVE:  Yeah.  He says, "'Fallen Dragon' is now one of my very favorite books, and I have suggested it to many a friend.  All the best, and thanks for a great podcast."



LEO:  Yeah, I knew that because when the Will Smith "I Am Legend" came out there were many articles about the various adaptations of this book.  And that's what actually led me to the book in the first place was, well, I want to read the original.  And it is very different, you know.  And everybody has their own take on it, which is interesting.



STEVE:  And my last little bit of randomness is that, as you  may know, Leo, photos of Kindle 2 leaked out.



LEO:  Now, they look - I don't know if they leaked or if they were Photoshopped.  And this is something those of us who cover the Macintosh...



STEVE:  Oh,  you  mean they could be completely fake.



LEO:  Oh, yeah.  Those of us who cover the Macintosh are used to this happening all the time.  So we might have a little bit more radar than the average Joe or CNN.  I haven't seen anybody from Amazon acknowledge that these are real.  But, boy, it's the kind of thing you'd expect Amazon to do at some point; right?



STEVE:  Well, yeah.  And in fact it was you who said that there are rumors of a new Kindle on the way.



LEO:  Amazon has acknowledged that they are working on a Kindle 2.  They have said that it will be out next year.  But I don't know how forthcoming they've been on details.  And I think so far it's kind of all rumors.



STEVE:  Well, and they don't want to cannibalize their current sales.



LEO:  Well, that's the risk, of course.  So you don't want to say it's coming out in December because nobody will buy Kindle 1.



STEVE:  Right.



LEO:  So the pictures, the so-called leaked pictures I don't think have ever been admitted.  I don't think Amazon has ever said that those are actual pictures.  It's from a very big rumor site called Boy Genius Report.



STEVE:  Right, right.



LEO:  And, you know, again, the Mac people are going, yeah, yeah, we've seen it all before.  So we'll just see.  You know, it looks like something that you would want.



STEVE:  Well, I'll tell you, Leo, I have fallen in love with my wacky little wedgie.



LEO:  Yeah.  I don't mind, I've gotten over the form factor issues, which are many.



STEVE:  Yup, yup.  And the fact that it's just weird.  I mean, it's a bizarre shape.  But I look at this one - and this one, for the sake of our listeners, it's sort of a - it's, like, traditional looking, very smooth, very slick, rounded corners.  It reportedly has, like, sort of a polished, stainless steel back, like an Apple iPod does; a keyboard in a single place instead of being broken into a left-hand and right-hand sort of thumb keyboard.



LEO:  Oh, yeah.



STEVE:  Very different navigation buttons.  What's missing from the photo - which actually, now that you mention Photoshop, raises my eyebrows - is there isn't the LCD selection stripe shown on the right-hand side.



LEO:  There's a scroller, but no stripe.



STEVE:  Yeah.  So maybe they've built the scroller into the eInk surface, or who knows what they may have done.  But, Leo, I would keep what I have.



LEO:  You would, even looking at this new one.



STEVE:  I have zero...



LEO:  Did you look at the new Sony one?  The new Sony one's quite nice.



STEVE:  With the touch screen.



LEO:  Yeah, touch screen, built-in light.  Also expensive.  It's more than the Kindle is and doesn't have wireless.



STEVE:  And again, unfortunately, it's Sony.  I mean, I owned two of them before the Kindle came along.



LEO:  Me, too.  Me, too.



STEVE:  Leo, the fact that this thing, I've now got - I've added a couple blogs to my four newspaper subscriptions.  And it's just, I mean, I love - even if I couldn't read books, the fact that this thing is newspapers and really interesting blogs - and, boy, the selection of newspapers has exploded, and the selection of blogs has exploded.  There is just so much content now.  And it just, you know, and the blogs are, like, a buck or two a month.  So if the...



LEO:  I subscribe to one.  I subscribe to Salon because I never read any of them, and I still don't even read that enough.  I feel like I'm wasting my money.  Are you pretty religious?  You read it every morning, and you get through it, and...



STEVE:  I like having them there.



LEO:  I like having them there, exactly, yeah.



STEVE:  No, no.  But, I mean, but I do spend several hours in the morning reading the newspapers.  And I'll jump around.  I'll wonder what The Wall Street Journal has, or The New York Times, or the Financial Times.  And I just sort of - I'll scan the front pages.  Often, depending upon my mood, I'll spend many hours or just a few.  So, but, I mean, the sense I have coming away is I really know everything that's going on that I care to know.  So it's super useful.  And I have a...



LEO:  Super, super useful.



STEVE:  Super useful.  I have a very short little SpinRite anecdote from a David Lisney in Hertfordshire in the UK.



LEO:  Oh, I say.



STEVE:  And he says - the topic was, oh, it just came in through our regular feedback submission, which is why I know where he's from.  He said, "On the 'SpinRite Saves Lives' subject," he says, "I used it on a PC running a paging system for the London Fire Brigade.  This is the largest brigade in the world as far as the population in their catchment area."  I guess that means, like, the size of the area that they're responsible for because he talks about as far as the population.  He said, "The machine which was running our paging system, upon which we depend, had chugged away 24/7 for 10 years.  It had finally suffered a failure of CPU fan and crashed.  After replacing the CPU fan, the PC still did not boot up.  I ran SpinRite on the failed drive.  It raced through, and in under an hour the PC was booted and running again.  My colleagues could not believe it.  Ironically, this PC was due for replacement the following week.  The story is not as exciting as some you have received, but it did save a lot of head scratching.  Needless to say, the recovered machine was fine for the remaining week and has now been put to use in a noncritical area, still running the same repaired drive.  Thanks for SpinRite.  Love the show.  Regards, David."



LEO:  Well, isn't that nice.  Happy story.



STEVE:  Another nice story, yup.



LEO:  A happy story.



STEVE:  Somebody happy with SpinRite.



LEO:  All right, Steve.  Let's - whoa.  Are you ready for the questions?  There's two of me and none of you.  Let's bring you back.  Are you ready for the questions here?



STEVE:  Brings new meaning to the term "talking heads."



LEO:  Talking.  I can talk to myself on the show, and in fact I do quite a bit.  Let's see here.  I had the email, and I had it open, then I guess I closed it.  Question 1 from John Schember in Florida.  He's wondering about Vista and TCP exploits.  He writes:  Vista includes a new network stack - we talked about this when Vista first came out - developed just for the OS.  According to the latest episode of Security Now!, Vista should be vulnerable to this newly discovered TCP stack attack.  Since Vista is supposed to be the most secure Windows yet, why did Microsoft design a new stack that was inherently insecure?  Well, nobody knew about Sockstress; right?  I mean, that's something nobody really knew about.



STEVE:  Well, yeah.  It's one of the things that I keep seeing out on the 'Net.  And I tried to make the point last week, and I want to reiterate it, and that is that this is not a bug in anyone's implementation.  It's that in order for TCP to have the power and flexibility that it has, which is truly phenomenal when you consider it's a complex protocol, but it's able to - a single protocol is able to handle massively wide variations in network connection.  It can handle very slow connections; it can handle very fast connections.  It can handle connections with a short delay or with a long delay, that is where - remember that we're just sending individual packets, in the final analysis, individual packets from point A to point B, and routing across the 'Net can go a few hops or many hops.  It can go to a satellite transmitter, up into the sky to a satellite and back down where you have really much larger latencies.  And sometimes the way some of these work you have, like, downloading to you comes down by satellite, but then uploading goes back over a terrestrial link, typically modem.  So there you've got very different operations.  So each direction in TCP can basically run at its own speed and adapt itself to the network.



Well, in order to pull off that magic, the protocol has to first of all be very sophisticated, and it has to be very adaptive.  And so what these guys have done is, by really understanding the guts of the way TCP is implemented, they've been able to say, you know, what would happen if we had one endpoint that was behaving in a specific way deliberately, and then what would happen if we had a lot of those.  And so it's a combination of sort of stretching the correct operation of TCP out to sort of an edge case, and then doing it a lot.  And so it's not at all that Vista's stack is vulnerable.  In fact, it's the sophistication of modern TCP stacks that allows them to be as adaptive as they are, that actually is sort of the - is the source of part of this vulnerability.  But the vulnerability, unlike much of what we talk about, where we talk about vulnerabilities that are the result of design flaws or implementation flaws, this is just a sophisticated protocol that is inherently prone to abuse.  And so this is what makes fixing it tough because...



LEO:  Because this is in the nature of how it works.



STEVE:  Yes.  To give an example, and this is again something already out on the 'Net, and it's something that had occurred to me, but I can say it now that it's been - it's now being bandied about.  One of the things that happens with fast networks that also have latency, there's something called the "bandwidth delay product."  And we've discussed this in the past, the idea being the bandwidth delay product is the size of the pipe times the delay from endpoint to endpoint.  And what it essentially refers to is the amount of data which is in flight between the sender and the receiver.  And so if you have a fast link, and it's got a long delay, well, then you end up with a large bandwidth delay product.



Well, the way TCP works is that it acknowledges the receipt of data back to the sender periodically.  Not every single packet that comes in is acknowledged, but there are various systems.  And in fact the acknowledgement routine is adaptive, as well.  Well, when an application wants to send data, it sort of dumps it into the TCP layer.  It says here's a bunch of stuff I want you to send.  So TCP allocates buffers to accept it and then says okay, fine, to the application.  Okay, fine, we'll send that for you.  The application goes off about its business.



Now, remember that in their original podcast they talked about working TCP in the face of lost packets, high packet loss situations.  Well, TCP, the sending end, has now accepted this data from the application.  The application has gone on.  The application is able to assume that the data that's given TCP will be sent reliably.  That's TCP's job.  Well, what this means is until all the data in these buffers has been acknowledged by the other end, that local TCP stack that is on the server side, which is typically serving large files, it has to hold that data.  It can't - there's no mechanism for it saying, oops, wait a minute, to the application, can I get some of that back because the other end said it never received it?  It doesn't work that way.  TCP has accepted responsibility for delivering it and now must.  Which means it has to hold that data.



Well, there are ways to cause TCP to believe that the network bandwidth delay product is very large, meaning that it will expand its buffers in order to hold all the data - basically it's got to hold a copy of all the data in that it could be in flight.  And it has to hold it until it's been acknowledged.  So you can imagine that this is a way of causing the local TCP stack to require that each instance of a connection end up with a large buffer.  And so, again, there's nothing about TCP that's broken.  It's the way it's supposed to work.



LEO:  It's the nature of the beast.  So how do you fix it?



STEVE:  Well, that's why this is such a tough problem.



LEO:  Redesign the protocol?



STEVE:  Well, we can't do that, of course.  Because, I mean, it's out there.  It's, I mean, it is the protocol.  It's taken quite a while to put it together right and get it all working right.  What'll end up happening is that, to the degree that this is used in an attack - and we've got a couple questions that we'll be encountering next that question this, that is, even why it makes sense to use it in an attack.  But you could imagine, and as I said last week, that the vendors of firewalls are no doubt immediately revving their products to be aware of these kinds of abuses.  And so we can imagine that, with time, there will be probably preemptive protection against this.



LEO:  Preempt - in other words, the firewall has to handle it, not the stack itself.



STEVE:  Well, Microsoft has, in their later servers, in IIS, they've got more - IIS, which is Microsoft's web server, is more finicky about connections.  In IIS v5 there is a timeout for, like, a connection that's not doing anything.  And I think Microsoft, I think they default to 900 seconds, which would  be 15 minutes.  And so that's a long time to wait before giving up that connection, before the server closes the connection preemptively.  Certainly you could bring that time down.  But they've got some other, in IIS 6, which is available in their later server operating systems, there are also, like there are limits you can place at the rate at which data is leaving the system.  And if it seems too low, IIS will just say, eh, this seems kind of fishy to us.  Let's just shut down this connection.  And so there are things you can do to hopefully not introduce false positives, because you don't want to be hanging up on valid users.  But at the same time you want to be less tolerant about strange connections which might be attempting to abuse your service.



LEO:  Very interesting.  Paul Cousins in Regina, Saskatchewan had a worm counterattack idea.  He says:  Hi, Steve and Leo.  I've been a long-time listener of Security Now!, and your show about Sockstress gave me an idea.  This is going to be a little black hat and probably bordering on illegal to actually implement this.  But it's still fun to speculate.  Is there any way this new attack could be used by security firms or even individuals as a way of taking worm-infested computers off the Internet?



Now, this idea comes up from time to time, I have to say.  It's not anything new, it's just a new way of doing it.  The idea being you leave your computer open to connections.  When you identify a connection from a worm or bot-type program, you launch a Sockstress attack on them.  As I say, this is probably bordering on illegal - not bordering, it is - as you would effectively be killing off computers of innocent users.  But I wanted to hear what Leo and you thought of this kind of concept being applied to the real Internet, what with many issues of Internet background radiation, as you like to call it.  Thank you for a great show.  What is your take on that?



STEVE:  Well, okay.  The first part of his thought, that is, that we are leaving our computer open to connections, I discussed that last week, this notion of a tarpit where you would deliberately have listening ports on tasty ports that worms want to attack.



LEO:  This was the topic of the very first Security Now!.



STEVE:  No kidding.



LEO:  The HoneyMonkeys, or whatever they were - remember, Microsoft was doing this?



STEVE:  Right, right.  Windows HoneyMonkeys.



LEO:  I'll look it up.  It wasn't HoneyMonkeys, it was something like that.



STEVE:  It was - that's close, though.



LEO:  It was TWiT.tv/sn1.  And of course I don't have a very good description of it in the show notes, alas.



STEVE:  It was a funny episode, too, because you were funny on that one, Leo.  You were wonderful, I remember.  Anyway, so the idea being that a tarpit accepts a connection and then manages to stall it...



LEO:  Strider HoneyMonkey.



STEVE:  Strider, that's what it was.



LEO:  That was Episode 2, Security Now! Episode 2.



STEVE:  So the idea is that the computer accepts a connection and then stalls it, basically holding onto that connection rather than either saying no, I'm closed, and allowing the scanner to go scan somebody else, basically it sort of stalls it and keeps it in a so-called "tarpit."  Now, the reason Paul's notion doesn't work is that we've got a connection, well, there's nothing we can really do to it without engaging it in a protocol.  So in order to attack a machine, we need it to be the server, and we are the client; where in the scenario of a worm scanning us, it's looking for our open ports, that is, open service ports at our end, and then hoping to abuse a vulnerable service on our machine.



So really there's no way to switch this around on the fly.  When a worm attacks us, if it had open ports, that is, the only way that Paul's idea would work would be we get a connection from a worm.  We know that - we assume it's a worm.  And that's one of the first assumptions you need to make.  And it's not like your ISP scanning you to check for your own security or making sure you're not doing things that are against their own terms of service.  And there has been some of that going on.  But the idea would be you accept a connection.  We know it's not spoofable.  So whatever it is that's hooked to you, you've actually got their real IP.  Well, then you'd have to do a port scan of them, right on the fly.  You do a port scan of that machine in order to look for any open ports, and then launch Sockstress attacks against those open ports.  But again, bad idea because it's illegal, and you do not know who you're attacking, essentially.



LEO:  In fact, I remember there was a virus, I can't remember which one it was, that the author said, oh, no, my plan was to get the bad guys, not the good guys.  It doesn't - you're not allowed to do this.  It doesn't matter.  You still go to jail.  And it isn't a very good idea.  It isn't.



Jamie Scanlon in Venice, California was also thinking about TCP stack attacks.  What a surprise.  He writes:  Steve, I just heard your discussion on the Sockstress issue.  What would happen if the TCP stack would just not care if the client were not able to deal with a connection because the buffer was full?  My logic would be, if you don't have buffer space, you shouldn't be making the connection in the first place.  I know this is not in the protocol, but how much of the Internet would break if this were implemented?  That's kind of an interesting idea - just ignore it.



STEVE:  Well, yeah.  In fact, that's another setting that many servers have.  I'm sure we've, you know, all of us who've been surfing the 'Net for a while have typed in a URL or clicked a link, and we've come across a dumb, blank, white page that just says "Server too busy."



LEO:  Yes.



STEVE:  What that "Server too busy" message means is that there's an administrative limit, that is, whoever it is that's running the server, for whatever reason, said we're going to accept only this number of connections.  Presumably they're saying somebody who can connect to us, we want to guarantee a certain level of service to them.  And that's better to do, it's better to deny newcomers connections that we couldn't adequately service than pull the whole server down.  The idea being, okay - and it's an arbitrary limit.  It's like whatever, based on experience, maybe a hundred people, a hundred connections total can be hooked up to the server at this time because of, you know, bandwidth limitations or whatever.  And so the idea is we'd rather just say, oh, sorry, we're too busy, try again later, than slow everybody down to the average of whatever number of connections are coming in.



So that's an interesting policy.  It wouldn't break the Internet.  It would just maybe annoy people.  I have a high limit at GRC because we've got good bandwidth and my server's not heavily loaded down.  And I've never needed to impose a limit.  But I certainly could if that ended up being a better approach.  And again, we've all probably encountered that as we've surfed the 'Net.  So certainly some people do.  They just say our resources are strained.  We're not going to entertain any newcomers.



LEO:  Seems like there would be a more graceful way to degrade, but maybe there isn't.  Maybe you just have to say no, go away.



STEVE:  Well, you could say would you, you know, we can accept a connection, but how would you like being, like, the last person on the block to get any data?



LEO:  Slow, it'll be slow.



STEVE:  But, you know, it'll be literally we will service these in first-come, first-served order in some sort of fashion.  So stay around if you want to.  How badly do you want what we have?



LEO:  Are you in a hurry?  Donald Stone in the UK really spun up his propeller beanie for this next one, Steve:  As I understand the problem, the source of the attacker is verified; but the attacker then states I'm too busy to receive any packets at the moment, thus causing the server in question to start a timer to increment the time between attempts to successfully communicate with the client, the fake busy client.  It is these timers running which results in the resource clogging.  Surely a workaround to this problem would be to ignore connection attempts from the client IP when a threshold of failed connections has been reached, kind of like what we talked about, but also to discard the previous connection attempts from the client IP.  There should be a limited time during which any rejected IP address should be blacklisted by the server in order that, should it be a genuine communication error, the client would have to wait five minutes or so, some arbitrary amount of time, before attempting to reestablish a legitimate connection.  Surely this would reduce the impact of this form of attack considerably.  The botnet attack scenario would still pose a risk, the big distributed denial of service attack, albeit a higher risk now, as it does anyway.  That's kind of the same thing; right?



STEVE:  Yeah, well, Donald got a lot of value from spinning up his propeller beanie on this one.  He's exactly right.  This is the kind of thing that you could imagine security device vendors, I mean, there are many, many vendors of security devices.  For many years when I was sort of a newbie at this, actually when I originally got set up with Verio, I said I knew I needed a firewall, and I wanted industrial strength.  And they set me up with a WatchGuard.  WatchGuard is a vendor of, you know, actually I think it's called the Firebox or something.  It's literally a bright red painted box.  And so that was my, early on, my first exposure to this.  And so it's that kind of a vendor that I'm sure right now are busy introducing a series of upgrades to their products that will add awareness about these kinds of problems, if they're not already there.



I mean, there very well could be sort of degenerate TCP connection strategy and logic in this kind of border protection device.  And, if so, that's an example, what Donald said is one way it could work.  You literally monitor your connecting clients.  And if you see some that misbehave, you decide, okay, you're bad.  And in fact, now that I think about it, I remember that that machine that I had, that Firebox, the WatchGuard Firebox, did have a blacklisting facility.  And I don't remember exactly how it worked.  But actually I think I do now.  It was by client IP.  And because I remember I came up with a wacky hack that Andy, my Verio engineer, really thought was kind of interesting.



There was something that clients could do that could upset me.  And what I did was I used my own raw socket system to send a packet at the Firebox, spoofing that remote IP, and contacting a service that I wanted to, like, trigger.  And this thing, whatever it was, I spoofed the remote client to tell the Firebox that they were bad and attacking me, and to cause them to go into the blacklist.  And so it was a way for me to add people to the Firebox's blacklist using my own logic rather than the Firebox's logic.  And it worked great.  I don't remember, I mean, this is in the dark ages.  This is a long time ago.  But so, yes, certainly that kind of approach could work in this case.



LEO:  Very good.  Another one for England.  Score another one for the British Empire.  And now moving along to Mat Ludlam in Weybridge, London.  He makes another great point, this time about Sockstress and botnets.  Love the show, been listening since Episode 1, favorite netcast, et cetera, et cetera.  So if a botnet has 10,000 machines...



STEVE:  As many do.



LEO:  ...then if each of them simply opened 100 connections to the same host at about the same time, holding them open would generate about 1,000,000 connections, which is probably enough to cause it to fail.  Yes.  100 connections is probably well within what a Windows client machine can handle; but 1,000,000 is probably well beyond a server, particularly if it's tuned for HTTP requests, which tend to be short.  Whilst I appreciate that messing around with user mode TCP stacks allows one machine to do this, surely if you have a botnet at your disposal then you don't need any of that.  I'd be interested in your comments.



STEVE:  Yes, and I put this in because I wanted to acknowledge Mat's notion.  And also there's been a ton of dialogue about exactly this on the 'Net.



LEO:  Well, what he's saying is that who cares about Sockstress, there's always the DDoS.  Right?



STEVE:  Well, and he's even saying in this case not even flooding, but just connections.  I mean, a Windows system...



LEO:  Oh, I see, it's not a SYN flood, it's just a million connections.



STEVE:  Yeah.  If you had 10,000 machines, and many people do...



LEO:  Many bad guys do on their botnets.



STEVE:  Many bad guys have 10,000-machine botnets.  And every one of them could easily just open 100 connections, just say hi there.  I mean, not even performing any fancy TCP Sockstress exploits, just opening 100 connections.  And he brings up that that, you know, do the math, and that's a million connections.  Which would be very rough for your typical website to handle, as you and I know, Leo.  When we mention something live, and you've got TWiT Live listeners, it immediately brings those sites down.



LEO:  Right.  We do that all the time.  And not intentionally, I should say.



STEVE:  No, and not a million.



LEO:  A few thousand.



STEVE:  Few thousand, exactly.  So I've seen this echoed in many forums online when people are talking about Sockstress.  They're essentially saying there are already bots that are able to do DDoS.  And they're distributed, and then they use a lot of bandwidth.  And the point being, so what if there's, like, some undisclosed 'nother way of using TCP?  We don't need another way.  And this way doesn't allow you to spoof.  And spoofing is nice if you can do it because then you're not giving away the IP of all of the clients in your - all the zombie machines in your botnet.  And so big deal.  It's like, eh, sort of like another...



LEO:  It's just another tool in a hacker's tool box.  But the point of this is that it requires - doesn't require a botnet, essentially.



STEVE:  Correct.  Well, and in fact the counter argument, if I were to raise one, would be that there are high-value, like, gambling sites that have been subject to extortion and are the repeated subject of extortion, as we've talked many times, for example, by literally organized crime operating out of the Ukraine and various places, where in order to keep these sites on the 'Net they've moved themselves onto very expensive, very large pipes behind organizations that specialize in anti-DDoS attacks.  Now, one hopes that it has not just bandwidth flood protection because, if not, then here is a new way of providing a non-high-bandwidth attack, which could be new and might succeed in pulling these sites down.  So the fact that this is new doesn't necessarily mean it has no value to attackers.  It's just, sure, there are existing ways to attack most sites.  This is a new way that might give a new way around.  And again unfortunately, you can imagine where there's big money here in this kind of extortion, that that's where the attention is being focused on.  Oh, wait, maybe we can develop this new idea into some non-high-bandwidth attack and succeed with our extortion where we're no longer able to otherwise.



LEO:  Well, anyway, there you go.  It's just one more way they can hit us.  And that's the point, really.  I mean, it's not like one is to the exclusion of the other.  They're all good if you're a hacker.



STEVE:  Bad.



LEO:  Or all bad if you're not.  Brian in Wichita, Kansas heard what Steve said, but not what he meant.  Listen up.  He says:  Steve, in Episode 164 you mentioned that routers have open TCP ports.  You said they typically accept Border Gateway Protocol connections.  Not really being advanced in my knowledge of routers, this is something I'd never heard of.  Actually I'm going to confess I didn't know either that just a regular cheap router could accept BGP connections.  Does this mean that my router I use at home has open ports?  I don't use port forwarding for anything, and my router is a two-wire gateway, which doesn't support the unsafe Universal Plug and Play you've mentioned in a few episodes.  So I'm safe as far as that's concerned.  I assumed it doesn't have any open ports since I haven't opened any ports.  Are those open ports you mentioned isolated from the firewall?  In other words, do they only allow connections to the router itself?  Is my network still safe?  I would hate to think the router's firewall has holes in it.  What is this BGP stuff?



STEVE:  And I've got to apologize to Brian - and you, Leo, and any other listeners I confused by saying this.  I didn't make myself clear.  I meant formal, out-there-on-the-Internet routers.



LEO:  Not our routers.  Not our cheesy little Linksys.



STEVE:  Not the toys that we have.



LEO:  Well, to be honest it's my fault, and I will take the blame for it because I heard that, and I should have said something.  But I understood you to mean the big Cisco routers that are running the Internet.  I understood that.  But I should have said something to make that clear.



STEVE:  Right.  BGP is port 179.



LEO:  There's no reason for a Linksys to take BGP commands.



STEVE:  No.  What BGP is, just to give a little information to follow up this clarification, it's what routers use - it's called Border Gateway Protocol.  It's what routers use in order to share with their peers, that is, the routers they're connected to, the networks that they're able to route to.  So essentially a router knows that one of its interfaces is connected to this set of networks, and a different interface connected to this set of networks, and a different interface to this set of networks.  Well, it needs to share that information with the routers that it's connected to.  So it uses BGP, Border Gateway Protocol, essentially to share its routing tables with its peers so that, when the peer receives a packet, it's able to figure out which one of its interfaces to send that packet out of as it hops to the next router.  Well, that's, of course, determined by which networks that next router is able to send the packet onward towards its destination.



So it's very elegant.  I mean, it's the height of elegance, actually, the fact that this all works as well as it does.  But it does create a potential vulnerability on port 179 for formal Internet routers.  Not, again, the little consumer boxes of plastic that we use at home.  They've never, I mean, you could certainly load real routing software into them, many of them that run Linux, for example, and get support for BGP.  But there's no purpose for it.  I mean, it wouldn't do anything for your little router.  But it is the core protocol that is how routers use - or how, sorry, routers talk to each other in order to share the connectivity that they all have with the routers that are adjacent.



And there have been many attacks in the past against port 179, the BGP port of commercial routers.  There is, for example, there were some TCP spoofing attacks where people assumed that routers had existing BGP connections and were able to splice themselves into the BGP connection in order to, like, in order to spoof the routing tables and redirect the router traffic to other locations.  So there have been some interesting exploits in the past.  Those sorts of attacks have been hardened against.  And something like ShieldsUP! would immediately tell you if your BGP port of your own router at home were open and accepting connections.  It would be port 179, and ShieldsUP! would tell you, oh, that's BGP port 179.  So the fact that - I don't think I've ever seen anyone say wait, why does my router have BGP port open?



LEO:  And if it were open, it still wouldn't know what to do with anything that came in at that port.



STEVE:  Yeah, no.



LEO:  I mean, it'd just go, huh?  You want to do what?  No, can't do that.



STEVE:  So I did not mean little routers, I meant big iron routers.



LEO:  It's not your fault, it's just there's a confusion between the two terms, frankly.  They both are called "routers."  You know, a little thing in the back of my head went off when you said it.  The problem is, Steve, you're such an authority that I don't - I think all of us go, oh, okay, whatever you say.  Whatever, yes, sir.  I don't question you.  And next time I'll make sure to get that clarified.



Kyle in Des Moines disagrees with the corporate IT administrators.  Oh, who doesn't?  Hi, Steve.  Before I ask my Security Now! question, I'm happy to tell you I've listened to every Security Now! episode since Episode 1.  See, he knew about the Strider HoneyMonkey.  And I've enjoyed every episode.  I listen to dozens of podcasts, including many TWiT netcasts.  And while podcasts have come and gone from my subscription lists over the years, Security Now! has always been among my favorites.  That's nice.  Thank you, Kyle.  I must also tell you that I'm a SpinRite owner and thankfully have never needed it in an emergency situation.  Should that situation arise, however, I will be ready.



STEVE:  Yes, and please don't forget that you have it, Kyle.



LEO:  Yes, exactly.  You know, it's funny because you do kind of forget.  And the other day we had a hard drive issue, and Colleen came back later and said, oh, I forgot, I should have used SpinRite.  Oh, yeah.  We got that.  We got that somewhere.  Now for his question, Kyle asks, he says:  I'm an IT professional, a programmer.  And I've found to be myself in disagreement with our office LAN administrator over a security issue.  I bet you get a lot of these questions, you know, like answer a bet for me, Steve, who's right?  Our LAN administrator believes it's possible for  our public web server to be infected by spyware that is installed on the computers of customers who visit our site.  I disagree.  While I can see that a security hole in the web server or OS server software could possibly allow that  machine to be compromised in a rare circumstance, I see no other way for a spyware-infected machine to spread its malware to a web server simply by that machine making an HTTP request to the server.  I should also mention that a firewall only allows HTTP and HTTPS traffic to this web server from the outside world.  The machine is hardened in all the usual ways.  I just don't see any way for spyware to happen in the circumstance.  Would you care to settle our disagreement?  Thanks to you and Leo, and keep up the good work.  Can it happen?



STEVE:  Well, I agree with his assessment.  There have been, once upon a time, exploits which only required an HTTP request to implement them.  So it's not inconceivable that, if there were bugs in the server - IIS had some horrible ones in the early days where you could basically take the machine over just by giving a malformed URL.  But he specifically says, notwithstanding a security hole in the web server or OS, is it possible that an HTTP request could do that.  And so absolutely not.  The HTTP request is simply a request for a page.



Now, it gets more complex because, as we know, the original spec for HTTP was the notion that web pages were static, and you were simply requesting static web pages from some remote server.  That was extended with the "get" and "post" verbs, HTTP verbs, to allow you, in the guise of a request, to actually be sending information back, and that enabled the whole Web 2.0 concept that users could add comments to blogs and so forth.  So you were accepting their data.  But again, the idea being certainly that you're not going to allow anything malicious to be done by someone who's fundamentally anonymous and outside of your system.  So I would say we never want to say "never" in security.



So to Kyle I would say it's certainly the case that, if everything is working right, that no one making HTTP or HTTPS requests would be able to harm a server.  And I've never heard of any spyware that makes its goal that of trying to do so because there isn't a clear way to do that.  At the same time we've seen all kinds of exploitable web-based attacks.  There are lots of web-based attacks.  But again, it requires some sort of vulnerability in the software or server that is receiving those requests.



LEO:  Yeah, I mean, you're being generous.  You're being complete.  It's very, very unlikely.  Like not going to happen.



STEVE:  Especially not random spyware infections on visitors' machines.



LEO:  Yeah.  Well, and most visitors are running Windows.  And at least my - all my servers are running UNIX, or Linux, or some form of Linux.  So that's even more unlikely; right?  You'd have to write a Windows spyware program that would be HTTP aware, would be Linux aware, and then I guess it'd have to be an exploit.  I mean, there's no generic way that this could happen.  It'd have to be a flaw.



STEVE:  Well, there's certainly no invitation to allow people to accept code that you run on your machine.



LEO:  The thing to understand is that you are not - the web server doesn't look at your disk, and you're in a very constrained way looking at the web server's disk.  It's not like you guys have write access to each other's disks.



STEVE:  Right.



LEO:  Eric in Los Angeles has seen a change in malware behavior.  Oh, it's changing all the time, I'll tell you.  Sometimes, he says, we want to test using ShieldsUP!, even when the connection is proxied.  I work for a large company, and I'm trying to check the security of a new proxy server; but ShieldsUP! detects the proxying, refuses to proceed because the connection is proxied.  That's just how you do it.  I deliberately installed an SSL proxy because more malicious sites are using SSL to avoid the antimalware filters.  Maybe you could adjust ShieldsUP! and allow for that, SSL proxies, and mention it on the show?  What do you say?



STEVE:  Well, I don't know how to do that.  That is, without causing ShieldsUP! to do the wrong thing.  Many ISPs are using proxies, so-called "transparent proxies," where their users are actually having their requests intercepted by the proxy, and then that proxy reissues the request to the web server and then receives the result, caches it, and then sends the response back to the user.  The advantage of that to the ISP is that, if a different user visits the same site, many of the site's components, all the little widgets and pictures and UI fluff that pages have that take a lot of time to fetch remotely, they'll be available on the local proxy because somebody else went to the site and pulled the same collection of debris, visual stuff, through the proxy.  It kept them in the meantime.



So the advantage is the ISP is able to improve the performance, the apparent web performance, for that second customer and any others who use those before they expire from the proxy's cache; and the ISP is able to limit and reduce the bandwidth that it needs to pay for out onto the Internet, basically keeping a lot of that traffic in its own network, for which is does not have to pay because it's just using its own infrastructure.  So there's a tremendous benefit and, that is to say, economic motivation for ISPs to use proxying.



So if one of that ISP's customers wants to use ShieldsUP! to test their computer, I need to, and I do, detect that the proxy is an intermediary.  Well, in seeing that it's an intermediary, I'm unable to affirmatively get that customer's actual IP address.  It could be a public IP address that is publicly routable, so that if I knew it, I could send probe - ShieldsUP! probe packets to it to check that machine for open ports.  But I cannot detect reliably what the connection is.



Now, he says he's installed an SSL proxy.  And I've been very careful in the design of ShieldsUP! even to detect that, so that I know that, even though it's an SSL connection, it still is being proxied, and I just go no further.  I bring up an intercept page that says, hey, I'm very sorry, there's a proxy in between you and us.  I cannot reliably determine your IP, and I just refuse to go any further.  I mean, I couldn't, for example, allow them to type in their IP because then bad guys could immediately use that to go test - to have me test the security of random machines on the Internet.  Well, go check the NSA.  No thank you.  I don't want GRC to be probing the NSA.  So there's just - there's no way around that.  There's nothing I can do that is safe.  And so I just simply stop.



LEO:  Yeah.  I think that's completely reasonable.  You can't do everything.  You can't please everybody.  All right.  Get ready.  Get a cup of coffee.  This is a long one.  Another quad venti latte, whatever it is you drink.  Ben Isenhour of Lexington, Kentucky, fed them a knuckle.  He fed them a knuckle, whatever that means.  Let's find out.  Hey, guys.  I want to mention a few thoughts on security questions.  As a business intelligence professional I always cringe when people solicit and record my personal information.  BI, Business Intelligence, is a very interesting discipline which collates information and allows businesses to make intelligent choices about - predictions about their future business and so forth.  But it probably does make you a little sensitive to the idea of getting your information harvested.



My family thought I was paranoid when at Disney World I refused to let the ticket-taking machine take my fingerprint.  What?  I don't blame him.  Geez.  This was supposed to control passing a multiday ticket to another individual.  So instead I put the crease of my knuckle on the machine.  It worked.  I have no idea what type of security practices they use in their corporate IT department, and I don't want a future biometric identifier escaping to the highest bidder.  You know, he's absolutely right.  I think it's unconscionable.



STEVE:  Yeah, here, take this, Pluto.  You know?



LEO:  It's none of their business.  Disney taking my fingerprints?  Give me a break.  And I feel the same way about security questions.  It seems like this is the new popular thing to do because I keep getting grilled by my online accounts to provide answers to very personal questions.  I tell them a lie.  I just say lie.  As long as you can remember the lie.  Sometimes up to as many as eight questions.  This is just...



STEVE:  Where was I born?  Gosh, I can't remember.  No.



LEO:  I just lie.  You've just got to write down your lies, otherwise you forget them.  This is just another way for more of my personal sensitive information to get out of my control.  I don't think anybody really cares the name of your first pet, but okay.  I really feel they're missing the boat on security, and in fact making us all less secure as time goes on.  We know that.  Those personal security questions are worthless, as we know from - you know they've now indicted the son of the Tennessee legislator that cracked Sarah Palin's Yahoo! email using security questions.



STEVE:  Yeah.



LEO:  Is this something that Sarbanes-Oxley is suggesting they do?  Or is it just their feeble attempt at multifactor authentication?  YubiKeys for everyone.  That's Ben saying that, but I agree.  One last comment.  Here's another interesting piece of info on Wells Fargo.  The username for my Wells Fargo online account was initially set by them to my Social Security number.  You know, my Fidelity account does that.  But now recently Fidelity's given me strong encouragement to change it.  Thank you.



STEVE:  Yeah.



LEO:  I called in, was instructed to use an online screen to change this.  I changed it and was feeling better.  Then one day months later I was in automatic mode, went to the splash page, typed in my Social Security number and password by accident instead of this username.  Well, imagine my surprise, it worked.  It worked.  Are old usernames kept active?  If so, as so it seems, for how long?  Hmm, maybe you guys could get someone from Wells to come onto the show and grill them.  Thanks, guys.  Keep up the good work.  What a great question.  Or actually statements, really.



STEVE:  Yeah.  Ben had a lot of interesting stuff to share.  And of course - and our listeners, I'm sure, agree with the sentiment of, you know, the idea, again, that it's a matter of risk-reward.  You know, our fingerprints are valuable.  I mean, they're valuable identity information.  And the idea of giving them to Mickey Mouse, or a Mickey Mouse ticket-taking machine at Disney World, because they want to prevent you from passing a multiday ticket around, I mean, there's no way the...



LEO:  Sorry.



STEVE:  Yeah, that a machine is going to get one of our listeners' fingerprints.



LEO:  And what he's worried about is now there's, in a database at Disney, a record that combines his name and other information, maybe credit card information, with his fingerprint.



STEVE:  And somebody will sell it in a camera on eBay, along with his Social Security number.



LEO:  Maybe Disney will sell it.  I mean, look at what the privacy - did they give you a privacy statement when they asked for it?  I bet you they didn't.  Unbelievable.



STEVE:  Yeah, yeah.  And so anyway...



LEO:  Very cavalier.



STEVE:  ...there's a tip, folks, use your knuckle.  When it's not a situation you actually want authentication, you don't want to provide any useful information.  You're somewhere where it's like, okay, I don't want to give this.  I do not...



LEO:  So he just flipped his finger over.



STEVE:  I don't want to ever authenticate again.  Yeah, I think he just gave it the back of his finger instead of the meat of his finger.  Which...



LEO:  It worked.



STEVE:  Lot of sense, yeah.  They're just not going to know.



LEO:  [In Mickey's voice]  We got it.  Ho-ho.  Have fun!  Brian Hoort at Michigan State University wanted a bit about OQO.  That's that new little teeny-weeny - did you get an OQO?  You did, didn't you.



STEVE:  Yup.



LEO:  Yeah.  Steve, during the Google Chrome episode you briefly mentioned you have an OQO PC.  I've been interested in them for years, ever since they were announced prior to release -  yeah, they announced it and, like, three years later released it - but I've never had the opportunity to see one.  Would you comment a bit on yours?  I'd love to hear your review.  P.S.:  Security Now! is my favorite programming across all media - radio, television, film.  I listen to it while running and doing yard and housework on the weekends.  I love the show.  Please don't change a thing.  P.S.S. - I think it's P.P.S.  But anyway, SpinRite is fantastic and worth every penny.  We use it often here at the office, where it has become one of my must-have troubleshooting tools.  All right.  It saves drives more often than it should have to.



By the way, I've been wondering, what is so wrong with the operating systems that they corrupt their file systems?  Is it indeed buggy OS code that's responsible?  Is it a failure in the drive firmware?  I haven't noticed any correlation between OS lockups and the need for SpinRite.  The drives just seem to fail randomly.  That's actually a very good question.



STEVE:  Yeah.  I think the systems are - it's like chaos, I mean, formally math chaos, where you're unable to predict the weather because there are just so many variables all interacting at once.  I mean, there's temperature.  There's power supply power; there's vibration; there's OS activity; I mean, just so many variables.  And there just isn't enough margin built into the reliability of all of those things.  The computers are not so cold that they can afford to warm up.  The power supplies aren't so extra powered that they can afford not to have enough.  The drives don't have so much more tolerance in them that they're going to be reliable just themselves, and on and on and on.  And so when everything is sort of near the edge, it doesn't take much to have the stars align, so to speak, and cause there to be a problem.  I'm in love with my little OQO, Leo.



LEO:  Really.



STEVE:  I really am.  The only complaint I have is that the battery life is about three hours.



LEO:  Well, that's not bad.



STEVE:  Well, no, it's not bad.  It's like many laptops.  And in fact it's a little bit more, probably about maybe, yeah, about three hours.  The reason I have it is that I wanted true connectivity.  My goal was that I wanted to be able, wherever I was, if something comes up, I wanted to be able to answer the question, check Wikipedia, or check for something.  I mean, just I'm - when I'm sitting here at home, I've become so used to the persistent, wired-into-the-network mode.  And when I'm in a restaurant or I'm at Starbucks or I'm anywhere, it's like, hmm, gee, I wish I had a 'Net connection.  And I've got my little Treo, that kind of has a web browser but not really.  And I didn't go with an iPhone because they were on the wrong network.  By the way, did you see that Verizon now has a very, I mean, a touchscreen BlackBerry, the...



LEO:  It's the Storm.



STEVE:  ...Storm, which people are saying apparently has a tactile touch where it taps back on your finger when it recognizes a touch.



LEO:  They call it a "haptic response," yeah.



STEVE:  Right, a haptic keyboard that really - that makes a big difference there.  So...



LEO:  You know, nobody's - it hasn't come out yet.  But believe me, I'll get one the minute it comes out.  I'm very intrigued by it.



STEVE:  Well, and it's on my network; it's on Verizon.  I specifically left Cingular back when they were Cingular and before AT&T acquired them because Edge just doesn't do it.  You need EVDO.  It's dramatically higher speed.  And they were talking about UMTS that was going to be the Cingular Edge-related technology that was going to give us the same kind of performance.  But it was already on Verizon and still not available here.  So I'm glad I made the move to Verizon.  So anyway, but I just wanted a real Windows machine.  So this is a - it's 800x480 resolution.  It has a Wacom active tablet as part of the screen.  Although I've got to say in my experience I have a couple tablet machines with much larger screens.  There you really do need real estate for, like, scrawling and writing and taking notes and things.  So it's really not very useful to have, in my experience, that Wacom.  Although I think they've done it more for vertical, like vertical OEM applications is why it's there, for, like, specific custom purposes.



But I really do like it.  It has answered the need I have felt for quite a while of just having it always with me.  It's small enough that literally it can be in my pocket.  And it lets me be on the 'Net because it has a Verizon wireless WAN built in, a little antenna you can pull out if you need greater signal strength.  And so wherever I am, I don't even need WiFi, I'm able to get on the 'Net at completely acceptable speeds.  And I'm using Firefox.  Firefox has a nice feature.  I'm, by the way, Leo, falling in love with Firefox.



LEO:  Oh, good.



STEVE:  It's all I use now.  I absolutely - everything I wanted to do, it turns out it has a way.  One of the things is that the fonts on many web pages are a little small for this small screen.  Firefox, under advanced font-rendering features, you're able to say minimum font size.  And I set it to, like, 16.  And now I don't have to constantly be scaling up all the screens.  They're just the right size for it.  I mean, it's just - so anyway, it's a perfect solution.



I did want to mention that the OQO Model 1 was pretty much horrible.  It was a Transmeta chip.  It had a horrible sort of like flat plastic keyboard.  The Model 2, which is now what they're selling, is far nicer, a real BlackBerry or Treo-style click-click-click keyboard.  And anyway, it's just a tremendous little machine, if it works.  I mean, it's expensive.  It's pricey.  But it finally answered my need for literally always having a connected Windows, real Windows machine with me.



LEO:  And you just carry it with you all the time in your pocket?  Or where do you put it?



STEVE:  No, I've got a little - actually I found a Franklin Day Planner, sort of a big one, that actually had handles.  And I hacksawed out the rings inside to create sort of just an empty binder area.  And so I have a whole little kit of stuff.  I've got my Bose QuietComfort 3 headphones and an iPod with background music and the little Windows machine.  And sort of it's like a little tiny little briefcase that I do - oh, and the Kindle fits in a side pocket perfectly.



LEO:  But Steve, you don't travel.  You don't go anywhere.



STEVE:  I go to Starbucks.   And I do that...



LEO:  It's a Starbucks kit.



STEVE:  I got to Starbucks, and I eat out.  So I'm reading my Kindle.  And if something comes up, I can order a book or check the 'Net or...



LEO:  You're ready.



STEVE:  Yeah, I'm ready.



LEO:  I love it.  Jimmy Retzlaff in San Jose, California wonders whether banks will ever learn.  I have a credit card from JPMorgan Chase, and they just sent me an email trying to sell me services.  As far as I could tell it's actually genuine.  The links - oh, man, an email.



STEVE:  I know.



LEO:  The links all go to Chase domains.  The headers are not suspicious.  It has my full name and the last four digits of my credit card, et cetera.  I've asked them not to send me such emails, but that's another story.  At the bottom of the email is a section entitled "Email Security Information" with the following text:



"If you are concerned about the authenticity of this message, please click here."  Isn't that great?



STEVE:  Oh.  Yeah.



LEO:  "Or call the phone number on the back of your credit card and reference the Chase Library Code: ALLSTANDINSR1001. If you would like to learn more about e-mail security or want to report a suspicious e-mail, click here."  Huh?  Well, I'm concerned about email security.  And because of that, the last thing I want to do is click a link in an email that seems to be from a bank.  If I were putting together a phishing scam, I can't imagine better text to put in the bait note.  You are right on, Jimmy.



STEVE:  Yeah.  I mean, it's just nuts.  It's like...



LEO:  Unbelievable.



STEVE:  Yeah.  And as he says, when will banks ever learn?  As our listeners know, the only acceptable thing to say, if you are concerned about the authenticity of this message, call the phone number on the back of your credit card.  Period.  I mean, you cannot click on a link in a message whose authenticity you are questioning.



LEO:  I guess if they said "Type www.jpmorganchase.com into your browser," that'd be okay.  But click a link, give me a break.



STEVE:  Yeah.  Please press the back of your knuckle onto your credit card.  Oh, just nuts.



LEO:  What a world, what a world.  All right, Steverino.  The Troubling Question, or actually News, of the Week.  This is from James Hudson, another British listener.  We have a lot of listeners in the UK.  I think that's fantastic.



STEVE:  Oh, maybe we have a lot of people who are writing to us from the UK.



LEO:  Well, they're more literate there, you know.



STEVE:  Oh, careful.



LEO:  Oh, boy.



STEVE:  You're going to get in trouble.



LEO:  Hi, Steve.  I opened Outlook 2007 for the first time in a few days today.  Since I use Gmail, I find myself going to the website more often than not because I don't particularly like Outlook's IMAP handling.  And I found there were a whole load of undeliverable emails in my box.  After searching around, there were a load of items relating to them in my Sent Mail folder with spam-type subjects.  Uh-oh.  Looking at the headers, I found they had actually been sent from my PC.  So I did the obvious thing and did a virus and a spyware scan, which revealed a couple of tracking cookies in IE and Opera, but not my default browser, Firefox.  Nothing that'd be sending spam.  Looking at the sent items again, I noticed each one began with "Not Read."  Now, doing a Google search revealed that they were Outlook read receipts that get sent when you delete an email without reading it.



STEVE:  Yeah.



LEO:  I hate those read receipts.  I hate those.  It's one of the reasons I don't use Outlook.  Further research reveals that Outlook has a bug in it that means if an email requesting a read receipt is deleted without being read, then it will send Not Read receipts automatically, no matter what setting you're actually using.  Now, this is good to know because I turn off the email receipts feature in Outlook.  I don't want to be doing this.



STEVE:  Set it to never.  Never, you know...



LEO:  Set it to never.  But here's the point.  In my case this is using Outlook 2007 with IMAP, which Microsoft has admitted is a bug on the MSDN forums, the Development Network forums, last year.  He gives us a couple of links.  But there are some reports of it happening with Outlook 2003 and POP3, as well.  I'm not sure how much of an issue this is, as it only sends it out if you don't read the email asking for a read receipt.  But it does generate a lot of extra and completely unnecessary traffic.  So is a spammer using this facility to...



STEVE:  Well, it verifies your existence.  I mean, that's why it's so troubling is that many of us can look in our inbox and easily identify spam.  And we know that it's dangerous to open them.  We don't want to preview them.  So as we know, the safest thing we can do is just delete them, and that's what we tell people.  Delete them without reading them.  Delete them without opening.  If it's clear to you that this is not something from your mom, or something completely random.  Well, now we learn that even if you've configured Outlook to never send acknowledgement of read receipts, a bug in Outlook causes it to do exactly that.  It sends, well, if the email had a valid From address.



Now, the reason he found these in his Unsent folder is that they were bogus addresses, so his Outlook was unable to send them to where they were trying to go.  But that just - all that did was reveal the bug.  You could certainly imagine spammers sending from some sort of a, you know, spoofing the source as being some sort of a catching server somewhere.  And it would catch any email that someone had deleted without reading and, in the process, confirm that they were real, that here was a valid, useful address.  I mean, this is a serious privacy concern.



LEO:  So what happened was a spammer sent him email with a read receipt.  Even though he had said never, this bug that crops up in IMAP and POP3 in some cases sent the read receipt.  The spammer - now, the problem is, don't spammers - they don't use real return addresses.  So maybe this isn't...



STEVE:  Agreed.  It's not the end of the world.  But it's certainly the case that I just - I wanted our listeners to know that any mail they get which requests a read receipt, which they delete without opening, will result in Outlook sending a Not Read response, even though you've configured it not to do so.



LEO:  I have to say I just hate it because, I mean, for security reasons; but I also hate it because people will then send me a note saying, "You deleted my message."



STEVE:  Well, exactly.  I mean, it could be someone you know who's annoying.  And it's like, oh, not this guy.



LEO:  Well, it's not even that.  I have three or four - I use IMAP.  I have three or four systems.  If I delete it on one system, maybe I already read it and responded, whatever.



STEVE:  Ah, very good point.  So, right, you would have duplicate copies pulled onto different clients.  And, oh, I already read that somewhere else.



LEO:  Yeah.  So I've actually had that happen from fans who say you didn't read my message?  No, I read it.  I just deleted a copy of it.  [Sighing]  Steve, a great 12 questions. If people want to ask you a question, how do they go about doing that?



STEVE:  GRC.com/feedback.



LEO:  Okay.



STEVE:  And I read as many as I can.  I love hearing from our listeners.  We get so much good - I get ideas for shows.  I get news.  People are writing in - as I expected, by the way, many people had picked up on the Sockstress issue on Wednesday and Thursday before - after we'd recorded it, knowing that this was going to be a big deal.  And so our listeners are on top of things.  And I really appreciate them letting me know what they see going on so that we have a chance to make sure everyone knows.  So GRC.com/feedback.



LEO:  And of course when you're at GRC.com don't forget the great SpinRite.  You can get it there.  And it is the disk recovery and maintenance utility, a must-have for everybody who has - if you've got a hard drive, you need SpinRite.  Just that's all there is to it.  Also some great free stuff, like we mentioned ShieldsUP!.  I love Wizmo.  It's a little tool that's just really fun.  All of that for free at GRC.com.  16KB versions of the show, too, for your friends who are on dialup still.  Transcripts, a lot of people like to read along as they listen.  It's all there.  GRC.com.  Steve, we will talk again next week.



STEVE:  See you in a week, Leo.



LEO:  Bye bye.



STEVE:  Bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#166

DATE:		October 16, 2008

TITLE:		Cross-Site Request Forgery

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-166.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's security events, then they address another fundamental security and privacy concern inherent in the way web browsers and web-based services operate:  Using "Cross-Site Request Forgery" (CSRF), malicious pranksters can cause your web browser to do their bidding using your authentication.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 166 for October 16, 2008:  Cross-Site Request Forgery.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers security on Windows and Mac and Linux and on the Internet, particularly lately these days.  Steve Gibson is our host from GRC.com, the man who discovered spyware, coined the term, has done so much to aid security with free programs he's put on his site, GRC.com.  And of course the creator of SpinRite, which is the ultimate disk recovery and maintenance utility.  Hello, Steve.



STEVE GIBSON:  Ho, Leo, how are you?



LEO:  I'm very well.  How are you?



STEVE:  I'm great.  Yeah.



LEO:  Big Windows Update came out today.  We record - or yesterday, I guess.  We record this on Wednesdays.  And yesterday all my systems reset themselves.



STEVE:  Yeah.  I've got mine - I guess I'm still not willing to completely give up control.  So I have many set to advise, but neither download nor install.  Because I just, well, because I don't want my systems doing what you just said yours did, so.



LEO:  Well, we do reruns overnight of the shows.  And of course, naturally, the machine that was doing the reruns reset itself, you know, rebooted at 3:00 a.m.



STEVE:  It's interesting.  Microsoft has indicated that they're going to start indicating for each of these different problems which they're fixing whether - it's like a new class of information.  You know how we have critical, and important, and less, you know, things of less concern.  They're going to be adding a new parameter:  Consistent exploit code likely; inconsistent exploit code likely; or functioning exploit code unlikely.



LEO:  Wow.



STEVE:  And the goal is to help sys administrators, you know, I guess individuals but mostly corporate IT people, get some sense of prioritization.  Like, okay, what's the priority I need to give to this?  Of course our advice to our listeners is stay current on all this.  But...



LEO:  Well, I guess if there's no exploits in the wild, I presume that's what that code, the red light, yellow light, green light means, is are there exploits in the wild.



STEVE:  Right, to give, yeah, exactly, to give you some sense for the urgency of disrupting everything else going on in order to, like, stop everything and install updates.  So that's a good thing.



LEO:  Hey, what are we going to talk about today?



STEVE:  Well, today's topic has an interesting genesis.  A couple weeks ago, I think it might have been Q&A before last, I screwed up one of the answers.  I was, when I was preparing the questions, I was putting them together, and there was a question that had too big an answer for me to deal with; but I thought, okay, that's fine, we'll give it its own show.  And I thought, okay, let me just update myself on this.  Maybe I'll throw some anecdotes in.  And what I saw on the web confused me and made me think that I was wrong about this particular bit of jargon.  And I don't remember if the phone rang, or I got distracted, or I lost my place or something.  But the next thing I knew, you were asking me the question.  And...



LEO:  Whoops.



STEVE:  ...I gave the answer that I had - that I didn't think was right, but what I had just seen had convinced me that I was wrong.  And it turns out, well, what I said was wrong...



LEO:  You knew better.



STEVE:  Yeah.  What I said was wrong.  And I knew better.  But then I go, like, agh, and I was, like, deer in the headlights.  Anyway, so the question a couple weeks ago was, Steve, what is cross-site request forgery?  And I incorrectly said, oh, it's pretty much the same as cross-site scripting, which we've already covered in detail, so next question, please.



LEO:  Right.



STEVE:  Well, what I should have said is, oh, that's really interesting and really important, but it's too big for it to be one of 12 answers on a Q&A.  It needs its own week.  Well, that week is this week.



LEO:  Cross-site request forgery on the next Security Now!.



STEVE:  [Trumpeting].



LEO:  Wow, okay.  I would have just said, oh, that's the same thing as cross-site scripting, no big deal.



STEVE:  Yeah.  The only thing they have in common are the words "cross" and "site."  Other than that...



LEO:  As usual, fooled by nomenclature.



STEVE:  Yeah.



LEO:  Yeah.  Well, and I bet - I'm guessing when you make a mistake you hear about it.



STEVE:  I don't remember if I heard anything or not.



LEO:  Interesting.



STEVE:  Yeah.



LEO:  People, you know, first of all, it's fairly obscure, I imagine.  But also people really trust you.  And so, but you know what I love about it, Steve, is that you are absolutely committed to, you know, your integrity is unassailable.  And you just said, you know, hey, let's fix it.



STEVE:  Oh, I'd much rather be right, yeah, absolutely.



LEO:  Yeah, let's get it right.



STEVE:  And it's been bugging me for a couple weeks.  And I've been waiting.  This is the first slot we've had because we've had various other emergencies and things.  So it's like, okay, fine.  Now we're going to get this straight.



LEO:  We will fix it.



STEVE:  And before that we've got a whole bunch of really interesting stuff.  There's some interesting security stories, some security news and stuff.  So it's going to be a great hour.



LEO:  So before we get into cross-site request forgery, or CSRF, is there any news?  There's got to be some security news.



STEVE:  Oh, we've got news coming out our ears.  Lots of fun stuff, too.  And something, a bizarre story that our listeners are going to love.  Okay.  First of all, Opera has had a major update from - the last version I had before 9.6 was 9.51.  They jumped it to 9.6 because there were some serious critical remote code exploits found.  So I wanted to make sure that anyone using Opera, the five people out there...



LEO:  Now, now.  Let's not be snarky.  Opera's a good browser.  Lot of people love it.



STEVE:  Yeah, it is.  And there are - we have some vocal convincing people in our newsgroups who are total Opera people.  I'm just I'm Mr. Born Again Firefox guy now.



LEO:  I know you are.  It's so funny.



STEVE:  Oh, yeah, I'm converted.  I've seen the light.  So I wanted to let any Opera people know that they want to make sure they move up to 9.6.  And these exploits are - the exploit details are in the wild and are loose and being exploited.  So this is, you know, they're anti-Opera, but someone felt it was worth doing, and it's been done.  So you want to make sure you get yourself updated.  Speaking of updates, we're recording on, well, you and I are recording on the 15th for the podcast on the 16th.  And on the 14th, Tuesday was the second Tuesday of October.  So, wait, yeah.  October.  And Microsoft did 11 bulletins.  It was a mega Patch Tuesday.  Sometimes we only have a couple.  This time was 11, covering everything from Windows and Active Directory, Internet Explorer, Office, and their host integration server, I mean, just across the board, four of which are critical.  So again, I wouldn't discriminate.  I wanted to make sure everyone knows, if they don't have themselves set to automatically have their machines reboot, as you do, Leo, they definitely want to...



LEO:  Not anymore.



STEVE:  ...check for updates and install those.  And I did mention at the top of the show that Microsoft will be introducing this notion, in addition to, like, critical and important, like the severity rating, they're coming up with something different for each update called an Exploitability Index.  And I'm not exactly clear on what it means.  They say it's a three-step scale that will accompany each flaw addressed.  The added information is intended to help users and administrators prioritize the patches.  And so it's like, okay, well, it would seem to me that you want to - if you're going to patch, you want to patch.  But I guess if - and so there's consistent exploit code likely, inconsistent exploit code likely - I'm not sure what that means, consistent or inconsistent.  Maybe like would an AV catch it if it was consistent, but if it's inconsistent - I just don't know...



LEO:  I don't know what "inconsistent" means in this context.



STEVE:  Yeah.  I mean, but that's verbatim what Microsoft is calling it.



LEO:  Maybe it's not like - it doesn't happen all the time?



STEVE:  Well, maybe reliable.  Maybe - but "reliable" was like an annoying word.  So, like...



LEO:  Yeah, you don't want to be reliable if you're a bug.  So they're saying the exploit sometimes works, sometimes doesn't work?  Maybe that...



STEVE:  That's exactly what it is, yes, yes.  So you could have a reliable exploit, an unreliable exploit, or functioning exploit code unlikely.  That makes sense.



LEO:  See, I would prefer that they said widespread in the wild, seen occasionally in the wild, or not in the wild at all.  That's much more usable.



STEVE:  Yeah, but that changes with time.  So they couldn't declare it and then have it suddenly not be true any longer.



LEO:  Yeah, okay.



STEVE:  So I think, I mean, it does, from a technical standpoint, given that we change their use of the word "consistent" to "reliable," I think that really - that says it.



LEO:  But is that information that an IT manager needs to know whether to apply that patch?  If it's not a reliable exploit, do I worry less about it?



STEVE:  No, probably they just need to get the URL for downloading FreeBSD.



LEO:  Yeah.  Okay.  Thank you very much.



STEVE:  Or Firefox.



LEO:  That's the first thing I've heard you say in a long time along those lines.



STEVE:  Switch to Firefox.



LEO:  Yeah, yeah, switch to Firefox.



STEVE:  Okay.  Many people may have received a note from their friends or directly to spam.  There is, I wanted to mention, a malware-laden spam that pretends to be an important Windows security update.  And so that's just been going around in the last week.



LEO:  Microsoft does not use email to send its updates.



STEVE:  Exactly.  Ever, ever, ever.



LEO:  C'mon, guys.



STEVE:  Okay, now.  In the most fun story - oh, wait.  I'm going to - I wanted to mention something that I ran across when I was scanning email for our last Q&A, Leo.  And this is Jeff Stuckey in Fort Payne, Alabama.  He said, "Steve, I could not contact Leo, but I set up the free Audible account using your code.  And imagine my surprise when the book Leo has been recommending everyone to receive as their first free Audible book was not free for me because I only get one credit with a free account, and Audible has set Neal Stephenson's book as...."



LEO:  "Anathem" is more than one because it's huge.



STEVE:  Okay.



LEO:  So I do a little fudge word.  I say you get a credit toward a free book.  I don't say you get a free book.



STEVE:  Ah, okay.



LEO:  Most books are one credit.  Really long books are two credits.  So, yeah.  So what you get is a - just to be clear, you get a credit toward a free book.



STEVE:  Gotcha.  Well, no.  You get a free credit toward a book.



LEO:  Free credit toward a book, yeah, that's a better way to say it, yeah.



STEVE:  Okay, cool.  Okay, now, and neat story of the week - and this is just bizarre.  And this is from an article in The Wall Street Journal that was picked up by several different outlets.  "European law enforcement officials uncovered a highly sophisticated credit card fraud ring that funnels account data to Pakistan from hundreds of grocery store credit card reading machines..."



LEO:  Oh, boy.



STEVE:  "...across Europe, according to U.S. intelligence officials and other people familiar with the case."  Wait till you hear the details.  "Specialists say the theft technology is the most advanced they have seen, and a person close to British law enforcement said it has affected big retailers, including a British unit of Wal-Mart stores and Tesco, Ltd.  The account data has been used to make repeated bank withdrawals and Internet purchases such as airline tickets in several countries, including the U.S.  Investigators haven't pinpointed the culprits.  Early estimates of the losses range from $50 million to $100 million."



LEO:  Oh, boy.



STEVE:  "But the figure could grow, said the person close to British law enforcement.  The scheme uses untraceable devices inserted into credit card readers that were made in China."



LEO:  Oh, wow.



STEVE:  Wait, wait, Leo, this is just amazing.  "The devices selectively send account data by a wireless cell connection to computer servers in Lahore, Pakistan, and constantly change the pattern of theft so it is hard to detect, the officials said."  And then, quote, "'Pretty small, but intelligent, criminal organizations are pulling off transactional multi-continent heists that only a foreign intelligence service would have been able to do a few years ago,' said Joel Brenner, the U.S. government's top counterintelligence officer.  "U.S. intelligence officials including senior National Security Agency officials are monitoring the case, in part because of its ties to Pakistan, which has become home to a resurgent Al Qaeda.



"The scheme comes on the heels of the August indictment of a fraud ring that stole more than 40 million credit card numbers from U.S. companies."  It says, "Examining the stores' credit card readers, investigators discovered a high-tech bug tucked behind the motherboard.  It was a small card containing wireless communication technology.  The bug would read the individual's swiped card number and the corresponding PIN, the Personal Identification Number, then repackage and store the data.  The device would once a day call a number in Lahore, Pakistan, to upload the data to servers there and obtain instructions on what to steal next."



LEO:  Wow, that's terrible.  This is amazing.



STEVE:  It turns out the only easy way to detect this from the outside is if you weigh a bugged and a nonbugged machine.  The bugged ones are a few ounces heavier than the unbugged ones.



LEO:  That's the only way is to weigh it?



STEVE:  Well, you could take it all apart and then, I mean, literally take it all apart and have to take the motherboard out and look underneath the motherboard to see this thing.  This little parasite had been hooked into the bottom of the motherboard.



LEO:  So these are put in at time of manufacture.



STEVE:  Well, presumably afterwards.  Somehow, like the shipment was intercepted.  You wouldn't imagine that the manufacture was doing it.  And apparently not all of the machines had this.  So it makes more sense that it wasn't, you know, blanket manufacturing installed.  It was some sort of an interception of this in shipment that had these things added.  But this is, you know, serious technology.  So you would have had to have the design in detail, the design and firmware probably of the reader, so have complete design knowledge of that.  Then design a custom daughterboard that is able to literally piggyback onto the reader's motherboard, getting power and intercepting data passively, and then have local storage, and then be able to make a data connection, a cellular data connection and then transfer the data.  And then also, because it's bidirectional, receive updated instructions for, like, whether its behavior should change.  In one of the stories that I read about this, apparently a guard noted that there was some interference on his cell phone at certain times of day.



LEO:  Oh, wow, that's pretty good.  Good on him.



STEVE:  Yeah.  And so somehow they, like, pieced the bits and clues together and zeroed in on where this problem had to be.  And it turns out it's these darn little grocery store readers were phoning home, literally.



LEO:  Wow.  That's very sophisticated.  It's almost like science fiction.  But I expect we're going to see more and more of this.  There's so much money to be had here that there's a lot of incentive to do this.



STEVE:  Yeah.



LEO:  This is where organized crime is headed, you know, is to much more sophisticated technically.



STEVE:  Yup, exactly.



LEO:  Wow, amazing.



STEVE:  And I have a fun and interesting SpinRite story to share.



LEO:  Fire away.



STEVE:  This was sort of a fun one.  This is, you know, subject is "SpinRite Saved the Day."  It's like, okay.  From - I don't think he's a listener - Ron Webb.  And he says, "I first purchased SpinRite 6 over four years ago, after I had heard a segment from Leo Laporte.  I can't remember what show Leo was doing at the time.  I've used it a couple times but don't recall the circumstances, and totally forget about it and that I owned it.  Fast-forward now four years, and my father told me he had a computer problem.  He had arrived home after being gone, finding that there had been a power outage" - I guess his clocks were flashing - "and his desktop computer would not restart after the power failure.  He could get the typical splash page of Windows XP, but it would immediately reboot, going through this process over and over."  Which, you know, we've heard time and time again.



LEO:  Yes, yes, yes.



STEVE:  "It would ask if he wanted to start in safe mode, but even that would not work.  It would just reboot again.  I tried to walk him through the process of repairing Windows XP by booting up via CD.  When we eventually got" - and I take it from the context of this that this was over the phone.  "When we eventually got to the portion of selecting the Windows partition to repair, instead of saying there was a Windows XP Professional installation, it reported an unknown partition type.  I knew this sounded odd, so I told my dad to bring me his computer.  He lives a couple of hours from here, out in the country.  I live in Roseville, California."  And you'll find out why in a minute I'm jealous of Roseville, California.



LEO:  Okay.



STEVE:  He said, "With a Fry's Electronics store" - okay, and that's not why I'm...



LEO:  Oh, that's a good reason.



STEVE:  I've got one of those, too.  But he says, "...in case I had to buy some hardware to fix the problem; and I have 20 megabits fiber-based Internet..."



LEO:  Oh, wow.



STEVE:  That's annoying.  It's more than I have at Level 3, you know, and this thing probably costs him, what, you know, 50 bucks?



LEO:  I wonder if he has FIOS.  Does he say, Verizon FIOS?



STEVE:  He didn't.  But I wouldn't be at all...



LEO:  Yeah, wow.



STEVE:  Maybe.  And so he said, instead of his dad's sub-1 megabit satellite service.  His dad's clearly out in the boonies somewhere.  And so he said, "...in case I had to download something."  So the point is, he had his dad bring the machine to him for reasons of the convenience of his location compared to his dad's location, instead of him going there.  "So last Sunday we made arrangements for my dad to come today."  He says, "On Thursday I happened to be in Fry's Electronics and overheard a gentleman asking a salesperson a question about hard drives that the salesperson was clueless about.  I interrupted and started talking" - and I don't know if you've done that, Leo, but I have.



LEO:  Excuse me, you're an idiot.  Stand back.  Stand back.  I have a better idea.



STEVE:  So he says, "I interrupted and starting talking to the gentleman and came to a solution to his issue.  But in the meantime he asked whether I ever used SpinRite.  I had not thought of SpinRite in years, despite purchasing the software in 2004.  I immediately thought of using it for my father's computer, but I had no idea what I had done with the software or where it was.  But since I use Gmail as my email address, I looked through my email archives and found my SpinRite purchase transaction code.  Using that code, I was able to instantly redownload the software after four years and burned a CD..."



LEO:  Oh, isn't that nice.  You have such a good system for that.



STEVE:  Really, yeah, I'm really happy with the way our system works - "...and burned a CD for working on my father's computer.  SpinRite ran for one and a quarter to one and a half hours to complete and found several errors.  It marked one part with a red block and a U, but otherwise everything seemed to work.  I rebooted the computer without the CD in it, and Windows XP loaded without any issues.  Windows did want to run a hard drive integrity test upon starting, which I allowed, but no further problems.  I was then able to perform many other maintenance issues using other software.  But I was so relieved to know that SpinRite 6.0 had saved the day.  I did not need to go purchase more hardware.  I had already purchased the software many years ago.  It was for this reason I wanted to write to say thank you for your software and for your licensing of software, allowing me to redownload and use it at any time in the future."



LEO:  That's a great success.



STEVE:  And, you know, it is, it's a cool thing about the eCommerce system that I wrote is I give people a cryptographic string which is unique for every purchase.  And as long as they don't lose that, they are entitled anytime, anywhere, to grab a copy of SpinRite wherever they are off the 'Net and use it to save themselves.  So it's a really nice, handy feature.



LEO:  You must be very proud of yourself, young man.  Thank you for the nice note.



STEVE:  I will be more proud once I have corrected my mistake from several Q&As ago.



LEO:  Well, we're going to do that in just a second.



STEVE:  Okay.



LEO:  Don't get into too big a hurry.  We are going to talk about - what is it again?



STEVE:  Cross-site request forgery.



LEO:  CSRF.



STEVE:  And you won't forget it, Leo, once you learn what it is.



LEO:  Oh, boy.



STEVE:  Yeah.



LEO:  Is it reliable?  That's what I want to know.  Is it reliable.  All right, Steve.  Here's your chance to make good.  It sounds like it wasn't too bad.  I mean, you know, you just kind of brushed it off and said, oh, cross-site request forgery, that's what I would have said, that's kind of like cross-site scripting.



STEVE:  Well, I knew better.  And like I said, it's been bugging me for weeks.  So now we fix it.



LEO:  You're a man of honor, Steve Gibson.



STEVE:  Well.  And it's, well, and on top of that, I mean, instead of my just being wrong, it's really important that we discuss it.  It had been on my list of things to talk about, which was what I had intended just to say was, you know, this is too big for a Q&A, but thanks for bringing it up.  We're going to give it its own episode.



So, okay.  I've talked many times about my annoyance from a security standpoint about the way users send data back to servers.  Remember we've talked about how the 'Net was initially - the web, sorry, the World Wide Web was initially sort of a "browse these pages that other people have put together."  And with the so-called Web 2.0 evolution, it's become far more participatory, where browsers are now able - users are posting comments to blogs.  There's online forums, I mean, virtually, calendaring, I mean, obviously webmail, all kinds of things are now really fully interactive to the point where we've got applications which are being delivered and managed and run over the 'Net.



Well, the mechanism for sending data back to servers is sort of an awkward extension of the mechanism for making a request.  When our browser issues a so-called GET request - there's two types of requests.  Well, three if you count HEAD, but no one - that's not used for sending data.  So there's GET and POST.  A GET request is exactly like what we see in a browser's URL.  You know, www.GRC.com/something.  And so that sends the verb GET to the HTTP server that looks...



LEO:  Does it actually send the word "GET" in all of this?



STEVE:  Yeah.



LEO:  It says, capital letters, G-E-T.



STEVE:  Yes, all capital letters, GET is the verb.  And I never see it in non-caps, so always caps.



LEO:  I mean, to the computer it's just - it's some bytes.  But humans read it as GET.



STEVE:  Yes, exactly.  And, well, and in fact the whole block of data, for example, cookies will be sent.  And it'll say, you know, "cookie:" and then a space and then the cookie's name and value pairs.  So...



LEO:  It can be - it's really instructive.  You could set up a telnet session and actually do this by hand and type these codes out, and the browser will respond.



STEVE:  Right, yeah, the remote server thinks, okay, well, this is a slow browser, but...



LEO:  G-E-T.



STEVE:  I'm being told to get something.



LEO:  I've done that diagnosing issues sometimes, or I do it more with mail to diagnose mail issues.  But you get - all these headers are actually English.



STEVE:  Right, right, exactly.  So the whole thing is an English readable dialogue.  And, I mean, that's been handy, certainly, for packet capturing, diagnosing problems, I mean, that's one of the nice things about the way the 'Net was set up.  Okay.  So what was - the first extension to this notion of GET was that normally it would be some path to a directory, and then an asset, like index.htm or html.  Well, in order to add additional data, they extended the definition of GET so that a question mark would terminate the asset description portion.  And anything after the question mark was considered parameter information.  That is, you know, parameters to the request.



And so there are, on a web form, you could have some fields which you fill in, and a button which you then click.  And the form data, that is, the form description, literally it's an open - it's a less-than sign, then the word "form."  One of the pieces of data is action.  And that can either say GET or POST.  And so if the form said GET, then essentially when you click the button the data that you filled into the form blanks is added to the end of the URL, which is specified in the form also.  And it's sent just like a browser fetching a page, except that it's got the data you specified on the end of it.



Now, that's the GET request way of sending data to a server.  The POST way is different than that.  You can also use the POST verb, that is, a browser can, and a web form can.  And in that case the data is not tacked onto the end of the URL.  Instead it's sent in individual lines in the actual data of the request, after all the headers.  So you have the word POST and then the URL and then various headers like cookie and what server and so forth, various parameters, then a blank line, and then the data that was provided by the user is sent.



Now, that's much more commonly used today.  For one reason, you're able to send much more data.  It used to be, for example, well, there is a limit on the total length of a URL which is not very long.  So, for example, in today's world where you've got people sending whole forum commentaries that go on for pages, the POST approach can accommodate that because you could have very, very long data elements; whereas you can't in a GET approach because it's got to all fit, sort of like on one line, in the URL.  Okay.  So those are the two ways that data is sent to a server.



Now, remember also, though, that not only data is sent that way.  Anything we do is sent that way.  Like when I am at Amazon, and I'm looking at an item, and I click Amazon's little, I think it's patented, their One-Click button approach, where you just click to buy it now.  And because I'm logged in, I'm already known to Amazon.  Then I click that button, and I just purchase something.



Well, when that request goes to the server, and that clicking the button is a GET request or a POST request, just like any other thing I'm doing, it's validated because whatever cookies Amazon has sent me before, which is the way I'm staying logged in as I move around Amazon's site, my browser is always sending back the cookies that correspond to the site I'm at, given that it has received some before and is configured to return them, as is the default case for all browsers.  So Amazon is able to verify when this request comes in because it's got the cookie that is, you know, represents my currently logged-on session and so it accepts it, and half an hour later I get email saying, okay, you've just purchased whatever this thing was.



So imagine now something happening that you didn't intend.  That is, you go to some third-party website, or you even are - you receive email which you look at in Outlook, in Outlook's default viewer, which is like IE, which is essentially a web page.  And either a third-party website or even email you receive contains an image reference.  An image reference, that is, when your browser receives that image reference it issues a GET request, just like when you ask for a page.  So and we've talked about how pages are built before.  We receive a web page.  It has a bunch of image tags in it.  And the web browser goes, oh, in order to finish displaying this page I need to get all of those other things.  So it issues a flurry of GET requests, often back to the same site that's providing the rest of the content of the page, sometimes to third-party sites, as we've talked about before, to pull advertisements in from advertising services.  Anyway, whatever, it gets all of that data.



Well, it's possible that the image is not an image at all.  If the URL in an image tag is a GET request, saying get a certain, like, purchase with One-Click a certain product from Amazon, my computer will send the Amazon cookie that represents me and my currently logged-on session along with that request, and Amazon will accept it.  Just as if I were visiting there and clicked that button.  Amazon sees no difference.  So it turns out that the problem is this notion of persistent log-on.  Essentially anywhere I go can ask my browser to GET things or, using some JavaScript, POST things to any other site.  For example, there was a site called MetaFilter.  Actually there is a site called MetaFilter.com, which is a popular blogging site.



LEO:  Yeah, it's a link site.  It's great, yeah.



STEVE:  Exactly.  And it turns out that the way their email management goes, if you're logged in and authenticated, and you want to change your email address, you simply say, you know, you click a link that says I want to change my email address.  And it asks you for your new email address.  That makes sense because you've already authenticated yourself beforehand, and you're able to do that.  And there's another facility on the site where you say I forgot my password, please email it to me, and we've seen those all the time, too.  You click "I forgot my password," and they email it.



So it turns out that it's entirely possible for a site you visit to take over your MetaFilter account, literally, by displaying - by attempting to display two images.  The first image that it sends to your browser tells your browser that you want to change your email address.  And it changes it to an attacker's email address.  Then the second image displayed says "I forgot my password, please email it to me."  And it emails your password to the newly changed email address.  And at that point the attacker has everything that they need to log in as you.  And the reason that works is that your browser has an established relationship with MetaFilter such that you're not being constantly asked to reauthenticate.  And nobody wants to be constantly, I mean, literally with every single thing you did you would have to constantly reauthenticate.



Well, it's a little bit harder if sites use POST verbs rather than GET verbs.  But it turns out that many very popular application packages, they sort of - they encapsulate the specifics of incoming data.  They abstract the GET and the POST so that the data can come in through any mechanism, either GET or POST, and the application framework, which many sites are now built on, doesn't see the difference.  So it turns out that even though the pages on the site may use the more formal and slightly more secure POST approach, many sites still accept the GET verb.  And any image tag is able to take advantage of that in order to exploit the trust that target sites have of you and your browser, again because when your browser sends the request, it appends the cookie that authenticates the request to the target site.



Now, it turns out that there has been all kinds of sort of horsing-around exploits of this.  There were, for example, there were Digg stories that dug themselves.



LEO:  Oh, wow.



STEVE:  So when you read the story, embedded in it was a link, an image tag...



LEO:  It's an invisible image, though; right?



STEVE:  Yeah, it's an invisible image that would cause you to dig the story.



LEO:  Oh, that's kinky.



STEVE:  And so they jacked themselves up in that way.  ING Direct, this exploit has been fixed, otherwise I couldn't talk about it publicly.  But ING Direct is...



LEO:  Big bank.



STEVE:  Big bank.  They were the fourth largest savings bank in the U.S. some time ago.  I don't know how big they are today.  It's been a rough month here in the United States.



LEO:  Yeah, no kidding.



STEVE:  Okay.  But, you know, and they're the people, they advertise with a big orange sphere is, like, their logo.  Okay.  ING Direct had - the way their system worked you were able to open a new account.  So a user logs in and says, I want to open a new account.  And so you press a button to open a new account.  You then choose to create a single new account.  You then choose an initial balance for that account to have.  And then you're able to add any other ING account as a payee on that account.  And you can transfer money from your existing account to the new account and confirm transfer.  It turns out that none of that required any interaction, that is, that sequence of steps is completely performed and can be performed by a set of blind queries to the ING server.  And this was an exploit that has been verified.  ING was informed, and they fixed it.



But until that was done, you could literally visit a malicious site, and maybe, for example, one that had used cross-site scripting to be infected, like a site affiliated to ING, so there was a high likelihood that ING customers would also go to this site.  So that site had a cross-site scripting vulnerability that allowed an attacker to install JavaScript on that site.  Any ING customer then who went to that site would cause JavaScript to download into their browser.  Their browser would dutifully execute the JavaScript, which would simply issue a series of blind POST commands to the ING server.  It would clone an account off of yours, transfer a dollar, set up the hacker's ING account as a payee on your account, then empty your account into that second, newly created account that the new guy was a payee on, confirm that you wanted the transfer, and send the money to them.



LEO:  Do we know how much money was lost in this exploit?



STEVE:  No.



LEO:  They won't tell you.



STEVE:  No.  Well, and here's the problem.  I've given a couple examples.  It turns out that this is regarded - the reason I wanted to talk about, the reason I'd had it on my list to talk about is it's regarded as the sleeping giant problem of Web 2.0.  Because it turns out that, you know, the idea is it's exploiting the persistence of our relationship with sites we visit, the fact that we're allowed to stay logged in over time.  Now, defeating this...



LEO:  Don't banks usually log you out when you - well, I guess they don't when you leave the page.  You're still logged in.



STEVE:  Oh, yeah.  If you come back...



LEO:  Tabs in browsers are part of what causes the problem because people keep open tabs.  So you may have - you may, I mean, I can't close the window to my bank and go back and open it, I don't think.



STEVE:  Okay.  And so that would mean that they were using a session cookie rather than some sort of a system cookie.



LEO:  Which would be prudent.



STEVE:  Yes.  Yes, yes, yes.  Absolutely.



LEO:  But even with tabs I'm still in a session when I'm tabbed to another window, so.



STEVE:  That's absolutely true.  Until you actually shut down the browser, that's when it loses the cookies that it never writes to a permanent storage.  So at this point this kind of problem, cross-site request forgeries, have been used for various anecdotes, I mean, for various mischievous purposes.  But many sites today are vulnerable to this.  It turns out it's not a horribly hard problem to solve.  What you need to do is - that is, websites need to do - is not accept requests that don't have some sort of information that an attacker cannot know.



For example, when a real web page displays the form, it ought to include a hidden value which is, you know, some sort of a cryptographically strong pseudorandom number string that is, you know, encrypted.  And that hidden value will be sent back.  It will accompany the post when you submit your data.  That's all that's necessary in order to validate that it's a valid post because no third party would know how to generate a blind request that contained the proper hidden value.  And again, you can make it as long as you want to.  So 128 bits, 256 bits, encoded into ASCII, listeners to the show know all about how to do that now.  So it's possible to engineer around this.  And in fact, those frameworks that I talked about, like Ruby on Rails and ColdFusion and various frameworks, they could easily be enhanced to even make the transition transparent so that they're adding this to outgoing forms.  They're comparing it and stripping it from incoming data and validating that this is truly not a blind request because that's the challenge.  But unfortunately that hasn't been done today.  And there are, I mean, there are more sites vulnerable to this approach than not.



LEO:  I'm thinking I remember putting a long authorization key into WordPress, my WordPress setup.  I think WordPress does this.  They have Off key, Secure Off key, Logged In key.  And it's a long random string that you generate when you set up your blog.  That must be what that's for.  So...



STEVE:  Does sound like there's something that they're doing which is needing those, and then from that they are generating - they're doing something with pseudorandom data.



LEO:  Yeah, yeah.



STEVE:  And if you did a view of the page source you would probably be able to see if there was, like, some wacky-looking token that was part of the form submission.  That would be something that they had included when the page was presented that your request would be sending back when it's being submitted.



LEO:  I bet you they're doing that.  And that's because your log-in is persistent to your admin on your blog.  So when you log into your blog, it remembers it.  And the next time you go back you're automatically logged in.  So it would be very important for them to do that kind of protection; right?



STEVE:  Well, it's very important for everybody to do.  I mean...



LEO:  Yeah.  Anywhere you have a persistent log-in.



STEVE:  Really.  And so there are a couple takeaways.  And believe it or not, there's even a Firefox plug-in.



LEO:  Of course there is.  You are a Firefox fan.  I've been trying to get you to use Firefox for years.



STEVE:  Well, I'm slow on the uptake, Leo.  But once I get...



LEO:  I can remember two years ago you saying, oh, no, I use Internet Explorer.  I can lock it down.



STEVE:  You know, I think my greatest concern was compatibility.  I just didn't want any compatibility problems.  And I'm telling you, I'm using it exclusively.  Only times I have to - I mean, now it's sort of hard to fire up IE.  I've got to figure out how did I get IE running in order to, like, do Windows Update.



LEO:  That's great.



STEVE:  But there's just no compatibility problems with Firefox.  And I think it was looking at the percentage of people who were using it.  And I'm thinking, okay, well, this thing must work.  I mean, Firefox must actually work.



LEO:  It's dominant now.  I mean, if you design a site that doesn't work with Firefox, you're going to...



STEVE:  You find out about it real quickly.



LEO:  You're going to hear about it, yeah, exactly.  Yeah, exactly.



STEVE:  Yeah.  So, okay.  Two takeaways.  One is I would advise our listeners to explicitly log out when they are done using a site that they don't expect to come back to soon, and/or it's an important site.  I mean, you really - you want to break that authentication that your browser has so that you're not maintaining a persistent relationship.  I mean, when I go back to eBay it's, oh, welcome back, Steve.  I don't have to do anything.  Well, that's a problem.  I mean, that's the kind of thing that there could easily be an exploit that would cause me to be bidding on things that I don't want.  Without ever going to eBay.  I mean, I don't even have to go to eBay.  The point is, any request my browser makes will have my current eBay cookie sent with it.  And if that's still valid, that will be - it will be taken by eBay's server, that doesn't know otherwise, as something I'm doing on their site.  And the problem is that anything my browser or an email client using a web browser as its UI, anything it displays or any script it runs is as authentic as something I do.



LEO:  I mean, I know - I have so many bad habits.  When I go to my bank, I just close the window.  I don't log out.



STEVE:  Exactly.



LEO:  When I go to my broker, I close the window.  I don't log out.  This is not good behavior.  So they always have a log-out button.   You're saying use it.



STEVE:  Use it.  And, yes.  And there is, as I mentioned, there is a Firefox plug-in.  Strangely enough, the little built-in plug-in finder in Firefox does not find it, so you need to manually enter it.  If you Google "CSRF Protector," it's the first Mozilla link that comes up, and it runs with Firefox 3.  It's got great reviews.  What it does is it looks to see whether the request you're sending is coming from a third party.  It's literally, it's like it's very similar to third-party cookies.  This is third-party requests.  It checks to see whether it's a cross-site request forgery.  It only can do it with POST, with the POST verb, because if it did it with the GET verb, then no images would work that were coming from some other site.  On the other hand, if you have an ad blocker which blocks any third-party images, you're getting protection automatically from the GET verb style of this exploit.



But anyway, I recommend, I commend to our listeners, if they're people who are doing high-value things on the 'Net, if they would prefer to stay logged in rather than having to log out all the time, and hoping that the site they're using is not vulnerable to GET requests, which this CSRF Protector will not, deliberately does not protect you from because it would break too many other things, then use Firefox 3 and the CSRF Protector.  And it will - it uses the existing pop-up blocking dialogue when it detects this problem to let you know that you've just been protected from a potential cross-site request forgery.



LEO:  Now, let me get this straight.  So first of all I want to write down this Firefox plug-in.  Now, you're saying, though, that it really would be good to get in the habit of just logging out of these sites.



STEVE:  Yes.  I think...



LEO:  I mean, whether you have this plug-in or not.



STEVE:  The overarching problem is this notion of persistent, the persistent log-in.  I mean, consider...



LEO:  Is there a way that the Internet could fix this?



STEVE:  Well, yeah.  Remember that there's a way that sites could fix this if they simply refuse...



LEO:  Use the key.  Right.



STEVE:  ...a blind request.



LEO:  And that's what ING, I presume, did to fix their exploit.



STEVE:  Yes.  And there are some, I mean, this is something that hasn't been getting enough attention.  So it's one of the other reasons I wanted to bring it up was to say, look, this is a fundamental problem with the client server, browser server, user persistent credential.  And this is not just with cookies.  The standard authentication, like you go to a website and it prompts you for a username and password with the little pop-up box?  That's standard HTTP authentication.  And what happens is your browser then continues to provide that authentication with every request you make.  So that's the same.  Anytime you've got an existing relationship between your browser and a site...



LEO:  And you have automatic log-in, where you don't have to pop up a window.  People love that, though.  I mean, who wants to type your password every single time?



STEVE:  It is convenient.  Now, consider, though, the vulnerability would be the same, sort of, as you walking away from your computer, and anyone having access to your computer.  Because if I were logged in, as I said, like for example to eBay, somebody could come up and just do stuff, and there's no way that eBay knows that's not me.



LEO:  We know that when you use a public computer you always log out and close the browser.



STEVE:  Right.  And so...



LEO:  For that reason.  But nobody's thinking that, oh, gosh, I could go to a malicious website, and it now could log in and go to that site without even me knowing it.



STEVE:  Exactly.  There's no - nothing visual happens because it's all happening between script and the remote server.  And it automatically - sometimes it's called "session hijacking," but also "session writing."  It's writing along on the credentials you had previously established.



LEO:  So the Firefox plug-in you're recommending is called...



STEVE:  It's called "CSRF Protector."



LEO:  Okay.



STEVE:  CSRF Protector.  And I looked through the reviews of it.  It looks like there was, like, a couple people had some downloading problems with it.  It was written by two good security researchers at Princeton who we've talked about before, Ed Felten and...



LEO:  Oh, Ed Felten's the greatest, yeah.



STEVE:  And Phil - can't remember his name.



LEO:  Not Cheswick.



STEVE:  Bill Zeller.  Bill Zeller, Ed Felten.  I mean, they're on this.  They're aware of the problem.  And they created this plug-in that solves a class of problems.  The problem is they couldn't block GET requests, third-party GET requests because too many images are coming from third-party servers.  But there's no reason ever that a third party should be sending a POST request.  That ought to always come only from the site you're visiting.  And so they're able to say, okay, that's definitely a problem.  And the POST is what servers that have blocked getting, using the GET verb, they will still be vulnerable to POST because that's how you submit things.  You've got to be able to submit things to servers.  So...



LEO:  So is there anything like this for people who are using Internet Explorer or any other browser?



STEVE:  I haven't run across anything for any other browser.  For them, I would really say explicitly log off of important sites when you're not using them, and consider that various kinds of mischief could occur for any sites where you have a  persistent relationship.



LEO:  What if somebody says I never go to bad sites, I only go to big-name sites, so how could this happen to me?



STEVE:  Well, email.  Anyone viewing email is able to do this.  And you might well imagine that spammers could spray a spam containing an image tag which contains the request that would cause...



LEO:  So another reason to turn off HTML email and preview panes in Outlook and things like that.  We've said this before, this HTML email is dangerous.  Wow, is it dangerous.



STEVE:  Yup.



LEO:  Oh, boy.  So if you, I mean, use Firefox, I guess, is one of the things.  Install this.  But you should probably get in the habit of logging out of these sites anyway.  But there are a lot of sites that I don't consider important, but I maintain a log-in to, including my blog and a lot of stuff.



STEVE:  Well, now, remember all...



LEO:  But they have to target those sites specifically.



STEVE:  I have been impressed with Firefox's auto password fill-in.  It does a good job of that.  And of course using Firefox 3 I've got that protected with my own master password.  So that reduces the onus of needing to reauthenticate when you go to a site.  You've got to remember, you know, what your username was.  But as soon as you provide that, Firefox will say, oh, here's the matching password, off you go.  So it makes it a lot easier.  And third parties cannot access that.  There's no way for them to access the auto fill-in stuff.  All they can do is send a blind request to the site.  So it is important that that not be valid.  And the way to make sure that's not valid is just log off when you're done.



LEO:  And they would have to - so you'd have to go to a page or get an email that was targeting a specific site.  I mean, because the JavaScript they're sending is very specific to that site.



STEVE:  Yes, and I think that's one of the reasons that this hasn't really hit the radar screens very much.  For example, a Digg story that digs itself, well, that's sort of fun.  I mean, that's like, oh, well, you know, there's high...



LEO:  Not for Kevin.  But I'm sure Digg is doing something to prevent that.  Can they?



STEVE:  Yes.  Well, it's well known.  This has been known for a while.  So they may well have already resolved that.  And Amazon was told about this by one of the security researchers who's been leading this.  And they were specifically told about the One-Click exploit, that is, you could go to someone's page, you could receive email, and without you intending to, something you did not want would be purchased.  And one year later they had not fixed it.  So this guy went public with it after a year.



LEO:  Oh, good, yeah.  That's - yeah.



STEVE:  And said, look, you know.  And he called it the "Amazon Anniversary."



LEO:  Now, it wouldn't be sophisticated enough to buy something and send it to another address.



STEVE:  Well, now, that's interesting because I know you're an Amazon user, Leo.



LEO:  Yeah.



STEVE:  Any time you do send it to another address, you must provide them with a new credit card or your existing credit card...



LEO:  Re-enter it, yeah.



STEVE:  ...and credentials.  So Amazon is aware enough that they're not allowing you to do that without reauthenticating at that level.



LEO:  So the only way you could really take advantage of this is by maybe forcing people to buy a product you are selling.  You know.



STEVE:  Yeah.



LEO:  But Amazon would catch you, I think.



STEVE:  Yeah, well, you would receive email, like half an hour later, saying hey, just wanted to confirm your purchase.  And you say, wait a minute, I do not want elephant teeth. 



LEO:  No, thank you.   No, thank you.  Wow.  This is amazing.  I could see how you could do it.  If you knew a bank had a vulnerability, I could see why ING might have been very vulnerable.  You send emails to 12 million people, and if 500 of them have ING accounts, you're happy.



STEVE:  Or it has been used to exploit voting sites, where you're voting for this or that.  People just send out spam.  And some number of people will - in fact, there are some voting sites where you don't have to log in or create an account, but they log you when you vote so you can't vote again.  So there you don't even need a persistent connection.  Just they spray spam out.  Anybody who displays it puts a vote in for what they want.



LEO:  So you really - you have to turn off HTML email.  You have to turn off that preview pane.  That's deadly.  That is deadly.



STEVE:  Yes, it's too frightening.



LEO:  I mean, it would just happen.  You wouldn't have to click anything or anything.  You wouldn't even have to read the email.   Just the fact that it's in the preview pane triggers it.



STEVE:  Right, right.  Because the act of displaying it causes a request to go out.  And it turns out that so many sites will now do something from a request.  I should mention, and I forgot to mention, that the updated RFCs for web surfing, for HTTP state, explicitly state, that the GET verb should never be used for modifying content on the server, should never be used to make changes.  It should only be used, as it sounds, for getting something from the server.  So traditionally you could do the same things with GET that you could with POST.  Now the RFCs are specifically saying, unh-unh, only retrieve information.  So hopefully that will migrate into practice with time because GET is more powerful than POST because just an image tag causes a web page to attempt to retrieve that image and get whatever it is.  Whereas you would need, you do need scripting enabled in order for the POST command approach to work.  But as we know, most people have scripting enabled, too.



LEO:  Sometimes you feel like Paul Revere saying, "The bad guys are coming, the bad guys are coming."  It's just amazing.  It's also impressive how sophisticated these things are.  The trick you talked about to steal credit card information at the beginning of the show, or this.  It's sad because these guys that are figuring this stuff out are smart guys.  They're very smart.  And, you know, if they would turn their brains to useful stuff instead of this kind of stuff, just think what they could accomplish.  It's really sad.



STEVE:  Well, and the reason I think maybe Paul Revere was right, as of course he ended up being, was that in our context today, what we're doing with the 'Net, the 'Net itself, and Web 2.0 applications, they're becoming more and more powerful.  Banks don't want to see us anymore.  It's expensive for them to maintain a retail faade and smiling people behind the teller window.  They're encouraging and pushing people by policy to use online banking, to use the Internet more and more.  And we're seeing example after example of that.  So we can only assume this is going to become more pervasive.  It's necessary to educate users and to educate the services about how to make this more secure.  So it's certainly worth doing.



LEO:  Yeah.  Steve Gibson, as usual, you've really - I'm glad we came back, circled around and talked about this.  You've pointed out something really both fascinating and scary, cross-site request forgery.  And, you know, log off important sites.  Download the Firefox plug-in if you're using Firefox.  Plug-in is in early beta, so some people are having trouble downloading it, I see.  And then finally, websites, stop using GET.  You know?  You can design - if you use POST, and you check referrers, you can avoid this entirely.  Right?



STEVE:  Yes.  Checking referrers is another solution.  There are some strange sites that check referrers but still allow null referrers because some users block referrers.  They have, like Proxomitron, for example, you're able to strip referrers out of your outgoing request.  Well, apparently that would break those sites that were requiring a matching referrer.  So they said, oh, okay, if the referrer is present and wrong, then we'll block it because that we know is a third party, and so we want to protect that.  They said, but if there's no referrer header, then we want to allow that because we don't know if it's a first-party or third-party request.  Well, the problem is JavaScript can null the referrer or change the referrer.  So that's not a robust solution.  It's better than nothing, but a really good solution is to actually provide a one-time token with the form, and when it comes back, verify it.



LEO:  Thank you, Steve Gibson.  Don't forget to go to GRC.com.  That's where Steve hides all the good stuff.  SpinRite's there, of course, his incredible disk maintenance and recovery utility, a must-have for anybody with a hard drive.  I go through hard drives now like candy.  They're so cheap.  They're 100 bucks for a 750GB hard drive.  And you'd better believe I SpinRite each and every one before I use it.  At that size, you'd better.  Of course he has a great array of free stuff there, as well, including ShieldsUP! and Wizmo, a fun little toy.  And the show.  16KB versions are available there, as well as transcripts and show notes, too.  Thank you, Steve.  We'll talk again next week.



STEVE:  See you, Leo.



LEO:  Bye bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#167

DATE:		October 23, 2008

TITLE:		Listener Feedback Q&A #52

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-167.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 167 for October 23, 2008:  Listener Feedback #52.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show where we cover all the latest security news and give you some inside understanding about what it means and what it is.  There he is, ladies and gentlemen, Steve Gibson in his beautiful lair.  It looks like a library.  For those of you who watch on video, you'll see Steve is surrounded by books.  Are those all programming books, Steve?



STEVE GIBSON:  I love books.  Yeah, there's some software, but largely programming books.  I have an unopened copy of Windows 3.1.  And...



LEO:  Why didn't you open it?



STEVE:  There's a bottle of Cabernet from Microsoft that was give to me, it's etched, a bottle that I will never open, sort of a collector's item, and other random little paraphernalia from long-gone days.



LEO:  You know, it's funny, because if I turn the camera the other way, what I'm looking at is a very similar bookshelf filled with books.  So, and many of them are programming books, as well, and computer stuff.  And I even have, thanks to Paul Thurrott, who sent it to me, a copy of Lotus Symphony for the Macintosh.  Yeah, look at that.  There's the wine.  I see it right on the top there.



STEVE:  Yeah.



LEO:  Lotus Symphony for the Macintosh.  And it's on floppies.



STEVE:  Yes, yes.  Yes, yes.  When you could actually fit something useful on a floppy.



LEO:  Well, there's, like, 40 floppies.  You know, and now I'm looking, it really is mind-boggling.  I just got a 32GB SD card for my camera from Kingston.  Thirty, you know, we're so nowadays cavalier...



STEVE:  Now, you mean CF or SD?



LEO:  SD card.



STEVE:  Wow.



LEO:  We're so cavalier about...



STEVE:  Gigs.



LEO:  ...gigs.  My new G1 phone has a little micro SD.  I mean, that's tiny, a size smaller than my pinky fingernail.  And that's 8GB.  Gigs mean nothing anymore.  You know?  When you and I were coming up...



STEVE:  Oh, in fact, a friend of mine sent me a very cool thing he found on ThinkGeek.  It's a dock cradle, but it's for docking an SATA drive.  So it's got a large port.  And literally you just - you plant - because SATA drives are hot-swappable, you literally just plant the drive into this thing, and it plugs it in.  And it's got both a USB 2 and an eSATA interface so you can do full high-performance drive interaction.  So, you know, here's hard drives have come down in price to that level where it's like, oh, just plug an eSATA drive in here and use it.



LEO:  Steve, I have six of those.  And I buy 750GB drives for under a hundred bucks by the dozen.  And then I pop it in, and that's what we record all our video on.  I pop it in.  At the end of the week I pop it out.  You know, Tony's got one on his machine.  Dane's got one on his machine.  Even our office manager has one on her machine.



STEVE:  Oh, you mean the eSATA docks?



LEO:  Yeah, and anybody can just...



STEVE:  Oh, cool.



LEO:  Because we just - it's easy to put eSATA on these new machines because it's just putting an external port on there.  And any of these drives, they're just barebones drives.  I've got them on my shelf now, starting to line up.  Anybody can come in, what do we need?  Oh, yeah, that's on Drive 4.  They'll pop it in.  It's amazing.  Now, I just - Dane just handed me - only people on video are going to see this.  This is 16KB of memory for a Data General Nova machine.  That is, it is the size - it's framed.  It's the size of a, well, a framed picture, you know, like 12x12 picture.  Sixteen, not megabytes, not gigabytes, kilobytes of memory for a Data General Nova.  So that's 40 years ago, 30 years ago.  Unbelievable.  We have come so far.



STEVE:  I programmed a Data General.



LEO:  Did you?



STEVE:  Yup, the Nova and the SuperNOVA.  Those were beautiful machines.



LEO:  This was a minicomputer; right?



STEVE:  Yeah.  Minicomputer, had big 19" boards that slid out.  Like it was 19" rackmount.



LEO:  Well, that's what this must be, then.  This is 19 inches.



STEVE:  Yeah.  And so that was a board of core, probably, core memory.



LEO:  It's core memory, there it is, yeah.  And probably hand wire wrapped.  I mean, I don't think this is stamped out.  This looks like all the solders are by hand, and the wires are visible, I mean, it's just amazing what's changed.  Just amazing.  We live in interesting times.  So what are we going to talk about today?



STEVE:  Well, today, Episode 167 is a Q&A, our 52nd Q&A, questions and answers from our listeners.



LEO:  That's hard to believe, too.



STEVE:  Yeah.



LEO:  Wow, all right.  That'll be fun.



STEVE:  We've got some good ones.  We've got a couple long ones and some short ones.  And so I think it's a nice lineup of questions.



LEO:  All right, Steve.  Any updates from last week's episode, or...



STEVE:  Well, it's been quiet on the security front.  There is another Mac update.



LEO:  I did get one just last night, yeah.



STEVE:  Yup, that one.  It was updating, once again, a bunch of security vulnerabilities in third-party components that are bundled in with the Mac OS, various open source UNIX gizmos.  But also there were some remote code execution vulnerabilities.  So I wanted to let our Mac people know.  I mean, last week when we recorded this I had a major update.  This one was small.  This was, I think, 31MB, so not nearly as big.  But you want to just check for software updates, and Mac users will find something there.  Also several of our listeners commented on my mentioning about application frameworks and the CSRF topic from last week, the cross-site request forgery.  And they wanted to mention that Ruby on Rails does have built-in CSRF spoof-defeating logic, and it's enabled by default, and it's been there since v2.0.



LEO:  Very interesting.  Rails is used on a lot of websites.  It's a very quick prototyping system, very easy to use, and a lot of Web 2.0 sites use it.  So that's good news.



STEVE:  Right, right.  And so this problem was recognized, and forms automatically include a pseudorandom token that must be returned when the form is submitted.  And just doing that prevents the blind request forgery that we were talking about last week.



LEO:  Excellent.



STEVE:  So I wanted to acknowledge that anybody who is, I mean, it's even a reason to use Ruby on Rails, in fact.  If you are up in the air about what framework you're choosing, all other things being considered, this is a good thing to have, just to keep anyone from messing around with your site.



LEO:  I'd be willing to guess, before you get flooded by emails from everybody else, that other frameworks, if they don't already do that, will do that.  It's an easy thing to implement.



STEVE:  Right.  Right.  And then I had one fun SpinRite anecdote from someone named - actually a listener of ours, Calvin.  And I ran across this when I was going through the  mail bag for Q&A, so I know that he's from Saint John, New Brunswick.  And the subject was "Save the Last Dance for SpinRite."  And he said, "Hi, Steve and Leo.  I have always been the tech guy for a friend of mine living in Alberta, mainly because I lived only about four blocks away for the longest time.  However, about six months ago I moved to the opposite end of the country.  Well, recently I convinced my friend to buy a MacBook as her old laptop was starting to fail.  She transferred her music, which she uses for youth dances at the Boys and Girls Club, onto an external hard drive to transfer over."  So she apparently put it from whatever laptop she was using onto the external drive, and then she was going to plug that into her MacBook.  "This is when the emails started coming.  When she plugged the external drive into the MacBook, she could hear a faint clicking sound."



LEO:  Uh-oh.



STEVE:  "But the drive would never actually mount.  I arranged for her to courier the drive out to me, and I set to work as I only had two weeks to get this figured out.  I first tried plugging the drive into the USB port on my laptop.  However, I encountered the same issue she had, just repeated clicking.  That's when I took the external casing apart, that is, the case of the external hard drive.  Luckily enough, it was a laptop SATA drive, so I plugged it into my laptop's drive bay and booted SpinRite.  When I launched SpinRite, I was met with the ominous red warning screen saying that the drive was in danger of imminent failure."  That's something that SpinRite is able to detect - I've stepped off of reading this for a minute just to tell our listeners that that's something that SpinRite is able to determine immediately by polling the S.M.A.R.T. interface on the drive and checking to see whether the drive thinks it's okay.  So even the drive knew it had a problem, although unfortunately through the USB interface that information was not being communicated.



So continuing with Calvin's note, "With this in mind, I launched SpinRite at Level 2.  After about 11 hours or so SpinRite finally finished its business, proudly displaying about 25 green Rs, meaning recovered data, showing all recovered sectors.  I then booted to a Linux Live CD, mounted the drive, and copied the files to a USB stick to send back to my friend.  Needless to say, the dance is saved, sparing my friend hours of CD ripping and recovery of songs for which she only had digital copies.  Thank you so much for your amazing product and an incredibly informative netcast.  Keeping my propeller beanie wound up."



LEO:  You know, she's, or he's very - she's very lucky to have him because he's obviously a major geek, smart enough to do things like use a Linux Live CD to recover the files and things.



STEVE:  Right.



LEO:  Obviously she has a good friend.  That's a nice story.  Hey, before we get to our questions, I have one story I wanted to mention.  You don't - you're not a baseball fan, are you.



STEVE:  A what?



LEO:  Baseball?  You ever hear of that?  It's this game, these guys, grown men, they go out with a stick, and they whack a ball around.  It's really fun.  The World Series is coming up in just a little bit.  But the American League championship series was a very exciting playoff between the Red Sox and the Tampa Bay Rays.  And Red Sox had come back in Game 4, and in Game 6 they won again.  And it was very, you know, they put it all the way to Game 7, the final and deciding game to see who wins the pennant and goes on to the World Series.



I tune in TBS, and they're in reruns.  They have some technical difficulty.  The first two innings of the game they miss.  They miss.  They can't - and I go on Twitter, and people are howling.  I mean, this is a big deal.  But they're running some crap rerun.  And I'm watching it because I figure, well, they're going to get it back pretty soon, and I want to see the game, this exciting game.  And on comes - I don't remember the name of the company.  And even if I did, I wouldn't give them a plug.  But on comes an ad for a company, I'm sure this isn't a very good product.  They claim to - you run this product on Windows, and it speeds up Windows and gets everything going faster, right, and they show - it's kind of a funny ad because it's mostly Macintoshes with Windows screens CG'd in showing Blue Screens of Death, and then they run the software, oh, it works.  And so at the end of the ad they say go to our website now and download this software.



Well, I had to go; right?  But I think what they weren't planning on is running in Game 7 of the American League championship series.  Because I go to the website, nothing.  They DDoS'd themselves with this ad.  And they did not come up for another half hour.  All that potential revenue gone, just shot.  People who couldn't get on the website.



STEVE:  Come to think of it, that had to have been an expensive commercial to run, too.



LEO:  Well, I think they were getting it for nothing because they thought they bought the Steve Harvey Comedy Show.  But they're going crazy in Atlanta, saying quick, throw something on.  I know, I've been there.  Throw something on.  We've got nothing from the game.  What are we going to do?  And so they're running whatever they got, including this ad that I'm sure these guys never expected to be on in a major ball game.  Just a word of warning, you know, if you're advertising a product that speeds up your computer access on the Internet, make sure you have enough web server capacity before you get the ad on the air.  Oh, sad.



All right, Mr. Steve Gibson.  It is time, my friend, to delve into the questions, the myriad questions from our listeners.  They're dying for your answer.  Are you ready, sir?



STEVE:  I'm ready.



LEO:  Like Carnac.  Like Carnac the Magnificent.  These questions have been sitting on Funk & Wagnall's porch in a mayonnaise jar for three weeks.  Listeners Colin Williams - oh, everybody wanted to know this one - Dave Mackenzie, Warren Matthews, Canuck Geek, Dullin Panuru, Rene, Rick E., Igor David Schneider, Pete Lisanti, and many others ask this question.  And I'm really glad they did because add Leo Laporte to this list.  We've seen this from ElcomSoft, the report that WPA and WPA2 WiFi may no longer be secure.  What's the story, Steve?



STEVE:  Totally bogus report.



LEO:  Yes, that's what I said.



STEVE:  Yes.



LEO:  I saw this news story, and I knew that we would get these questions.



[Talking simultaneously]



LEO:  And it just, in fact, pisses me off, frankly.



STEVE:  Yeah.  It was really, really, really bad.  Those are just the names of the first few people, starting on October 10, when this report came out.  Unfortunately, of course, it got picked up by Slashdot.  And most irresponsibly, the well-known SC magazine, a good security magazine, I remember picking up a copy when I was at the RSA convention, they carried a story which really inflamed this whole issue.  



Okay, so basically what ElcomSoft has come up with is not unexpected.  They're using the extremely high-power integer engine inherent in state-of-the-art GPUs, the graphics processing units in NVIDIA display cards.  They're using those to accelerate basically brute-force encryption attacks.  And they give many examples in their flyer of different sorts of passwords that can be cracked.  And what's most telling is that it's ElcomSoft themselves are only billing this, for example, as a high-powered way to maybe check for weak passwords in a corporate environment.  They're only claiming that two of these cards, two NVIDIA cards and their software in a fast machine would break WiFi encryption up to a hundred times faster.



Okay, I don't doubt that at all.  Except that it's already, like, 10^38 times harder to do anything with a good, random password.  Now, they don't explain whether they're just brute-forcing the 128-bit encryption, or whether they're brute-forcing ASCII, which is then hashed using the WPA scheme into 128-bit key.  So it's not exactly clear what it is they're doing.  But the problem is that this SC magazine story which got picked up, and then which of course The Register in the U.K. picked up, and then Slashdot did, the guy who wrote the SC magazine story said, oh, this is the end of WiFi security as we know it.



LEO:  You know, and the other thing that pissed me off is instead of saying a hundred times faster, he said 10,000 percent faster.



STEVE:  Well, yes.  And the way you...



LEO:  Moron.



STEVE:  The way you could theoretically get that, because this is also a distributed attack tool, if you had 10,000 computers, each with two of these in a huge network, each of them a hundred times faster than if they were just doing it in software alone, okay, yeah.  So then you could get it up to 10,000 percent faster.  But even that doesn't matter because, you know, if you have followed our advice and have a strong, really robust WPA key, which you should have in any event, then this doesn't help you at all.  I mean, this...



LEO:  In other words, if you use your special passwords program to generate a 64-character random string, you're still, you know, so what if it's a hundred times faster.  It's not even two orders of magnitude compared to infinity.



STEVE:  So now you're down to several tens of billions of millennia rather than 10,000 several tens of billions of millennia.



LEO:  I was really shocked at - I can understand the mainstream press getting sucked in by this.  I was really shocked that people at Slashdot and SC mag, they should know better.



STEVE:  Yeah.  Well, especially when even the original report from ElcomSoft makes no claims about its ability to crack WiFi.  I mean, I read the whole press release.  They're saying a hundred times faster.  It's like, okay, I believe that.  But that doesn't help you.  It doesn't in any way weaken WPA because it was already strong enough to withstand a factor of a hundred gain in cracking.  I mean, and besides, a hundred is not that much.  If WPA weren't strong enough to withstand a hundredfold increase, it wouldn't be strong enough to withstand a onefold increase.  Because, again, a hundred isn't a huge number.



LEO:  No.  You know, that's I think why they couched it in percent, which makes it sound like it's so much more.  But even then it's not a significant - I'm really - I guess I've been doing this show long enough, I've learned a thing or two.  And I debunked - I had the same debunking reaction on the radio show.  It's just - but of course it scares the heck out of people.



STEVE:  Yeah.  Well, because we have seen situations.  There was a report recently where the encryption scheme used for the remote car keys had been cracked.  And in fact it has been.  And it was kept secret for two decades.  And it leaked out, and some cryptographers got a hold of it, and it turns out that under certain circumstances it's possible, if you receive several successive outputs, to determine the master key in the keys we use for unlocking our cars and garage door openers and things.  But even then, the only good attack is a so-called "side channel attack" that we've talked about before where you measure the power being consumed by the transmitter.  Well, okay, how do you measure the power being consumed by the transmitter someone's holding in their hand, you know, across the street?  So just receiving the radio, it turns out, is still very secure.  And so people get these stories mixed up because they're technical, and we end up upsetting people needlessly.



LEO:  Right, right.  You know, one thing that it does raise, though, is this issue of you could sit out on the curb with a wireless connection and collect a lot of data and then go home and analyze it.  You're not doing this on the curb.  And I guess - is that right?



STEVE:  Well, yes.  The ElcomSoft or any - and we've talked about...



LEO:  Any brute force.



STEVE:  We've talked about the only, as far as we know, the only vulnerability in WPA which has now been, I mean, seriously reviewed by the world's top cryptographers, the only weakness we know of is a brute-force attack where - and you only need a few packets.  You don't need much.  Although if you were going to - if you wanted to crack the security, you would be wanting to suck in a bunch.  But then you would only analyze a few.



LEO:  So you'd say maybe take 10 minutes worth of data?  Would that be enough?



STEVE:  Half a second worth of data.



LEO:  Okay.



STEVE:  Would be enough.  Because the goal is to find a key by trying them at random that happens to decrypt a couple packets.



LEO:  But it does - it is a form of vulnerability because unlike, you know, if you want to brute force, for instance, SSH to break into my server, you can't really automate that.  It slows you down.  You can only do one try every few seconds.  But this does at least mean you can get a batch of data, take it home, and you can throw a lot of hardware at it and hammer it.



STEVE:  And when you're not playing whatever your videogame of choice is...



LEO:  World of Warcraft, yeah.



STEVE:  World of Warcraft.  You can idle your computer trying to crack some WiFi.



LEO:  So you can do it at your leisure, which is a little different than a lot of brute force cracking.



STEVE:  Well, for example, the WEP crack, because of the vulnerabilities in WEP, the prior generation encryption, WEP, anyone can crack that in a minute.



LEO:  Sitting on the curb, yeah, yeah.



STEVE:  So, you know, that's just broken now.  But WPA is still safe as long as you're immune to brute force attacks.  As long as you use a really good key.  So again,  GRC.com/passwords.



LEO:  Breathe safe.



STEVE:  And we will give you a good, strong key.



LEO:  Nothing to fear.  Mike in Toronto, Canada needs a public VPN service.  We get this question fairly frequently, as well:  I hope you're reading this, Steve.  I'm looking for - yes, he is.  I'm looking for a VPN service for surfing the web.  The problem is I tried Strong VPN, but the service is very poor.  Could you tell me or ask your readers if there's any good VPN service in the USA?  I'm scared to get another one, fearing getting ripped off again.



STEVE:  And this was an easy one.  I know of, and you and I both used, and while I was using it, you know, I had a trial subscription that the owner of the service gave both of us, Leo, and that was HotSpotVPN.



LEO:  Yup.  And it's 10 bucks a month, 8.88.  It's very affordable.



STEVE:  Yup.  And it works.  I mean, their servers are strong.  It's a standard.  They just use OpenVPN.  So when you download the client from them, this installs OpenVPN into, for example, your laptop, with it all preconfigured and ready to go.  And so it's simple to use.  And while I was using it I was very impressed with it.  I had no trouble with it.



LEO:  And there are others.  But, yeah, I think it's a very good one that I would highly recommend.  You do get some slowdown by using a VPN service.  I mean, it's not, you know, you have to go through their server; right?



STEVE:  Right, yes.  And you also need to trust them because, remember, just like TOR, where you're using essentially other servers out of which your traffic is being emitted, there's inherently a traffic concentrating aspect to that.  So, you know, somebody could be looking at all of the traffic coming in and out of the HotSpotVPN network figuring that maybe it's higher value because somebody wants to encrypt what they're doing in their local connection.  So there is some traffic concentration consequence of that.  But, you know, for email and web surfing and so forth, it's certainly safe.



LEO:  And I wouldn't dream of doing anything that you needed to be safe in a hotel, especially a hotel.



STEVE:  No, no, no.



LEO:  In a hotspot, I mean, these things are risky.  So you do need something like this.  Bruce Kincheloe in Denver, Colorado, USA, says he just wants to plug in and turn on and tune in and drop out.  No, no, just plug in.  Hi, Steve.  Thanks to you and Leo for the great work you do with Security Now!.  I love the show.  My question is about power line networking.  These devices are newly available.  From a security point of view, is the encryption used sufficient to prevent eavesdropping by others?  You know, I haven't tried this.  They kept foisting it on us years ago.  And I think now the new power line networking actually is pretty reliable, pretty fast.



STEVE:  And the good news is, it is very secure.



LEO:  Oh, that's neat.  So they encrypt the data.



STEVE:  And they do a - well, yes.  And we've seen keyboards that said they encrypt the data, and it turns out they're XORing an eight-bit byte with it.



LEO:  I just saw a hack of a wired keyboard from 20 feet away.



STEVE:  The good news is I did a check.  All of these come from the same company.  And this company understands security.  They understand that, if they're sticking your network on your wires, and for example you're in an apartment building, so that your wires are the same as your neighbors' wires, they'd better get the encryption right.  And they look like they did a, I mean, I haven't done an absolute full security analysis.  But in order to find an answer to the question, I did look around.  I took a look at the security and the technology, and they were using all the right words.  And it really looked like they understood they had to get this right, and they did.



LEO:  Good.  That's excellent news.



STEVE:  So I would tell Bruce, yes, it's safe to use power line networking.



LEO:  Very good.  Lance Reichert in Greene, New York wonders what his corporate security people are meaning when they say, well, let me read it to you:  A quiz circulated by my company's security department says filling out online forms like web questionnaires or registrations to receive work-related magazines, for instance, when you're doing it from work, is a serious risk.  Quote, "Every time you log onto a web page you create a scenario hackers could potentially use to crack your employer's network."  Huh?  Every time?  If this is so, how is anyone going to safely conduct any business at all on the web?  Are they talking about avoiding shady offers, or are they talking about exploits through well-known, well-managed sites such as EE Times Online?



STEVE:  I thought that was a neat question because you can sort of see a little bit of FUD spreading.  I would say that his particular corporate security people are a little over-concerned, though it's probably a good thing from a standpoint of educating the employees of the company to sort of give them a sense of things you do on the 'Net are not completely without risk.  And I think he summed it up nicely.  It is, you know, these are what we've talked about.  We've talked about how the number one attack mode now is going to bad websites with browsers containing vulnerabilities.  And I guess that's being redundant to say "browsers containing vulnerabilities."  They all do, apparently, from everything we've seen.



LEO:  Some more than others, but yeah.



STEVE:  Well, and vulnerabilities known or not yet known...



LEO:  Right, that's the problem, you can't guarantee that...



STEVE:  ...discovered or not yet discovered.



LEO:  Yeah, right.



STEVE:  And so the problem is that some bad websites can do this.  Now, we've also seen situations - and he refers to EE Times Online.  It might very well be that the EE Times Online webmaster and company are above reproach, their integrity, and would never deliberately hurt anybody.  But their server could have a vulnerability that allows people to change their web pages and put malicious code on them.  And we also see that happening all the time.  So you can't just trust a highly credible site not to do something bad to you because highly credible sites are being infected because, while they may be credible, they're not keeping their own security up as much as they should.  You know, they might have a framework which is using SQL database on the back end in order to generate their web pages and have an exposed SQL port with a vulnerability that allows somebody to get in and take them over.  So, and there are - we've talked about various types of exploits of this nature.  So it's true that the web is not completely safe.  I sort of think that the corporate IT people are maybe making a little more of this than they should.  But it's certainly something to keep in mind.



LEO:  Yeah, I mean, yeah, I guess it is a good thing to say, you know, be careful out there.



STEVE:  Yes.



LEO:  Don't order EE Times - well, you're right, you can't assume even EE Times would be safe.  I mean, so what do you do?  Because he has the point that it kind of makes the web kind of useless if you can't fill out forms.



STEVE:  Well, you turn off scripting, Leo.



LEO:  Ah, yes.



STEVE:  Sorry about that.



LEO:  Well, you know what, I'm coming more and more on your side on this one because it really - it seems to be the only thing to do that secures you against most of these exploits.  And something like NoScript for Firefox makes it very easy.  I mean, you just, you know, when you get to a site you want to - the problem is, okay, now you go to the EE Times site.  And I guarantee you they use JavaScript in some context.  And you want to use the site.  You're going to turn it on.  But now you're vulnerable to an exploit they may not have known about in the form.



STEVE:  Right.



LEO:  So you're still kind of stuck.



STEVE:  We will be talking soon, in fact we're going to have the author soon of Sandboxie because...



LEO:  Which is a great program.



STEVE:  Yes, a large number of the people who hang out in GRC's newsgroups are, I mean, they're using Sandboxie.  They love it because it sort of is a lightweight sandbox.  And I've had some dialogue with the author, and I've just been waiting for a window of opportunity to get him on and talk about it because it is a great program, and it does have the advantage of putting some protection around your browser to keep your browser from being able to do anything to your system that you don't want it to.  And so the heavyweight approach is to use a full VM, a full Virtual Machine system like Parallels or VMware or...



LEO:  But they raise this interesting point.  You're on the corporate network now.  Even if you're using a virtual machine, can't something bad spread through the network?



STEVE:  Yeah, um...



LEO:  You really want to isolate it from the network, too.



STEVE:  And of course you can't isolate a browser from the network because...



LEO:  You can't.



STEVE:  ...it's got to be on the network to browse.



LEO:  We're screwed, basically.



STEVE:  Yeah.  It's not good.



LEO:  It's not good.  You just, what, do you pray?  You just hope.  You say okay and just...



STEVE:  I think all you can do is be as aware as you can.  You know, as I'm reading email from our listeners, the overriding sort of background theme is, you know, listening to this podcast has raised their level of awareness.  They're more aware of these things.  And it's changed their habits.  You know, we don't want people to just disconnect from the 'Net and go sit under a tree.  We don't want to keep them from doing the work they have to do.  But there are things you can do like considering trying Firefox and NoScript and seeing how that works for you, and knowing that you really do have more protection than if you're just using IE with scripting turned on.



LEO:  And it's important, even though there is no perfect protection, it is important to remember that some protection is better than no protection at all.  You shouldn't just throw up your hands and say, ah we're screwed, and give it up.



STEVE:  I so often think, as I'm using my key in my front door, what a ridiculously poor security a lock and key are. But it's better than leaving your door unlocked.  It certainly won't keep anyone from getting in if they want to.  But again, some is better than none.



LEO:  Lance - oh, no, that was Lance.  Matt Ludlam in Weybridge, London has a few questions about stressing his socks.  Got Sockstress?  Steve, love the show, the only one I listen to and learn from every week.  Okay.  One thought on the most recent Q&A, you mentioned that the latest versions of Microsoft's web server IIS have been hardened against some forms of TCP attack.  My understanding is an application like IIS would pass information to the TCP stack, and the TCP stack would then manage the lower level communication.  Following on from there, if Microsoft hardened IIS, in effect they'd be hardening the entire TCP stack.  Ergo, we are all safe.  Are we?  Obviously my above conjecture must be wrong, but where?  Does IIS have its own TCP stack in users mode?  Does Sockstress pick up on areas that Microsoft has not hardened?  Your thoughts, as always, eagerly anticipated.  So he's saying basically Microsoft says we've fixed IIS, we've hardened.  And he's saying, but wait a minute, isn't the problem at TCP?



STEVE:  Yeah.  I liked the question because I didn't really explain that very well when I talked about it before, and a number of our listeners had written with similar questions.  The relationship between the TCP stack and the applications that use it is such that the stack is sort of a service that the application uses.  So a web server like IIS says I want to accept connections coming in on port 80.  But I'm not wanting to reinvent the wheel.  TCP is a complicated protocol.  So I want the operating system that I, IIS, am running on, to deal with all the messy details.  I want to accept connections on port 80.  I want to be notified when someone connects.  I want to receive their data.  I want to send them data.  But I don't want to have to worry about the bandwidth delay product.  I don't want to worry about packet loss in the connection.  I don't want to be - I just don't want to deal with any of those details.  I want to be told when they connect, told when they disconnect, get their data, send them data.



And so the so-called "socks" interface, the socket interface that the operating system creates is an abstraction of all of that, everything else that the TCP protocol deals with.  So one problem, for example, that I discussed when we were initially talking about sock stress would be the idea of a client creating a connection and then stalling the connection by saying that it had no available buffer space at its end to receive any data.  So the server would sit there and patiently wait for some buffer space to become available.  Meanwhile, that client could be creating connection after connection after connection doing the same thing, building up this large number of stalled connections.



So an application like IIS, but one that wasn't aware that this could be considered abusive, would sit there and go, oh, look at all the people that want to connect to me, isn't that nice.  I wonder - I wish I could send them something, but none of them are willing to receive any data.  Doot do doot do doot do doo.  And it would sort of sit there waiting until somebody received data.  And before that happened, something would collapse.  The OS would run out of space.  The stack would collapse.  The application wouldn't be able to hold any more connections.  Something would just, you know, go wonky.  So a smarter application, a hardened application, not necessarily the stack itself, but the application, could be told, okay, look.  We're not going to put up with this.  If lots of people are connecting, but no one is willing to have us send them any data, we decide that's not okay.  And so after 15 seconds of this, which is really - it should never happen for that length of time.  Then we just say, okay, sorry, you had your chance, and we hang up.  Because the application can disconnect in the same way that the client can disconnect.



So the idea is that the service using the stack, which inherently kind of creates the vulnerability by telling the stack to open the port and please accept connections, the service could be hardened against these kinds of abuses, where it inspects the - like it inspects what's going on on those connections and becomes intolerant of behavior that technically is okay, but unfortunately in the 21st century of the Internet can more often than not be indicative of abuse.  And so it says, eh, you've had 15 seconds, you're still not getting any buffer space.  Look, so don't call back because, if I can't send you anything, what's the point of hooking up to me anyway?  And so just hang up.



LEO:  I don't trust you.  I don't like you anymore.



STEVE:  And so that's a much better thorough description than I gave last time.  But it does also tell you that, while you might have IIS running on a server that is protecting itself, you might also have an SMTP, an email server running there, not protecting itself.  So while port 80 might, on a given IP address, on a given server, might be invulnerable to a Sockstress attack, the attack could simply switch over to port 25, where SMTP is running, and you might have a non-stress proof email server which you could do the same thing to and bring things down.  So it is a per-application solution unless the stack itself were hardened.  So either the stack could be hardened, TCP stack - and doing that would protect all the applications on the system.



But it might be that there are some applications that would want to tolerate that kind of behavior.  For example, you know, one of the things that IIS does, as I mentioned, is if it sees a connection that's been held open for a long time and nothing going on, it'll close it.  But TCP the protocol deliberately allows that kind of connection.  That is, TCP, you don't have to have any packets go by for weeks.  And then you can send something.  And as long as both ends still agree that there's a connection, that packet, that data will go across the 'Net and be received.  So TCP the protocol allows for infinitely long connections with no data transit.  By definition, some things want that.  IIS can decide, or whatever hardened web server, I'm not an application where that makes any sense.  We're going to shut those connections down.  So you have to be careful if you harden the stack in a way that would break things that are making assumptions about TCP, and you're changing those assumptions.



LEO:  All right.  Makes perfect sense when you explain it that way.



STEVE:  There's a complete answer.



LEO:  Yes, as usual.  Sheldon Smith in Apple Valley, Minnesota wonders why Visa is not enough:  Hi, Steve and Leo.  Let's talk about Internet security and online shopping.  The two of you frequently mention PayPal, but PayPal is tight with DoubleClick.  And recently you mentioned Amazon is coming out with a competing online payment service.  Google has one, too, as a matter of fact.  My question to all this is, but why do I need something else?  Visa already provides online security and, as you know, watches out for fraud so I don't have to.  I already have a Visa card.  In fact, both my credit and checking account and debit cards are associated with Visa.  So why do I need anything but Visa?  Why are Amazon, PayPal, and Google doing their own payment service?  Even Amazon offers a Visa card.



By the way, I started back around Episode 7.  I've listened to every episode so far.  Steve, back when Leo first came up with the idea, who woulda thunk this funny little podcast would still be going strong after four years?  Great job, guys.  Well, thank you.  That's very nice, Sheldon.  I guess it's true. Why do we need other payment services?



STEVE:  Well, there are a number of reasons.  First, I like the idea of insulating myself and my financial...



[Talking simultaneously]



LEO:  ...credit card to a vendor.



STEVE:  Yes.  Yes.  But one thing that Sheldon doesn't mention is, it is a hassle losing your credit card.  And when I say "losing," I mean losing it onto the 'Net.  It's happened to me now three times, even though, you know, I'm Mr. Security Now!.  I'm not giving my card out to random people that I don't have to.  I will say, however, I'm giving it out much less often now that PayPal allows me to generate cards on the fly.  I'm liking that and using that a lot more because it'll allow me to create a temporary card that is just there for one use, and then I shut it down.  So in my experience what has always happened - and it happens that I'm a Visa card user.  I don't know why I got onto Visa, but that's what I use.  As I mentioned once on the show a few months ago, I got a call from them saying, hey, somebody's using your card in France.  Is that anything that's authorized?  And I said, eh, no.  And so they said, okay, we didn't think so.  Someone made a test purchase, which they denied, and then a big purchase.  And that was the trip that tripped them up.  And so I was protected.  So that was really nice.



LEO:  And I have to point out that's something that I don't think you get - the credit card companies do it by law because they're required to by law.



STEVE:  Yes.



LEO:  I don't think PayPal, Google payment or Amazon payment has that same requirement.  I know, in fact I know PayPal doesn't because I got defrauded.  And unlike with a credit card, where you just - by law they have to stand behind you, PayPal I had to go through many hoops.  And frankly, I think if I hadn't escalated it to the office of the president, I wouldn't have gotten my money back.



STEVE:  And for what it's worth I have heard that American Express is even more pro-consumer.  American Express...



LEO:  Yeah.  Well, you pay for that, believe me.



STEVE:  Yeah, they don't even ask a question.  They just give, you know, put the money back on your card.



LEO:  So credit cards by law are, you know, the banking laws in this country require them to do that.  And some do better than others.  But I don't know, and maybe this is just a gap, and maybe the law will fix it at some point.  But I don't think they have the same - you have the same kind of protection with these payment services.  So that might be a reason not to use one.



STEVE:  Well, in my experience, I guess the point I wanted to make was that while, yes, you are protected from the financial consequence of losing your card, having it get loose on the 'Net, you are not protected from the hassle of changing the number.  I've got a bunch of things, you know, Amazon knows my card number.  I subscribe to the little toll road pod that deducts automatically from my card whenever the account runs low and a number of things that, last time I lost my card, had to have the number changed, it was like, oh, god, okay, now, what are all - and my cell phone billing goes to my card and all that kind of thing.  So it really is annoying to have to change your credit card number.  And going through an intermediary that either doesn't use, doesn't expose your card to the 'Net, or someone like PayPal that allows you to generate a pseudocard for the purpose of doing a single transaction, it prevents you from having that exposure.



LEO:  I guess what I'd like to see is the same requirements put on these payment services.  Now, here's a question.  If I use that one-time-only Visa number that PayPal gives you, I presume now I'm using a Visa card that I'm protected.  Right?



STEVE:  Actually it's MasterCard in the case of PayPal.



LEO:  I would assume that that gives me now those protections because I'm using a PayPal credit card.



STEVE:  So let's see.  So somebody else uses it again, it's not going to work.



LEO:  Yeah, but I'm just saying the fraud protection.  Here's the deal.  When you buy something with PayPal, if you get defrauded, it's up to PayPal what they want to do about it.  Not so with a credit card.  If I use a PayPal credit card, I would presume, because now we're using MasterCard, that we are protected.



STEVE:  Yeah, I don't know.



LEO:  That's a good question.  Like to find that out.  See, it's a tradeoff.  And what I'd really like to see is the banking laws say, you payment services, you have the same requirements as a credit card has.



STEVE:  Yeah.



LEO:  Let's see.  Let's go to New Jersey.  Paul Corr in Trenton, New Jersey was concerned and a bit confused about Skype quality and the need for port forwarding, which is something we do.  We'll talk about it.  I have a colleague in the U.K.  We use Skype to talk to each other.  I decided to research best practices.  Skype has a security page.  I see connections point-to-point are encrypted to guard against man-in-the-middle attacks - unless the man in the middle is Skype, but we'll talk about that some other time.  I see connections - right.  Important because it is a peer-to-peer network.  I found a page on improving performance by using port forwarding, and I found my router setup details on PortForward.com.  After reconfiguring my router I visited ShieldsUP! to test vulnerability and found it failed due to ping exposure.  I reenabled "block anonymous requests" in the router admin screens, tested again.  Now it passed.  I will return to Skype's preference for using dynamic port assignment rather than the explicit high port I set following the article on performance.



So now I'm wondering what is a best-practice approach for Skype security?  I did find the GRC page on NAT and saw that if one port forwards, it should be on an isolated machine.  Any light you and Leo can shed would be appreciated.  I found Security Now! a while ago and returned to the archive of earlier podcasts until I caught up.  Thanks again.  Well, thank you, Paul.  I'll tell you what I do, and you tell me if it's safe, Steve.  I have a dedicated port for Skype, 22222, something like that.  And I port forward from my router to that particular machine, 22222.  So that is the only machine that incoming connections on that port can be accepted.  And that gives us, I think, better Skype results.



STEVE:  Yeah, there are a number of things going on here that are interesting and non-obvious that Paul's question brings up.  First of all, I'm not sure what he did on port forward.  But he says that by reenabling "block anonymous requests" he was then able to get a true stealth pass on ShieldsUP!.  Port forwarding itself should not cause a ShieldsUP! failure, especially on a high-numbered port.  So what he may have done - there are two ways to enable unsolicited incoming traffic through a router.  There is port forwarding, which you mentioned, Leo, where you specify by - explicitly say I want this port number whatever it is to be forwarded to a specific IP behind the router, to a machine on an IP behind the router.  And then only traffic bound for that port will go to that machine.



The alternative means is something called a DMZ, the so-called demilitarized zone, which is what DMZ stands for.  And that's an entirely different approach.  That says allow anything unsolicited to be sent to a specific machine.  Now, if you do that, ShieldsUP! will go nuts.  I mean, it'll be lighting up in red because...



LEO:  Yeah, DMZ is a pretty big cannon to use against a little gnat of a problem.



STEVE:  Yes, if you'll pardon the pun.



LEO:  You're opening everything.



STEVE:  Yes.  Now, I should also mention, though, stepping back from both of these, that the only time that this is necessary, that any DMZ or port forwarding is necessary to improve performance or call quality, is in the event that both of the endpoints are behind NAT-hostile routers.  That is, it's more the case these days that port forwarding won't buy you anything.  You and I do it, Leo, because we absolutely positively insist on having a really good connection between us.  It happens that my NAT box is NAT hostile.  It is not something that Skype is able to penetrate.



Remember that Skype came from the - Skype was developed by the guys who did Gnutella.  And one of the Gnutella technologies was very good NAT traversal where they came up with the idea of how Skype Central could talk to both endpoints and arrange a direct connection between them.  Well, that requires that one or the other of the NAT routers be NAT traversal friendly, which means it'd be predictable in the way it works.  Mine isn't, so I had no choice but to statically map a port through my router.  So what I would tell Paul is that one thing you can do, with no port forwarding established, is to use a program like Wireshark, a packet-capturing program, which is actually pretty easy to use.  It's a nice program.  It installs cleanly.  And while you're talking to your friend in the U.K., take a look at the packet flow and see whether the UDP packets, which will be streaming out of your system, are going to his IP, that is, the IP that he currently has for his router or his Internet connection.  So that's a robust way of determining whether there's any relaying going on.



The reason performance and call quality drops in some cases is that if Skype is unable to establish a direct point-to-point connection, it will use somebody else's machine, who knows who, somebody who is out on the 'Net, who is not behind a firewall.  It will actually relay traffic through a so-called Skype supernode in order to still allow that connection to be connected.  One of the ways that Google Talk differs is that it doesn't use its customers' machines as supernodes if it can't establish a NAT traversal, a direct link between the two endpoints.  It will do the traffic forwarding on behalf of that connection.



So it's not the case that you ever gain - that you necessarily gain anything from doing port forwarding.  But oftentimes you can.  And if you care about higher quality, it does make sense to do that.  You do not need to use this DMZ mode, which as you said, Leo, is really - it's easy to turn it on, but you're opening yourself up to lots of security problems because essentially it's like putting that machine right out on the Internet.  Unsolicited traffic can all get to it.  So that's the case where you really want to make sure that machine is isolated.  But again, you don't need to do it.  All you need to do is route a single port through to Skype.  And then you tell Skype in the UI which port you have sent to it.  And that will cause it to then route the traffic in to you.  And, also, only one of you really needs to do that.  Because, if one does it, then the other person is always able to initiate a connection out through their NAT, no matter how hostile their NAT may be, in through your forwarded port to your machine. 



LEO:  I find it really - maybe it's voodoo.  But it seems to make a difference.



STEVE:  Oh, it's a good thing.  It's better.



LEO:  I mean, we probably, because we have routers, we're never going to be a supernode or use supernodes; right?



STEVE:  No, that's the other nice thing is, if you were to DMZ your machine, you would be exposing it to carrying Skype traffic from other customers.  But if you use port forwarding, then you're not able to accept supernode traffic.



LEO:  That's very interesting.  On we go.  More questions for you, sir.  Hi, Steve, says David Greenland in Perth, Western Australia.  I have just found out that my ISP, Telstra, is blocking port 25.  They claim this will help eliminate spam through the port.  I need to know how me using port 25 on my mail server affects Telstra.  They claim that to overcome this issue I need to register and pay $10 a month for a static IP address.  Well, $10 a month may not seem like much to U.S. Internet users with their 25GB limits - ha ha.  It's actually 250GB.  It is an exorbitant amount since I already pay $99 a month for a mere 25GB which by the way is upload and download combined.



Is there any way I could change my SMTP port to still send mail from my mail server whilst using my dynamic IP address?  I have this through dnsExit, which periodically an application on my server checks my ADSL IP address and updates my DNS records to suit.  This works great and is absolutely free.  Thanks for any help you may be able to offer.  I enjoy the netcast, though much of it is beyond me.  Keep up the good work.  It won't be beyond you for long if you keep listening, I promise.



STEVE:  Okay, well, there are a couple of things going on here.  So one of the things I've been expecting sort of for a long time, and I'm still expecting it, I can foresee the day where ISPs will simply drop incoming SYN packets, incoming TCP SYN packets at their border.  It is so trivial to do.  And what that immediately does is it prevents any of their customers from being a service, from serving over TCP, like the SMTP protocol, the Simple Mail Transfer Protocol on port 25 that David's talking about.



LEO:  So I just want to make this clear.  They're not talking about blocking port 25 to protect you from spam.  They're talking about blocking port 25 so that you can't send spam, or some demon on your machine without your knowledge can't send spam.  This is a big problem; right?



STEVE:  Well, now, that's the other question, is that there's - when he says they're blocking port 25, it's not clear whether they're blocking traffic inbound to port 25 or outbound to port 25.  And both can be done.  For example, many ISPs, in fact I think Cox does it, for example, there's a big cable modem company here in Southern California, many ISPs will block outgoing traffic to port 25 because what that prevents - because that prevents a client, their customers, from sending traffic to other people's SMTP servers.  They allow you to only connect to their own ISP-provided SMTP server.  For example, in the case of Cox I think it's west.smtp.cox.net.  So you have to configure your email client to send your outgoing email there, and then they will forward it on.  So that's blocking outbound traffic with a destination of port 25, which is for sending email to somebody else's - sending email out to the Internet.



Now, what David is describing is different, though.  And it's further assured because they talk about registering and paying $10 a month to receive a static IP.  What that's implying is that he would be - he'd have a fixed IP.  And they would then allow incoming traffic to his port 25 for his email server.  And he talks about running his own email server.  So there normally what you do is of course you use your ISP's email server.  So, you know, yourusername[@]yourISP.com.  And so email traffic coming in to you goes to port 25 on your ISP's email server.  And then your email client picks it up using POP protocol or IMAP protocol in order to obtain the email which is sitting on your ISP's email server.



What David is saying he wants to do, and he's using a dynamic DNS service in order to keep his own domain pointing at his own machine, even though its IP may move around, he wants to run his own email server for whatever reason.  So, well, and for example, that way it could be david[@]davidgreenland.com, for example.  He'd have his own domain that he's come up with.  And so it's just sort of nice.  He can, you know, he's got his own domain for his email.  There might be, you know, family or special interest or who knows what it is.  So in this case his ISP is saying, ah, we're blocking incoming email on port 25 unless you pay us money.  We'll give you a static IP, and then you can run an email server.  So, again, I'm - at this point that's a less common thing to do.



Now, we are seeing other ports blocked.  We're typically now seeing, for example, as a consequence of the history of Windows vulnerabilities, we're seeing ports 135, 136, 137, 138, and 139 are blocked, and often 445, which are all the Windows filesharing ports.  Those are often blocked coming into an ISP, which protects all their customers from the traditional bad Windows filesharing attacks.  So again, I wouldn't be surprised if, in the fullness of time, we see ISPs just saying, eh, we're not going to let customers be services at all.  You can be clients of the Internet.  You cannot be services of the Internet.  Unless you make special arrangements, like at this point Telstra is doing with port 25 for somebody who wants to run their own email server.



LEO:  Right.  All right.  No, that makes sense.  I think this isn't just Telstra.  You're seeing this, as you said, most cable companies are now doing it.  Comcast resisted this for a long time.  And people said, look, if you just block port 25, you're going to eliminate a lot of the zombie spam that's coming out of your network.  And they said, but if we do that we're going to get millions of dollars in tech support calls from people who suddenly whatever was set up isn't working.  So they resisted it for a long time.  They finally did it.  And I think it probably does make a big difference in the amount of spam that's being sent by, not intentionally, but being sent by these zombies.



STEVE:  Well, that, again, that's outbound port 25.



LEO:  That's outbound.  Right.



STEVE:  Right.  Because in order for people to send spam they need to send it to somebody's remote server.  Now, you can certainly send spam to your own ISP.  They'd get unhappy very quickly.



LEO:  They'd know.  They'd know.  Exactly.  What a lot of these zombie programs do is they actually put an outbound mail server on the PC, an SMTP server on the PC.  And for it to work, it uses port 25.  You could use any port; right?



STEVE:  Again, it uses outbound - it's sending...



LEO:  Outbound port 25, yes.



STEVE:  Yeah, it's sending packets to somebody else's SMTP server which is available and open on the 'Net.  And there are so-called "open relays" which are SMTP servers that will accept email from anyone to anyone.



LEO:  Well, couldn't it just - what if I'm running an SMTP server on my machine, whether with my knowledge or not?  Why would I need to go to another SMTP server?  Wouldn't it just become an origination point for spam?



STEVE:  No.  Well, if you were running an SMTP server on your machine, you would put your spam on your SMTP server.  Then it would need to forward it to somebody else's SMTP server in order to deliver that spam.



LEO:  Oh, I see, as part of the process.



STEVE:  Right.



LEO:  Right, yeah, I get it.



STEVE:  So in that case it would not be using probably an open relay.  It would literally, for example, if you had spam bound for AOL...



LEO:  It would just go right to AOL, and AOL's going to accept it and say it's...



STEVE:  It would look up, yes, it would look up the so-called "MX records," the mail exchange records, for the AOL domain.  It would give it a whole list of IPs of AOL's SMTP servers.  It would then - those would be listening on port 25.  It would then connect to one of them on port 25 and start sending garbage to it.  But in every case that would mean that traffic would be egressing from the ISP bound for port 25, which the ISP - and that's what ISPs have blocked.



LEO:  That's what they don't want, yeah.



STEVE:  Right, yes, exactly.  There is no reason that their customers should need to be directly connecting to foreign SMTP servers.  Their customers should connect to their SMTP server, and then their server will forward it out to AOL, for example, in the...



LEO:  But that's what David's doing, he's running his own SMTP server.



STEVE:  Well, no.  He's receiving on port 25, which is different than sending to port 25.  So he's running his own SMTP server because he wants to support his own email domain, and so allow people to send email to davidgreenway.com.



LEO:  Oh, okay.  Well, because there are people who run SMTP servers for outbound mail purposes.  You're...



STEVE:  Yes.



LEO:  I just thought that that may be what he was doing.



STEVE:  Ah, okay.  But if he were, then he wouldn't need - he wouldn't go through the dynamic DNS and all that.



LEO:  Ah, you're right, that whole point of that is so that you can get inbound stuff.  You're absolutely right.  Yeah, I get it.  Yeah, I get it.  I love this idea of blocking SYN packets.



STEVE:  Well, it's simple.  It is so trivial.  It's one command given to a router, essentially.  And...



LEO:  It would eliminate all of this stuff.



STEVE:  Yes.  It ends all incoming connections.



LEO:  What would be the negative?



STEVE:  All kinds of things would break.



LEO:  Things like remote access, things like that.



STEVE:  Well, and for example, I believe that Skype uses TCP connections for its persistent connections.  I know that Hamachi does.  And so Skype uses UDP, as does Hamachi, for its bulk data transit.  But TCP is still often used.  On the other hand, those are not incoming connections.  Those are outgoing connections.  Those are clients connecting to the Hamachi server or clients connecting to Skype.  So it's not the case that most things that people are doing would be broken by simply disallowing incoming TCP connections.  And I expect it in the future.



LEO:  But it is exactly that issue that I talked about, with Comcast saying, yeah, we'd like to do it, but it's going to cost us millions in people going, you broke XYZ.  It was working.



STEVE:  Well, and remember, too, Leo, we have seen instances, we know there are ISPs that are NATing all their customers.



LEO:  Right.



STEVE:  ISPs are running big NAT boxes, and all of their customers are receiving private IPs, not public IPs.  Well, the fact that that's happening means none of those customers are able to receive incoming TCP connections, or UDP for that matter, neither protocol, because it's just like they're behind their own NAT router.  And their computers are being protected from incoming unsolicited connections.  So it's certainly the case that ISPs are already not providing those services to their customers.  And apparently it's working.



LEO:  Ian Clark in Sydney - we have a lot of Australian listeners.  You ever notice that?



STEVE:  Yeah.



LEO:  Ian Clark in Sydney, Australia wonders whether all solid-state drives are created equal:  Hi, Steve.  Is a thumb drive and the new, no-moving-parts, solid-state hard drive, are those the same?  Can they both read and write the same as a normal hard drive?  What's their lifespan?  Thank you.  Oh, this is a good subject.



STEVE:  It is.  And I did a little - I updated myself on the state of the art a month ago because I decided I was going to splurge when I did my little OQO machine and have it configured with the 64GB solid-state drive.



LEO:  Quite a splurge, if you get a good one.



STEVE:  Yeah.  And I did.  And so I wanted to find out exactly what was the technology going on, what was I paying so much money for.  Because here you've got a 32GB SD card.  Why aren't two of those the same as one 64GB solid-state drive, you know, a full-on SSD?  There are a couple things going on.  Not all - first of all, the answer, are they all created the same, the answer is no.  There is cheap technology.  And in fact I don't remember now what show it was of yours I was listening to, but I had your TWiT Live channel on in the background, Leo, and there was some discussion of multilevel storage versus single-level storage.



LEO:  Yes, SLC versus MLC.



STEVE:  Yes.  Yes.  SLC is much more robust and much more reliable and more expensive because it is less dense.  It only stores one bit in a single cell, rather than multiple bits.  The way the MLS, the multilevel storage functions, is it's literally they're not bits, where "bit" means binary digit.  You know, that's what "bit" is a contraction of.  They're mvts or mivits or something.  They're multilevel digits where an analog value stored in the single cell is used to store several digits or several bits' worth of data rather than just one.  So the cell isn't storing a 0 or a 1.  And you might think of that as like a voltage of 0 or 10, for example.  It might be storing 0, 1, 2, 3, 4, 5, 6, 7, 8.  So it might store eight different levels of voltage in a single cell that allows that cell to represent three bits of data.



Well, while the advantage of that is that you get three times the density, the problem is now you've got to be much more careful in distinguishing the voltage level.  It's not just either 0 or 10 volts where you set a threshold, for example, at - well, actually you set a threshold generally low because, if the cell discharges over time, you want to make sure you know that it was once 10.  But if it's 0, it's going to stay at 0.  So, for example, you would set a threshold of maybe 2.  And if it's anything greater than 2, you call it a 1.  And if it's anything less than 2 volts, you call it a 0.



The problem with multilevel storage is you still have that uncertainty, but that means that you could have more problems because there is a cost in reliability of storing more bits in a single cell.  The advantage, of course, is you get higher density and lower cost.  So solid state drives that need to be high-performance and highly reliable, they're not only universally single-level storage, so they're much - they're the most you can get in reliability.  They also go to great lengths to do so-called "wear leveling."  That's the other thing that you need in a high-quality thumb drive that will be missing from the cheapo thumb drives they give away now free at the cash register at Micro Center and Fry's and things.  Those things, I mean, again, you get what you pay for.  What it means is that it's much easier to burn out spots in a highly used thumb drive that is not doing good wear leveling than is possible in a thumb drive that has high-quality wear leveling.  You pay more for it because there's more logic involved, and it's just a higher cost solution.  But in this case you get what you pay for.



LEO:  Right.  Yeah, it was with Ryan Shrout of PC Perspective - in fact we're going to start doing a little hardware show with him, he's great, on Thursdays on TWiT Live.  And so we were talking about - I was talking about the Mac, the new Mac laptops.  And it's very easy to remove the drive and put in a new solid-state drive.  They only charge a few hundred bucks for - I think 400 bucks for a 128GB drive.  And that's...



STEVE:  Whoa, whoa, whoa, whoa.



LEO:  That's cheap.



STEVE:  What?



LEO:  Yeah.  Well, and that's probably because it's SL - MLC; right?  That's the cheap memory.



STEVE:  Wait.  Mac?  Apple?



LEO:  Apple, for a premium of I think it was $400 you could get the 128GB solid-state drive in there.



STEVE:  Wow.



LEO:  But it's not a good - so Ryan was saying the Intel is the best drive, and it's twice as much for that storage.



STEVE:  Yes.  And again, you're getting something for what you pay.



LEO:  Yeah.  So, yeah, I'm wondering what they're using in there.  Obviously they want to promote SSD drives.  And I was very intrigued.  But what I decided was I'm going to buy the solid - the regular hard drive.  And when solid-state drives come down in price - will they come down in price?  I think they will in a year or two.



STEVE:  Yes.  And I heard you say that, Leo, and I thought that was very smart.  So, you know...



LEO:  Simple thing to pop it in.



STEVE:  Yup.



LEO:  And then you get a big upgrade in value for - you kind of get another year out of the thing.



STEVE:  Yup, I think that's very smart.



LEO:  Steve, are you ready for one more Wells Fargo?  It's just - it's so funny.  Should we give people the background?  If you haven't been listening, this all started with one email from a guy who's a Wells Fargo online customer, who said, hey, it's ignoring, it's chopping off the extra five characters or whatever in my password.  It seems to be case insensitive.  Is this secure?  And then we've been going back and forth ever since.



Here's the latest from Gary Warner.  He's the director of research for the University of Alabama Computer Forensics - this guy ought to know - in Birmingham, Alabama.  Man, we've got smart listeners.  He says:  Steve, sorry, I'm far behind on my listening so only now getting to the September 11 broadcast.  That's the one we talked about Wells Fargo.  But I wanted to comment that banks still run on mainframes.  Mainframes have been accepting userIDs and passwords since the '60s.  Many web apps in banks are just front-ending mainframe applications.  And it is the problem that may mainframe systems can't have userIDs or passwords longer than eight characters, in some cases seven characters.



It's also not possible on these same systems to have a case-sensitive userID.  Everything's uppercase.  Recall again that some of these systems were implemented before we even had shift keys on computers.  I just thought you'd get a kick out of that.  What you describe is actually quite common for front-ended mainframe applications.  I'm listening to Security Now! tonight on my iPod while my Computer Forensics students at UAB take their mid-term exam.  I bet he's a great teacher.  Gary Warner, director of research, University of Alabama Computer Forensics in Birmingham.  Thank you, Gary.



STEVE:  And it's certainly the case that...



LEO:  It's true.



STEVE:  ...the way a lot of these systems have been moved onto the web is that a front-end GUI-like application is still talking to really old, traditional technology on the back end.  And basically somebody was given the job of, we've got to get online, darn it, get us online immediately.  And so someone glued together a web surface.  But it's still talking to the same database technology on the back end.



LEO:  Yeah.  I know that because when I first started using my Bank of America online banking, I think I might have mentioned this.  It was white text, black screen, all uppercase.  You enter a menu item, 1, 2, 3, or 4.  Now, this was in the '80s.  But I bet you, I wouldn't be surprised if it's still the same mainframe behind the scenes, doing all the same things.  You know, I mean, it works.  Why mess with it?



Brian Voeller in Ashland, Oregon brings us the Fun Observation of the Week:  Happy DVD Day.  Greetings, Steve and Leo.  I just wanted to drop you a line of congratulations acknowledging the passing of a significant milestone in your program.  All of your episodes will now no longer fit on a single DVD.  As I type this, I am able to archive Episodes 1 through 164 for mandatory distribution to security-deficient family and friends.  Oh, my goodness.  I  hope they're geeks.



STEVE:  Boy.



LEO:  Note that while I've been saving the high-quality version, a bit of math reveals that the lower quality versions should fill a DVD just after January 2019, with Episode 692, assuming you keep to your current schedule.  And if I know Steve, we will.  That's cool.  So we've passed, I guess, 4.7GB worth of Security Now! episodes at 64kbps.  



STEVE:  Yup.  And in fact we're not even filling up your hard drive shelf very quickly at that pace, Leo.



LEO:  No.  Look, I've got, you know, we'd better hurry up.  I've got three 750GB drives so far.  We get about two weeks.  And this is video.  The video that I'm saving is 10GB an hour.  And still just three drives for the three months we've been running.  It's pretty amazing.  Pretty amazing.



And finally, Matt Bender, Madison, Wisconsin with the Big Topic for Next Week:  Hi, Steve and Leo.  I'm relatively new to the Security Now! - ahem - "netcast" and find it very informative and entertaining.  As an IT professional the topics you cover are very relevant to my daily activities.  The show on Sockstress was extremely interesting and, well, scary, to say the least.  I feel the same way.  I've been following another, possibly even more scary exploit called click-jacking.  I'm sure you must know about this, so I'd love to hear your views about it.  Keep up the great show.  Matt.  Thank you, Matt.  We talked about click-jacking, didn't we.



STEVE:  You and I never have.



LEO:  No?



STEVE:  No, we've not talked about it here.  It's been on my radar for some time.  And it is, as Matt suggests, important and potentially even more scary, many people feel it is more scary than many of the other things we've been talking about.  It's been in the news, the security news a lot lately.  And we will cover it in detail and in depth next week.



LEO:  Oh, good.  This is one, yeah, I've been reading a lot about it.  I've been testing stuff and seeing how it works.  I'd be very interested to know how it works and what we can do about it.  Besides running NoScript.



STEVE:  I was just going to say.



LEO:  It all comes down to running NoScript.  Hey, Steve, always great to talk to you.  Thank you so much for joining us, and we'll see you next time on Security Now!.



STEVE:  Talk to you then, Leo.  Bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#168

DATE:		October 30, 2008

TITLE:		ClickJacking

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-168.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss yet another challenge to surfing safely in the web world: Known as "ClickJacking," or more formally as "UI Redressing," this class of newly popular threats tricks web users into performing web-based actions they don't intend by leading them to believe they are doing something else entirely.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 168 for October 30, 2008:  Clickjacking.



It's time for Security Now!, the show where we cover everything you'd ever want to know about security.  And we do it with a guy who is the king, really, as far as I'm concerned, the man who discovered spyware, named spyware, wrote some of the most used security utilities out there, including ShieldsUP!, Mr. Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Yes, in fact sometimes we're discussing things that you'd rather wish weren't the case.  I mean...



LEO:  Well, lately it's been kind of bleak because it's like, there's bad stuff, and there doesn't really seem like there's any cure.



STEVE:  Yes, that's true.  I mean, because what we're beginning to see now is that the technologies we rely on fundamentally are really being exploited.  I mean, what we're going to talk about today, clickjacking, is very much like that.  The good news is there are things now that people can do.  Firefox users are essentially completely protected by recent updates to NoScript.  But we'll talk about all that, and also about some, well, there's lots of news in the last week since...



LEO:  Lots of security.



STEVE:  Yeah, since 167, so...



LEO:  So let's get an update on what's been going on in the world of security, Steve Gibson.



STEVE:  Well, it's funny.  Microsoft put out an out-of-cycle patch.



LEO:  Last week.



STEVE:  Yeah.  And I picked up a little blurb in GRC's newsgroups.  Some people were saying, do you think Microsoft deliberately does this after Steve and Leo record the podcast, you know, like the moment after it's been recorded and before it actually goes public?  Because this dropped out at exactly that time.  It is substantially different than, or more of a problem in some ways than [audio dropout] referring to it during the Tech Guy stuff over the weekend when you were talking about it.  Because this is not a user goes to a bad website with their browser sort of problem.



LEO:  Oh, I misunderstood it, then.



STEVE:  Yeah, it is like one of the old-style, packet arrives at your computer...



LEO:  It's a worm, okay.



STEVE:  Yes.



LEO:  Oh, I didn't know that, okay.



STEVE:  Yes, yes.  It runs - it's an exploit in the RPC service that runs in all versions of Windows.  It affects Windows 2000, XP, and Server 2003.  The architecture of Vista, the updated security architecture mitigates the problem.  But it's...



LEO:  Mitigates or eliminates?



STEVE:  Mitigates.  It's reduced from critical to important on those platforms.



LEO:  So why?  Is that because UAC pops up and says something's trying to access your system, or...



STEVE:  It's the nature of the way they're running the service.  The service that is exploitable, the remote procedure call, RPC service, it's sort of sandboxed so that it's not able to do as much damage as it can under 2000 and XP.  But, okay.  So this is a - basically it's the service which is always lit, is always running and open and listening for things coming in on ports 139 and 445.  That's the traditional Windows filesharing ports.  You know, file and printer sharing and other things.  So many things have happened to mitigate this being a problem, which is why, you know, I didn't immediately find, track you down and say, Leo, we've got to immediately alert our users to it.  Microsoft had to do the responsible thing, and call this critical, and push an out-of-cycle patch.



LEO:  And that's because there were websites already taking advantage of this; right?  There were sites out there that...



STEVE:  No, it's not websites.  But the way they discovered...



LEO:  Oh, there were worms floating around.



STEVE:  Yes.  The way they discovered it was that - and I'm not sure who it was.  It wasn't Microsoft.  It was somebody else who saw some suspicious traffic on the 'Net, like packets arriving to 139 or 445.  And they looked at them thinking, hmm, what is this packet trying to do?  This is trying to do something strange.  Well, turns out it was attempting to exploit this vulnerability that was not known.  So this was a zero-day exploit, meaning that it was discovered in the wild, I mean, for the first time.  And so...



LEO:  And I saw that a security service within two hours of Microsoft's release was able to reverse engineer it.



STEVE:  Yes.



LEO:  Immunize or something like that?



STEVE:  Yes.  There was immediately a proof of concept.  And now there are active worms.  And the exploits have been  moved into some of the security toolkits that exist.  So this thing exists now.  Now, setting back - so, okay.  Once upon a time, when we had Windows 2000 that did not have a built-in firewall, or we had Windows XP before Service Pack 2, which did have a firewall, but it was not on by default, that was the era where we had the Nimda and the Code Red and Blaster worms.



LEO:  Right, and Zotob, too.  So is this like those?



STEVE:  Yes.  This is as bad as those.  Except that the world has changed so much since then because Service Pack 2, of course, turned the firewall on by default.  And so many people are behind routers that block incoming traffic by default.  And one of the other things that Microsoft has done is that they've limited, by default, file and printer sharing to your local network.  So those services are not being offered out on the whole Internet itself.  If you look in the details of file and printer sharing and the server service, inherently they said, wait a minute, it makes no sense, unless someone's nuts and wants to make their C drive available on the whole Internet, it only makes sense to have that available on the local network.  So there is local network topology.



However, the concern is that, if something got into an Intranet that is behind either a home or small office firewall or in a corporate network, then potentially it could - this would allow things to spread between machines within a network.  So that was really where the concern was, is essentially, you know, you're behind the router, you're behind the firewalls, you're in a local environment where you might have trust among machines.  This potentially abuses that trust because there you would have a scenario where you might, for example, have available file and printer sharing among machines, and this can exploit - essentially it's a classic buffer overflow on the stack in this remote procedure call service running on all Windows machines by default.  So it was bad, but it didn't just go wild on the outside because Microsoft has, since the era of those worms, they've done many things like limiting the scope of the network where file and printer sharing was available to the local network.  And having a firewall turned on and having those ports blocked and so forth.



LEO:  Well, it's really an example of the success, in fact, of Microsoft's improved security policies that what would have been a big deal was nothing.



STEVE:  Right.



LEO:  Yet they still put out the patch.  I guess that's because there are still people who are not running firewalls.



STEVE:  Well, that and there is the scenario of local exploitation.



LEO:  Oh, internal, inside the network.



STEVE:  Right.  And so I think that was what really motivated them to do it now rather than wait three weeks for the next second Tuesday of November, when they could have certainly fixed it.  It also demonstrates...



LEO:  That actually makes sense.



STEVE:  It also demonstrates how quickly they can act if they really want to.  I've criticized them often for, like,  having bad problems that they have known about for six months before they do something.  And it's like, okay, clearly when they want to do something, they can fix something really fast.



LEO:  Yeah.  I think I got another one this week.  But maybe that was just some of my machines didn't get updated earlier.  There wasn't another one this week, was there?



STEVE:  No.



LEO:  Okay.  That's probably what the other machine is doing.  You know, it really is, in a way, a testament to you, too, because you're the one who's really been promoting this idea of using a firewall.  The whole idea of ShieldsUP! is, you know, protect yourself.  And so I think that drum beat's really been heard.



STEVE:  Well, and in fact ShieldsUP!, the original concept of ShieldsUP! was to tell people to absolutely close down those ports.  I mean, and the other thing, too, for example, in terms of mitigation, I have a Cox cable modem.  And Cox blocks those ports because of...



LEO:  It's RPC?  So is that 138, 139?



STEVE:  Yeah, it is the same file and printer sharing ports.  Several services all live on those ports.  So it's 139 - Microsoft said 139 and 445, which to me says it's a TCP exploit.  I don't know for sure that it can't be done over UDP.  But 139 is the TCP version of the older file and printer sharing that worked on 137, 138, and 139, when 137 and 138 were UDP protocol, 139 was TCP.  445 uses both UDP and TCP, sort of in the new generation of Microsoft's use of these services.  But it's specifically in response to the prevalence of those worms in the past that ISPs began blocking those ports.  So there is another example of how things have moved along such that this wouldn't be a problem.  Because, you know, even a Cox cable user with a wide-open Windows 2000 or old XP machine or an XP machine where they were deliberately trying to open those ports, Cox wouldn't have allowed that stuff to get in from the outside.



LEO:  Well, it's good news.  I mean, it sounds like - and it's true that we haven't seen any - I remember when Zotob came out, and CNN was brought to its knees.  We haven't seen anything like that.



STEVE:  No.  No.



LEO:  Will these worms be endemic to the 'Net in the same way that Sasser and other worms just kind of live forever?



STEVE:  Yeah.  We are seeing traffic for a new trojan which is looking for machines that have this vulnerability.



LEO:  The sad thing is that those machines get bit, it's the Windows 95 machine that's running dusty in the closet somewhere doing some crazy little service.



STEVE:  Yes, and we've seen that before.  Strangely enough, there are, like, old Windows 2000 servers...



LEO:  Unpatched.



STEVE:  Exactly.  No firewall, on the 'Net, just sort of abandoned.  But, you know, they will end up getting found.  They'll get exploited, and then they in turn will start searching for other machines in standard worm propagation behavior.  And so now those machines that'll have this thing on them will just be spraying this traffic out on the 'Net, as I call it, "Internet background radiation," IBR.  It's just stuff that'll live there now and we just put up with.



Opera, just after - I think it was last week that I told people about the update 9.61, which fixed three relatively worrisome vulnerabilities in Opera.  Just, like, the day after they released the patch, another related one was found.  We don't yet have the update for it.  It'll be 9.62.  And the Opera folks have said real soon now we'll release it.  But I wanted to let people know.  Probably by the time a week passes and this next podcast comes out, our next one, I imagine that Opera 9.62 will be out.  They're just finishing the final stages of testing for this update.  It's a cross-site scripting vulnerability that - there was a demo I saw where you could click a link, and it would pop up your Windows calculator, meaning that it was able to, unfortunately, run...



LEO:  Nothing should be able to do that.



STEVE:  Run code on your machine.



LEO:  Yeah, that's not good.



STEVE:  No.



LEO:  That's a very dramatic proof of concept, when a program just starts itself.



STEVE:  And I've talked several times about my own experiences with credit cards getting away from me.  And I received a robocall this morning from my main Visa card, asking me if the following charges had been made that morning, or this morning, literally while I was putting things together for this podcast.  It's like, no, those are not me.  So I called them back and confirmed that these were not my charges.  The first one was a four-cent charge for computer consulting, then a $1 charge on eBay, and then a $400-and-some-odd, and they began going crazy with it.  But again, this was Visa.  And they're no longer our sponsor, but they did immediately lock the card down.  They denied those charges.  They went through a bunch with me.  We walked back to dinner last night, which was the last time I had used the card.  I said, yep, that one I recognize.  Nothing since.



LEO:  Do you think it got stolen at the restaurant?



STEVE:  Oh, no, no.  This is - no.



LEO:  You use it online?



STEVE:  I use the card, I mean - and again, we've talked about what to do in terms of safe use of card.  I am going to again check my various cards to see if any of them offer a native, one-time use service.  Last time I checked they did not.  I'm hoping that someone will.  If not, I'm going to make heavier use of PayPal's plug-in for that purpose, even though I don't really like it in my browser.  I may try it in Firefox, now that I've moved from IE to Firefox.  But I have been using it more.  The problem is, it insists on withdrawing from my checking account.  And I really don't like that.  Also it confuses my bookkeeper because she would like to balance my checkbook, and there's all these random charges that don't have any checks against them.  So I think what I may do is create - either transfer a block of money to PayPal and then have it pull from that, I think I can do that, in the same way that you've got PayPal credit in there, and it can pull from that.  I think I may just move a block at a time and let it sit there and then - but it's amazing to me, the rate at which a heavily used credit card is now being compromised, even by someone who's very cautious about where I go and who I give it to.  So...



LEO:  Why do they do those two small transactions?



STEVE:  Those were to test whether to - so it didn't hit any limit on the card, to see whether - they've probably received this card in a batch of them that they had purchased from someone.  And again, this is generally not - it's not like I used the card yesterday, and it got abused today.  It's probably from some use months ago where there was some exploit on someone's server that lost a huge chunk of cards, and mine was among them.  And it took a few weeks for it to drift over to wherever it went before this really began getting abused.



LEO:  I know there are some Visas, some MasterCards, some American Express cards that allow you to generate a one-time number.  It's just the, you know, I think it's the bank, the offer.  Although American Express offers its own cards.  So I think they offer it, as well, is a one-time number.



STEVE:  Yeah, it's time to get serious about that.



LEO:  Yeah, I have that PayPal one, and I haven't used it all that often.  And I probably should start using it more.  You know, it's kind of a little bit of a pain because you've got to generate it and everything.  But, boy, yeah.  Although now with everybody so aware of it, you've got to wonder how often does that happen now.  I mean, how often do they get away with it, I guess?  You know, that $400 charge, do you think they got the merchandise?



STEVE:  I'm not sure.  They're sending me a printout of, basically, of everything that might be suspect for me to go over it and make sure that it's nothing that I did.  And then, for example, there was a $5.99 charge from Amazon that was probably some Kindle subscription of mine that just happened to cycle at that time.  So it's like, okay, whoops, there is one of mine that was part of an automatic charging cycle.  So I have to just go through, make sure.  But of course I'm completely indemnified from charges that I say I've looked at these, I'm sure they're not mine.  Which is, you know, that's what you want.  It's just a pain to lose the card.  I had it memorized, of course.



LEO:  You get to start all over, yeah.



STEVE:  And I did have a fun SpinRite story to share, with someone who deliberately was anonymous.  He used the Security Now! /feedback form to send this to me.  And he wasn't anonymous for any particular reason.  But he said his location was somewhere in California.  And he said - his subject was "SpinRite Makes Coworker a Believer."  And he said, "I've been a listener of the Security Now! netcast since Episode 1 and have always enjoyed the SpinRite testimonials that you share on the show."  Much like this one.  "I'm a systems administrator at a laboratory and have had SpinRite help me both in my professional and personal life.  Nothing quite as amazing as many of the stories that I've heard on your podcast.  But I thought I would share this one as it shows the power of SpinRite to prove itself to those who doubt its true power.



"I had heard of SpinRite in the past, but never purchased it or used it until I started listening to your podcast.  I told my coworker, a fellow sysadmin, about SpinRite, and he did not seem to share my desire to try the product.  He seemed to think that SpinRite was just like other snake oil products on the market that look fancy, but do not really seem to fix much.  I still decided that I would purchase a copy through work to try it out.  The purchase process was a little bit longer for me since I had to go through our purchasing department, but that was the only thing that delayed me from receiving my copy.  Once I had it downloaded, I burned the ISO and was eager to try it out on a failing hard drive."  But he didn't have one.



He said, "I ran it on several systems around the office that were not having problems and showed my coworkers the various screens in SpinRite that showed what was going on.  But since there was nothing wrong with these systems it really did not impress him.  Then the day to really put SpinRite to the test finally came.  One of the tablet PCs that was hooked up to an instrument in the lab started having trouble booting.  And similar to other testimonials I have heard, the system was stuck in a boot loop where the system would start booting, blue screen, reboot, and blue screen again, and so on.  My coworker had taken this trouble ticket and was not looking forward to reinstalling the Windows on this system, along with all the other software.



"I handed him our copy of SpinRite, and without much optimism he booted the system off the CD and started SpinRite.  This time, right off, SpinRite switched into DynaStat mode and started chugging away, repairing the first few sectors of the drive.  He seemed a little more interested when he saw this different behavior and watched as SpinRite worked on the drive.  After a while we left SpinRite to its task and decided to come back in a few hours.  I don't remember how long exactly, but later that day SpinRite was done, and it was time to try booting the system into Windows.  My coworker rebooted the system, and Windows started right up without any problems.



"After this experience, not only did my coworker never mention his doubts about SpinRite, he began using SpinRite on every system he thought might have a hard drive problem, and we purchased three more copies so that we had a site license.  To this day SpinRite is still one of our favorite tools, and we use it all the time.  Thanks, Steve, for the great podcast and for your work on Security Now!; and thanks, Leo, for not only the Security Now! netcast, my favorite, but also for all the other great netcasts you do.  I'm leaving my name out in case you do decide to read this on the podcast, but I'm putting it in my email just in case you want to replay."  So thank you, Anonymous Listener.  I certainly appreciate the testimonial.



LEO:  Always welcome.  Well, let's talk about something that actually is pretty timely.  It's pretty newsworthy.  I started reading about it just a couple of weeks ago.  I'm sure you started getting emails right about then, too.  Clickjacking.



STEVE:  Yes.  What's interesting about clickjacking is that it's a problem which is arguably serious, yet it's not a consequence of any bugs.  So much of what we talk about on the show are, like, are the result of specific defects in software which the author of the software didn't see.  Somebody came along and discovered a bug and said, oh, we can leverage, we can exploit this defect to our benefit.



Now, also there are - there's sort of another class of things, sort of like the cross-site request forgery that we talked about two weeks ago, or cross-site scripting that we've talked about where, for example, bad guys can take advantage of Web 2.0 functionality where a site will accept text from a user, and that text, if it were script, would then run on subsequent visitors' browsers when that text is again shown, like in a blog or an online forum or something, thus requiring that accepted text be sanitized for exploits.  So there's an example of the power of the technology sort of being turned to a malicious purpose.  So clickjacking is something similar.  It's interesting, too, because it's been around for a few years.  And it's...



LEO:  Well, that's funny because we just started hearing about it.  So you're saying it's not new.



STEVE:  Well, I would relate it a little bit to, like, the Sockstress that we talked about where sort of the concept, sort of a dim awareness of the potential for problems had existed, but no one really sat down until - to sit down and look at it closely.  And so a couple of researchers, a security researcher, it's Robert Hansen and Jeremiah Grossman, they were getting ready to do a presentation that was going to be earlier this month, OWASP, the Open Web Application Security Project.  And they said, okay, we're going to do it on this sort of an interesting class of exploits.



Well, as they explored this sort of dimly worrisome problem and, like, matured it for their - literally for their presentation, they realized much more could be done that was, like, more worrisome than they had thought.  For example, one of the things, we've not yet really talked about Flash cookies.  But Flash cookies are another type of cookie, user identity persistence in the same way that web browser cookies are, that are supported by, originally it was Macromedia and now Adobe Flash technology, where...



LEO:  We talked a little bit about it in the context of banks using it.



STEVE:  Yes, in order to maintain a grip on you when...



LEO:  Right, when you deliver cookies.



STEVE:  Exactly, you...



LEO:  And in fact our Stickam chat, which, you know, if you watch our live video, it's on Flash, and the chat is in Flash.  And those Flash cookies sometimes cause problems.  So the Stickam people who use our Stickam chat are very familiar with it because one of the fixes for those problems is to clear your Flash cookies.



STEVE:  Right.  So what happened was some of the things that these guys realized they could do - and I'll explain how in a second.  But they could, for example, trick people into enabling their webcam and microphone through abusing some security problems with Flash.  And Flash is configurable from using pages on Adobe's site is the way you configure the security settings, or by using URLs that the Flash object will see.  But normally you have to push buttons to make this happen.  Well, what these guys realized was that it's entirely possible to, due to the complexity of contemporary web browsers, to essentially have layers.  It's possible to have something hiding below the surface, literally on, like, a layered page, where the user clicks on what they see, but what they're actually clicking on is content on the page behind.  So you can use things like dynamic HTML and CSS.  You do not need scripting.



So even disabling scripting doesn't protect you from this.  And in fact disabling scripting can in some cases make the problem worse because there are - some of the ways that this is exploited is by using frames and causing other sites' content to appear in a frame, but then obscuring that.  So, for example, we've talked about frames in several different contexts in the past.  The idea of a frame on a web page is that your browser brings up a web page, and there is a region of the page called an iframe, an inline frame.  And the URL for that can be some other site.



So, for example, you could cause Google Mail to come up in a frame.  Well, now, because your browser has gone to Google Mail and said, hey, load this URL, please, Google Mail knows this as you.  That is, it's you.  It's just exactly as if you put the Gmail URL up in the browser's main URL field and loaded the page.  In this case it's just contained in a frame.  The problem is that this clickjacking exploit - it's also known as, a little more formally, the formal name is "UI Redressing."  Some people who don't like "clickjacking" prefer calling this "UI Redressing," which is also...



LEO:  "Clickjacking" is catchier.



STEVE:  I think so.  I think "clickjacking" is good.  I mean, as you say, it's a fun name.  So the idea would be that it would be possible to hide this inline frame literally behind an opaque kind - behind an opaque window where a malicious site has put something else, for example, maybe a game where you try to click on successive buttons in a certain pattern, or anything, I mean, it doesn't even have to be something so extensive.  And literally, when you think you're clicking on one thing, you're actually physically clicking buttons on the content that's been loaded in a frame underneath what you can see.



And I have, for people who are interested, I've got a ton of links in this week's show notes, in the show notes for this episode of Security Now!.  There are some demos which are benign, which have now surfaced, that are on the 'Net.  There are some takeaways.  For example, I mean, some actions that people can take that we'll be talking about because this is something which has gotten a lot of news.  It's like sort of the current state-of-the-art exploit.  And it's become a new popular thing to, you know, basically script kiddies and people who have various sorts of intent are now - they have a new way, a new toy they can use for causing people problems.  And as I said, just disabling scripting doesn't help.  Now...



LEO:  So your favorite little NoScript plug-in isn't going to fix this one.



STEVE:  Oh, actually it does.



LEO:  Oh.



STEVE:  Because, well, not because of disabling scripting, but because Giorgio - Giorgio Maone is the guy's name, is the author of NoScript, he picked up on this early.  He was clued in by the security researchers about what was going on.  And he's enhanced NoScript to specifically add a new feature that he calls "ClearClick."  So anyone using Firefox can - actually he's had it for some time.  I already had a version just through the regular NoScript updates.  Because this is about, now about three or four weeks old, since the  news first surfaced.  I guess about three weeks old.  So he's already updated it.  He's done a whole series of updates.  I updated myself again when I was coming up to speed because he's had a bunch of updates.  But there is now, by default, NoScript, even when you allow scripting, it will block these types of attacks.



LEO:  Oh, that's great.



STEVE:  Yes, it's really great, Leo.  So anyone using Firefox and NoScript, even if you disable NoScript, if you say "Globally allow scripting for trusted and untrusted sites," he'll protect it.  Basically what he's doing is he's looking at, in detail, at what's going on when a user clicks something and will pop up a dialogue saying, wait a minute, you may not be clicking on what you think you're clicking.  So he's actually checking the content on the fly to make sure that there aren't any games being played.  Which is very cool.  Okay.



LEO:  So do you - let's take a break, and then maybe you can explain a little bit about how this works.



STEVE:  Sure.



LEO:  And what it looks like.  Are you going to give out the URL for your special test site, too?



STEVE:  Sure.



LEO:  Or do you want to keep it a secret?



STEVE:  No, no.  I'll have the formal URL.  I did create, for people who just want to easily see what's going on, snipurl.com/clickjack with no "ing," just c-l-i-c-k-j-a-c-k.  Our TWiT Live users can do it right now if they're curious.  That will redirect your browser to a much longer and hairier URL that I do also have on this week's show notes for people who don't want to use SnipURL, or they've got browser redirects disabled or something.  It's a nice little page because it sort of clearly demonstrates what's going on.  If you were a MySpace user - I'm not.  But if you were, this would be - it demonstrates how you could inadvertently give the world access to your MySpace profile, even though you didn't intend that.  But you don't have to do that.  He shows you, he's got two little links that reduces the opacity of the covering layer, allowing you to see the MySpace page that's lying underneath that you were inadvertently clicking on.  Anyway, it's just a simple, very visual demo that demonstrates the power of this kind of attack.  So that's snipurl.com/clickjack.



LEO:  You didn't do this.  Somebody else designed this page; right? 



STEVE:  Yeah.  I saw somebody else, or somebody in TWiT Live said, "Holy crap, this is scary."  If you look at that page, you really get - it makes such a nice, visceral...



LEO:  Demo, good demo.



STEVE:  ...demo that - so what this means is...



LEO:  The MySpace thing is a good choice because I suspect that people are actively using this to hack MySpace accounts.



STEVE:  They absolutely could.  So the idea is that, you know, if you imagine that you are a normal web user, you put in a URL to do something, to go somewhere, to eBay or to PayPal or MySpace, for example, where one way or another you are known by the site.  Remember we've talked about the problem with persistent log-in.  So persistent log-in is a problem.  But notice also, for example, that if you have Firefox, as I often do, remember my password.  Then I go to the site.  My email address or my username is filled in.  Firefox then fills in my password.  So notice that I now have one-click log-in.  Even if I have logged out when I was last there, just going to that page prompts my browser to log me in.



Well, even though that page waits for a click, if that page were hidden behind some other screen where I would innocently click something, I would be logging into a site with my full credentials, even if I had last left it logged out.  So logging out of a site doesn't protect you from this kind of exploit.  So now imagine that you are, whatever you're doing, banking or PayPal or something less significant like MySpace, but still something where you can imagine people just having some fun and games.  The site has a fixed layout with its various elements of the page at known locations.  And so anything that you might do through a series of clicks, you could be potentially induced to doing by someone designing essentially a cover sheet, a page that is over that and induces you to click, for whatever purpose, in some sequence.  And you think you're doing one thing.  But you as you, that is, you known to your browser and known to that site that has been brought up behind the scenes, you're doing something that you're not aware of.  And anyway, so the problem is it is completely cross-platform.  IE, Firefox, Safari, Opera...



LEO:  Well, it uses web standards.  It's using - this is how the web works.



STEVE:  That's exactly right.  And in fact it was of a big enough concern that Robert and Jeremiah aborted their presentation that they were going to give at the Open Web Application Security Project.  Specifically, Adobe said please don't make this public.  Because several of their examples demonstrated how easy it was to cause Flash to turn on to give anyone remote access to your webcam and microphone.  And so what happened is - and this is one of the other takeaways.  So the first takeaway action item from this is for Firefox users, just update to the latest version of NoScript, and you've got blanket protection.  Giorgio has got NoScript up to date, and has actually for some time.  You've got blanket protection.  Also the latest version of Flash Player, I think it's like 10.0.12, I updated both my Flash Player...



LEO:  Yeah, that just came out, actually.



STEVE:  Just came out, yes.  And this is Adobe's response to this specifically.  What I had before was 9.0.124.  That was a recent update.  That and earlier are vulnerable to this.  So Adobe has responded to this threat by updating Flash to v10.0.12.36, which is what's current.  And it's available for all the various browsers.  You want to update to that.  And then that's Adobe taking responsibility for making sure that this will no longer function.



LEO:  So it can be done in Flash as well as just plain old HTML.



STEVE:  Yeah, exactly.  There's a way, for example, that if someone - if a site tries to - if a site wants to look at you, a pop-up - Flash will present...



LEO:  They turn on the camera, that's right, yeah, yeah.



STEVE:  Exactly.  It'll pop up something saying, hey, this site you're visiting wants to turn on your camera.



LEO:  I've seen that, yeah.



STEVE:  Yeah, exactly.  Well, what this clickjacking, or so-called "UI Redressing" allows, is that allows that pop-up to be essentially a pop-under, so that it will not come up on top.  It'll come up behind.



LEO:  And then when you click "Okay" on some other button, it says "Okay" to that.



STEVE:  Exactly.



LEO:  And they're looking at you, or listening to you.



STEVE:  Exactly.



LEO:  Oh, man.



STEVE:  And so...



LEO:  Oh, man.



STEVE:  Yeah.  It was, you know, Adobe said please don't go public with this.  The guys gave a much toned-down presentation.  They were already on the schedule.  They had to do something.  So they kept it quiet.  However, as we've seen before, just the fact that they had said something caused other researchers to figure it out.  And it took about two days after all this first little flurry that it had been - that people had figured out what it was.  There were proof of concepts popping up on the web.  And then, after it had been worked out, these guys came back and said, okay, well, since the cat's out of the bag, here's the whole story.  And they gave a really complete layout of this.



So, yeah, I mean, the problem is, as you said, Leo, this is not a flaw.  This is just the power of the system that has been built.  I mean, the capability is so extreme now with frames and layers and transparency and CSS and dynamic HTML, that there are unintended consequences of this kind of power.  Now, one of the things that has been done, there is something called "frame breaking."  It's possible for a site to put some JavaScript in its pages where the JavaScript itself says do not allow me to be in a frame.  That is, I'm a page that wants to not function in a frame because I want to prevent any kind of frame-based exploits.  I want to prevent the abuse of my pages being enclosed in a frame.



The problem is that requires JavaScript in order to function.  And there is a tag that Internet Explorer offers in an iframe where you crank the security up, saying I don't want - I want to bring up an iframe, that is, an inline frame, I want to pull up some content from some other site in an inline frame.  But to protect myself I want to disable any scripting.  So in disabling any scripting, you're disabling the frame-breaking intent, which is to help you in a site that you're bringing up.  So it ends up being that you've got IE working against the positive security enhancement of the content that you're bringing up in the frame.



Anyway, the point of this is it's a mess.  And ultimately browsers will have to adapt to this.  There is nothing at the moment that Safari, Opera, and IE users can do.  There is no - there's no similar protection that I have discovered in all of my looking around that is similar to what NoScript does for people who are using Firefox.



LEO:  Firefox, NoScript.  Firefox, NoScript.  Firefox, NoScript.  Just use it.



STEVE:  It's another...



LEO:  It's free.



STEVE:  It's one more reason.  And I have to say, you know, I'm as late an adopter as there is.  And, I mean, I really, as I said, I think it was last week that one of the things I felt uncomfortable about Firefox was I was just afraid of incompatibility.  I thought, oh, you know, I don't want to have anything, anywhere I go, not work.  Well, I've been using it now for several months.  And, I mean, I'm not a wild surfer.  But I've never, never had a site that I have problems with.  And since its adoption is such a high percentage now, webmasters, you know, it used to be that only IE, sites were only being checked in IE.  Now, especially with Apple coming on as strong as they are, sites have to work in Safari.  They have to work in Firefox as well as IE.  So again, I'm very pleased with Firefox.  And this NoScript add-on is a beautiful solution.  It gives you complete protection from clickjacking.



LEO:  Which is very good news because I don't want anybody turning on a camera on me.



STEVE:  No.



LEO:  Without my knowledge.  I have them on all the time, but...



STEVE:  That's not a good thing.



LEO:  When they're not on, I don't want them on.



STEVE:  Or, I mean, or transferring money out of your bank account.



LEO:  Or that, yeah.  Or just stealing my MySpace or Facebook page.



STEVE:  Yes, or exactly, changing configuration of standard high-traffic sites and site experiences, behind your back or without your knowledge.



LEO:  Now, we talked last time about logging out on all the sites that you don't want anybody to automatically log-in.  That's another thing you could do to be proactive about this; right?



STEVE:  Yes, still a good thing to do because the idea is that this is like you going to a site and pushing buttons you don't intend to.  So if you, like for an eBay user, if you stayed logged into eBay, you could imagine that somebody could - imagine them making you push buttons you didn't intend to.  There are things you could do you wouldn't want to do.  But if you were not logged into eBay, and you had to first log in...



LEO:  You'd know.



STEVE:  There's not a way they're going to trick you into doing that.



LEO:  Right.  Well, I mean, it'd ask you to log in.



STEVE:  Right.



LEO:  And you'd say, well, what are you talking about?  I just - I wanted to punch the monkey.  I'm not...



STEVE:  Well, unless you had - you, like I do, have your browser configured to remember your password.



LEO:  There's still an "Okay" dialogue.  And so they'd have to kind of get you to click that; right?



STEVE:  No, because you'd think you were clicking some monkey paw or something.



LEO:  So all they have to do is have that click, click the Submit button.  And since it's auto-populating the log-in and password, that'd be enough.



STEVE:  Exactly.  That's the problem because you're not having to provide that explicitly.  You know, we've simplified our lives by having our browsers remember how to log us on.  Well, in the process we've simplified the attack because all we're doing is clicking Okay.  We don't know we're actually logging on.  We think we're doing something else.



LEO:  There's always a lot of trial and error in getting this to work.  So they would have to do some clickjacks that would assume you're already logged in, and some that assume that you're not, but that your password's autofilling.



STEVE:  Yup.



LEO:  But I'm sure they can do that.  Hackers are nothing if not persistent.



STEVE:  So our users were sending email several weeks ago saying, hey, Steve, talk about clickjacking.  Now we've got the whole readout on it.  I've got lots of links for people who want to pursue this further.  But, you know, the takeaways are Firefox with a new version, a recent version of NoScript, and make sure you update your built-in Flash plug-in to Adobe's latest.  Just go to Adobe.com.  Right on Adobe.com's home page it'll say "Get Adobe Flash Player" for your various browsers.  Do that, and you're covered.



LEO:  Just updated NoScript on my Firefox.  And just it's a good reason to keep using Firefox.  And I'm not going to say I told you so.  I won't.  I won't do it.



STEVE:  Well, no.  Because, you know, I've been Mr. NoScript for a long time.



LEO:  You have been Mr. NoScript, that's true.  You get credit for that.  Steve Gibson is the host at GRC.com.  Go visit.  Boy, there's lots of good reasons.  I mean, of course there's SpinRite, everybody's favorite disk recovery and maintenance utility.  But it's also the home of Security Now!.  You'll get your show notes there, links to the page he just mentioned, 16KB versions of the show, and transcripts, too, so you can read along as you listen.  People often find that helpful to understanding the show.  And every episode we've done, all 167 of them - 168 of them now.  You can also get some great free software.  And don't forget ShieldsUP! when you're installing your new firewall.  It's GRC.com.



Steve, thanks so much.  I won't talk to you again till after the election.  I presume that you - are you going to vote on the Tuesday?  Or are you going to mail in your ballot, or vote early?



STEVE:  I think I'm going to vote early, just because, you know, why not?  It makes sense to do that.  I know what I want to do.  And I think I like the idea of getting that done.



LEO:  It's nice, yeah.  I already voted.  Jennifer and I already mailed our ballots in.



STEVE:  Neat.  Neat.



LEO:  Yeah, we do that every year because I never know - it came from when I was going to Canada.  I never knew if I'd be here on Election Day.  And I didn't want to miss an election.  So we just encourage everybody to vote.  However, this is a very important election.  Not just the federal election, but every state has some important propositions.  We do here in California.  So get out there and cast your vote, let your voice be heard.



STEVE:  I did want to mention, just to remind our listeners, I really appreciate the feedback that we get.  It helps me, gives me ideas for the show, tells me what's going on, what things people think are important.  And that's GRC.com/feedback.



LEO:  Great.  Everybody go there.  And we will have questions and answers next week.



STEVE:  Next week.



LEO:  Next week.  Thanks, Steve.



STEVE:  Hey, Leo, bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#169

DATE:		November 6, 2008

TITLE:		Listener Feedback Q&A #53

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-169.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 169 for November 6, 2008:  Your questions, Steve's answers.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



Time for Security Now!, the show that talks about protecting yourself online, your computers, at home, keeping spyware, adware, and malware off your system.  And here he is, the guy who coined the term "spyware," knows more about protecting you than anybody else, Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Hello, Leo.  Great to be with you for our weekly chat.



LEO:  Yes.  Did you stay up late on election day?  Election night?



STEVE:  More than usual, yeah.  I finally gave up at 10:00, I think, because I'm up at 4:30 in the morning, so yeah.  But I feel fine.  I'm on six and a half hours, so that's fine.



LEO:  Is that all you need?  You only sleep six hours a night?



STEVE:  No, no, no.  I normally give myself eight.  I've learned, I mean, I'm just useless to myself and the rest of the planet unless I have enough sleep.  And so I really do give myself enough.



LEO:  I read a programming book once, the guy gives programming classes, and he says to his students, he says, "Coffee is not a substitute for sleep.  Don't think it is."  There he goes.  Now, Steve, how big is that?  Wait a minute, how big is that cup of coffee?  That's the biggest thing I ever saw.  As soon as I said, "Coffee's not a substitute for sleep," Steve pulls out, like, a quart of coffee and starts drinking out of it.  But it is a good point.  You've got to have, you know, if you really want to use your brain, you've got to have a good night's sleep.



STEVE:  Yup.



LEO:  And a quinti venti latte.



STEVE:  Quinti venti latte.  Keeps everything going, yeah.



LEO:  Today our Q&A segment.  We've got 13, or 12 great questions from our listeners, including the Sockstress solution and a Sandboxie question.  Which we'll answer in just a little bit.  We also have the tech news.  And I'm sure we have errata and addenda from previous episodes.  So did you make any mistakes in the last couple episodes?



STEVE:  Well, we have no errata.



LEO:  See, he's perfect.  I knew it.



STEVE:  Although we did have someone who disagreed with something that we said.  And so we've got a nice disagreement question in here, which we'll discuss.



LEO:  We'll do that later.



STEVE:  It's not quite the same.  But there was a bunch of security news, or some.  Some interesting stuff.  I discussed the update to Opera last week and said that probably by the time people heard this, 9.62 would be available.  I wanted to confirm that, sure enough, I think it was later that day when we recorded it, last Wednesday, 9.62 because available, which solved a very serious exploit in Opera.  So I wanted to make sure that anyone using Opera knows that 9.62 is available and updates themselves to it.



The OpenOffice suite has an also serious image-based remote code exploit.  Any OpenOffice versions prior to 2.4.2, and apparently OpenOffice v3, which is just out, also has it fixed.  And I'm not sure about StarOffice, the commercial version.  But it might very well be that StarOffice has a problem.  If you own StarOffice, you'll want to check to see whether this problem that's been found in OpenOffice - it involves the display of WMF and EMF, that is, Windows Meta File and Encapsulated Meta File format.  So that, you know, if an OpenOffice product displays one of those images, there's a - actually it's a heap overflow in the processing code for the image display that can cause a remote code exploit to occur on your machine.  So you want to make sure you update OpenOffice, if you're an OpenOffice user.



LEO:  And there are Mac users who use NeoOffice, which is a Mac spinoff.  They probably should also check.



STEVE:  Absolutely.



LEO:  I'm sure they all use the same Java libraries, so.



STEVE:  Then Microsoft produced what they call their Security Intelligence Report for the first half of 2008, so the first half of this year.  And they've had some interesting statistics.  For every thousand runs of the MSRT, that's that Malicious Software Removal Tool, which every second Tuesday one of the things almost invariably on the checklist is update your malicious software removal tool.  And then it runs the next time you restart your machine.  So for every thousand runs of it, it finds, or in the first half of this year found three bad things in Vista Service Pack 1; found 10 bad things in XP Service Pack 2; and eight bad things in XP Service Pack 3.



LEO:  Holy cow.



STEVE:  So that gives us some sense, I mean, I've always wondered what it's doing.  It's never found anything bad on any of my machines.  But clearly, so what's that, 10 and eight, that's 18, and three, so 21 things bad out of a thousand runs.  So it certainly is finding problems.



What's interesting is, and this was not - it won't be a surprise to our listeners, who've been following along and paying attention, is that eight out of the 10 top problems, that is, 80 percent of everything found relate to ActiveX controls.  That is, this really disturbingly ill-conceived technology that I've groaned about in IE from the beginning, the idea that Microsoft didn't implement a secure, a fundamentally secure approach to allowing scripting and add-ons for IE.  They basically took their existing DLL technology and renamed it ActiveX so that basically anyone can provide ActiveX controls, which is executable content that your browser runs.  And we know what a focal point for security problems web browsers are.  I mean, it's the thing you're sticking out onto the Internet every time you visit a website.



Microsoft defended, as part of their dialogue explaining this, they defended ActiveX but acknowledged that it was impossible for Microsoft to police its technology.  And the guy that produced the statement said, quote, "You have to enable add-on development for the browser.  The question is, how do you extend the browser and at the same time provide guidance to developers on how to write secure ActiveX controls?"  And of course my answer is, well, you don't.  You use something like JavaScript, which is a sandboxable, fundamentally protectable technology, where you're able to run scripting in a safe interpreter rather than literally downloading executable code that runs natively on the machine.  That's just too dangerous.  So for that reason we're going to have the author of Sandboxie on as our guest next week because...



LEO:  Oh, good.  Oh, fantastic.



STEVE:  Yeah.  He and I have had a dialogue in the past.  I asked a question in our newsgroups, GRC's newsgroups, and learned that a ton of people are using Sandboxie with 100 percent good experience with it.  So that, okay, it's time to have this guy on to tell us about the notion of sandboxing web browsers.  And it goes way beyond.  Sandboxie started off as Sandbox IE, but it's an absolutely effective sandbox, for example, for Firefox, as well.  So he will be our guest next week.



Also there's a really interesting report from RSA Security about their discovery of the surprising penetration of a trojan called "Sinowal," also known as "Torpig" and "Mebroot."  And it's three different names for the same thing.  But we spend a lot of time talking about, okay, you want to be careful because you don't want to get one of these on your machine.  Well, next week I'm going to describe in detail what RSA found and has made public about this trojan because it really drives home how important it is for people to go to whatever lengths they need to to keep their machines clean.  And so it'll be the perfect companion to our talking with Sandboxie's author because his concept is the notion of wrapping protection around the browser.



We know that you could use a so-called "heavyweight" approach, for example, running a browser in a virtual machine, and use that for containment.  But that's, again, it's expensive in terms of starting it up, shutting it down.  As we know, VMs need to have all of the RAM that they ever might use preallocated.  So it's not RAM friendly in terms of sharing resources with your machine.  Sandboxie takes a very lightweight approach.  And so I want to have the author on to sort of explain to us what he's done, and why what he's done is safe.  Because from everything I've heard, and I've used it myself, what he's done is easy to use, and that's really what you want in this kind of a prophylactic wrapper around our web browsers.



LEO:  You know, when you say "trojan penetration" and "prophylactic wrapper," you're really making me think it's another subject entirely.  But I'm going to keep my mind out of the gutter and remember this is about security.  Okay.



STEVE:  Well, and I'll change the subject quickly to get us away from that.



LEO:  Please.  Thank you.



STEVE:  Just sharing a quick little note from someone, Jake Oswald, who for a change is not a Security Now! listener.  But he wrote to us just to tell us that he was really happy with the way SpinRite works for him.  He said, "I recently  had a system failure after an automatic update of Windows XP from Microsoft which required a system restart.  When I turned on my monitor, the screen displayed 'Windows is shutting down,' which it wasn't because there was no hard drive activity, and it had been trying to do that for hours.  So I pressed the reset button and eventually got a screen that said there was a corrupted config file, and the system could not restart.  I contacted my employer's technical support service.  And as soon as he learned that it was my own home computer and not one of the office computers, he said, 'Log onto GRC.com and buy SpinRite because it repairs, quote, nine out of ten disk failures, unquote.'"  So he says, "I did, and it did.  SpinRite ran for about five hours.  And when I rebooted, it was fixed.  Thank you for a great product."



LEO:  Very good.  Very good.  Once again, SpinRite to the rescue.  It's like the Dudley Do-Right of software programs.



STEVE:  You did that voice well.



LEO:  We'll save you, Nell.  Just turn on SpinRite, and all will be well.  Sorry about that.  I apologize profusely.  We've got questions for you, Steve.  We've got some great ones, 12 questions from 12 listeners, strong and true.  Are you ready, Steve, for some questions?



STEVE:  Ready.



LEO:  We've got us some good ones.  Actually a similar question from two listeners.  So if you don't mind, I'll read two questions in a row for you here.  First, from Guillaume Auclair in Sherbrooke, Quebec, Canada.  He wants to crypt his links.  He says:  Hello, Steve and Leo.  Now, I've re-thought about your forthcoming project CryptoLink.  And we talked about that on a previous show.  I relistened to both the PPP Security Now! episodes, the Perfect Paper Passwords.  And I've just got to have at least an idea of when this product's going to be available.  And I'd like to know if split-tunneling will be a part of it?  I'm sure you'll explain that, Steve.  Well, I guess he's going to explain it.  If I'm at a remote location, plugged into an insecure link, I want to be able to VPN tunnel home, ask for a web page, then home fetches the page, sends it to me through the VPN tunnel.  I have some customers who'll be ready to pay for that kind of setup, especially if it's going to be in Assembly and small and fast.  Which is your specialty, Steve Gibson.  So he wants to know when we're going to see CryptoLink.



And Rich Schreiber in Erie, PA, says - it's a question - "CryptoLink?"  He says:  Dear Steve, I know you're extremely busy.  I wanted to thank you and Leo for your devotion to keeping us all informed and secure.  I also want to know if you could mention on a future show the status of CryptoLink, maybe even some of the features you plan to implement.  Many of us are waiting with great anticipation.  OpenVPN works great, but too difficult to walk someone through on the phone.  Hamachi forces disconnects if you don't continuously upgrade every time they come out with a minor upgrade, and you can't route through the host.  Other options aren't secure enough, or don't offer true VPN connectivity.  Thanks again.



So, Steve, what's the story?  CryptoLink in your future?



STEVE:  Well, this is representative of a bunch of questions, so I finally just today I thought, okay, as I was reading through these, I ought to just take a minute to sort of explain to people where we are.  You may remember, Leo, I think it was a little over a year ago, you and I were - it's the time we were in Vancouver, sitting at the table on that patio outside.



LEO:  I'll never forget.  It was a beautiful night.  That was a lovely bottle of wine.  And you told me something very interesting.



STEVE:  Well, I recited to you just by memory three pages of bullet-point features for the upcoming VPN-ish thing that I wanted to develop.  And at the end of that third page your mouth was hanging open, and you said something like, wow, you know, if you pull this off, Steve, it'll be the most significant thing you've done.



LEO:  I had the same reaction these guys are having, you know, when?



STEVE:  Yeah.  Well, and that's the problem.  It's just me doing this.  And my style is much more the tortoise than the hare.  It's not that I'm slow.  But I hope that I'm thorough.  And my approach is to really want to get something done, I mean, get it done, finished, really to a point where I never need, or not soon, need to look at it again.  SpinRite 6 has - not a single byte of its code has been touched since it was released in 2004.



LEO:  Which, I want to point out, is not a bad thing.  It means it's there.



STEVE:  It's done.  It's bug free.  There's nothing that I know that needs to be changed.



LEO:  And you don't - this is what I admire about you.  Your tight code, you know, the feature set is there.  You don't feel the pressure that many manufacturers or vendors seem to to add unnecessary features just so that there'll be an upgrade every year.



STEVE:  Right, exactly.  So, yes.  So I'm not, like, nickel-and-diming people.  SpinRite 5, I think, lasted for five years before 6 came along because I needed to add compatibility with unknown partition types. 



So last summer I was really anxious to get going on CryptoLink, but there were a couple of things that I had left undone.  There was the whole third-party cookie initiative that I feel strongly about.  I wanted to add the technology to the site, to GRC's site, to sort of automatically in the background let people know if third-party cookies were enabled because it's so easy to turn that off in all contemporary browsers.  The problem was, strange as it sounds, sort of due to the organization or disorganization of the site, I didn't really have a place to put those pages.  That is, there was already sort of everything there, but no real good organization.



So I thought, okay, before I do that, I need to do a menu.  And so I developed over the course of several months the world's only really bullet-proofed, 100 percent script-free, non-active anything, non-JavaScript anything, menuing system.  Well, it took much longer than I expected.  But when it was done, it was done.  And it's perfect.  I haven't touched it since.  All kinds of people have used it and do adopt it continuously.  I get email from people with a question here or there, or they'll often post a question in the newsgroups, and somebody there will answer it.  So that gave me sort of the structure that GRC was missing, that allows me now to hang new things off of the menu, which I didn't have before.



Then I switched back and plowed into finishing wrapping up the third-party cookie technology, which I had written all kinds of substrate, but had never gotten it finished because something else came along and interrupted me.  So I thought, okay.  My point was that, when I start on CryptoLink, because I am so resistant to changing what I'm focused on, I just - I didn't want to have to be pulled away from CryptoLink.  So I thought, okay, that means I have to have menuing on GRC, and I've got to get the cookie system finished, like finish these things that I had invested in heavily but hadn't had time to get back to.



So what ended up happening was, we found bugs in every browser's handling of cookies.  And I've ended up with an amazingly thorough cookie-handling analyzer.  Several things already happened.  Firefox 3 is substantially better as a consequence of the Firefox guys, who were tuned into what was going on.  They, for example, realized that when this thing came out and was going to require people, I mean, tell people you need to turn off third-party cookies, they had removed that from the user interface in Firefox 2.  And they realized they're going to be in trouble if they don't have that in Firefox 3.  So that's the reason that simple checkbox was returned in Firefox 3, making it easy for people to disable third-party cookies.  And there were some problems, there was some cookie leakage that the technology at GRC discovered in header assets, page assets, page headers.  Turned out you couldn't turn them off.  Even though you said disable third-party cookies, they kept happening.  And IE, both 6, 7, and 8 have problems, as well.



So all of this was - so all that technology finally got finished.  And I was just starting to work on the documentation, and Dan Kaminsky happened with his DNS exploit.  And remember, I think that was in May, I think.  Well, in June I decided, okay, this is a problem.  It'd be useful to do a really thorough analysis of DNS servers.  Well, that was four months ago.  And so I suspended the work on documenting and getting the cookie system public in order to do this test of DNS server operation.



What we have is something phenomenal.  I mean, it hasn't - it's not public yet.  All of the guys in the newsgroups have been testing it.  Turns out all kinds of DNS servers are still vulnerable.  They have not been patched by their ISPs.  I will be making this public to our Security Now! listeners before anybody else, probably maybe two or three weeks from now.  Essentially, all the technology is finished.  Now I've got to explain it all so that people aren't left with more questions than they started with.  But once that's done, then I go back and write the documentation for the cookie system, which is also completely finished.  And at that point I get to start on CryptoLink.



LEO:  So you haven't even - you've mapped it up, but you haven't started writing code; is that what it is?



STEVE:  Correct.  I have - no code is written.



LEO:  Because you had a very - you know what you're going to do.



STEVE:  Oh, it's so simple.  It's just a matter of sitting down; and, I mean, there's nothing I want to do more than to say, okay, I get to start on something new.  Now, there's three - at least three patents are going to come out of this.  One of them I already started.  In fact, one of them is finished, done, submitted.  I've got serial numbers and so forth.  And to give people an idea, I mean, to answer our second, Rick's question, like some of idea of what it's going to be.  First of all, it can be anything we want.  I mean, my intention is that it is an incredibly easy-to-use VPN product that, for example, supports the YubiKey natively, supports Perfect Paper Passwords natively, supports OpenID.  It has a fundamental TNO, the Trust No One model, so that there's no third-party involved.  So, for example, in our first questioner's instance, you'd be able to run your copy of CryptoLink at home, and you'd also be able to have it on your laptop.  And so your laptop would connect to your home.  And then your home would reissue the traffic coming from our laptop out onto the network.  So it'd be like your own personal hotspot VPN, with the advantage being that your traffic is decrypted only at your home, not at some central point like on a TOR node or at a hotspot VPN that might tend to be a magnet for people who want to do traffic analysis to see, oh, who's using the system for what purposes to encrypt their traffic?  So it'll do that.



It'll also do NAT router penetration the way Hamachi does, so that if you don't want to set up a system at home, if you just want to, like, mail a copy to a friend whose desktop you need access to, you can just email it to them.  They can run it, and it'll connect in the same easy way that Hamachi does.  But, for example, unlike any other SSL VPN, even though it has an open port, the port is not open, which is the first of the patents that I have underway.  I don't want CryptoLink's open ports to be visible.  So I have a way of cryptographically stealthing open TCP ports.  That'll be part of what CryptoLink does.  And, for example, CryptoLink will also be able to open an array of ports, and your client will send an array of packets to them so that, if any intermediate ISP is blocking some of them, other ones get through.



I mean, the idea is I'm going to do everything I can, and that's a lot, essentially anything, to come up with a product that just works.  I was having dinner with some people about six months ago.  Two couples were in the car, driving to dinner.  And both of the gals, by bizarre coincidence, were complaining that their corporate VPNs wouldn't connect.  One had been in the hospital with her husband, and she said,  yeah, I couldn't use the - I was able to get online in the hospital, but my corporate VPN wouldn't work.  And the other one said, oh, yeah, I have the same problem.  I'm never sure if it's going to work or not.  Well, my goal is, this thing, I mean, I'm not going to stop until this thing manages to find a connection no matter what it has to do.



So anyway, that's my plan for it.  My development arc is - what I intend to do is to very quickly get something working.  That is, I'm not going to just sit, the hermit in the cave, for who knows how long until I believe that I've got something fully finished.  The technology just isn't that hard for me to develop.  I've got so many pieces that I've worked out already that I'll be able to get something going soon.  So it'll be in pre-release but usable condition.  And then we will start adding features.  I say "we" because a lot of this is going to be done with full visibility to the people in GRC's newsgroups.  They're just a phenomenal resource.  I've used them with SpinRite and with the cookie development and with this DNS name server testing.  It's just so tremendous for me to be able to put some code up and say, okay, guys, here's something new.  Tell me if I got it this time.  And in very short order I've got a really good, broad-spectrum testing.  And it also allows people to say, hey, what about this, or what about this?  Or, hey, I need this, or I need that.



So anyway, I'm very excited about it.  I have no idea at all when it will be done.  There will be a "done" because everything I am is about saying, okay, this is Version 1.0, and it is complete.  It is finished.  What I can say is that lots of people will be able to use it as it goes along.  And basically what I'll be doing is adding feature after feature after feature.  My intention is to actually write the UI in something very plastic, like Delphi, just because I don't - what I always end up doing is I paint myself into a corner by designing the user interface first.  Then, because I want everything tight all the time, and that then tends to limit me from adding features.  So my development arc is to write the core in Assembler.  Ultimately, once we know what it wants to be, once every feature that we can think of and is useful is there, then I will cast the UI portion in Assembler.  So it will end up being 100 percent Assembly language, super tight, super small, with a ton of features that everybody wants, that nobody has taken the trouble to do before.  Because I look at these VPN products, and they're just like, okay, well, that's fine.  But that's - I can do something way better, that is way more robust and way more secure, with all kinds of authentication, Trust No One or use a third party, a rendezvous server for NAT penetration, it's just - it's going to solve the problem.



LEO:  And unfortunately it's going to be Windows-only.



STEVE:  Yeah.



LEO:  Just thought I'd throw that in.



STEVE:  Yeah.



LEO:  When it's Assembler, you don't have a choice.  Actually, you know, you could write the low-level code, well, I guess you're going to make calls, though, to the Windows API, even from Assembly.



STEVE:  Well, yeah.



LEO:  So you really can't write the low-level code in portable fashion.



STEVE:  It'll have, I mean, in my wish list, as I've been brainstorming this, so many cool things.  For example, you'll be able to maintain plastic connections to remote instances of CryptoLink, meaning that, if your 'Net connection goes up and down, it's not going to give you dialogues; it's not going to complain.  It'll just wait until it's back on the 'Net and then reconnect to the things that you said you want to make a persistent connection to.  So that, for example, you could have resources like your printer at home.  Your printer at home will just look like a printer on your laptop.  And you can print to it, seamlessly, no matter where you are.  And CryptoLink will take responsibility for maintaining and repairing and keeping its connection to your printer at home, transparently.



You'll be able to run in what I call a "full enclosure mode," which actually is what one of these guys was asking about, where all of the traffic that you use on the Internet is encrypted through the link to the remote point.  And then it's decrypted, whether you're accessing machines in that network or going back out over the Internet.  But maybe you don't want to operate that way.  Maybe you only want to talk over the link to your network at home.  Otherwise, for whatever reason, you're fine with the greater performance you would get going directly to the 'Net.  So you'll be able to specify that.  I mean, all kinds of things.  You know, one of the problems OpenVPN has is that it's router table based.  And so if the network you're connecting to happens to be in the same network as the one you're on, that completely fails.  Well, CryptoLink solves that problem.  So just one thing after another, after another.  Problems that I've experienced, problems that other people have experienced, I'm just going to solve them all.



LEO:  Sounds great.



STEVE:  So that's my plan.



LEO:  Looking forward to it.



STEVE:  And I've got some things I have to get finished first.  But there's nothing I want to do more than to get working on it.  So as soon as I can, that's what I'm going to do.



LEO:  Very good.  Question #2, Dan Gardner - "Disappointed" Dan Gardner, I might add...



STEVE:  Oh, very disappointed.



LEO:  Very disappointed in us.  In San Antonio, Texas; writes "I'm very disappointed."  He says:  In Episode 167 - the last listener Q&A that we did - regarding the response to Dave in Perth about his ISP blocking port 25, if incoming SYN packets get blocked, then those of us who run small home-based web servers will be totally up the creek.  That's right.  Besides that, what impact would incoming SYN blocking have on remote desktop access, desktop and other services like that?  I assume remote access, remote desktop uses TCP/IP.



STEVE:  Yup.



LEO:  I couldn't believe Leo when he said, "I love this idea of blocking SYN packets.  It would eliminate all this stuff."  It won't "eliminate all this stuff."  It might eliminate some stuff, like botnet operators from contacting bot-zombied machines via TCP packets.  But will it prevent bots from receiving UDP packets on standard open ports?  I don't know a lot about how UDP works, so you'll have to answer that one.  I don't think you can have a conversation with UDP, but I guess they could - well, I'll ask - we'll ask the expert.  Will it prevent the spread of virus through malicious Java code on websites or through emails?  Either way, blocking incoming SYN packets will affect a lot of people in a bad way.  So why are you and Leo salivating over the idea?



I don't think we salivated.  In fact, I think we were very clear that there would be problems associated with it, including people running servers.



Maybe Leo and you can afford to pay for a web host, but there are lots of folks who can't and just want to run a noncommercial, low-traffic web server from their homes.  And dropping incoming SYN packets will eliminate that ability.  Yeah, there are free hosts with tons of ads and pop-ups, I suppose.  But maybe we don't want all those ads.  Anyway, I'm very disappointed in you and Leo.  I am a SpinRite 6 owner, promote it all the time.  I'm probably one of the few who actually made an in-office purchase of SpinRite.  At that time I lived in Garden Grove, California, and drove to your office to get it.  Wow.  You don't get a lot of people in the office buying SpinRite, I would imagine.



STEVE:  There's no office anymore.  We're completely virtual.



LEO:  Well, that was version 5.  He said, I picked up ChromaZone - wow - at the same time.  I've been a big fan of GRC and a loyal listener of Security Now! for over a year, ever since I found out about it.  But when you and Leo take positions like these, which restrict our use of the Internet, it really hits a sore nerve with me.  Feel free to use this on the netcast if you wish.  "Disappointed" Dan Gardner.



STEVE:  Well, I wanted to let Dan vent, and I also wanted to clear up any misconception that any other listeners might have.  I wasn't saying I thought this was a good idea.  I was saying I was sort of seeing it as inevitable.  I could sort of see the handwriting on the wall.  At the moment, ISPs are blocking incoming SYNs on specific ports.  But sort of the general nature of an ISP's customer, the end-user is as a client of servers, rather than as a server of clients.  And so I completely understand what Dan said.  Of course, I mean, I'd be up the creek myself if I didn't have...



LEO:  As would I.  But those of us who run servers maybe should be buying different service or, you know, we have a higher responsibility.  Now, here's the fundamental, I think the crux of his question.  If it doesn't significantly improve security, then he's right.  There's no point in doing this.  What about, you know, does it completely thwart botnets?  Does it thwart viruses in any way?  Is it really an improvement in security, is the real question.



STEVE:  Well, first of all we know that the word "completely" doesn't have any place in any kind of a discuss...



LEO:  How significant is it?



STEVE:  The problem is, it's trivial to do.  It's literally a command entered into a router, into a filter list in a router.  I mean, it's incredibly simple for an ISP to do.  We know that, as I mentioned when we discussed this, I guess it was two episodes ago, in 167, we know there are ISPs that are already NAT-ing their customers.  Customers don't have publicly routable IP addresses, like 25.26.27.28, for example.  They've got something like 10.something something something, which we know is a non-publicly routable IP.  It's in that 10. reserve space, just like 192.168 something something.  So we know there are already ISPs that are not offering those services to their customers.  And we do know that there are some ISPs who don't offer that service, but for an extra price you can purchase that.  I mean, I can see that happening.



I mean, again, Dan somehow really got the wrong, I believe got the wrong impression of where you and I stand, Leo.  We don't, you know, you and I are all for absolutely nonfiltered, nonrestricted use of the Internet.  And my concern is that, because the majority of ISP customers don't need to serve, they only need to be clients, and because it's so simple to block incoming SYN packets - even though it isn't, as Dan challenges me on this, even though it isn't a solution for so many things - it's so simple to do, and it would solve such a large chunk of problems, that I'm worried we're going to see the time when that happens.  But I said "worried."  I'm worried we're going to see that happen.  Not that I...



LEO:  You weren't advocating it.



STEVE:  ...can't wait.



LEO:  You weren't advocating it.



STEVE:  No way am I advocating it.



LEO:  Yeah, I think if you listen closely, we merely spoke of it as a possibility.  And maybe even a probability, but not necessary something we were saying should happen.



STEVE:  Yeah.  I'm afraid at some point we're going to start - we're going to hear about it, and we're going to see it, and we're going to say, well, yeah.



LEO:  People were very upset when Comcast started blocking port 25, which I think is a perfectly reasonably thing; but a lot of people say, but I want to run my own email server.  I think that there are, you know, there's a balance.  And frankly, if you're running a server, I think maybe you should be buying a different class of service.  Maybe the solution is to offer tiered service.



STEVE:  Yeah.  And you can certainly imagine a point where this price gets you a client-only connection, and this point allows you to host services.



LEO:  Right.  And then maybe they'd have to vet you more carefully, or monitor you more carefully.  But most people would get the less expensive one, and that would eliminate a whole category.  You couldn't do a botnet without SYN/ACK.  Because you need...



STEVE:  Oh, sure.



LEO:  You could?



STEVE:  You absolutely can because typically bots are phoning outwards from the infected client.  So it's the SYN packet going out.  And that you have to allow because that's how anybody connects to a remote web server.



LEO:  But you also have to allow incoming commands, or a botnet is useless.



STEVE:  Sure, but those commands come in over the connection that was established first outbound.



LEO:  I see.



STEVE:  So this would do nothing to thwart botnets, for example.



LEO:  Well, if it doesn't stop botnets, it's not that useful.



STEVE:  Well, see, and that's the other thing, is that I don't think ISPs are really seeing much cost of problems at this point.



LEO:  Right.



STEVE:  That is to say...



LEO:  It hasn't hurt their pocketbook.



STEVE:  Right.  If it was really expensive that customers were able to run servers, then there might be - you could imagine a motivation for the ISP to tighten things down.  But there just isn't.  It doesn't really matter to an ISP whether you're running a web server or a mail server.  Well, except in the case of a mail server where it was expensive because then they were getting blacklisted as a source of spam.



LEO:  Right.



STEVE:  And so there's another good example.  ISPs are blocking 25 because they were finding their networks were added to blacklists, and that was causing a problem for all their customers.  So their ISPs responded.  When something causes pain, the ISP will deal with it.  At this point, in general, running services doesn't cause an ISP any pain, so we're not seeing any consequence.



LEO:  Well, I imagine so few people are doing it.  I mean, it's not something most users do.



STEVE:  Right, right.



LEO:  Ward Reed in Pensacola, Florida says, "Don't do it."  Steve, sorry for the overstated subject line, but do not use your PayPal card - we were talking about the one-time credit card feature of PayPal.  And he says:  Don't use it as your primary credit card.  It's acting like a debit card, or as one radio host calls it, a "fake" credit card.  Even though  Visa isn't a show sponsor anymore, the zero liability is relevant for a credit card only.  That's not true, but we'll talk about that.  The only problem with debit cards is that the vendor or scammer has your, as opposed to the bank's, money.  You may or may not get it back.  You are giving up far, far too much to use a debit card.  Getting up one-time use isn't worth it.  Discover has a one-time use option.  I've used it many times.  Citibank does, as well, for some of their cards.  Our listener said American Express does.



But the banking laws have changed for debit cards.  For a long time debit cards were very dangerous.  But the banking laws have changed.  I think a debit card is pretty much treated as a credit card now.  Used to be they were only - you could take out a thousand dollars out of somebody's account, and the bank would say, yeah, sorry.



STEVE:  Well, it's interesting that this question hit at a time when just a couple days ago I found myself, like, at the PayPal site, ready to move forward; and I stopped because I remembered that it is impossible to override the source of the account.  That is, PayPal will only take it from a checking account.  And unfortunately, in my case, that's what I've got registered.  I don't have a source of funds sitting in PayPal.  And I remember there was - I wanted to briefly join for something, I don't remember now what it was, but it was a very sketchy site.  And it was like, oh, there's no way I'm giving them my real credit card.  So I thought, okay, I'll use a one-time PayPal.



But then I thought, wait a minute, I mean, I mistrusted this site so much that I didn't trust them even to withdraw the $4.95 or whatever they said they were going to.  And I realized I was letting them, because PayPal doesn't give me an upper limit capability, I couldn't say create a card and set a limit for $5.50.  It's just it's open-ended until you close it.  And I thought, there's no way I can use this.  Now, I do know - because many people have written in with their solutions for my credit card dilemma.  One did say that American Express had withdrawn that service.



LEO:  Oh, interesting.



STEVE:  So I don't know whether that's still available.



LEO:  Oh, that's too bad.  I'll have to check.



STEVE:  He was using it, and then they said it was no longer.  However...



LEO:  Why would you stop?  That's such a great service.



STEVE:  Yeah, well, and apparently both - many people recommended Bank of America and Citibank, with both Visa and Discover cards.  So I'm going to track that down.  Someone said that Citibank has a downloadable piece of software.  And I do like the idea of using a piece of software just for ease of use instead of having...



LEO:  You need to go to the website and...



STEVE:  Yes, exactly.



LEO:  Although the website keeps all transact- all the card numbers and so forth, so you can kind of - you do have this record.  I've just checked Visa and MasterCard, which is the kind of card that PayPal uses.  Do stand by the zero liability for debit cards.  So that - banking law apparently does give a little more leeway on debit cards for the bank.  But both MasterCard and Visa have the same zero liability policies for your debit card as they do for your credit card.  So Ward brings up certainly a good point, and one to pay attention to.  And you might check.  But according to MasterCard, which runs the program for PayPal, you do have zero liability.



Mark Bentsen in Dallas, Texas wants to transfer his risk:  Hi, Steve.  Can you recommend ways to transfer the risks associated with enjoying the conveniences of an online life?  Wonder what he means?  Well, let's find out.  I do about everything that could be done online.  And there's something in me that feels like I'm playing Russian roulette when I make a purchase or complete a form requiring personal information.  I know that feeling.  Since listening to the show, Steve, I have the same feelings, like what am I doing?  I'm extra cautious now.  As a project manager, we could spend a great deal of time considering what to do with risk.  I follow the ATM methodology of managing negative risks:  Avoid, Transfer, or Mitigate.  Had you heard of that before?  I've never heard of that before.



STEVE:  No, I thought that was neat.



LEO:  Much of what I've enjoyed learning on your Security Now! podcasts are behaviors that I would classify as avoidance or mitigation of a negative event happening to my computer or personal data.  In a recent financial course, I learned of insurance for identity theft that seemed reasonably priced.  I know I'll not be out any money with charges made against my Visa card.  But the loss of time it takes to repair personal identity theft increased on average to 600 hours - wow - 300 percent over previous studies of the Identity Theft Resource Center.  That's true, though, when I hear about people having to clear this up, it does, it's just a time...



STEVE:  Oh, it's just unbelievable, Leo.



LEO:  With my time and my attention being very valuable, do you agree this type of insurance is a good measure?  Identity theft insurance.  Do you see other ways of transferring the risk of identity theft when it comes to protecting your personal information?  So he's saying we teach about avoidance and mitigation, but what about transferring the risk by buying insurance?



STEVE:  Yeah, the problem with that is that I'm not exactly sure what it is you're buying.  As I understand it, the individuals who are victims of identity theft have to spend their own time and resources.  And, I mean, just writing letters and explaining and just jumping through hoops.  And, I mean, really, we've all heard stories about how it just, like, ruins their life, and they end up with their credit messed up, and no one believes them.  And it's like all of the burden is on them.  I don't know how you insure against that.



LEO:  Well, there are companies that do this.



STEVE:  You mean, what, like take over the responsibility of doing all that for you?



LEO:  Well, the one that comes to mind is LifeLock, which has gotten a lot of advertising.  That's the guy who gives out his social security number.  And by the way, you know, here's the point of it.  Basically they do what they can to mitigate.  But then the real point of this is they, if you get your stuff stolen, they have a $1 million service guarantee, and they take care of it and so forth.  I would investigate thoroughly.



STEVE:  So, okay, but that's prevention rather than...



LEO:  No, it's both.



STEVE:  Oh.



LEO:  It's both.  So they do the prevention part, which I think is very important, although, you know, they do things like put credit locks on the various secure, like Equifax...



STEVE:  On the three different security services, yes.



LEO:  The credit reporting agencies and so forth.  But then - so they do all the proactive stuff.  But then they say we'll pay up to a million dollars to cure the failure or defect in our service.  See, I'd read these fudge words carefully.  But the idea being, if you should lose your identity, we'll take care of it, and we'll reimburse you.  I don't know if he's talking about LifeLock.  I think that's the best known of these services.  And, you know, there was some criticism of LifeLock.



But then Bruce Schneier, whom I know we both recognize as a real great security expert and very reliable guy, kind of came to their defense, saying that it's the credit - he wrote an article which I recommend reading called "The Pros and Cons of LifeLock."  He said that the credit agencies hate these guys because they don't like these fraud alerts being placed.  It's a pain in the butt for them, et cetera, et cetera.  So they've kind of tried to pooh-pooh this.  But he says, I think it's more an economics thing.



So Wired magazine's "Security Matters" column by Bruce Schneier, he talks about this.  It came out in June of this year.  I could put a link in the show notes.  You can read about the pros and cons.  I would say his bottom line is, well, you can do all this yourself, so I don't know if it's worth paying for it to do it.  But what the service claims to do, he says, get LifeLock if you want, or one of its competitors if you prefer.  But remember you can do most of what these companies do yourself.  You can do the fraud alert.  You can put the credit freeze on your account.  You know, you can check it regularly.  I guess the real question that they, you know, you can do all that, is the insurance then worth it.  And that's exactly what our question is about.



STEVE:  Well, and it's interesting, too, because I liked how Mark started off by saying, look, you know, I'm doing everything I can online, and I'm feeling very vulnerable.  I mean, and you commented that just participating in the podcast for the last four years has heightened your awareness.  And it has mine, too, because, I mean, this stuff is going on.  And it is unfortunate that at this point in time we're sort of in this strange place where we are filling out forms, giving our name, address, fundamental information about us, spreading it far and wide to all kinds of entities that we know nothing about.  We know not where they are, not who they are, nothing about their reputation.  It's like, oh, I want what you have.  So I'm going to tell you all about myself.  I mean, it really is, it's something that doesn't scale well.  And I don't think in the future that's going to be the way the model works.  There will be models more like Google Checkout and PayPal, where they serve as a front and protect a lot of this information for us.



LEO:  Yeah, ultimately that's probably a better way to do it.  Google's doing it with medical records, too.  And so they're really kind of investing in this kind of thing.  Bruce's bottom line is it's 120 bucks a year.  That's a lot of money.  He doesn't think the risks you run are great.  He says you can do it yourself.  He does say they've paid out their guarantee 113 times in the four years the company's been around.  So they do pay it out.  He says, and by the way, most of the time it's been problems that occurred before the LifeLock was used.  So he's saying what LifeLock does is effective.  So you can do it yourself.  Maybe the best thing to do is figure out what they do, read this article, do what he says to do, protect yourself, and then not worry about getting in trouble because you won't.



STEVE:  Right.



LEO:  One hopes, anyway.  It is scary.  I mean, I understand what Mark's saying.  It's scary these days.  Mike in Ohio has an idea for hassle-free clickjacking protection.  I used NoScript, by the way, and it's such a hassle I turned it off.  It's like, every site, every site says, you want to use these scripts?  And that's like, I gave it up.  He says:  After listening to the clickjacking episode last week, I had a question regarding NoScript.  I have not used this plug-in prior to listening to the netcast, so I gave it a try.  I quickly came to the conclusion - as I did - that this wouldn't be that easy to recommend to friends and family, who are nontechnical, based on the high potential of fatigue and frustration they may have in using the plug-in.



I remember you mentioned that NoScript would still protect you against clickjacking, even if you chose to use the option to allow scripts globally, which they say, dangerous, danger.  So my thought was to get my family and friends to download the NoScript plug-in.  If they experience any fatigue or frustration using the plug-in, then I'd have them enable the option that says just turn on all scripts, thinking they're still protected against clickjacking.  Your thoughts on this would be greatly appreciated.  I also want to say I've listened to every episode, and I greatly appreciate all the work you and Leo do every week to produce a top-quality netcast.  So that's what I'm doing, Steve, right now.  I'm using it, but only with all scripts on because it's such a pain.



STEVE:  I did verify that what I had said last week was correct.  And that is, with NoScript present, the current version of NoScript, if you do choose to allow scripts globally, then you still get full clickjacking protecting.  The second link on the show notes for last week's clickjacking episode is a demo, a simple clickjacking demo.  And if you go to a browser, either a non-Firefox browser or Firefox without NoScript installed, you don't see what's really going on.  You go there with NoScript installed, even if you have decided to allow scripts globally, and instead what you see is what would normally be hidden, which is in this case the little Flash configuration dialogue asking for permission to turn on, to give the other end access to your camera and video.  So yes, I wanted to let Mike know that strategy works.



LEO:  And Leo.  Because Leo's using it, too.  It's like it's worse than User Access Control.  I mean, oh, my god, every five minutes.



STEVE:  We have a couple more questions about that later on.



LEO:  Okay.  Jared in Australia, Washington - wait a minute.  Or either in Australia, Western Australia, one or the other.  I don't think there's an Australia, Washington.  I'm guessing he's in Western Australia - is getting SSL certificate errors from Google's Gmail.  He writes:  For people who access Gmail over SSL using IE7, they might like to be aware of a certificate error page that IE presents you with before entering Gmail's page.  If you didn't know this, you do now.  You'll see, "There is a problem with this website's security certificate."  Really, I haven't seen that.  Of course, I'm not using IE7.  "The security certificate presented by this website was issued for a different website's address."  One of the two links is to "continue" - not recommended.  Can you explain why this happens only with IE7 and not previous versions of IE?  He's using the beta version, the new version of - oh, no, no.  IE7 is the current version.



STEVE:  Yeah.  It's weird.  When he wrote this, I thought, well, okay, this doesn't sound right.  On a hunch, I put in https://gmail.com.  And I got that error message.



LEO:  Oh, all right.



STEVE:  And so here's what's going on, is for some reason Google has grabbed the Gmail.com domain and has that pointing at the regular Gmail domain, which is mail.google.com.  



LEO:  Oh ho.  So a little mismatch of the names.



STEVE:  Yes, exactly.  So what Jared is doing is he's using Gmail.com, which is not the official website.  I mean, that's not the domain name for Gmail that Google is offering.  But it happens that it works.  The problem is, since he's using https to go to Gmail.com, the first thing that happens during the connection is the name of the certificate sent from Google's server is compared with the URL, and they don't match because he's not supposed to use Gmail.com over a secure connection.  So that's the cause of confusion.  But I thought it was an interesting question for all of our listeners because the idea is that, as we've discussed before, the certificate of the server that you're connecting to, the exact name has to match what you've got in the URL, or the browser says, whoa, wait a minute, I've gone to the IP the DNS told me to go to.  I've established an SSL connection.  I've exchanged credentials.  Yet the server is saying it's a different server than the one you're expecting.



Well, this is crucial for avoiding man-in-the-middle attacks because a man-in-the-middle attack would, I mean, it would intercept that.  And what the man-in-the-middle cannot do is give you Google's certificate signed by an authority you trust.  That's the critical link.  And so it's important that the browser complain if there's a security certificate mismatch.  But in this case Google doesn't have a different IP and a separate certificate for Gmail.com.  Instead they just dump you on their regular IP.  And sure enough, the certificate does not match.



LEO:  Interesting.



STEVE:  Yeah, I thought that was sort of an interesting glitch.  So Jared, you can avoid that by going to mail.google.com using https, and it works the first time, every time.



LEO:  Yeah, I think I've seen that happen before when, you know, it's a mismatch of domain names.  It's fairly common.  So that actually would happen not just with IE7, with any browser would do that.



STEVE:  Yes, it should.



LEO:  One hopes.  If it doesn't, get a better browser.  Kevin Lampo in Lebanon, New Hampshire was thinking about secure ways to vote using SSL:  Steve and Leo, I've been listening since Security Now! was known as This Week In Tech.



STEVE:  I don't think that ever quite was, but...



LEO:  Never happened that way.



STEVE:  But you launched your show first, and then Security Now! came along as number two, I guess.



LEO:  So it's always been part of the TWiT network.  It's a confusion because This Week In Tech is the Sunday show that's the roundtable with the journalists, which you've been on.  And TWiT, which stands for This Week In Tech, is the name of the network.  So you're a member of the TWiT network, but the show is Security Now!.  I know, I don't blame him for the confusion.  He says, whatever the name:  It's stimulated much gray matter, to the chagrin of my wife.  As I sit here pondering what Tuesday's election will bring, I began to wonder how else people can securely and fairly vote.  I also began to think about the long lines, the ordeal many have and the lack of polling personnel.  I came to one question:  Could a secure website, using SSL and a credit card, be structured to provide the mechanism for the a state to collect votes?  There already exists the means to check authentication.  The whole validation process can happen behind the scene as one is filling out the voting forms.  The process could be done with little need for human interaction at home or at work.  And that's what scares the hell out of me.  What do you think?  Thanks for all the info and the incredible and valuable SpinRite.



STEVE:  Well, it was an interesting question.  My take is that the technology is not the problem.



LEO:  Right.



STEVE:  You know, we've got the technology.  I mean, we've got technology coming out of our ears.  As soon as you have a public key technology where you're able to have one key encrypt something that only the matching key can decrypt - and vice versa, that other key can do the encryption and only your key can do the decryption - once you have that, that's an incredibly powerful piece of technology.  And we've seen all the different ways that it can be used.  But that's just the technological enabler.  The problem is everything else.  I mean, we could just sit here, and I'm sure our listeners could, too, just sort of tick off all the things that could go wrong with anything where we, like, try to come up with a non-person-present voting technology.  And  unfortunately, there seems to be a high motivation among some people to game the system, to come up with a way of exploiting any sort of weaknesses.  So I just - I don't think - I think we're a long way away from anything happening.  Not at all because we don't have the technology, but because we don't have anything else.  So much else of what we would need to come up with a trustworthy voting system just doesn't exist.



LEO:  You know, the temptation for technologists like us is to say, well, eVoting.  And as we've learned from eVoting, which is even one step less removed than online voting would be, without a paper trail it's very, very dangerous.  And even with a paper trail, people have to know enough to look at the receipt and say, is that what I voted for?  And I suspect it's a problem.  Doing it online, I wonder if we'll ever have online voting.



STEVE:  I'll be surprised.  I have to say, though, I'm very disappointed in so much of what I see.  I saw yesterday, because we're recording this on Wednesday, and yesterday was Tuesday, November 4th, Voting Day, the examples that were being drawn of the butterfly ballot, where how you're supposed to join two boxes by filling in a black mark, and it creates an arrow?  And, I mean, in a recent small election something like one out of 10 people did it wrong.  It's like, my goodness, folks, how can it be so messed up as that?  And the other problem, the idea, for example, that a company like Diebold has a proprietary system that is closed source, closed technology, and they're selling it saying, trust us.  I mean, really, that's the kind of thing that can really get me going ballistic because it just seems so wrong.



LEO:  In the state of California, I think we have a very enlightened Secretary of State.  Debra Bowen, who I've interviewed before, is very technologically savvy.  Last year she had the University of California assess these machines, and they were all decertified because they were all hacked.  They could hack - they hacked them several different ways, and they said if you'd given us more time, we could have hacked them in more ways.  So let's solve the security problems we have with online banking and the Internet first, and then we can think about voting.



STEVE:  Well, and for example, Leo, I mean, somebody is making a tremendous amount of money selling these machines to municipalities and the U.S. government.  It seems to me, I mean, given all the technology we have, the proven capability of open source with a lot of oversight to vet problems, I know that if a requirement were put together saying, okay, whatever, manufacturers, you have the right to make the hardware following these specs.  We're going to force everything else to be open, and let academicians and hobbyists and security professionals plow into this and come up with a robust solution.



LEO:  Yeah.  Still don't think it's going to happen.



STEVE:  I know.



LEO:  And this is too important to mess with.  You know, going to the polls, validating your, I mean, by the way, the secret of voting anyway is that a significant percentage of votes are lost, miscast, messed up.  It isn't a perfect system as it is.  And I don't think making it electronic is going to make it more perfect.



STEVE:  No.  And although not wanting any more nightmares, it was nice that there was such a decisive result because now we're not in the margins, having to recount hanging chad.



LEO:  And that's where it becomes problematic.  And the thing is, as we go forward, elections are going to continue to be close.  I don't think in this country, the way it's constituted, that any party is going to have such a strong majority, that many elections are going to be razor thin.  And that's when all this stuff really becomes an issue.



STEVE:  Yeah, well, in fact, I think right now in California, here we are, it's the next day, and there are still a number of propositions and ballot measures that have unknown outcomes because they are very close.



LEO:  Right.  Virginia, I think, is still out there unregistered.  Let's go on.  Another question.  And this one comes from Athens, Georgia.  Bill Rakosnik writes:  Thanks for your explanation about the latest updates to NoScript.  I was using NoScript on a couple of my computers already, but I wasn't using it on the family computer because my wife and children have too much trouble functioning online with scripting disabled.  Sorry, Steve.  After your explanation last week, I now have it installed on the family computer with scripting allowed globally.  That's how I'm running it here, too.  However, I've always wondered what the other updates to NoScript do.



Steve, you've used IE with scripting disabled for years.  You didn't need regular updates to that feature of Internet Explorer.  Why does NoScript get so many frequent updates?  I currently only understand what the last update to NoScript was for.  I don't understand what any of the previous updates did.  I mean, scripts are on or off; right?  I would have thought NoScript either disables scripting or it doesn't, and that it wouldn't need an update to block a script that it didn't block before.  That would just leave updates to make sure that NoScript was compatible with the latest version of Firefox.  And I know I'm getting more updates to NoScript than there have been updates to Firefox.  What's the story, morning glory?



STEVE:  I think the problem is, I did notice sort of the same thing, a long trail of point, point, point updates and versions.  I think that the author is nailing down problems that he encounters that users report.  I don't know if he's writing it hastily, if it's not being tested by a large group of people, I mean, I can attest to the fact that the people in my newsgroups are a tremendous asset for all the work I do because they're able to really pound on stuff quickly.  And I'm not putting out half-baked versions that haven't been heavily tested.  And unfortunately, in this incredibly heterogeneous environment of all kinds of operating systems and browser versions and operating environments, there is just no way not - there's no way to get around the need to really test.  And so it must be that the problems are being found, and NoScript's author is fixing that problem.  Then another one is found, and he fixes that.  And another one's found, he fixes that.



The other thing is, he's not doing something that is as simple as it appears.  He's getting himself much more involved with the browser in order to give us the features that we're asking.  So NoScript is really evolving beyond something that simply turns scripting on or off.  In fact, these latest features are not about scripting being on or off.  They're completely tangential.  But because NoScript is so popular, he's giving us new features in this existing tool.



LEO:  Almond McClain - love that name.  Almond McClain in Yuma, Arizona wonders why netstat is bailing:  Hello.  Longtime listener since numero uno.  I just noticed today when my PC was running a little sluggish, I did netstat, and as soon as it finished loading its last address it closed itself, as if it didn't want me to see it.  So hit my print screen button and went to paint.  Somehow I'm connected to nine connections.  Time to format?  I'm always running Skype and an old version of Hamachi since LogMeIn messed it up.  They bought Hamachi, of course.  Perhaps an old version of something I'm running is giving me issues.  Why is Almond having nine connections?  Is that an unusual number?



STEVE:  Well, it's been a long time since we've talked about netstat, the netstat command.  And we have described it.  I wanted to just sort of refresh our listeners, or to pick up any who hadn't heard this description.  It's a very handy command built into Windows, every version of Windows, and 

other operating systems, as well, that gives you a status of your network connections.  So you launch a so-called "DOS box," or command prompt, and type netstat.  And it will immediately give you sort of a listing of what's going on.



Now, as to how or why this thing is crashing or closing the box, I can't really respond to that.  I have no idea why netstat would run and then terminate itself.  It should not have the ability to do that.  It shouldn't be able.  So it may be that the particular instance of the netstat command is buggy, and it's crashing the DOS box.  But even that I wouldn't expect really would close the command prompt window.  So I don't know what's going on there.



As for why he's got nine connections, when you run the netstat command, you'll see the status of a bunch of stuff over on the right-hand side.  The word "established" is indicative of a connection, meaning that a connection has been established between your computer and another computer.  And so you can look at the IP addresses and see if you recognize them.  Many times you'll see 127.0.0.1 on the "from" side, and the same 127.0.0.1 on the "to" side.  What that just means is that processes inside your own system are using the IP technology in your computer to talk to themselves or to other processes.  So that just means a connection has been established within your own computer, not to anything outside.  So that's nothing to worry about.  It may very well be that that's what Almond is seeing when he talks about these established connections, is these things are just connected to themselves.



The other thing you can do is to add some additional features.  For example, I use "netstat -an," as in alpha Nancy, "an" to get my normal - that's normally the way I run the command.  But if you put "abn," the "b" option was added in XP.  It does not exist in Windows 2000.  So in XP you can say "netstat -abn," and it finds out and displays which process is responsible for each of the line items in the netstat display.  And that quickly allows you to determine who is establishing these connections.  Likely, I know that one of my concerns, when we talked to Alex, who is the author of Hamachi, was gee, he's got TCP connections established to every single Hamachi client running on the planet, which seemed like that would be a problem.  So I do know that Hamachi will be responsible for some of those established connections.  Skype may well have a static connection hooked up to Skype Central in order to perform its various housekeeping and management tasks.



But if you do "netstat -abn," you should see Skype.exe, Hamachi.exe, and you'll be able to determine what it is that is responsible for making those connections.  And if you see things you don't recognize or you're surprised by, that's a great place to start in doing research to find out what's going on inside your system.



LEO:  Very useful tool, netstat.



STEVE:  We did skip No. 9, Leo. 



LEO:  Oh, sorry, let's go back.  More NoScript.  I got confused because of all of these NoScript ones.  Esbjorn Larsen in Denver, Colorado is fighting and losing with NoScript.  Steve, first I wanted to thank you so much for all your dedication and knowledge.  You've added to my own experience.  I love NoScript, but I actually end up disabling the add-on more often than not because most sites I visit use scripting.  That was my experience.  It even makes the Google search page unusable, even if I specify Google as a safe site.  So what are your suggestions on effectively using NoScript?  Right now my experience with NoScript is very similar to my experience with Vista UAC, which I immediately turned off.  Oh, boy.  Low tolerance for pain.  I'm a very secure user.  I work with security issues.  I've never had a virus or hard drive problem, knock on wood.  But I do own a licensed copy of SpinRite just in case.  You and Leo are awesome.  Keep up the good work.  Well, if he knows what he's doing, I guess UAC doesn't matter.  How do you use NoScript without having it drive you absolutely bazooti?



STEVE:  The reason I didn't want to skip this question was this was when I planned to confess.



LEO:  You turn it off.



STEVE:  I've turned it off, too.



LEO:  It's just, I mean...



STEVE:  It's running in Firefox.  But I've got a little exclamation point on my little red S down there in the tray because I've enabled scripts globally.



LEO:  Yup.  It's just because there are so many scripts on every page.  And I don't know if it's a flaw in NoScript.  But it just seems like when you click yes, yes, use anything on this page, or everything on the site, it doesn't seem to remember it, and you still have to, I mean, it just drives me crazy.  So, yeah, finally I use it, I'm using it like that, too.



STEVE:  Yeah.  What I'm doing, my compromise is, if I am in a mode where I'm going to sketchy places, I mean, this isn't - this really, you know, it's not the way to be the most secure, but it's the way to keep your sanity, is I turn it on when I'm going places I don't - where I may be exposing myself to some sort of problem.  And again, it's another reason that I'm very excited to have the author of Sandboxie on next week is we need a solution that allows scripting to be left on and still protect us from what websites may be doing to us.



LEO:  Well, I'm glad we put this one in there, then.  Because I was feeling like, oh.  I think a lot of us, oh, we're bad security people.  We're going to take a little break here and come back in just a bit with Sheldon, who has a simple solution, he says, for the Sockstress problem.  That would be welcomed by the entire security community.  And Dominik in Stuttgart, who has a question for Sandboxie's author, which will lead us into next episode.



Now, Steve Gibson, our ninth and, oh, I'm sorry, our 11th and 12th questions, starting with Sheldon Smith.  He's in Apple Valley, Minnesota.  He says, oh, no problem solving this Sockstress thing.  First he says:  Thanks for a great netcast and SpinRite.  By the way, "Dr. Who" is supposed to be cheesy.  I know.  It's part of the fun, the humor.  Listening to the Sockstress episode and thinking of past episodes where Steve explains TCP and the TCP protocol, we're talking about an exploit based on how the initial handshake works; right?  So a miscreant sends a SYN.  The target servers reply with a SYN/ACK.  The miscreant sends an "Oh, wait, my buffer is full."  And then everything grinds to a halt.



So why can't the target have a timeout, and just send a NAC and drop the connection?  If some clown calls me and says something like, "Oh, wait, someone's at the door, I'll be right back," I either tell them to call me back or wait maybe a minute, then simply hang up.  If it's that important, they'll call back. Anybody would do that.  In addition, don't the packets also have sequence numbers?  The earlier we are in the sequence, the shorter the target system's "buffer full" timeout timer.  That would be a good way to solve it.   What do you think?  Is that a solution?  Didn't we address - I think we addressed a timeout as a solution.



STEVE:  Well, yeah.  And the problem is there are many different ways that this problem can be solved.  The problem is, none of them are in place today.  So it's certainly the case that there are a number of ways that TCP could be hardened against this kind of exploit.  You have the potential problem for false positives, that is, for TCP being expected to function in, for example, a patient, forever way because there are some situations where you want that, where in fact TCP by definition establishes a connection which it maintains forever.  At the same time there are, I mean, all kinds of things that could be done to minimize the window of exposure to Sockstress sorts of problems.  But they're not in place right now.  So it's like, yes, we can certainly do things.  But the point was, we need to do them.  And they're not done yet.  So anyway, I wanted to sort of respond to Sheldon...



LEO:  He's right, the answer is good.



STEVE:  Yeah.



LEO:  That would work.



STEVE:  Yeah, he's right.  But it's like, okay, well, we've got to do that.  And the good news...



LEO:  It's on the list.



STEVE:  Yeah, exactly.  And the good news is the guys that came up with this are getting traction now.  They've got the vendors' attention.  And I expect that these kinds of problems are going to get solved because they succeeded in bringing this to the attention of the powers that be that are in charge of managing the development of our core low-level protocols over time.  It is just going to take a while.



LEO:  And it takes so long because you've got to get all these clients to work together.  I mean, it's a complicated blanket of interacting servers.



STEVE:  Well, it takes a while because anything takes a while.  I mean, just making a change...



LEO:  Well, you don't want to break the Internet, either.



STEVE:  Well, and that's the other part.  It's not just it takes a while.  It's that the problems with side effects, you absolutely have to make sure that what you do doesn't make things worse.



LEO:  Right.  And finally, Dominik in Stuttgart, Germany.  Dominik writes he's got a question for the author of Sandboxie:  Dear Steve, I was at the edge of buying Sandboxie, really great tools.  But then I read in the forums it's not working in Vista 64, for reasons the author has explained.  That's a killer for me.  I'm planning to switch from XP to Vista 64.  When you have Sandboxie's author on your show, maybe you could ask him about his plans for 64-bit support.  Great show.  Haven't missed one.  And I bought SpinRite.



STEVE:  So we will absolutely put that on the list of questions.  We'll have a great episode.  I'm going to talk about some really interesting details next week of the trojan that RSA Security has provided a great deal of documentation about, talking about penetration and the nature, detailed nature of the damage that it's done.  And these were infections that came in through people's browsers.  So that's the perfect opportunity to have Sandboxie's author on, as we will, and talk about a very nice, lightweight solution for solving this problem.



LEO:  Very good.  Can't wait.  It's going to be fun.  Steve Gibson, you're the best.  Always fascinating to go through these questions and answers with you and get some insight.  I think it's a really - I like that we do this every other show because you talk about some heavy-duty stuff.  And so to get some clarification, the opportunity to get some clarification is valuable for everybody, I know.  And I include myself in that.  So thank you for doing that.



Next week we're going to talk to Mr. Sandboxie.  And we thank you for being here.  Don't forget you can go to GRC.com to get SpinRite, the world's best disk maintenance utility.  I use it on every drive before we use it.  We SpinRite ahead of time.  And of course should anything, you know, we have any trouble, that's the next time it gets SpinRite.  Very often saves our bacon.  And, as you know, you can save yours.  GRC.com to get that.  And also, while you're there, that's where to get all the Security Now! show notes, the 16KB versions for the bandwidth-impaired.  Steve has transcripts online there, too, which is very helpful a lot of times to read along as Steve talks.  That's all at Gibson Research Corporation, GRC.com.  Thank you, Steve.



STEVE:  And I will remind people to go to GRC.com/feedback in order to submit their questions.  All the things that I've been reading from people are from people who went to GRC.com/feedback.  There's a web form there.  Fill it out, and I receive it.  And in two weeks we'll go through that.



LEO:  Very good.



STEVE:  Thanks, Leo.



LEO:  We'll see you all next time on Security Now!.



STEVE:  Bye bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#170

DATE:		November 13, 2008

TITLE:		The TKIP Hack

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-170.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo begin with a refresher on WEP, the original technology of WiFi encryption. With that fresh background, they then tackle the detailed explanation of every aspect of the recently revealed very clever hack against the TKIP security protocol. TKIP is the older and less secure of the two security protocols offered within the WPA and WPA2 WiFi Alliance certification standards.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 170 for November 13, 2008:  WPA Crack.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks.



It's time for Security Now!, the show that covers all those important little gotchas on the Internet, on the computer, in your banking, in your online privacy.  And who better to do that than Mr. Steve Gibson, head honcho.



STEVE GIBSON:  Hey, Leo, great to be with you again.



LEO:  Yeah, it's good to talk to you, Steve.



STEVE:  170.



LEO:  170, can you believe that?  The man at GRC.com, and also author of SpinRite, his fantastic disk recovery utility.  Discovered the first spyware in the world and coined the name "spyware."  And today we are going to change gears a little bit.



STEVE:  Yes.  I said last week that we were going to have the author of Sandboxie on to talk about his program and the way it functions, it being a cool way of encapsulating pretty much any program, but specifically web browsers - which of course, as we know, have so much trouble with security - in order to prevent anything the web browser might do from escaping.  We've talked about the problems of disabling scripting, which is a really good thing to do.  But it just - so many sites are increasingly requiring scripting that it becomes a problem to disable it.



Anyway, in the meantime the big news hit, between the time I said that last week and now, about a - well, we're going to talk about this WPA WiFi security problem.  Everything I have read in the press has been wrong.



LEO:  Oh.



STEVE:  Gizmodo said, "WPA Wi-Fi Security Gets Cracked:  Your Network Is No Longer Secure."  And, I mean, the headlines have been blaring because, I mean, this is, well, it would be big news if it were true.  Something did happen.  It was significant, but - and also incredibly limited and incredibly clever.  So this ends up being a major propellerhead episode.  What's so cool is that we can explain what happened in a way that people will understand.  And there's remediation things that people can do.  Some things that people might do wouldn't work.  So anyway, we're going to explain exactly what it was that was figured out, who did it, what they did, and what it means.



LEO:  All right.  The details of the exploit and, most importantly, what you do about it to avoid it.  And I've already done that, by the way.



STEVE:  And the correct story.  I mean...



LEO:  Yeah, that's the most important.



STEVE:  The absolutely this is what it is.  Anyone who listens to this podcast will come away really getting it, I mean, what exactly this thing is.  And it is complicated.  So we're going to have a good episode.



LEO:  All right.  We geek out.  So, Steve, before we get to this TKIP hack, is there anything you want to cover from last week, or security news?



STEVE:  Yup, got a bunch of little goodies.  We actually have some errata bin things.  One of the notes I read as I was reading through last week's Q&A - actually I guess I saw it afterwards or I would have mentioned it then - was somebody felt that I was evidencing a bias against Russia and China.



LEO:  That's a reasonable point.  And...



STEVE:  Yeah.



LEO:  Yeah, I think that's a reasonable point.



STEVE:  Well, I would say it's reasonable if it weren't - it would be reasonable to believe I was biased if perhaps I wasn't clear enough that in fact I'm repeating and restating geographical fact about where these attacks originate from.  I mean, unfortunately, for whatever reason, and I don't have any political bias, these attacks actually come from China and Russia.



LEO:  Well, but I think we should make the point, I think we've made it before, that doesn't mean that's their origination point.  It could very easily be that somebody's hacking from Dover, Delaware, but going through a Chinese server.



STEVE:  Yes.  In fact, studies have shown that, for whatever reason, again, lots of Chinese machines are compromised by zombies.  And so when, for example, denial of service attacks come, they come in from machines at Russia, not because - or, I'm sorry, from China, not because Chinese people are launching them, but because Chinese people have their machines compromised.  So...



LEO:  Possibly because they have a lot of - they apparently have been using a lot of pirated versions of Microsoft Windows.  They're probably not getting updates.  And of course they're getting hacked as a result.



STEVE:  Right.



LEO:  But it happens everywhere.  But I guess the real point is that you can never determine who's doing the hacking based on where it seems to be originating from.  In fact, it's highly unlikely that it's originating from the last point of departure.  You'd be a bad hacker to say I don't care if you know where I am.



STEVE:  Right.  Although also, I mean, it is known that there is organized crime in Russia that is responsible for a lot of the cybercrime that we see.  I've had several conversations with FBI friends who have, I mean, who've backtracked this to specific organizations, to specific locations physically in Russia.  So when I do say something is originating from this or that country, it's normally that the evidence and the facts - I'm not making that up; I'm not picking on them for no reason.  It's that typically that's really where a specific event that I'm describing came from.



LEO:  Well, and to follow our theme of today, the mainstream media doesn't make that - very frequently doesn't make that observation.  When you saw the stories this week that the Obama, McCain, and White House - Obama and McCain campaigns and the White House had been hacked from China, the implication was it was Chinese hackers.  But that does not mean that at all, does it.



STEVE:  No, it could easily be that somebody was relaying the attack through a machine located there.  And you would, because for the kind of penetration that was found by the FBI, they end up with logs and IP addresses.  And you know somebody is getting their door knocked on in China.  So hopefully it's an innocent grandmother who has her machine and didn't understand what was going on, and on it they will find some relay technology that has left no track or trace for where the actual connection came from.  So somebody was using it to cover their tracks.



LEO:  When I do a whois - I get attacked all the time, I imagine any server does - and I see IP addresses in my log, usually it's people trying to brute force SSH or other services.  Whether or not I'm running them, by the way.



STEVE:  Or it's, as we've discussed, it's Internet background radiation.  It's just junk that we know will never die, probably.



LEO:  Banging on my door.  Well, I see, you know, they type SSH, you know, root at TWiT.tv, and then they try a password.  It doesn't work, they get three chances, they come back.  Usually it is a Chinese IP address coming from a university.  That's what's interesting when I do the whois.  It almost always the address is owned by a university in China.  That could be two things.  Could be a college kid, or - which is, I think, perfectly likely - or it could be that that university, like many, have UNIX servers or other servers that are easily compromised, they're just on all the time, and that's frankly where a lot of attacks come from.  Doesn't mean that's where the attacker lives.  Anyway, that's my point.



STEVE:  The other thing that - the other observation which people in our newsgroup made, and I even saw people submitting their observation, the similar observation to GRC.com/feedback, is I made the comment last week when the guy was talking about how he runs netstat, the netstat command, and he had to resort to, like, hitting PrtScr really quickly because...



LEO:  Yes.  Doh.



STEVE:  You know, it didn't even occur to me that he may have, and this has been suggested, been typing "netstat" not at an open DOS prompt window, but under the Start menu, using the Run option, to get the little command line, typing it there.  Well, when you type netstat - "netstat," for example, space "an," in the little Run line under the Start dialogue off the Start button, it will launch the command window, run the command, and shut the window down afterwards.  And it's like, oh, I'll bet that's what he was doing.  Just didn't even occur to me.  So for what it's worth...



LEO:  It occurred to all of our listeners, I might add.  I think I got a lot of email.  And every one I went, oh, of course.



STEVE:  Exactly.  So, for example, if you wanted to launch the command in a static way, in the same way, from the Start menu, you could start by saying cmd space /k.  "K" keeps the window up after the command has been executed.  Then say "space netstat space hyphen an," and it'll launch the window, run the command, and then leave you there.



LEO:  Oh, that's a good way.



STEVE:  In fact, I think it leaves you with a "Press any key to close the window."  So you can then scroll around, look at it, see what you want to do, then hit Spacebar or Enter, and it'll close the window, and you're back where you were before.



LEO:  That's a really good idea.  I never thought of that.  I always just type "cmd return" to open a window, and then run the command in there.



STEVE:  Right.  So in security news, this is a podcast occurring on the Thursday after the second Tuesday of the month.  And we know pretty much reliably every month what that means.  That means that Microsoft has released some security updates.  This is no different than most months.  Not a huge number.  I think once we had 11.  This time we just have two.  They are both remote code execution flaws.  Microsoft had a whole bunch of problems with their XML parsing, XML being sort of an interesting standard for flexibly and in textually describing hierarchical relationships among data.  And there were some code execution problems there, one critical, one important.  So standard routine is, as always, just make sure that your machine is up to date.  You'll want to get to that sooner or later.



It's also worth mentioning that the flaw we talked about a couple weeks ago now, I think it was two weeks ago we talked about a problem with Adobe PDF file parsing.  It is now being actively exploited.  So you want to upgrade to v9 if you can.  I don't know if Adobe has an update for - I don't think they updated beyond 8.1.2, which was where the flaw, anything there or prior.  So you do want to move to v9 of your PDF reader, which you can easily do just by going to Adobe.com, as I mentioned before, and download an update.  But there are websites - apparently ads, web ads in bad sites are carrying a reference to this PDF.  Your browser will load it and get itself taken over, and trojans are being installed through this vehicle.  So it's something you do want to take care of.  And...



LEO:  Adobe updated Flash, too, for a similar reason, didn't they.



STEVE:  Yes, yes.  And finally, I know you've mentioned this.  I've watched you on TWiT Live, Leo.  But it's worth mentioning that Google has updated Android to fix a very embarrassing problem.



LEO:  No kidding.



STEVE:  With the first release of their phone.



LEO:  It happened on my phone.  I couldn't believe it when I read it.  And I immediately typed "reboot" into my phone, just at the, you know, not at the command line, but just at the desktop, you know, when you first turn on the phone.  The phone reboots.



STEVE:  It turns out that they left a debugging switch set in their final release build of Android, such that anything you entered through the keyboard was going also to the root shell of the OS, with root privileges.  So, I mean, so no matter where you were, you could be texting somebody or entering data into a file, I mean, anything, it was all being echoed into the root shell.  So you had root level command privileges by default.  And as you said, Leo, you type "reboot" anywhere and hit Enter, and the phone shuts down.  Whoopsie.



LEO:  It's the strangest bug I've ever seen.  And I was stunned that it worked.  And I got - I have to say that immediately, the day that article came out describing it, a patch was pushed.  And I think they've pushed it now to everybody with a G1.



STEVE:  Yeah, yeah.



LEO:  Terrible, though.



STEVE:  Well, embarrassing more than anything.  If it's your own phone, it's not any kind of remote exploit.  But still, you know...



LEO:  Well, I imagine that probably little hacks, you know, people said hey, here's a special cool thing you could type into your - the other thing that was a little worrying is it appeared that it was logging everything that was being typed.  So in theory there's a file there on that phone that had some passwords and things like that.



STEVE:  Into the history buffer, right, that's a very good point.  Even passwords and things, yes.  And a listener of ours, Bob Morris, sent a nice little email saying "SpinRite Success Story."  This is a quickie, but a nice example of what SpinRite was able to do for one of our listeners.  He says, "My aging P4 went south a few days back.  Chkdsk reported errors on D:, circular redundancy in a folder, and some other such errors.  So I ran chkdsk D: with the /repair option.  Then the drive was gone completely.  It asked me if I wanted to reformat.  Yikes.  So I ran SpinRite on all drives.  SpinRite said S.M.A.R.T. was reporting the drives' imminent peril.  Did I want to tax them any further by continuing?"  He said, "I said yes because there were still a few things on the hard disk that I hadn't backed up.  SpinRite ran for 10 hours.  Upon rebooting, while S.M.A.R.T. still reported problems, D: was back, and I immediately backed up all my remaining files.  Thanks again, and I listen to your excellent podcast frequently."  Signed, Bob Morris.



LEO:  Isn't that nice.



STEVE:  So nice little happy SpinRite success story.



LEO:  Thank you. Bob.  Might take a break here, and then we're going to talk a little bit about what this exploit, this WPA exploit is.



STEVE:  Oh, we're not going to talk a "little bit" about it.



LEO:  Explain what it means.



STEVE:  Buckle your seatbelts, folks.



LEO:  And, now, the mainstream media got it wrong.  It has to do with this temporal key thing.



STEVE:  Integrity protocol, yes, TKIP, a mistake in basically, probably maybe by default, the WiFi encryption that everyone is using because until now it was believed to be completely safe, and it was less taxing on systems and more widely compatible because it's an evolution upwards from the, as we now know, really badly broken WEP encryption that nobody should be using.  The problem is, it's not quite as bulletproof as it was believed.  It's not broken, by any means.  It's not - this is not some horrible end-of-the-world problem.  But we're going to explain exactly what it is.



LEO:  You can imagine my consternation after recommending and telling for the last two years everybody, all you need on WiFi is WPA, you're safe, to read that headline, "WPA Cracked."  So we'll tell you what it really means in just a second.



[Commercial break]



LEO:  So, Steverino, it's time to get down to WPA brass tacks.



STEVE:  Yeah.  Okay.  So I would imagine that our listeners have seen the stories all over the place.  Most of the electronic online media carried the story.  This was big news.  The distressing thing, the reason we're talking about it, is that I read everything that I could find.  Nothing got it right.  Nothing...



LEO:  Even PC Magazine.



STEVE:  Yeah.  PC Magazine was as bad as any, actually.  I mean, really, I don't know why everyone went overboard about this.  Maybe it's they didn't understand what it meant.  And I can forgive them for that because this is a very complicated - it's complicated to execute.  What you end up being able to do is very limited, but potentially means something.  Anyway, so...



LEO:  Now, has he revealed the technique?  Because I...



STEVE:  Oh, yeah.  In detail.  We know everything about it.



LEO:  Okay.  Because the initial stories - and maybe that you can't fault the initial stories because he hadn't explained how it worked, he had just merely said there's a  hack, and I'm going to tell everybody in a week.



STEVE:  No.



LEO:  No?



STEVE:  What I saw from day one was it being clear - well, okay.



LEO:  He was going to present it at some security meeting, I think.



STEVE:  Well, actually that's happening right now.  Given that this podcast is being listened to on Thursday, November 13, it is - Erik Tews is the lead on this.  His friend Martin Beck, who - they're both students in Germany.  Erik is a Ph.D. candidate at the Technical University of Darmstadt.  And Martin Beck is a student at the Technical University of Dresden.  And Erik is the guy who brought us the 60-second WEP crack.



LEO:  Oh, so he's an expert.



STEVE:  So he is - oh, yeah.  In fact, we had a podcast about this.  I think we called it "More Badly Broken WEP."  It was already damaged.  But Erik demonstrated how it was possible to obtain the key, the WEP key that is in use on a WEP-based WiFi network, full WEP encryption, how you could obtain the key with as little as 25 and as much as maybe 40,000 packets, which on a typical network would take about a minute.  Now, prior attacks, there was an earlier attack that took about 700,000 packets.  So, yes, you could still get the key.  But, I mean, these guys really, really know this stuff.  So that was one reason why they were taken - why what they said was taken very seriously.  Now, it's a - I would call this an extremely, well, I'm going to explain exactly what it is and how it works.  But it's not WPA is broken.



One of the other problems is there are a bunch of acronyms we're swimming around in here.  For example, I've read online that WPA is not safe, but WPA2 is safe.  Okay, that's not true.



LEO:  Oh, it's not.



STEVE:  No.  I mean, because WPA and WPA2 are not cryptographic protocols.  They are certifications offered by the Wi-Fi Alliance of certain levels of operation of WiFi hardware.  So WPA2 is not something different from WPA.  It's a different level of certification.  But it's not - but WPA2 can be just as insecure as WPA.



LEO:  See, I thought WPA2 used - automatically used AES.  So it could use TKIP.



STEVE:  No.  No.  And there again, AES is a cipher called "Rijndael."  TKIP is a protocol.  CCMP is the protocol which uses AES.  I mean, so my point is...



LEO:  I see.  So I, too, have completely misunderstood this.



STEVE:  Right.  So, I mean, there's so many acronyms here.  So we're going to go through it very carefully.  And again, I promise our listeners, when they stagger away from this podcast, they'll know exactly what is going on and what has happened and be able to tell all their friends, wait a minute, here's what you have to do, and this is what this means.  And except for, as far as I know, Security Now!, everything else that's been written so far just doesn't, you know, people are doing the best job they can.  But this is complicated.  And acronyms and the usage of these technical terms correctly is really important.



So let's turn the clock back first and remember how WEP works and what's underlying it because that's the source of the breach that these guys have been able to create.  The way original WiFi encryption, WEP, worked - remember that stands for Wired Equivalent Privacy.  The idea was that the original designer said, well, we're not saying that this is the end of all possible problems.  But we're going to give you privacy that's the equivalent of what you would get with a wire.  It's wired equivalent.  And it turns out they were wrong about that.



The way it works is there's a very simple pseudorandom byte generator.  And we've talked about how XORing encryption works.  If you took a message composed of a stream of bytes, and you were to XOR that stream, we'll call that the plaintext, the normal, unencrypted text.  You XOR that with random noise.  What happens is, the way the XOR operation works is, bit by bit, if the bit is on in the noise, it inverts the bit in the data.  And if it's off in the noise, it does not.  So what that means is the noise selectively inverts the data bits to produce the cryptographic result.  And odd as that is, I mean, as simple as that is, if you really have noise, that is, random noise, that means you are randomly inverting the bits in the data.  And it turns out that there's nothing that can decrypt that.  Nothing.  I mean, as simple as that is, nothing can decrypt it.  So the only thing that can decrypt it is if you take the same noise again, exactly the same noise, and do the same thing to it.  You XOR it, which is that operation.  It's what the operation is called, an exclusive or.



And if you think about it, if you have the same noise, and you invert the same bits again, then the bits that you inverted have been inverted twice.  They were inverted to encrypt it and then inverted to decrypt it.  And the bits that weren't inverted just kind of went right through.  So if you invert a bit twice, you get the same bit out that you started with.  If you have a zero, you invert it to a one, and then again back to a zero.  If you start with a one, and you invert it to a zero, and then again back to a one, it comes out the same way.  So you can see that this XOR operation is trivial.  And two of them essentially remove themselves.  Two is the same as none because it's that simple, conditional bit inversion.  So the beauty of that is it is incredibly simple to do this in simple hardware.  And the original WiFi specification really wanted to be able to implement WiFi with minimal hardware, or minimal firmware or software.  So they came up with a simple source of random stuff.



Now, we switch from the notion of actual noise, actual random stuff, to pseudorandom data.  The pseudorandom data means you've got some algorithm of some sort which is complicated enough that it emits data bytes that appear random.  That is, analysis of them does not give you an obvious pattern, so that somebody can look at data bytes coming out of this algorithm, and to them they look random.  Now, the algorithm in use is something called "RC4," which was developed by RSA a long time ago and kept as a proprietary algorithm.  Technically, they never formally released it.  It was always a trade secret.  But it leaked out in the world, and everyone knows what it is.  It's a really good algorithm, but it's got some problems, which is it involves a 256-byte array, which is sort of mixed up and scrambled based on the key you give it.  It turns out that there are weak keys that don't do a good job of starting off with this array being scrambled.  And also that, since this array is scrambled as it works, some of the initial data that it produces, the so-called "pseudorandom data," isn't as random in the beginning as it ends up being later on.



So all of these things created some weaknesses in the original implementation of WEP.  But the idea is pretty simple.  You have a key.  And you use the key to produce a stream of pseudorandom data using this RC4 algorithm.  You XOR your so-called "plaintext," the normal packet data, with the output from the pseudorandom generator.  And it's going to flip the bits.  It's going to randomly, pseudorandomly, invert the bits in the source data to create something that's encrypted.  And again, as long as no one knows what the output from the pseudorandom number generator was, what you get out is also pseudorandom.  There's nothing that you can do to figure out what the original data was except reinvert the bits with another copy of that same pseudorandom data. 



So that's how original encryption worked, is both endpoints would have a so-called "preshared key."  They would both know what the key was, so they would know how to generate the pseudorandom data.  The one sending would generate a stream, a so-called "key stream," which is the stream that's generated by the key.  It would take the key stream, use the XOR operation to invert the bits in the plaintext, the unencrypted packet, stick it out in the air.  The other end would receive it from the air; and, if it had the same preshared key, it was able, by using that, to regenerate the same pseudorandom sequence, the same key stream, XOR what came out of the air, the encrypted data, with the key stream, which is the process of reinverting the bits that the transmitter had initially inverted.  And in doing so, as you can imagine, as you can see, it gets back the original, unencrypted data.  So that's how WEP worked.



Now, there were some complications that we don't need to go into.  We have described them in detail in earlier podcasts, if anyone's interested.  For example...



LEO:  I encourage people to listen to that podcast because that alone is enough for a whole show.



STEVE:  Yeah, and it was.  For example, one of the weaknesses - there are a number of weaknesses with something as simple as XORing because, if you knew some of the plaintext data, that is, if you knew some of the data that had been encrypted, for example, if you knew the IP address, the source or destination IP address that would be in the packet, well, if you XOR the encrypted data with the unencrypted data, what that gives you is the key, that is, the key stream.  That gives you the pseudorandom data that was used to invert the bits to create the encrypted data.  You can work it out on a napkin, if you're curious.  It's sort of cool.  And it means that there's, like, there's three things.  There's the unencrypted data, the key stream, and the encrypted data.  And XORing any two of those gives you the third.  So if you know the cipher text and you know the plaintext, you can get the key stream.  And it turns out that that's something we're going to come back to because that's part of what this hack involves.  So the point is that you never want to encrypt different packets with the same key stream because it's very possible then to find correlations between the packets and start the process of decrypting.



So one of the things - there are many other additional complexities to WEP that, again, I don't - I'm not going to go into here because they're not really germane to this.  But, for example, there's a 24-bit counter on the front of the packet which is used as part of the key in order to prevent successive packets from ever having the same key stream.  And so when the receiver gets it, it looks at that and is able to figure out exactly what the key was that was used so that you're not actually reusing the same key, the same key on the same packets, because you don't want to do that.  So in order to verify that there was no transmission error, at the end of this packet four bytes are added.  And it's just a standard CRC32, a 32-bit, that is to say, four-byte CRC, a Cyclic Redundancy Check, which is a well-known algorithm that was added to catch any transmission errors, literally bursts of static in the air that would cause the receiver not to receive what the transmitter sent.  So after the packet is decrypted, then the packet is scanned, and the proper CRC is computed.  And that's called the ICV, the Integrity Check Value.  And that was part of the original WEP also.  And it was often implemented in hardware because a CRC is easy to do in hardware, as was this RC2 pseudorandom number generator.



Okay.  So as a consequence of the relative simplicity of the system, all kinds of problems were found.  One of the problems that was found, and we talked about it, there are some clever ways that it's possible, essentially, to determine what the original key is, that preshared key.  And if you do that, then you know what the same - you have the same key that everybody on the network has, and you're able to then receive any encrypted traffic and decrypt it, and generate your own spoofed or false traffic, encrypt it, and send it out into the air, and everyone will believe it because, when they receive the packets and decrypt using their key, the packets are going to be valid.



There's a different kind of attack which a clever hacker whose name no one knows came up with.  He uses the handle KoreK, or maybe it's Kore K.  It's K-o-r-e, and then capital K again.  He came up with a really interesting attack called "chopchop."  It's named that because he realized you could chop a byte off the end - and we're still talking about WEP now.  We're talking about the original Wired Equivalent Privacy because, as we're going to see, some of these problems unfortunately ended up surviving as we moved into the world of WPA and more complex protocols that were designed to prevent these simple attacks.  So this KoreK guy, he realized that, if you chopped the last byte off the packet, it would almost certainly now be invalid, that is, the ICV, the Integrity Check Value, was now no longer going to work correctly because you had chopped off the end of it.  But he worked out exactly what the relationship was between the first three bytes of the Integrity Check Value and the last one that you had chopped off; and the fact that, if you sent that back out onto the network, now the system would think that the last byte of data was the first byte of that ICV, the Integrity Check Value.  Remember, because the ICV is always the last four bytes of the packet.



So this guy worked out a way of getting the access point to tell him what that last byte was that he'd chopped off.  Because the access point will complain, will send back a message saying, wait a minute, you've got a checksum error.  And so the idea was that, since a byte can have any 256 values, from 0 to 255, that you could simply guess, make guesses about the value of that last byte.  And in an average of 128, that is, in an average of half the guesses, you would end up having the access point confirm that you now knew what the byte was because you had corrected the checksum.



LEO:  So you're allowed to keep trying until you get the checksum right?



STEVE:  In WEP you are.



LEO:  That's a flaw, obviously.



STEVE:  That's a big flaw in WEP.  And they fixed it.  But not quite.  And that's part of what is so clever about what Erik and Martin figured out in WEP - I'm sorry, in WPA.  In TKIP.  So in WEP you could flood the access point with these invalid packets, and it would just dutifully tell you if you had guessed right or not.  And so very quickly you had figured out what that byte was.  Then you chopped the next one off, and you figured out what that one was.  Then you chopped the next one off, and you figured out what that one was.  Now, remember that that checksum testing is done on the unencrypted data.  That is, the way this works is the packet is received.  Decryption is applied.  Then you have the so-called plaintext, the decrypted text.  And it is processed to see if the checksum matches.  So the checksum isn't...



LEO:  [Indiscernible] another flaw.  Couldn't they do the checksum on the encrypted text?



STEVE:  Well, perhaps.  Who knows, I mean, I haven't thought that through, what that would mean.  Although you would probably...



LEO:  It would eliminate this hack.



STEVE:  Well, it would change the hack.  See, the problem is that this integrity check value is too simple.  It's just four bytes, and everyone knows what the algorithm is.  It's not even keyed.  There's no unknown data for it.  It's just a standard algorithm to check - and, see, that's the problem, is it was meant to check for transmission errors, not meant to check for the data being spoofed, not meant to check to see if the data were changed.  It wasn't a so-called - I'm blanking on the name now.  It wasn't meant to authenticate the packet, merely to check for changes.  So anyone could make changes, and then change the ICV to make the CRC again valid.  That's trivial to do.  But the problem is, it's encrypted.



But here's the cool thing, is that by guessing the byte which is unknown but encrypted, once the access point tells you you've got it right, well, you know what the byte originally was because, remember, that's the byte you chopped off.  So if you XOR your guess, which is the decrypted guess, with the byte that you had, what you get is the key stream byte, that is, this is a way, by using chopchop, you are not only figuring out what the plaintext decrypted value is, but by comparing that to the encrypted value you get out what the key stream is.



So what this means is that this KoreK guy figured out a way of taking any packet that is received under WEP and successively chopping off the last bytes, walking this packet down in size, and he's going to end up getting the - decrypting the packet, determining what the plaintext was.  And here's the cool thing.  He gets the key stream.  That is, he gets the exact pseudorandom sequence which was used to originally encrypt the packet.  What that means is he can make up his own packet, encrypt it himself with the same key stream, and inject it into the network.  He doesn't know what the actual preshared key is.  He was just able to figure out one instance of the pseudorandom data that had been used for that one particular packet to encrypt it.  But that's all he needs because he's able to take that and make his own valid packets.



Now, what that means is there's no replay protection in WEP.  There's nothing to prevent you from basically making an altered packet where the sum of the packet is the same, for example, sum of the header information may be the same.  But you're able to change the data, create a correct CRC32 for it, that ICV, the Integrity Check Value, and stick it back out onto the network.  And everybody's happy.  They receive it.  They decrypt it using their preshared key, which they know.  You still don't know what that is.  You don't need to because you've got a sample of the key stream which was valid for that particular packet number.  Remember there's that 24 bits at the front that says this is the particular key stream for the following packet.  You use that, and you're able to just spoof packets and synthesize them.



So, okay.  So all kinds of problems are surfacing with WEP.  And the IEEE decides, okay, we've got to come up with a solution for this.  So they start working on a spec called 802.11i, which is going to be the security portion of the 802.11 overall specification for wireless security.  But when you look at the number of people on this 802.11 committee, I mean, this thing goes - it goes on for pages.  And it's the reason that this thing took forever to do.  It's a huge committee.  Nobody could agree on anything.  And so the whole industry is sitting around waiting for the 802.11i specification, and finally gave up waiting.  They said, you know, we can't wait any longer.  We need a solution for this.  So we're going to come out with something called WPA, which is going to be a certification for some of what you guys have agreed on so far, basically based on a preliminary incomplete version of the 802.11i specification.  You've figured out this TKIP.  You're talking about maybe using AES for stronger encryption, but you haven't figured out exactly how to want to do that yet.  Well, TKIP is a whole lot better than WEP, which is so badly broken now, so we've got to get on with this.  We're going to just go with TKIP.  So what happened was a bunch of manufacturers didn't wait for the 802.11i specification to get finished.  So they came out with the TKIP portion of a next-generation wireless.



LEO:  Interesting.



STEVE:  And they said, well, you know, it looks like AES, which uses the really well-regarded Rijndael cipher, that's going to be part of it.  And here's maybe how it's going to work.  So we're going to toss that in.  So...



LEO:  I can see the problem already.



STEVE:  Oh.  Well, it turns out that things did change in the AES side of the 802.11i spec, between the time the manufacturers launched out of the starting gate prematurely and the time it was finalized.  So that initial hardware that said it was WPA certified, and oh by the way we've added AES because it's that good, that turns out it won't work necessarily.  There's several things different about that than the final specification, which is what WPA2 certifies.



So to clarify that a little bit, or say it differently, WPA is not encryption.  It's not a protocol.  It's not a cipher.  It's nothing but a certification from the Wi-Fi Alliance.  And WPA certification means that your system can run TKIP properly, in full conformance to the 802.11i IEEE formal final specification.  Because that didn't change from the time all the manufacturers went out of the starting gate prematurely.  So WPA just says it will interoperate, equipment that is WPA certified will interoperate with TKIP protocol security.



Now, again, many of the hardware devices, access points, for example, at the time also threw in AES.  And you may have seen, some of them say AES-64, AES-128, AES-256.  Well, there is no AES-256 in the final spec.  So any hardware that had that is completely non-interoperable with the WPA2 certification that was finally arrived at.  So that's an example of where manufacturers sort of got a little bit ahead of themselves.  But the TKIP portion was solid and has remained so in terms of its specification.



Okay.  So in terms of terminology, WPA says you've got TKIP.  What is TKIP?  That's an acronym for Temporal Key Integrity Protocol.  The guys at the IEEE, this massive committee with an unbelievable number of people, they said, okay, we know we need to fix all these problems with WEP.  Let's do so.  So they did a number of things.  They added a replay capability, that is, an anti-replay awareness to prevent any kind of replay attack, so that you couldn't take a packet and either send the same one in later and just replay an identical packet - it turns out there are even attacks where you don't have to know anything about the packet, but just sending the same packet later can cause problems.  Literally, you decrypt nothing, you figure out nothing, you just inject it later, and it messes things up.  So they said, okay, we want to prevent that from happening.  We also need to fix this really weak CRC that's hanging on the end of these packets because that's dumb.  It's only useful for checking for mistakes.  It's not useful at all for checking for malicious packet contents modification.



So they came up with a new double-size, this thing's eight bytes, thing called an MIC, which stands for Message Integrity Code.  And actually it's known as Michael, just M-i-c-h-a-e-l.  So it's the Message Integrity Code.  Now, they put the Message Integrity Code first, and then the ICV, the Integrity Check Value, at the end, again because their goal was to make TKIP upward compatible with existing hardware.  This actually is the flaw.  The fundamental flaw in all this is that they tried to wrap improvements around a really fundamentally insecure approach for WiFi, which was WEP.  But they did it with the best of intentions.  They gave us all years of pretty, I mean, much better security than WEP for all of us who have routers that are using WPA and TKIP protocol, the TKIP security protocol on WPA-certified equipment.  So they made it much better.



Okay. So the problem is they're still using TKIP.  The Temporal Key Integrity Protocol still uses RC4, that is, it still uses that pseudorandom sequence generator approach. And it still uses this XORing of the pseudorandom data with the plaintext approach.  This was, again, done deliberately to create something where you could just upgrade the firmware.  But, for example, in much of the WiFi hardware RC4, that pseudorandom sequence generator, was built into the hardware.  And that CRC32 was built into the hardware.  No matter what you gave the hardware, it would tack on a CRC32, this ICV, the Integrity Check Value, automatically.  You couldn't make it not do that.  So they said, okay, that means we need to put a better integrity code at the end of the packet, which the hardware will then stamp its CRC32 onto the end of.  And so they designed this very cleverly to be able to be retrofit into existing systems that only understood WEP.  And they succeeded.  And it's been good for a number of years.



Meanwhile, the 802.11i committee kept cranking away, and they settled on all the details of using an entirely next-generation approach, AES, the so-called "Rijndael cipher," which is extremely robust and good.  And they didn't have to worry about the past at all.  They dealt with the past using TKIP.  And they said, so we're going to have two different security suites in WPA2.  You did not have to have any AES in order to get WPA, the first WPA certification.  That is, the Wi-Fi Alliance said we don't really know how that AES thing is going to work out because the 802.11 committee is not done yet.  So WPA only had to have TKIP.  WPA2 has both.  And so it's not the case, for example, that WPA2 no longer has TKIP.  It has both.  It's got the final version of the AES approach.  And I'm saying AES.  AES is the same as RC4 over in TKIP.  The protocol that uses AES is something called CCMP, that's an acronym, because the way the AES cipher is used is in a way called counter mode cipher block chaining.  So CCMP is the protocol that uses AES in the same way that TKIP is the protocol that uses the RC4 cipher.  So very likely in today's access points, anything that you've purchased recently that is WPA2 certified, that's the Wi-Fi Alliance saying we've tested this equipment using both TKIP and AES, or I should say CCMP, although unfortunately the user interfaces of these all say typically TKIP or AES, even though one is a protocol and one is a cipher.  To be really accurate they should say RC4 or AES, or they should say TKIP or CCMP.  But they don't.  Now you understand exactly what these acronyms mean.



So we've got ongoing research, then, by these guys, Erik and Martin and KoreK, into various ways of screwing around with TKIP.  The question is, we know it was based on old technology, deliberately keeping some of the requirements of the old hardware so that we could fix WEP without obsoleting all of our investment in hardware, so that just driver software or firmware could be changed.  But if the hardware was going to stamp every packet with an ICV, an Integrity Check Value, we had to allow it to still do that.  And if the hardware insisted on generating, you know, using RC4 to generate pseudorandom data and just XORing it with the data, we have to somehow make that work.  So they were able to change sort of the interior of the packet and leave the exterior envelope the same.



One of the things they did was they added, as I mentioned, this double-size, this eight-byte MIC, this MIC, the Message Integrity Code, to the end.  Now, this was a much more powerful solution than CRC.  It uses a key.  So it's a keyed authentication chunk.  And unless you know what the key is, you are unable to synthesize the proper eight bytes to authenticate the payload of the packet that precedes it.  And so they were able to sort of change the interior of the packet in order to keep everything else the same.



Well, these clever hackers figured out how to use a chopchop-like approach on TKIP.  And here's the way that works.  So now we have a WPA or WPA2, remember, those are just certification levels.  Those are, as I say, nothing about which security protocol you're using.  So either WPA or WPA2, both of those will have TKIP.  And many people have been using that because of its backward compatibility and because it's been felt to be good enough.  There weren't any known problems with it until now.



So we've got that scenario.  And so we capture one small packet out of the air.  The length of the packet turns out to be important because it's necessary to know what most of the packet is.  It turns out there are many limitations in the nature of this reverse engineering hack that these guys came up with.  But you can do some damage to a network even with small packets.  For example, ARP, the Address Resolution Protocol, that's the protocol which matches up the physical adapter addresses, the so-called MAC address, to the logical Internet Protocol address, the IP address.  So ARP is the glue where you're able to send an ARP packet out onto an Ethernet network and say who has this IP.  And all Ethernet adapters listen for these ARP broadcasts, and they check to see if the question is for them.  Oh, I have that IP.  In which case they send an ARP reply back to the MAC address that issued that ARP broadcast.



So these are very small packets with very well understood format.  And on a given network, not that many bytes are unknown in such a small packet.  So this attack on TKIP begins by somebody grabbing just one of these small packets off the air.  And you can pretty much know, you know exactly how long it's going to be because you're going to have the ARP data with well-known ARP headers and ARP contents, followed by the eight-byte MIC and the four-byte ICV, which is the format of these packets in the air when they've been encrypted.



Well, it turns out that, if you do the - you start doing the chopchop guessing.  You chop the last byte off the packet, and you send it back out into the air, back, for example, at the access point.  If the checksum that you guess - remember they still have an ICV on the end.  If the checksum is wrong, a TKIP - a newer, modern, strengthened, better protocol system - if the checksum is wrong, it ignores it.  It just says, bad checksum, I'm dropping it.



LEO:  And you don't get another chance.



STEVE:  No.  It simply drops it because it figures, okay, that was a transmission error.  It figures it's a transmission error, so it doesn't punish you for that.  So with an average of 128 guesses, just like before under WEP, but now we're under TKIP, using the same kind of approach, when you get it right, when you do end up creating a shorter packet with the CRC, that is the ICV at the end that matches, now the problem is the MIC, the Message Integrity Code, will be wrong.  And now that, when that's in violation, if you get a checksum that's correct, but the MIC, the Message Integrity Code, is wrong, now you've pissed off the access point or the client you're sending this to. Anybody who's receiving it is like, whoa, wait a minute, this is a valid packet, but the MIC is wrong.  Something's fishy somewhere.



Well, they didn't want to just shut down the whole network.  So they said, okay, here's what we'll do.  As long as we don't get two MIC failures within a 60-second window, as long as they don't occur more often than once per minute, we'll decide that's okay.  Whoops.  Because look what happens.  You can guess as much as you want and be wrong.  But as soon as you guess correctly, you have to wait a minute.  But that's not so bad because you just guessed correctly.  In knowing that you have to wait a minute - because what happens is a message is sent out that says "MIC failure," so the whole network knows there was one, to sort of like put everybody on notice.  But you've just been put on notice that you guessed correctly.  So you've got one byte.  So you wait a minute, and you start guessing the second from the last byte until you get it.  Now, that allows you to march the packet down in size 12 bytes.  And that'll take a little over 12 minutes.  When you've done that, you've just determined the plaintext for the MIC and for the ICV.  Remember, those were the last 12 bytes on a TKIP-encrypted packet.



Okay, so now you know what the plaintext for the MIC is, the Message Integrity Code, and what the plaintext for the ICV is.  Now you can guess the other few things that may be unknown, like the IP addresses of the sender and receiver, by plugging them in and checking to see whether the ICV matches.  You didn't know what they were.  They're up at the front of the packet.  But now that you know what the ICV is, you can perform - and the ICV is a simple CRC32 - you can plug in, quickly plug in guesses until you get a match.  That allows you to determine what the IP, the source and destination IP was.



Okay.  Now you know all of the packet up to the MIC, to where the original, full-length Message Integrity Code was.  Well, turns out that the Message Integrity Code was never designed not to be reversible.  That is, it's not like a hash, where you cannot reverse it.  It's an algorithm that is as easy to run backwards as it is to run forwards.  Knowing what...



LEO:  Like an XOR.



STEVE:  Sort of.  It's fancier than that.  But it is reversible.  So now, knowing all the data ahead of it, which would be the input to its algorithm, and knowing the result, you can reverse engineer the key, the so-called "MIC key."  So now you have the MIC key which was used - which is unique for, not per packet, it turns out, but it's unique for a keying session.  So that allows you - you've got the MIC key.  You know all of the plaintext of the packet.  And as a consequence of knowing all the plaintext, remember that, since we also captured the original cipher text, the encrypted text, you just XOR those, too.  Now you've got the key stream.  That is, you've got a sample of the TKIP key stream that you were never supposed to be able to get.  And because you've got the key for the MIC, the Message Integrity Code at the end, you can now make up any kind of packet you want, ahead of the MIC, and recreate a proper MIC, which will then pass muster.



Now the final problem, and this is the last bit of just stunning genius from these guys...



LEO:  Yeah, because you still don't know how to decrypt all the traffic.



STEVE:  Oh, you never do.  Yes, this does not give you that.  What you've got is the ability to make up, to modify...



LEO:  To inject stuff.



STEVE:  Yes.  Well, and it turns out not much, because they did add in TKIP, they added a block against replay.  There's replay attack prevention.  There is a counter that they added to the packet.  And every time a packet is received, that counter is incremented.  And so there's going to be continuing packet traffic, and that counter is going to keep incrementing.  So if here you come along and say, hey, here's a packet, and you try to reinject this into the network, it's going to say, sorry, we've already been there.  We've done that.  That's an old packet.  Don't know where you came up with it, but we're not interested.



Okay.  Get this.  These guys realized that in a system that has Quality of Service support - 802.11e is the Quality of Service support - that that represented a breach in replay attack prevention.  Okay.  What Quality of Service is, is it says, okay, on Ethernet networks there may be times when some traffic needs a higher quality of service.  For example, VoIP, Voice over IP, like you and I are using now with Skype, Leo, it's not that it needs, like, to dominate all the bandwidth.  It's that it's delay, it's delay sensitive.  You know, Voice over IP, we need to know that those packets are streaming out, and they're not going to be buffered up in some queue, waiting for bandwidth.  They're going to have priority.  So it's a priority system.



But in order to do that, you do have to have queues.  You have to have buffers where other packets can be held while the express train packet, the VoIP, the higher priority packet, is able to pass by and get through.  So in most modern access points which support Quality of Service as one of their bullet points, oh, look, you want to buy ours because we've got QoS on ours, what they've got is up to and typically eight buffers.  Most traffic just runs on channel zero, and channels one through seven are not used.  Well, that means their replay counters are not incrementing.  And when you send one of your made-up new packets to a different QoS channel, it will be accepted rather than rejected because...



LEO:  Wow.  You get eight chances.



STEVE:  Yes.  And so, exactly, you could do the decryption once, and you can't use the channel that it came from.  But you can use the seven others.  So you can then - you decrypt the packet once, and that takes - it's going to take 12 minutes for you to get those last 12 bytes, one at a time, because you remember you're punished by having to wait a minute.  And if you don't wait a minute, that sets off alarms in the whole network that causes the access point to shut down for 60 seconds and then rekey everybody.  So you've lost all your work unless you make sure that you wait at least 60 seconds between succeeding with one of your guesses because the succeeding with the guess means that the message integrity value which is inside the packet will fail.  And that sets off the alarm.  But that's okay because it just confirmed that you guessed the last byte correctly because you got the checksum correct.



LEO:  Right.



STEVE:  So what this means is, with TKIP on a network, that after 12 minutes it is possible to take a small packet - and the reason it has to be small is they have to know everything about the packet.  That is, the MAC addresses are not encrypted.  They exist at the front of the packet before the encryption begins because you have to have the MAC address in order for it to come or go.  A packet like an ARP packet has very little data that's unknown.  A long packet, you don't know what's in there.  And so there's no way for you to, well, I guess you could continue marching down the packet one by one, pissing off - for every single byte having to wait a minute.  But for a typical full-sized packet, which is 1,500 bytes, that would be 1,500 minutes.



And the problem is, these things do rekey, typically every hour.  Every 3,600 seconds an access point will rekey just as part of its security.  So that's 60 minutes.  So you don't have 1,500 minutes in order to be able to sit there and march down, being punished for minute every time you guess a byte correctly.  So that limits you to the length of packets that you can apply this attack to effectively.



When you finally figure out what the MIC key is, and what the key stream is, that allows you to synthesize a packet up to the length that you caught and inject it up to seven times, given that that system has Quality of Service available, in which case it will not reject the packet as being a replay.  Now, once you've done that, that is, you've injected that packet seven times, you can capture another one.  And this time it only takes you between four and five minutes because you only need to get - now, if you capture another packet, it's going to have a different key stream, but it's going to have the same MIC key.  So all you need is to get the last four bytes of the Integrity Check Value, and that only takes four to five minutes.  You don't have to go the 12 to 13 minutes to get all of the last 12 bytes.  You only need the last four.  So that's the nature of what these guys have done.  It means that...



LEO:  I guess one of the takeaways I have is that, first of all, it has to be a router with QoS.



STEVE:  Yes.  And if you...



LEO:  Has to be enabled.



STEVE:  Yeah, exactly.



LEO:  And they don't really - they don't crack your content.  They can inject stuff into it.



STEVE:  Yes.  Well, they do crack your content, but not probably any very valuable content.  They can crack some of the management of your network, your network management.  Now...



LEO:  But they can't sit there and watch what you're doing online.



STEVE:  Correct.  Correct.  They never get your key.  They're never able to get all your traffic.



LEO:  So what are they able to do?  I mean, what good is this?



STEVE:  Well, and that's one of the reasons why, you know, people saying, oh my god, WPA WiFi security is cracked, head for the hills.  I mean, it's like, okay.  I mean, this is a - now, admittedly, this is the way these things begin.  So this is like the first chink in the armor.  This is a wedge into something that we thought was completely secure.  Not so much.



LEO:  But is there reason to think that you could go to the next step?  It's still a pretty big step to go to the next step to decrypting every packet.  Since they aren't getting the key.



STEVE:  It is a huge big step.  I mean, yes.  No one knows how to do that.  They're not getting the key.  They're getting one key stream, and they're able to generate a few packets from it.  Now, there were a few interesting things.  Because, first of all, they're also only able to intercept from the access point towards a client, grab one of those packets.  So they're only able to access in one direction because of their need to use this MIC failure frame in order to determine whether they guessed right or not.  So you have to have quality...



LEO:  It really sounds like a surprisingly limited hack.



STEVE:  It really is, Leo.  I mean, it is uncomfortable, but it's very limited.  I mean, and, okay, so maybe, maybe you could send a spoofed ARP, do like an ARP spoof and cause a client to send its traffic to a different IP.  For example, and we've discussed this in the dark ages of Security Now!, if you sent - if you have an encrypted client, and you get it to send its traffic to a different IP, then the access point decrypts it, and then it goes out onto the Internet in the clear, bound for the wrong place.  Except that ARP spoofing doesn't really let you do that.  ARP spoofing would allow you to send it to the wrong MAC address.  So if you went to the wrong MAC address, if the client didn't know how to decrypt it, and it wouldn't, then that doesn't help you, either.



So these guys haven't told us anything that you can do bad with this.  They've sort of said, well, you could decrypt ARP packets, or maybe DNS, like small packets.  They're locked into small packets, and they're very much locked into what you could actually do.  We're going to have to wait a while, probably, to see if anyone comes up with something clever that you could actually do with this.  There may not be anything that you can actually usefully do with this.  I mean, this...



LEO:  You know, they're giving this presentation today or tomorrow.



STEVE:  Yeah, tomorrow afternoon, that's Thursday.



LEO:  Might they reveal more?  Or is this the full story?



STEVE:  This is it.  They've published the paper, which discusses this, basically.  There is code now in Aircrack.  Martin Beck is an Aircrack contributor, so there is code in the existing Linux build of Aircrack, which Martin put in for Erik because they were working on this together in order to sort of test some of this, to see if they could actually do it.  So they took it from theory to practice.  They were able to decrypt the one packet.  They were able to use Quality of Service channels to get that packet not rejected, but accepted.  But they haven't been able to do anything more.



LEO:  Which is not that surprising.  I mean, they haven't - what is surprising is how it was treated as...



STEVE:  As the end of WPA. 



LEO:  Yeah.



STEVE:  As the end of WiFi encryption.  I know.



LEO:  I mean, I have to say now, knowing this, I'm not that afraid of somebody sitting out on my porch trying to crack my TKIP.  I mean, they aren't really cracking it.



STEVE:  No.  They're not cracking it.



LEO:  [Indiscernible].



STEVE:  Well, and that's per session, and that changes every hour.  So even if they get the MIC, they still don't know the key.  And all the MIC does is allow them to do succeeding packets in four to five minutes, rather than 12 to 13 minutes.



LEO:  Can they mess with me?  I mean, could they, like, send a fake - I'm trying to think of a heinous application for this.  Can they send a fake packet that - I don't know.  They don't know the key, so they can't encrypt a packet, so they can't really - they can do ARP spoofing because they can spoof the IP address.  But they can't spoof a packet.



STEVE:  Correct.



LEO:  So they really don't - they ain't got much.



STEVE:  They really don't have much.  And if there's one thing worth mentioning is that new access points will be offering - anything that is WPA certified, I'm sorry, WPA2 certified, will, in order to get that certification, have to be able to both do TKIP, and we'll call it AES, although it's really CCMP, either of those protocols, CCMP being the really secure one, modern, with no compromises to the past, that uses the 128-bit AES Rijndael cipher.



LEO:  But before we get into what people can do to mitigate this admittedly not so horrible hack, let's take a break.  But we're going to come back, and you're going to explain what settings you should set on your router, what you should do in response.



STEVE:  Yes.  There are things, there are some things that are still dangerous, and some things people can do.



[Commercial break]



LEO:  All right.  Let's get back to this because now any time you see a headline that says "WPA Hacked," the first thing I want to do is go out and tell my listeners, well, what do you do to fix it.  Now, you've actually, if anybody who's really understood what you're talking about, you've actually - well, I mean, look, I'm not going to talk about this on my radio show.  It's way too complicated.  But you've actually mitigated it somewhat by showing what's possible.  It's not a lot.



STEVE:  No.  It's not a lot.  We'll see what clever people are able to come up with.  But at this point it's sort of a technical hack.  So here's the issue.  Anybody with updated firmware, who's bought a WPA2 router, maybe a WPA-certified access point in the last few years, they'll probably have both TKIP and, for the sake of agreeing with the UI on the router, I'll say AES.



LEO:  Yeah.  It always says AES.  But it's CCMP is really the encryption?



STEVE:  Yes.  Exactly.  CCMP is the protocol the way TKIP is a protocol.



LEO:  Yeah, all right.



STEVE:  So the problem is, if you enable both on the access point, TKIP is still present.



LEO:  Got it.



STEVE:  And it's still in the air because the broadcasts that are sent out to, for example, ARP broadcasts, they  need to be sent out to the lowest common denominator so that the access point knows that everybody will be able to receive it. So the only way, if you are able to disable TKIP, the only way to know that it's not in the air is to remove it from your access point.  Do not include its support in your access point along with AES, CCMP encryption.



LEO:  So uncheck it or...



STEVE:  Yeah, exactly.  Often you'll have, like, radio boxes where it'll say TKIP, AES, or TKIP plus AES, for example.



LEO:  Ah, okay.



STEVE:  And so you do not want to use that.  You don't want TKIP anywhere near your system.  Now, okay.  We've all said, okay, this doesn't look like it's such a big deal.  The point is, fine, but why use it at all if you don't need it.



LEO:  Right.



STEVE:  Now, we know that there are poor people - you know, sad people - who are even...



LEO:  Unfortunates.



STEVE:  Unfortunate, that's the word I was looking for, unfortunate people who are still having to use WEP in some cases because they've got some refrigerator or TiVo or something, some device that is mission-critical to them...



LEO:  I was so miffed, I bought this Rovio robot that's supposed to go around and take pictures.  It uses WEP.  It's like, what are you thinking?



STEVE:  As long as you don't mind someone else commandeering it and driving it out of the house and down the street to them.



LEO:  Yeah, right, no big deal.



STEVE:  Yeah.  So...



LEO:  So there are some unfortunates that have to use devices like that, or Nintendo DS is another very [indiscernible] example of that.



STEVE:  It may turn out that there are similar situations where you've got something that is only TKIP.  You might, for example, have some equipment which was only WPA certified and did not include the gratuitous AES, or included a non-final compatible version of AES, so that if you switch your access point to your WPA2 access point, that really supports real AES, if you disable TKIP, you may not be able to connect.  I would say, because there's still some unknowns about this, if you don't need TKIP, disable it.  You just change your access point to turn it off.  You probably don't.  The majority of people who are using Macs and PCs and Linux machines, and anything in the last few years will support AES and TKIP, it's better just to say, okay, no more TKIP.  If you have to have it, you don't have to worry that much.  If you can, you have the option of turning off QoS, disable it because that will probably defeat this attack also, if you needed to keep TKIP.  And turning off QoS won't have any effect because most things don't use it anyway.



LEO:  We use - I use it for Skype.  I use it for Skype.  So...



STEVE:  Okay, you actually do?



LEO:  Yeah.  But I'm not using it - I'm using it on a wired router, so I don't care.



STEVE:  Okay, but how do you know - so is Skype smart about saying that I want to use a different QoS?



LEO:  Well, I don't think so.  What I do is I tell the router that stuff that's coming in on this port, turn on QoS.  Is that not enough?



STEVE:  Well, it might prioritize the port traffic.  But normally...



LEO:  Good point.  Doesn't help between you and me, the part we care about.



STEVE:  It's normally the case that the packets themselves have to be marked, they have to have an 802.11 QoS header that says I'm to be given higher priority.



LEO:  And then all the routers across the internet have to support it, which of course none do, probably.



STEVE:  Or at least it needs to get out of your point of congestion.  But you're right, once it gets out of the 'Net, lord only knows what's happening.



LEO:  Right.  Well, and I don't, you know, because one of the reasons we get such good Skype results is I have a dedicated Internet connection with nothing else on that connection, and nothing else on the router, so it's completely pointless.



STEVE:  Right.



LEO:  When I was upstairs, we had everything on one connection.  And maybe it made sense then.



STEVE:  Right.  So bottom line is...



LEO:  You can turn it off in most cases, in other words.



STEVE:  I think most people, 99.99 percent of the people will be able to turn it off.  When your friends come over, they'll have a computer from this century.  And so it'll probably work just fine on your router with AES.  And you do want to disable TKIP because, if it's on, it's out in the air, and you're still vulnerable.  But again, if in the worst case you need it for whatever reason, it's probably not such a big deal.  This is nothing like key recovery where they can now intercept your traffic and monitor what you're doing.  I mean, it's just - it's one small packet they're able to get and decrypt every four to five minutes.  And you're not sending small packets.  Your payload is 1,500 bytes.  That they'd never have time to decrypt because your system rekeys every hour.  They don't have 1,500 minutes.  They've got 60.



LEO:  So to summarize, the easiest thing is probably to turn off QoS.  None of this works unless QoS is - your router supports it, and it's enabled.



STEVE:  Because the modified packet would have the same counter value, and it would just be rejected as a replay.  And that replay protection absolutely does work.  It was them cleverly realizing that QoS allowed them a way around that that made all of this possible anyway.



LEO:  If for some reason you need or want QoS - and if your router doesn't support it, then you're home free anyway.



STEVE:  True.



LEO:  So your router has to support it.  If for some reason you want to continue to use it, the next - the other thing you could do, and there's no reason not to do this, either, is to - you have to go to WPA2 to use AES.  Is that correct?



STEVE:  No.



LEO:  No.



STEVE:  Remember, because WPA is not a place you go to.



LEO:  Understand.  Understand.



STEVE:  It's just a certification.



LEO:  Right.



STEVE:  So it is the case that...



LEO:  The router is either - if your router is WPA2 certified, then you're fine.



STEVE:  You definitely - then you know you have a final standard AES protocol, that is, the CCMP protocol.  A non-WPA2-certified router, that is, WPA, it may work.  You know, just try it.  Just switch to WPA and see if Windows and Mac and Linux still connect up to it.  Because they may have gotten it right.



LEO:  But so you turn off that TKIP, turn on AES.  You'll be using that safer CCMP or whatever it is encryption...



STEVE:  Protocol.



LEO:  ...protocol using the Rijndael encryption.  And you don't have - and then you're completely in the clear, too.



STEVE:  This whole thing is then of no concern to you.



LEO:  Is it, do you think, worth doing that anyway?  Is it a better - is AES preferable anyway?



STEVE:  I would say that the fact that this happened is making people nervous.  It's sort of the way we found some collisions with the smaller hash functions.  It's like, they're not broken, but we're a little uncomfortable now that we found some problems.



LEO:  So if you have a WPA2-certified router, or even if you don't, turn off TKIP, turn on AES, doesn't hurt.



STEVE:  Work just fine.



LEO:  And nowadays everything, I mean, yes, it's a longer key.  It requires more CPU power.  But everything's fast enough.  Is that CPU power, it's both in the router and in the connecting machine have to do it; right?



STEVE:  You know, one of the reasons that Rijndael was chosen as the AES standard is that it is very efficient computationally.  It is a computationally efficient cipher.  So it is - and it's a symmetric cipher, and we know that those are generally much faster than asymmetric ciphers.  So it was mostly to preserve hardware that - where the RC4 pseudorandom sequence generator and that ICV tack-on was just - it was built into the hardware.  There was nothing they could do to change that.  So they said, okay, we're going to change the interior of the packet so the hardware could still generate the same kind of random numbers, and it could still tack now not very useful four-byte CRC32 on the end.  And so it was mostly a - it was so that, you know, backward-compatible hardware could still be used in a secure fashion.



LEO:  Yeah.  Very good.  You know, I can understand why mainstream media might have gotten this wrong.  But to overstate the risk is really unacceptable.



STEVE:  It was, yeah, I mean, people were freaked out and panicked needlessly.  And I was sort of smiling to myself when you said you could understand why mainstream media got it wrong.  You can understand how hard it would have been for them to get it right.



LEO:  Yeah.  But...



STEVE:  It took this podcast to explain it.



LEO:  But I think that they should have not jumped to the conclusion they jumped to, if they didn't understand it.  In other words, if you don't get it, don't just assume that we've got a crack here.



STEVE:  I mean, yeah.  I mean, the headlines were saying, "WPA WiFi Is Cracked."  You know, your network is no longer safe.  It's like...



LEO:  Is that, do you think, because Erik Tews might have overstated it?



STEVE:  No.  I think it's because it is really complex.  I  mean, okay, Leo...



LEO:  And it's also a sensational story that you're going to get...



STEVE:  I have two WiFi routers here, one on my internal network, one on my cable modem.  I haven't changed either of them.



LEO:  You don't care.



STEVE:  Well, I mean, this is not a big problem.



LEO:  As Zephyr is saying in our chat, "WPA Almost Cracked" is not as big a headline.  It's not as...



STEVE:  As they say, you're not going to sell so many newspapers.



LEO:  No.  Doesn't really grab you.  Oh, it was close.



STEVE:  Or a "Partial Long-Duration Replay Attack," that's not going to sell anything either.



LEO:  No.  In fact, I don't think I'd click on that link.  All right.  Very good.  As usual, Steve Gibson, you are an asset and a boon to the community because you can figure this stuff out and explain it, I have to say, explain it in a way that makes perfect sense, doesn't require a Ph.D. to understand, and put us all, our minds at rest.  I still am going to turn on AES and turn off TKIP.  But what...



STEVE:  Yes.  And I should say, I should also say I haven't done so just because I haven't done so yet.  It's not - I don't see it as, like, a critical emergency.  I will, next time I'm visiting my wireless routers, I will switch over.



LEO:  Next time you log in, flip that switch.  Steve's at GRC.com.  That's the place to go for his fantastic software, SpinRite.  Just, what is it, 62K of Assembly language goodness.  It's just the program you want if you have a hard drive, and you need to maintain it and/or restore it.  I use it all the time, on every drive before we install them.  And I recommend you do the same.



STEVE:  You know, I ought to mention that while people are in their routers and reconfiguring them, if they don't know about GRC's Passwords page, that's a great place to get a password.  About 3,200 people use it every single day, day in, day out.  It's just GRC.com/passwords.  And an extremely high-quality, extremely random gibberish password is just presented for you, over a secure connection.  It never repeats.  I've got all kinds of code to make sure that the same thing is never issued to two people anywhere in the galaxy, so.



LEO:  And in fact that is a good point because WPA is a little vulnerable to brute-force attack, and that...



STEVE:  Oh, yes, the only known attack against WPA - well, okay, here we're using the wrong acronym - against the AES CCMP encryption, which is part of the WPA certification, is a brute force, where they guess what your key is and try using it against a packet which had been captured.  That's an offline attack.  It's still not a big problem, as long as you use a really hard-to-guess password.



LEO:  Well, yeah.  And these passwords at GRC.com/passwords are as random and as long as you can get.



STEVE:  Yup.



LEO:  The best passwords you can use.  The only issue is remembering them.  But you don't have to remember them.  You just save them somewhere.



STEVE:  You can't.  Yeah, you can't even type it into stupid Apple iPod Touch because they're just so long.



LEO:  Yeah, you have to cut and paste.  And if you can't cut and paste, then don't do it.  All right, Steve.  GRC.com is also the place to get the 16KB versions of this, for those of you who are bandwidth impaired.  Share them with your friends, they're tiny.  Also of course the transcripts from Elaine.  And this one is another one you might want to read along while Steve talks.  This should be a graduate-level course in security, frankly.  I mean, this is - you've got your textbook right there.  You can also find all these great programs like the Perfect Passwords, ShieldsUP! for testing your router, lots of great stuff.  GRC, Gibson Research Corporation.  Steve, we'll talk again next week.



STEVE:  Talk to you then, Leo.  Thanks.



LEO:  Bye bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#171

DATE:		November 20, 2008

TITLE:		Listener Feedback Q&A #54

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-171.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 171 for November 20, 2008:  Your Questions, Steve's Answers.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now! the show that tells you how to stay safe on the Internet.  And Mr. Gibson is here.  He's kind of like, you know, the crossing guard.  He's got his little crisscross orange shirt on, and his flag saying "Do not cross here.  It is now safe to cross."



STEVE GIBSON:  Proceed with caution.



LEO:  Proceed with caution.  That should be the name of the show, Proceed With Caution.



STEVE:  That would be a great name for the show, actually, yeah.



LEO:  Yeah.  Because there's nothing you can do.  I mean, except proceed with caution.



STEVE:  Yeah.  Basically that's what we're helping to explain to people is where the pitfalls are, where the potholes are, and how to behave themselves, so...



LEO:  Proceed with caution.  Well, we're going to do - we have - today is our Q&A day.  I know people kind of are a little confused because we originally were doing this on odd episodes, I mean even episodes.  And then we had an emergency to cover the DNS poisoning issue.



STEVE:  And we changed our parity.



LEO:  We changed our parity.



STEVE:  Went from even parity to odd parity.



LEO:  Typical engineer.



STEVE:  Something will happen.  We'll have another emergency, and we'll switch back over.



LEO:  Right.



STEVE:  So just to keep everybody off balance.



LEO:  So even though it's Episode 171, it is Listener Feedback #54.  We've got a dozen questions, including some really good PayPal tips and tricks.  Should be good.  And we're going to get to the latest security news and any addendum or errata from previous episodes.  Let's get the latest security news.



STEVE:  Well, a bunch of stuff has happened.  One follow-up on DNS.  I'm still very much up to my elbows in DNS stuff.  I hope, probably, I'm guessing three weeks from now - we've got the author of Sandboxie on next week, then a Q&A.  Probably the week after, I think by then I'll be ready to unveil the work I've been doing for, like, the last five months on the whole DNS spoofability stuff, to allow people just to check to make sure that the DNS servers they're using cannot be easily spoofed.  And in the process we discovered that we're able to crash a bunch of routers, which is a concern because, as we know, what starts off as a crash often can be evolved into a remote exploit.  So I've also got a router crash test that has evolved out of this, so people can see whether their router is crashable and bug their router manufacturers, if it is, to update the firmware, to fix whatever might be an as-yet unidentified buffer overrun in a router.  And of course that's a problem because if someone sent your router a packet that could take it over, that's a bad exploit.  



LEO:  Yeah, no kidding.



STEVE:  Anyway, all kinds of things have happened.  An outfit called the Measurement Factory received a commission to evaluate the status, the current, like to take a snapshot of the current status of the DNS servers on the Internet.  They grabbed the routing tables from some central routers and used that to determine how many IPs were actively being routed.  And it was a little shy of two billion, which is interesting, since as we know there's a total of 4.3, actually it's 4.29, billion IPs potentially possible, although some are permanently removed, like anything beginning with 10.  We know that the so-called "10-dot" IP range is reserved for private networks, so not publicly routable.



But this is something that Mark Thompson told me years ago that surprised me, is that here everyone's all worried about IP space depletion and running out of IPs.  But still only half of the 'Net actually has publicly routable IPs.  There are things like, well, for example, remember that Hamachi is using the 5-dot space because no one is using it.  It's not assigned to anything.  It's just, I mean, and that's a huge chunk of IP space that is still sitting there because typically they've been allocated to organizations that don't want to let them go because it's valuable, even though they're not using them yet.



So this outfit looked at the routing tables, found the 1.9 billion IPs that were routed, took a random, I think it was 10 percent sample of those, and sent out probes, DNS probes, just at random to find random DNS servers and check to see how they were performing.  They ended up determining, based on their sample, their statistical sample, they estimate that there are 11 - I'm sorry, yes, 11,900,000 name servers publicly accessible on the Internet.  So just shy of 12 million, 11.9 million name servers on the 'Net.  Of those, 4.3 were open resolvers, meaning that you could send them a query, and they would do the work of looking up an IP address for you and send you a response.  And of course those are what - that's the source of the vulnerability.  So 4.3 of those are open.  Of those, they found that 25 percent of the servers that were open resolvers, that would do open recursion, have not yet been patched.



LEO:  25 percent.



STEVE:  Yes, one out of four servers are still vulnerable, I mean, really vulnerable to this Kaminsky-style attack, meaning that when you ask them a query or you ask them a question, they launch the query out of a fixed port or an incrementing port, something which is easily predictable.  And that's all you need in order to be able to fake the answers that that name server is looking for and poison its cache such that anybody else using it will then be redirected to a malicious site.



LEO:  I'm going to say something surprising.  That's a lot.  I mean...



STEVE:  Yes, that's a lot.



LEO:  I mean the other way around.  I'm surprised 75 percent are patched.



STEVE:  Well, remember, a lot of news was made of this.  Now, what was really interesting was that, as part of this study, a survey was sent out.  And 45 percent of administrators responding to the survey said that they lack, quote, "lack the necessary resources to address the DNS vulnerability."  Whatever that means.



LEO:  We don't know.



STEVE:  I don't have time.  I'm busy doing other things.



LEO:  The guy who set it up doesn't work here anymore, and I have no idea how to fix it.



STEVE:  Exactly.  It's a black box in the corner.  It's got cobwebs on it.  We're afraid if we touch it, we'll break it, and then we'll never get it going again.  So we're just leaving it alone.  30 percent of the administrators responding said they do not know enough about DNS to make the required change.  Which is encouraging - not.  And then in their analysis they did fingerprinting.  That's one of the technologies I've added to my test also.  You'll be able to see what the make, model, and version of the DNS servers you're using are, among a whole bunch of other really cool things.  So they found that 90 percent of the DNS servers are now running BIND 9, which is the latest and greatest.  And they also, from a sample they'd made a year ago, they learned that there had been a significant decrease in Microsoft's DNS server, which frankly pleased everyone because it's not really very secure.  And they did find...



LEO:  That's the one you use; right?



STEVE:  No no no no.  I'm using BIND on FreeBSD UNIX.



LEO:  Oh, for some reason I thought you were using IIS on a Windows server.



STEVE:  Well, IIS for web serving, but not for DNS.



LEO:  Not for DNS, okay.



STEVE:  Yeah, for many reasons I need real DNS.



LEO:  What's the name of Microsoft's DNS program?



STEVE:  It's just DNS Service.  And when you install, for example, the server version of Windows 2000 or 2003, it's one of the options you can just install.  And, yeah.  I actually, I had it installed here for a while, just sort of I'm curious about it, to see how it worked.  And, you know, it's like I didn't see anything wrong with it.  But I wanted to go with real BIND.  And I'm running BIND 9 also.



And then the last thing that was of particular interest that they discovered was that there was a distressingly low adoption rate of DNSSEC, the DNS security extensions, which we've talked about, which really do solve these problems.  Oh, that's another thing that I will tell you when you use my soon-to-be-unveiled test, is whether your ISP's DNS servers are supporting DNS security.  So you have to sort of get a sense for where your ISP stands relative to others.  And also I have a DNS benchmark that will allow you to determine the speed of yours versus, for example, OpenDNS, so you could see whether your use of the Internet could be faster by switching to some other alternative DNS server.



LEO:  Oh, that's good, that's nice.



STEVE:  Cool stuff, yeah.  Many, as I was running through the Q&A for this - I'm sorry, as I was running through all of the user submissions of stuff at GRC.com/feedback, I ran across a whole bunch of people that were wanting to bring to my attention that Visa over in Europe, in the EU, has released a new card that contains a built-in keypad and eInk display that produces a one-time code for part of their, Visa's rollout of a next-generation security technology.



LEO:  Hallelujah.  That's like the VeriSign card.



STEVE:  It's, yeah, in fact it looks like very much - I would imagine it comes from the same manufacturer.



LEO:  But it's a Visa card?  It's an actual charge card?



STEVE:  It's got a mag strip on it.  And so you can hand it to, you know, the server in the restaurant who can scan it just like a regular credit card.  But it also has this challenge/response technology.



LEO:  Fantastic.



STEVE:  Yeah.  So it's not something that's universally available yet.  It does require substantial backend technology in order to support it, in order to do the challenge authentication handshake with the card.  But it's really a very comforting sign because it demonstrates that we're moving forward.  And the only reason you would do something like this is where you have a so-called "card not present" purchase, where you're doing an Internet purchase, and rather than having the physical card present, you're reading it out over the phone or over a web form.  And so this allows that kind of technology.  So I wanted to acknowledge all the people that wrote to tell me about it.  And we'll certainly be keeping our eye on that.



There was a bunch of security news for the week.  Apple has released a big update to Safari which fixed 11 vulnerabilities.  Unfortunately there have been many complaints of crashes afterwards.  So apparently there's some little bug of some sort, doesn't affect everybody, but there's been a high incidence of complaints of Safari crashing after this update was released.  It's 3.2, and it fixed, as I mentioned, 11 security flaws.  Most of them were for the Windows version of Safari, but a couple were for the Mac OS X version.



LEO:  And the reports of crashing, are they on both platforms?  Or are they on Windows mostly, or...



STEVE:  Oh, predominantly Windows.  I don't know of any over on the Mac OS X platform.



LEO:  Yeah, because I haven't seen any, haven't had any problems.  But I don't use Safari on Windows.



STEVE:  Also I got an update of my use of Firefox to 3.0.4.  I would imagine anybody using Firefox would have had the same thing saying, oh, we've got a new version of Firefox, you have to shut down and restart Firefox.  But I wanted to make sure everyone knew.  It was also a big update, fixed 11 security, I'm sorry, 12 security flaws.  Several were remote execution vulnerabilities.  So you'll want to make sure you get that fixed.  Half of them, six of them, were rated critical.  And those that weren't, that were not remote code execution, were technically local denial of service, meaning they would crash your machine, which is not good.



Chrome, Google's browser that's still in beta, expected to be in beta for a long time, has moved forward also.  There was a file-stealing hole that was found in Chrome which has been fixed.  The latest version apparently is a development release that may not yet be available to typical users.  And they're at 0.4.154.18.  That's the latest and greatest from Google.  And they've added some features.  There's now a bookmark manager in it, and they've reworked their popup blocker to be more effective.  So that continues to move forward.



In some dialogue I saw online there were some independent researchers saying, you know, this kind of stuff reminds us that a browser probably needs about a year of gestation before it's the kind of thing you want to jump on.  And until then you want to run it, like on an experimental box or in a secure virtual environment of some sort because there's just - it takes a while to nail all of the debris and bugs out of anything, you know, out of a big, aggressive chunk of code like this.



LEO:  Well, and the browser is such an exposed surface to hackers.  That's the most critical application; right?



STEVE:  Yes, it is now the target.  Speaking of which, I picked up a little interesting tidbit of news that I knew our listeners would appreciate.  NebuAd, the heinous install-their-equipment-in-ISPs'-facilities that we've talked about extensively, has been sued now by 12, or at least a dozen subscribers.  NebuAd and six ISPs that were using it but have since dropped it like a hot potato have been sued.  The suit asks for $5 million in damages and requests that it be moved to class action status.  So and they're alleging that the web surfing habit tracking technology and the companies that used it without customers' knowledge violated anti-wiretapping statutes.  And people who - legal experts who've looked at the suit believe that NebuAd is in bad trouble, that is, that it absolutely does violate anti-wiretapping statutes.



LEO:  It's an illegal application.



STEVE:  Yes, it's fundamentally illegal, certainly within some areas, to do this.  So the good news is the other guys, Phorm and Front Porch and anybody else who was thinking this was a good idea, they're certainly aware of this, too.  And with any luck they will be staying far, far away from this kind of really invasive technology.



LEO:  And they don't do anything so differently that it wouldn't be any more legal, I mean, it's the same idea.  You're using somebody's computer to kind of spy on them, or to modify their content.



STEVE:  Yeah, exactly, yes.  And in some cases you're modifying the content on the fly.  But in any event, you are definitely reading the pages that they are requesting, and you're using the content of their pages and their search requests and all of that in order to target ads at them individually.  I mean, it's just - it's a bad privacy problem.



LEO:  Well, sorry it's illegal, guys.  Guess you'll have to stop.



STEVE:  Oh, darn.



LEO:  Oh, darn.



STEVE:  But I wanted to share a really kind of a fun and wacky note from a listener of ours.  I hadn't chosen yet anything to share with our listeners for SpinRite this week, and I encountered one as I was reading through all of the input from our listeners.  The subject sort of caught my attention because the subject was "Thank you.  SpinRite got me fired, and I do mean thank you."



LEO:  Okay.



STEVE:  So he asked to be anonymous.  He sent me his name, but so he's calling himself "Scooby Drew."  He says, "I did tech support for a company that I will not mention because I am in the process of getting a season job with them.  We had a computer crash that had lots of customer information on it, including credit card numbers, addresses, and other personal information.  They left the computer out in front of the building.  Even if our IT guy said, quote, 'They can't do anything with it other than scrap parts,' I wanted to see if there was more to it than that.  So, being curious about SpinRite, on my lunch break I picked it up and took it home.  Now..."



LEO:  It's scrap parts.  It's scrap parts.



STEVE:  Exactly.  "Now, I'll be honest."  He says, "Now, I'll be honest.  I did download a pirated copy of SpinRite from a dangerous pirate crack site to see if SpinRite really was the amazing program you and Leo go on about.  After I let it run over the weekend, I was able to boot the computer up just fine.  I went to work with the machine and started it up in front of the IT guys.  They were shocked and amazed that I was able to, quote" - and he has this in quotes - "'work my necromancy on the hard drive,' unquote.  Later that day they told the CEO about SpinRite and what it did."



LEO:  What is this SpinRite?  Is this a hacker program?



STEVE:  Well, he says, "In the CEO's opinion, he felt that I had stolen personal information, and I was fired."



LEO:  Oh, man.



STEVE:  "Here is why I want to thank you for making SpinRite.  Now the IT department has a copy of SpinRite, and so do I, both legally purchased.  And because I was let go after that, it freed me from the dead-end tech support job and gave me the motivation to go back to school and get my bachelor's degree."



LEO:  Good.



STEVE:  "So thank you, Steve, and thank you, Leo, for helping me finish my education.  As a side note, please don't read my name.  Now they want to hire me back.  And the customers I had listen to Security Now.  And, well, they know where and what I'm going for.  Plus I don't think the company would like it if this story about them went public.  I have an associate degree in software programming and now going for marketing and economics at Slippery Rock University."



LEO:  Great.  What a good story.  That's...



STEVE:  Oh, it was a great story.  Thank you, Scooby, for sharing your...



LEO:  I know so many people who have been fired or gotten in trouble for demonstrating stupid security policies in companies, including our friend Randal Schwartz.



STEVE:  Yeah, I mean, I hear stories, I read stories, because I'm keeping my eye on what's going on, all the time with people who get into trouble because they say, when they bring it to someone's attention, literally it's shoot the messenger.



LEO:  Yeah, yeah.  You know, it's one thing if you're hacking their systems in-house to demonstrate a security flaw.  That's probably ill-advised.  I think Randal learned his lesson on that one.  But they put the computer out on the front porch.



STEVE:  Yeah.  It looks like, hey, let the people take it away because it's got nothing on it.



LEO:  He did them a favor.



STEVE:  Even though it was full of critical information.



LEO:  Unbelievable.  But I guess maybe a lesson to all of us.  Even though you know that it's a bad idea, sometimes demonstrating it to the company is a bad idea, too.  Oh, man.



STEVE:  Yeah, wow.



LEO:  That's an incredible story.  Thank you, Steve.  Ready for some Q&A?



STEVE:  I'm ready.  We've got the first five, not surprisingly, are follow-ups from last week's WPA and TKIP hack/crack episode.  So we've had, of course, listeners listening intently.  In the case of that last episode, listening in some cases several times to pick up all the details.  But some great questions came out of that, and a bunch of other stuff, too.



LEO:  Well, you put some minds at ease when you explained exactly what the problem was.  You sure made me feel better.  Although I did, I have in the intervening week changed everything over to CCMP encryption, AES encryption, so that - just why not.



STEVE:  Yup, exactly.  I have done the same thing.  It's like, well, why not do it?



LEO:  Why not do it?  Ben - actually two similar questions from two different listeners.  Ben Jaques in Des Moines, Iowa, had his thinking cap on during last week's TKIP Hack episode.  He said:  When I heard about the crack, I didn't panic.  I knew that tech media often cries wolf on security issues.  I also knew that in a few days you'd explain it all on Security Now! - that's a nice vote of confidence - in a way that only you can:  precisely; correctly; in great detail; and, most importantly, in a way we can all understand.  So here's my question.  You said during the show if the access point detects more than one MIC failure, one MIC failure - what do they call them, Mickey...



STEVE:  Yes, well, Mickey is the - or, no, Michael is the...



LEO:  Michael, that's right, yeah.



STEVE:  Michael is the protocol, or the algorithm that they use, yes.



LEO:  More than one MIC failure in a 60-second window, it's going to set off an "alarm" - he puts that in quotes - in the network, shuts down for 60 seconds, rekeys everyone.  When I heard this, "alarms" went off in my head.  Doesn't this open the door for a denial-of-service attack?  My idea is this:  An attacker uses the chopchop method to come up with a valid checksum for a packet - you described that last week - then purposely causes multiple MIC failures within the 60-second window, causing the access point to shut down.  When the network comes back up 60 seconds later, boom, do it again, and in another 60 seconds down, on and on.  Later in the show you and Leo seemed to conclude that this new WPA problem is an interesting hack, but it can't be used to cause any real damage.  Well, if this attack works, it would render the wireless network unusable.  I mean, it's not as serious as, say, WEP, where an attacker can get in and see every packet on the network.  But a DoS attack still is a serious threat, wouldn't you agree?  Now, I'm not an expert. I haven't studied this problem as you have.  But I have listened to every episode of Security Now! at least once, so I'd like to get your thoughts on this idea.  I'm hoping it would not work and that you'll explain why not.



Bruce Harrison in Durban, South Africa, same problem.  He says:  Hi, Steve, and a wave to Leo.  Listening to Episode 170 on the TKIP hack, I was wondering if one does generate two or more MIC failures in a row, does that stop the access point from working?  Or does it just stop traffic from the client that generated the errors?  If the former, it does seem that it would be trivial to continuously bring down a wireless network by generating two or more MIC failures in a minute.  Warm regards from Africa.  So what's the story, Steve?



STEVE:  Both guys are absolutely correct.



LEO:  Okay.



STEVE:  It is a known and significant problem with the TKIP protocol.  And this of course applies to WPA and WPA2 setups, as long as they have TKIP enabled even as an option, because in recognition of the fact that the use of TKIP is retrofitting a very insecure solution, the predecessor, WEP, in recognition of that, these guys who designed it saw, well, you know, this is really not as secure as we need it to be.  It's as secure as we know how to make it.  So we're going to detect hacking attempts and develop a countermeasure against that.



Well, as we saw, if the checksum on the packet is wrong, then the packet is rejected as a transmission error.  But if the checksum is correct, and the eight-byte MIC check, basically a packet authentication, if that fails, then the access point says, whoa, the packet was received correctly, but it's got an incorrect MIC value inside.  Meaning that we're in the process of being hacked.  Well, for some reason they said, well, we don't want to be shutting down and rekeying because of this potential denial of service.  We don't want to do it by mistake.  So when we get one, we start a 60-second timer.  And if we get another one before that 60-second timer expires, two within a one-minute window, then that's really unusual.  We need to suspend and rekey.  So literally the access point shuts down for a full minute, completely.  The whole network goes dead.  And then as it comes back up it rekeys everybody.



And so unfortunately what this means is it would be trivial to take the code that already exists - this code is in the Aircrack code, open source, freely available - and turn this into a persistent denial-of-service attack.  So that anybody with access to a network that had the TKIP protocol running, even as an option, even if everybody using the network were using the CCMP that uses AES encryption, if they're using the good super-secure protocol, if TKIP was present, if it was enabled in the access point, the access point would sense this because broadcast packets will still use TKIP, believing that there might be some clients that need that.  So even though no clients are using it, it's still available.  You could sniff packets.  You could maliciously spoof them in a way that would cause the MIC test to fail.  Whereas the checksum on the packet would pass, the access point would think, oops, we're being hacked, and shut down.  And you could literally hold the network down as long as you wanted, denying it to everyone.



LEO:  You would need to have access to the network by being proximate to it; right?  You can't do this over the Internet.  You'd have to be right there.



STEVE:  Correct.  So, exactly.  So...



LEO:  So you could, I mean, let's face it, there's probably a million ways to do a DDoS to a WiFi network, including just getting something on that frequency and jamming it.



STEVE:  Yes, exactly.  And I think that's why it's not such a huge concern is, you're right, all you have to do is just spew out radio noise on the same channel that the access point is using.  And you're going to, if it's loud enough, it's going to override the authentic transmission and cause all kinds of problems for people.  So it's like, yes, well, people could do that.  But at the same time the hacker is denying himself access, so that's arguably less of a problem.  But it is...



LEO:  Well, they have to be sitting in - they have to be within a hundred meters.  So it wouldn't be too hard to figure out who's doing it.  So, I mean, it's just, it's you're exposing yourself, right, because you have to sit there.  It would be one thing if you could do it over the Internet.  But since you have to be physically proximate...



STEVE:  Well, but you could imagine people, like in a coffee shop, if for some reason maybe there were too many people using the network, and so someone said, okay, I'm going to clean the network off by shutting it down until people give up and go away, and then I'll release the attack, and I'll have access to the network without all this too much competition.



LEO:  Right.



STEVE:  But definitely possible.



LEO:  It's doable in many, many, many ways.



STEVE:  Yes.



LEO:  So that's why I think probably nobody's made too big a stink about this.



STEVE:  Yup.  It's a known problem.



LEO:  Well, as long as we're doing similar questions, I've got three similar questions from three listeners.  You could just take one, you know?  All right.  Marc Carroll at the British Army Base - we want to give you all credit - Falkland Islands, VPNing to U.K., has a TKIP question.  To help stop potential hackers even decrypting small packets, could one, if their router supports it, set their WPA group renewal key time to a lower value?  Say 10 or 5 minutes or even lower than that?  He says his router default is one hour.  Not necessary for me as my router supports CCMP without TKIP, a Buffalo router WHR-HP-G54 - oh, he's using the Tomato firmware, that's why, 1.21.  But perhaps that could be some use to people who don't have that luxury.  Increasing your default group renewal key time.



Cam C in Melbourne, Australia, wonders about group key renewal, as well.  You mentioned in Episode 170 that the method requires 12 minutes to perform the chopchop, and that routers rekey every hour.  All of my wireless routers allow the changing of the group key renewal interval.  Would reducing this timer to 10 minutes eliminate the limited attack?



Ted also came up with this idea.  He's in Research Triangle Park, North Carolina.  He says:  I have to stay with TKIP.  I have a PDA that only supports TKIP.  This is not unusual, by the way.  Same thing with WEP.  People often are stuck with older hardware that forces the use of less safe protocols.  He says:  As it sounds, though, exploitation of the small hole would require 12 minutes.  I run DD-WRT, another patch firmware like Tomato router, on my Linksys WRT54G router, which has a lot of options, as I'm sure you know.  So I just changed my key renewal interval to 11 minutes, one minute shorter.  Does that sound like an effective patch?  Thanks again for the superb podcast.  My coworker and I eagerly await the posting time each Thursday.  What do you say, Steve?



STEVE:  Well, and I should say, you know, we read three.  There were many people.  I really appreciate, clearly people are listening so closely, and we've got smart listeners who are saying, wait a minute, okay, if we need to determine the last 12 bytes of the packet, and the way we determine each byte is by successfully changing - we take a byte off the end.  We fix the checksum so that it works.  But in the process we're going to get a MIC failure.  And so when that happens we know that we got - we guessed the byte that we chopped off correctly.  But we now have to wait for that 60-second timer we talked about in the first question.  We have to wait for that 60-second timer to expire before we try to get the next byte.  Which means it's absolutely the case that there is no way to perform this attack in fewer than 12 minutes.



So these guys are saying all of the routers that they discuss, and many other access points, do allow you to change the rekeying interval from an hour to whatever you want.  Normally it's specified in seconds.  So they often have 3,600 seconds, which is an hour.  But, for example, 660 seconds is 11 minutes.  And so it's interesting, too, because the attacker would, if he really wanted to perform this attack, remember that it generally takes 12 to 15 minutes to get all of this work done.  Well, you don't know, okay, so 12 to 15 is a quarter of an hour.  So you might have the access point rekey itself right in the middle of your attack anyway just because an hour, only four of those fit into an hour window, and so just by chance you might have the hourly rekey occur.  So part of the attack, of an effective attack, would probably be to wait for a rekeying because then you know that it just happened, you know that presumably there won't be another one for an hour, unless somebody was wise to this and brought the rekeying interval down to something less than 12 minutes.  Doing so prevents you from being able to get confirmation of all 12 bytes within 12 minutes, and you're out of luck.  Because as soon as the rekeying occurs, everything changes.  None of the bytes you guessed until then are useful then under rekeying.  So, yes, absolutely it is the case, if someone has to continue using TKIP, and your router allows you to bring that interval down, that completely defeats the attack.



LEO:  Well, there you go.  These guys are sharp.  Sharp cookies.  Paying attention.  Dennis Wigmore in Port Hope, Ontario, Canada thinks he may have found a faster approach for TKIP hacking.  Man, I'm impressed.  So I was listening last episode.  You explained we'd have to wait a minute to continue every time we correctly guessed a valid byte of the key stream.  What about hitting up the deauthentication attack?  We force them to reconnect, send out another key.  Couldn't we do this until we had enough information and go from there?  That would dramatically speed it up, wouldn't it.  As I know, this is only related to TKIP injections, but wouldn't this be a quicker method than just active listening?



STEVE:  Well, no.  What Dennis missed is that we're not trying to get the key.  So what we're trying to get is we're trying to get a sample stream of pseudorandom data emitted by the key for a given packet.  And that's only going to be valid for that given packet.  So the idea is to just change the data in the packet, but leave everything else the same.  Leave the packet number the same because that determines specifically which chunk of pseudorandom data that is going to be used in that packet.  So if we were to cause a deauthentication and reauthentication, that would be a rekeying, and so we're back to square one again.  So even though you could certainly do that in much less than a minute, every time that happens you know nothing about the new key, so anything you learned previously would just be washed away.  And that is specifically why you don't want to allow a rekeying, if you're a bad guy.  You don't want the rekeying window to close on you when you're mid-attack because you just have to start again.



LEO:  All right.  Okay.  Mike in Salt Lake City has an important note about WiFi QoS.  We had mentioned that you need QoS turned on for this hack to work.  He says:  I just wanted to send my thanks for the good TKIP Hack show.  I checked my router, and I do have TKIP enabled.  I need to.  Again, legacy hardware.  I went to check QoS, I couldn't find it.  It did, however, have an option called WMM.  I did some research, found out that that's the same thing.  So now that's disabled.  I just wanted to let you know so you could notify listeners about the distinct acronym.  I never heard of WMM.



STEVE:  Yes, it's WiFi Multi Media.  And he's right.  I should have mentioned this last week.  That is what many routers call Quality of Service.  It is a subset of the 802.11e subspec.  What it does is - oh, and I should say WMM is like WPA and WPA2.  It is a certification.  And it is a trademark of the Wi-Fi Alliance.  So newer routers, if you look at the feature lists they have, you'll see WMM, which stands for WiFi Multi Media.  What this does is...



LEO:  Why invent a new acronym?



STEVE:  I know, I know.  I know.



LEO:  Stupid.  Just so they could trademark it.



STEVE:  Well, so they could trademark it, and so they...



LEO:  So they can license it.



STEVE:  Exactly.  And so that it's something that people can only put on their box if the Wi-Fi Alliance has had a chance to check their hardware.  I mean, I really - fundamentally I really agree with the value of somebody certifying interoperability.  Otherwise it'd just be a pain in the butt to buy something and not know if it was going to work.



LEO:  Right, okay.



STEVE:  So that's good.  So what they've done is - and I have a feeling we're going to do an episode on this because it's going to be important moving forward.  They assign four different broad categories of traffic:  voice, video, best effort, and background.  So as you would imagine, voice is the highest priority.  Any traffic that is tagged as voice traffic gets to use the router with - gets to use the airwaves with minimal delay.  Video is second priority.  Best effort is default.  So anything not tagged is default.  And then, being sort of a good citizen, you can tag traffic as background.  And it's the lowest priority, meaning that when the airwaves are free and there's nothing going on, then the background track will have an opportunity to flow.



So, again, it's all about optimizing the use of a limited resource.  You would not want software that said, oh, I want much better download speeds, so I'm going to tag myself as voice traffic so I always get more.  In doing so you would corrupt any real voice traffic that was also trying to use that same WiFi access point because there would be some big bulk download going through with the same level.  Now, it's incumbent upon the applications to perform the tagging.  So it's not something that's done automatically.  Which I was a little sorry to see in the specification because arguably you could say, okay, web traffic on port 80, and especially TCP, is not going to be voice.  Voice is going to be UDP traffic, as we know, as opposed to over a TCP connection that does not carry voice very well.



So they could have done some things smart by default.  But apparently they haven't because you do require application in order to do tagging.  But with any luck, applications like Skype that are all about quality and Voice over IP, you would imagine that Skype probably is tagging their traffic as voice in the case that it might be going over a WiFi access point and want to maintain the highest quality possible.



LEO:  Right, yeah.  So WMM is QoS.



STEVE:  It is QoS.  And if - oh, and here's the point.  If you need to use TKIP because you've got legacy hardware and your access point says either QoS or WMM, disable WMM.  In doing so you've turned off Quality of Service support, and this hack will not function.



LEO:  Okay, good.  So that does work.



STEVE:  So that's the cool thing, yes, it absolutely does work.  Disable WMM, WiFi Multi Media, that is QoS.  And without that the trick these guys use of allowing a replay attack, because that is something, basically, when I mentioned before we're changing just a part of the packet, we're changing the payload, but there's a lot we can't change.  Part of what we can't change is the packet number.  And so by not being able to change the packet number, the replay protection comes in and prevents us - we would normally reject that packet because it's already been used.  But they use the Quality of Service hack in order to get around that. So if you turn off either QoS or WMM, WiFi Multi Media support, in your router, then you shut the hack down, too.



Now, if you happen to be using Voice over IP through a WiFi connection, you might find that there was some difference.  Although my sense is, I mean, you hadn't even heard the acronym, that acronym before.  My sense is this is still very new and not yet widely deployed.  So it's probably nothing is using it anyway.  It's one of those features that's there for the future, not getting heavy use yet.



LEO:  Yeah, VoIP does use QoS, but usually they use their own router, and usually they want to be wired.  In fact, in order to do it they want to be outside your router, connected directly to the Internet.



STEVE:  Right.  They want, like, nobody in the way.



LEO:  Right.  Which means they're probably doing some sort of hack to QoS.  Paul Kamet in Kaneohe, Hawaii has a great question about WiFi encryption.  What a surprise.  Steve, during the TKIP Hack show - I've listened to it several times now, by the way - it sounds like the IP address fields in the WiFi packet are encrypted along with the data.  If that's so, how can this packet traverse the network?  Even with the MAC addresses in the clear, it doesn't sound like enough information is available to send the packet across the country.  Your thoughts?



STEVE:  I thought this was an interesting question because he's right.  The IP, the source and destination IP addresses are encrypted.  So it's only when they're decrypted that anyone knows where these are bound for.  What's important to recognize, though, is that within a single network, within an Ethernet-style network, whether it's a wired network like we all have at home or a wireless network, the addressing from one adapter to the next is not done over IP.  IP has nothing to do with it.  It's the MAC address.  It's that 48-bit MAC address which is composed of a 24-bit vendor field and a 24-bit device field, together making 48 bits.  That's the entire addressing information within the network.  So that's why that is not encrypted and cannot be encrypted, because that is the way the packet physically gets seen by the receiver.  Once it's seen, then it's decrypted using the shared key in the case of preshared key wireless, either TKIP or the CCMP AES style, the good, still strong, and believed not to have any of these weaknesses technology.



Once it's decrypted, then the machine is able to look at the packet and see whether the destination IP is one or more of the IPs that that machine may have.  Because, as we know, it's possible for computers to have more than one IP.  And this is the way they can have more than one IP.  They can only have one MAC address per adapter.  But that adapter could be associated with more than one IP.  So the machine says, oh, is this an IP that is mine?  And, if so, then it proceeds to process the packet further.



Now, as for how can a packet that's encrypted, whose source and destination IP addresses are encrypted, how could that, as he asks, cross the country, well, this is a source of another set of problems with potential with WiFi, and that is the nature of the gateway, which is typically the access point, which is also normally a router.  The nature of the gateway is that when the packets which are encrypted are received at that gateway router access point, just as they come in they're received because they've got the gateway's MAC address.  So exactly the way it works with a client, the access point will decrypt the packet in the clear and then look to see where it's going.  It will typically have an external IP address that is not part of the local network, but part of the external network somewhere out on the wide global Internet.  And so the router does what a router does.  It says, oh, this is for outside.  So it shoots it out of its WAN port.  Notice that it's been decrypted in the process of crossing that router.



LEO:  So it's only encrypted internally, never externally.



STEVE:  Yes.  Yes.  And in fact, that's one of the interesting things that can be done, one of a well-known attack that was primarily used earlier on about WEP.  But it's still a concern in some cases about TKIP.  If you can arrange to have, like, even just a ping, if you can arrange to have some sort of packet with known data sent into the network, which you're able to receive, if you - for example, say how a ping packet is able to carry a payload.  So you could have a ping packet with just all zero, just filled with zeroes.  If you could get that into the network and receive it, then for that particular destination that had a unique key, you end up with the encryption stream that was used to XOR against that plaintext, which is all zeroes.  So it's just the key stream.



LEO:  Excellent.



STEVE:  So because you've essentially - you've gotten the access point to perform encryption for you on a known packet.  And as we know, if you know what the packet is, you just XOR that with the encrypted data, and you get back the key stream, as we talked about last week.  So anyway, it's unfortunate that we're dealing with this legacy technology that just uses "exclusive or" and pseudorandom streams for encryption because it just really never was very secure.  And it's tremendously good that we've gone to AES.  And certainly in the future we're going to see more and more equipment moving in that direction.



LEO:  Matt in Howell, New Jersey wants to add just a dash of salt.  He says:  Hi, Steve, Leo.  Been a listener since Episode 1, love the show.  I'm a computer science student.  And many times lectures were just refresher courses on something I'd already learned on Security Now!.  I was in the lab last week, and a teacher was about to start a class.  He said I could stay for his lecture as long as I didn't cause any disruptions.  I stayed to finish my lab and listened in on his lecture.  It was for a graduate course and was all about hashing.  This is a smart kid, I can tell.  Something he mentioned at the end of his lecture caught my interest.  He described something called a "salt value," which as far as I could understand was a constant that is mixed into the value being hashed to increase randomness.  Am I right?  If not, can you explain this to me?  What is salt?  Thank you, Steve, for your supplementary education.



STEVE:  Okay.  So we have well-known secure hash functions.  MD5 is a hash.  SHA is a hash.  The idea being, and we've discussed this in episodes long ago, that a hash function is a so-called one-way function, meaning you put any stuff you want into the front of it.  And when you're all done, you read a value out which is essentially a signature.  It can be thought of as like a signature for everything that you put in.



Now, the reason a hash is cryptographically strong is it is impossible, or I should say really, really, really infeasible, to deliberately get a signature out from something that you put in.  If you make a change at all to anything coming into the hash function, you get something completely unrecognizable out.  That is, for any change you make, half the bits are going to be different.  So there's no way to figure out, given what you got out, what it was you put in.  But it is the case that every time you put the same thing into, for example, MD5 or SHA-1, when you put the same thing in, you get the same thing out.



Well, now, that's important because, if someone makes a fingerprint, for example, people who download software on the 'Net may have seen where source code will be available, and then the MD5 will be given for the source code.  Well, that allows someone to receive that source code and to perform their own MD5 hash separately, that is, to recreate the signature that was originally created by the person who was offering the source code.  Then you compare the MD5 listed with the MD5 you've got, and that verifies that you're using an exact copy of whatever it is that was originally run through the hash.  So it's important that their MD5 is the same as your MD5, that SHA-1 is universally used in the same way in instances where you want fingerprinting.



Well, there is a downside to this, and that is, for example, with passwords.  If passwords, for example, were only hashed, for example, with MD5, you could do something called a "precomputation attack."  And it's popularly known as "rainbow tables" because the rainbow technology that's been used for anti-software hacking and anti-piracy was using an unsalted hash for a long time.  And the idea is that you take like a whole bunch of dictionary words, and you hash them into the result.  Then, if you have the ability to see what the hashed secret password is, you simply do a comparison between this large dictionary you've built of already hashed things because you can compare that much more quickly than you can perform all the hashes.  So the idea is you only need to do the hashes once to create all of the results of the hashes.  And those you can compare very quickly.  When you get a match, you know what the original password was that created that.  And there are on the 'Net, you can download huge, huge tables of precomputed hashes to use in hacking.



Well, the reason that works is the hash that was used to create the password is the same hash function as was used to build the precomputation table, if you added a little salt to the hash.  If, for example, the system that was hashing the passwords, if it simply put in some pseudorandom stuff before the password, then essentially what you've done is you've created a keyed hash.  You've created a hash that uses a standard function, but this salt is a key.  And unless you know also the key, you're never going to get a hashed value that matches.  So it's a way of taking a standard hashing function, but for your particular purpose.  For example, just verifying passwords, you never need to have that transportable, unlike the instance I gave where you download software and you need to compare hashes.  In this case a system that's a closed system merely wants to verify that the same input generates the same output.  But it doesn't ever need to compare it with anything else.  In that case you want to make a keyed hash by adding some salt.  Just put something else in, in addition to the normal input, and you're going to get a hash value out that's completely different.  So that's what salt is.



LEO:  Very cool.  And you've mentioned it, I think, before in the program.



STEVE:  Probably.



LEO:  Yeah.  Sounds familiar to me.  Rodney Morton from Round Rock, Texas, on assignment in Germany, has the sniffles.  He says:  I read the following article about keyboards being remotely sniffable.  Yeah, in fact I meant to ask you about this because I just saw this myself.  I want to have your take on it.  It's a BBC article.  He says, and the article says, "Keyboard sniffers to steal data.  Computer criminals could soon be eavesdropping on what you type by analyzing the electromagnetic signals produced by every key press."  The attacks worked at considerable distance, like across the office, like 20 meters.  Have you heard about this?



STEVE:  Oh, yeah.  I'm looking at the article.  It says, "By analyzing the signals produced by keystrokes, Swiss researchers have reproduced what a target typed.  The security researchers have developed four different attacks that work on a wide variety of computer keyboards.  The results led the researchers to declare keyboards were, quote, 'not safe to transmit sensitive information.'  The attacks were dreamed up by doctoral students Martin" - whoo, boy, Martin [Vuagnoux] and his friend Sylvain [Pasini] - "from the Security and Cryptography Laboratory at the Swiss Ecole Polytechnique Federale de Lausanne, EPFL."  Thank goodness for acronyms.  "The EPFL students tested 11 different keyboard models that connected to a computer via either a USB or a PS/2 socket."  So these were not wireless keyboards.  "The attacks they developed also worked with keyboards embedded in laptops.  Every keyboard tested was vulnerable to at least one of the four attacks the researchers used.  One attack was shown to work over a distance of 20 meters.



"In their work, the researchers used a radio antenna to fully or partially recover keystrokes by spotting the electromagnetic radiation emitted when keys are pressed.  In a web posting they added, 'No doubt that our attacks can be significantly improved since we used relatively inexpensive equipment.'  In videos showing their early work, the researchers are seen connecting keyboards to a laptop running on battery power.  They avoided using a desktop computer or an LCD display to minimize the chance of picking up signals from other sources.  Details of the attacks are scant, but the work is expected to be reported in a peer-reviewed journal soon.  The research builds on earlier work done by University of Cambridge computer scientist Markus Kuhn, who looked at ways to use electromagnetic emanations to eavesdrop and steal useful information."



So we've talked about this kind of thing in various different formats in the past.  Traditionally this is what was known as TEMPEST, where it was possible to aim a directional antenna at a CRT, and the CRT generated electromagnetic radiation in a defined pattern that was exactly dependent upon what was showing on the screen because the electron beams were being turned on and off to energize and illuminate the phosphor on the back of the glass of the screen.  And it turned out that you could - it was possible to decode it.



So it's really not surprising when you think about it.  But this demonstrates, I mean proves, that typical computer keyboards which use a - they're being scanned electromagnetically.  There's a scanning process going on in order to essentially pick up which keys are being depressed.  So when you press a key, there's an event that occurs which can be a change in the scanning pattern that is always generating a weak transmission from the keyboard.  And the act of typing generates enough output, enough radio frequency interference, that it's possible to determine what's being typed.  And that's not using any sort of wireless, you know, we've talked about the really weak, single-byte XORing encryption that's being done by many insecure wireless keyboards.  This is wired USB and PS/2 keyboards.



LEO:  This is something similar to what they call "van Eck phreaking," where you can see, monitor the electromagnetic radiation of monitors through a wall and see what the monitor - on the monitor.  Which I don't know if it's science fiction or real, but that's what they call it.



Mark Piper, writing from an undisclosed location, wants a hard drive password:  I understand now most hard drives have the feature to request a password on startup.  How is this feature typically activated?  I can't seem to find it anywhere in my BIOS configuration.  If my BIOS doesn't support it, is there anything I can do short of whole disk encryption to require preboot authentication?  Thanks in advance.  I think we talked about this before.  This is something IDE has had for years.



STEVE:  Yes, in fact I don't think there's a drive on the market now that doesn't offer this as an option.  Unfortunately, you absolutely do have to have support in the BIOS because it is before the drive can be used at all it needs to be given the password that the BIOS knows to contain.  Either it's in the BIOS, or it's asking you for it, depending upon how your security setup is working in the computer.  It might be that you authenticate, for example, by swiping your finger on a fingerprint reader.  That authenticates you to a TPM, the Trusted Platform Module in the BIOS.  That then unlocks the key that the BIOS gives to the hard drive in order to unlock the hard drive in turn.  The problem is, until that's done, you can't read anything from the drive.  So there's just - there's no way to do it.



I actually came up with an interesting idea a while ago that I never implemented in a product, either commercial or freeware, where you could boot from a floppy or a USB device.  It would support that function that the BIOS lacked and unlock the hard drive and then transfer the boot over to the hard drive.  But I've never known that that's been done by anyone.  I never got around to do it, and I've got so much stuff on my plate now, there's no way that's going to happen.  But the answer is, unfortunately, if you poke around your BIOS, and you cannot find anything about establishing a hard drive password, then the BIOS doesn't support it.



You might, if this is, for example, a laptop, you might check to see whether there's any newer firmware for the laptop because it is a feature which is appearing more and more currently in late-model laptops and in late-model BIOSes.  So you might find that updating your BIOS would allow you to suddenly have that feature where you didn't before.  But without going to extreme measures, if the BIOS doesn't support it, there's really no way to get that hard drive to - the password to the hard drive in order for the BIOS to boot it.



LEO:  And this is different from the password protection, the more modern, like Hitachi, the encryption that's built into the hardware of the drive itself.  This is something else.  This is an IDE password, basically.



STEVE:  Well, yes, exactly.  So it's not whole-drive encryption.  It's essentially the drive is locked.  So even though the data out on the drive is still in the clear, you just - you can't get to it at all because it's got that password.  Although...



LEO:  Is it pretty secure?



STEVE:  It's good for thwarting most people.  But if you had a government subpoena, the government could go to the hard drive manufacturer and say here's the court order, remove the lock from this drive.  And they could definitely do so in order to unlock the drive.  And then all the data that is available on the drive would be in the clear.  It's not as secure as full-drive encryption.



LEO:  So don't confuse it with that.



STEVE:  Right.



LEO:  John in Columbus, Ohio wonders how universal Plug and Play should be.  He says:  Hi, Steve.  I'm wondering if I should still be disabling Universal Plug and Play on my wireless router.  I wasn't sure if Microsoft solved the buffer overflow issue or not.  Thanks, and keep up the great work.  I disable it all the time, on every router.



STEVE:  I know you do.  In fact, I was listening to you, Leo, when you were having problems with the...



LEO:  I was listening to you.



STEVE:  You were having problems with a new router that you had installed.  And I think it needed to be configured for VPN use or something.  And you thought, well, maybe I'll try turning it back on to see if that will solve the problem.



John's question confuses a couple different things, but there was an important point that I wanted to sort of clarify.  He's talking about a Microsoft buffer overflow which existed long ago in the Universal Plug and Play service that was running by default in Windows.  In order to deal with that, and this is in the era before Service Pack 2 that has the firewall on by default, in order to deal with that, I created the little freeware UnPlug n' Pray.  And all Unplug n' Pray does is make it trivial for anyone to disable that service.  Because most people at the time had no use for Universal Plug and Play.  That is, and so what happened was, in original versions of XP that did not have the firewall turned on by default, it turns out they were exposed to a buffer overrun vulnerability that was widely exploited until Microsoft brought up their XP firewall and issued a security patch in order to close that.



My feeling has always been let's not have services and open ports unless we need them.  So I've always been annoyed that Microsoft was running all this stuff by default.  And that's, of course, why early on Microsoft had such a bad reputation for security.  Being behind a router, of course, further protects you.



Now, when John asks, should I be disabling Universal Plug and Play on my router, the answer is absolutely.  There are known trojans and malware which are now Plug and Play aware.  I mean, I predicted this years before it actually happened.  It has happened.  So the idea is you can get malware in your machine, for example, which you invite in through a browser vulnerability.  The malware will send a packet out, a broadcast packet, onto your LAN, looking for your router, through Universal Plug and Play.  The router says, oh, hi there.  Yes, I'm here.  And the malware says, ah, thank you.  Please open the following ports.  And the router will dutifully do so.  There is no security, believe it or not, built into Universal Plug and Play.  Nothing that prevents something on the inside of the network from accessing the Universal Plug and Play service that is actively exposed and unfortunately often turned on in routers.



LEO:  And you won't get a warning or anything?



STEVE:  Nothing.



LEO:  The firewall won't tell you?



STEVE:  No, there's no - no.  I mean, again, this is Microsoft making sure it's all easy.  We just want, you know, when you plug in your refrigerator, we want everything to be discoverable and for all these different services to expose themselves so that everything just kind of works.  Unfortunately, that implies that everything, every single thing within your network perimeter is trusted.  If anything isn't, if anything is compromised, then - and for example, Universal Plug and Play, essentially it is a programmatic access to your router's API.  That is, anything you can do from the screens, and in some cases even more than you can do through the user interface, can be done silently, without your knowledge, behind your back.  Like setting up a DMZ or opening ports, that then of course just allow the floodgates because it's like not having a router anymore.  Certainly not one that you can trust.



LEO:  You know where you really get people using this is Xbox 360.  A lot of kids want to use Xbox Live, which lets them play games, start games with other people on the Internet.  And the Xbox, I think, in a very irresponsible way, will check your network and say, if you don't have Universal Plug and Play on, it will say, oh, you have limited connectivity.  And I get calls all the time on the radio show.



STEVE:  And what's so annoying, Leo, is you only need to map a few ports through the router to the Xbox in order for it to say, oh, you've got excellent connectivity.  It's simple to do.  But again, but you're right, they just say, oh, turn this on.  And...



LEO:  Well, and most people, you don't really want, I mean, most people would probably - when people call me, I say, well, you've got to do port forwarding.  And they go, huh, what?  They get nervous.  And so I see why Microsoft turned this on.  But it's unconscionable.  I mean, they really are encouraging people to turn on Universal Plug and Play without explaining to them any of the risks.  You know, they're really scaring them into it.  And it just makes me crazy.  I get calls about that all the time.



John H. Storey in the United Kingdom wrote with the subject "Port 1029 Open."  You must get - you probably get a hundred of these a day, port XYZ open, because of ShieldsUP!; right?



STEVE:  Right.



LEO:  Hi, there.  How do you close this port externally?  What do you recommend?  I'm a beginner at computing.  Best regards, John H. Storey.



STEVE:  Well, this was obviously a very short question.  Something is telling him port 1029 is open.  It's probably ShieldsUP! which is telling him 1029 is open.  And that's a problem because it means that he doesn't have any other protection between his computer and the Internet.  That is, there's no router.  And it sounds like his firewall is down because even the XP built-in firewall would recognize that port 1029 is only meant to be open internally, within the system.  And if you look, we had talked about, I guess it was a couple weeks ago, netstat and the mysterious self-closing of the netstat window because I imagine that the listener was entering it at the Run line under the Start menu, rather than starting up a DOS box separately.



Netstat will show you often a number of very low-numbered ports, like starting at 1025, 1026, 1027, down, very low number, just over 1024, which is the boundary.  And those are typically ports that are opened by processes within the system that want to use the networking stack for talking among themselves.  So that's meant to be local, and never meant to be exposed publicly.



However, if you've got no firewall on the computer, or if your XP firewall is turned off or has been expressly configured to allow one or more of those ports to come through, they'll be exposed.  So when he asks how do you close it externally, this is not something you can stop.  That is, you can't stop the process that is opening 1029 because it's probably service host, that ubiquitous service carrier inside Windows.



LEO:  And you don't know what it really is.



STEVE:  Exactly.  So what this does say is that your firewall must not be currently enabled.  That's also surprising because XP is so annoying now about making sure you've got your firewall enabled.  I know, I say "annoying" tongue in cheek because we really want it that way, especially for a beginning user of computers.  So I would explore whether the firewall is enabled.  And in the firewall configuration there are various overrides that can be applied.  You really want to turn those things off.  If you're a beginning, you probably don't need them turned on.  Maybe something installed itself that wanted to make an exception for itself through the firewall, which is on that port.  But it's worth pursuing why this thing is open to the  outside world because that's not usual.



LEO:  Let's move on now to our topic of the day, Steve Gibson.  Or our Tip of the Day is a PayPal tip.  We got two different ones from our listeners.  I don't use - I use PayPal for donations, so I'm always interested in PayPal tips and tricks.  Starting with Mike O'Hare in Georgetown, Massachusetts.  He has a PayPal workaround.  He says:  Steve, listening to Security Now! podcast 169, you said PayPal only accepts a checking account number.  What I did to get - I guess when you, well, I don't - you can use a credit card, but eventually you have to give them a checking account; right?



STEVE:  Well, the problem is that they always default to a checking account.



LEO:  Oh, right, right.



STEVE:  So you're having to manually override that.  But more importantly, when you use their one-time credit card number generator, there's no way to override that.  It insists on pulling from a checking account.



LEO:  Ah, okay.  So he says:  What I did to get by that was open a "savings account" in my bank, specifically for PayPal use.  I can then transfer whatever money necessary from my checking account into the savings account to cover PayPal purchases.  PayPal is happy, and I'm happy they don't have access to my checking account.  And I imagine he keeps the balance at zero unless he needs the money in there.  I wish you and Leo the best.  I'm a happy SpinRite user.  That's a good idea.



STEVE:  I just liked that idea.  In fact, I may adopt that idea.  I mean, I do like using the PayPal service.  It's just annoying that they want to pull from my main checking account.  And I hadn't - I don't know why I hadn't thought of just setting up an account for PayPal.



LEO:  Just for them, yeah.



STEVE:  PayPal likes pulling from checking.  The reason they even have my checking account information is that that's part of what you have to do to become fully identified or certified or recognized or something.  I mean, they really do push that on you.  And so it's like, okay, fine.  Take this one, and I'm just going to move money as I need to into that.  So keep a relatively low balance, PayPal pulls from it, and then you replenish it as necessary.  I think that's a useful solution.  So I wanted to...



LEO:  I am not fond of PayPal in so many ways.  And yet it is, you know, the most convenient way for us to get donations to the network.  So we continue to use it.  I'd love to find an alternative, though.  I guess Google Payments, maybe Amazon Payments?



STEVE:  Yup.  It's going to happen.  Ultimately I think somebody will come along and - but PayPal has a huge edge because they were there so right off the bat.



LEO:  Right.  Moving on to Jason Deabill in Southampton, U.K.  He provides an important update on PayPal security tokens.  That's that little football.



STEVE:  Yup.



LEO:  I love my little football.



STEVE:  And that's one of my security devices I have not gotten tired of.  I've got mine hooked up to my PayPal account.



LEO:  It's really, really handy.  So he says:  Hi, Steve.  First up, many thanks for the excellent website and podcast.  I can't express how useful they've been to me in recent years.  I just thought I'd drop you a quick note to point out that PayPal security tokens are now available outside the U.S.  Yeah, these were available only in the U.S. for a while.



STEVE:  Yeah, yes.  In fact, we disappointed a lot of users because I didn't realize that was the case.  And we immediately got mail saying, hey, I can't get it where I am.  So apparently, and I wanted to bring this again to the attention of all of our listeners, that I don't know exactly where they're available, but they're still very inexpensive.  He said he ordered his for about three pounds, which is about $5 U.S., so it's about the same price, super affordable.



LEO:  It's a token price because it costs them - if you forgive the pun.  It costs them more to make it than that.  So that's just really to encourage you to buy it, but they want to give you some price to kind of make sure you're going to use it.



STEVE:  Yeah.  So any of our listeners who have been disappointed that they could not get the PayPal token wherever they are, you may want to check again because at least we know it's in the U.K., and it may be many other places, as well.  Which would be really terrific.



LEO:  You know, this is today some good news.  Both Visa is going to start doing those - it's the same idea, that token card.  I'm really glad to see more and more of that.



STEVE:  Yeah, these things seem to take a long time to happen.  But it's really something we desperately need because we want to facilitate secure and safe Internet commerce.



LEO:  Absolutely.  Steve, we've come to the end of our 12 questions.  12 questions, good and true.  We thank all of you.  We do this every other episode.  You can always ask more questions of Steve by going to GRC.com slash...



STEVE:  Feedback.



LEO:  Feedback.  And a great place to put your feedback.  Of course, he has security forums.  You can go there to find out more, as well, and to ask questions on the security forums.  In fact, GRC.com is a great resource all around.  Besides ShieldsUP! there's lots of other free utilities.  Of course there's the great SpinRite, which everybody ought to buy just because it's the hard drive maintenance utility.  You've got to have that.  And you also find 16KB versions of the show.  There are transcripts.  Every episode we've ever done.  It's all at GRC.com, the Gibson Research Corporation.  Steve, thank you so much.



STEVE:  Always a pleasure, Leo.  And next week we're going to have Ronen on...



LEO:  Oh, that'll be fun.



STEVE:  ...the author of Sandboxie, to tell us about the product in more detail, the challenges he's had to overcome, and answer some questions.



LEO:  Very good.  Thank you, Steverino.



STEVE:  Talk to you then, Leo.



LEO:  Bye bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#172

DATE:		November 27, 2008

TITLE:		Sandboxie

SPEAKERS:	Steve Gibson & Leo Laporte

GUEST:		Ronen Tzur

SOURCE FILE:	http://media.GRC.com/sn/SN-172.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo return to take a much closer look at "Sandboxie," an extremely useful, powerful, and highly recommended Windows security tool they first mentioned two years ago.  This time, after interviewing Sandboxie's creator, Ronen Tzur, Steve explains why he is totally hooked and why Leo is wishing it was available for his Macs.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 172 for November 27, 2008:  Sandboxie.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that focuses, aims a laser beam at your security and privacy online.  Steve Gibson is here.  He's the security wiz from GRC.com, the creator of ShieldsUP!, also the first antispyware software and many other great utilities, including, of course, SpinRite, which is the must-have hard drive maintenance and recovery utility.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you this week.



LEO:  What are we going to talk about this week?



STEVE:  Well, we're going to finally have the show that I've been wanting to have and mentioning and hinting about for many weeks.  We're going to talk about Sandboxie.  We talked about it about two years ago.  When I fired up my email to contact Sandboxie's author, Ronen Tzur, I realized, I mean, I was surprised it had been almost exactly two years when he and I had had some interaction.  We did a show about Sandboxie, sort of an overview, cursory look at it.  And he felt the effect of us talking about it on Security Now!, thanks to our audience, and sent both you and me some registrations for it.  I was really pleased to see that they hadn't expired, even though Sandboxie has evolved a lot in two years.  When I downloaded the current version, which is 3.32, and applied the registration information from two years ago, it worked because his registration is once per lifetime.



LEO:  Yay.



STEVE:  That is, I guess, yours or his or somebody's - ours.  And then you own it for life.  And also you're able to use it on all of the machines that you own.  So it's not restrictive in any way.  And I've spent the last couple weeks looking at it more closely and then really focusing on it in preparation for wanting to really get to know it.  And I've got to say, Leo, I mean, this is - it has turned into a really significant security tool.  I mean, it is for people who are interested in security and want control over what things go bump in their Windows machines.  I'm going to explain it in great detail.  We've got Ronen on with an interview so people can get a sense for him and what his goals were and what the product does.  And then I'm going to go into, in detail, how it works, to really explain it.  I couldn't be more excited.  I think this is just a - it is, I think, as important a tool as a personal firewall is for network communication.



LEO:  Wow.  High praise indeed from the master.  So, Steve, before we talk to Ronen - I'm excited about talking to the author of Sandboxie - let's find out what's going on in the world of security.



STEVE:  Okay.  First thing, Leo, we need to get you back using NoScript.



LEO:  Oh, is it that bad?



STEVE:  No no no.  It's that good.  I wanted to acknowledge all of the annoyed listeners we have.



LEO:  Including me.



STEVE:  Well, no.



LEO:  It's still running on my system, by the way.  I just turned off scripting.



STEVE:  They were annoyed that you and I gave up on it so easily.



LEO:  Oh, okay.



STEVE:  And I found the secret.  It's the secret everybody else knows except you and me.



LEO:  Oh.  What is that?



STEVE:  You turn off notifications.



LEO:  How?



STEVE:  It's that annoying audio gwerp sound it makes and the popping up of the bar all the time that, you know, what I was doing - and I don't know, I mean, I know better than this because I was using a script management system in IE.  It was my own.  But the idea being if a site, I mean, virtually every site on the planet now wants to run scripts.  But most of them don't need to.  So you don't want to know when every single site you go to is trying to run scripts and then, like, oh, give it permission.  The idea is you only give permission to the ones where you notice something doesn't seem to work, and you care.  And so what I've been doing now for about the last two weeks, after I read through lots of people saying, okay, you guys are just dumb, I thought, okay, well, let's try this again.  So I'm back using NoScript.



LEO:  I'm looking in the options.  You tell me what to do to make this work okay.



STEVE:  Okay.  You just go into Options, go to the Notifications tab, and you'll see the first checkbox you turn off for popup notification when scripts are blocked.  Then in the second region is audio, and turn that off.



LEO:  Yeah, I have that turned off already.



STEVE:  Okay.  And now then also go back to, I think it's on the first tab down at the bottom, is Globally Enable Scripts.  And it says "Dangerous " or something after it.



LEO:  Yeah, I had that checked.  I'll uncheck that now.



STEVE:  Yes.  And I've got to say, Leo, I'm now two weeks into this, and it's heaven again.  It's only when I notice that something's not right.  So you do, sort of in the back of your mind, you need to remember that you've got NoScript going, meaning that sites are not being allowed to script.  But it's only the ones that matter where you then manually, you just click on the little "S" down there.  And it'll show you if it's blocking something.  And it makes it very simple to enable just the things that it has blocked.  And so I'm really happy with it.  I mean, I really think that the notifications should be off by default rather than on by default because...



LEO:  Well, here's my concern is that I'm going to be surfing around now, and I'm not going to know that I'm not getting the full page.  Almost everything I use uses JavaScript.  And I disagree, it's nontrivial, it's not JavaScript I don't need.  In many, many cases it's JavaScript I do need.



STEVE:  Well, okay.  So we're going to talk today about Sandboxie, which is tremendous for preventing system modifications if you go to a malicious site that wants to hurt you.  The problem is, it wasn't designed to be a privacy tool.  So what you really want is you want scripting disabled unless you want it enabled.  I mean, I've always been saying, even before I...



LEO:  Right, opt in.



STEVE:  ...switched to Firefox and using NoScript that, you know, scripting is a real problem.  And the reason you finally yourself added NoScript was you were listening to all this and thinking, wow.  And, you know, one incident after incident after incident demonstrating what a problem scripting is.  So...



LEO:  Well, I've had it, and I've turned it on and off and on and off for years because I just get frustrated.



STEVE:  Well, so all I'm saying is I wanted to acknowledge all of our listeners who are successfully using it thanks to disabling notification and selectively enabling it.  And I am now, too.  So...



LEO:  I'll tell you one thing it breaks.



STEVE:  ...you can join the party, Leo, or you can stay out there.



LEO:  Well, first of all, I'm using a Mac, so I'm not too worried.  But second of all - and if people would just use a Mac they would have fewer problems.  But second of all, things like Amazon 1-Click is seen as a clickjack.  It's like, okay.  So many of these techniques that are potentially dangerous are also used by legitimate websites, even Amazon, that it becomes an issue.  Now, in a perfect world, Amazon wouldn't use these techniques.  Nobody would use these techniques.  They wouldn't be so reliant on scripting.  But we don't live in a perfect world.  And I'm not - I'll use it.  I'll give it a shot, and we'll talk next week about whether it's been successful.  I'm sure you'll do the same.



STEVE:  See what you think.



LEO:  Yeah.  I've turned off notifications, so now I have no idea what's happening.



STEVE:  It works for me. 



LEO:  Well, yeah, because you don't know what you're missing.



STEVE:  And if I don't, I guess it's not very important.



LEO:  Well, that may be.  Maybe not.  Maybe you're missing 90 percent of the functionality of a site.  Part of my job is to look at sites and review them.  If I'm missing functionality on a site because I have a NoScript running, it's not very functional for me.



STEVE:  Okay.



LEO:  But I'll try it.  I'm open-minded.



STEVE:  Give it a shot.



LEO:  I'll give it a shot.  All right.



STEVE:  Okay.  Second bit of errata, before we get into the security news, is a couple days ago PayPal started acting differently for me.  When I logged in, I gave it my email address; and then, because I've got my little PayPal football, I type in my password, and I know how I can then just add the next six, the six digits from the football to the end of my password in order to bypass the separate screen which says, oh, you're registered to use the security token, what is the current token value in the display window?  Well, that didn't work.



LEO:  Yeah.  It's changing on mine, yeah.



STEVE:  So the reason it didn't work is PayPal suddenly became aware of my VeriSign VIP card.



LEO:  Right.  Well, that's why.  It wants me to choose.  All of a sudden I saw that.  It wants me to choose.



STEVE:  Yes.  And so we've been waiting for this.  So I thought, oh, how cool, let me try that.  Because now it's allowing me to choose any of the registered tokens, the security authentication tokens that are associated together.  So I, for the first time ever, chose the VeriSign VIP, the credit card dealie that we've talked about using eInk.  And the problem is, I pushed that little button so many times that it's gone off into the twilight zone.



LEO:  It's out of synch, right, right, right.



STEVE:  I mean, PayPal has no, I mean, PayPal is using VeriSign's back end in order to provide these services.  So what it did was it asked me three times, and I kept giving it the number.  And it says, don't think you're right, try it again.  I kept giving it the number.  Then it took me to a screen where it asked me for two in a row.  And that was the synchronization process we've talked about.  And it worked perfectly.  And I now have my VeriSign credit card authentication and my football.  And this is the problem we talked about where what if I didn't have my football with me because it's kind of bulky and a pain; whereas my little VeriSign credit card is in my wallet, and it's with me all the time.  So now PayPal and eBay know about both.



LEO:  I think that it was - I may be wrong, but I think I've been using my VeriSign card on PayPal for a while.  So I think they knew about it.  But I think what's happened is they're now explicitly asking you to choose which one you're using.  Because I believe I have been using the PayPal - because the football's here, but I carry the VeriSign with me in my wallet.  So when I'm at home I've been using the VeriSign.  And I think I've been doing that for some time now.



STEVE:  I don't know how they would know which is which because...



LEO:  They wouldn't.



STEVE:  Yeah, right.



LEO:  Which is probably why they want you to do the dropdown now.



STEVE:  Exactly.  Now you have to tell them explicitly which one that you're using.



LEO:  They're both six digits; right?  They're both the same length.



STEVE:  Yes.  There are six digits.  And one is time based, and one is sequential based.  The card does not have a clock in it; so every time you push it, it generates the next cryptographic string in a sequence, which is why it needed a couple in order to synchronize itself.  And actually the football does have - is time based and has the clock in it.  So it's transparent to the user.  Although if you were to push the football button a lot between uses, no one would care because it's time based.  If you push the credit card a whole lot and, like, really go off into the future of sequences, then you would be forced to go through this resynchronizing process when you next tried to actually use it for authentication.



LEO:  Yeah.  It's a wonderful thing.  And what's really nice is to be able to use either/or.



STEVE:  Yes.



LEO:  Because, as I said, I have one here and one there.



STEVE:  Well, and for a long time you could register only one.  So I wanted to let people know that PayPal is now up to speed, and the little credit card format tokens are functioning and work great.



LEO:  Fantastic.



STEVE:  Security news.  Bunch of interesting things.  I wanted to mention that Apple Safari had a major update, both for Windows and Mac, to something past 3.2 - probably 3.3.  I know that anything prior - I'm sorry, no.  Now to 3.2 because anything prior to 3.2 had some critical remote code execution vulnerabilities that have been cured in 3.2.  When I fired up my Mac this morning I did my routine check for updates.  And it says, oh, we've got a new version of Safari for you.  So I checked into what was going on.  And that has been since we last talked.  So Safari users will want to update themselves, whether they're on Windows or Mac.



MSNBC carried an interesting story about a report that Symantec released that I thought people would find interesting.  It turns out that hackers that are breaking into eCommerce-enabled enterprises are no longer necessarily rummaging through the database, trying to install trojans, trying to just wreak whatever havoc they can.  When they realize that they've cracked into an eCommerce-enabled enterprise, they stay on a down-low, and they actually commandeer the enterprise eCommerce system to use for verifying stolen credit cards.  They've set themselves up as a third-party service.  They charge $10 per card, Symantec reports, to get lists of stolen cards from other card-stealing people.  And then they will quietly use the backdoor that they have established into an eCommerce system to verify the validity of the cards, which an eCommerce system is able to do.  I wrote my own from scratch, and so I've used the API that is available for merchant services.  And you're able to verify cards, that they're valid, without putting any charge on them.  And so what hackers are now doing is they're breaking into enterprises that have merchant service backend access and commandeering it, using it quietly for their own purposes, and not wanting to be discovered because they want to keep being able to use this service.



LEO:  That's really interesting.



STEVE:  Isn't that interesting?  Yeah.



LEO:  Well, they're so, you know, I hate to give them any credit at all.  But when there's money involved they get pretty clever and wily.



STEVE:  Yeah.  Microsoft announced that the November version, that is, this month's version of their MSRT, their Malicious Software Removal Tool, removed what Microsoft described as phony security software, which of course was  malicious, from nearly one million Windows PCs in the first nine days of its deployment.



LEO:  Wow.



STEVE:  And so a million machines had some sort of phony security software installed, and the MSRTs - I always kind of think that it's like, okay, well, is this really doing anything at all?  You get a new one every month.  And you may remember that two months ago, in September, it removed the Storm trojan from about 300,000 machines.



LEO:  This was the - this time it was the Antivirus 2009; right?



STEVE:  Right.



LEO:  That's a weird one.  And I'm not surprised to hear there's a million of them out there.  In fact, I bet you there's a lot more.  I would get calls all the time on the radio show from somebody that says, hey, you know, Antivirus 2009 found some bugs on my system, and I installed it.  It was like - and it has certain behaviors when it's broken.  I mean, fortunately, as wily as these guys are, they're still crappy coders.  So there are certain symptoms of this thing that when people call me up I go, oh, you got it, you got bit.



STEVE:  Well, and then there's a - we have a first to report.  Dutch authorities, operating in the Netherlands, convicted a 19 year old for operating a bot network.



LEO:  Yay.



STEVE:  Excuse me?



LEO:  Yay, I'm glad they've convicted him



STEVE:  Yes.  And here's what's very cool, and this has never been done before.  After they arrested him, they used his command-and-control system of his botnet to inform all the infected end-users that their machines were infected with a powerful botnet.  They redirected them to a different website which provided instructions for how to remove this thing from their machine.



LEO:  That's interesting.



STEVE:  And that's something we have never seen before.  It's questionable whether it's legal in the U.S.  You know, there have been - everyone is always saying, hey, why can't we use these things to, like, disinfect themselves?  And the idea is that, well, you're communicating with software technically in violation of the law by having any modification.  Maybe it's the fact that they didn't remove it, but they just redirected people to a site which said, hey, you're here because the Dutch police have figured out that your machine was under control of a bad guy.  Now it's under our control.  We don't want it to be under anyone's control, even ours.  So here's how you remove this.



The problem is it was a nasty bot.  It was a rootkit bot.  So it evaded scanners and antivirus things.  It turns out it's difficult to remove, at least at this point.  Maybe somebody would create an auto-remover.  But you'd probably have to, like, boot a CD kind of thing in order to get it out of there.  Because, I mean, it really set its hooks deep into the operating system.  But I thought that was really interesting, that they said, okay, we're going to use the network to let people know they've been affected and let them do whatever they want to do with that information.  But we're going to give them the information.



LEO:  I suspect that's a first.  But it seems like since they're not modifying their machines, just notifying them, that would be okay.



STEVE:  Yeah.  And then some Australian - you may have heard about this - some Austrian, rather, some Austrian firewall vendors found a kernel memory overwrite bug in Vista.



LEO:  Yeah.



STEVE:  There's an API, an Application Programming Interface, there's essentially a subroutine that you're able to - that a program can call, called Create IP Forward Entry 2, which is it allows programs to modify the Internet routing table in Vista.  You can also, if you use the ROUTE ADD command from the command line, and you give it a netmask larger than 32 bits, you will get a Blue Screen of Death.  It will crash Vista.  Now, what we know is that this is actually overwriting kernel memory, and that that's a dangerous thing to do because even though Vista has got a - and we've talked about this in detail - has some substantial anti-hacking technology, like the Address Space Layout Randomization, where DLLs are always being loaded in different locations so that it's not possible to do a highly successful jump to a certain location.  Also it requires either full admin privileges in order for this to work at all, or you need to be a member of the Network Configuration Operator group, which most people aren't.  So, and thanks to Vista, the way Vista operates, as we know, most users are now not operating as admin.  They only elevate themselves to admin privileges during a time through the UAC that they actually need that facility.  So...



LEO:  You know, I saw that in the article, that, oh, this is nothing to worry about because nobody's running as admin.  Is that really the case?  I think most people do, in fact, run as admin, even on Vista.  It's easy not to, and I tell everybody not to.  I don't think the default install of Vista sets you up as a limited user; does it?



STEVE:  Yeah, it does.



LEO:  Oh, it does.



STEVE:  Yeah.  You are not - I believe in Vista, unlike XP, you are normally not an admin.  And then you use the UAC in order to elevate yourself when you need to.



LEO:  Oh, I hope that's true.



STEVE:  I think that's the case.  And but I forgot to also  mention, as far as we know, it is exclusively a local attack.  Meaning that it's not something that can be done remotely.  So code in your machine would have to be already in your machine in order to exploit this.  As a consequence of all these mitigating factors, Microsoft just yawned a little bit and said, eh, we'll fix this in the next service pack.  This doesn't seem like something, you know, yes, we'd rather Vista didn't crash.  You could experiment with it using the ROUTE ADD command and give it long netmasks.  And if you're an admin user, you'll crash your Vista.  Well, okay.  Anyway, Microsoft is not...



LEO:  Doesn't sound - mostly because it's a local attack.  Somebody has to have physical access to use this one.



STEVE:  Precisely.  And, well, and the point is - or code just has to be running.  Well, if the code's running, then you've already been compromised.



LEO:  Right.  Too late anyway.



STEVE:  So it's like, yeah, okay.  And of course I've got a - always try to find a fun and interesting SpinRite story to share.  We've got Edward McCall wrote with just a simple subject:  "SpinRite."  And he said, "SpinRite just completed its analysis and low-level corrections of my hard drive.  And I was delighted to find it corrected two Cyclic Redundancy Check, CRC, errors I had encountered.  I was trying to copy two important files when I encountered CRC errors on those two files, and they refused to copy.  SpinRite corrected those, and now I'm able to copy the files.  Thank you, thank you, thank you.  You have a wonderful product."  All in caps.  "Thank you again."



So we get so many people who write in where Windows won't boot, it's sort of an all-or-nothing sort of thing.  Here was a different one because he had specific files on the system, not in the boot process, but on some important files that he absolutely needed.  So he ran SpinRite on the whole drive, specifically targeting just those two, and it fixed it for him.  So that was neat.



LEO:  I just wish that there was some way - you know I use SpinRite all the time, and it just saved Dane's drive on his Vista machine.



STEVE:  Yup, I got email from...



LEO:  Colleen.



STEVE:  From Colleen, yeah, she was asking me...



LEO:  She's become, by the way, she's become the biggest SpinRite advocate you've ever met.  I think when she first started working here she might have kind of heard of it.  She certainly knew who you were.  But now, man, she's like a SpinRite fanatic.  Every drive that comes in the door, SpinRite, SpinRite.  But I've got an iMac, and the newer iMacs are very hard to get to the hard drive, which is really frustrating because I know if I could SpinRite that drive, all would be well.  But I just can't get to it, so I'm going to have to take it into the Apple store.  And they'll probably replace the drive unnecessarily.



STEVE:  Ouch.



LEO:  Yeah.  Just, you know, if it's a SATA drive, it should be easy to access.  The good news is it's not really debilitating because it's got Firewire 800, and I just bought an external drive, and it runs and boots off that just fine, so...



STEVE:  Ah, cool.



LEO:  Yeah, it's not the end of the world.



STEVE:  Colleen sent mail because she wanted some clarification on SpinRite's S.M.A.R.T. monitoring screen to know whether it would be worth running SpinRite.  And from what she said, I said, well, what you're looking at is data that was never meant to be seen.  SpinRite services sort of the internal workings of the S.M.A.R.T. system.  And so we don't even state what it is we're really showing.  We just say, okay, this is stuff going on behind the scenes.  We do also show the normal S.M.A.R.T. data.  But the stuff behind the scenes is substantially more sensitive.



And so, as I explained to her, it's useful if you had a couple drives of the same make and model.  You could compare the actual error rates that normally nothing shows you when you're running the drive under SpinRite to get the sense for which one is in better shape.  Comparing similar makes and models would mean that the data that they were showing you was the same.  Or if you looked at a drive at Day 1 and Day 120 and Day 240, it would also give you a sense for the rate at which the drive's condition was deteriorating, if it was.  So comparing over time the same drive or the same make and model, it's very sensitive.  Anyway, I said, so don't worry that those numbers seem high.  Give SpinRite a shot.  And I got email from her, I guess the next day, saying yippee, it just worked.  So that was neat.



LEO:  Yeah.  She is a very, very happy SpinRite customer.  You could add her to your list of testimonials.  I mean, she is just a big fan of SpinRite.  Steve, let's say hello to Ronen Tzur.  He's calling us from Israel.



RONEN TZUR:  Yes, that's right.



LEO:  It's nice to meet you.  I guess you and Steve have talked already.



RONEN:  Yeah, yeah.  And it's great to be on the show.



STEVE:  Yeah, we've been exchanging email for a couple weeks.  And because I had originally hoped to have him a couple weeks ago.



LEO:  Well, a couple of years, really.  I mean, I think we've talked about Sandboxie for a while now.



STEVE:  Well, it comes up from time to time.  And actually my motivation, we originally - we did an episode on it, sort of talked about it a couple years ago.



LEO:  Right.



STEVE:  And it was just maybe a couple months ago that I noticed there was some dialogue in GRC's newsgroups.  And when I jumped into those to ask people what they thought, they were like, wow, completely addicted to it.  And so I thought, okay, we've been talking about Firefox; we've been talking about NoScript.  It's time to revisit Sandboxie and really understand what this is about.  So Ronen and I fired up a dialogue.  I've spent a number of days, parts of a number of days getting my, I mean, really coming to understand what it is that Ronen created.  And I'm really, really bullish about it.  It's what I recognize now is that it's a - what he created is a universal security tool that encapsulates program behavior in Windows in a way that prevents things, malicious things, or inadvertent things, or privacy things, I mean, there's so many ways this can be used.  So after we talk to Ronen, I'm going to explain in detail exactly how this functions, sort of from the user's Windows perspective.  But I wanted to get a sense, for example, like what Ronen's original motivation was behind Sandboxie because this is, as I mentioned, four years in the making at this point.



LEO:  How does it feel to have a program people are addicted to, Ronen?



RONEN:  Well, it feels very good.



LEO:  Yeah, I bet.



RONEN:  Yeah, the addiction aspect of it is something that I recognize because once you start using it and you get the feeling that whatever you do with these protected programs inside the sandbox, they can't harm your computer, then without this tool you feel almost naked after a while.



STEVE:  And, I mean, a perfect example is just this morning I had received email that included a PowerPoint presentation.  It was something someone had forwarded to me.  He didn't create it.  This was something roaming around the Internet.  And it's like, oh, I mean, I'm nervous when I launch anything in email because you just don't know what it is.  And when I initially clicked on it, I got a notice from Sandboxie saying powerpnt.exe does not have permission to run in the sandbox.  Because I've got Eudora right now, my email client is in a Eudora sandbox, and Firefox is in its sandbox.  And I had tightened it down so that only Eudora and Firefox could run in the Eudora sandbox.



But now Eudora wanted to launch the PowerPoint viewer.  So I said, oh, yeah, well, I want to do that.  So I'm evolving the settings a little bit of Sandboxie as I go.  So I added powerpnt.exe to the list of permitted executables that could run in the Eudora sandbox, and then clicked on the link.  Well, so now it worked this time.  PowerPoint was allowed to run in the Eudora sandbox.  And I knew that no matter what this thing did, it could not hurt me.  Its view of the system - this is what I'll be talking about after we're through talking to Ronen - its view of the system is essentially Eudora sandbox-centric.  And it is not allowed to make changes outside of the sandbox which are persistent.  So, I mean, it's just - it's really spectacular.



LEO:  Ronen, a lot of great software is written to scratch your own itch.  Is this how Sandboxie started?  Was it something you did for yourself?



RONEN:  Yes, that's really the drive behind it because early on in 2004, when I just started developing the product, Sandboxie, at that time, or just sometime earlier than that, I was hit by spyware.



LEO:  Oh.



RONEN:  And I - yeah.  So I couldn't get rid of it.  And you know these traditional antispyware tools, they take some time to catch up with everything.  So what I seemed to get at that point in time was something that traditional and at least the more common tools, they did not identify.  So I ended up with a compromised system.  And I didn't like it very much.  So then...



LEO:  How did you come up with the idea of a sandbox?  Was that your first thought? 



RONEN:  Yeah.  Pretty much, yeah.  I thought if I could get Internet Explorer to run in isolated space, inside a sandbox, some kind of disposable space that I wouldn't care if it gets infected with spyware or anything else, that in the worst-case scenario I just throw it away and start over.  So that was the initial thought.



STEVE:  So over - now, that was four years ago.  At some point, then - were you originally thinking of making it a commercial product?  Did you just do it sort of as something to solve your own problem?  Where did it transition from, okay, now I've got Internet Explorer running in a contained environment, maybe this would be useful for other people? 



RONEN:  Well, I always had hopes for it as a commercial product.  But I have to say that initially it was just a proof-of-concept product because I couldn't tell in advance that this is going to definitely work, and I'm going to be able to do it.  For instance, there was a lot of talk on the Internet for a while how Internet Explorer is part of the operating system, and you can't really take it out of the operating system.  And so, you know, this raises questions whether something like Sandboxie is even possible.  So there was the initial idea.  But then I had to work on it to see that the implementation actually works.  But once I got that going, and I saw that it definitely was possible, and there are no real technical limitations to getting that done, then yes, I certainly was hoping to turn it into a commercial product at some point.



STEVE:  And so how has it evolved since then?  From then to now? 



RONEN:  Well, it's been four years now.



STEVE:  Right. 



RONEN:  So there has been some evolution.  Like I said, the first version was really a proof-of-concept code, and not something that you could really use.  And that was in June of 2004, about six months or so after I started working on it.  And at the time I felt that the idea is really something new and something novel, and it's going to take some time to really become popular.  So I thought even though this is not really a finished product I might as well start early getting the idea out.  All right?



So over time I took that idea of isolating the browser, and I applied it to programs in general.  And in fact that's what today most of Sandboxie is concerned with, that is, creating a sandbox that can run almost any program.  And running the isolated Internet Explorer or the isolated Firefox is just a specific case of the general idea.  Well, I think you touched on that earlier when you spoke about Sandboxie, Steve.



STEVE:  Well, yeah.  And in fact, in talking with you, I didn't realize, for example, that you could use it, for example, to sandbox the setup or installation of a program.  If you run an installer in the sandbox, then everything the installer does, including a sophisticated installation of an application, it's in the sandbox, so... 



RONEN:  That's right.



STEVE:  ...so and is not really making changes to your system.  It thinks it is, but that's the trick and the beauty of what you've done is it thinks it's installing the software on your system.  It's in fact making modification sort of deltas in the sandbox.  And if you decide you don't want this, then you just delete the sandbox, and it's like this never happened. 



RONEN:  Exactly.  That's the core idea of Sandboxie that, unlike other security tools, it doesn't try to stop the malicious program from working because then you have false positives when real software gets identified as malicious, or malicious software falls through the cracks.  So Sandboxie takes another idea.  It says, I'm going to let this program do whatever it wants.  And if you don't like it, you can easily get rid of it with just a single mouse click.



STEVE:  Right.



LEO:  Does it help now that you've got hypervisor and built-in hardware support for virtualization?  Does that make it a little easier to do what Sandboxie does now? 



RONEN:  No, unfortunately, not at all because the hypervisor is designed and developed really for virtual machines, which is a similar but different technology from - similar perhaps from the concept, conceptually similar to what Sandboxie is trying to do, which is isolation.  But from an implementation point of view virtual machines are different, so the hypervisor doesn't really make any difference.



STEVE:  One of the ways that we can think about this - and I was going to ask you how you would compare Sandboxie with a traditional virtual machine approach.  In a virtual machine, what we're virtualizing is the chip.  And so that's what is being extrapolated.  And so to use a virtual machine, you're essentially virtualizing at the chip.  You then have a sort of a clone of the chip, which you then install an operating system into, which you then install applications into.  And that's sort of the traditional virtual machine approach.  Here you're - it's sort of like you're virtualizing the API, that is, the operating system's Application Programming Interface, so that you're inserting yourself between the application and the OS, which solves, well, many problems that the traditional virtual machine has in that it's sort of an inherently much lighter weight solution.  You're not having to commit a gig or half a gig of RAM to a virtual machine that is then taken away from the host operating system.  Nor do you need a second copy of an operating system and second copies of all your applications installed in that separate virtual machine. 



RONEN:  That's right.  Also a virtual machine is inherently a different computer.  It may be a simulated computer; but it is, at the end of the day, what you have, you have two computers now that you're managing, one computer as your primary applications, and then you dedicate the second computer, which just happens to be virtual and exist within your main computer.  But in that second computer you have to install a second set of your applications and then keep them up to date.  Now, what Sandboxie does is let you have roughly the same kind of isolation, let you have a logical virtual space that cannot - that is one way, that cannot touch back and make modifications to your primary system, but is isolated.  But you don't have to dedicate any of the things you mentioned there.  It's not a separate computer.  You don't have to install a second operating system and a second set of applications.  You don't have to dedicate...



STEVE:  Oh, and also a whole virtual networking system.  When you use, for example, VMware, suddenly you've got virtual adapters that are, like, popping up all over the place. 



RONEN:  Right, right.  It's really a complicated and advanced tool, and I don't think it was ever primarily designed to make life easier on the Internet, you know, to secure.  It was, I think, it's - it may be used this way.



LEO:  It's a side effect. 



RONEN:  Yeah.  But Sandboxie, on the other hand, has been designed from the ground down - from the ground up.  That's always been the core idea, to let you be safe on the Internet so that you can use your web-facing or Internet-facing programs in a secure way, where they are isolated from your system, and they can only do as much as you let them, and never more than that.



STEVE:  Well, then I guess the way it's evolved beyond that original motivation is that you realized that, because you've created this containment system which is robust, and you generalized it beyond Internet Explorer, for example, and even beyond email, to running anything in a sandbox so that any changes that anything you're running in the sandbox makes are transient.  They are not permanent.  They don't actually affect the system in any way outside of the sandbox. 



RONEN:  That's right.  Most of what I had to do with Sandboxie, most of the challenges I had to address for Internet applications - for Internet Explorer, for Firefox, for Thunderbird, all kinds of Internet applications - because at the end of the day these are programs that are running on the operating system.  So the bulk of the work that I had to do anyway to get just these programs to run.  And I did some additional work to make Sandboxie in a sense generic.  So the extra work that other programs may require, I also addressed that because I thought, why not, it's just the little extra mile, the one extra mile to go so Sandboxie can have much more applications than just using it for Internet security.



STEVE:  Yeah.  I just - it's a tremendous solution.  I'm really glad that I took the time to look at it again.  I now have Firefox sandboxed, and Eudora sandboxed.  I'm not a big IE user anymore.  I was sort of noticing it's convenient that the name Sandboxie, that I guess began as SandboxIE, you know, it's convenient that the name is also sort of generic, and it doesn't really say IE that much because you've really moved it beyond just being a solution for Internet Explorer. 



RONEN:  Yeah, I thought it was a cute name, so the IE aspect of the name.  But it's really a minor thing because you have to suffix the Sandbox with something.



LEO:  Sandboxer.  Sandboxit.  Sandboxie is good.  I like it. 



RONEN:  Yeah, yeah.



LEO:  So you do pronounce it "Sandboxie," not "Sandbox IE."  We need to clarify that. 



RONEN:  Yes, Sandboxie.  Yeah.



STEVE:  And where do you go from here? 



RONEN:  Well, I think the most challenges of Sandboxie have already been met.  It does most of the things it set out to do.  And but there is one particular aspect that I would like to address in a future version, which is even easier configurability than what Sandboxie has today.  In some cases you have to configure Sandboxie to let the sandbox  program talk to the software outside the sandbox.  For example, a common case is PDF printing software, which has a part running outside the sandbox and a part running in the program that you are now running sandboxed.  For example, part of it comes up in the sandboxed browser.  And then when you click "Print," it tries to communicate with this part that runs outside the sandbox.  Now, the strict isolation of Sandboxie initially prevents this communication.  And the failing - I'm sorry.  The printing fails.  So what you would have to do is tell Sandboxie in this case to relax its isolation just a bit to make this printing possible.  So right now what you have to do is you have to visit the Sandboxie website and get instructions for the particular piece of software that you are interested in, and then apply these instructions into the Sandboxie configuration.  And then you have it the way you need it.  But what I'd like to advance in that area is to make it somehow more accessible to offer these prepackaged configuration packages inside a program.  All right?



STEVE:  Yeah, that sounds great.  I should mention two things.  First of all, it is, also from my own experience, I had exactly this issue, for example, with generating PDFs from inside Firefox.  It is possible to use the tools that you have provided.  There's like a restrictions monitor or resource monitor log where, as you're trying to do something, you log things that are blocked and allowed.  And so it's possible for someone who understands the Sandboxie user interface, as I now do, to see what things were attempted and blocked.  And that gives you literally the strings that you then add in the UI to permit those things that were blocked.  And by doing a little bit of experimentation, even without, for example, going to the Sandboxie website, it's possible to develop your own little pinholes through the sandbox in order to get things to work that weren't before. 



RONEN:  Yeah, but I think it's also - it's worth mentioning that for people who want to just visit the website and get the pre-prepared list of instructions, that's also possible.  You really don't have to...



STEVE:  Yes, I agree. 



RONEN:  ...go through monitoring.



STEVE:  Yes.  And in fact I use, as it happens, Macro Express as my keystroke macro program.  And I've got a bunch of macros that I use for helping me with email.  And after I sandboxed Eudora they didn't work anymore.  And I thought, I think I remember seeing something about that.  And so I went to the Sandboxie site, looked under the compatibility, and there you had two strings that I needed, and step-by-step instructions, two strings that I needed to add to the Eudora sandbox specifically to permit Macro Express to work.  And, bang, I did that, restarted Eudora, and now it works perfectly. 



RONEN:  Right.  So it's already - it's fairly easy.  But I want to make it even easier by offering these things directly in the program, without you having to visit the website.  Because occasionally there are updates, and I just think it would be better.



LEO:  Well, and that is what scares people off from security software in general.  We've talked about that before, Steve, with NoScript.  The harder it is to get it working, the more hassles and hitches you have, the more likely you are to turn it off eventually.



STEVE:  And so the idea, Ronen, would be that you would have, in the UI, like a list of known programs or activities that require some cross-sandbox operation.  And you'd just be able to, like, turn on checkboxes, like if you - it would say Macro Express.  And if you use Macro Express, you just turn the checkbox on, and that allows Macro Express to work across the sandbox. 



RONEN:  Yeah, yeah.  Exactly like this.



STEVE:  Very nice.  I should mention also to all of our listeners that I'm really pleased with your licensing policy because the license, once purchased, allows, first of all, that copy of Sandboxie to be used on all the machines owned by the licensee.  So, for example, with your permission I get to use Sandboxie on a couple of laptops and various machines.  I, at this point, I don't want to be without it, you know, truly.  And the other thing is, it's a license for life.  That is, you get it for Sandboxie and anything you do in the future is covered by that single license. 



RONEN:  Yes.  Any future upgrades to Sandboxie are covered by that license.  It's a lifetime registration license.



LEO:  How has response been?  Are you selling a lot of copies? 



RONEN:  I'm doing well.  I'm doing all right.



LEO:  Good. That's always nice. 



RONEN:  People like the software.



LEO:  That's great. 



RONEN:  Yeah.



LEO:  Is it your full-time job now, or are you still working in the business? 



RONEN:  No, it's my full-time job.



LEO:  Fantastic. 



RONEN:  It's my full...



LEO:  Isn't that a nice feeling, that you can write something like that - well, Steve, you know that feeling pretty well - and make a living on it is great. 



RONEN:  Yeah, it actually does feel great.  And the positive feedback has been overwhelming, so that's also very nice.



LEO:  Yeah, you're doing some...



STEVE:  Well, I'm really glad to be able to shine a bright light on this again, Ronen.  You really deserve, well, I think you deserve success with this.  And as a security-conscious person who's talking to a very security-conscious audience, I'm excited to be able to bring this back around, really explain it to our listeners, as I'm about to, and make it a tool that more people are going to be able to use. 



RONEN:  And I appreciate that very much.  So thank you, Steve and Leo, for having me on the show.



LEO:  Thank you, Ronen.  Sandboxie.  And it's - is it Sandboxie.com? 



RONEN:  Yeah.



LEO:  It's easy to remember. 



RONEN:  It is.



LEO:  Sandboxie.com.  Thanks a lot, Ronen. 



RONEN:  Thank you.



LEO:  Take care.



STEVE:  Bye bye. 



RONEN:  Bye.



LEO:  That was Ronen Tzur from Israel, the creator of Sandboxie.  Now we want to find out how Sandboxie works. This is where we get geeky.  We're famous for this.



STEVE:  Yeah.  And this is why I get excited, Leo, because this is, as I mentioned earlier, and also while we were talking to Ronen, I am truly, honestly excited; and, I mean, my world has changed.  I'm now using Sandboxie for Firefox and for Eudora.



LEO:  If you use Sandboxie, do you need to use NoScript?



STEVE:  Okay.  Here's, I mean, that's a good question.  The answer is yes because Sandboxie is not a privacy enforcer.  It's a security enforcer.



LEO:  Ah.  Makes perfect sense.



STEVE:  So it prevents something from changing your system.  But the program in the sandbox still has full access to everything in your system.  So you can think of it sort of as like it makes it read-only, so it's able to read everything.  So if you had malicious scripts running that were trying to steal information, they could still do so.  So it's not a replacement for NoScript.  And I am using NoScript in Firefox inside of Sandboxie.



LEO:  All right, Steve.  Sandboxie.  How do it work?



STEVE:  Okay.  The way I would like our listeners to think of this is as a very powerful, general purpose, security enhancement solution.  As Ronen indicated, he initially started because he went to some site and clicked on some link, and his system was deeply infected by malware that he was unable to remove, some sort of spyware in Internet Explorer.  So he thought, okay, this is bad.  I don't know whether he reformatted his drive or what.  But I think he indicated that he was really unable to satisfactorily remove this.  So he thought, I'm going to see what I can do to prevent anything bad from happening to my machine.



So the way this works, what a sandbox is in Ronen's implementation, is imagine that you've got a program running in Windows, and it opens a file with read/write permission.  It's possible, for example, in Windows to open a file for read-only access, where Windows itself then gives the program a handle to the file, which allows the program to read the contents, but not to alter them.  In that case, Sandboxie does nothing.  It just says, okay, this program that is sandboxed is going to only read, so it's permitted.  If, however, the program in the sandbox tries to open a file with read/write permission, so that it might modify the file, Sandboxie transparently copies the file into the sandbox.  That is, and what the sandbox basically is, is just a set of folders on your hard drive.  So it makes a copy of that file and subsequently redirects all access to that file rather than to the original copy out on the system.  So anything [clearing throat].  Excuse me.  Anything the program does, it does to the copy of the file, not to the original one.



Well, that concept is then extended to all aspects of the system, for example, to the registry, so that any keys that are edited or created in the registry - which of course is what malware does when it's trying to arrange to install as a rootkit to get itself started up surreptitiously - any changes that are made, anything that writes in any fashion is actually written in, like, it's intercepted and written into the sandbox.  So from the view of the program it has successfully made these changes because, when the program tries to look at them, Sandboxie realizes that it's got its own local, sort of like a locally cached copy.  You can really think of it like a cache, where it's getting the contents originally from the operating system, then caching it in the sandbox.  And modifications are contained in the sandbox, so that the application thinks it's succeeded, and it's chuckling to itself, when in fact it didn't do anything to the system.



So what Sandboxie does, another way to think of it is it sort of creates a fork of the state of your system, where the program that's making modifications, it sort of forks off of the real condition of your system and begins to see its own local private view, which only it sees.  Nothing outside of the sandbox is aware of the sandbox or has access to it.  It's just the normal system.  But the thing running in the sandbox sees a different view.  It sees its own private view.  So what this means is that you've isolated any actions which are taken by this program, and nothing outside is actually modified, even though that's transparent to the program running in the sandbox.



So in practical terms, the way this works is, for example, with Firefox or Opera or IE, whatever web browser - and generally what's so cool about this, even though this started out to be, as Ronen indicated, a program to sandbox Internet Explorer because that's where his first problem was, and how many times have we said on this show that the web browser is now the biggest security problem in the system because it's the way - it's what you use to go out onto the Internet, where unfortunately not everybody is a good guy.  And as you click on things and go to websites, you're oftentimes, as we talk about with scripting, you're running code, you're running ActiveX controls which are being downloaded, whatever you're doing, I mean, that's the big danger.



But Sandboxie is a universal solution for any executable that you want to run in your system.  And when we were talking to Ronen I gave the example of using it to isolate the installation of programs.  If you run a setup program or an installer in a sandbox, it thinks it's installing the program in your system.  But in fact all the changes it makes are constrained within the sandbox.  And he even has the ability - it modifies, for example, the Start menu.  It thinks it's added things to the Start menu.  But if you look at your Start menu, they're not there because your Start menu is not in the sandbox.  But Ronen in his popup menu has a sort of Start menu clone which merges the updated Start menu in the sandbox with the external Start menu that hasn't been merged.  So there you can see this thing you've just installed is in the internal Start menu, and so you can run it.  So this allows you, for example, to do what many of us do with a virtual machine.  In fact, remember that I installed Chrome in a VM initially.  And you were saying, wow, you must not really...



LEO:  You don't trust anything.



STEVE:  You don't trust anything.  Except I was doing it for containment because I know, and old-time, old-school Windows users know, that when you install things sometimes you can't really get rid of them completely.  Well, I was installing Chrome in a VM.  Now, today, knowing Sandboxie as I do, I would install it, I would run the Chrome installer in a sandbox.  And in fact that's trivial to do because Sandboxie adds to the right-click context menu "Run Sandboxed."



LEO:  Wow.



STEVE:  So literally...



LEO:  That's so great.



STEVE:  ...any program on your system, you can right-click on it.  And rather than, like, double-clicking on it if it was sitting on your desktop, like you just downloaded some installer, rather than double-clicking on it you could right-click on it and just select from the context menu "Run Sandboxed."  And it fires it up in this containment environment so that all the changes it makes are constrained.  Now...



LEO:  Is there any limitation to this, I mean, that you've found?  Are there any kind of places where that doesn't work very well?  



STEVE:  Well, when you think about it...



LEO:  Programs assume that they're accessing the whole system.



STEVE:  Right.  And there's no place that I have found where there is a problem you can't overcome.  One of the things that users will see, and which I have seen, is this has all the feeling of being a very mature product.  This is not a 1.0 or a .99.  It's at 3.32.  It's been around long enough, and it's had enough of a user base, that it's matured so that the various things that might cause problems have solutions.



Now, one of the things we all do is we download files using our web browser.  So here's a problem.  Because we've downloaded a file, but inherently we don't want that to stay in the sandbox.  We want to, if we trust the file, if we believe it - well, for one thing, when we download it and execute it, you might want to execute it in the sandbox, in the browser's sandbox, if we're not sure we can trust it.  But often, like I'm downloading an MP3 from you, Leo, well, it's an MP3, it's from you, I want it out of the sandbox.  So there is a - you have the ability to define special directories where anything that is written to that directory you're notified about.  A popup comes up and says, oh, you've just written something to your desktop from your browser.  Do you want to recover this?  He calls it "recovery."  Do you want to recover this file from the sandbox?  And so with just a click you can say yes.  And then it appears on your desktop.  Until then it was contained within the sandbox.  So he has provided ways which are convenient to allow the migration of things from inside the sandbox to outside.  And they're very convenient.



One of the other things that is very cool, for somebody who's interested in, like, doesn't trust some software or wants to maybe sort of do some forensics, you know we've talked for example about running Filemon or Regmon and then, like, scanning through it to try to figure out what did this program do?  Thanks to the sandboxing technology, which is file based, after you run something, like I've been running Eudora in its own sandbox for a while now, I can - and Ronen provides through the Sandboxie user interface the ability to explore all the things that have been going on in the sandbox.  It's a tree-structured file system.  So you can just - you can open up your C: and your Windows and your system and, like, explore through and see what things have been modified because any modifications that would normally be made to your system are intercepted, and they create the modified files in the sandbox.  So it allows you to literally do like a forensic exploration of every single thing that has happened in the sandbox during its lifetime.



There's also the notion of persistent and transient sandboxes.  That is one of the options, and it's the one I've got set up for Firefox, is when I close Firefox the sandbox contents are deleted.  So any accumulation of debris from surfing, it might be malicious, it might not, but any accumulation is just completely flushed every time I close the last instance of Firefox running in the Firefox sandbox.  But you may have an application where you want more persistence.  For example, imagine that you wanted to create, like, a private, a very secure surfing privacy area.  Well, you're able to define and create different sandboxes.  You name them.  And so I've got a Eudora sandbox, a Firefox sandbox.  You could also create, like, a private surfing sandbox.  And Sandboxie allows you to define where the sandbox lives, that is, on what drive it lives.



So one of the examples, and this is being done by Sandboxie users, is they'll use TrueCrypt to create an encrypted area of the drive, of your drive, as a drive letter.  You can then aim Sandboxie at that drive letter.  And that means that everything done in the sandbox is, thanks to TrueCrypt, is encrypted as it's being written and decrypted as it's being read.  So at no time is anything permanent being done on your hard drive that could ever be recovered by anyone doing any kind of forensic analysis.  So it allows you to create, thanks to TrueCrypt, not only do you have this notion of transience, but you could set up the sandbox to be permanent.  And in fact there's an option to prevent its inadvertent deletion.  So you can turn that on, and you won't be able to delete it unless you go through a bunch of, yes, I'm really sure sort of jumping through hoops involving turning that off and then confirming that you want to and so forth.  And that would allow you to create an environment where any programs running in this privacy enforcement sandbox, they don't - they're not special programs.  They don't know - they don't use encryption.  They don't need to use encryption.  It might just be like a photo album, for example, where for whatever reason you want photos through your photo album that absolutely only you have access to.  And since you've got TrueCrypt, you'd have to, in order to get access to that sandbox, which is running in a TrueCrypt drive, you'd have to provide the TrueCrypt password in order for that sandbox to have any opportunity to access that drive.  And then from then, any programs you run within that privacy enforcement sandbox get all the benefits of absolute privacy enforcement and the use of TrueCrypt, even if they're not aware that they've got this going on.  It's completely transparent for them.



LEO:  Wow.



STEVE:  I mean, it is a universal, very powerful security enforcement appliance.  The one thing that he talked about that I want to reiterate is I will say that it takes some time to sort of bring yourself up to speed.  When I was first using it, and I created a PDF, I got an error from Adobe Acrobat. complaining that it was unable to create the PDF.  And I thought, okay, what do I do about this?  So I did some looking around.  And he provides all the tools for basically analyzing what the problem was.  There's a log that Sandboxie - that you're able to open when you do something that goes ouch.  It'll appear in the log and show you what it was that was blocked.  And then Ronen provides, through the user interface, the ability to, for example, give access down a certain path on the hard drive to a file, or to allow interprocess communication, an IPC event.  And so the tools are there, although they're a little tricky to use yet, which is why - what we heard him say was that he wants to make that process more automatic so that you would just check, oh I need Adobe PDF.  You would just turn on a checkbox in a sort of like a compatibility list.



But what's cool is we're not dependent upon Ronen to provide that in the future.  All of that exists now, though it does require a little bit of experimentation in order to understand basically how the system works.  So I would say that it's not trivial to use, but it is something that you could set up for someone.  And after you made sure that they could print and that they could do the things they want to, it is sort of a set-it-and-forget-it.  The way Sandboxie functions, one question I forgot to ask him, but I already knew the answer to it, is could this be set up in a portable mode.



LEO:  Oh, yeah.



STEVE:  Could you have Sandboxie on a USB stick, for example?  



LEO:  Wouldn't that be cool, yeah.



STEVE:  Unfortunately, in order to pull this off, Sandboxie is a driver that requires a reboot of your system.  It's a kernel driver...



LEO:  That makes sense.



STEVE:  Yes.  And there's a service running in the background.  Because, for example, one of the things you can do is you're able to say, and I have, don't ever allow Firefox.exe to run outside...



LEO:  Without Sandboxie.



STEVE:  Yes, without sandboxing.



LEO:  That makes sense.  You'd had to - because you have to catch calls.  You'd have to be running as a service or a driver in the background.



STEVE:  Yes.  It is a low-level piece of technology.  I mean, basically he's sunk his hooks into the OS.  It is Vista compatible.  I'm running it under XP.  He sunk his hooks into the OS so that, for example, he's catching an executable starting.  I don't have to, like, have some funky shortcut or something to, like, get Firefox to run in a sandbox.  When the system - when Sandboxie, which is down in the kernel, sees Firefox.exe starting up, knows to insert it into the Firefox sandbox, or to create one because now I've got Firefox sandbox set up to be transient so that it just deletes it after my last use of it closes.



LEO:  Ironically, he's using a lot of the techniques that bad guys use.



STEVE:  Oh, yeah, I mean, it is...



LEO:  We should have asked him.  I didn't think of it until now.  But we should have asked him, where did you learn to do all this?



STEVE:  And one of the other cool things, it sort of shows his roots, all of the use of that configuration UI, it all boils down to a single sandbox.ini, a sandbox.ini config file.  So you're able to take your mature configuration and easily copy it to another system.



LEO:  That's nice.



STEVE:  And thanks to his licensing, a license is a lifetime license for all of the past and future of Sandboxie.  And you're able to run it on all the machines that you own.  And I mentioned also earlier, I just want to say it again because it was a neat - I'm still having to get used to the fact that I've got this level of security now because last night someone sent me a PowerPoint that they were passing around the Internet.  It was some Einstein quotes PowerPoint.  And it's like, okay.  And it's funny because I had configured my Eudora - I'm using the Eudora email client.  I configured my Eudora sandbox to only allow it and Firefox.exe.  And I didn't even know about Firefox, but I clicked on a link in email, and I got a notice saying, whoops, Firefox.exe has no permission to run in the sandbox.  And I thought, oh, that's right.  So I went over to the UI, and I added Firefox.exe.  Then when I clicked on a link, Firefox ran just fine because it was running in the Eudora sandbox.



So earlier this morning, when I clicked on this Einstein.ppt, this PowerPoint file, I got a little popup that said powerpnt.exe does not have permission to run in the sandbox.  It's like, oh, that's right.  So I added that to it.  So there is some, just very much like with a software firewall, where over time you need to give it the permissions that you choose to give it in order for it to understand who you are and how you want it to operate, there's that same sort of evolution of the settings of your use of Sandboxie.  But now, as a consequence, I did click on the link, and PowerPoint opened.



Now, PowerPoint was opening in the Eudora sandbox.  Meaning that no matter what this did, if there was an exploit, like even an unknown exploit - and this is the point of where this is the way I want to operate, rather than relying on an AV program to, like, scan the Einstein.ppt file on the way in to see if it contains something malicious.  The problem, of course, is that necessarily AV patterns lag behind.  So what I've got now is better than that because, if there was an unknown vulnerability in powerpnt.exe, and I had just received an exploitive PowerPoint file, and it tried to do something to my system, I'm protected because it's going to be contained within the Eudora sandbox and never get out.



LEO:  Isn't that sweet.



STEVE:  I mean, it is a tremendous solution, Leo, for our listeners who are willing to spend some time.  He takes you through a nice tutorial when you first start using it.  It's a little bit rough at the beginning, so it's not like just completely smooth sailing.  And so there's some learning curve associated with it.  But this is, I mean, it is the most significant security tool I've run across in a long time.  The alternative, as we talked about, for example, is a heavyweight virtual machine.  And, I mean, I've got VMware installed here.  I'm not running my browser in it because it's just too clunky.  It's too heavyweight.  I want to run my browser in my operating system where I can easily move files in and out of it, and I can click on links and do things and not have that in my way.  And a virtual machine, as we've talked about before, requires a commitment of a block of your system's RAM while it's running because it's unable to share RAM with the main system.  And you need a second copy of your OS, and you need your various applications all installed in there, too.  And then you've got to keep them all up to date.  The beauty of Sandboxie is that it is running with your existing OS, no heavyweight virtual machine, no precommitment of RAM while you're using it.  It's just it's not in your way, but it is preventing things from getting out of containment.  It's just a tremendous security solution.



LEO:  Of course writing it requires a great understanding of the deep guts of Windows.  And it's not...



STEVE:  Oh, yeah.



LEO:  It would be nontrivial to port it to other operating systems.  But boy, I think it'd be great to have something like that on other operating systems, Mac and Linux as well.  It'd just be really useful.  But maybe now that the idea is  out there, somebody will do it.



STEVE:  Well, we've got it for Windows, which is where I am and where a lot of our listeners are.  And again, it is - you can download it.  You can use it for free for 30 days.  After that there's some sort of - after 30 days, if you continue using it without registering it, there's some sort of an annoying popup.  I've never seen that.  There are a couple additional features which you get with registration.  He's got some, I mean, as much as I've just talked about this, there's a bunch of stuff I haven't talked about, like you're able to turn on automatic CD and DVD protection, so that anything that runs from your CD or DVD drive is automatically sandboxed.  And so there's like a whole bunch of other cool little features which are the kind of things you see in a truly mature product where people have said, hey, what about this, and Ronen says, oh, I like that idea.  And there it is a week later.



LEO:  I'm so glad he can do this full-time because that's what it takes.



STEVE:  Yes.



LEO:  That's really great.  Really great.



STEVE:  Yes.  I mean, I have a new security tool which I recommend without hesitation, with the only caveat that it's going to take a little time to kind of get comfortable with it, to understand how it's changed your system.  But once you've done that, once you've made that investment, what you've got is something that truly protects you in a way that nothing else we have, except creating an entirely separate virtual machine and doing everything in a virtual machine, this is a much easier, not in-your-face, light way to get that level of protection.  And I can't recommend it highly enough.



LEO:  Yeah.  Well, thanks for highlighting it.  It's funny, we've been talking about it for a couple of years at least.



STEVE:  Now we really know what it is.



LEO:  And now we know the details, and we got to meet Ronen, which is really cool.  As usual, Steve, you do a great job of bringing this all to light and sharing it with the world.  And I hope many, many, many, many thousands more people will be using Sandboxie.  Of course...



STEVE:  And I hope so for their sake, not even for Ronen's sake.  I mean, this thing is an honest-to-god serious computer security tool.



LEO:  And so far I've been using NoScript for another half hour, surfing around.  You're right.  Turning off the notifications seems to make it quite a bit more usable.



STEVE:  Oh, it ought to be turned off by default, yes.



LEO:  It's a significant difference.



STEVE:  It's really, well, we'll see how you last, Leo, with it, because I'm...



LEO:  I can't even tell it's running now.



STEVE:  Yeah, exactly.



LEO:  Yeah, yeah.  No, that was definitely the thing to do.  And I can live with the 1-Click kind of giving me a warning, what the heck.



All right, Steve.  We are going to wrap this thing up.  We do invite everybody to check out Steve's website, GRC.com, if you would like to know more about the subject.  We've got of course, show notes, transcriptions of every show, 16KB versions for those of you who are bandwidth impaired.  And there's lots of other great stuff, including Steve's great security forums.  That's where to go, by the way, to pose your question.  If you want to ask a question for our next episode, GRC.com/feedback is the place to go.  Hi, Steve.  Are you waving at me?  Hi, Steve.  And, let's see.  Oh, don't forget, SpinRite's there, too, as well as many great free programs Steve makes available.



STEVE:  Colleen's favorite new utility.



LEO:  Yeah, no kidding.  I'm going to have her start doing the ads for SpinRite.  She just loves it.  And that's about it.



STEVE:  Talk to you next week.



LEO:  Don't forget, you can catch this show and all of our programs free on iTunes.  Just search for TWiT in the iTunes store.  They're all free, and there's lots of great stuff, including Security Now!.  We'll talk to you next week, Steve.  Thanks very much.



STEVE:  Okay, Leo.  Thanks.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.












GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#173

DATE:		December 4, 2008

TITLE:		Listener Feedback Q&A #55

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-173.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 173 for December 4, 2008:  Listener Feedback #55.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that looks at security, now.  Right now.  Right this minute.  Steve Gibson is here.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.



LEO:  From GRC.com, the man who discovered spyware, coined  the term, created the first antispyware program, has written so many useful security utilities like ShieldsUP!, Shoot The Messenger, Unplug n' Pray.  And every week we talk about the latest security news and answer questions and also kind of explain, I think you're really good at teaching, what all this is.



STEVE:  One of our questions this week reminded me that I also wrote the very first personal firewall leak testing utility.



LEO:  That's right, which was called, cleverly, LeakTest.



STEVE:  It was called LeakTest, not surprisingly.



LEO:  That's right.  And they are now, yeah, everybody's doing it now.



STEVE:  There's a bunch of them now, yeah.



LEO:  All right.  Now, Mr. Steve Gibson, is there any security news?  I think there is.  I've seen a lot of stuff.



STEVE:  Oh, Leo, there's a bunch of stuff.  I wanted to mention, we talked in October, so that would have been a number of our episodes ago, about Microsoft's uncharacteristic out-of-cycle patch, which they did because they discovered that a zero-day vulnerability - that, remember, is one where someone is seeing traffic that seems to be odd, and it's in the wild addressing a vulnerability which is not at that time known.  So this was something in the so-called "server service," the RPC, the remote procedure call in the server service of Windows.  And it uses port 445.  And so there has been since this time a spike in port 445 traffic because there are now some worms and bots that are spreading and successfully spreading to exposed and not-yet-patched Windows systems.  There's a word - a word - a worm called Conficker.A and a bot program, IRCBot.BH, which have both been seen using this vulnerability to spread themselves.



LEO:  Oh, boy.



STEVE:  Interestingly enough, the worm goes in and fixes the bug.  It patches it in RAM to fix it after it enters the machine so that nobody else can get in using the same exploit and kick it out of the machine.  So it sort of locks the door behind itself after it gets in safely.



LEO:  Wow.



STEVE:  So I did - and I don't know whether the worm is using completely random IPs because I haven't looked at it closely.  The best strategy that has been used in the past, and this was the case with the major worms that we had several years ago, was that the agent would be combining looking at local network addresses, that is, IPs near it, and also IPs far away from it.  The reason that's significant is that port 445 is the traditional Windows file and printer sharing port.  It's blocked by many ISPs just for this reason, to protect their own customers from this, and because you really don't expect to see people deliberately doing file and printer sharing of their machine's resources out over the Internet.  Now, thanks to ISPs blocking this port, you can't even if you wanted to.  And of course we would certainly think that any router would be blocking it, and any firewall, and any corporate-scale firewalls.



But the reason worms will still use local IPs is that, if one managed to get into a machine, then it would like to propagate itself within the local network, not only out across the Internet, trying to find other vulnerable machines on the Internet because, if you did have a single router protecting a LAN, or a corporate firewall, for example, protecting it, but within the network you were doing lots of filesharing, and so you had holes poked in all of the individual firewalls that exist on the machines within the LAN, then something bad could be propagating locally.  So it's still a concern.



I just wanted to bring it up.  I think it's an interesting note for our users, but also it's something you definitely want to make sure you're patched.  I mean, these are unpatched machines which, for whatever reason, still exist on the Internet.  And it may well have been, for example, IT personnel who are not applying out-of-cycle patches, even though the fact that it is out of cycle implies that it's something you really need to take a look at, otherwise Microsoft wouldn't have done this because they know how much it upsets the IP, I mean the IT personnel.



LEO:  Yeah, yeah.  That's [indiscernible] change.



STEVE:  We also talked, might have been last week, about this Vista kernel crash which Microsoft has decided - actually they decided they're not going to patch it.  They're going to let it go to a service pack, wait for the next service pack because they're not feeling, at least as of the time that they are talking about this, that this represents such a big problem.  You'll remember that you need to be an admin or have network operator rights on your non-admin account.  It's an inherently, as far as anyone knows, a local sort of attack that allows a kernel potential remote code execution, although that has not been demonstrated.  Anyway, what has surfaced in the meantime is a very simple route command that anyone who's interested can type at a command prompt that will crash your Vista machine.



LEO:  But they have to be at the term- they have to be at your machine.



STEVE:  Right.  Or have a way...



LEO:  I mean, I can crash your Vista machine without typing anything.  I just punch the box.  I mean, if they have access to your machine.



STEVE:  So it's route space add space 1.2.3.4 slash 240 space 4.3.2.1 [route add 1.2.3.4/240 4.3.2.1].  And if you give that route add command, that turns out that that's an illegal subnet mask for the network that was just defined, and it causes this overflow to occur in the kernel and crashes Vista.  So Microsoft says, well, we don't care.  We'll fix it in the next service pack.  So...



LEO:  It's an ugly bug, but not really a real security threat.  It's a bug.



STEVE:  Okay.  It's a bug.  And it's a bug until it's a security threat, Leo.



LEO:  So it presents, you think, a potential for a security threat.



STEVE:  Well, yeah.  I mean, all of these things, for example this worm, this worm RPC server service, it started as something that would crash the service.  And then they figured out how to turn it into executing code of their choice that was part of the packet that was arriving at port 445.  So all of these things, I mean, you need to really understand them to know if they can't be turned into a remote code exploit, it certainly would be mischievous, for example, if email was crashing your Vista machine.  An email could certainly give that command.  So that's bad.



LEO:  Right, right.



STEVE:  Anyway.



LEO:  No, that's a good point.



STEVE:  Yeah, I just thought that users would get a kick out of knowing, you know, "route add 1.2.3.4/240 4.3.2.1," hit Enter, and that's - it's over.



LEO:  Yeah.  I suppose you could attach that as a Windows scripting host command.



STEVE:  Yeah, precisely.



LEO:  So you could send somebody an attachment that would crash their machine.



STEVE:  Yeah.  Someone you don't like very much.



LEO:  Yeah.  Although you could also send them - I would think you could send a program that would crash the machine.  Maybe not.



STEVE:  Yeah.  Very good point.  If they executed a program, well...



LEO:  It's harder than it used to be.  Used to be you could write to ring zero and stuff.  Now you can't.  So it might be harder to blue screen a machine than it used to be.



STEVE:  I wanted to update our listeners that TrueCrypt, the program we love, and I think we have a Q&A about it later on, has been updated to version 6.1a.  All users of TrueCrypt are encouraged to upgrade.  They fixed random little scattered bugs around, nothing terminally critical, but it's better to have these things fixed.  And they've also added a feature that I really appreciate.  They've given you the ability now to override the default logon screen when you use the whole drive encryption and are being prompted for a password at boot time.  Normally, it used to be that you just had this sort of this very uninteresting screen that you had no control over.  And they decided, oh, let's let people either blank that screen and/or replace it with their own.  So there's now a mechanism for doing that.  So it allows you to sort of customize your whole boot encryption experience when someone turns a machine on and is presented with, essentially, the need to log themselves into the system.  So I thought that was neat.



In a really interesting and sort of freaky story, some students who were screwing around - I'm trying to think, oh, it was University of California.  Using state-of-the-art standard digital photography and computer modeling, they have demonstrated that they can duplicate a key, a traditional house key, for example, from 200 feet away by taking a picture of it.



LEO:  200 feet away.



STEVE:  200 feet away.  They can take a digital photo of a set of keys and...



LEO:  So you kind of hide your key in your hand when you use  your keys.



STEVE:  Isn't that interesting?  I thought that was just a - it just ran across my radar, and I thought, oh, that's just too neat.



LEO:  There was a demo at DEFCON where they could take a picture and then, you know, cut out a key.  But 200 feet is quite a long distance.  Do they have super telephoto lens and special cameras?  Or was this just a regular old...



STEVE:  I think it's, I mean, what I like about this is, at its core, I mean, sort of irrespective of the details, it sort of highlights something that we've taken for granted.  And that is, you know, you and I cannot look at a key and go home with a file and file a blank key down into that size.  But computer technology, digital technology, digital photography and, I mean - certainly this key that you take a picture of, it's probably going to be rotated and off-axis.  It's not going to be exactly face-on the way you want it.  You know, the technology now exists to model it from the photo, rotate it, and end up driving an NC machine to grind yourself an exact duplicate.  So, yeah.



LEO:  Wow.  Wow.  That's really amazing.  So you only need one side of a - I'm looking at my keys.  Maybe keys should be more three-dimensional or have double-sided things.



STEVE:  Well, of course a lot of fancy car keys - we went through the pre-electronic car key phase where there were keys that had, remember, like different depth holes cut in them, and the...



LEO:  Those would be hard to duplicate.



STEVE:  ...[indiscernible] car has got, like, a wiggly slot down the side.  Although it turns out that all of that is just sort of to prep the electronics because it's actually an electronic handshake in many car keys today.  So...



LEO:  Yeah, I have a chip in my key.  You couldn't duplicate the metal and get into the car.



STEVE:  Right, exactly.  Although, you know, traditional house keys and keys that are just, we'll call them "dumb keys," apparently you can, from quite a distance away.



LEO:  Now we have smart keys and dumb keys.



STEVE:  Apple, for the first time ever, posted an advisory telling their users that they recommend the use of antivirus software.



LEO:  And then did a funny thing.



STEVE:  It was on one of the support pages of Apple.  They said...



LEO:  Yeah.  And then they pulled it down.



STEVE:  Yup, they said use McAfee, Symantec, or Intego VirusBarrier were the three that Apple specifically recommended.  And so it got picked up by the news.  It's like, oh, look at that, you know?  Apple has long enjoyed sort of this we don't - "we're not such a big target" posture.  But it is the case that increasingly, as the people who generate these sorts of exploits also have Apples - and as we've said, you really can't make an exploit for a machine you don't own.  And of course as Apple has acquired a larger market share, prices have come down.  The people who do these sorts of exploits have them now.  And so we're beginning to see this kind of trouble.  And certainly McAfee, Symantec, and Intego have jumped on and said, okay, we've got AV for the Macs, as well.



LEO:  You didn't mention, but that bulletin was pulled down shortly after they put it up.



STEVE:  No, I didn't know.  No.



LEO:  Yeah.



STEVE:  Oh, okay.



LEO:  And I think, well, I think that what happened, the marketing department freaked out, said wait a minute.  That's one of the things we say is we don't have viruses.  You better pull that down.  And it wasn't in response to any particular threat.  But it's good advice, of course.



STEVE:  Yeah, exactly.  And speaking of which, I wanted to make sure that people who are iPod Touch and iPhone users have got themselves updated.  Probably it's been pushed out.  But anything prior to version 2.2 has web-based remote code execution problems, which Apple has fixed with version 2.2 and later.



LEO:  Okay.



STEVE:  And lastly, or actually two last things relative to Phorm.  We've talked about Phorm many times, the pretty horrible ISP background monitoring, behavior profiling, and actually stuffing cookies all over your system and in theory inserting their own ads onto web pages.  In a very controversial move, British Telecom, BT, who has been at the center of this controversy because they were secretly hosting Phorm technology for proof of concept in trials without notifying their customers, well, there had been traditionally lots of activity on their boards, on their customer service forums about this.  Well, they, a couple days ago, formally changed their policy, said no more discussion of Phorm will be hosted here.  And they deleted all the previous threads of content that had been there.  And that sort of raised a bunch of eyebrows.  It's like, wait a minute, what's going on?  I mean, people are calling this censorship and getting themselves bent out of shape.



LEO:  Very good.



STEVE:  And on that note, yes, on that note I wanted to mention that there is now a Firephorm add-on for Firefox.



LEO:  Firephorm.



STEVE:  Firephorm, F-i-r-e-p-h-o-r-m.



LEO:  Ah.  And does it block Phorm?



STEVE:  You'll find it - yes.  Reading from the description here, it says "Firephorm is an extension for users of ISPs that deploy the Phorm Webwise system.  It can add Phorm opt-out cookies to web page requests to avoid storing a Phorm tracking cookie for each website you visit.  It can avoid Phorm Webwise.net, redirects and protects your preference to opt-out from being overridden.  If your ISP deploys Phorm's Webwise system, then we strongly recommend changing" - oh.  And they say, "Aside from that, if your ISP deploys Phorm's Webwise system, then I, the author, strongly recommend changing ISPs as soon as possible."  So we don't like this, but we do have an add-on that you can use under Firefox that will make it lots more tolerable.



LEO:  Yeah.  Great.  Awesome.



STEVE:  So two bits of errata, Leo.



LEO:  You mean we made a mistake?



STEVE:  I have a note - no, I have a - just, well, it's not really errata, but it's non-security news.



LEO:  Okay.



STEVE:  I have a note here to ask you about NoScript.  How are you doing, a week later?



LEO:  I took it off.



STEVE:  Okay.



LEO:  I took it off.  I did get a note from the NoScript folks who had actually, and I'll probably put it back on, an interesting suggestion.  I'm in a different category, though, than the average user.  I have to - I look at sites and report on those sites.  So I have to see the site in its full experience.  Otherwise I can't give it a fair review.  So, you know, if I were an everyday user I would absolutely use NoScript.  And clearly the security benefit is great.  And maybe you already are going to say this.  But one of the developers of NoScript sent me a note, Mark Zipp is his name, and he said - because I had mentioned that I was worried about missing parts of a website.  He said in the NoScript Options General section there's a box labeled "Temporarily Allow Top-Level Sites by Default."  And he says, "Then try one of the radio buttons below.  I use full addresses.  This is allows any script being run by a full address."  So I'm going to try that because that will give me the full experience automatically, but I guess gives me some level of scripting protection because any subdomains are turned off.  You could even get more promiscuous and turn off base second-level domains.  Do you see what I'm saying?  So...



STEVE:  Yup, I do.



LEO:  Was this the note you were going to talk about? 



STEVE:  No, although, okay, well, because I just was curious whether or not, I mean, I didn't know what your answer was going to be.



LEO:  How about you?  What's your experience been?



STEVE:  I'm happily using it and plan to keep using it.



LEO:  I think if I weren't a journalist looking at sites and reviewing them, I would be much more likely to use it.



STEVE:  Yeah.  The only caveat is you need to sort of in the back of your mind remember that it's there - that it's there, you want it, and it's protecting you - because you will go to sites where it doesn't seem like everything is on the page.  And it's like, oh.  And it's trivial to either temporarily allow it, if you don't think you're going to come back.  That way you're not clogging up your system in general.  But if it's a site you use a lot, it's like, oh, okay, and you just give it permission, and then everything's back to normal.  So I just think it's a great utility.  I mean, remember that I was using something like this for years under IE, using IE's zone system, where I was - and we talked about before I switched to Firefox, that's the way I was operating.  So I'm a little more accustomed to this notion.  And as we know, I'm seriously anti-scripting.



LEO:  Right.  I'll tell you what happened.  I went to a site, I think it was during a show, to look at a site, and parts were missing.



STEVE:  Oops.



LEO:  And I forgot that I was running NoScript, and I started talking.  I said, well, wait a minute, I'm not seeing - and then I realized, oh, wait a minute.  And so it's just it's too risky for me to be running it and not get the full experience.  That's just the risk, part of the risk I pay for bringing you content.



STEVE:  And my final note is I have an update on one of my favorite sci-fi authors, Michael McCollum, who does the Sci Fi - AZ site.  Remember that a couple months ago I mentioned that I was excited that the third book in the trilogy, the Gibraltar Trilogy, which will be called "Gibraltar Stars" - he has "Gibraltar Earth," "Gibraltar Sun," and "Gibraltar Stars."  I finally sent him a note because he'd sent me something back in May, actually, and I'd had it pegged to get back to him.  And I wanted to offer my services as proofreader because I would love to get my hands on the third of that trilogy.  And so he says he'd love to have me proofread the book.



LEO:  Cool.



STEVE:  But what he also said was he said he's been experimenting with the Natural Voice system.  Oh, and by the way, he's completely Kindle-ized.  I also wrote to him about all my recent experiences with Kindle.



LEO:  Well, you helped him a lot with that, I know.



STEVE:  Well, actually that was back...



LEO:  Oh, you helped him with Sony.



STEVE:  Sony, yes, that was the LRF format, the Sony format.  Since then he bought his wife a Kindle this summer, and he said she's bankrupting him with all of the books that she's buying.  But she absolutely loves it.  He loves the fact that it's got a built-in web browser in it.  And so he now has Kindle versions of all of his eBooks, which excited me a lot.



LEO:  Now, do you buy them from Amazon, or do you buy them from his Sci Fi - Arizona site?



STEVE:  Just directly from his site.



LEO:  I didn't know you could do that with Kindle.



STEVE:  Yes.  Oh, yeah, you're able, absolutely, to use any - it's the Mobipocket format.  I can't remember what the file extension is [.prc].  But...



LEO:  If you download it, do you go to his site in the Kindle browser?  How do you get it on the Kindle?  Do you email it to yourself?



STEVE:  You probably - you could do it in any of the ways that you can.  For example, you could email it to yourself.  You could just download it and then just dock it with your computer and move it over.



LEO:  I have never docked my Kindle.  Not once.



STEVE:  I did once to sort of explore it, to see what the format was of memory and so forth, and to look around.  But and I think once there were some clippings that I had that I wanted to get off of it.  And so I used that in order to pull them off.  But you're right, I mean, it's been more than a year now, or about a year probably, since I first got it.  I got it in early November of '06.  And so, and I don't know if you know, but they are once again sold out.  There are 10 to 11 weeks of backlog.



LEO:  You know what that means.



STEVE:  Probably because Oprah loves it, so...



LEO:  No, Kindle 2, I think.



STEVE:  Ah.



LEO:  Yeah.  All the rumors are Q1, Kindle 2.  And the 11-week backlog just or about gets you right to where you'd want to be if you had another Kindle coming out.



STEVE:  Yeah, that's true.



LEO:  So actually more power to Amazon because what they could have done is sold all those people Kindles, Kindle 1s.



STEVE:  And then you'd be really upset that you got - that you missed - yes.  Sort of like Apple does all the time.



LEO:  Everybody does that. That's normal.  That's the normal way you do business.  You want to sell those old devices right up to the day you introduce the new one.  And so if that's, in fact, what Amazon's up to, credit to them for doing that.



STEVE:  Well, and so what Michael has done is he thought, you know, there's one more format that I haven't tried, and that's audio.  And so he is, for the Gibraltar series, he is using Natural Voice's Paul.  Which is - actually it's funny because he and I chose the same voice.  Paul I think is the best one that the Natural Voice people produce.  He also slowed it down by one notch, as I do.  And he's running the text of his books through it in order to generate, in the case of the first book, I think, it's a 12-hour audio file.  And people have told him they would be very interested in purchasing his books in audio format, even if a robot were reading them.



LEO:  Hmm.  Well, we'll see.



STEVE:  And frankly, I mean, Paul is a very good-sounding voice.  I use it for notifications.  If either of my T1s go down, suddenly I hear, in the same way that I have Fred doing yabba-dabba-doo when a credit card clears for SpinRite, I hear "Your primary Internet link has gone down."



LEO:  I think there's a big difference between a robot reading it and an actor reading it.  But we'll see.  You know, there's such a - I think that this comes from people who don't listen to audio books, that they go, oh, it's just somebody reading it to you.  There's a perform- it's a performance.  It's not just somebody, "And now here is book one of...."  It is a performance.  And a robot's not going to do that.  But, you know, if you like it audio, and it's, I mean, god knows it's expensive and time-consuming to have an actor record it - I wish I had the time.  I'd love to do his books.



STEVE:  Oh, you'd be good.



LEO:  Oh, I'd love to do that.



STEVE:  Yeah.



LEO:  Maybe I'll do it in the evening in my spare time.



STEVE:  And that wraps up all my random stuff.



LEO:  Excellent.  All right.  We've got some great questions from our great audience.  Mr. Steve Gibson, are you ready for our questions, brave and true?  Let me see.  Did I close the - I think I might have closed them.  Let me reopen the questions.



STEVE:  The question is, are you ready, Leo?



LEO:  Apparently you are, and I am not.  How about that.  I have them here.  I have them right here.  Really I do.  What Steve does is he goes through the list at - in fact, you can go to GRC.com/feedback and submit questions.  And then you pick questions that are representative; right?  You're not trying to get just one - often it's the question that you hear the most; right?



STEVE:  Yes.  Very often I'll see it over and over, and it's like, oh, okay, fine, I'll, you know...



LEO:  Yeah, I'd better answer this, yeah.  We'll start off with Art, shall we?  He posted this in the newsgroups.  Little different.  Another great way you can participate.  He asked about Sandboxie.  We talked about it last week, about their help with people bringing USB drives into their organization.  You know, the Pentagon just banned USB drives.



STEVE:  After a major breach.



LEO:  Yeah.  And he explained that they had had lots of trouble implementing this and wondered whether there might be any way to sandbox USB drives.  Are there, is there any way, perhaps, to do that?



STEVE:  There really is, it turns out.  There are many features of Sandboxie that we didn't go into in detail because, I mean, I could just have bullet points for a whole show.  But one of them is a forced drive or directory.  And it's used, for example, and Ronen suggests, for example, that you could put the drive letter of your system's CD/DVD ROM in, and it would automatically sandbox the autorun so that anything that runs from your CD/DVD drive is automatically sandboxed and has no opportunity to make permanent changes to your system.  Well, similarly, in the case of a USB drive, since the drive letter can tend to float around a lot, what I would do if I were serious about this is I would put every letter in there.  And you can make a list of these so you're not restricted.  Put every letter in there that isn't assigned permanently to a drive or a share.  And what that would mean is when someone sticks a USB drive on, and the system assigns it a drive letter, anything that you run from there is automatically sandboxed.



LEO:  Wow.



STEVE:  So it's another of many features that's in Sandboxie.



LEO:  Would that then prevent any form of infection?  So if it's malware that's being run, it couldn't expose itself?



STEVE:  Well, our topic for next week is what are the limitations of virtual environments, like full-on virtual machines and Sandboxie.  I didn't want to - I realized in my excitement, which is genuine, for Sandboxie last week, I may have sort of oversold what it can do.  But so what it does, it does really well.  But it's not to say that you have nothing to worry about for the rest of your life, even if the sandboxing were perfect.  There are still things that can go bump.  And so that's what we're going to be talking about next week.  But for this sort of thing, for example, just making sure that anything that might be run from a plugged-in USB drive or from a CD that is run, it's easy for Sandboxie, which is a service and a device driver, I mean, it's really down in the kernel, sitting there watching so that nothing has a chance to get around it, it does have that feature just sort of built in.



LEO:  Well, and you remember I did ask him a little bit about how it relates to virtualization.



STEVE:  Right.



LEO:  And he was clear that it's not the same thing.  It's a different kind of thing.  But it clearly can be used.  I'll look forward to next week.  That'll be interesting.



Louis Gerard in Montreal confirms another listener's report about wider PayPal authentication availability.  He's in Canada.  He writes:  Hi, Steve. Following up on your last episode, I successfully ordered my PayPal Security Key in Canada, too.  10 business days.  $5 Canadian.  That's actually less than what U.S. users pay, he says, 20 percent cheaper.  Did the Canadian dollar go down that much?  Wow.  So, great.  I use mine.  I love it.



STEVE:  I just wanted to confirm, again, this is representative of a bunch of email that we received from people saying, hey, thanks for bringing this back to our attention.  We're Canadian, and - eh?



LEO:  Eh?  Don't say that.  They hate that.  Especially if they're from Montreal.  They don't say "eh" in Montreal.



STEVE:  Oh, okay.



LEO:  They say [grunting].  Meanwhile, Jon Peter Hansen, not having any luck getting the football.  Hi, Steve and Leo.  I'm unable to order a PayPal football.  When I click to order it, I get "The Security Key is currently not available, please try again later" message.  This could mean they're just out of stock because they got Security Now'd.  But I think I read somewhere that it was only available in the U.K. and Germany.  I'm not sure where Jon Peter is; but I'm thinking Scandinavia, perhaps?



STEVE:  Based on his name, Jon Peter Hansen, sort of sounds  Scandinavian.  So it does sound like they are rolling them out, that they are expanding the geographic coverage.  I think it was originally the U.S. and the U.K.  I know that there was a second region outside the U.S.  Maybe it was Australia?  I don't really remember now.  But I think there were two regions.  And certainly we know that Canada was not supported because we have a lot of Canadian listeners, thanks to your exposure through TechTV.  And they were like, wait, I can't get it up here.  So now they can.  And in general, I guess it was when we talked to - did we have someone on from VeriSign?



LEO:  We did.  Yeah, yeah.



STEVE:  And he was explaining that they just sort of have to do this incrementally.  Their goal is to have it available anywhere PayPal is.



LEO:  We love this.



STEVE:  But, you know, they're rolling it out one country at a time.



LEO:  The idea being when you log into PayPal, you press the button on the key, and it generates a one-time-use number that you add to your password.  And unless somebody knows your password and has this key, they can't get into your account.  So that's really great.



STEVE:  And I have to tell you, it is so comforting, Leo.  I've been active lately, doing some PayPal stuff.  I mean, 'tis the season, as they say.  And to have to provide that, push the button, give them your code, it's just it's the right thing.  It's non-burdensome.  You really wish that this was the way everything, all authentication net-wide, was up to speed and using because it would solve so many of these problems with keystroke recording.  And we're going to be hearing about that, too.



LEO:  Yeah, yeah, I agree.  I'm a big fan.  Although I have a feeling that the hardware devices like the VeriSign card or the football may end up being superseded by things like my bank uses SecurPass where they send a code to your cell phone.  Everybody's got the cell phone.  It's a lot cheaper for them to do that.  And that has the same security because they have to verify that it's your cell phone number.  You have the cell phone.  Right?  That would be equally as secure.



STEVE:  Yes.  Yes.



LEO:  I love that.  I use that.  I've turned that on on all my - my accountant's not crazy about it because she can't get into my accounts anymore.  But I just turned it on on all my bank accounts.  And the only way I get into the bank account is I log in, and then it says, okay, you need to send your SecurPass.  We're going to press the button, it sends the SecurPass to my cell phone.  I then have to enter in that number, and only then can I get in.  I love that.



STEVE:  Yup, and it is, it's on the list of the authentication technologies that my future little - that my CryptoLink product will also use.  I'm going to support all of this stuff in CryptoLink.  And since it's possible for software to send SMS messages, that'll be one of the ways that you can set up CryptoLink to require you to authenticate yourself.



LEO:  Excellent.



STEVE:  So zero cost there, too.  And of course Perfect Paper Passwords.  So you can just have the little list of goodies in your wallet and use that, as well.



LEO:  That'd be another way.



STEVE:  Yeah.



LEO:  Absolutely.  Jared Burford wonders about maintaining a TPM-protected PC.  He says:  You've mentioned in the past about TPM, fingerprinting authorization and so forth.  While I do agree this is great security - that's the security built into the processor and the laptop hardware security - I see a problem.  What if your computer needs to go in for repairs?  How will the technician have access to the computer if they can't get past TPM?  If there's a way to disable it, then maybe, though I doubt this is possible.  Even so, you still need to access BIOS setup in order to accomplish this.  Your thoughts?



STEVE:  Well, there are a couple things.  Jared should not worry that this is an unsolvable problem.  It has been solved, and in a number of different ways.  TPM, we did a whole episode on it before...



LEO:  Trusted Platform Module?



STEVE:  Exactly.  And it is essentially a little vault which is soldered non-removably to the motherboard of an increasing number of machines.  Laptops typically have it now.  Some desktops do.  And the idea is that, in order for a system to be secure, there needs to be someplace that software can't access, no matter what you do.  Like even if you use a boot CD in order to avoid all contact with the normal OS protections, there needs to be something fundamentally intrinsic that is, like, the last resort of protection.  And that's what the Trusted Platform Module is.  And in fact the way it's been designed is you can't - software cannot, cannot, no software can access its contents.  You can merely ask it to verify things.  So you put data in.  And, for example, there isn't a way to get it back out.  You can only say this is the data I think you have in a secure way.  And it can say, ah, you're right, I do.



So anyway, it's been really well designed.  The UI, the user interface for this always, in every case I've ever seen, gives you a backup.  So, for example, if your fingerprint won't scan, that is, for whatever reason, maybe you only registered one, you're able typically to register your whole - both hands, all fingers of both hands.  So no matter how badly you damage yourself, you probably still have one.  You might even be able to register the back of your knuckle, as some of our users have cleverly done when Disneyland was asking them for their fingerprint, and they said I don't think Dumbo needs my fingerprint.  But the idea is, failing that, you always have the backup of manually entering your password.  Which hopefully is a big gnarly long thing.



And so the idea is that the fingerprint is a shortcut for having to manually enter a big gnarly horrible password.  So what you could do is either give that to the technician, which I'd be reluctant to.  Obviously you would change it once you got the machine back and had it back under your control.  But if you were going to change it, and you had, like, learned or written down the big gnarly long password, you might as well go into the BIOS and change it before to something simple, since you're inherently reducing the security while your machine is out of your control to a hopefully trusted technician.  And so after you do use your fingerprint, or you manually type in your password, essentially that unlocks the machine, and you then have the ability to enter the BIOS the way you normally would by hitting F2 or Delete or F1 or whatever the BIOS entry keyboard sequence is.



So then you'd go in, and you'd have to give it your - in traditional change-your-password mode you'd give it your big gnarly long password, and then you'd give it "hijack" or something, something simple for the machine to have.  And you just tell the technician don't worry about the fingerprint.  When it's asking for the fingerprint, just type in this simple password, and you can get to my machine to fix it.  And then of course when you recover your machine, you reverse that process and put back in your big gnarly long password, which is always your fallback in case the TPM-based biometric system, whatever it is, fingerprint or retina or who knows what, happens to fail.



LEO:  And you would give that gnarly long password to the repair guy.



STEVE:  No, you would temporarily change your machine to a short password.



LEO:  Give it to him, give him that password.



STEVE:  Exactly.



LEO:  Yeah, okay.  Got it.  Got it.



STEVE:  He uses that.  He never knows your gnarly long password.  You don't have to change it afterwards because you've removed it, put in a simple one.  Or maybe you just take it out completely, just shut down the password protection.



LEO:  Right.  You can do that, too.



STEVE:  Yeah, exactly.



LEO:  Okay, okay.  Yeah, I mean, it doesn't make sense.  I mean, Lenovo uses these.  I mean, these are laptops that are corporate laptops.  Doesn't make sense that once you install the password, nobody would ever be able to access it again.  That would be a bad thing.



STEVE:  There is a very good, intuitive, and sort of sane UI which, if you've implemented - basically, your fingerprint is a substitute for your having to manually enter the big gnarly long password.  Which encourages you to use a big gnarly long password.



LEO:  Absolutely.  Absolutely.  I just read a "10 Mistakes That Linux or Unix System Administrators Make."  And one is not having a really gnarly long bad password, you know, tough, tough, tough password for the root.  And never log in as root.  You don't need it.  They said it should be a password so tough that you have to insert the USB key, decrypt the USB key to get to the file where you've put the password and cut and paste it.  That's how hard it should be.  It shouldn't be something you can keep in your mind.



STEVE:  Right.



LEO:  And that makes sense.  Sam in Sweden wants to know how to really kill a hard drive.  Hi, Steve and Leo.  I have a quick question about how to properly scrap old hard drives.  It's not so difficult when the drive is operational.  Then he uses DBAN - we recommend that, Darik's Boot and Nuke - to wipe the disk clean.  Google "DBAN," you'll find that, it's free.  What if the drive has completely died?  Hey, you know, I had somebody call the radio show with this question.  So if you can't SpinRite it, you can't obviously boot and nuke it because you can't mount it.  He says:  I've in the past done all kinds of things such as soaking he drive in various not-so-healthy solutions, physically breaking the drive, done some damage to the drive platters by drilling holes and whatnot.  Is there a quick fix?  Quick way?



Somebody asked me, I'll tag this on, if they could take the drive - actually, you know who it was?  It was Kris Kosach, used to work at TechTV.  She used to work on the music show.  She's married to Alex Wellen, the CyberCrime guy?  She said, can I take my old drive, no longer operational, put it on the - they have a - you know this, Steve, because you've worked in audio - on the degausser that they use to erase audio and videotapes.  It's a big magnet with a conveyor belt.  Can I just put it on the degausser and degauss the drive?  Will that work?



STEVE:  No.



LEO:  Oh, baby.



STEVE:  Degaussing a drive from the outside won't.  You really have to be in intimate contact with the platters.



LEO:  So if you took the platters out and degaussed them, that would probably work.



STEVE:  Yes.  I mean, if you take the platters out, scatter them to the four winds, or the four corners, and you're going to be safe.  What I would do, to answer his question, you can always pull the board off the bottom.  So that's the first thing.  It's easy to do.  I mean, you don't even have to be gentle with it.  You're destroying the drive, so just take a screwdriver to it and pry it off, crack the board off, break it up in pieces.  Now, that's not by itself enough because the boards are interchangeable among drives of the same make and model.  The boards, however, are connected to the inside by a connector.  And that is easy to destroy also.  So destroying the connector, it just looks sort of like a dual inline set of pins.  And you can just sort of scrape it off with the screwdriver.  And that's going to further make it very difficult.



But if you really want to go one step further, and you have access to power tools, and I'm not kidding, simply drilling a hole through the drive, like an inch or two away from where you can tell the disks are spinning, that's game over.  And it turns out that the metals are all pretty soft.  They're aluminum, and so it's not like it's going to take some monster kind of drill.  But if you'd simply drill a hole through, and while you're doing it you might drill a few more, it's going to go through the case.  It's going to go through all the platters.  And there is no way that the drive can mount and fly its head if it's got a quarter-inch hole running through the platters.  And at that point it's pretty much game over.



LEO:  Although somebody like the NSA might be able to use some sort of system to read the magnetic markings on the rest of the platter.  But...



STEVE:  It's true that, I mean, if...



LEO:  That's pretty hardcore.



STEVE:  ...somebody absolutely, desperately had to have it, they could go in, take it apart, fill the holes with something maybe, so that the head would fly across it.  But, I mean...



LEO:  Seems unlikely.



STEVE:  ...it would have to be so smooth.  I mean, and again, the only way you're going to do it is you have to fly a head.  Older drives, there were various things you could do where you could actually view the bits visually by subjecting the surface to various types of polarized lighting.  But with contemporary vertically recorded drives, that's gone now.  I mean, you literally have to fly a head with really good electronics over the surface.  And if you've got some holes in the platters, there's just no way a head's going to fly over that.



LEO:  I think I remember reading that in Britain probably the MI5 spec is they take apart the drive, degauss it, grind it up into a fine powder, and then they don't throw it out.  Go ahead.



STEVE:  Returning it to its constituent atoms is pretty much a good thing to do.



LEO:  And then, they don't even throw it out then.  They put it in a box, and they store it in a safe in the basement, just in case.  That's a little overkill.



STEVE:  Yeah.



LEO:  Not necessary.  That's good.  Drill a hole in it.  And that's an easy - it's actually just a few screws to open up the drive; right?  It's not a big deal.



STEVE:  No, no, don't open it up.  Drill right through it.



LEO:  Oh, go through it.



STEVE:  I mean, that's why I like it, is in terms of, like, reasonable and seriously good, is just take a drill and go [manly drilling sounds] a few times.  And it's over.



LEO:  Now, you'd have to have a drill that could go through metal, obviously.



STEVE:  Yeah.



LEO:  But you just go - so this is the drive platter is that round thing?  And you just pick a place, a spot on the round thing, and you...



STEVE:  Yeah.  Normally on any drive, certainly from the bottom, you can sort of see where the bearings are and that you're going to have the disk platters radiating out from there.  And so just drill a few holes...



LEO:  I love it.



STEVE:  ...an inch or two away.  It feels good.  And believe me, it seriously took care of that drive.



LEO:  We opened up a drive on The Screensavers for a segment on this very purpose, and Patrick was going to show how to destroy the platters.  So he opened it up.  And what he didn't know was that some drives - I didn't know this - sometimes have glass platters.  So he hit the platter with a hammer and went [manly shattering glass sound], and shattered glass flew everywhere.  We were very lucky we didn't get hurt.



STEVE:  Right.



LEO:  So have you seen that, the glass platters?  I thought that was weird.



STEVE:  Oh, yeah, sure.  Yeah.  And although typically they're aluminum.  And if you wanted to, like, disassemble the drive and pull all the platters out, inside you'll find a hub with a whole series of either hex or, in some cases, torque screws.  You take all those apart.  And there might be eight of them.  And then basically the platters will all come apart in your hands.  And you could step on them, bend them, whatever.  But really just...



LEO:  You don't need to do that.



STEVE:  ...drilling a couple of holes through it, it's over.



LEO:  Meanwhile, another Sam, hiding in an office cubicle somewhere, wonders what to do about his boss spying on me, spying on me.  Sam is not, I hope, a pseudonym for Tony in the other room.  Hello, Steve and Leo.  I was wondering which anti-corporate-spyware program you recommend - anti-corporate spyware, hmm - as there is increasing spying going on, both in the office and at home.  I feel my computer is not secure.  I know for a fact some of the companies I work for on occasion - I am an IT consultant - use these kinds of programs - he references something called "Spector," which does sound kind of scary - to spy on their employees.  I just have this uneasy feeling in my gut, and I want to be sure I'm not being spied on.  Is there an easy way to check whether programs like Spector are installed on a computer?  For instance, some program that checks or warns you if something is hooking into your keyboard and monitoring it?



STEVE:  The answer is, unfortunately, no.



LEO:  Really.



STEVE:  We've talked a lot about rootkit technology.  There are a couple bad viruses now that are modifying the boot sector and installing themselves before the rest of the system gets going.  We've talked about Blue Pill, which was Joanna Rutkowska's sort of theoretical and continuing to evolve work on showing that it is impossible for programs to know if they are not operating on the actual native chip, but if they've been virtualized, because in theory there's no kind of test you could perform that you couldn't, as long as you encapsulated the environment appropriately, you know - and she calls it Blue Pill, of course, because it's very much like the famous sci-fi movie "The Matrix," where Neo and company did not know until they broke out of it that they were living in a simulated world.



So unfortunately there is nothing I could say except the following which would save Sam.  And the following is that, if you were to boot one of these entirely bootable from CD or DVD environments, then that would never touch any resources on the machine.  It would, as long as the BIOS is set up to boot first from a CD before it attempts to boot from the hard drive, and that's typically the default case, although you might have a corporate environment which is really bolted down where the CD and USB and floppy have been removed from the boot sequence, in which case you might be able to put that back in if you have the opportunity to get into the boot when it's, I mean, to get into the BIOS when it's booting.  But my point is that the only way I know that you could safely use a machine is if, literally, you booted it yourself from a non-writable media that had preference priority, boot priority, over the hard drive.



And so many of these boot, you know, the pre-boot environment solutions, and they're becoming increasingly mature, I mean, you can boot up a very workable system with networking and browsing and email and everything that runs off of a CD or DVD.  So, Sam, if there was something that you were doing that you needed to really know you were private about, and if the corporate environment wouldn't notice your machine had disappeared from the 'Net for a while, that's what you could do.  But if you just leave it in its de facto booting, and you're not sure what's been installed, it's very possible for good technology to hide so well that it's undetectable by anything you could do as a user.



LEO:  Geez, Louise.  Well, there's a good reason to create a Linux boot CD.



STEVE:  Right.



LEO:  ...and boot from that.  Because even then they can watch your IP traffic.  And they might, I mean, there's also you could put a camera over your shoulder, or we talked last week about Van Eck phreaking the keyboard.  



STEVE:  Right.



LEO:  It's pretty hard not to do that.



STEVE:  Yeah.  So it's better just not to worry about being spied on, and don't do anything at the office that you would not want your boss to see.  Maybe get your work done and, you know...



LEO:  Well, courts have held for years - now, he's a contractor, so it's a little different.  But if you're an employee, you have no rights.  You're using the boss's equipment, the boss's premise, the boss's Internet access.  You have zero rights.



STEVE:  Yup.



LEO:  The boss can do anything he wants.  Doesn't have to tell you.  That's just the way it is.  I mean, I usually tell employers it's good to have a policy, written policy, make sure you explain what you watch, what you don't watch, what you allow, don't allow.  But they don't have to.



STEVE:  Well, and when I've done similar sort of consulting, I've said to people, look, just bite the bullet, put a sign, like a notice glued to the top of everybody's LCD screen...



LEO:  We're watching.



STEVE:  ...that makes it very clear.  This is corporate property.  Your use of this is at the discretion of the corporation.  We reserve the right to log, track, monitor, filter, do anything to all of your use of any sort of this computer.  Just put it there.  And the advantage is everyone's notified, nobody's being discriminated against, and what it will do is it will tend to tamper down, tamp down, any of that kind of behavior that is inappropriate in the workplace anyway.



LEO:  Now, of course, if you're bringing your computer in as a consultant, there's two concerns:  one, that there may be something personal on that computer; but also that they could put something on that computer, and then you go to another business, and they could spy on that other business or even infect that other business.  So it behooves you to have a sanitized computer every time you go to a new client; right?  You want to sanitize it.



STEVE:  Depending upon what you do with the machine while you're there, yeah.



LEO:  Would Steady State or Deep Freeze, Faronics Deep Freeze, one of those programs that kind of, you know, you reboot and everything goes back to the way it was, would that effectively eliminate that kind of problem?



STEVE:  Yes.



LEO:  Okay.  So that might be another way to go.



STEVE:  Although, I mean, depending upon, I mean, it should.  But I don't want to say, like...



LEO:  Well, they may not wipe the boot sector; you know?  They may...



STEVE:  I was just going to say, if you boot something that someone gives you, you've lost control potentially before Windows and Steady State gets itself going.  So...



LEO:  Right, yeah.



STEVE:  ...it can be bad.



LEO:  An interesting challenge for somebody who goes from office to office with his own system.  Hmm.  We'll have to think about that one.  John D - I'm sorry.  Let's go to Patrick in Des Moines, then we'll get to John D.  Patrick in Des Moines needs some clarification about hard drive passwords:  Quick question about hard drive passwords, the issue that was discussed on 171, a couple episodes back.  I'm understanding - am I understanding this correctly?  The only way to thwart a hard drive password - and we were talking about the old IDE passwords, not TPM and that kind of stuff, or the built-in hardware - is via the manufacturer's intervention via a subpoena from a government agency?  If that's the case, wouldn't the contents of any government computer's hard drive - the Social Security Administration, for example - be relatively secure when that computer is lost, stolen, misplaced, or reutilized?  Here's the part I'm unclear about.  If the hard drive that is set to require a password is transferred into another computer that does not support this function, would the drive function, or would it remain locked?  I'm hoping it would not function.  And if that's the case, it seems like this is a simple solution to protect data.  Thanks for a great netcast.  I learn a tremendous amount from every single episode.  That's a good point.  Why doesn't the government lock its hard drives?



STEVE:  Okay.  The issue comes up.  And so I thought, okay, what I should do is to explain what the mechanism is.  And then our listeners, who are certainly smart and alert, can extrapolate for themselves.  The mechanism is that in the API, the application programming interface to the drive itself, you are able to say to the drive, hi there, I'm the BIOS, and here's a password that I'm giving you.  And henceforth I want you to refuse access if you've been reset or power cycled unless I give you this same password again. So that's what it is.  It's not - there's no encryption going on.  It's simply at the interface to the drive something says, hi there, here's a password.  Henceforth I'm asking you to require this password before you will accept any instructions except some basic ones like, you know, the drive ID instruction where it gives you its serial number, make and model, and so forth.  There are a couple simple sort of background characteristic reads that don't contain any user data at all, which the drive is still allowed to respond to.  But other than that, it will simply fail any request it receives with an error that says, sorry, you need to give me the password before I'm going to do anything for you.



So that's what it is.  So to give a drive the password, you typically need BIOS support.  That is, so the BIOS needs to be able to give the drive the password.  But so, for example, understanding that model, Patrick asks, if I were to move that drive to a different BIOS, would the drive remain locked?  Well, clearly it's the drive that's locked.  So the lockedness goes with the drive.  It follows the drive.  And a different BIOS might use a different algorithm to translate the user-provided passphrase into the actual code, the actual digital password that's given to the drive.  So, because there's no real standard for that, that is, the mapping of a passphrase into whatever pattern of binary is given to the drive as its password.  So it might be that, if the algorithm were the same, for example, same make and model of laptop, then you could expect to relocate a locked drive to a different laptop of the same make and model and be able to have the BIOS unlock it when it powers up.  But it's equally likely, and in fact very likely, if you went to an entirely different type of laptop, that that drive would remain locked, and nothing you could put into it that you could figure out to put into it would result in the BIOS unlocking the drive.  So the drive is inert.



Now, and relative to subpoenas and things, what this really means is that the drive at the interface, at the connector point essentially, has been instructed, do not do anything unless we give you the matching password.  That password is written in a maintenance area on the drive.  And so that does mean that the drive gods, typically the drive manufacturer, but also third-party data recovery companies also, have the ability to go in and remove that password from the drive with, you know, with direct access to the drive.  And it's very likely that there are undocumented commands, not publicly known commands that make it easy for, like, the manufacturer to provide some super secret code that would tell the drive, okay, we know you're locked, and somebody gave you a password, but ignore that please.



So I want to explain the difference in security between this and whole drive encryption.  Whole drive encryption means that there is nothing stored on the drive except noise.  And it doesn't matter, you don't even need the drive lock anymore.  It doesn't matter what anyone does.  No force on earth can determine what that data is if it's been whole drive encrypted, given that it's been done correctly and that the passphrase is not known.  So what's there is just noise.  But if it's just locked with a standard BIOS-level hard drive lock, then that lock is carried by the drive, but it can also - the drive can be instructed to ignore the lock, not only by the drive manufacturer, but as I said, by third-party data recovery companies have the ability to do that, as well.



LEO:  They could probably just pull the platters, put it in a new mechanism, and be able to read it.  The data is not encrypted.



STEVE:  Exactly.  The data is not encrypted.  So I don't know whether pulling, I mean, when we say "pulling the platters" glibly, it's very difficult to do that.  I mean, it's...



LEO:  Well, but that's what people like DriveSavers actually do.  They have duplicate mechanisms, and they have a clean room, bunny suit environment, and they can take the platters and put them in a new drive.



STEVE:  What they would need would be they would need different microcode for the drive.  Because if they pulled the platters and put them in a different drive, that drive would obey the lock which is carried by the platters.



LEO:  So it is on the platters, stored on the platters.



STEVE:  Yes.



LEO:  Okay.  All right.



STEVE:  Yes.  And so...



LEO:  So that still wouldn't solve that.



STEVE:  ...for that reason, for example, an easier thing would be just to switch the electronic boards.  If the lock were memorized on the electronic boards, you could just swap it, which is very easy to do, and then have it unlock.  No, it's actually on the platters.  That's what they're using for their permanent storage.  So but you could certainly have microcode which ignores the lock.  And this could come from the manufacturer, or it could be reverse engineered.  So there are ways around this.  But it's sort of at the level of, for example, it's like protecting WiFi with a MAC address lock.  I mean, it would prevent people from casually reading the data, but it's not as good as full crypto, which prevents anyone from ever being able to read the data.



LEO:  I've got a way for you to be even more famous.  You should create the Gibson Scale of Crackability.  And it'd have to be, you know, it's kind of hard because there's things like MAC address versus decrypting a password, I mean, it's apples and oranges.  But maybe you could make it in the number of hours it would take a reasonably sophisticated hacker to crack that, something like that, and create a Gibson scale.  And you could say this is an eight on the Gibson scale, or a two on the Gibson scale.  Would you do that?



STEVE:  No.



LEO:  You'd be famous. 



STEVE:  I don't want the responsibility.



LEO:  You'd be like Richter.  Nobody remembers who Richter was, but they know his name.



STEVE:  They do.  And they unfortunately remember him at times of severe trouble.



LEO:  True, maybe Richter's not the best example.



STEVE:  Yeah.



LEO:  Let's see.  John D in Chicago, IL, poses a great question about cracking decryption:  Hi, Steve and Leo.  With the recent discussions about various encryption/decryption scenarios, I have a general question about knowing when a possible decryption method works.  I think it's fairly obvious to figure out when something like a password crack works by being able to use the password to gain entry into something.  That's pretty obvious.



STEVE:  Ooh, look, I'm in.



LEO:  It worked.  But considering both transmission decryption and file decryption, how does an attacker know when something he or she is trying actually has worked?  For file decryption I assume it would deal with working with the file system and file metadata to determine what something is.  In other words, it'll say, oh, this is the right form for a PDF file or a text file.  For transmission decryption I assume it would be something like being able to determine the encapsulated frame packet, et cetera, header information, whether it's a viable transmission medium.  These thoughts popped into my head while doing an encrypted file copy using SCP over a Hamachi connection over an encrypted wireless network.  Thanks for the great shows.  This is actually a real problem, and it probably is an academic problem.  How do you know when you've got the cleartext?  



STEVE:  Yeah.  I mean, and that's what I loved about the question.  I don't think we've had it asked before.  And remember that the process of decryption, all the processes that we know of that don't involve a badly broken cipher, that is, where the cipher is intact, you have plaintext.  And one way or another you are brute-forcing, you are guessing one after another after another key, applying the key and the decryption algorithm on the cipher against the cipher text in order to get the plaintext.  So the question is, how do you know when you've got it?  Because essentially it's not like the cipher algorithm says bingo, I've correctly deciphered it.  No, it doesn't work that way.



All the algorithms that we've been talking about, you put - it's sort of like garbage in, garbage out.  You put something in, and you're going to get something out.  The algorithm doesn't know anything about whether what you put in is readable or not.  It just says, oh, look, this is binary data, and I'm an algorithm that transforms it into a different binary data.  And so it's entirely up to the decrypter, to, that is, the person who is involved in this, or the system, whatever the architecture of this cracking project is.  It's up to something or someone to look at the data that comes out of the cipher and say, did we guess correctly?  And so, you know, if it were just unknown data coming in, and you got unknown data coming out, it might be the right unknown data, but you have no way of recognizing it.



So John suggested some things, for example, if this was a packet that was going through.  And he talks about the headers, for example.  And there he's completely correct because many forms of data have pretty well-defined structure.  He talked about file system metadata where, you know, you've got in certain locations of the file system, like in the old FAT file system we had the file allocation table and the boot sector, for example, at the very beginning, and the directory at a given location, and various structures which are known.  And in the case of packets we have a known formal definition for the layout of a packet where you've got the source IP, the destination IP, on the outside are the source and destination MAC addresses and so forth.  So, and relatively well-formed structure.



So in something where you have a sense for what you're expecting, like if you're trying to decrypt a packet that you snatched out of the air, you could apply some heuristics, some rules of thumb to look at the output of each of your guesses of a key after it comes out of the cipher to say could this possibly be a valid packet?  And there's enough structure that one chance out of many, many, many billions would you get something that looks valid but really isn't.  And so that's enough to, like, for the system to kick out, here's the key I used to get this.  This looks - this meets my first pass criteria for having properly decrypted it.  I'm going to keep working while the humans come along and apply a higher level of judgment to whether this thing works or not.



And, similarly, say that it was just ASCII text.  It was completely known ASCII text.  But you had, in a block of text, say maybe you were decrypting a sector, 4K bytes.  Well, even in 4K there's many things about ASCII text, even if you don't know what it says, that are tip-offs.  For example, in ASCII, typically ASCII compresses highly because, for example, the high bit, the eighth bit is always off.  Most of the alphabet fits, typically fits within the first 0 to 128, or 127, rather, characters.  So your high bit is off.  Well, in a block of 4,000 characters you're going to have - well, actually 4,096 in a 4K block - you're going to have 4,096 high bits.  So if any decryption of something that you thought was just ASCII happened to suddenly have the majority of all of its high bits off, that's suddenly a very good chance that you've decrypted it correctly because encrypted text, which we know is going to be highly random, encrypted anything is going to, on average, have 2,048.  That is to say, 50 percent of the high bits in the bytes are going to be on; the other 50 percent are going to be off.  And it's going to be extremely regular.  And so if suddenly you get a decryption of even something you don't know at all, except here again we know something about, we've made some assumptions about what it is that we're decrypting.  We're saying we think this is ASCII.  And when we get right, suddenly most or all of the high bits are off.  The chance of it being a wrong decryption where all of that is true is just astronomical.



LEO:  Although I suppose somebody could throw in a decoy where - this would be pretty tricky - where it seems to appear to be a decoding, but in fact it's a middle step to another decode.  Is that possible?



STEVE:  Well, in fact it was one of the things I said a long time ago that actually generated a surprising amount of controversy when I talked about double-encrypting something.



LEO:  Right.  Oh, I remember that.  Oh, we got so much email on that one.



STEVE:  I know.  People just - they were pulling their hair out on that.



LEO:  In other words, is double encrypting it making it harder to get to cleartext.



STEVE:  Right, because I was taking the position that, if you double encrypted using different keys, and technically you could probably even use the same key, although you'd like to use different keys for more.  But if you didn't, if someone did not know that it was double encrypted, they'd only be testing it after a single decryption.  They would never know to do it twice.



LEO:  They'd never see the cleartext.



STEVE:  Much better.  Exactly.  You'd never get cleartext.  You'd just get more random stuff.  And they don't know that they ever guessed one of the keys correctly.  So, yes, the more you obscure it and prevent somebody from being able to test - because this is the point of John's whole question is in every case it's a test you apply to what comes out of the decrypter, whether you got it right.  The decrypter itself doesn't know.  It just says you gave me something; I gave you something else.



LEO:  It's what I think.  Right.



STEVE:  It doesn't know.



LEO:  Right.  A human is needed.



STEVE:  Right.



LEO:  I mean, it's easy when you unlock a door, it's unlocked.  But it's not so easy with decrypting.  Thomas in Stockholm, Sweden, wants to stay with the tried and true.  But he wonders what can be done, if anything, to safely run older software with known security problems - like, say, Windows 95/98/ME would be a good example - but which is no longer supported by the manufacturer.  His example is he has ACDSee, which is picture editing software, really a great program.  But he'd have to buy a new copy because the old copy is no longer supported.  Is there a - could you Sandboxie it?



STEVE:  That is exactly the answer to the question.



LEO:  I'm not so dumb as I look.



STEVE:  It's why we keep you around, Leo.



LEO:  I'm paying attention.



STEVE:  That's exactly what I would do.  I would say to Thomas in Stockholm that, yes, Sandboxie would be a perfect solution.  It's unlikely that he's going to get attacked through picture editing.  I guess he would be opening a picture like a JPG where Sandboxie's JPG decoder had a known buffer overflow problem.



LEO:  Which was in fact the case, yeah.



STEVE:  Those have been known to exist.  But so that he's opening a picture that is a malicious JPG that tries to do something.  Well, this is exactly what Sandboxie is designed for and why it's so cool that it's a general purpose sandbox that's able to sandbox not just Internet applications, but anything that you're doing.  And so, yeah.  And the cool thing is I've now been using Sandboxie for several weeks.  I see no overhead, no core code or RAM bloat consumption.  I see - nothing seems to be slowed down at all.  I'm using it for Firefox and Eudora, my email client.  And they're all just running perfectly.  So I'm really pleased with it.  And I'm sure you could run ACDSee in there and just have the confidence that, if by chance you did open a malicious JPG, it wouldn't be able to do any writing to your system.  Sandboxie would protect you from it.



LEO:  Very cool.  John Pitt in Melbourne, Australia has discovered his ZoneAlarm is sneaky and leaky.  He says:  Hi, Steve and Leo.  I recently heard on one of your Security Now! episodes a recommendation to get a program called Wireshark.  What is that?  That's the old - they renamed it.



STEVE:  That used to be Ethereal.



LEO:  Ethereal, that's right.  I did this.  Thanks.  And in addition to discovering the packets I was looking for, I discovered that ZoneAlarm was constantly sending DNS requests and packets to its own server.  I don't like that.  Even though I have another firewall running concurrently with no permission for this ZoneAlarm behavior, the other firewall does stop ZoneAlarm from contacting Zone Labs for the phone home purposes, but it doesn't see these DNS requests at all.  How are they doing this?  What are they doing, and why?  Please talk about why ZoneAlarm is so sneaky.  I love to listen to your show every week, and I hope you continue to educate people about the ugly world of Internet security.  Hey, I'm a little disappointed in ZoneAlarm.  What are they up to?



STEVE:  Well, when I saw this I thought, oh, yes.  This is something that Gregor Freund and I once discussed as a sneaky way of getting data out of a PC that firewalls would not block.  Now, I'm still getting myself in trouble for having once, many, many, many, many years ago, recommended ZoneAlarm.



LEO:  No, it was a good program.  You introduced me to it.



STEVE:  Version 2.6 something was a great program, back when Gregor and Conrad and those guys, the original founders were there.  I liked them; I liked it.  Now the company bears no resemblance, nor does the product bear any resemblance...



LEO:  Oh, so they're not there anymore.



STEVE:  No.  They've sold out long ago.



LEO:  Oh, okay.  And literally.



STEVE:  And the thing's just become a bloated nightmare program.



LEO:  We no longer recommend it.  You know what, you recommended it, but we recommended it on The Screensavers.  I recommended it on the radio for years.  It used to be a great program.



STEVE:  Yup.  And that is seriously in the past tense.  What  ZoneAlarm is doing is it is deliberately using DNS to bypass firewalls so that it is able to contact ZoneAlarm, and ZoneAlarm's end-users are unable to block it.  The reason this happens is that DNS is one of those many things that uses the service host.  So what happens in, for example, in XP, in one of the services running is called the DNS client service.  And so you must give permission, any firewall must give permission to the DNS client service, or your system can't do DNS lookups.  And we know from having talked a lot about DNS that email and web surfing, I mean, everything needs to use the DNS system.



So what happens is programs do not themselves use the IP system, the UDP/IP or TCP/IP system, to form and send DNS requests.  Instead, this is a service offered by the operating system.  So the program asks the operating system to please look up the IP of this domain name.  Then the operating system does that on behalf of the application.  Well, that means that the operating system has to be permitted to do DNS.  And so what John has described is, literally, it's ZoneAlarm deliberately being sneaky, ZoneAlarm doing something for the sole purpose of bypassing the user's control over its phoning home.  And he saw this with Wireshark.  He says that they're sending DNS requests to ZoneAlarm's own servers.  Well, ZoneAlarm, the only reason ZoneAlarm would have servers is to receive stealthful DNS packets from its customer base.



LEO:  What's the content they could send?  They could send lots of information.



STEVE:  They could be sending anything they want.



LEO:  And it gets through because it's a DNS request, and so it just bypasses...



STEVE:  Yes.  It's because the DNS request goes to the operating system.  And all firewalls, either you...



LEO:  If you don't allow it, you can't surf.



STEVE:  Well, exactly.  Either the firewall, the first thing that happened when he installed it was it said I need you to give me permission for DNS, and you have no choice.  You say, okay, fine.  Unfortunately, ZoneAlarm is deliberately using that permission in order to send its own packets containing lord knows what, I mean, anything it wants, over which you have no control.



LEO:  Oh, that sucks.  That's terrible.



STEVE:  It's really bad.



LEO:  I'm devastated.



STEVE:  I'm unfortunately not surprised.



LEO:  And a very good reason why you might want to download the free Wireshark.  I mean, you have to be somewhat sophisticated to use this.  It's a packet sniffer.  But boy, that's - and it's a protocol analyzer because it can...



STEVE:  Or don't download it.  Just get rid of ZoneAlarm.  Just say unh-unh.



LEO:  Well, clearly we now know.  Wow.  Assuming that this guy is accurate in what he's saying.  But it's interesting because you had that conversation with Gregor.



STEVE:  Yes.  We were talking about this a decade ago, I mean, or whenever it was.  When ZoneAlarm was very young we were talking about different ways of sneaking data out.  And it was on my list of LeakTest enhancements for years.  And it's a known way of getting data out.  I'm disappointed to hear, but not surprised, that ZoneAlarm is doing this.



LEO:  Well, just to be fair to ZoneAlarm, this is what a listener tells us.  We haven't independently verified that they're doing that.



STEVE:  No.  And given the facts, this is my explanation for what it is he's seeing.  And it's interesting, too, that this other firewall is blocking the overt phoning home, but it's not catching this backdoor leakage through DNS.  And there's no reason ZoneAlarm should be sending DNS packets to ZoneAlarm.  I mean, to Zone Labs.  That's nuts.



LEO:  Right.  Right.  Unless they wanted to send out information of some kind.  But again, I just want to make sure that you understand we haven't verified this independently.  This comes from a listener.



STEVE:  Yup.  And I'm not installing ZoneAlarm on anything I've got.



LEO:  Yeah.  Wouldn't surprise us.  But there are other reasons not to install ZoneAlarm anyway.



STEVE:  Right.



LEO:  Wow.  Chris in Detroit needs a bailout.  Yeah, join the club.  Get in line.



STEVE:  I couldn't resist using that word.



LEO:  Get in line.  For his friend's once-infected PC.  Hi, Steve.  I love the Security Now! podcast.  I've been a long-time listener.  I'm having a few problems on a friend's computer.  First, the machine was the unlucky host to a virus.  My friend installed somehow Comcast's Internet Security.  I can't - they relabel somebody, McAfee or Norton.



STEVE:  Yeah, of course.



LEO:  Which found the virus and diagnosed it as Apple HEBI.  It is now removed.  But the problem is that whenever you try to visit Google, the computer forwards you to what looks like a Microsoft page saying you have spyware - oh, boy - download our new spyware removal, but you know it's not.  Any other Google site just ends up with a 404 error.  Access to the rest of the Internet works fine, though.  I was concerned - yeah, really?  No.  I was concerned that possibly the virus had changed his default DNS server's IP.  I corrected that by sending him to OpenDNS, and I looked up the IPs of the servers on my own computer, so if his was possibly infected it wouldn't send me to a fake OpenDNS.



STEVE:  Very sharp.



LEO:  So I set up his DNS servers manually, went to Google.com, still no avail.  How could this possibly happen?  The problem has to be within the computer itself, and I'm at a loss for a solution.  He's got Antivirus 2009, is what he's got.



STEVE:  Well, what he also said, I liked it, in the subject of his note he called it "Pre-DNS?" with a question mark.  And so what this could be is nothing more than this thing made a modification to his hosts file.  Because the hosts file, as we've often said, is where the PC goes before it goes out onto the Internet.  And so if something said Google.com and then gave an IP to this bogus Google.com, any attempt to access Google.com would instead be redirected to this foreign server.  And it also follows that other things that are Google.com, gmail.google.com or google.com on other pages, well, those wouldn't be supported by the foreign spoofed server, so they'd come up as 404s.  But you have more specific knowledge about something that does this, Leo?



LEO:  Yeah.  And I'll say a couple of things.  First of all, there is a removal tool called Malwarebytes, B-y-t-e-s, lot of people recommend.  But you and I both agree on this one, Steve, that what he tried to do, he got a virus, and he tried to manually remove it.



STEVE:  All bets are off.



LEO:  All bets are off.  And oh, lo and behold, something's still wrong.  You don't know what's wrong.  You might have a rootkit.  You might have...



STEVE:  Can't know what's wrong.



LEO:  You can't.  You've got 20 other things going on.  I say this on the radio show.  I want you to just tell me if I'm completely full of it.  Once you've been infected, really the only safe bet is backup your data, format the drive, and reinstall Windows from a known good source.  That means an install disk or a system recovery disk.



STEVE:  Yeah, I was just going to say that the advantage is, his system is running.  So with a running machine, I mean, my point is that many people have, for example, their hard drives die.  And then they're like, ooh, I wish I had a current backup.  It's like, yeah, I bet you wish.  Go get a copy of SpinRite and pray a little bit.  But here he's got a working system.  So he has access to his data.  As you said, get the data off, all the things you care about, your programs, your My Documents folder, all that stuff, get it off.  And then the only thing you can really do to be sure is rebuild the system from scratch and then restore your data.



LEO:  From a known good source that can't be corrupted.



STEVE:  Yes.



LEO:  Like an install CD.  There are a lot of cocky guys.  Every time I say this I get guys in the chatroom say, oh, no, no, I can remove that.  And there are a lot of guys out there, and gals, who say, oh, no, I can get rid of anything.  I have the toolkit.  And, yeah, you can get rid of things.  In this case you didn't.  But let's say you did, and everything seems to be all right.  These guys don't want you to know they're on there.  There's no - you have no way of knowing that you're completely cured.  Once a bad guy gets on your system, he modifies all sorts, he can modify all sorts of stuff, hide things everywhere, and you can never detect it.



STEVE:  Well, and we are seeing a gradual escalation of the amount of - because it's evolution - of the amount of technology and effort being employed by the bad guys to make their stuff harder to remove.  I mean, in the good old days it used to be you'd look in autoexec and win.ini and the Startup folder, and you'd take some things out of there, and it would be game over, you know, nothing is running anymore that you don't know about.  But oh, those days are so far gone.  I mean, system files can be replaced with things that, I mean, I've had friends who were cocky like this, who have spent untold weeks fighting, just because they're so stubborn.  They've spent so much more time than if they had just pulled the data off and...



LEO:  Formatted the sucker.



STEVE:  ...reinstalled.  And then they call me, and they say, Steve, I don't know what the problem is, what's wrong.  This thing keeps coming back.  And I say, well, I know where the problem is.  It's that you've spent three weeks on this so far, and you've called me four times, and every time my advice is give up, this is really beyond you now.  It is very possible that this is beyond the casual, oh, I used to know what every file is on my computer, and I kind of still do.  No.



LEO:  The program Apple HEBI is a rootkit, by the way.  So...



STEVE:  Ooh, goodness.



LEO:  Yeah.  We know it's bad.  We know you're in trouble.



STEVE:  And what that means, just to remind our listeners, is it means you can trust nothing that you see.  The rootkit means it's down in the operating system.  It is filtering the operating system's own use of itself.  So when you do a directory, when you bring up a listing, nothing that you see can be trusted.  And, well, because the rootkit is in there making the OS lie to you about its own condition, about the files it has.  You can no longer trust it.  The only thing you could do would be to boot something, as we said earlier in this show, boot something off of a CD that allows you to inspect the hard drive and the file system so that you're not running the OS itself, you're running a different OS coming from a read-only medium.  And then you've got a chance of seeing reality.  But again, scraping this thing off - and in this case you want to make sure that your boot sector is cleaned, as well, and the first track of the hard drive.



LEO:  Mess, just a mess.



STEVE:  A mess.



LEO:  I, you know, I was that cocky guy many years ago.  And I learned my lesson.



STEVE:  Well, and we all were because once upon a time...



LEO:  Sure.  Used to be able to do it.



STEVE:  Once upon a time it was feasible.  It is no longer feasible.



LEO:  That's really the bottom line.  All right, our last question, Steve Gibson, and it's a good one.  It's actually one I think I wanted to ask you last week.  Ken Harrington, Herndon, VA, says, well, if you use Sandboxie, and it's so good, why do you need NoScript?  Steve, thanks for your recent show on Sandboxie.  It looks like a great product.  The question is, doesn't it make NoScript redundant?  If I understand it correctly, even a nasty JavaScript can't do any damage if it's trapped inside the sandbox.  Can I just uninstall NoScript?



STEVE:  Well, this being the last question, it is a bit of a segue into next week's topic, which is the limitations of the use of virtual machines and any sort of sandboxing program like Sandboxie.  But to answer Ken's question on this exact topic, you can make a differentiation between, and arguably these terms are a little similar, but security and privacy.  I would say that Sandboxie is not an enforcer of privacy because things running in the sandbox have full read access to your system unless you deliberately block them.  There is the ability, and one of the other features of Sandboxie is you can, if you've got, like, you don't want anything to access your My Documents folder, you can easily put that in Block Access, and then something running in the sandbox will not be able to access anything under your My Documents folder and the whole tree of things below it.  So that's yet again another cool feature of Sandboxie that we've never talked about before, the ability to deliberately blind things in the sandbox to some aspects, as many as you want, of your machine.



But where I would say that is a security benefit, Sandboxie is not providing a privacy benefit.  And that's one of the things that not allowing scripts to run, a browser with no scripting and no other known security vulnerabilities that are being exploited, it is a read-only device, too.  It's showing you static pages, which are not able to run any code, coming from a remote location.  So there's nothing, there's no way for information to get out of your system and back out.  But if you're running scripting, then there's the potential, at least, for the scripting itself, or for the scripting to invoke other modules in the system that have discovered vulnerabilities and use that to get data out of your system.  And so, and notice that if something has access to your system, for example, it could look at the other pages that are loaded in your browser, maybe one page in your browser has the ability to watch you enter username and password into a different page in your browser.  So even though all that activity is constrained within the sandbox, and nothing is making a permanent change to your system, it could still do some damage.  So I really see both NoScript and Sandboxie as companions to each other, and neither one rendering the other obsolete.



LEO:  There you go.  And why not use both?  After all, you got it, it's free.



STEVE:  Yeah, exactly.  Unless you're you, Leo.



LEO:  I don't use either.  But that's okay.  That's okay.  I'm okay.



STEVE:  But now here I am Mr. Born-Again Firefox User, it's like, oh, what's wrong with everybody?



LEO:  I do use Firefox.  I do use Firefox.  And I, you know, absolutely, I'd probably use NoScript at home.  But I don't feel too much at risk anyway.  We'll see.  Hey...



STEVE:  You and I are both safe, and we don't go in strange, dangerous locations.



LEO:  Yeah, I'm pretty careful about what I do.  Hey, we have come to the end of our show, but not the end of Security Now!.  You know, if you go to GRC.com you could find 175, something like that, 173 issues.  Go back in time and listen to them all if you haven't.  There are 16KB versions to make your downloads quick, if you don't mind the kind of reduced audio quality.  Of course the full 64KB version, as well.  And transcripts, if you like to read along while you listen.  Some people like to absorb information through their eyeballs.  You can find that, too.  GRC is also the home of SpinRite, the world's best hard drive maintenance and recovery utility.  We didn't do a SpinRite letter, did we, today?



STEVE:  I just had that thought.  You're right, we didn't.



LEO:  You want to do one?



STEVE:  I've got one.



LEO:  Yeah, let's hear it.  SpinRite is such a great tool.  We use it all the time.  I mean, I'll give you a testimonial.  We use it all the time around here.



STEVE:  I found a really fun one from a guy in New Zealand whose name is Hamish.  He said, "Hi, Steve.  As a loyal Security Now! listener from the very beginning, I've been aware of SpinRite and its stories for miraculous recovery for some time now.  I've owned a copy for a while and used it occasionally on misbehaving hard drives over the years.  Recently I got" - oh.  And the subject, that's what - it was "SpinRite Saves Lunch."



LEO:  I like it.



STEVE:  And I thought, okay, I've got to read this one.  I've got to find out how SpinRite saves lunch.  So he says, "Recently I got a call from the school cafeteria where I work, telling me their computer which runs their cash register software would not boot up.  This was about half an hour before the cafeteria was due to open and be filled with hundreds of hungry students.  I raced over to the cafeteria with my SpinRite CD in hand, popped it in, crossed my fingers, and made offerings to several gods in the hope that my students would not go hungry.  After about 20 minutes - it's a small drive, only 4GB - SpinRite said it had finished and repaired a couple of problems.  With bated breath I rebooted the computer, and up it came, loading the register software and allowing students to buy their lunches.  Ten minutes later students filled the room and ordered their lunches, unaware of how this wonderful hard drive recovery utility saved them from an afternoon of grumbling stomachs.  Thanks, Steve, for such a wonderful utility."



LEO:  I do like that.  SpinRite Saves Lunch.  SpinRite to the rescue.  GRC.com, you get your SpinRite there, you get  your free software utilities, and of course ShieldsUP! and all that great stuff.  It's a great site, highly recommend it.  Steve will be back next week, and next week we're going to talk about virtual machines, what they can and cannot do to protect you.



Don't forget you can listen to Security Now! and not only download it from TWiT.tv and GRC.com, you could subscribe to it in iTunes.  If you want to hear it every week, that's the best way to do it.  Just do a search for Security Now! in the iTunes store, absolutely free.  And/or you can watch it live.  If you're really a glutton for punishment, watch us do the show live in video.  You could see Steve's shining face every - we do it every Wednesday at 1:00 p.m. Eastern time.  I'm sorry, 2:00 p.m. Eastern time.  It's 11:00 a.m. Pacific at live.TWiT.tv.  Steve, thanks so much.  We'll see you next time.



STEVE:  Right-o.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#174

DATE:		December 11, 2008

TITLE:		Sandbox Limitations

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-174.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Having described "Sandboxie" and Virtual Machine sandboxing utilities in the past, Steve and Leo discuss the limitations of any sort of sandboxing for limiting the negative impacts of malware on a user's privacy and system's security.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 174 for December 11, 2008:  Virtual Security.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now! Episode 174.  In a continuing series, continuing effort to keep you safe online and off, Steve Gibson is here.  He's the security guru from GRC.com.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you.  I have to say, when you say "continuing series," I get so much email from people who sort of append at the end, oh, and I hope you and Leo never stop doing this.  Please, please, please, I look for this, my favorite podcast, or netcast.  You know, just I look forward to it every week.  Please, please, please don't ever stop.  And that's germane, in fact, today, because we're actually recording this a week ago.  We're having to get a couple episodes ahead in order so that we can provide content, Security Now! content to our listeners every single week throughout the holidays while you and your family are off in Paris.



LEO:  "We're recording this a week ago" sounds like we've done some sort of science fiction thing.



STEVE:  I do watch - I watch "Sarah Connor Chronicles," of course.  So we may very well have recorded this a week ago.



LEO:  But we believe that we are actually recording this now for use in the future.  You have a different point of view, ladies and gentlemen.  You believe we've recorded this in the past for your listening enjoyment in the present.  Man, this is a science fiction novel.  What are we going to talk about today, Steve?



STEVE:  Well, our main topic isn't going to be extensive.  I've got three interesting, contemporary security stories that occurred this week, which was actually a week ago last week in the future.  So we'll discuss those.  But I wanted to talk about I feel like I may have, two weeks ago on our Sandboxie episode, sort of maybe oversold what Sandboxie can do.  We got a lot of email from people saying, oh, great, this is the only thing I need.  I don't need to worry about antivirus.  In fact, I think I even said that at some point.  Like, oh, yeah, you don't need to worry about AV stuff because Sandboxie creates complete containment.  And the same is true of virtual machines that also create containment.  So I wanted to spend a little bit of time to walk myself back from that a little bit or, as Rachel Maddow says, "Talk me down," so to get a little bit more reality-based about the limitations of any kind of sandboxing thing and what bad stuff that gets into your computer can still do.



LEO:  Well, and that's one thing I really like about you is that you have always been hard-headed.  And as an engineer I think this is kind of an occupational hazard.  You try to be very specific about what's so, and very honest, as opposed to somebody like me might get excited and jump up and down and say, ooh, it can do anything, anything, wash the car.  So good.  We'll get the reality-based facts here on Sandboxie and virtualization in general.  All right, Steverino.  Let's get the latest security news.  Anything going on in the world out there?



STEVE:  Well, yeah.  There were three really interesting security-related stories that I wanted to sort of extensively share with our listeners because they all bring home some of the topics that we've talked about.  So I'm going to share each one, and then you and I will talk about what's essentially going on, what the story involves.  This was the Boston Globe reported this.  The headline would catch one's attention because it says "Sandwich loses nearly $50k to hacker."



LEO:  What?



STEVE:  Well, Sandwich is a town in Massachusetts.



LEO:  Ah.



STEVE:  So it was Sandwich, Massachusetts which loses nearly $50,000 to a hacker.  And so the Boston Globe reported, they said, "The same type of data security breach that has menaced retail stores, restaurants, and other businesses has made its way into the Sandwich treasurer's office, where a hacker with possible international ties stole tens of thousands of dollars from town coffers in a complex computer-fraud scheme.  Sandwich officials have warned their counterparts in surrounding towns of the computer breach.  Police believe the hacker used a virus to attack Treasurer Craig Mayen's computer and implant a keylogger that monitored any keystrokes he entered."  So this is the treasurer of the town of Sandwich had a keylogger installed somehow on his machine.



"With technology similar to what is known as a 'sniffer,' a device that tracks computer information, the hacker was able to record Mayen's security code and password as he typed them, and used that information to make withdrawals from town bank accounts.  The money was then transferred to four accounts - three in Florida and one in Georgia.  Police Chief Michael J. Miller said yesterday that Mayen discovered the breach two weeks ago and notified police detectives.  Investigators were able to determine that the scheme netted close to $50,000.  Miller said yesterday that detectives will ask the state attorney general's office and the FBI for help in what he called a 'complex case.'"  He said, "'That's the problem with tracking all this stuff, we don't have that ability,' the chief said.  'At this point, it's outside our realm of expertise.'



"Police have been working with the town's banks and a white-collar crime-fighting collaboration of law enforcement and bank security officials.  Miller said police in Florida were able to question a man who opened one of the four accounts there as he was trying to make a withdrawal [from the account].  However, police do not believe the man is criminally involved in the scheme.  The chief said the man in Florida, who was not identified, told authorities he answered an advertisement offering to pay him to open an account."



LEO:  Oh, boy.



STEVE:  "The hacker would then move funds from Sandwich into the account, and the Florida man would then wire those funds through Western Union to St. Petersburg, Russia."



LEO:  Wow.



STEVE:  "Miller would not say how much money was stolen from town coffers, but said it was less than [but approximately] $50,000.  He said the culprits have been systematic in the account transfers in that each has been in amounts of less than $10,000, the threshold that banks use to notify FBI officials of significant monetary transfers.  Mayen noticed the problem when he was conducting a bank transaction for the town and noticed a series of unauthorized withdrawals" - from under his own credentials, which had been stolen from them, he said - "beginning on [November] 4th under his security code.  Gail Marcinkiewicz, a spokeswoman for the FBI, would not say yesterday whether her agency would assist the investigation."  My guess is that they will.



"The FBI has jurisdiction to participate in such investigations, but any number of factors could determine whether the [agents actually get] involved.  A spokeswoman for Attorney General Martha Coakley's office would not comment yesterday.  The elaborate scheme is part of a larger underground computer fraud economy that has netted hundreds of billions of dollars through identity theft, credit card fraud, and other breaches, said Dean Turner, director of global intelligence network for Symantec.  Miller downplayed reports that police are investigating whether the hacker has ties to Russian organized crime because of where the money was being sent.  But Turner said that computer fraud is a booming industry in Russia and Eastern Europe, with organized crime rings offering all types of information and hacking equipment on the black market.



"'This is only a small slice of what's going on in the economy,' he said.  The data breach that occurred is similar to the type of scheme that attacked retailers such as TJX and BJ's Wholesale Club in one of the largest computer fraud cases in the country, Turner said.  In this case, a hacker was able to implant a malicious code in the treasurer's computer.  That could have been done in several ways, by email or through a website that was carrying the virus.  From there, the hacker could have begun reading the keyboard strokes.  Turner said hackers sell toolkits that can accomplish such fraud on the underground market.  This is, what this really is,'" - what it really is.  Oh, he says, "'...what this really is is a data breach, an ability to compromise information.  In this case it's banking information.'"



LEO:  Very interesting story.  And I'm sure just one of many, some of which we'll never hear about.



STEVE:  Right.  Well, and probably, based on how well organized this is, this is the sort of thing that we've talked about a number of times where it was probably a targeted attack.



LEO:  Spear phishing.



STEVE:  Exactly.  Spear phishing.  So instead of just spewing email around, it seems very likely that the treasurer's office, if not the treasurer himself, was deliberately targeted, sent some email hoping he would click on it, using some known or maybe even unknown vulnerability.  I mean, at this point certainly publicly they're not saying how this got into his system.  It may well be, and it sounds like that the local police are not, at this point not equipped technically to go in and forensically figure out exactly what happened.  Certainly the town treasurer has realized the kind of damage that can happen when his computer gets infected by something.



LEO:  Right, right.  A very interesting story.  I guess you would think, if you were running this computer system for a town, you would have something like an Astaro Security Gateway maybe, or some sort of security filtering the mail.



STEVE:  Yeah.  Again, we don't know what the vector was that brought this thing into his machine.



LEO:  Seems likely to be mail, though; right?



STEVE:  That would be my guess.  Given that it was targeted.  Certainly you could probably get from the website of the town the email address for the treasurer.  Or you could call up and pretend to be - do a little bit of social engineering, pretend to be somebody else and ask what the treasurer's email address is.  Oh, I bumped into him, and he told me, but I didn't write it down.  I thought I would remember it, but I forgot it, you know, what is it.  And so then you start sending him things, hoping that he's going to act on it, and literally target him to install this thing.  And then of course you're all set up, once you get control, with the backend money transfer system in order to get this stuff transferred through an intermediary so that it's not a direct connection.  And then we know that unfortunately Western Union is how a lot of these funds get transferred out of the country.



LEO:  Right.  Yeah, I mean, figures, this is probably an operation, that they go through the websites of many, many municipalities, figuring especially small towns have less security.  And once you've got the guy in Florida with the account set up, you can go through, you can have a number of checks go through.  Doesn't have to be from Sandwich.  Very interesting.



STEVE:  Well, I have another interesting story.  This is the actual - I'm looking at the PDF from the United States Department of Justice, the DOJ, from the U.S. Attorney in the District of New Jersey who put out a report that I thought, again, touches on things we've talked about many times.  This is from Newark, New Jersey.



"Law enforcement personnel in three states arrested four men this morning" - this is late November - "who were charged with engaging in an international conspiracy to deplete millions of dollars from U.S. victims' home equity lines of credit using personal information obtained through identity theft and unauthorized computer access," U.S. Attorney Christopher J. Christie announced.  Today's arrests bring to eight the number of individuals charged to date in New Jersey with participation in [this single] scheme in which the defendants conspired to deplete available funds from home equity lines of credit, called HELOCs - just Home Equity Lines Of Credit...



LEO:  Right, right, right.



STEVE:  "...belonging to identity theft victims, either by engineering fraudulent wire transfers or by gaining unauthorized access to the victims' online bank accounts.  The four men arrested earlier today are," blah blah blah.  They're scattered around the country - Los Angeles; Brooklyn, New York; Springfield, Illinois - who are expected to make initial appearances in federal courts in those towns.



"The defendants are part of a multinational identity theft ring that operates in the United States, the United Kingdom, Canada, China, Japan, Vietnam, and South Korea, among other places.  The defendants and their co-conspirators have acquired identity information from thousands of victims and used that information to conduct numerous fraudulent schemes, including depleting their victims' home equity lines of credit accounts.



"The Complaints charge that co-conspirators have withdrawn more than $2.5 million from home equity lines of credit accounts belonging to innocent customers of banks and credit unions and have attempted to draw at least approximately four million more in ultimately unsuccessful transfers from those accounts.



"The Complaints charge that the defendants and their co-conspirators initiated the HELOC fraud by gaining access to confidential customer and account information used by customers of banks, credit unions, and credit card issuers to conduct finance transactions in the United States.  This information included account holder names, addresses, dates of birth, account numbers, Social Security numbers, and account balances.  Other fraud information frequently obtained by the co-conspirators during the course of the fraud included mothers' maiden names, security question answers, and online usernames, passwords, and other data used by banks and lending institutions to service and secure customer accounts.



"According to the Complaints, the defendants and their co-conspirators compromised confidential customer account information relating to several large and small banks, credit unions, and credit issuers throughout the United States.  The larger institutional victims identified in the Complaint include Citibank, JPMorganChase, Wachovia,  Washington Mutual, Bank of America, among others.  Dozens of smaller banks and credit unions have also been victimized, including the Navy Federal Credit Union, Pentagon Federal Credit Union, U.S. Senate Federal Credit Union, and State Department Federal Credit Union, and at least approximately 11 New Jersey-based financial institutions."



So here we have, I mean, like the raw information, all the facts associated with a major ring located throughout the whole United States.  And bottom line, Leo, is this is about people using publicly available information to impersonate enough about a person in order to convince their lending institution that it's them.  And oh, by the way, I want to withdraw money from my home equity line of credit and send it off in this direction.



LEO:  Right, right.



STEVE:  We've talked - we've never really gone into detail about identity theft because it's a large and sort of amorphous topic.  But one of the things that I take away from this is, and we sort of touched on this before, is do not use real, like your real information when someone says - gives you a form and says what's your mother's maiden name?



LEO:  Right.  Too easy to find out.



STEVE:  Yes, exactly.  Come up with some other information.  What's the name of your first pet?  I mean, the Internet, it's often said that no information that ever goes onto the Internet ever leaves.  And so, and for example, I was noting with interest the vetting process that people entering this next administration are going through and the questionnaire they've having to answer.  They're having to say, have you ever written an email whose contents would embarrass you if it were made public?  Well, okay.



LEO:  Yeah.



STEVE:  Who among us have not?



LEO:  Yeah.



STEVE:  You know?  Like, okay, yesterday, and in fact maybe this morning.  It's going to be a very empty White House, I think.  I don't know how they're going to have anybody in there.



LEO:  Well, they're asking for everything.  It's amazing.  They want everything.  They want a complete...



STEVE:  Yeah, they really do.  And so it's said that anything that goes on the 'Net never leaves the 'Net.  And so similarly you could imagine the context in which you might have innocently answered a question about your first pet.  And now we have Google that's able to allow anyone to do deep research into people.  I've also seen - someone gave me, like, a trial account for some of these online information-finding services.  I was actually curious, I had lost touch with an ex-girlfriend, well, I should say a high school sweetheart, way way way.  And I was able to find her to the home she had recently sold.  And I called the owner of the home saying, hey, you know - and of course I'm very conscious of identity theft and security and things.  And I didn't expect this person, I didn't even ask her what had happened to Terry, could she tell me who she sold the home to.  But I explained that I was someone who knew her years ago, and I was hoping she was still there, and that's how I learned that she had sold the house.



But, I mean, you can literally - there is so much information available on the 'Net that I hope our listeners that are certainly people who care about this, and people who don't listen but who are friends of the people who listen, can get clued into this notion of absolutely not using valid information except when you absolutely have no choice.  I mean, you can't lie about your Social Security number when you need to give it to the bank.



LEO:  Or the government.



STEVE:  But you can certainly give Disney's turnstile your knuckle...



LEO:  A knuckle.  That's my favorite.



STEVE:  ...when it asks for your fingerprint.



LEO:  Still my favorite letter we've ever gotten.  Mr. G.



STEVE:  Hey, Leo.



LEO:  Mr. G, you got any SpinRite email for us?



STEVE:  Yeah.  I have agreed not to share Craig's last name because he said if - he's a Security Now! listener.  And he said, if you share this, please keep my name confidential.  So but his subject was "SpinRite Saved the Computer Outage Day."  And he says, "Hello, Gibson Research Corp.  Please forward to Steve Gibson, if possible.  This is the first user testimonial I've ever sent for any software in my lifetime.  I'm sure Steve is always very busy, but he does say that he loves to hear from users of SpinRite.  SpinRite saved my power outage day."



So he says, "Dear Steve.  Firstly, I would like to say thank you for all your hard work in both making the Internet a more secure place to explore and getting the word out to the world about security issues that are very important to us computer users.  I've been following your site since 1999, when using Windows 98, before I was behind a router, and learned of ShieldsUP! to help me close my open ports and make my computer much more secure in many ways.  A lot of the computer knowledge I have has come from reading your extensive information on your website.  I've also been following Leo Laporte since The Screensavers and was happy to see the both of you collaborate on making Security Now!.  I've enjoyed listening to every episode since its inception.  I still look forward to listening to it every week."  So a great listener.



He says, "I finally bought SpinRite!  I suppose, like most of our customers, we will all need to purchase SpinRite at some point due to a hard drive failure.  Well, my time came to pass last month.  I was working away at work, using my computer.  There was a thunderstorm active that day, and the power went out for one or two seconds.  When my PC was rebooting after the outage, I noticed it went into a repeating boot cycle.  Every time, during the boot sequence, after the BIOS screen but before the Windows welcome, it would emit a clock beep and reboot.  I thought I was a goner for sure.  I called the support line for the PC, and they said the best they could do was to replace the drive.



"Well, even though I do back up, I only do so about once a month.  And of course this happened in the last couple days of the month.  So I thought, well, time to try SpinRite.  I purchased and downloaded it and put it on a floppy.  I powered off the PC, popped in the floppy, and started it up. Thankfully the BIOS was able to load SpinRite.  I was worried that, depending on where the error was, it may not even load the floppy.  I can't even remember which level I selected now, but I ran SpinRite.  And after only maybe 30 to 40 minutes it was finished.  It had found one damaged sector and stated that it had done its best to repair its data.  So I thought, cool.  Time to reboot and see what happens.  Well, I was amazed to see it boot up like nothing had happened.  Needless to say, I immediately backed up my data.  I just wanted to let you know that you have another happy customer and a much more savvy computer user, thanks to your hard work.  I will without hesitation recommend SpinRite to everyone who will listen.  Thanks again."



LEO:  That's great.



STEVE:  So thank you very much, Craig.



LEO:  Always nice to hear those stories.



STEVE:  Yup.



LEO:  So last, or it's actually two weeks ago now, we had the creator of Sandboxie on.



STEVE:  Yes.



LEO:  And we talked a lot about how this sandboxing application could be used for security, to protect you.  When applications run in Sandboxie, if you get a bad guy, some malware, whatever, it doesn't have access to the full machine.  It's sandboxed.  It's enclosed.



STEVE:  Right.



LEO:  We also talked about virtual machines and how they can kind of do the same thing.  A lot of people I know, in fact I do this myself, will instead of using Windows bareback, if you will, will run a virtual machine with VMware or some other program, and run that way.  And that way, if we get infected, we just throw out the virtual machine and start over.  But there are limits to what this can do.



STEVE:  Well, there are, exactly.  And I feel like, as I was thinking about this, I thought, you know, I didn't want to give anyone the impression that Sandboxie or running things in a virtual machine was absolute protection against anything that malware can do because there is so much that malware can do.



LEO:  Right.



STEVE:  For example, if you did - we heard earlier this example where a password logging program got installed on the treasurer's computer in Sandwich, Massachusetts.  And that caused the loss of nearly $50,000 worth of funds transferred from accounts that he had access to, using his credentials.  Well, that's a perfect example of something that Sandboxie would not have protected him from.  Now, I'll say that with some caveat because, for example, Sandboxie would have not protected him until the sandbox was cleaned because, had he been using email - well, okay.  Say that he installed himself - that this thing did use email as a vector of entry, as we hypothesize.  Well, if he had a separate sandbox for it to contain his email client from his browser client, and if he were logging in to - we also don't know how he was logging in.  But if he did have his email system sandboxed, and if it was clicking on a link that installed something is the way this keystroking logger got in, well, the keystroking logger would have been installed in the email's sandbox, so it would not have been able to log keystrokes in activities outside of the sandbox.  So there he would have had isolation, so Sandboxie would have solved the problem.



If, however, if the keystroke logger had been installed in the web browser sandbox, and he used the web browser to log in, then until he cleaned the sandbox that keystroke logger would have been installed.  I've got my Sandboxie sandbox set up so that it flushes the sandbox when no programs are running in it.  So it just deletes the contents every time to prevent things from accumulating.  And I ended up, after I talked two weeks ago, I talked about how I do - at that time I was using separate sandboxes for Eudora and for Firefox.  And I ended up amalgamating them into a single sandbox because so often I am clicking links in email - I subscribe to a bunch of newsletters where they're trusted  newsletters, like security newsletters, and they've got links to stories that are on the web.  In fact, that's how I brought up those stories that I read earlier.  So it's easier to have the email client and the browser sharing a sandbox because otherwise the email client is wanting to run another copy of the browser, another instance of the browser, in its own sandbox because things cannot get out of the sandbox.



So I decided, okay, look, let's just put email and my web browser together in the same sandbox.  So in that scenario, because they are sharing a sandbox, if email were used as the vector to install the keystroke logger in this treasurer's office in Sandwich, Massachusetts, then he logged into the facility using the web browser, since they share the sandbox, they would share the keystroke logger, which would be a bad thing.  On the other hand, if he were using some other sort of software outside the sandbox, then the keystroke logger would have been localized to the sandbox.  Still not good, but it wouldn't have created this compromise.  So there's an example where something is being protected by the sandbox, but only within the constraints.



So notice that - my point is that the sandbox creates limits, and you would have the same sort of limits in any kind of a virtual machine environment where it would be installed on the virtual machine and not on your real machine, so activity outside of there would be protected, but not activity inside of there.  And so, for example, if you were using all web browsing in that virtual machine where you now had a keystroke logger, you'd still be in trouble.



So I wanted to sort of further clarify the sorts of things that malware could still do.  And so this notion of a password-stealer is a problem.  Also things in the sandbox or in a virtual machine, they've got access to the network.  It's because they are network-enabled applications that they're dangerous because bad stuff comes in from the outside.  Well, that means they are able to initiate connections.  A browser initiates connections out to the Internet.  Email client initiates connections out to the Internet.  Well, that means that programs running in the sandbox are Internet-permitted.  Which means that, if malware got in there, notice that, unless you deliberately block areas of your system using Sandboxie - Sandboxie does permit you to, for example, blank out your whole My Documents tree, which is probably a good thing to do because your email client typically doesn't need access to that.  It needs access to its own email repository.  By poking a little pinhole through the sandbox so that that can be persistent while you flush the sandbox, you're not flushing all the email that you've received and replied.  You want that to exist outside the Sandbox and persist longer than the life of the sandbox.  But if you black out areas of your system, then nothing in the sandbox is able to access, for example, the whole My Documents tree where you may be having the bulk of the content that you're creating yourself on the system.



So it's certainly possible, if you had an Internet-enabled piece of malware, for it to read things in your system and send them out.  You could have a spambot that you have unfortunately installed, doing everything it needs to, which is not what you want in the sandbox.  Because if it came in through email, it has access to your email.  We know that many spambots rifle through all of the email repository of the machine that they have access to and send out email pretending to be you, sending out something malicious to your friends.  So that's a perfect, another perfect example of the kind of thing that no sandboxing environment can protect you from because everything it needs to do it has within the sandbox.



So it's very clear that this kind of sandboxing, while very useful, is not ultimate protection.  And I did make a statement that I need to also pedal back from two weeks ago when I talked about the idea of testing, using a sandbox to test malicious software and drawing conclusions from the behavior of software in the sandbox and extrapolating that to outside the sandbox.  The problem with really relying on that is that, as we know in the case of the Blue Pill work, it is difficult, but maybe not impossible, for software to detect that it has been sandboxed.  And sufficiently clever malware - again, this is theoretical.  But as we know from security, everything starts as a theory and ends up actually happening.  Malware could deliberately behave itself if it knows it's running in a virtual machine or in a sandbox, believing that maybe it's being tested, it's being watched to see...



LEO:  That's really interesting.



STEVE:  Yeah.



LEO:  How can it detect it?



STEVE:  It could...



LEO:  Does it have to use, like, Blue Pill kind of stuff or...



STEVE:  Yeah, I don't know off the top of my head how you could detect it, but...



LEO:  I mean, a good VM, virtual machine or sandbox would hide the fact that you are inside a sandbox; right?  It should look absolutely normal.



STEVE:  Yes.  One thing off the top of my head, most VMs, for example, that are set up just to be used for containment testing, they're not very mature environments.  They are a recently installed operating system that doesn't have the signs of having been used for years.  There's not a whole bunch of documents in the My Documents tree.  There aren't lots - there's not a whole, like, collection of programs installed in the system.  So, for example, if software were to enumerate the uninstall list from the Control Panel, like here's the list of all the things that are available to be uninstalled, if there were not a bunch of them, it could be skeptical.  Again, it would have to use some heuristics, some rules of thumb to judge that.  But it could say, you know, this seems like a computer which has not been used awhile.  I'm going to behave myself until I wake up in this machine, when it actually looks like it's been much more used.  So that kind of thing.



LEO:  Right, right, right.



STEVE:  And again, once then you trust the software, and you allow it to run on your native machine, it wakes up, looks at your list of removable software and goes, ah, now here's a thousand pieces of junk this poor sucker has loaded into his Windows machine.  Now I believe I'm talking, I'm in the real Windows environment.  And he can go to town.



LEO:  Right, right.  Well, and was it Blue Pill, or Red Pill, where it would test timing and...



STEVE:  Yes.  I mean, it is...



LEO:  That was clever.



STEVE:  In fact, there's been some evolution of this.  Joanna said that the original Blue Pill 1.0 was undetectable.  Well, now she's working on 2.0 because it turned out you could detect Blue Pill.  You could tell that you were in the matrix, you were not actually in the real world.



LEO:  This is the stuff I love the most in computer science.  I love it.



STEVE:  It really is difficult to completely fool something.  One of the things you could do is - and we talked about this then, for example.  There is, scattered around the Internet, high-accuracy time references using NTP, Network Time Protocol, which systems are able to use to determine the time outside the computer.  And so there are things you could do by comparing the passage of time inside and outside and look for differences because there are subtle differences in the timing of instructions because there is some virtualization overhead. That virtualization layer causes instructions to operate differently if it's present than if it's not.



Then the countervailing argument is okay, yes, but anything that the software running in the virtual environment does to detect that is in the virtual environment, so why can't you emulate it?  And again, it's like, yes, in theory you can.  But again, it's like the removal of spyware that we talked about last week.  It's a cat-and-mouse game.  And malware is upping the ante all the time to make it more difficult to root it out of the operating system, literally, you know, in the case of a rootkit.  And similarly, software trying to detect if it's been Blue Pilled, if it's operating in the matrix and not in the real world, is being more and more clever.  And so that requires that the virtualization environment become more and more clever in order to counteract it.



So what I wanted to explain, I wanted to really drive the point home that I love Sandboxie.  I like it much better than a full-on VM.



LEO:  Well, it's a lot simpler.



STEVE:  I use VMware.  I've got it sitting here.  I fire it up when I'm wanting to run multiple browsers and jump around.  I like the feeling of knowing exactly what a virtual machine is.  But I'm not running email in VMware, nor am I browsing in VMware because it's just - it's heavy.  I fire it up for a purpose.  It takes, you know, it commits a chunk of my system's memory permanently for the operating system, the copy Windows XP that I'm running in there, or different operating systems.  So and in fact it's different OSes that is the big advantage with VMware because I'm able to host them on this single platform.



But I'm bullish on Sandboxie.  I'm liking it a lot.  I'm using it.  It is lightweight.  It does not tie up memory.  I mean, it's always running and always providing containment for Firefox and my email client, Eudora.  I mean, it's just pain-free.  I'm 100 percent sold on it.  But I wanted to make sure that I hadn't oversold it because I've given a bunch of examples here of things that could still be bad that are going on quite happily running in a sandbox, still not having behavior that you would want to have going on in your machine.



LEO:  Well, fair enough.  And I think if anybody says, ever, oh, I've got the silver bullet that will protect you from anything, that's suspect.  There is - because there's so many ways, and these guys work so hard to figure out ways around that you've got to - it's constant vigilance, and you've got to use a variety of tools.



STEVE:  The cleanest thing to say about Sandboxie, which is my favorite solution for sandboxing, as I said, over using VMware, which I use for hosting different OSes, is that the cleanest thing, the way to put it is it prevents something from writing outside the sandbox.  It prevents what's in the sandbox from writing to your system.  So if you sort of just keep that as the rule of thumb, it's like, okay, I know, I mean, that's a good thing.  That's an important thing to prevent.  But it's not everything.  Because there's bad things that malware can do just by writing only within their own contained environment.



LEO:  I want to ask you, in a second, where you would recommend Sandboxie, where you'd recommend a virtual machine, where you might recommend SteadyState.  As I said, there are all these different tools.  And some are better for some situations than others.



[Commercial break]



LEO:  So Steven, so we now have in our toolbox kind of four related things; right?  We've got Sandboxie; great.  We've got virtual machines like VMware.



STEVE:  VMware, Virtual PC, Parallels.



LEO:  Ton of them.  Sun has one, I didn't realize.  It's free.  We have SteadyState, which we've talked about before, which is really cool technology that lets you kind of get back to where you were on a reboot.  Each of these is a tool that seems to overlap a little bit.  But they are, as you said, you would use Sandboxie in most cases?



STEVE:  Yeah.  SteadyState is - it's very heavy-duty and heavyweight.  I would say that's the right application for an untrusted environment.  The real benefit for it is that there isn't anything that users can do to get around its encapsulation.  The idea being that, for example, in a library where you've got public access terminals, you want to really lock them down.  It's possible to lock down a PC without SteadyState using the Group Policy Editor.  You can remove all kinds of privileges, I mean, it's freaky how customizable Windows really is.  You can turn off, like, right-clicking; and you can turn off, I mean, like, all kinds of amazing little tweaks you can do to Windows if you really get in there and do that.  The advantage with SteadyState is that it brings you that kind of group policy editor power just by clicking a few checkboxes.  But more importantly, anything that someone does is being held in sort of in a file system buffer, very much like Sandboxie, where you're able to read, but any writes you create are cached so that you can read them back, but they're not actually modifying the hard drive.  They're modifying a sandbox.  So it's like Microsoft's sandboxing technology, which is bulletproof.



Sandboxie isn't made for that.  Sandboxie assumes that, well, because it's just not its job.  It assumes that you're using your machine, and you like your machine, you're not trying to abuse your own machine, because Sandboxie gives you the ability to control what it's doing.  So its intention is different.



I would not use a system myself with SteadyState.  And I've set up several for other people who are really concerned about security because, I mean, it doesn't slow it down.  But the process of booting, when it boots up it has to flush the changes out.  And it takes, I mean, it just - it feels much heavier when you're using SteadyState.  So that's like the high end of the absolutely-allow-no-one-to-modify machine.  It's from Microsoft, and it's free, and it works really well.



I would say next down from that is any of the VM solutions, whether it's Virtual PC, VMware, or Parallels, the main ones over on the Windows platform.  And of course they're available now, because VMs are so widespread, on many different platforms.  I can't see a reason for using one for just application containment because we really have that with Sandboxie.  I see them as OS containment.  That would make sense, as I said, for example, if I want to have a virtual machine running Vista or FreeBSD or Linux, that is, I want to cross-host operating systems.  That's not something that Sandboxie can do, not ever intended to do.  Sandboxie is an application sandbox, not an OS containment.



And so virtual machines, I think, really come into their own when you need to basically start with a pseudo-copy of an empty environment and install something, a whole operating system and upwards from there.  And again, another reason that they're heavyweight is you have to have another licensed copy of the operating system.  You can't use the same one.  So that becomes burdensome.  If you're using, for example, multiple copies of Windows, Microsoft wants to get license fees for all those.



So I'm back around then to Sandboxie, really feeling that, given that we understand its constraints - and notice that neither VMs, full-on virtual machines, nor SteadyState, none of them would prevent the kind of non-writing malware that we talked about.  That is, they would, as long as you flush the state of your virtual machine, and you flush the state of the SteadyState environment, much as you flush the sandbox, you would turn those things into being transient.  You'd get rid of them when you cleaned out that state.  And so all three of these mechanisms have this notion of being able to reset the world to its prior state, which would remove anything that had crawled in.  But while it had crawled in, before you had cleaned it, there are certainly bad things that can be done, but they can be done in every case.



So this is why I wanted to talk about sort of to generalize this notion of sandboxing, either with Sandboxie or VM or even SteadyState, doesn't completely protect you from every possible behavior of malware.  But having said that, I'm back to Sandboxie because it is lightweight.  It's running for me all the time.  I don't have VMware running because I don't want to give it half a gig of RAM to run a copy of Windows XP.  And with Sandboxie you have this lightweight, low-overhead, very nice solution.



LEO:  Well, it's great to get the clarification.  I love you for that.  You're always impeccable in that regard.  You don't want to overstate it.  You want to be exactly accurate, and I appreciate that.  And I have to say, once again, as I said last time when we talked about Sandboxie, I just wish it were available on the Mac because, unlike something like NoScript, which is a little more intrusive, that's something I would use all the time.  I mean, that is - what a brilliant idea.



STEVE:  I am using it all the time.  I should mention that I've exchanged an email with Ronen.  I had a couple questions about whether it was filtering Windows shares access.



LEO:  Oh, interesting.



STEVE:  Somebody in our newsgroup had said, hey, Steve, what if something just tried to open your C$, the default admin share, on localhost?  And wouldn't that give it access?  And good old Ronen, he's there ahead of him in this case.  He understands that and blocks it.



LEO:  Interesting.



STEVE:  And I also was writing to him about our topic for week after next, two weeks from now.  We're going to talk about an interesting utility that was written four years ago by a Microsoft engineer called "DropMyRights."



LEO:  Oh, yeah, I know about that.  That's another one that our listeners often bring up as a good choice.



STEVE:  Right.  And we're going to discuss it in great detail in two weeks.  And it was in that context that I said, hey, Ronen, this is a cool thing.  What about having that for Sandboxie?  And he said, oh - anyway, we went back and forth a couple times.  Turns out that Sandboxie is already doing a lot of that.  It is dropping the rights in many different aspects to keep programs from being able to do bad things.  But it's not doing as much as DropMyRights.  Ronen, I told him that I was going to be talking about it; he says, oh, I think I'll add that.



LEO:  Oh, that's so funny.



STEVE:  And I said that'd be good.



LEO:  You know what I love, it's a real cat-and-mouse game between hackers who are smarter and smarter than ever, I mean, these guys really have an incentive now to really get into your machine, so they've gotten a lot smarter and a lot more clever.  And the good guys, people like Ronen and you who are really - you guys have to use your brains, too.  And it's just a fascinating intellectual exercise where, hmm, would they do this?  And how would I stop that?  It's point-counterpoint all the way down the line.



STEVE:  Well, and he did say in our initial email exchange that he had absolutely and definitely felt the effect at his end on us having told our listeners, all of our Security Now! listeners about Sandboxie and my being so pleased with the way it was working for me.  So, and I'm glad because it means that a lot of listeners are now using this kind of protection to make their use of machines more safe.



LEO:  It's interesting because, because Windows is the most attacked platform, in some ways it might be the most secure platform because there are the most defenses designed, the most patches, the most fixes, the most tools.  You can use Windows very securely now.  So I think that's fascinating, too.



STEVE:  Gotten a lot better in the last few years.



LEO:  You bet, yeah.  Steve Gibson, thank you so much.  Next week a question-and-answer session, so go right now to Security Now!'s website, GRC.com/feedback.  Submit some questions.  If there's something you'd like to know more about, we'd love to fill you in.  Of course when you're there check out SpinRite, that's at GRC.com, the world's best...



STEVE:  Pays the bills at this end.



LEO:  That's right, the world's best file and recovery maintenance utility file - hard drive maintenance and recovery utility.  It also is just a tool that I use proactively, just to kind of keep an eye on things all the time.  And we've found that to be very, very useful to SpinRite our drives before we put them in service.  And he's got a lot of great free utilities there, too.  You've heard about ShieldsUP!, Shoot The Messenger, DCOMbobulator, it goes on and on and on.  Don't forget Wizmo.  Love that Wizmo.  And that's not even a security application.  Well, it is now.  You added a little bit of security to it.



STEVE:  Yeah, some WiFi stuff.



LEO:  GRC.com.  Steve, thanks so much.  I guess - are we going to do a show on Christmas Day?  I guess we are.



STEVE:  Absolutely.  We're not missing any.



LEO:  Steve never sleeps.



STEVE:  Christmas Day and New Year's, Leo.



LEO:  All right.  Well, get your shopping done.  We'll talk to you Christmas Day on the next Security Now!.  Thanks, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#175

DATE:		December 18, 2008

TITLE:		Listener Feedback Q&A #56

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-175.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 175 for December 18, 2008:  Your questions, Steve's answers, #56.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now! Episode 175 in a never-ending saga of security with Mr. Steve Gibson.  He's the man in the beret today.  Hey, Steve.



STEVE GIBSON:  You're right, Leo.  It is never ending and never skipping a beat.  Never missing a week.



LEO:  He's very proud of that.



STEVE:  You're somewhere in France as this is being aired.



LEO:  Yeah.  No, I don't think I'm in France yet.



STEVE:  Oh.  On the 18th?  Oh, no.  Yeah, the 18th.



LEO:  I will be in France.  You're right.  Oh, my goodness.  Yeah, I'll be in Paris.



STEVE:  Hello from France.



LEO:  I'll be sending back pictures.  Hello from France.  And then next week, Christmas Day...



STEVE:  Our Christmas Day episode, believe it or not, yes.



LEO:  You're going to do an episode.  And he's just not going to stop.  New Year's Day.  He's not going to stop.



STEVE:  Yup.



LEO:  Unbelievable, Steve.  You're just trying to beat TWiT.  But you know what, this year - we learned our lesson last year.  Actually, I learned my lesson in Australia.  I went to Australia in the spring.  And we skipped, I think, two or three episodes, and the subscriptions just fell off miserably.  So this year we're going to do - actually it's going to be kind of fun.  Our holiday at TWiT, which is December 22nd, I think, is going to be a special episode with Jonathan Coulton, the geek singer, the guy who did "Code Monkey," and John...



STEVE:  Oh, neat.



LEO:  Yeah, and John Hodgman, his neighbor in Brooklyn, who's of course PC in the I'm a Mac/I'm a PC ads, and a very funny fellow.  So it'll be a very special Christmas episode.



STEVE:  And he also appears with Jon Stewart on "The Daily Show."



LEO:  He does, he's on "The Daily Show."  He was in the movie "Baby Mama."



STEVE:  Okay, I'll take your word for that.



LEO:  Me, too.  I didn't see it.



STEVE:  Missed that one.



LEO:  Really a wonderful guy.  Two great old friends who actually were Screensavers fans going way back, and I'm sure Steve Gibson fans.



STEVE:  Oh, no kidding.  So you've known Hodgman from before he appeared on the Apple commercials.



LEO:  Not at all.  I didn't know he was a fan until he sent me an email.  And that was a great thrill for me.  So that's been fun.  And they're both Yalies.  So it'll be kind of an Old Blue Christmas.  I'm going to rename myself Jon for the event.  So we'll have Jon, Jonathan, and John.  And then on New Year's Eve we're going to do a special edition of This Week in Tech which will be a "best of" - the biggest stories, the hottest moments from 2008.



STEVE:  So you're going to edit the audio out of all the previous...



LEO:  Yeah.  Tony's working on that right now.  In fact, if you have a suggestion for Tony for a great moment in TWiT from the last year, email tony@twit.tv.  He's working on that right now.  So we're not going to miss an episode.  So you think you're gaining on us.



STEVE:  Yeah, but you're cheating kinda.



LEO:  Yeah, you're right.  Steve has fresh content every single episode.  We have some Q&A.  But before we do that, do you have anything you'd like to catch up on, security news?



STEVE:  Oh, we've got a bunch of stuff.  We've got an errata piece and some security news.  So absolutely.  A listener of ours, Bruce Olin, wrote to say, "Whoops, Steve, 'Coma' was not written by Michael Crichton.



LEO:  Oh.  That was Robin - that's Robin Cook.



STEVE:  Exactly.  Very good.  You pass the trivia quiz test, Leo.



LEO:  But no, when you said it, I said, oh, yeah, Michael Crichton.  Now I'm seeing the cover, Robin Cook, yeah.



STEVE:  Exactly.  So I wanted to correct the record for that.  Also there's just, well, just as we're recording this, which will now be, what is this, two weeks from today on the 18th, I guess it is...



LEO:  We're recording this on the 10th.



STEVE:  Yes, we are.



LEO:  This is going to air on the 18th, a week from - a week hence.



STEVE:  And so new for us on the 10th is just a shocking bit of news regarding Linksys routers...



LEO:  Oh, no.



STEVE:  ...that just surfaced.  Get a load of this, okay.  And this was reported on Secunia's website.  They say a security issue and a vulnerability have been reported in Linksys.  Okay, now...



LEO:  Everybody uses - everybody uses this router.



STEVE:  Yes.  The Linksys, the WVC...



LEO:  No, I don't know that one.



STEVE:  ...54GC.  So again, WVC54GC.



LEO:  This is not one of their most popular routers, thank goodness.



STEVE:  Yes.  If you have the router, you want to absolutely immediately update your firmware.



LEO:  I think it's a camera.



STEVE:  Well, it involves an OCX exploit.  And what's bizarre is this is not the first time this has happened to Linksys.  But receiving a UDP packet on port 916 causes this router to send all of your private information.  It sends the login...



LEO:  That's terrible.



STEVE:  It's unbelievable.  It sends your login credentials, your username and password, all of your wireless network connection information including your WEP and WPA keys, in plaintext, after it receives this packet on port 916 over UDP.  And in their report it says this could be exploited to gain access to sensitive information - yeah, no kidding sensitive - by sending a specially crafted packet to a vulnerable device.  So in doing some...



LEO:  Now, I'm looking at the model number.  This is a - the WVC54GC is a camera.  It's a wireless, WiFi G camera.



STEVE:  Okay.



LEO:  So that would even be more serious in that...



STEVE:  Okay, now, that also makes sense because there is an exploit in an ActiveX, in an OCX control.  And what threw me a little bit was that back in March of '07 SecuriTeam had a posting talking about a Linksys WAG200G ADSL modem router.  And their report says "...has been found to return sensitive information to anyone sending it a packet to its UDP port 916."  So, and again, it sends back the PPoA username and password credentials.  And so this was an ADSL modem router where you could send it one presumably from the WAN side, although I haven't confirmed that, and it would send back the product model, the password for the web interface, and the PPoA username and password, the SSID, and the WPA passphrase.  So basically it dumps all your private information out in receipt of this packet.  I mean, it just - lord knows why that's set up that...



LEO:  Well, and if you're using this camera to monitor your situation, they have suddenly access to your camera, as well, which isn't good.



STEVE:  Right.  So their solution is to update to firmware v1.25.  So my mistake in thinking that that was a router, the other issue was a router.  This one, as you say, is a webcam with firmware.  So you need to update to 1.25.



LEO:  Okay.  Fortunately, that's usually pretty easy.  It's just you go into the firmware of the router, go to the interface and say I want new firmware.



STEVE:  Right.



LEO:  Usually it's in the advanced section, yeah.



STEVE:  Right.  Also this was - we have had, a week ago now, Microsoft's Patch Tuesday.  So this is an event that we have, as we know, the second Tuesday of every month.  This one was a particularly massive one, 19 different vulnerabilities in - well, 19 critical vulnerabilities.  There were two privately reported vulnerabilities in GDI where any user opening or displaying a specially crafted Windows metafile could be subject to a remote code execution vulnerability.



LEO:  That's an old - that's like we [sputtering]...



STEVE:  Keeps coming back.  It's an oldie but a goodie, Leo.  It just, you know, we never seem to get rid of those.



LEO:  That's frustrating.



STEVE:  There were also the new Windows Search Service that Windows Update has been offering me now for several months.  And I put it on one machine, curious about what it was.  And it was like, eh, no thank you.  So now I just mark it as, okay, don't tell me about this any more.  I do not want Windows Search.  Well, that turns out to have been a good thing because there are two privately reported vulnerabilities, remote code execution vulnerabilities in Windows Search, where if you save a search file, or you click on a specially formed search URL, that can execute code in your machine; four privately reported vulnerabilities in IE, remote code execution which will be triggered by you visiting a specially crafted web page; eight privately reported vulnerabilities in Word and Outlook involving the display of a specially formatted, crafted RTF document, Rich Text Format document; and three privately reported vulnerabilities in Excel, where if a user opens a specially crafted Excel file, remote code execution.  So a total of 19 different remote code execution vulnerabilities that were all addressed in this December update. So even though it's been a week ago, I'm sure that our security-conscious users have - those who can have brought themselves up to speed.  I just wanted to make sure that users knew.  This will require a reboot, which is annoying.  But in this case, I mean, this is a mega pack of serious vulnerabilities you want to take care of.



LEO:  Mega pack.  And by now you should have.  In fact, I really have to say that - well, let me ask you.  Here we are, it came out eight days ago by the time you hear this.  Unless you're listening live, as many of our audience does.  Do you recommend automatic updates on Windows?  Should it be happening, like, the Tuesday that they put them out, should you be updated?



STEVE:  I've got mine set for download and notify, but don't install.  And I always choose the "custom" mode.  I like to browse through them because, for example, I got bit by XP Service Pack 3 that caused some weird things to happen, as did a handful of people.  I think you did, too.



LEO:  Yeah.



STEVE:  And things like this Windows Search.  I don't want new things added to my system without giving me a chance to audit them and decide if I want that or not.  And also I see that Windows has in optional updates, they're constantly modifying the root certificate collection.  And that's not installed by default, but I do want to update my root certificates all the time.  So, well, and I certainly don't want to have my systems rebooting themselves.  I mean, I've got my system running so well that I am literally, except for this annoying, now, constant Windows updating, I don't ever have to restart Windows.  I mean, it just goes and goes and goes and goes.  And there are times where I'll have pending updates, but it's just not convenient for me to restart because I'll be running browsers with lots of open tabs, and I'm using those sort of as placeholders for things I want to get back to.  I'm sort of - I'm using my environment as my to-do list, essentially.  So it's not easy for me to shut down, and I need to plan ahead when I'm going to go do a reboot cycle.  So anyway...



LEO:  Do you recommend that?  I mean, is that what you would tell people?  I mean, I guess if somebody - if it's your mom, you're going to say apply them automatically.



STEVE:  Correct.  And, for example, I still don't run AV.  So I don't recommend that nobody else run antivirus.  But, you know, you don't, either.



LEO:  Right.  That's just you.  Yeah.  That's us, yeah.



STEVE:  So I'm doing - I'm working in my own fashion for what works for me.  I do want to know in general that these things are available.  But I'm still - I still don't have Service Pack 3 installed on this machine.  It's like, uh, just something about it seems to be unhappy.  So...



LEO:  Yeah.  Well, I have to say, though, the way it happened for me with Service Pack 3 was I applied it, and Microsoft - on one machine.  And Microsoft said nah, and rolled it back.  It said I can't do it, rolled it back.  And then eventually I guess whatever...



STEVE:  Really.



LEO:  Yeah.



STEVE:  Interesting.



LEO:  So I think they're getting better, to their credit, about avoiding installation.  For instance, Service Pack 1 on Vista wouldn't install on machines that had incompatible drivers.  But Windows Update was smart enough to get the latest driver when it came out and then apply Service Pack 1 at an appropriate time.  So I think for most users it's probably a good idea, unless you're a listener of Security Now! and you know better, to say do it automatically.



STEVE:  Yeah, and of course in the corporate mode there is...



LEO:  That's different, yeah.



STEVE:  There have been instances where Microsoft's changes have really collided with mission-critical corporate apps.  And so there the IT guys are saying, I mean, this is why we've got the Second Tuesday rule is they wanted to lump them all together and do them at once. 



LEO:  Yeah, yeah.



STEVE:  One last bad zero-day remote code execution problem...



LEO:  Oh, boy.



STEVE:  ...in the very popular Trillian...



LEO:  Oh, I use that.



STEVE:  ...instant messaging system.  You absolutely want to update to what is now 3.1.12.0.  Anything prior to that has a zero-day, meaning that it was discovered by it being done to people, remote code execution where Trillian's receipt of an IM can cause code to be executed in your machine.  So this is another biggie.  Anyone using Trillian wants to make sure they're at 3.1.12.0 or later because this fixes a handful, actually, there were a bunch of different approaches which are being exploited in the wild, and this was found when it was happening to people.  Thus the "zero-day" designation.



LEO:  Right.  Now, the good thing about Trillian is it auto updates.  So if you've...



STEVE:  Good, good.



LEO:  It should say, hey, we've got an update.  Whoa.



STEVE:  And I have a very fun Security Now! little blurb.



LEO:  SpinRite.



STEVE:  Yes.



LEO:  You're confusing your products, sir.



STEVE:  I was reading Security Now! on the screen because it's addressed to Security Now! Feedback, which is the way the form submissions come in.



LEO:  I see.



STEVE:  Anyway, this is from Dan Baldwin, who - and his subject kind of, again, caught my eye:  "SpinRite Almost Saved a Computer."  I thought, huh?  So he starts off by saying, "Yabba dabba do."  He said, "I am the 'IT department'" - in quotes - "for a local radio station and take care of several computers that are used by the news, programming, production, and sales departments.  Recently one of the computers which holds a lot of data for sales, in fact the sales manager's computer, would not boot.  I had a friend's copy of SpinRite."  Okay, I'm not quite sure how he has that, but he just happened to have a friend's copy of SpinRite, and he "...decided to run it and recover the hard drive, assuming there was no other problem.  I put the SpinRite CD into the drive and booted into SpinRite, and it quickly found at least three unrecoverable sectors.  We let SpinRite run to the end, then pulled its boot CD and tried to reboot.  Oh, no.  The screen brought up a message that part of the Windows XP OS was damaged or missing.  But at least that was better than before."  Because before they got nothing.  "Fortunately, the computer had originally been loaded with Vista, but we had replaced it with XP.  So we had the disk for the installation, unlike most computers that come with a restore disk, and we put that in the CD drive.  When that came up, I used the "R" command to restore the operating system, XP, to normal function, and all was well again.  Thanks to SpinRite for prepping the drive for restoration.  Now, having balanced my accounts" - and he says, "I was having financial problems long before the mortgage problem/stock market drop bailout, et cetera - I have sufficient funds to purchase a copy of SpinRite for myself, which I have considered for quite a while as I have been familiar with the Leo/Steve duets going back to ZDTV/TechTV, the Click of Death, and listen to Security Now! podcasts as I drive to work at 4:30 in the morning on Sundays.  So that 'yabba dabba do' you just heard a few minutes ago was mine, as my credit card is no longer overdrawn..."



LEO:  People know about your yabba dabba do.



STEVE:  He says, "...though I could get back to overdrawn very easily."  And he signed it John Paradox, his cybernym, Dan from Tucson.  So thank you, Dan.  I have, of course, no problem with your using your friend's copy of SpinRite, and I thank you for buying your own because that's what keeps the yabba dabba dos happening at this end.



LEO:  We should explain that every time a credit card clears, not an angel gets its wings, but Fred Flintstone says "yabba dabba do" in Steve's office.  It's a complicated story.  You just have to take our word for it.  That's nice.  I think that's what happens.  You know, when you don't do copy protection - although you do, I think, a smart kind of copy protection.  You kind of watermark each copy; right?



STEVE:  Oh, yeah.  The licensed user's name is in the product.  It's built in when they download it.  And all I'm saying is take responsibility for the fact that your name is in it and try not to let it get loose.



LEO:  Well, and I think as a result you seem to get a lot of email people saying I used it, but it worked, so I'm paying you.  If you do a great product, it works, and you're not a jerk about it, people pay you.



STEVE:  Yeah.  And I have no problem with that.  I mean, I recognized a long time ago that - and I draw the notion or the line between what is lost revenue and what is not.  Certainly there are people who download SpinRite from some piracy site.  Actually we've had email saying that they ran an infected copy of SpinRite.  So that, like, hurt them more than if they'd bought a real one.  So it's not safe, I should mention.  I mean, I have talked about this before.  And I actually have had email from people scolding me for saying, Steve, you need to tell people that there are trojanized versions of SpinRite.  And I've never mentioned that before, but that is the case.  We've received feedback from people where they've downloaded something calling itself SpinRite that was actually malicious code.  So that's a problem, but it's not my fault.



So but anyway, my point is that, yeah, I recognize there are people who, no matter what I did, they would not purchase SpinRite for whatever reason.  So if they run it and take the risks of running a pirated copy, okay, it doesn't represent lost revenue for me.  So it's like, well, okay.  I recognize that.



LEO:  I think that's enlightened, Steve, frankly.  I think more people should have that attitude.  We start from John Meyer - not that John Mayer - of Orlando, Florida.  He says, "Your body is a wonderland."  No, no.  He says he stumbled on an interesting revelation.  He says: Steve, I found the following blog post by a Microsoft employee.  He gives the link.  We'll put the link in the show notes.  It's a long one.  But basically the title of it is "Update on the GDR That Is Coming for NET Framework 3.5 SP1.  It contained a note about Patch Tuesday that I was completely unaware of.  I thought this was very interesting.



[http://www.hanselman.com/blog/UpdateOnTheGDRThatIsComingForNETFramework35SP1.aspx]



STEVE:  Yeah.



LEO:  Security-related patches are the second Tuesday of every month.  We were just talking about that.



STEVE:  As we well know.



LEO:  But then they do more non-security patches on the fourth Tuesday of every month except December.  They take the week off.  I don't know what's going on there.  So these out-of-band patches that you and I talk about all the time?



STEVE:  Yes.



LEO:  They're non-security related.



STEVE:  Yup.  I was unaware of the policy.  I went poking around after I received this note from John, seeing if I could find some official policy statement of Microsoft somewhere, but I couldn't.  And looking at the blog posting, this guy is speaking very matter-of-factly about it.  It's like oh, yeah, you know, we're doing the non-security patches on the fourth Tuesday.  It's like, since when?  You are?  But, I mean, it is the case that stuff seems to trickle in, not on the second Tuesday.  And it just didn't even occur to be that those were non-security-related things.  So I don't know what that means from, like, an IT management standpoint.  But at least our users know that if they get something two weeks after their security patches, it's like, okay, this is a non-security update.  So that's cool.



LEO:  Right, right.  Excellent.  Thank you, John.  Creighton in Arizona, he's happy to be in a sandbox.  We talked about Sandboxie, of course.  Thank you, Steve and Leo, for your recent coverage of Sandboxie.  I've been a big fan of both of you for years, Leo since The Screensavers, Steve since the worm attack that shifted your focus to security issues. Was that when your system was being attacked?



STEVE:  He might be referring to the denial of service stuff.  Although actually I was focused on security ever since I realized people had their C: drives mapped out onto the Internet and said, okay, this is a problem.



LEO:  That's what did it.  That's right.  You were looking at logs or whatever, and you were seeing all these people's C: drives.



STEVE:  Yeah.  Well, in fact it was - our office was being set up with an ISDN line, the very first persistent connection to the 'Net.  And given that it was persistent, I thought, okay, what's the security implications of this?  And this, of course, is years ago.  And we received an IP for - or maybe a little block of IPs.  And I remember just sort of poking around with a scanner around the neighborhood surrounding that IP address, and there was a bunch of people's C: drives, just hanging out in the breeze.  And I thought, okay, there's no way they could know this was going on.  I mean, literally anybody could just log onto their C: drive and browse around.  It was unbelievable.  So that of course was what launched ShieldsUP!.



LEO:  That's what we call a "wakeup call."



STEVE:  Yes.



LEO:  Yikes.  Anyway, he goes on to say:  Thanks to you guys, all of my Internet activity is now sandboxed.  That's great.  That's really great.  Additionally, the sandbox - oh, this is interesting - is actually a TrueCrypt container.  So he's using another program we recommend all the time, TrueCrypt, mapped to a drive letter.  It's nice knowing that not only am I protected from malware trying to do permanent disk writes, but also the privacy of my browser usage is utterly assured, as nothing I do while online is written to the disk in the clear, but rather to the encrypted container, and then thrown out.  This is a paranoid fella.  But, you know, there's no overhead.  I don't think there's any overhead to doing this.  So...



STEVE:  No.



LEO:  ...this is great.  He says:  I'm very careful how I spend my money.  I expect you're similarly careful when you recommend something.  Certainly buying SpinRite, which has saved my bacon once already, is something I'd put in my, quote, "Gee, I'm glad I bought that" column.  And now Sandboxie, firmly in that column.  My thanks goes out to the invisible staff that make GRC, the podcast, and TWiT run so smoothly.  They deliver week after week and deserve mention as well.  Thank you, thank you.  Well, thank you, Creighton.  That's a nice letter.



STEVE:  Yup, I know you've got a good staff, and I certainly do, too, Leo.



LEO:  Well, you know, what's interesting, and I think you were talking with Dane about this when he visited you for lunch, neither of us have vast operations.  You used to have - he said you used to have 20 employees?



STEVE:  23.  We got up to 23 people.  And my lack of hair is a consequence of that.



LEO:  Yeah.  We have two full-time employees, Dane and Tony.  And they both work on Security - Tony works like the dickens on Security Now! and all the shows.  And Tony of course - Dane is, of course, doing all the payments and the money stuff.  Frederique, our office manager, is doing all the bookkeeping.  I know you have a very good office manager.  And then Colleen does the infrastructure, yeah.  And that's it.  And you have, what?  You have an office manager...



STEVE:  And a tech support guy.



LEO:  And that's it.



STEVE:  We're 100 percent virtualized now.  They both work out of their homes.



LEO:  That's great.



STEVE:  It's just - it's perfect.



LEO:  Yeah.  I really think that's great.  That's all you need.  But if you have good people.



STEVE:  Yeah.



LEO:  We're very lucky, you and I.



STEVE:  Well, and the key is they're people I trust to do the job with absolutely no oversight and management.  They don't need me to tell them what the job is.  They know.



LEO:  Autonomy.  Yeah.



STEVE:  Yeah.



LEO:  I think that my guys would say that, too, that I hardly ever breathe down their neck.  Only once or twice a day.  And I do it in a loving way.  They are in the other room, I have to say.  They're not offsite.



Garrett Lucas in West Virginia wonders why Microsoft is "sort of" updating his machines:  Steve and Leo, thanks for the great job with Security Now!.  I've been with you all since the beginning.  I have my requisite copy of SpinRite as part of the toolbox.  However, my question is about how Windows Update works with multiple computers on a network.  I have three computers on my home network.  I use them for various tasks.  I'm very strict about keeping my computers updated and patched.  And I made sure last week that all three of my computers were up to date and no high-priority updates were available.  I heard that there were going to be several patches on the 9th.  That's Patch Tuesday.



STEVE:  That's that mega - the mega patch one.



LEO:  Right, right.  So I fired up all three PCs just now to update them.  The first computer I updated said there were five high-priority updates, including some kind of core pack.  However, when I tried to update the other two computers, I was told no high-priority updates were available.  I'm a little confused.  If all my computers were up to date last week, why wouldn't they all need updating today with the new patches?  I have XP Pro on all three of them, and I can't figure it out.  The only thing I wondered was if Microsoft looked at anything having to do with IP addresses when sending out the patches, maybe saying, well, we sent out this patch to that IP address, we don't need to send it again?  He said, but wouldn't all three machines need the same updates and patches?  What's the story here?



STEVE:  You know, I have wondered the same thing.



LEO:  You see the same effect?



STEVE:  I've seen the same phenomenon where, if I go to a machine and update it, I'll go to another one, and it'll say, well, now, there's a difference between using the web interface explicitly and the little yellow shield that comes up down in your tray.  I've noticed that the presence of the yellow shield tends to be lazy.  And my guess is that Microsoft is just sort of distributing the updates out.  That is, if you explicitly say does this machine need an update, it may be that Microsoft is busy right now, that is, they're doing some load balancing, and they're saying, okay, we're going to temporarily say no until we have some more bandwidth available because we're already busy pumping out updates to a gazillion people at the moment.  So we'll let that one float back a little bit, and we'll get it a couple hours from now.  But I've definitely seen sort of this strange phenomenon of not all security updates available in all of my machines at the same time.



LEO:  Yeah.  I'll have to look.  I haven't seen that, and yet that wouldn't surprise me.  We also know that Microsoft rolls these out, though.  Right?  They don't - to keep their servers from getting bogged, they don't do it all at once.  Some people are...



STEVE:  Well, and that's exactly what I mean.  By this sort of distributed, I don't know if you'd call it a "rollout," but essentially not telling every - they couldn't tell every single Windows machine on the planet that they've got multi-megabytes of new stuff to download.



LEO:  Right.  That's 200, what is it, 200, 300 million machines.  No, maybe more.



STEVE:  Some of these updates are, like, replacing most of the OS.  So when Microsoft, you know...



LEO:  Well, I mean, even Microsoft...



STEVE:  ...does an SP3, for example, that's a 500-meg blob.



LEO:  Well, we know those, in fact, they take several weeks sometimes to push those out.



STEVE:  And so clearly they're doing some sort of staggering release of this.  Which is what I think accounts for what I and what Garrett have seen.  And I'm sure a number of our users with multiple machines have seen the same thing.



LEO:  But if you check later, does it happen in the same - in a 24-hour period, or...



STEVE:  I've seen it appear, like, even a day or two later.



LEO:  Yeah, okay.  That makes sense.  I mean, how many Windows machines - there might be a billion Windows machines out there.  I think it probably...



STEVE:  However, whenever I have explicitly gone to Windows Update or Microsoft Update to launch the browser task, I've never been lied to.  That is, as far as I can remember it's always told me, oh, yeah, we've got some stuff, here you go.  And then I browse through it.  I choose, again, the custom mode and select what I want it to do.



LEO:  That's because nobody does that.



STEVE:  Probably.



LEO:  I mean, yeah, so few people do that, they can afford, you know, they can serve all of them, I'm sure.



STEVE:  Exactly.



LEO:  Yeah.  Robert Berry in North Carolina wonders if it's safe not to scan.  He says:  I'm setting up a new laptop for my daughter to use.  I want it to be secure without the security getting in her way.  Most AV programs perform regular scans of the entire system, usually scheduled for the middle of the night, maybe once a week.  The problem is the laptop's typically powered off or suspended when it's not in use.  That means a scheduled scan ends up running the minute somebody turns on the computer, trying to use it.  And of course everything bogs down.  So I'm thinking of turning off the scheduled scans and relying instead on the real-time protection, which presumably works through hooks in a file system.  Assuming the virus info is updated frequently, isn't that enough?  I don't really see what a scheduled scan would add, if every change to the file system is scanned as it happens.  That's a good question.



STEVE:  It's a great question.  And it has also a perfect answer.



LEO:  Okay.



STEVE:  The problem is that we know that AV is inherently a reactive process.  That is, that's the problem, is that AV signatures are being updated periodically in response to the appearance of new problems that are discovered in the wild.  That is, it's not - the AV can't update ahead of seeing something.  So imagine the scenario that you've got current patterns.  Then you go somewhere and acquire a virus which is brand new and not yet in those AV patterns.  Well, that means that the scan as it comes into your system will not see it, and it'll get in because it's newer than your most recent update.  Okay?



LEO:  Okay.



STEVE:  Then if, say, the patterns got updated, well, the patterns got updated to now catch and see that virus which was in your system, it was already in.  So if you tried to acquire another copy of it, then the newer patterns would catch it.  But it would only be by doing a scan using the updated patterns of the entire system that a virus that had slipped in through that window of opportunity, between successive updates, that's the only way that one would get seen.  So you absolutely need to periodically scan because you want to catch anything that might have slipped in between the time of - in that interval between virus updates.  And so I would say scanning is not entirely optional.  It's something you could maybe take some control over so that it's not becoming a real problem.  But it's definitely something you do need to do periodically.



LEO:  Weekly?



STEVE:  Well, you know...



LEO:  That's what they usually recommend.



STEVE:  Yeah.  I mean, the question would be what damage is going to be done by the virus.  I mean, there's no hard and fast rule.  It's all sort of a heuristic stew.  So it's like, well, nightly, if you leave your machine on.  Or maybe come up with some sort of behavior where the laptop does get left on overnight on a certain time.  Or a scan is manually started when you go to dinner or something.  I mean, the idea being it is important to do it.  If you're going to rely on AV to protect you, you can't only rely on what it knows about what's coming in over the wire as it does.  You need to be able to have it take a look at things that are on your machine.  And there are various installations of AV where it's cryptographically transmitted, but then it doesn't unbundle itself until it gets into the system.  So again, it might be missed until it's actually present.  So scanning is definitely something you don't want to put off, if you're a person who relies on AV.



LEO:  And, you know, you can just control the schedule or say - I do most of that kind of automatic stuff, like backup scanning and stuff, right after the end of the workday, like 5:00 or 6:00 p.m.  So I know the system will still be on.



STEVE:  And it's like defragging.  No one wants to defrag their disk while they're trying to use the computer actively.



LEO:  You can't.



STEVE:  Exactly.  So many of us will deliberately start a defrag process when we're going out to dinner.  And we come back, and it's done.  So I would say putting scanning in the same class as that, where you give it some deliberate focus of your schedule.



LEO:  I've never asked you this.  Do you have an AV product you recommend?



STEVE:  No.



LEO:  Okay.



STEVE:  I don't know much about them, actually.



LEO:  It's, you know, the more I learn about this, the more I realize it's impossible - there are a number of companies that will have a kind of a set of viruses that they throw the AVs at, and then they give you a score.  Virus Bulletin does that.  And AV companies hate this.  I've talked with AV companies.  They say, you know, you just tune the - you tune the antivirus to work with the set.  It's a synthetic.  It's not a good measure.  And yet measuring the effectiveness of an antivirus in the wild is next to impossible.  So I don't know how you do it.  The only thing we've ever done is measure how much impact the antivirus has on your system.  And then you just have to say, well, I hope it catches everything.  I mean, I don't know what you do.  I don't know what you say.  I mean, it's something that, you know, you need a PC Magazine and a lab.  And unfortunately all these guys are shutting down their labs now.  It's not a good - it's not a moneymaker.



STEVE:  I'm very careful with what I do.  I run with scripting turned off.  I just - the nature of my computer use is very proscribed, I think, compared to most people.  So I'm not just wandering around clicking on things.  And maybe because I'm a mature adult I'm not intrigued by some of the more dangerous areas of the Internet, where were I a young teen I might be much more likely to get myself in trouble.  So I think my own demographic habits don't put me at risk to much degree.  I'm a boring user of the Internet.



LEO:  Well, and you also don't - I think now the number one vector, I would guess, is clicking - and in fact I think I just read a study that said this - is not attachments in email anymore.  And I think we've trained people pretty well not to open email attachments.  But clicking links that either take you to a site loaded with malware that just tries every exploit, or explicitly says, oh, you need new Flash.  Download Flash and install.  And you know enough, I know enough, anybody that listens to this show knows enough not to do that.  It's nave users who go, oh, yeah, I often need a new Flash.  They go download it, something didn't happen right, oh well, oh well, and they go on.  And they're the ones who are infected.



STEVE:  Yeah.



LEO:  So I think it's navet in many cases.



STEVE:  No, you're right.  And in fact one of the other - one of the recently very effective approaches, unfortunately, is something gets in your machine, or you're browsing and you run a script, and then the script generates a pop-up that says, oh - and it looks very much like Windows.  And it says that it's scanning your system for malware.  And then, oh, surprise, it finds something.



LEO:  Quite a bit, yes.



STEVE:  Yes.  And then it says, oh, you need to update your AV.  Click here to purchase an update.  And, I mean, even the most...



LEO:  Suspicious?  Paranoid?  Careful?  Cynical?



STEVE:  Yeah, I was going to say, it really - that approach catches out even relatively experienced users because they're used to Windows popping things up, and they just assume this is Windows.  I mean, they don't get that - and in fact it can even be disconnected from your going to a page.  Someone might be skeptical if the moment they go to a page it pops up a pop-up because lots of people had that happen back in the advertising pop-up days.  But it's possible for scripts now to use various means to delay notification so there isn't the association between the web page you went to that initiated this and the presence of the pop-up.  So it seems more like it's Windows doing it for you.  And, I mean, again, it's a social engineering sort of hybrid attack.  But I read somewhere that one third of the viruses now, or malware, in people's machines are coming in that way, from something popping up and saying, oh, we're going to check your system for malware.  And in fact, if you purchase from them, of course, they collect your credit card information, as well.  And what you download is a trojan that is remote controlled, that lets them take over control of your machine.



LEO:  This is...



STEVE:  It's getting a lot of people.



LEO:  It says Antivirus 2009 at the top of the window, looks very realistic.  And, yeah, we get a lot of calls on the radio show from people.  A lot of them don't even know that they've been bit.



STEVE:  Right.



LEO:  Richard Warriner, Bedford, U.K., has been playing with his new PayPal footballs.  Stop playing with your footballs.  Steve, he says - although I play with mine all the time.  There's something about it.  You just want to, you know, kind of press the button and - ooh, it's so fun.  After the heads-up on the show a couple of weeks ago that PayPal dongles were now available in the U.K., I got myself a couple.  I now get prompted to enter my security key number when logging in, either via the dongle or sent direct to my mobile.  However - you know, his cell phone - there is still the option to click that I don't have my dongle, and then I can log in via security questions.  It seems crazy that this backdoor exists.  I kind of am with him on this.



STEVE:  Yeah.



LEO:  And there's no way to disable it.  The only solution seems to be changing the answers to the security questions to the wrong reply so that nobody can guess them.  The issue here is that one of the options is my bank account number, but I can't enter bad info here as PayPal uses it for funds, and it needs to know that number accurately.  Am I missing something?  Is this a hole?  Is this a bad thing?



STEVE:  Why don't we go ahead and read the next one, from Theo.



LEO:  Okay.



STEVE:  It's about the same issue, and we'll talk about them both at once.



LEO:  Yeah.  This is - I'm glad that they wrote in because this has kind of bugged me for a while.



STEVE:  Yup.



LEO:  Theo is Theo Jones in London.  He says:  Love the podcast.  Just checked out the PayPal security key, new to us in the U.K.  So we're getting a lot of new users on this one.  But they're smart, and a red light goes off for them.  He says:  It gave me the option to use my phone as a security key instead of getting the football.  This is the thing that I like that my bank is doing lately.  So when I log in, it sends me a text message with the number.  Hey, great.  However, I decided to look at the option for "I don't have a security key with me."  It gave me two options to identify myself, bank account number or security question.  I was very surprised.  My bank account number is an eight-digit number.  They gave me the last two digits so I'd know which one it is.



STEVE:  So, you know, blank out the first six; right.



LEO:  It's only six.  My bank account number is not exactly public knowledge, but it's not super secret.  I've given it to several friends and family members.  And I think it's on the check.  It's on your check.



STEVE:  Yeah.



LEO:  It is in the states.  Everybody you write a check to has your bank account number.  It's on various bank statements, too, which could fall into the wrong hands.  I understand this is still two-factor authentication.  But it seems like the fact that the random element of the security key being lost reduces security to quite a large degree, in fact to where we were before.  Because the hacker just says, well, I don't have the key.  It's actually quicker for me to bypass my own security key and type in my account number.  Am I right?  Am I missing something?  What do you say to these people?



STEVE:  Yeah.  I mean, I'm impressed with both questions, and I am really disappointed with PayPal.  I followed up and looked at this.  And in addition...



LEO:  But everybody does it, Steve.  They have to because people lose the dongle.



STEVE:  Yes.  It is a perfect example of compromising security for the sake of convenience.  And, I mean, I could understand doing it if they allowed you to disable it.  When I told them that I don't have my dongle with me, I get one additional thing.  I get the security questions, I get my bank account number, and the credit card that I have registered with PayPal.  So three different options.  And, I mean, and no ability - I clicked on them.  I explored around.  There's no ability to say I do not want fallbacks for my dongle.  I mean, it is truly not secure.  And it just, I mean, the only benefit you get, if you don't choose those, is the one-time password aspect, where - which is of course why the football exists in the first place, is so that if something were monitoring your log-in, if there was a sniffer, then it wouldn't be able to use the same code to pretend to be you again.  Whereas if you did use one of your fallbacks, then a sniffer watching you log in would be able to do so.  So there is still a benefit to using the one-time password aspect.



But both of these guys are right.  PayPal has substantially reduced the overall security of their log-in.  And as we know, just, I mean, all of our listeners know it's a fundamental aspect of security that the more ways you offer of getting in, the lower the overall security of the result is.  It's just like how many times I've griped about all of the root certificates that are now in our browsers.  That list just goes on and on and on.  And it's like, you know, all it takes is one of them to make a mistake in issuing a certificate, and we're in trouble.  And so the more you have fundamentally, the less your security is, the less secure you are.  And similarly, the more different ways to log in, fundamentally the less secure that is.  And so, I mean, I'd absolutely take responsibility for having my football with me and disable the alternatives.  But there's no way to do that with PayPal right now.



LEO:  Yeah, yeah.  Or my bank.  And, you know, my bank is using the cell phone thing, where they send you a passcode.



STEVE:  Oh, and get this, Leo.  I don't know if you heard.  But there's some dialogue.  Apparently some of the carriers are going to start doing a surcharge if a non-phone sends you a text message.



LEO:  Yeah, I did see that.



STEVE:  And that is so annoying because texting is probably the largest profit center...



LEO:  Oh, yeah.



STEVE:  ...of telephones.  It's, like, zero bandwidth in terms of usage of bytes traveling through the air.  And they make more money from texting than from anything else.  And so now they're going to start, I mean, who would send a phone a text message except some sort of an authentication loop?  And now they're going to hit you with some extra charge for that.



LEO:  Yeah, it's like three - actually, who they hit is the bank.  It's, like, three cents.  But, you know, people use it for Twitter and other things.  It's a gateway to SMS via email, and they want to charge you for that.  I agree with you.  I did the math once.  Even if you use all 140 characters every time that you send a text message, at the rate they're charging, 20 cents a message, that's $1,500 a megabyte.  That's a good profit.



STEVE:  And Leo, in terms of data bandwidth, when you compare that to speech, speech, which is a constant flow of bytes between you and another party, compared to a single shot of, you know, a short burst of data, there's no comparison, the bandwidth consumed by audio versus SMS.  I mean, SMS ought to be absolutely free.



LEO:  Or at least cheap.



STEVE:  Yeah.



LEO:  I'm with you on that one.



STEVE:  [Indiscernible] take your money, so that's what they're going to do.



LEO:  Cell phone companies, these guys, just they're awful.  Just they deserve every bit of opprobrium they get.



STEVE:  It's a racket.



LEO:  It's a racket.



STEVE:  And by the way, I did finally go to Verizon and try typing on the Storm.  And, no.



LEO:  Yeah, I got a Storm here.



STEVE:  No.



LEO:  Yeah, I got a Storm here.  It was a little hard to - you know, if you want a BlackBerry, get the Bold.  The Bold has a real keyboard.  It's a nice...



STEVE:  But the Bold forces you over to AT&T, and I will not go there.



LEO:  Oh, you're Verizon, that's right.



STEVE:  Yeah.  And so I'm hoping that BlackBerry - there'll be enough backlash from people who actually want to type on a keyboard that they'll move their newer technology to another BlackBerry that Verizon will carry which will still have a keyboard on it.



LEO:  I think Verizon will get the Bold pretty soon.  You know those exclusives don't last very long.



STEVE:  Ah, that would be perfect.  Because the Bold would be absolutely the right phone, except that it's on the wrong carrier.



LEO:  Right, it's AT&T right now.  But I think that that...



[Talking simultaneously]



STEVE:  ...phone carrier.



LEO:  Yeah, isn't that kooky.



STEVE:  Yeah.



LEO:  No, I agree with you.  I have a Storm here, just for review, and it's that clicking thing, it's just too hard to type on the screen.



STEVE:  And I was doing a little bit of a search through my Kindle the other day that has that same sort of little thumb keyboard?  And I was really surprised how fast I can type on that.



LEO:  Oh, yeah.



STEVE:  I mean, that's the right thing.



LEO:  That's all you need.  I like real keyboards.  I do, too.  Kyle Hasegawa of Tokyo, Japan clarifies Zone Labs' DNS usage.  Remember we had last time a question saying, hey, I was watching ZoneAlarm with Wireshark and all this.  Dear Steve and Leo:  After hearing about ZoneAlarm phoning home from one of the other listeners, I decided to test this out for myself.  I set up a virtual machine to install the latest ZoneAlarm v8.0.065.0000 and enabled PCAP on my router.  Here's what I found.  ZoneAlarm does not send DNS requests to its own servers.  But it does request lookups of zonelabs.com and register.zonelabs.com on the DNS servers configured in Windows.  In fact, I don't think an application can override the system's DNS server list when making DNS requests through ServiceHost.



STEVE:  I think that's probably true.  I was wondering about that myself.



LEO:  ZoneAlarm does phone home just after installation, but it does so using a normal browser window and some ASP thank-you-for-installing pages with non-personal information about your instance of ZoneAlarm appended as query string parameters.  Also, strangely, ZoneAlarm does continue to query zonelabs.com every 10 seconds.  That's what our other listener was seeing.



STEVE:  Right.



LEO:  But these are normal queries to the configured DNS servers.  There's no extra data going on.  So what's going on?  Why is it doing that?



STEVE:  Well, I wanted to clarify.  We left this sort of pending.  What the other user saw with Wireshark was not queries to Zone Labs' servers, but queries of Zone Labs.  So he saw this little 10-second heartbeat querying zonelabs.com.  The only thing I can think is that maybe it's a way of detecting 'Net connection, whether your system is currently connected to the Internet.  Because those queries are not - if they're just going out to your registered DNS servers, the first time you do it it's going to cache in your ISP's resolver, as we all know from understanding how DNS works.  Subsequently, for as long as the TTL, the Time To Live, of the records which were received from Zone Labs servers are living in your own ISP's cache, it's going to be responding.



So my feeling is this must be a way, this must be the way that the ZoneAlarm Firewall keeps a constant watch on whether you have an Internet connection or not.  Because when you drop off the Internet, then the system's attempt to get an update on zonelabs.com would fail.  And so that must be what it's doing.  It's using this little heartbeat to sense a connection to the system's configured DNS servers.  When that no longer exists, that will fail.  And so that's the way Zone Labs knows, or ZoneAlarm, the product, knows that your machine is no longer on the Internet.  But it's definitely not a phone-home technology, and there's no information dribbling out of them, from what Kyle has said.  And what Kyle has said makes absolute sense to me.



LEO:  Well, I'm glad to get that.  And as I said last time, we're just listening to what the listeners are saying.  We haven't done any verification on our own.  So there's two different stories going on, and who knows what's really going on.  But that kind of makes sense.  It's a ping to say, am I alive?



STEVE:  Right.



LEO:  And that would make sense.  And with no extra data going out.  And that's not - what Kyle is saying is not inconsistent with what our first guy was saying.  He wasn't looking at what they were sending out.



STEVE:  Right.



LEO:  Okay.  Actually we have two Sandboxie comments here, one from Mathieu in Montreal, Canada.  He was kicked out of his 64-bit sandbox.  Hi, Steve.  I just wanted to give you and listeners of the fine Security Now! show a heads-up concerning the compatibility of Sandboxie.  Yeah, I heard other people say this.



STEVE:  Oh, yes.



LEO:  In fact, when we were talking about Sandboxie I heard this from the chatroom.  I was looking forward to trying it out on my new Vista 64 computer until I found out that Windows PatchGuard prevents the use of Sandboxie.  PatchGuard is the technology Microsoft has put in to say you can't modify the kernel.



STEVE:  Yes.



LEO:  Sandboxie is such a great concept, but I guess I'll have to stick to virtualization for now unless there are enough voices heard at Microsoft to make the move and allow us to disable or bypass PatchGuard for selected applications.  Thanks for the wonderful show.  Also Peter J. in Orangevale, California.  He's using Sandboxie, but he says only for the time being.  Hi, Steve and Leo.  I'm a regular Security Now! listener, have been since the early episodes.  After listening to the recent Sandboxie episode, I finally decided to buy it after having used it since you guys talked about it a couple of years ago.  I love the program, find it extremely useful.



However, after I browsed around in the Sandboxie forums I noticed the author said there will never be a version for the 64-bit version of Windows due to PatchGuard because it prevents modifications to the kernel.  That made me very disappointed since Sandboxie is one of those applications I'd like to make a part of my software arsenal for years to come.  I suspect there isn't a good way of bypassing PatchGuard.  Actually we know there is.  You've talked about it, Steve.  But is there a way that Sandboxie can live on without having its hooks into the Windows kernel?  Is there a way to do that?  I just don't want to lose such a great platform once I finally make the switch to the 64-bit platform.  Thanks for a great podcast.



STEVE:  Everybody who is interested in 64-bitness has been concerned about this.  In the second case, Peter is using a 32-bit system, but he can foresee the day that he'll be  migrating to a 64-bit platform, probably Vista.  And so he's unhappy that he'll be unable to use Sandboxie there.  And our first questioner says he's already on Vista 64 and can't use it at all.  It causes a - first of all, we got a huge amount of our listeners who wrote in, said wait a minute, how can this be?  How can it not work in 64 bits?  And over in Sandboxie's own forums this is a real sore point.



I've discussed it with Ronen.  And he's not at all happy with Windows, or with Microsoft over this.  But it is an absolute fact of what PatchGuard does.  In order for Sandboxie to do its sandboxing, which is completely different from the way Windows operates, Windows has no inherent capability to, like, to create sort of this forked caching area, which as I described Sandboxie is the way it works, is when it opens a file or even a registry region where it wants to make some changes, those changes are caught and written instead into the so-called "sandbox," which is just a set of files sort of off to the side.  And then any reads are intercepted and fed back from the sandbox.  So the application sees that it's written, even though it's only written to a private copy, essentially.  It creates like a little private fork off of the operating system where all the changes go.



To do this you absolutely, because there's no facility built into Windows to allow this, you have to intercept Windows, the API, the Application Programming Interface in the kernel and essentially filter, is the term, filter those things like file reading and writing, and registry key opening and reading and writing, and all the various things that applications might do to modify the system.  You have to insert yourself down there and intercept those.  Well, that is also, unfortunately, exactly what rootkits do, is hook the kernel in order to hide themselves.  So exactly what PatchGuard is designed to prevent, and it does very effectively, is what Sandboxie needs to do in order to do its job.  So there's a complete collision.



Now, the early versions of the 64-bit XP had weak PatchGuard that Sandboxie was able to live with.  And so Ronen went to the trouble of doing a 64-bit driver.  He had 64-bit hooks.  And there was a 64-bit Sandboxie which actually is still available from his site that runs under 64-bit XP.  But then later, along came an update as one of those serialized-looking updates, and he shows you which one it is on his site.  And the update strengthened XP's 64-bit PatchGuard technology, brought it up to Vista strength, and Sandboxie would no longer work.  It would immediately crash the system when it attempted to come in, and Sandboxie attempted to - when Sandboxie's service started up, which is where it then hooked these API calls, it would immediately crash the system, which is what PatchGuard does.  I mean, it's a deliberate shutdown saying the OS has been corrupted.  The only thing it can do is just refuse to go any further, and it just shuts down.



So, I mean, this is a huge concern for the people who love Sandboxie because they want Sandboxie in the future, in fully patched Windows 64 or in Vista 64.  But there just isn't - there is not a way to do it.  I mean, it's just oil and water.  You cannot make them cohabitate.



Now, you'll remember that some of the firewall vendors were upset by this, too, because firewalls have traditionally been deep kernel hookers in order to install themselves, since Windows did not provide the hooks that firewalls needed.  So Microsoft produced a PatchGuard API to allow those sorts of things to be done.  Unfortunately, it's not extensive enough to allow Sandboxie kinds of things to be done.  It's not a general purpose patching facility.  And the problem is, you can't create a workaround, or the bad guys would use it.  The instant there was a way for Sandboxie to do the things it does, there would be a rootkit that whatever it was that Sandboxie was doing, this rootkit would do it.  So, I mean, Microsoft has to create an absolute barrier.



And so essentially people want what Sandboxie is doing, but they want it in an environment that is absolutely resistant to having the kernel modified.  Now, you could argue that, okay, fine.  If Vista 64 doesn't let me do this, do I need Sandboxie?  And the answer is yes because what Sandboxie is doing is preventing modification, and sandboxing and caching modification, which is a different sort of behavior than what PatchGuard is preventing.  PatchGuard is protecting the OS, but not necessarily the configuration of the OS.  It's protecting the function of the OS.  So PatchGuard is protecting changes to the configuration, which Vista 64 and the patched XP 64 doesn't do.  So having PatchGuard doesn't obviate the need for Sandboxie, but it does unfortunately prevent Sandboxie.



LEO:  And we - go ahead.



STEVE:  And it's just, I mean, it's just like game over.  Ronen is really not happy because he feels the pressure.  He invested in a 64-bit solution.  He had one.  It's still available.  But if you install - and if you remove that one little update in XP, then Sandboxie will work with the reduced PatchGuard strength.  But that's not a good solution for the long term.  And he recognizes that fully, and he's just fuming over the fact that he can't go into the future with 64 bits due to PatchGuard.



LEO:  Well, I'm sympathetic with Microsoft.  I think the key is that, if Microsoft's going to do this - which I think they should do, I don't think anybody should be allowed to modify the kernel - then Microsoft has to provide Sandboxie-style sandboxing.  Right?



STEVE:  And unfortunately this is a good enough idea that you can see, you can foresee Microsoft saying, hey, that's kind of cool.  Let's add that.



LEO:  Well, hire Ronen or give him some money.  I mean, I'm sympathetic with Ronen.  But I think you and I both agree that PatchGuard is a necessary step forward with Vista.  That's what we've talked about; right?



STEVE:  Yes.  It is.  It's a good thing, and so is sandboxing.  I think that if - I wouldn't be surprised to see, well, I mean, remember once upon a time Windows had no firewall.  We were all jumping up and down, saying gee, let's add a firewall to Windows.  Well, Microsoft got a clue finally.  Took a long time.  They added a firewall to Windows.  I wouldn't be surprised if some future version of Windows offers sandboxing natively.  But I can absolutely guarantee that there's no way that Microsoft is going to be hiring Ronen or giving him any money because that's just not the way Microsoft works.  They'll just do it themselves.



LEO:  They'll do it themselves.  And didn't we talk, when we talked about PatchGuard - maybe it was on Windows Weekly, but I think it was on Security Now!.  There are ways around it, aren't there?  Remember it was kind of not the strongest - it was like Microsoft saying, hey, guys, get ready because we're going to really enforce this.  But they're not yet a hundred percent enforcing it.  Or are they?



STEVE:  Well, it's been so long since I looked at it closely, and I'm not a Vista user.  So I remember something about that, but I don't remember whether it was PatchGuard.  It might - there are many different new security features in Vista.  And so it might have been something else.



LEO:  My dim memory, and I may be wrong, is - and I'm sure we'll be corrected - that in this instance the way they implemented PatchGuard on Vista 64 was as much to say to legitimate companies, hey, don't base your business model on modifying the kernel.  Going forward we're not going to allow it.  But if you were willing to be illegitimate, there are ways around PatchGuard.  If you were willing to break the rules, there are still ways around it.  And I guess the message was, hey, Symantec and Ronen and everybody, you're a legitimate business.  You don't want to break the rules here.  And going forward, you're not going to be allowed to.  That's my memory of the discussion, but I don't remember the details on that.  So I think there is a way around PatchGuard, in other words.  But I could be wrong.  You're the expert.



STEVE:  I can guarantee you that Ronen is unable to operate with it.  So whatever...



LEO:  Well, but he may not want to do the things required to break it, in other words.



STEVE:  No, that's not, I mean, it cannot work.  It absolutely will not work because he did all those things originally and was compatible with XP's PatchGuard before they strengthened it up to Vista level.



LEO:  Right, right.  Okay.  Daniel Smith in Sioux Falls, South Dakota added an exclamation point to Wizmo.  Wizmo!  Bang.  He says, "Wizmo Fixed It."  Wizmo.  I love Wizmo.  I'm glad we can give a plug to Wizmo.  Dear Steve:  To start off, thank you for all you do.  Now onto the feedback.  I'm a desktop support representative at a company.  And recently we've been having problems with a few brand new PCs.  I just put them into service.  For whatever reason, these systems refuse to log off.  They refuse - this is very common.  I see this all the time.  They won't shut down or reboot for any of the users they were assigned to.  Now, I was getting frustrated.  I was going to create batch files to have these users run to use Windows' built-in shutdown command, when for whatever reason I remembered your dinky little Windows gizmo - no offense intended.  I figured I'd give it a shot on a user's machine.  I have nothing to lose.  Your application, all of your applications have a great track record of being solid and dependable.  I wanted to see what would happen.  Also Wizmo would be easier for an end-user to operate than my little batch file.  At first we tried Wizmo's "nice" command to log the user out.  Windows said unh-unh, not gonna do it.  We then got serious, asked Wizmo to make Windows an offer it couldn't refuse.  You do have that switch; right?  Forced, forced it to shut down.



STEVE:  And literally, you put an exclamation point on the end of the verb "Shut Down" or "Log Off" or "Reboot."  I call it - I don't want to offend our users.  I call it the "Dammit Variation."  Shut down, dammit.



LEO:  Shut down, dammit.  Lo and behold, in the battle of wills, Wizmo won.  Windows logged the user off.  But wait, there's more.  After that point I thought we'd have to continually use Wizmo on those systems.  Since we're a corporate environment, we're leery about continued use.  Going to the bank, oh, let me shut down, I've got to use Wizmo.  Despite Wizmo being a free piece of software, it's still another application that has to be installed, tracked, okayed by the powers that be.  However, my Windows user decided to try logging out the normal way without Wizmo's help.  This time Windows did it.  It would restart, shut down, log off, everything.  We got the same results on the other machines that were also exhibiting the problem.  Before Wizmo, they didn't work.  After using Wizmo to teach them a lesson once, they all worked.  Needless to say, you gave me a great Christmas gift.  I've installed Wizmo on all my personal machines.  Now I have it on my work machines.  It's free, by the way.  I'm still not installing it on every machine at work.  However, I'm keeping it ready in case anyone complains about Windows giving them trouble.  Thank you for this excellent tool, and have a Merry Christmas.  Hey, that's really cool.



STEVE:  And I have no idea why.



LEO:  Well, when Windows won't shut down it's because there's a process that won't exit properly, usually; right?



STEVE:  Well, yeah.  That I know.  And there's also - sometimes it'll sit there saying "Saving user preferences" or something.



LEO:  I hate that.  I have that all the time.



STEVE:  Oh, goodness.



LEO:  So what does the bang do?  What does it say?  I mean, is it a different call to...



STEVE:  Yeah.  Yes.



LEO:  Are you using interrupts?  What are you doing?



STEVE:  Well, down in the API there is a force option.  And so I don't know what it does.  But I say, okay, I'll give the user the option of forcing it.  And so it may just say, look, give apps some time and then force them to shut down.  What's bizarre is that apparently doing this once fixes the problem then on.  So you no longer need Wizmo at all.  You can just use the regular Windows shutdown, logoff, and reboot, whatever.



LEO:  Does the force lose data if you have unsaved files, things like that?  Will it force close...



STEVE:  I don't think so.  No one has ever, I mean, I don't know.  Since I don't know what it does, I really don't know what the implications are.



LEO:  Probably, you know, it's probably setting a higher standard for, like, am I going to stick around.



STEVE:  No one has ever complained of Wizmo costing them, like, any sort of data loss.  I would be extremely surprised if that were the case.  But, I mean, because it is part of the API.  And I would be surprised if anything in the API allowed you to, like, deliberately close a file that had been - that hadn't been saved.



LEO:  I bet you there's something Microsoft's doing, like saving settings or something, there's some script that runs once.  It must be a run-once.  And when you do this force, it figures, hey, I did it, and it never tries again.



STEVE:  Whatever it is, it works.  So I just wanted to share it with our listeners in case anyone has encountered this problem before.  There is a free fix for it, and apparently you only need to use Wizmo once, and then it teaches Windows a lesson.



LEO:  It's going in my database because I get this call weekly on the radio show.



STEVE:  Perfect.



LEO:  Windows won't shut down?  Wizmo.



STEVE:  With an exclamation point.



LEO:  Bang.



STEVE:  Wizmo Bang.



LEO:  I love it.  Andrew Green of Tampa, Florida, shares his Knuckle Print of the Week Story.  I love these.  Hi, Steve and Leo.  Last week I took the drive over to Universal Orlando.  Being a Florida resident we got annual passes, a slight discount.  When we got there, they scanned your pass, and you're required to provide a fingerprint.  It's obviously leaking over from the Disney folks next door.  Now, being a listener of Security Now! since Episode 1, I knew this wasn't a good idea.  I told the attendant I didn't want to do it.  She said I have to.  So like your previous correspondent, I used my knuckle.  She said no, it has to be a fingerprint.  After a bit of arguing, we got a manager who reluctantly put a sticker on my pass stating "Check ID."  This guy might be a sneak-in type.  Battle won.



If that were not bad enough, some rides didn't allow bags, but they provided free lockers.  The locker system was automated, and no attendants are around.  Your key?  Your fingerprint.  The system checks your - I'm sure they think, oh, is this cool, we'll do this.  The system checks your fingerprint twice, assigns you a locker.  When you return you enter your locker number and your fingerprint.  If they match, it opens.  Luckily we didn't have any bags.  But besides the fingerprint issue, there was no way to unlock your locker without a valid fingerprint.  So if you forget what finger you used, or they don't align correctly, your locker won't open.  There seemed to be no way to override this system since no other information is taken other than your fingerprint.  What would prevent someone from getting an attendant and asking them to open your locker?  I saw no reason why this could not happen.  I don't know if they have more traditional lockers.  We didn't have any bags; we didn't bother worrying about it.  If you go to Universal, pack light, make sure you have your ID, and stand up for your privacy.  Keep up the great work.  Boy.  That's a story.



STEVE:  Yeah, this is the sad consequence of fingerprint technology becoming inexpensive.



LEO:  All of this bio...



STEVE:  Well, yeah, I mean, fingerprint readers are now very inexpensive.  And it's like, oh, this is wonderful.  Let's just put fingerprint readers everywhere.  And unfortunately, you know, fingerprints are personal property.  We've talked about it.  Fingerprints is not something that you want to be sending out in digital form all over the place.



LEO:  So modern.  We use fingerprints.  We're the future.



STEVE:  Yeah, we ought to come up with, like, some sort of a - remember how on "Hitchhiker's Guide to the Galaxy," Arthur Dent had - I guess it was Arthur - had an electronic thumb that was - it was a way of, like, thumbing a ride for a passing alien spaceship.  [I'm pretty sure it was Ford Prefect who had the electronic device.  Elaine]



LEO:  That's right.  That's right.



STEVE:  And we ought to come up with, like, some sort of rubber thumb, like just, you know, you carry it around in your pocket, and it's somebody else's fingerprint on the thing, and you just push it against the screen when you - when something says we want your fingerprint.  So, like, this is just a bad - this is a bad trend we're seeing here.



LEO:  You could see why people start to figure privacy's dead.  You know?  I mean, this is just going to be everywhere.  And at some point you just throw up your hands and say, fine, take my fingerprint.  I mean, just people just give up.  Most people don't even know.  But even - but those of us who know, at some point, I mean, I just go, okay, fine.



STEVE:  Well, and our listener Andrew, I mean, he had to fight them not to take his fingerprint.  And, you know, not all people, even if you're security conscious, are going to feel like putting up a big fight.



LEO:  I'm not a fighter.  I always said all right, all right.  I would have tried the knuckle thing.  And if they didn't, I'd say okay, fine.  Which is not probably a good idea.  We don't know what they do with that fingerprint database.  Who knows.  You know.



STEVE:  Yup.  I say give them a knuckle if you can.



LEO:  Right to the temple.  An anonymous listener brings us the Hard Drive Destruction Headache Story of the Week.



STEVE:  [Groaning]



LEO:  We were talking about how to get, you know, is drilling - you said drill a hole through the platter and so forth.  In Episode 173 you guys spent some time discussing secure disposal of hard drives that no longer function.  I'm an admin with one of the top security companies in the world.  We go through a lot of SCSI and SAS drives a week in our RAID systems.  We have Dell to thank for that because their hard drive firmware requires an update on a lot of our systems, but you have to take the server down before updating the firmware on the RAID arrays.  That's not exactly an option.  So since Dell doesn't offer a live firmware update - HP does, by the way - we kill disks like it's our job.  To dispose of - this is terrible.  So they have to shut down, and then the disks die because they shut down?  Is that...



STEVE:  I don't quite - I didn't quite track all that.  But I, you know, I believe him.



LEO:  To dispose of them we have a large degaussing machine about the size of a microwave.  Wow.  We shove the entire drive into the machine, hit a button, and after two seconds the drive slides out the side fully degaussed.  That's interesting.  So I was talking about doing it in the radio station degausser.  But obviously if you have a big enough magnet...



STEVE:  Oh, just wait till you hear what this thing - what the side effects are.



LEO:  We had some guys test the disks afterwards to check for data.  Not only does it fully destroy the drive, it seems to destroy the heads on the drive.  The thing won't even spin up.  It probably bends.  Everything gets bent.  This may be why we get a little bit of a headache after using the machine for a while.  Yeah, maybe.



STEVE:  Ooh.



LEO:  Maybe you want to get a lead apron.



STEVE:  Ooh.



LEO:  Can you get hurt from a magnetic field?  Is that bad for you?



STEVE:  Well, MRI uses a very strong magnetic field.  But, I mean, the idea that this thing gives them a headache...



LEO:  That's not good.



STEVE:  ...I mean, that's just - that's really frightening.



LEO:  That's not good.  Maybe it's just - it could be like a low hum or something that's bugging them.  I hope that's it.  Yeah, wow.  So while you guys and some listeners may like to vent by dismembering some drives, for anyone doing any kind of volume destruction, I'd say buy a degaussing machine.  Just leave the watch, iPod, credit cards, et cetera, in another room, if you still want them to work afterwards.  And bring some Tylenol.  Oy oy oy.



STEVE:  Oh, yeah.



LEO:  Oh, man.



STEVE:  So just I wanted to acknowledge that industrial-strength degaussing does exist and is clearly effective.  It sounds like not only is there data on the drive, there's also extensive servo information, which is always prerecorded on the platters.  And the degausser will, of course, uniformly wipe everything.  So there's no way, I mean, it's not like just - it's not going to selectively remove the data out of the sectors in between the so-called "sector headers."  The beginning of every sector has a bunch of management.  Very much like a packet has header data at the beginning of the packet, sectors have sector headers that confirm that the head is on the right track and the sector number and the status, the health of a sector, is this one maybe no good, in which case there can be a pointer to the sector that has been replaced so that the drive then goes and gets the data from the relocated sector.  It's all that kind of housekeeping data.  So all of that will get wiped out, in addition to some carefully laid down servoing information, which is what the heads read in order to follow the tracks around the drive.  That's all gone, too.  So, I mean, I'm not at all surprised this drive doesn't even spin up.  I mean, it's just - it doesn't know what has happened to it.



LEO:  I'm a mess.



STEVE:  I mean, the drive has a headache, in addition to the people who are using this thing.  But boy, I tell you, if a machine was giving me a headache, I would seriously wonder what other radiation besides magnetic it's putting out because I don't think a magnetic field can give you a headache.  But...



LEO:  Well, we have hemoglobin; we have iron in our blood.  Maybe it's pulling all the blood to one, you know, like one side.  Like [sound effect].  That would give you a headache over a period, you know, if all the blood is pulled to one half of your head.  I don't know.  I'm sure, again, I love talking about stuff like this, Steve, because invariably we've got somebody really smart who's listening and says, oh, yeah.  Well, I know why that's happening [muttering].



STEVE:  Well, and there have been science fiction stories where super strong magnetic fields have killed people by pulling all the iron out of them.



LEO:  Right.



STEVE:  You know, all the iron in their blood gets yanked out.



LEO:  And there's a lot of quack science about this, you know, the orgone machines and all this stuff, which is all quackery.



STEVE:  Yeah.



LEO:  But in the early days of electricity, that's what - that's a lot of the stuff that people did was, like, medical treatments with magnets.



STEVE:  Well, and there are still people, yeah, who will pass magnets over you and believe that it's helping you somehow.  It's like, okay.



LEO:  Oh, I don't think so.



STEVE:  Good luck with that.



LEO:  Yeah.  Hope it helps.  Randy Hammock, Lake View Terrace, California, with our last question of the week.  It is our Hard Drive Destruction Tip of the Week.  Seems that most of the drives I've had use glass or ceramic platters.  So I just take the drive outside and toss it on the sidewalk.  After a single toss, I pick it up and shake to see how much it rattles [laughing].



STEVE:  Isn't that great?  I love that.



LEO:  If it doesn't sound like sand rattling around, and it almost always does, then a hammer strike or two will render the platter pretty much destroyed.  So are a lot of drives using glass platters these days?



STEVE:  You know, I was wondering that myself.  And there must have been a change since I have last been opening drives because I've looked inside a lot of drives.  But mine are, like, early first-generation IDE drives.  I have a huge inventory of them that I used for developing and testing SpinRite.  So, like, during SpinRite 6 I ran it on every single one of these old drives I had in order to see how it was behaving.  But as far as I know, back then they were all metal platters, not glass/ceramic.



LEO:  Well, I told you that story about when Patrick slammed the thing with a hammer, it went - we thought it was metal, and it went, like, everywhere.



STEVE:  Right, right.  So anyway, so yeah, toss the drive on the sidewalk.  And if, I mean, literally, as he says, if it sounds like sand, you know your job is done.



LEO:  I love that.  I love that.  Steve, our job is done.



STEVE:  Ours is, too.



LEO:  All we have to do is tell people that they should go to GRC.com for many good reasons.  Wizmo is one.  Lots of really great free utilities that Steve writes just because he loves to do this stuff and give it away.  Of course there's one that's not free that you must have, SpinRite, the world's best disk maintenance and recovery utility.  That's at GRC, Gibson Research Corporation, GRC.com.  While you're there, of course, you'll find the Security Now! forums there.  You can ask questions, securitynow.com/feedback.  And you'll find - I'm sorry, GRC.com/feedback.  And you'll find the Security Now! shows, the 16KB as well as the full 64K versions; transcripts of each and every show so you can read along as you listen; and show notes, too, with links.  So it's a really great place to go.  GRC.com.



You can, of course, subscribe to the show in iTunes.  I encourage you to do so.  Just go to the iTunes store.  I know it says "store," but it's still free, don't worry.  We don't charge you.  I think a lot of people - not our audience.  They know better.  But I think a lot of people go to the iTunes store, they find a podcast, and they see a button that says "Subscribe," and they think it's going to be a charge of some kind.  It's kind of a flaw in the setup.  No, it's absolutely free.  Just search for TWiT.  You'll find all of our fine shows, including Steve.  Just look for the mustache on the cover.  No, actually Dick DeBartolo's has a mustache, too.  But yours is more...



STEVE:  Yeah, he's got a mustache that could take over the world.



LEO:  "Viva Zapata!"  All right, Steve.  It's great talking to you.  We will talk again, believe it or not, Christmas Day.



STEVE:  Christmas Day, yes.



LEO:  Amazing.  The man never sleeps.



STEVE:  I'll talk to you then, Leo.



LEO:  Have a great Christmas, and we'll talk to you on Christmas on Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#176

DATE:		December 25, 2008

TITLE:		"DropMyRights"

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-176.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo delve into the inner workings of a free, easy to use and useful yet unknown Microsoft utility known as "DropMyRights."  It can be used to easily run selected, dangerous Internet-facing applications - such as your web browser and email client - under reduced, safer non-administrative privileges while everything else in the system runs unhampered.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 176 for Christmas Day 2008:  DropMyRights.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!.  Yes, the show that never sleeps.  Yes, a Christmas Day Edition.  I'm Leo Laporte, and Steve Gibson is with us.  And just in case you're worried, we did not record this on Christmas Day.  Hi, Steve Gibson.



STEVE GIBSON:  Hi, Leo.  Great to be back with you.



LEO:  We are not working on Christmas.  We're taking some time off.  You're going to be with your family for Christmas?



STEVE:  Yes, I am.



LEO:  Good.  Oh, that's nice.  Me, too.  I'll be in France.



STEVE:  Yes, you'll really be with your family.



LEO:  Yeah.  We miss our daughter.



STEVE:  Reunited for the first time in a while.



LEO:  Oh, let me tell you.  We really miss her.  It's been hard to have her in France for a whole year when she's only 16.  We didn't expect this.  But she's having a great time.  And I'm sure we'll come back reporting wonderful things.  And with lots of pictures.  I'm bringing the new Canon 5D Mark II with me, so I'm going to have some beautiful shots of Paris at Christmastime.



STEVE:  Very cool.



LEO:  So what possible security topics could we talk about today?



STEVE:  Well, we're going to discuss some technology which was rather quietly added to Windows XP when XP was released.  And a Microsoft engineer who is very security aware made a blog posting about four years ago where he talked about a  little utility he had created called DropMyRights.  And it takes advantage of some of the new technology.  Remember that Microsoft was ballyhooing all the great security features in XP, and how it would be by far the most secure operating system they had ever made.  Of course that ended up not being true.  And I argued at the time that that's not something anyone can say ahead of time.  It's something that only history can demonstrate.  And in this case I was correct.  XP initially was a catastrophe.



But there is a very cool technology.  And this is sort of a - I guess I would call it a poor man's - a very poor man's - Sandboxie.  But it's a technology that allows individual applications to not run with admin rights, even though you are running with admin rights.  So I'm going to explain what the technology is in XP and talk about what DropMyRights does, how it works, how to use it, for - certainly for the people who don't have the opportunity to use Sandboxie or for people who are really belt-and-suspenders people.  I'm using DropMyRights and Sandboxie because - at the moment, I should say - because it's even better than one or the other by themselves.  But I've also had some dialogue with Ronen, asking him why exactly doesn't Sandboxie have this built in?  And so we're going to talk about that.



LEO:  Great, I can't wait.  That sounds really, really interesting.  All right, Steve.  Now, we are prerecording this several weeks before the show airs.  So any security news we give you is going to be, well, not news.



STEVE:  Although there were some interesting things that I found that I wanted to share with people, just sort of of a security news-y nature, without being, like, oh my god, you've got to immediately update your firmware to the latest edition.



LEO:  It's not breaking news.  Yeah, yeah.



STEVE:  There's been a trojan around for a long time called DNSChanger.  And this has been something which likes to get into people's machines and change their DNS settings because - and in fact I've run across some individuals whose DNS settings were changed away from their ISP's default, to some bizarre bad DNS server somewhere.  Now, we know from having talked about the Kaminsky problem that getting spoofed DNS is a really bad thing because your browser will show you the proper URL.  You'll look at www.paypal.com and see that it's typed in correctly with no spelling typos, and you'll think you're there.  But in fact you're not.  Your browser is hooked up to a different IP for PayPal.com because it got the address from a spoofed DNS, either because you're using your real server that is carrying spoofed information, and we know that today only - well, only.  About 75 percent of servers have been patched to render spoofing much more difficult.  But that leaves 25 percent on the Internet that are still able to be spoofed.



LEO:  That's just stunning that that number is still so high after all this time.



STEVE:  Yeah, it is amazing.  And I'm glad I've invested as I have in my DNS spoofability test that we'll be showing to our listeners here in a couple weeks.



LEO:  Yeah.



STEVE:  But the other way this could happen is if your system has been reconfigured to go off to a deliberately malicious DNS server.  You wouldn't know it.  And in fact that DNS server could serve valid DNS except for those specific domains that it wishes to commandeer.  So, for example, if you gave it MyHappyPuppy.com, it would send you back the IP, the proper IP of MyHappyPuppy.com.  But if you give it BankofAmerica.com, it sends you to its clone of the Bank America site and collects your credentials and performs all kinds of bad stuff.  So this is a problem.



Well, what's new about this DNSChanger trojan is fascinating.  The latest version is installing a valid NDIS driver.  NDIS is one of the lower networking layers that's always been part of Windows networking.  It's using - what I read said that it was installing a driver that had been used by ARPNET, so it's a valid driver.  What the installation of this driver does is essentially gives it raw socket capability.  Well, what it's doing with its raw socket capability is pretending to be a DHCP server.  So one machine on the LAN gets infected with this trojan, which installs this networking driver, which then listens for any other system on the LAN to come online.  The first thing the system does as it's booting is it sends out a broadcast, a DHCP query essentially, saying hey, I don't have any IP settings.  I need them.



Well, what happens is the trojan hears it, as does the real DHCP server.  Now there's a race.  Who can respond more quickly?  And unfortunately many DHCP servers are running on underpowered machines because they don't need much power.  If there's a machine that is fast, that's got this trojan in it, it will respond first, satisfying the outstanding query and essentially reconfiguring the IP settings of any DHCP client to route all DNS to a malicious DNS server.  And this affects any LAN environment.  So Wendy could set up her laptop at Starbucks that has this trojan on it and be sitting there happily computing, not knowing that this is present.  Anybody else who then boots their system at the Starbucks network, because they're essentially on a LAN even though it's WiFi, will get themselves redirected from the actual LAN's DNS server to the malicious one.  And this has been found in the wild, and it is going on now. 



LEO:  Now, we should emphasize, it's not automatic if you're on a Starbucks server.



STEVE:  No no no no no.  Nothing against Starbucks.  I'm drinking their coffee every morning.



LEO:  We don't want to start any rumors here.



STEVE:  No.



LEO:  But if you've got this bug on your system is the point.



STEVE:  Yes.  So the idea, though, I mean, I use that as an example to indicate, for example, that even roaming users, anybody, any system that is using DHCP, as is the default configuration for all Windows systems.  You know, in my own network I've got static IPs for everything, so I'm manually configuring them, and I keep a whole log of every IP that I've configured.  But default Windows configurations just use DHCP.  That's obtain IP address automatically setting, which is the default.  And it means that, if there were a rogue DHCP server anywhere on the LAN, it would receive the request, which is a broadcast out on Ethernet.  There are a set of MAC addresses reserved for, you know, that everybody will receive.  So not only does the DHCP server receive it, but anybody else on the LAN receives it.  Now, typically it's just ignored.  But if you've got this trojan on your system, thanks to raw sockets, it's able to intercept it and to build - essentially it's spoofing the reply from the real server and providing the DHCP information to the requesting client.  And in this case it's malicious.  So you don't want to let one of these things get anywhere in your network because it's not just then affecting the one machine, it's affecting all of the machines. 



LEO:  All right.  Hey, do you recommend, do you think - uh-oh.  I'm getting a little error message right over your face.  That's not very attractive.  Do you recommend a static IP over DHCP in general?  I mean, it would avoid this problem.



STEVE:  It would avoid this problem.  I guess the function of...



LEO:  Or would it?  Would it avoid the DNS issue?



STEVE:  Oh, yeah, yeah.  Because, yeah, you're not using a DHCP protocol at all.



LEO:  So nothing is setting your DNS; right, yeah, okay.



STEVE:  Right.  You're establishing it manually.  I mean, I know people that are into their network like to know what the IP is of their different machines.  I've got three TiVos, and I'm able to connect to them remotely.  I have got web browsers, or web servers running in my TiVos, and also some other third-party hackery that allows me to go in and delete stuff that accumulates, and play games.  So I know what those IPs are.  I know the IPs of pretty much all the many machines that I've got on my LAN.  So for me it's very useful to have them fixed.



And there are lots of instances where you do want a fixed IP for a machine.  The way you would normally do that, still using DHCP, is you are able, for example, in any of the contemporary consumer routers, to map a MAC address - that is, the physical address of the adapter - you're able to map a MAC address to a fixed IP so that a computer, a given computer, when it asks for DHCP - it asks using DHCP for its IP, its local IP on the LAN, the router will say, oh, this is a MAC address I know about, so I'm always supposed to give it the following IP.  So you are able to, like, use DHCP, which is a dynamic IP assignment, in a static fashion so that given machines always receive the same IPs.  So you can sort of achieve the same effect.  That's often used, for example, when you're doing port forwarding.  You want to forward incoming data to a specific machine behind your network.  Even though it technically has a dynamic IP, you've told the router always give this particular machine, recognizing it by its MAC address, the same IP.



LEO:  Reserve this IP for this machine.



STEVE:  Reserve the IP.



LEO:  Yeah, because we have this debate here.  I don't want to have to put - if I put static IPs in all of the machines on our network here, which there are maybe a dozen, and then another machine comes in, I don't want to have to keep track of all that.  So DHCP is so much easier.



STEVE:  Right.  It requires a lot of juggling.  You have to have, like, a reason for doing it, or just be an old fart like myself.  It's just nice to know...



LEO:  Or here's a reason.  We just gave you a reason.



STEVE:  Yeah.  In some interesting security news, I noted that Firefox, the final version of Firefox Version 2, is scheduled.  It's six days in the future from when we're recording this on December 10th.  It's scheduled for December 16th release.  That'll be the final Version 2 of Firefox.  And it loses its antiphishing features.



LEO:  What?



STEVE:  It's losing it because it's still using the very first version of the antiphishing API, which Google has told the Firefox folks they're no longer going to support.



LEO:  Well, that's a step backwards.



STEVE:  So, well, but Firefox Version 2 is a step backwards itself.



LEO:  You shouldn't be using it, yeah, yeah.



STEVE:  Version 3 has been out now since June.  I've switched.  Everyone I know has switched.  I would advise, if you have the ability to switch, you probably should.  If you are depending upon the antiphishing feature, which is certainly a nice feature of Firefox, you may want to deliberately not update to the very latest Version that misses that feature.  Although you will be informed, if you attempt to update to this final one, that if you do so, if for whatever reason you choose not to go to Firefox Version 3, you want to stay with 2, that you'll be sacrificing their antiphishing interception if you switch up to the very final version of Firefox 2.  And remember that then you're on an unsupported - from that point on you're on an unsupported version that will no longer be receiving any security updates or other updates.  And so if nothing else has talked you into moving from 2 to 3, then I would imagine that would because, you know, you want to be able to be using a continuously supported browser.  And 3 is working just fine for everybody.



LEO:  Oh, I love 3.  3, in my opinion, is an improvement.



STEVE:  Yeah.



LEO:  Over 2.



STEVE:  And I've got a little YubiKey news.



LEO:  Okay.



STEVE:  YubiKey is now being used to authenticate with TrueCrypt.  TrueCrypt of course we've talked about is the terrific utility for encrypting deeply and very strongly encrypting drives or whole drives or partitions and directories and so forth.  It's a very flexible tool.  There is a personalization tool that Yubico, the creators of the YubiKey that we've talked about several times, have now produced.  It was originally just an ActiveX control.  Now they've turned it into a little turnkey Windows app.  It allows you to do two things.  It allows you to basically take over responsibility for your own YubiKey and give it its own new AES key, which is what it uses for generating the one-time only tokens.  So that allows you essentially to take control away from Yubico's authentication servers, if for whatever reason you want to do that for yourself.  The other option, which is interesting, and this is what TrueCrypt is using, is it allows you to create a 32-character static password.  That is, change the way the YubiKey works entirely so that, when you press the button on the little USB YubiKey dongle, it spits out a long and absolutely random, but never-changing password, 32 characters long.



And what that's useful for is any instance where you need to do offline authentication.  For example, if you wanted to use whole drive encryption, like on a laptop, so that nobody can use your laptop unless it's you, well, you could use TrueCrypt in order to produce the whole drive encryption, which is doing preboot decryption and preboot authentication.  The problem is there's no way at that point to have Internet access, so you couldn't use the normal YubiKey.  So you could use instead this YubiKey which you have changed using their personalization tool to have it emit a 32-character monster random password.  People might say, wait, wait a minute, only 32 characters.  Is that enough?  Well, yes.  I mean, if it's ASCII...



LEO:  It's pretty good if it's really random.



STEVE:  Yes.  Exactly.  It'd be absolutely random.  Imagine that you probably get about 64 bits, that is, 64 different characters per - 64 different characters per character slot, so six bits.  So that's going to be times 32, which is what?  Is that 192, I think?  So that's 192 random bits.  I mean, that is seriously good protection, even though it's not changing.  Now, the vulnerability is it's a one-time - it's the same thing every time.  On the other hand, even if somebody saw it, and any time you're typing in a password, it's blanked.  But even if they saw it their eyes would just glaze over.  But passwords are always entered blanked out, so no one is seeing it anyway.  So it's just an interesting...



LEO:  How hard is it to change?  I mean, if you decide that you want to go to a different...



STEVE:  You can change it any time you want to.  The new personalization tool allows you to...



LEO:  I love this.



STEVE:  Yes.  I think it's very cool, Leo.



LEO:  Because you could use it for your WPA key...



STEVE:  Yes, exactly.  You use it for WPA.  The only sensitivity would be to beware of keystroke loggers.  A keystroke logger is not a problem with preboot authentication because nothing's running at that point.  You know, there's no OS or anything going at that point.  It's just TrueCrypt.  But you're right, Leo, I mean, you could use it to instantly load your gnarly WPA key into a system that you're visiting.  Or say, for example, some friends come over, I mean, how many times...



LEO:  I can have a YubiKey and say here's the key.



STEVE:  Yes.



LEO:  Just put this in.



STEVE:  Yes.



LEO:  I don't have to divulge it.  They won't see it.



STEVE:  Yes.



LEO:  That's what I'm going to use my YubiKey for.



STEVE:  It's a perfect solution because we've always - many users have said, hey, I've got a gnarly password, but how can I give it to my friends in a safe way?  So they bring their laptop over.  You simply put the cursor in the field where it's asking for their password.  You touch the little button on the YubiKey, it zaps it in.  Then it says confirm it.  You do it again, zaps it in, they're now on your network.  And they don't know what it is, and it was never disclosed.



LEO:  I like that.



STEVE:  It's really neat.



LEO:  They're going to sell a lot of YubiKeys with stuff like this.  This becomes really great.



STEVE:  Yeah, I mean, and again, remember that the YubiKey is not expensive.  So anyone can get it, use the personalization tools to turn it from a one-time password into this 32-character random password that you can use anywhere you want something that makes your eyes glaze over when you see it.  And no one is going to be able to glance at it and then type it in.



LEO:  That's just awesome.



STEVE:  And, finally, the open source Password Safe utility now supports the YubiKey in its full, normal, using Yubico for authentication, one-time password mode.  There's been some dialogue back and forth.  One of our listeners who is a YubiKey user wrote to the author, the maintainer of Password Safe, and said hey, is there any way you would support the YubiKey?  And they now do.  So the Password Safe, which is, I think - I'm not sure if it's multiplatform in the YubiKey support because he's got two versions in beta right now.  One adds the YubiKey; the other is Linux, that was doing some experimental stuff.  I don't know if the Linux one incorporates the YubiKey support also.  But YubiKey support is now part of Password Safe.  So that's very cool.



LEO:  That's even better because now, okay, I use that strong password on the YubiKey to unlock Password Safe.  And that could have the WPA key in it. It could also have my True- oh, no, because the TrueCrypt key you need on preboot.  So I need three.  I need three YubiKeys.



STEVE:  Yes.



LEO:  They're going to sell a lot of them.  That's great.



STEVE:  Yeah.



LEO:  That's really great.



STEVE:  It's a really nice forward motion.



LEO:  So you put the Password Safe on your U3, and then it'll say okay, what's the password?  Then you put the YubiKey in the other USB slot.  It authenticates.  Pull the YubiKey, put that back in your pocket, and you're done.



STEVE:  Yeah.  And the way Password Safe works, as you may know, is that when you minimize it, if you maximize it, it makes you enter it again.  And if you've got a gnarly password, that's a real pain.  So you can simply use the YubiKey in order to give it the password again.  Just zap it right back in again.



LEO:  Love it.  Love it.



STEVE:  So it's nice authentication.



LEO:  All right.  We're going to come back in just a second.  We're going to talk about DropMyRights, a good thing.  Usually you'd say I want more rights.  Not in this case.  Fewer rights are better for security.  We'll explain all and talk about this.  It's free; right?



STEVE:  And I do have a fun SpinRite story, too.



LEO:  Well, do the SpinRite story then.  And then we'll talk about DropMyRights in a bit.



STEVE:  Well, this is a neat guy, Earl Pearce, whose subject in the email he sent to me by way of GRC Sales account just says "SpinRite is amazing."  And he said, "Hi, Steve.  I purchased SpinRite in 2006 after hearing about it on the Security Now! podcast and used it a few times, just in case, on my system.  But no miracles were apparent.  However, a few days ago my laptop suffered from a severe case of BSD..." - I think he means BSOD, Blue Screen of Death.



LEO:  BSOD, yes.



STEVE:  "...so bad that I had to video the screen just to read the BSOD unmountable boot volume message."  So it must have just been flickering up very briefly for some bizarre reason, and he had to videotape it and then, like, single-frame his video in order to figure out what the message was.  He says, "I tried all the usual Safe Mode yada yada tricks with no luck.  Then I remembered SpinRite.  After a few warnings about drive heat, SpinRite rebooted, and the system worked great.  You are a wizard.  Carrier of the wand.  Gandalf reborn.  Creator of the best hard drive resurrection tool in the galaxy.  I have listened to the other emails you have received and thought, wow, it must be good.  But experiencing the miracle in person was amazing.  Thanks for all your hard work and long hours."  Signed, Earl Pearce.



LEO:  Wow.  It must be good.



STEVE:  That was a neat message, and I just wanted to share it.



LEO:  Oh, that is.  That's a great message.  So I didn't realize that DropMyRights was just kind of a side project by a Microsoft employee.  I had no idea.



STEVE:  Well, yeah.  I mean, what I like about it, being Mr. Write Everything in Assembly Language and Have Little Tiny Applications, what I really like about it is that it is also extremely small.  Now, okay.  There's a bunch of links that users are going to probably have to come to Security Now!'s page to find, our show notes for this Episode 176, because the original blog posting from four years ago unfortunately is obsolete.  I had to dig around for quite a while to track it down to find where it had gone.  Microsoft had moved it over the course of four years.  The links that I could find were broken.  So I found everything.  So there's a bunch of resources relating to this in this Episode 176's show notes.  So just go to GRC.com/securitynow and click the third icon, which is the show notes, and that'll take you to the page.  Or I'm sure that your team will have also added them to your site, Leo.



LEO:  Yes, of course.



STEVE:  So my point was that it's a very small little utility that basically leverages technology that has been built into Windows since XP.  Windows has - and we've never really talked about the security model, the way security functions in Windows.  But frankly, every time I go back in there, because I've had to understand it and dig around in there from time to time over the years, every time I refresh my understanding of everything going on in Windows from a security standpoint, I am surprised again that it even manages to boot.  There is just - there is so much stuff happening under the covers, behind the scenes in Windows at an amazingly granular level.



There are fundamentally two different things, objects, in the Windows security model.  There's this notion of an access token which is a collection of rights.  And then there's a security descriptor, which is sort of a collection of needs.  And so when you log in, when a user logs in, based on the type of account they have - we had talked about, of course, normal users versus admin users.  There's guest users.  There's limited users, various types of users.  Well, when the user logs in, the rights that they have are collected together.  Users can be members of groups.  And so groups can confer rights onto users that are their members.  So there's a complex set of sort of rights aggregation which occurs when a user logs in.



Now, once they're logged in, any applications, any processes which they run, sort of like from their own context, from the context of their user, they confer all of their rights onto that process.  Then anything that the process attempts to do, and I mean pretty much anything, it's checked against sort of like the rights requirements of the things that the process is sort of doing it to.  So, for example, files have the so-called "security descriptors."  Directories do.  Other processes do.  Individual threads of execution within the process, individual execution threads have the security descriptors.  As do registry keys and Windows services, and even printers have them, and network shares, and interprocess synchronization objects.  Basically sort of everything that is something in Windows has its individual set of requirements for who gets to mess with it - who gets to read it, who gets to write it, who gets to change it, who gets to even browse it, even see that it exists.  And so there's this high level of granularity.  And amazingly, when a process is rummaging around doing things at very high speed in Windows, somehow Windows has time to check all of this.  And, I mean, on an individual action-by-action level to make sure that the user that started the process that's trying to do whatever it is has the right to do so.



Now, there are a huge, like, dictionary of sort of privileges that can get conferred on a process.  For example, like there's a restore privilege and a backup privilege, a load driver privilege, a shutdown privilege, a debug privilege.  Even a privilege to change the system time so that if - so that you could create a user who could do everything except change the time on the system.  Just when they try to do that, they can't.  They're unable to do that.  A debug privilege is very powerful because debugging allows a process to view into the memory of another process, which is what a debugger that is running in Windows inherently has to do, is be able to peer into and even go in and muck around in another process's memory space.



Now, backing up and restoring might sound sort of benign.  But what the backup and the restore privileges confer on a process running with, like, backup and restore rights, is they violate any other access restrictions for that program.  Meaning that, for example, if you want to back up a whole system, well, the whole system might have a bunch of system files and a bunch of different user, multiple different users' files.  And when you back that hard drive up, you want to know you're backing it all up, you're getting it all.  Which means that any other sort of restrictions which would prevent one user from being able to see or view another user's files, well, the backup process needs to be able to see everything.  So the backup privilege is very powerful.



And of course there's sort of the granddaddy of all is the admin privilege, the overall administrative rights.  Malware wants to have admin rights because, for example, admins are able to create files in the system32 directory, which is obviously a highly privileged directory.  You don't want malware to create files in your system32 directory.  Malware is able to - I mean admins, somebody with admin rights can terminate a process, meaning that if something were running that an admin had created, it would be able to terminate whatever process in the system it wanted to.  Admins can also disable the Windows firewall.  Non-admins are not able to do that.  Well, you don't want malware to be able to turn off your Windows firewall if it wants to.  And even downloading and writing files to the system32 directory.  Or, for example, modifying or deleting keys in the registry.  There's a whole branch in the registry called HKEY_LOCAL_MACHINE.  Admins have access to that, but non-admins do not.  And again, you don't want malware to be able to go in and delete keys from the registry because those are, for example, where things you care about are used for configuring and starting them up when you boot Windows.



So there's this notion of rights that the user has, and then the things that require the processes that are running on behalf of the user to have in order for the operation to be successful and to not generate an error back through the operating system to the application.  So what Windows XP added was the ability to, on the fly, allow these rights to be modified.  There's something, a new feature in Windows XP which is called Software Restriction Policies.  Software Restriction Policies essentially allow policies to be applied based on, like, the hash of an executable, the executable's name, the location of an executable on the hard drive.  So you're able to sort of create broad-based policies which corporate IT professionals will use in order to sort of lock down the systems and circumscribe what their users can do.



Well, this security guy at Microsoft, Michael Howard was his name, who did this blog posting four years ago, he said, you know, I'm an admin.  That is, I want to run with admin rights because of the stuff I'm doing.  I'm a power user.  I don't want to have to be logging in and changing - logging out, logging in, changing who I am all the time.  And we know historically it can be annoying to be running as a non-admin user because of sometimes there are things you want to be able to do like, for example, installing software.



LEO:  I would guess most of our users are the type that just say, I want to be the admin.  I'm not willing to be a limited user.



STEVE:  Yes, exactly.  And so what he realized was - that is, Michael Howard realized that he could leverage this rich security model in Windows and the new feature of software restriction policies to create a simple little app that would allow some programs to be demoted from admin rights, even though he was an admin.  So normally, as I was explaining, if you're logged in as an administrator, anything you run, anything that runs from you is essentially - it inherits the rights that you have.  But he recognized that some things were extra dangerous.  And sort of this begins to overlap on Sandboxie's territory because he realized, for example, IE, you really don't want Internet Explorer to run as an admin because then anything that it runs has full administrative privileges.  And as I was saying, can write to the system32 directory, can terminate processes, can alter the settings to your firewall and so on.  So you'd really want to be able to run some applications with limited rights.



And thus was this concept he came up with of DropMyRights.  The idea is, it's a simple little utility where you simply - if you had a shortcut on your desktop, for example, or down in your Quick Start tray, or under your start menu, if you right-click on the shortcut and look at the command it's executing, you'll see some string.  It'll say C:\program files\whatever it is, the path to the executable that ends up with iexplore.exe or outlook.exe or firefox.exe or opera.exe or outlook.exe.  Anyway, you're able to prefix that string with dropmyrights.exe.  So DropMyRights is actually the thing you're running, and you're passing it the path to the executable as its argument.  So what happens is it runs, and it creates a process token that has non-admin rights.  That is, essentially, normally a process token created, for example, the one that it's running under, would have your rights.  It would have your full administrative rights.  DropMyRights creates a token that has non-admin rights.  And then it runs the thing that you would have normally run under those restricted rights.



LEO:  So it's interesting because this is kind of like the Run As command in reverse.



STEVE:  Yes.  That's a very good analogy.  It's like Run As.  Whereas instead of, like, being a limited user who wants to run as admin for something, you're saying I'm normally an admin.  And the beauty is you're able to set this up with your shortcuts so that any time you run Firefox or Outlook or Opera or IE or whatever, it's running with reduced rights.



LEO:  I want to talk about this a little bit more, and the implications of it.  And I really want to talk to you about the difference between running - what I do, and what most people in Linux and UNIX do, which is run as a limited user, it's kind of the conventional wisdom.  You never run as a superuser on Linux.  And we use this escalation, this Run As, or in the case of Linux SUDO, or sudo, to escalate, versus this de-escalation process, which is probably pretty typical Windows user thing.  From the day I started using UNIX, and then later Linux, it was drilled into you, you never ever log in as superuser.  You always log in as a  normal user.  If you should ever need administrative privileges, Linux makes it very easy with the sudo command to do that, to escalate.  Wouldn't it be better to do it that way on Windows?



STEVE:  Absolutely would be.  The problem is that the two different operating systems, Linux and Windows, sort of came at this from different directions.



LEO:  That's a good point because Windows 95/98/ME you were always administrator.  There was no conception of a separate limited user.



STEVE:  Right.  And essentially it's Microsoft has been trying to impose the security paradigm after the fact.  Whereas UNIX, this notion of being a root user and having godlike capabilities, I mean, there's always been, from day one there's been an appreciation of the need for security and the notion of user accounts and the idea of a superuser who is absolutely not the normal user that you run as.  You only go into superuser mode when you're wanting to be an administrator.  So there you elevate yourself.



Well, the point is because the system always evolved that way, all the applications running in a UNIX environment made the assumption that their users would not be root, would not be the superuser; that they would be a regular, normal, lesser privileged user.  Unfortunately the assumption was reversed under Windows.  So applications assumed the way Windows always was, which was the user was the user, there's only one type of user.  This notion of creating a lower privileged user was something Windows later in the game said, oh, that's kind of a good idea, let's do that.  The problem is that most of the developers and programmers, they were all running as admin.  So none of their software was being tested as non-admin.  So they were making an implicit assumption that everybody was going to be using Windows the way they were.  And it turns out then that trying to use their systems as a non-admin created all kinds of problems.



LEO:  Well, I guess it really goes back to DOS.  When, in fact, in the earliest days of DOS you didn't even have other - you not only didn't have other users, you didn't have other processes.  Before TSRs, there was one thing going on in that computer.  And DOS was so brain dead, and that really is the heritage for this whole thing.  I mean, it began there.  Whereas UNIX always was multi-user.  And anytime you have a multi-user system, you have to have concepts of permissions and different levels of power and so forth.



STEVE:  Well, and so what Windows has, Windows with this use of, this notion of software restriction policy, Windows defines five different levels.  There's the trusted user, the normal user, a so-called "constrained" user, an untrusted user, and then disallowed.  And so those are the five different levels that an application can run under.  Trusted is essentially admin, meaning that the application gets to run with any rights that you otherwise have.  Those are conferred on the application.  Then the normal user is the so-called "non-admin."  And people who use DropMyRights will see that there are two options.  In addition to normal, you can ask DropMyRights to drop them to even below those of a constrained user, I mean, below those of a normal user to a constrained user, or to an untrusted user.  Well, untrusted is virtually useless.  Those rights are so restricted, as I was experimenting with this, not even Notepad will run as an untrusted application.



LEO:  That's pathetic.  What can you do with Notepad?



STEVE:  Exactly.  So untrusted, I don't think anybody will ever be able to get anything to run as an untrusted user.  I was experimenting with constrained.  And even that is kind of sketchy.



LEO:  Is that because these programs feel like they have to write to, I mean, why couldn't they run?  I don't - what are they doing?



STEVE:  It's because they're not developed with this whole mentality of minimalism.



LEO:  They probably write to the registry, for instance, which would be something you wouldn't want an untrusted program to do.



STEVE:  Well, for example - that's a perfect example.  A constrained program, if you use the argument C with DropMyRights, then for example the whole key in the registry underneath HKEY_CURRENT_USER, which is a very rich key, full of registry entries, it's read-only.



LEO:  Oh, there you go.



STEVE:  So no constrained program, that is, program running as a constrained user, is able to modify anything underneath the HKEY current user.  And similarly, anything under the so-called User Profile Directory, that's Documents and Settings\Administrator, that's completely inaccessible to a constrained program.  And even crypto operations, including SSL negotiation, do not work.  So that just tells you you can't run a browser under constrained.  So I don't want people to be too concerned about those other two options.  Basically just using DropMyRights and dropping the application rights to normal, that takes away admin privileges, which takes away basically all the things you don't want a program to be able to do.  And so, for example, I've been using DropMyRights now for the last few weeks [inaudible] discovered it.  I've got Eudora running as a non-admin and Firefox running as a non-admin.  And they work just fine as a non-admin.  Yet the rest of the time I've got godlike rights on my system, which I need because I'm using...



LEO:  You're using Notepad.



STEVE:  I'm using Notepad.  Now, here...



LEO:  This cracks me up.



STEVE:  Here's what's really interesting, is when I - again, when I ran back across this, and I think it might have been, like, two weeks ago a Q&A question, because I've seen people talk about DropMyRights, I know that you and I have talked about it a couple times, Leo, but it's not something we've covered extensively.  I was looking at this, thinking, you  know, why doesn't Sandboxie just add this, because this seems like a good thing for it to do.  So I shot Ronen a note.  And I said, hey, what about this?



And he said, well, first of all, Sandboxie already strips many rights from the programs in the Sandbox.  It strips the restore privilege; the backup privilege, which we talked about as being very powerful; the load driver privilege, so that nothing running from anything derived from a sandbox can load a driver, and that's good because you don't want to be able to do that.  The debug privilege, which we talked about, is very powerful.  You absolutely don't want a program to be able to reach into other process spaces and muck around with it.  And I'm not sure why, probably just because it was there, he removes the system time privilege so that something running in a sandbox is unable to change the time of the system.  And I said, okay, cool.  What about admin?  And he says, well, I really don't want to do what something else has done.  And I said, well, I kind of appreciate that.  But I think you ought to put it in there.  And so it's in the beta right now...



LEO:  Oh, that's neat.



STEVE:  ...of Sandboxie.  I don't know whether the beta will be public.  I think it's 3.3.3.  I'm using 3.3.2.  Or maybe it's 3.32.  But it's in the next one.  He sent me a link to it privately so that I could play with it.  But there's now an option that will be in the next version of Sandboxie that incorporates the full strength of DropMyRights, which Ronen has completely figured out and understands, so that you can optionally run anything in a sandbox in a non-administrative context.  Now, it's worth, however, talking about DropMyRights for, for example, all of the 64-bit users who are unable to use Sandboxie.  So this is still something moving forward for people who, for whatever reason, aren't using Sandboxie, don't want to use Sandboxie.  Still makes a huge amount of sense to run.  If you're running as an admin normally, by all means look into DropMyRights to run specific dangerous applications, that is, anything that is Internet facing.  Your email and web browsing, maybe newsgroup reader, instant messaging program, whatever.  If you like to run as an admin, I'm not going to scold you about it.  I mean, I do.  Then this allows you to bring the rights down of other dangerous programs so that there's less damage that they can do if something tries to take advantage of them.  And it's completely free.



LEO:  And because Run As is so inconvenient, people are just not going to use - are not going to run as limited users.  I have to say, though, it is easier on Vista than it used to be.  I mean, it's certainly - it's not doable on XP, but it's not so bad on Vista to run as limited user.



STEVE:  Well, and Vista sort of incorporates this.  When we were talking, the times that we have in the past talked about this notion of privilege elevation, it's when we've talked about User Account Control, the UAC in Vista.  Because in Vista when you log in, remember that the user gets two sets of credentials.  You get a limited credentials, which is how you normally run.  And there is the option of being elevated temporarily to privileged credentials, and that's what the UAC essentially allows you to do is lift your credentials briefly to do something that you normally don't have permission to.



LEO:  Right.  So that's very similar to this.  Well, it's the flip-around, but it's...



STEVE:  It's sort of the evolution of it.  But for those of us who are not on Vista...



LEO:  Still using XP...



STEVE:  Have no plans to go to Vista, this is a tremendous, nice, little, I mean, it's clean and simple, nothing's like - there's no weight to this at all.  It simply launches these apps with reduced rights.



LEO:  Very cool.  Well, it sounds like a must-get.  Absolutely free.  Does it run on Vista at all?  Probably not.



STEVE:  Don't even know.  I don't care.



LEO:  You don't need it.  You don't really need it.



STEVE:  I don't care, Leo.



LEO:  You don't care.  You're happy, and you're going to use it as Sandboxie, anyway, when [indiscernible] comes out [indiscernible].



STEVE:  Exactly.  It's going to be built into Sandboxie here within a few weeks probably.  So maybe by the time this episode is being aired.  I want to just close by saying something that I alluded to before.  I think there's a way to do this with policies and not even needing the DropMyRights.exe.  During the research I was doing, I said wait a minute.



LEO:  That would make sense.



STEVE:  Normally there's only two categories, trusted and disallowed.  But I think there's a way to create the additional categories.  And, if so, then the policy system, which automatically - which, like, corporate IT uses for constraining what their users can run.  I think normal users could use this and just automatically have a class of applications get non-admin rights, even if they're running as admin.  I'm going to - I don't think I can hold myself back from poking around at this a little bit more and seeing if maybe I can come up with...



LEO:  That would make sense.  I mean, I think you should be able to.  And, you know, you may not have to poke around too much because I bet you we've got some IT types who are running their office exactly that way.  I mean, that's what I would do is use GPEDIT and just say, you know, this is how it is.



STEVE:  Well, but I've looked.  And there's only trusted...



LEO:  There's no settings.



STEVE:  ...[indiscernible] allowed.



LEO:  Isn't that interesting.



STEVE:  It's either yes or no.  It's a binary option.



LEO:  That seems like something that you really should have, to me.



STEVE:  I would think so.



LEO:  It's very odd.



STEVE:  Well, although you can imagine, in an IT corporate mode, they're not letting their users run as admin.  All their users are being run as normal users.



LEO:  Well, right.  Can you do it the other way around?  Can you say escalate this program?  If they have to run Notepad as an administrator, can you have it escalate?  I think you can - you know what you do, actually I've done this, is you create a Run As icon.



STEVE:  Oh, sure.  Exactly.  And then you provide credentials on the fly.



LEO:  You have to give them credentials; right.



STEVE:  Because Run As is going to prompt you for your username and password.



LEO:  Exactly.



STEVE:  Yeah.



LEO:  Oh, what a tangled web we weave when first we operate in DOS.



STEVE:  So again, if our users will go either to the TWiT.tv show notes or my page, the Security Now! page, Episode 176, I will have a page there with links to track this stuff down.  And it's just a very nice, cool thing to do.  Drop the rights of high-risk programs so that they're not admin, even if you are.



LEO:  I agree.  Very cool.  Very - a slick idea.  And I bet you the inspiration for UAC, at least to some degree.



STEVE:  Yeah.  It was certainly the precursor to it.



LEO:  Yeah.  You can get more information, as always, on Steve's website, GRC.com.  That stands for the Gibson Research Corporation.  GRC.com.  You'll find, of course, this show, and 16KB versions if you're bandwidth impaired, or the full 64K version.  You get the transcripts so you can read along.  Many people like to read along while Steve talks.  You can also get the show notes, as he mentioned.  We have stuff there for you, including a link to DropMyRights.  And let's not forget, GRC.com is the home of SpinRite, the world's best file and - or I'm sorry, disk recovery and maintenance utility.



STEVE:  Yay.



LEO:  Yay.  Just go to GRC.com, click that big SpinRite link.  While you're there you'll see a lot of free programs, too, like ShieldsUP!, Wizmo, Shoot The Messenger, DCOMbobulator, all that stuff.  Steve does a great job of giving back to the community.  GRC.com.  Merry Christmas, Steve.  I hope you're having a wonderful holiday.  And I thank you for your - just it's been such a great three years working with you.  We're in our fourth year now.



STEVE:  Yup.



LEO:  And always been a pleasure.  And I just - your determination never to miss an episode, even on Christmas Day, blows me away.



STEVE:  And I guess New Year's Day, too, next week; right?



LEO:  Next week, New Year's Day.  New Year's Day.  Yeah, we'll do it later in the day, give you a little time to recover from New Year's Eve.  But we'll have it out, of course, for you in time to enjoy a little revelry on New Year's Day.  Steve, have a great holiday.  And we'll see you in 2009 for another great year of Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#177

DATE:		January 1, 2009

TITLE:		Breaking SSL, PDP-8's and UltraCapacitors

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-177.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the newly discovered cracks in SSL (Secure Sockets Layer), antique PDP-8 minicomputers, and the importance of next-generation UltraCapacitors.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 177 for January 1, 2009:  SSL, PDPs, and UltraCaps.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



Happy New Year!  It's 2009.  Fitting the first podcast of the new year would be the podcast that never sleeps, that never rests, Steve Gibson's Security Now!  Hi, Steve.



STEVE GIBSON:  That never misses a beat.  Hey, Leo.  It's great to be with you.



LEO:  You are now officially ahead of TWiT.  You're doing very well.  177 episodes.  Did you have a good holiday?



STEVE:  Every time I hear those Dick DeBartolo episode numbers, I just grit my teeth.



LEO:  I know.  In the 700s.



STEVE:  Yeah.



LEO:  That's what happens when you do it every day.  You wouldn't want to do this show every day, would you?



STEVE:  No, we can't do this every day.



LEO:  It could be arranged.  I think we'd have an audience.  Well, how are you?  Did you have a good Christmas?



STEVE:  Had a great Christmas.  Had a little bit of a fall in the middle of the night on Christmas Eve, sort of somehow blackened my left eye, even though it doesn't hurt.  Everything's fine.  And I came down with the Christmas cold from hell.  It's been really nasty.  So I apologize in advance if I unconsciously sniffle or make annoying audio sounds.  I will work not to do that for the next hour or so.



LEO:  Well, and I'll charge Tony Wang, our brilliant editor, with cutting out...



STEVE:  Well, if I do a big sneeze we could cut that out.



LEO:  All the snarfles will be gone.



STEVE:  We'll work to do that.  But we have a very special episode this week.  It was exactly 13 weeks ago, Episode 164, where we bumped our regularly scheduled Q&A to talk about Sockstress, which was, you know, is the Internet going to come down?  Is TCP broken?  All that stuff.  And we said, well, no.  But it's interesting, so here's what it is.  So that changed the parity of the episodes, the even-and-oddness of the episodes where we do the Q&As.  We're going to do that again because there's been a huge amount of news caused by a disclosure only a couple days ago of essentially an exploit in a known weakness that involves the authentication of SSL, our favorite security protocol for the Internet.  Secure Socket Layer is what SSL, of course, stands for.



But even before that happened I had written to you with my intention to talk about two things that were not security related, that I just - I'm passionate about them both.  I wanted to share this with our listeners.  Also there's some listener involvement because there's a possibility of building a certain type of kit that I will talk about that would be available for, like, the last time ever on Earth this could happen, as a consequence of a particular chip that became available.  So a bunch of stuff.



LEO:  You've really got me intrigued.  This is very intriguing.  All right.



STEVE:  It's going to be a fantastic episode.  We also, since we haven't been live for three weeks because we had to pre-record, we've got a whole bunch of security stuff.  So I've just got tons of stuff to talk about and some really interesting things.  And finally, the last thing that happened was a patent was granted on December 16, Tuesday a couple weeks ago, that discloses, as patents must, the fabrication details of a breakthrough energy storage technology...



LEO:  Oh, boy.



STEVE:  ...which potentially obsoletes batteries.



LEO:  That would be huge.  It's the one breakthrough I've been kind of saying, if you could pick one, you know, this is the one because all of our portable devices are right now hobbled by the inefficiency of batteries.



STEVE:  Well, yes.  The lifetime, the cycle length, the charging time.  This technology, a so-called ultracapacitor, just makes - it makes so much sense because...



LEO:  Useful for autos, as well, do you think?



STEVE:  Well, that's the primary target was for the whole hybrid auto market.  However, it's completely scaleable.  So, and it changes everything.  I mean, imagine a laptop that, first of all, with the same size of battery, could give you three times the life for the same size and weight. But because this is a capacitor, when it begins to run down, you plug it in, count to five, and unplug it.  It literally charges in five seconds.



LEO:  I love that.



STEVE:  It changes everything.



LEO:  It does.  Oh, this is exciting.



STEVE:  So we've got lots to talk about.



LEO:  So Steve, should we, I mean, we can't - where do we start here?  We haven't talked in so long.



STEVE:  I know.  Well, we'll exercise some discipline, although I'm so excited to talk about this...



LEO:  You want to talk about your batteries.



STEVE:  Yeah, nonsecurity stuff.  But we've got to cover a bunch of security stuff.



LEO:  Well, I tell you, I saw this, I saw an image, I can't remember which magazine it was, with a Microsoft certificate saying the name of my bank, issued by, like, Hacker.com.  And I thought, what the heck is going on here?



STEVE:  Yes.  Throughout today's episode I'll be referring to the show notes for this week.  They're always accessible where they always are, which is GRC.com/securitynow.  And then for Episode 177, one of the little icons there will take you to the show notes.  But because I expect so many people are going to want to get to that page, I created a little SnipURL shortcut for it.  So it's snipurl.com/sn177.



LEO:  Oh, that makes it easy.  We probably should do that for every episode.



STEVE:  That'll take everybody there immediately, rather than having to navigate through a couple pages.  So it's snipurl.com/sn177.



LEO:  All right.  That's where all the details will be.  Don't go there now.  I don't want to spoil it.



STEVE:  Lots of links.  Well, for example, one of the things that's there is a demo of - actually it's not there at this instant.  It's on my copy.  I haven't put it up on the server yet.  So our live listeners will need to wait for a couple hours, and I'll get caught up as soon as we're done recording.  But I will have a link to a demonstration of this fraudulent certificate where, if you set your clock back, the security researchers who created the fraudulent certificate made it expire after August of '04.  So if you set your machine's clock to a certain date, during which their fraudulent certificate is valid, then you can click this link, and you will get an SSL connection from your  browser to your server using an invalid certificate based on a valid root authority.  So, I mean, we'll talk about what this means in detail after we cover a bunch of, well, after we get all the other security stuff out of the way we'll do that and then the other topics I want to talk about.



LEO:  Big, big story, yeah.



STEVE:  So again, that URL is at snipurl.com/sn177.  Okay.  So in terms of patching there's been a lot that's happened in the last three weeks.  When I turned on my Mac, my Intel-based Mac, it said, oh, we have 190MB.



LEO:  10.5.9, was it, I think?



STEVE:  No, we're at 6 now.  10.5.6.  So there were many critical vulnerabilities that were patched.  I imagine everybody who knows, I mean, who has been following along, you may want to just make sure that your Mac is up to date by telling it to run the little software update under that main menu item and give it a chance.  Opera has been updated to 9.6.3 with a bunch of problems fixed.  Firefox, I said last time and I'll say it again, it's time for the people who are still using v2, if v3 is available on your platform, it's time to switch to v3.  V2 is going to no longer be maintained.  The last version of v2 is 2.0.0.20.  And that fixed a bunch of critical vulnerabilities which were also fixed in the latest version of Firefox v3, which is 3.0.5.  So if you can't switch to 3 for some reason, you do want to make sure that you're using 2.0.0.20 under Firefox 2.  But no more fixes are coming down for that.  So you probably do want to - it's time to move over to - it's been a year.  And I'm there, and we know how reluctant I am to move.  I'm just completely happy with Firefox v3.



LEO:  Yes, yes, yes.



STEVE:  Also, Google's Chrome officially left beta.  It is no longer in beta.  So the Chrome browser is done.  And remember we were speculating whether it would ever get out of beta because...



LEO:  Most of the time Google doesn't, yeah, yeah.



STEVE:  Okay.  But it's really nice that they got it done and made a bunch of changes.



LEO:  Is it done, or is it just, I mean, it's arbitrary.



STEVE:  Yeah, I think they just - they decided to take it out of beta, make a v1, something or other.



LEO:  Good.



STEVE:  Okay.  Now, also since we last talked, actually it was like the afternoon of our last recording, Microsoft once again surprised us with an out-of-cycle patch.  There was a zero-day exploit which they discovered that affected all versions of IE, which caused Microsoft to react very quickly.  There were seven different exploits that have been identified.  And at the time as many as 6,000 websites were infected with this.  So this was code on those websites which was installing software in users' machines using a flaw that was not known until it was found in the wild, thus zero-day exploit.  So certainly our listeners who are, I'm sure, keeping up with patches know about this.  But it was substantial.  And what it allowed was for malicious code to run in the context of the logged-on user.



Well, I mention that because both Sandboxie's new rights-dropping feature and the DropMyRights tool, the little utility we talked about last time, both would have prevented this.  So it's a perfect example of running your browser with lower rights, which you have the option of doing with  Sandboxie.  I mean, Sandboxie would have likely prevented any problem anyway.  But this would have, by using the new right-dropping feature in Sandboxie.  Frankly, I'm not sure if it's yet available publicly.  I've been testing the beta with Ronen, and he's got it working great.  So I have it.  And I imagine, if it's not out, it'll be out soon.  But then the DropMyRights utility that we talked about does the same thing.  Basically it removes admin and a whole bunch of other privileges from the instance of running applications.  And it would have shut this thing down even if you were hit by the exploit before the patch was out.  I mean, and that's the kind of protection you want, real preemptive protection instead of saying, well, okay, how do I disinfect my machine after this disaster has hit?



LEO:  Yeah, yeah, yeah.  Another reason to use this.



STEVE:  Yup.  It just makes sense.  Samsung has had a - we have another digital picture frame malware problem.  In this case it was the Samsung Model SPF-85H, which is an eight-inch digital photo frame.  The frame itself is not infected.  There were some before where the firmware that shipped with these was infected, such that when you connected it to your computer it could infect your machine.  In this case it's the companion software disk that comes along with it which is necessary to use the frame as a USB monitor on Windows XP machines.  It contains the, well, a worm.  It's the W32.Sality.AE worm.  And the bad news is it installs keystroke-logging malware on the machines where it has been installed.



LEO:  You've got to wonder how that leaks into the production facility.



STEVE:  Oh, yeah.



LEO:  I mean, it's on some testing machine or something, and it must be crafted to spread itself on that particular platform, I would think.



STEVE:  Yeah.  And also to jump onto anything else you're doing.  So it says, oh, look, here comes the master imprint of the CD for the digital photo frame.  Let's just jump over on that.



LEO:  You almost think it has to be an inside job, that somebody in the factory knew that they were going to do this production run and snuck it in there.  It can't be an accident.



STEVE:  I mean, I agree that it's - it's hard to know what the environment is where these things are created.  It may just be amateur league, wherever the software is coming from.  They may be subcontracting it to some random third party.  It's really not something that Samsung does.  They just get the software from someone else who says, oh, you know - and they say this is what we want to do.  So they take it, and they check it out, not realizing there's a trojan there.  And that's a problem.



LEO:  Yeah,



STEVE:  Microsoft reported that the most recent version of their MSRT, the Malicious Software Removal Tool, that is the December edition for last month, cleaned more than 400,000 PCs from something you have mentioned before, Leo, the Antivirus 2009.



LEO:  It's amazing.



STEVE:  Phony security application.



LEO:  Now, that's on top of some hundreds of thousands that they had removed the month before.  I think we even talked about it.



STEVE:  Yes, exactly.  So it's still spreading.  And, I mean, this demonstrates that this MSRT - I've never see it do anything, unfortunately.



LEO:  Well, it's almost - I have to think that Microsoft knew that this day would come.  And it was like, well, let's get this thing going.  Let's have it on the system.  Let's keep it up to date.  And now we need it.



STEVE:  Well, and it's so nice, too.  Because, I mean, this leverages - it's proactive removal, and it leverages the Windows Update facility which, when Microsoft first introduced it, the old-timers among us were like, I don't think I want this being done all the time.  Now it's like, okay, let's make sure we've got all the latest updates.  Make sure we got all the latest updates.



LEO:  This is done automatically.  It's installed as part of Windows Update.  You have it if you run Windows Update and you install critical updates.  And every time they do a Windows Update it seems that they push new fixes for it.



STEVE:  Yeah.  And so the idea is that, when you reboot your machine, this thing runs once as Windows is starting to scrub your machine of any of this.  And it's not doing a big, long search that takes a long time because it's targeted.  There are specific malicious things that they go directly to them and work out the details of removing them as Windows is starting.  So it's free machine cleaning.



LEO:  Right, right.



STEVE:  So that's a good thing.  A little bit of bright news about how the RIAA is dealing with music piracy.  They formally announced that they're changing their approach.



LEO:  They're giving up?



STEVE:  Well, no.  But they're not going to go randomly suing end-users all over the place.



LEO:  Really.  Wow, that's a big change.



STEVE:  It is a big change.  A huge policy shift.  I mean, they've been suing people now for the last many years.  And often innocent people, some grandmother who got some trojan installed on her machine and didn't know that her machine was serving music through some peer networking system.  So what they're going to now do, they've said, is work with ISPs, identify pirates, let either the ISP notify users or the ISP will provide the information, allowing the RIAA to notify users.  But that will be the limit of it.  They're not saying they absolutely...



LEO:  Well, but where's the stick, then?  I mean, how do they enforce it?



STEVE:  Well, they're not saying they absolutely won't sue someone. But it will only be real gross offenders, people who, like, mass, mass offenders.  But your typical end-user will get some warning notices.  And they have said then that the ISP may throttle their bandwidth or take some - the ISP could say look, if you don't stop this, we're going to cut back your bandwidth, so knock it off.



LEO:  So I guess the threat is that they will sue the ISP, that the ISP is in a way held liable for what its users are doing.



STEVE:  Well, I'll be surprised if that sticks.  The ISPs want to be called a common carrier...



LEO:  Right, that's not their job.



STEVE:  ...not responsible for - exactly.



LEO:  Right.  But it sounds like the only way the RIAA could make this work is if they hold, I mean, if they're not going to hold the users responsible, then it's the ISP.  The ISP could just ignore them.



STEVE:  That's true.



LEO:  The ISP could say, hey, I'm a common carrier.  I'm the phone company.



STEVE:  And speaking of ISPs, remember that - you may remember that we covered a story about how the government of Australia was planning to do a continent-wide filtering of the Internet.  Well, to say that it's met with some resistance would be an understatement.  The ISPs, no ISPs want to participate.  What the government has said they were going to do was to block as many as 10,000 sites that are known to be hosting illegal content.  Well, Telstra, which is the largest ISP...



LEO:  And partly owned by the government of Australia, I might add.



STEVE:  Uh-huh.  And Internode, which is another biggie, both flatly said no, we will not do it.



LEO:  Oh, wow.



STEVE:  There's another smaller one called Optus that said it would participate in some sort of scaled-back deployment, whatever that means.  And then another one, iiNet, said, well, they'll participate only to demonstrate that the filtering plan will not work.



LEO:  How stupid it is.



STEVE:  So just 100 percent backlash.  I mean...



LEO:  Good, good.



STEVE:  And there have been public protests in Melbourne, Brisbane, and Sydney that have been formal, organized protests saying we don't want our Internet filtered by our government.



LEO:  Yeah.  It was kind of a kooky idea.  But it's not the first.  I mean, remember, they spent millions designing filtering software that was cracked in a few days - in a few minutes.



STEVE:  Yeah.



LEO:  This is crazy.



STEVE:  It just makes no sense.



LEO:  Clearly somebody in the government has no clue.



STEVE:  Well, gee, you think?  And Cisco released their annual security report for calendar '08 that had some interesting statistics that I thought our users would find interesting.  The total number of disclosed security flaws increased in '08 by 11.5 percent.



LEO:  Now, see, on the surface that sounds bad.  But I think that's good.



STEVE:  Well, it's, I mean, it's got both good and bad to it.  I mean, we're glad that these things are being found.



LEO:  Exactly.



STEVE:  We're sorry that there are so many of them to be found.



LEO:  Right.  I guess my supposition is they were there anyway.  They've always been there.  The fact that they're finding them and disclosing them is an improvement.



STEVE:  Yeah.  Although we're also not - I don't feel like the software we're using now is more secure than what we had.



LEO:  You don't?



STEVE:  I mean, there's certainly more awareness of it.



LEO:  I think Vista is more secure.  I don't think we're hearing nearly the number of exploits on the Vista side that we used to...



STEVE:  Okay, but that's not a consequence of software flaws as much as it is design, where Microsoft finally really got serious about security.



LEO:  True, true.



STEVE:  And implemented architectural features that are protecting us.  But for example, all of those, that zero-day IE flaw, that affected IE, Outlook, Outlook Express, and even there were Word documents that were causing this problem.  I mean, that was across all platforms except Server 2008 was the only platform that was not affected by that.  So Vista was no more secure, a Vista user no more secure in this case than would a XP user be.  So what was interesting was that attacks that were spread by malicious email attachments fell by 50 percent.  And Cisco reported that they're seeing more and more blended attack.  A blended attack, remember, meaning that there's - more than a single flaw is being used.  It's sometimes multiple flaws.  And in fact we'll be talking about that relative to SSL because for phishing you need both an illegitimate certificate and some way to get somebody to the wrong website.  So multiple vulnerabilities being used in combination in the so-called "blend" in order to actually make the exploit happen.  And finally, 90 percent of world-wide email is now spam.  Nine zero.



LEO:  You know, 99.9 percent of my email is spam, according to my spam service.



STEVE:  But Leo, you're Leo at Leoville.com.



LEO:  That's great.  Thanks for incurring 99.99 percent.  No, no.  And I've been using that address for 10 years.



STEVE:  Put a big beacon up.



LEO:  Yeah.  I mean, it's on every list there is.  Interesting, though.  So what they're saying is, of all the email traffic going on, nine out of 10 messages in that email traffic is garbage.



STEVE:  Yes.



LEO:  90 percent.



STEVE:  Unsolicited.



LEO:  Appalling.



STEVE:  Unsolicited mail.



LEO:  Now, remember it went down, it went down a huge bunch when they disconnected that company in San Jose.



STEVE:  Yes.



LEO:  But I guess it's back.



STEVE:  Yes.



LEO:  It's like roaches.  You can't get rid of them.



STEVE:  Okay.  So a couple days ago, and it was just a couple days ago, two security researchers, German security researchers Alex Sotirov and Jacob Appelbaum, introduced a surprise at a security summit.  They demonstrated that they had created a fraudulent CA, a Certificate Authority, that was carrying a valid signature from a root authority.



So let's review a little bit what that means.  The idea is, we've talked about the so-called "chain of trust."  That is, for example, GRC's SSL certificate that I got from VeriSign, I think in this case it is signed by VeriSign.  And VeriSign has their certificate signed by their root.  They happen to have a - VeriSign has a root certificate authority installed in Windows.  It's installed in Mac.  It's installed in Linux.  It's a very common certificate.  So the idea is that, when someone visits GRC and wants to establish an SSL, secure, https connection to GRC, in the initial handshaking of that, after the TCP connection is established, the very next thing that happens is certificates are exchanged as part of the SSL protocol.  So my server, the GRC server, sends the user its security certificate in order essentially to authenticate that they've really connected to GRC.com.  So in the certificate is www.grc.com, the domain name.  And so the browser makes sure that matches the URL that it was trying to get to.  And then there's this chain of signatures.  Basically my certificate provides the VeriSign certificate, which has been signed by the root authority.



So the browser has this group of so-called root authority, root certificates, which are sort of like the master keys for SSL.  And remember that we've talked about, in fact, jokingly but a little bit disparagingly in the past about how many root authorities there are.  My system, which I keep updated with the root certificates, has 277 root authorities.  And remember that I've talked about, like, for example, the Hong Kong Post Office.  That's an example of one.  The good news is they're secure.  I will be running through a little list from my own little browsing, and also give our listeners a way that they can check their own root security certificates to see whether they are safe or not against this attack.  Because many are; many are not.



So what these guys did was they set up a network of, well, first of all, to - the digital signature operates with a hash.  And we've talked in years past, when we were doing our whole crypto series on Security Now!, we talked about how digital signatures work.  A digital signature is a hash, a hash function, a cryptographic hash function where you take, for example, GRC's certificate, and it is hashed using MD5 or SHA-1, one of these secure hashes.  And then the hash is cryptographically signed using the private key of an authority.  So that creates another little blob of binary-ness.  Then what happens is, to authenticate the signature of, for example, GRC's certificate, when the browser receives it, it takes the certificate, applies the hash to get essentially a fingerprint for that certificate, and it's then able - it doesn't have the private key, but it has the public key for the certificate authority.  So it's able to use the public key in order to verify that the hash it gets is the same as the hash that was signed by the authority.  It compares those, and that way it knows through the sequence of cryptographic operations that the certificate it got from me is the same certificate that was presented to the certificate authority and signed by them when they issued that certificate to GRC.com.  And up until now there has been no way to break that process.



Well, there's been evolution in digital certificates and in hash functions over time.  And an older hash function known as MD5 - MD stands for Message Digest, which is another term for a hash or a fingerprint.  MD5 has begun to have some problems.  Cryptographic experts over the last few years have begun to poke little holes in it, finding little things that, sort of at the esoteric far end of crypto land, were beginning to worry certificate researchers.  And as a consequence, many responsible cryptographic providers began to say, okay, look, don't use MD5 anymore for things that are really mission critical.  It's beginning to have problems.  So far it hasn't been cracked.  There have been sort of like collisions where, for example, you're able to deliberately create two different texts which, when hashed using MD5, end up with the same signature.  And it's supposed to be very difficult, I mean, like really, really, really cryptographically difficult to do that.  But it turns out some weaknesses cause it to be less difficult than the designers of MD5 intended.



So what happened is an additional weakness was found in MD5 using what's known as a chosen prefix attack.  It's extremely computationally intensive, even with this defect.  Even to exploit this defect it's computationally intensive.  Now, we've talked about the notion of using gaming platforms, high-performance GPUs, the graphics processing units, in state-of-the-art graphics accelerators in order to increase the number of cryptographic operations that can be performed.  What these guys did, these researchers, they took a cluster of 200 PlayStation 3 systems, so 200 PS3s, which cranked on this for two weeks.  And they were able to create a fraudulent certificate authority.  So what that meant was they were able to create their own certificate authority where it looked like it had been signed by one of the main root authorities.  And in specifically Equifax, which is one of the oldest, been there for a long time root authorities.  So they have a certificate which appears to have been issued by Equifax, but wasn't.  And what that allows them to do, then, is now create any fraudulent SSL certificates that they want, apparently for any website.  It's very much like - it's like they're now a VeriSign.  They can easily create certificates - www.amazon.com, www.paypal.com, anything they want.  And when their certificate is presented to any browser in the world, it will be accepted.  So that's not good.



LEO:  Is that true for the - is it the extended certificates, too, the green ones?  Or is this just a standard SSL certificate?



STEVE:  Well, okay, now, that's really interesting.  Because what I did was to browse through my certificate store.  Remember I said I've got 277 of these.  And...



LEO:  That's quite a cost, isn't it.  That's thousands of dollars you've invested in this.



STEVE:  Oh, well, no.  I mean, everyone has...



LEO:  Oh, this is the thing that's built into your browser, not GRC certificates.



STEVE:  Oh, no no no.  No, these are the trusted root certificates that are preinstalled in any contemporary active system.  So the Mac has them, Windows has them, Linux has them.  This is the way you do SSL.



LEO:  Right.  You have to.  Right.



STEVE:  So, for example, and in order to browse these certificates, it's not easy.  But one of the many things I have on this page, on the Security Now! Episode 177 show notes page, so again that's snipurl.com/sn177, I have instructions for how you can browse your own store of certificates.  You've got to use the Microsoft Management plug-in console thing.  It's a really messy UI that Microsoft came up with.  But it's possible to do it.



LEO:  At least you can do it.  At least you can do it.



STEVE:  Huh?  Yes.



LEO:  At least you can browse it, yeah.



STEVE:  And so what I did was I just said, oh, okay, what's going on here?  What you look for is what was the message digest, what was the fingerprint technology used for those certificates.  And so, for example, the Microsoft root authority was signed with MD5.  Oops.  Microsoft's Authenticode root authority, MD5.  Oops.  Thawte's certificates are signed with MD5.



LEO:  Now, they're owned by VeriSign.



STEVE:  Uh-huh.  Although VeriSign's are all signed only with SHA-1.  Equifax has both SHA-1 and MD5.  And that was the one that these guys chose.  So any of these roots which are signed by MD5, that have an MD5 variant, could be targets for this exploitation.  There's something called Entrust.net, was MD5 and SHA-1.  So but MD5 is there.  That's in trouble.  And, for example, the Australian Society for Data Protection has a - for some reason there's a root certificate in my machine, and it was signed by MD5.  So that would be potential for exploit.  On the flipside, the roots which are only SHA-1 are, for example, AOL is only SHA-1, so it is absolutely safe because as far as we know there are no known attacks against SHA-1 that there are against MD5.  Comodo is also SHA-1, as are GoDaddy, GeoTrust, Wells Fargo, Visa, VeriSign, Network Solutions, and the Hong Kong Post Office.



LEO:  Yay.



STEVE:  So they get kudos.



LEO:  Yay.



STEVE:  The Hong Kong Post Office gets kudos for only having an SHA-1 cert.  Now...



LEO:  Our favorite whipping boy.



STEVE:  ...essentially, the guys that are still using MD5 really belong in the doghouse because MD5 has been chipping - it's been chipped away at for about the last four or five years now.  And so...



LEO:  So it's known that this is a flawed hash.



STEVE:  Well, it should have been making people uncomfortable.  And it's one of those things where, you know, people who were on top of their game said, you know, there's no reason for our certificate to be signed with MD5.  We're only going to sign it with SHA-1.  Because even though there's nothing that we know is wrong with MD5, it doesn't seem as strong to us as we thought it was when we first signed our certs with it five years ago.



Now, one of the things that I'm noticing Microsoft is doing a lot is updating this root cert database.  It is not part of the standard updates in Windows.  So you need to use the custom, I think, what is it, expert mode or something they call it where you are able to look at all the things that you can update.  And then it's under optional updates.  And you'll see root certificate updates.  And pretty much every month or two I'm seeing that Microsoft is fussing with that.  So I think - I expect what will happen is that, because this is making a huge, well, I mean, yes, huge waves, as it ought to.  I mean, this is not the end of the world.  These guys are really good cryptographers.  They built a network of 200 PS3s that it cranked for two weeks in order to create this.  But as we know, the fact that some group can do it and have now publicized this means that everyone now knows it's possible.  So they seem like really good guys.  They're security researchers hoping to fix this problem by demonstrating it.  And unfortunately it's only by demonstrating a problem like this that many times people get off the dime and take the effort to fix it.



So what I expect to happen is that Microsoft, for example, will immediately remove MD5 from their own root certificates.  And so the next update to the Windows root authority database will remove certainly Microsoft's MD5, and I imagine Thawte, GTE, Equifax, I mean, you can imagine how fast Equifax is scrambling since they're the ones that happened to get hacked because their MD5 certificate...



LEO:  They're the poster boys.



STEVE:  Exactly.  It was sitting in there and widely distributed across all the clients that are using SSL on the Internet.



LEO:  Wow.



STEVE:  Yeah.



LEO:  So does this impact other technologies using MD5?  I mean, MD5 is still a widely used hash.  



STEVE:  Well, what this says is that MD5 is clearly no longer safe.  MD5 is now - it can now be said that MD5 is not just dented, it is broken.  The fact that you can deploy, I mean, two weeks is not that long, even though you need 200 PS3s.  I mean, you can imagine an ad hoc, some sort of, like, Internet network of PS3s, cranking along in their spare time.  And there have been projects that repurposed these kinds of gaming platforms through peer-to-peer networks for searching through SETI star noise and folding of biological organisms and all kinds of different things.  So you could imagine that it would be possible for other exploits using MD5.  Basically, MD5 makes sense in low-security applications where you want a fingerprint.  But having said that, and given that SHA-1 is so available...



LEO:  And so effective and uncracked, yeah.



STEVE:  Exactly.  Why not use it?  I mean, I think this is the death knell for MD5.



LEO:  It's a big shock.  So is there anything people can do at this point?  I mean, there's no, I mean, all these certificate authorities have to change their technology; right?



STEVE:  Yeah.  I would say, I mean, if somebody were - if you were the CIA or somebody who was really concerned, what you could do is go through your root store - and again, on the show notes for Episode 177, snipurl.com/sn177, I will show our users how to do this.  I'll see if I can do it on the Mac.  I'm not nearly as familiar with the Mac as I am with Windows.  But it's certainly possible to look through the root certificate store.  And users could delete any of the certificates that are signed using MD5.  And in doing so, they have essentially said to their computer, okay, this computer is no longer going to accept MD5-signed certificates.  Which, you know, it does solve the problem.  You may find that if there were a website that didn't have, for example, both MD5 and SHA-1, if it was only signed with an MD5 cert and not co-signed with an SHA-1, then you may not be able to connect with SSL.  And then you'd have to decide if you wanted to or not.  Now remember, this, however, would only be used as part of a blended attack.  So two things are necessary.  You would need not only to be able to have a spoofed certificate offered by a server, that is, the destination server that you go to, but also some way of diverting you to that.  Now, as it happens, earlier this year we talked about DNS spoofing and the so-called Kaminsky Attack, which does exactly that.



LEO:  Aha.



STEVE:  So, yes.  So we were saying that, okay, so you go to a site which is a spoofed site, thanks to DNS being poisoned.  And okay, well, fine, maybe you don't notice that when you're logging into eBay it hasn't switched you into a secure mode.  And if they don't switch you to SSL, and you just assume that the login is going to take care of your security because it always does, then you're using a spoofed server, and SSL doesn't come into play at all.  But if you were very security conscious, you might make sure that you were at https://www.ebay.com, or PayPal or whatever, and you could even then, as we've often said, check to make sure your lock is unbroken or your key is unbroken.  Right-click on the page, make sure that you're secure.  All of that would work if the server had a fraudulent certificate issued by a fraudulent certificate authority.  So two things are necessary.  It's not just the spoofing of the certificate.  It's also somehow getting you to a fraudulent server with a fraudulent certificate.  So both things are necessary.  Although both things are potentially possible.



LEO:  Hanging out there.



STEVE:  And 25 percent of DNS servers have still not been fixed.



LEO:  Is that the number still?



STEVE:  Yeah.



LEO:  Geez, Louise.



STEVE:  One out of four.



LEO:  Use OpenDNS.



STEVE:  Exactly.



LEO:  Let's talk about the PDP-8.  I remember, when I first started working at a radio station in 1987 in San Francisco, KNBR, they were doing their music programming with a PDP-8.  And I thought, this is so antiquated.  This is '87.



STEVE:  Well, the very first computer I ever saw, I must have been, like, 10.  And my dad took me to his corporate computer facility.  He worked for Industrial Indemnity in San Francisco, big industrial insurance company.  And this was the guys walking around in the white lab coats on the raised floor.  The whole facility was like it was a little jewel.  It was, I mean, it was a showpiece for the company.  And so we went down, and of course there was no going in the room.  I just sort of pressed my face up against the window, which was cold because it was all air conditioned on the other side.  And I was just mesmerized.  Here was, I think it might have been an early IBM 360 because it had a huge panel of lights, the buttons all over the place.  I mean, the classic sci-fi-looking, what people think of as like an old-style computer with all literally active twitching reel-to-reel tape drives, a pair of reels, and then the vacuum loops that were used for mechanical buffering because the tape would be twitching back and forth, and then these vacuum loops would be used to drive the reels back and forth.  And, I mean, just - and a big huge line printer going ching-ching-ching-ching-ching-ching-ching, moving through paper very fast.  I mean, I was just - it was like love at first sight.



LEO:  Now, that was a mainframe; right?



STEVE:  That was, oh, yeah, that was a full-on, major league mainframe.  And back in a time when machines like that were still very expensive and very new.  But a big industrial insurance company like Industrial Indemnity, they live and breathe with managing all of their accounts and accounting and had the kind of money to afford that.  So that's...



LEO:  This was a huge breakthrough, really.



STEVE:  Yeah.  So that really sort of set me off on, well, I mean, I was already - I knew computers was where I was going to be.  At that point I was very involved in electronics.  You know, my dad took a picture of me before I was five years old wiring up stuff in the backyard.  We had a picnic table, and I was wiring buzzers and bells and knife switches and things.



LEO:  Why am I not surprised?



STEVE:  I was a computer hobbyist from the beginning.



LEO:  If you could have made your doorbell go "yabba-dabba-do," you would have.



STEVE:  And then when I was in high school I used to hang out in the math resource center, I mean, serious geek, nerd person.



LEO:  Nerd, nerd.



STEVE:  And one of the high school teachers told me about a company in San Carlos that was located not far from San Mateo, where I was, that was doing something with computers, and that maybe there was an opportunity there.  And I thought, well, I've got to go find out about that.  So this was a company called Technica Education Corporation.  And it was there that I actually encountered and touched my very first computer, which was this Digital Equipment Corporation, DEC, PDP-8e.  And it was a 19-inch-wide, rack-mounted thing with switches on the front and lights.  And this was my first computer.



LEO:  You can't underestimate the importance, by the way, I think, of that human scale.  Going from that thing that was isolated on the other side of the glass, and the high priesthood was maintaining it...



STEVE:  Exactly.



LEO:  You had no accessibility.  When you're suddenly touching a computer, the whole thing changes.



STEVE:  Oh, yeah.  It was, I mean, I want to say a religious experience.



LEO:  Yeah.



STEVE:  I mean, it was just like, oh, my god.  I mean, here it was...



LEO:  Well, you're not alone.  I think Bill Gates, the PDP that he used at Lake School, Lakeside School, that's what turned him on.



STEVE:  Yes.  Well, and there was the ASR-33, the classic teletype that had the big, round, sort of cylindrical keys you would press down one at a time.



LEO:  [Sound effects]



STEVE:  Yeah, exactly.  And it went 10 characters per second was as fast as it could go.  Then over mounted to the left of it was the paper tape punch and reader.  So because, you know, you loaded software on eight-channel, eight-track paper tape.  There was a guy there who was - so I was probably either a sophomore or a junior in high school, so 15 or 16.  There was a guy there who was a few years older than I, guy by the name of Lynn Cooley, who at the time had, like hippie sort of long, blonde hair tied in a big pony tail.  And he had a job at Technica, where I was soon employed.  And it was Lynn who sat down with me and said okay, let me show you how this works.



LEO:  Oh, that's neat.



STEVE:  And I learned Assembly language, the very first Assembly language, on the PDP-8.



LEO:  And you never stopped.



STEVE:  Oh, and I never stopped.  I'm still programming Assembly language.  That's my language of choice.



LEO:  What was the Assembly for PDP-8 like compared to the 8086 Assembler that you - the x86...



STEVE:  Oh, well, it's funny.  Minicomputer, we think of mini as meaning "miniature."  But they called it a minicomputer.  They meant it as "minimal."  That is, it was deliberately a minimal computer.  That is, the least computer that you could have and still be a computer.  So, for example, there's no load instruction to load from memory into the accumulator.  Instead you can add what's in the accumulator - you can add a memory location into the accumulator.  Which means to do a load, you have to do a clear the accumulator...



LEO:  Zero it first, and then you add.



STEVE:  Zero it and then add.  There's no XOR.  There's no OR, believe it or not.



LEO:  Wow.  What?



STEVE:  Those fundamental logical operations.



LEO:  But you can simulate all of them with multiple steps; right?



STEVE:  Exactly.  And so the PDP-8 is a 12-bit machine.  That is, you know, we're used to 16 and 32 and 64.  This thing is 12 bits.  And there was a lineage of 12-bit machines that DEC produced over time.  The first three bits of the 12-bit word is the opcode, meaning there's eight of them.



LEO:  That's eight things it can do.



STEVE:  Yes.  Now, eight fundamental things.  So, for example, there's add...



LEO:  Add, subtract, there's got to be a move; right?



STEVE:  No.



LEO:  A compare?  There's a compare.



STEVE:  Well, one of the opcodes has - is like a lot of little bits down below.  So, for example, there are things like complement the carry, complement the accumulator, those sorts of things are all variations in one of the opcodes.  And one of them is an I/O instruction.  So you have I/O.  You have that math.  There's the...



LEO:  Right.  No multiply, probably, just add and subtract.



STEVE:  Oh, yeah.  No multiply.  Oh, my god, you were just dreaming if you wanted to multiply.  There's an instruction called DCA, Deposit and Clear Accumulator.  And you don't have a choice.  So anytime you store data in memory, your accumulator is cleared.



LEO:  Oh, man.



STEVE:  So if you want to store it and not have it cleared, then you've got to store it and then do the TAD, which is that add instruction.  But the accumulator is cleared now, so when you add back what you just stored you get it back again.  So the point is it was really, really minimal.  There's no stack in this machine.  They hadn't invented stacks at the time.



LEO:  Wow.



STEVE:  But what it was, was a perfect platform for playing around with a computer.  I mean, this was...



LEO:  Well, it was a personal - it was the first personal computer.



STEVE:  Yes.  Well, yes.  I mean, it was personal.  I was able - I don't think I slept for about three weeks after I had access to this machine.  I didn't want to sleep.  I didn't want to eat.  I didn't want to do anything except - and it had a front panel and lights, just like the big one that I had seen behind the glass.  And so you literally, when you - it also had core memory, so actual ferromagnetic little doughnuts in there that were magnetized one way or the other.  And everything worked with core memory.  There was no - we didn't have solid-state memory back then.



LEO:  And how many words did you have?  Probably not a lot.



STEVE:  Well, okay.  !2 bits can only access 4K.  4K.



LEO:  Yeah, but 4K probably costs thousands of dollars when it's core.



STEVE:  Oh, yeah, yeah, yeah.  This thing was - it was, I think, like a $25,000 minimal computer at the time.



LEO:  Unbelievable.



STEVE:  It was expandable.  They had, like, a bank-switching arrangement.  You could expand it, so you could have eight 4K banks, meaning the absolute maximum configuration was 32K.  32 kilobytes, or kilowords.  So anyway, I was just, I mean, that was my first machine.  And obviously it had a warm spot for me.  I mean, it's meant a lot over time.  So you are actually responsible, Leo, for what happened next.  I was watching TWiT Live, and somebody on camera brought out a core memory plane.



LEO:  Me.  I have one.



STEVE:  You've got one, I know, somewhere around there.



LEO:  Yeah.



STEVE:  And I don't know what I was doing.  I was working or doodling or something.  I just had TWiT Live on in the background.  And there was this core memory plane.  I looked at it.  I thought, I want one of those.



LEO:  Had you told me, that could have been your Christmas gift.



STEVE:  I don't have any - well, I've got core now.  But so I thought, I need some core memory.  Just, you know, because.  Before it all goes away.  Before it's all been...



LEO:  Yeah.  Somebody sent - they framed it, and they sent it to me.



STEVE:  That's so neat.  So of course I went to eBay, and I put in "core memory."  And there was a bunch of people selling core memory.  So I got a couple different ones.  And there was one that I struck up a dialogue with this gal in West Virginia, a surplus seller.  And I don't remember now what it was, maybe we were talking about shipping, or maybe I bought two of them, and I thought, well, I'm going to get these two, why don't you just put them together and ship it to me in one box and we'll save some money or something.



So we're sending email back and forth, and she says, by the way, I also have a couple PDP-8s with core memory.  And I said, what?  You have what?  Okay, now this, you know, this was 35 years ago that this was all happening, or more than that even, maybe 40 years ago.  And I said, what do you mean, PDP-8s?  They're all gone.  She says no, I've got a couple in a couple crates.  So I thought, okay.  Send me pictures.  So she didn't - she wasn't sure what they were.  They were two machines, each in their own crate.  And she took a picture of the front panel.  And sure enough, it's a PDP-8.  But it wasn't a completely standard PDP-8.  There was something different about the panel.  Well, Google is your friend.  I was able to figure out that these PDP-8s were part of a Canadian LORAN-C monitoring network.



LEO:  Whoa.  This is...



STEVE:  LORAN-C is a land-based navigation system, sort of old school.  And what's interesting is that until the attacks of September 11, LORAN-C was going to be decommissioned because now we have GPS.



LEO:  Right.



STEVE:  But the Department of Homeland Security decided that we might need a backup positioning system.  So they decided not to scrap LORAN-C because the advantage of LORAN-C is it's completely different from GPS.  GPS is satellite based, uses a completely different frequency range.  LORAN-C is much lower frequency.  GPS is very high frequency.  LORAN-C is ground-based as opposed to space-based.  So it made sense that this would be a good fallback navigation system.  So I learned from doing some Googling that these machines had been integral to - had been designed into these monitoring stations years ago and had been decommissioned.



And in fact there was a letter I found where someone said that they, when they tried to remove the PDP-8s, because these were such old machines, and just like replace them with something new, they found that they - it was a much, much harder job than they anticipated because the PDP-8 wasn't monitoring the receiver.  It was the receiver.  That is, it had been integrated so tightly into the electronics that it was involved in all aspects of running the receiver.  What these were, these were fixed-location stations that received the LORAN-C transmissions and just checked them.  They were just verifying that what the various LORAN-C transmitters were sending was correct.  So they were doing the sort of like land-based quality control.  Well, what I then found out was, to my amazement, these two machines that this gal in West Virginia had had never been used.  They were...



LEO:  Really.



STEVE:  They were spares.  Brand new, never deployed.  They've been sitting in Alameda County at the U.S. Coast Guard in Alameda for who knows how many years.



LEO:  And presumably maintained and kept dry and, I mean...



STEVE:  Well, yeah, I mean, in individual crates.  They were crated, ready to be sent out to replace a broken deployed PDP-8e in one of these monitoring stations, if that ever happened.  So I own them now, needless to say.



LEO:  You bought the whole thing.



STEVE:  How could I not?  I mean, this is a piece of history that - and it's funny, too, Leo.  Because, I mean, whenever I look at the photo of the front of one of these, I just kind of like, oh, god.  I mean, it just...



LEO:  Isn't that neat.



STEVE:  It really gets me.  Okay.  So the reason this is interesting for, or potentially interesting for our listeners, is that something else happened while I was doing all this PDP-8 research.  I stumbled on a site, SpareTimeGizmos.com, by a neat engineer who's also a programmer PDP guy.  DEC did a bunch of different PDPs.  There was the PDP-10 actually I encountered when I was working at the AI lab at Stanford.  They had a PDP-10, and I think they used a PDP-11 as the front end.  So PDP stands for Program Data Processor.  Anyway, this guy Bob Armstrong created a PDP-8 kit toward the end of the life of the PDP-8 line.  Intersil, that was a semiconductor manufacturer, created a PDP-8 on-a-chip, a single-chip PDP-8.



LEO:  Probably not such a sophisticated chip either, given what you've told me.



STEVE:  Probably not that difficult to do; right.  And Harris Semiconductor later bought Intersil.  They produced the HD-6100 was the name of their chip, and then a second-generation HD-6120.  Well, Bob Armstrong, who is sort of a hobbyist/craftsman/kit builder guy, he's got a whole bunch of cool things on his site.  One of them is a - he calls it the SBC6120, Single Board Computer 6120, which is - it's about, I don't know, four by five inches.  And it is a complete PDP-8 kit with a serial interface and, nicely, an IDE interface.  So you could interface this PDP-8, which is a - it runs all the standard DEC software.  DEC has done something interesting, too.  All of the software has been preserved.  All the manuals have been preserved.  BitSavers.org has all of this.  And there are various PDP-8 hobbyist/enthusiast sites around the 'Net where there's been an active effort to preserve this and keep this from being lost.



LEO:  Now, would you power yours up, your LORAN systems up?  Or are they just going to sit under glass in a museum?



STEVE:  Well, it's interesting.  We're going to be talking about capacitors of a different sort here next.  What happens with unused electrolytic capacitors is that...



LEO:  They leak.



STEVE:  They die.  And the old-style power supplies, so-called "linear power supplies," or you could almost think of them as, like, analog as opposed to digital power supplies. Contemporary power supplies are almost universally switching power supplies.  The original old linear power supplies have typically very large silver cans which are electrolytic capacitors, which are essentially the technology we have for creating a lot of capacitance in a reasonable space at a low voltage.  They rely on aluminum oxide as their insulator.  And over time the aluminum oxide breaks down in the capacitor.  So it's very likely that, were I to simply plug these machines in, they would explode.  The capacitors would explode.



LEO:  Oh, dear.



STEVE:  Fuses would blow.  Rectifiers would blow.  I mean, not something you want to have happen to your Model T prize antique of your life.  So it's possible, though, through a process of restoration - it's called "reforming" a capacitor.  You take the capacitors out one by one.  You give them a little bit of voltage and run some current through them.  And they will replate themselves.  They will...



LEO:  Oh, so it's not a leak.  It's just they got deplated.



STEVE:  Yes.  They've been deplated.  Unfortunately, if you put them under full use load, they would be short circuits.  And what happens is that a current would flow through, then it would burn the capacitor in that spot, and it would never be fixable again.



LEO:  So you're just going to trickle something into it so that the surface replates itself, essentially.



STEVE:  Exactly.  So you run a controlled current of a couple of milliamps through the capacitor.  And over time you'll see that - in fact, what I'll use is I'll use a constant current lab bench supply.  I've got one, and so I'll set it to - I'll limit its current to a couple mils and then set its voltage to the rate of voltage of the capacitor.  So over time it'll slowly bring the voltage up on the capacitor as the current running through it is kept constant.  But as it's replating itself it'll eventually become an open circuit again.  It'll end up essentially no longer leaking.  And that capacitor will have been fixed.  And so I'll step through every single large filter capacitor in the power supply, one by one, bringing them back to life, essentially.



So anyway, so I do certainly - I'm interested in making those machines work.  But I'm also excited, or I was excited, about this notion of there being a kit.  The problem was that when I went to this site, this SpareTimeGizmos.com, this was years ago it had been done.  The kits used to exist.  I think they were discontinued maybe in '04.  So Bob had created this, I mean, literally a turnkey kit - circuit board, all the components, everything you need, buy it from him, sit down on a Saturday afternoon with a soldering iron and build yourself a working PDP-8.  Then he went the next step.  And he created a front panel for this thing.



LEO:  I see it on the site.  It's so funny.  It doesn't say PDP-8.



STEVE:  I think he calls it, what, Gizmos?



LEO:  It says Gizmo SBC6120.



STEVE:  SBC6120.  Yup.  So that is a working control panel that emulates the PDP-8, just like what I had when I was 15, and what I may have...



LEO:  Now, do you flip those switches to program it?



STEVE:  Yes.  Yes.  I mean, for example, when the machine is empty, and you want to read in a paper tape, you have to key in the so-called "boot loader."  So you flip the switches...



LEO:  How many switch flips is that?



STEVE:  Oh, it's not that many instructions.  I think it's maybe like 12 or 13 instructions.  It's a very simple loader that is simply - it simply says read the next chunk of - read the next data from the paper tape.  Store it here.  Read the next one.  Store it there.



LEO:  But you're flipping those switches essentially with binary code for the Assembly instructions.



STEVE:  Yes.  Yes.  And in fact that was what...



LEO:  It's a great way to learn about computers, frankly.



STEVE:  Oh, well, in fact, Leo, many universities teach, I mean to this day, teach Assembly language using PDP-8 emulators. 



LEO:  Interesting.



STEVE:  I mean, the PDP-8 has been emulated.  There is courseware about the PDP-8.  If you put into Google "PDP-8 programming," you'll find page after page about the PDP-8 and programming because it's a perfect machine to learn programming on.  And this front panel, it's got the lights and switches just like the original PDP-8 did, where you're able to, like, flip the switches and then press Load.  And so it stores that and steps to the next instruction.  Flip the switches, press Load, literally to key in a little program.  And then it's got a switch that says Run.  And you press Run, and the machine runs it.  I mean, it's a real, honest-to-god little computer.



LEO:  Very neat.



STEVE:  So anyway, what happened was I was mourning the fact that four years ago this had happened and I didn't know about it, because I would have loved to have had one of these single-board computers, and certainly this fantastic front panel to go along with it.



LEO:  That's the real reason.  Because, frankly, you could do it all in software.  I mean, you could run a PDP-8 on any modern computer system easily.



STEVE:  An emulation of it, certainly.



LEO:  Yeah, yeah.  But you want the flip.  You want the switches.



STEVE:  Oh, yeah.  Well, and it's so thin now that you can literally get sort of like a deep picture frame, and you could hang it on the wall.



LEO:  You're right.  It's not - I'm looking at.  You're right.  It's not a big old box, is it.



STEVE:  No, it's only - I think it's maybe, what, maybe four or five inches deep.



LEO:  Because it's just that little board is all that's in there.



STEVE:  It's just a little board inside.  But, I mean, but Bob did - I mean, he's a craftsman.  Those front panels, they are multicolor silk screen.  They are laser cut panels.  I mean, just beautiful work...



LEO:  I've got to get one of those.  That is awesome.



STEVE:  Well, in fact, Leo, what I'm going to tell you is, I don't know if your builder gal...



LEO:  Colleen?



STEVE:  Colleen, yeah.  I don't know if Colleen wants to build it.  But if you want one, and she doesn't want to build it, I will build it for you.



LEO:  I'll probably - but I can - I'm not an idiot.



STEVE:  Okay.  Well...



LEO:  Is a little soldering involved?  There's a little soldering?



STEVE:  Lots of soldering, yes.



LEO:  Lots of solder.  Oh, because you have to put all the chips and everything on the board.



STEVE:  Yeah.



LEO:  Oh, okay.



STEVE:  Anyway, so what happened was, I was shedding a tear, I mean, yes, I was going to get some real PDP-8e's.  But this was just like portable, low power, it would really work, brand new.  And it was just a work of art that this guy had created.  So anyway, I wrote to Bob, and I said, hey, Bob, I've seen your site.  I realize this was years ago; it's too late.  I said, if you know anyone who wants to sell theirs, I'm definitely in the market.  I'd be happy to buy one.  I think in fact maybe at some point he put them on eBay.  I'm not sure, but I saw some reference to eBay.  Also, all of his work is open source.  That is, he's not trying to make any money on this.  So, like, all the software, all of the Gerber tapes for making the circuit boards, I mean, he's just said, if anyone wants to do this much more on their own, they're welcome to.  But otherwise he was producing a kit.  So I wrote to him and I said, for what it's worth, I don't know, if ever one - if one comes along, if someone wants to sell theirs, if it ever comes back to life, absolutely put me on some list.  I have to have one.  And so I got email back from him a couple days ago, I mean, a couple days after that that said, well...



LEO:  Colleen has just come in to say I want to build one.  I don't know why.  She never would have seen anything like this.  For her this is like the Dark Ages.



STEVE:  Oh, but it's just such a slice of history.



LEO:  She wants to do it.



STEVE:  Good.  So he said we may have some news by the end of the year, if not sooner.  And sure enough, somehow - see, this chip that's the heart of this is this Harris, this HD-6120.  And they haven't been making them for 15 years.  I mean, it's been dis- it's long since discontinued.  Somehow Bob got some more.  And there's been enough pressure on him to, like, bring this thing back to life that for a limited time it's going to come back to life.  And I've told him I need three.



LEO:  [Laughing]



STEVE:  I don't know why.  I mean, two, you know, because it's going to go away, and it's never...



LEO:  I want to do a Beowulf cluster with my PDP-8.



STEVE:  It's never - it's going to go away, and it's never going to come back again.



LEO:  No, that's true.



STEVE:  I mean, this is never going to happen again because when these chips are gone, they're completely gone.



LEO:  I would just buy the front panel and hang it on the wall here and pretend.



STEVE:  Well, Leo, you've got to have the lights blinking.



LEO:  Oh, yeah, you're right.



STEVE:  And so what I'll do is I'll write a little program for you that makes blinky lights.



LEO:  So it's 350 bucks for the full kit.  So that's the board; that's all the parts.  You have to solder them, though, onto the board.



STEVE:  Oh, yeah.  It's not for someone who's not comfortable building things, building electronics.  But that does not include the front panel.  The front panel, he needs to see whether there's enough interest.  At this point he's got a Yahoo! Group.  I've got links on our page.  But he also, down in the lower left-hand corner of his page, he talks about Yahoo! Groups.  There's a SpareTimeGizmos Yahoo! Group.  I've joined the mailing list side.  You can just send sparetimegizmos-subscribe@yahoogroups.com, I think is the address.



LEO:  No, I've got to have one.  I've got to have one of these.  I've got to have one of these.



STEVE:  It looks like about 15 people so far have said, oh, absolutely, I need a front panel.  I need three front panels because I want one for each of my little boards.



LEO:  I would like to automate my home using this device.



STEVE:  Well, it is expandable.  It's got a bus on it, so you can do that.  It's also got the IDE interface.  And remember that IDE is the same as Compact Flash.



LEO:  Right.



STEVE:  So you could just take a little 1GB, inexpensive Compact Flash and have nonvolatile storage.  Also the other guys that have paved this road already, they've got the various - all the DEC software is in this format.  OS/8, which was the operating system for it, is there and running on this.



LEO:  Would I need a paper tape loader?  Or how would I get - I guess I could put it on the Compact Flash.



STEVE:  Yeah.  I haven't followed through all the details.



LEO:  That's going to be interesting, yeah.



STEVE:  It has a serial interface also.  So you could also connect it to your PC or your Mac and then use a terminal emulator in order to talk to it.  But one way or another we'll do this.  So it runs OS/8.  FOCAL 69 was the formula calculator, was the language that the DEC created back then for these machines.  And a whole bunch of stuff.  And, I mean, for anyone who is interested in, like, a chunk of history...



LEO:  No kidding.



STEVE:  ...who, you know, the idea of switches and lights on a real little computer, something very understandable.  The original books, the handbooks are still available online.  Everything has been scanned and has formally been released from copyright by DEC.  So you can get PDP, I mean, you can get PDF files of all the documentation.  It's just - and anyway, I just wanted to tell our listeners.  I don't know how many old-timers we've got.



LEO:  That's so cool.  Did he say how many people he'd need to get to order that front panel?



STEVE:  He said 100.  100 would...



LEO:  100.  And how much would it be?



STEVE:  I think it's going to be, like, $400, or $450.



LEO:  For just the panel.



STEVE:  For just the panel.  So I'm not sure, but...



LEO:  So you're talking 350 for the guts and 400...



STEVE:  Yeah.



LEO:  750 bucks to build a computer that is essentially dumber than my digital camera.  Or, I mean...



STEVE:  I know.  It's nuts.  But it - I want...



LEO:  I understand.  I understand.



STEVE:  I felt such a sense of loss when I thought I had missed the window, that this had happened, and it was never going to happen again.  Now it is.  So I wanted to take some time to tell our listeners.  Based on the reactions just in my own newsgroup, because I've told the GRC newsgroup about this, there were a bunch of people, like, oh my god, that was the first computer I encountered.  Or we had one at work.  Or just like you said, you had one at the radio station.



LEO:  Sure.



STEVE:  That was still doing something.



LEO:  Well, we've got 75,000 people listening.  I bet we could find 100 people listening who would want to build one of these.



STEVE:  We'll find out.  Because again, all the links are there.  You can go to SpareTimeGizmos.com or Security Now!'s Episode 177 page that I've mentioned, snipurl.com/sn177.  I put a bunch of notes up there.  Contact Bob.  Join the SpareTimeGizmos Yahoo! Group.  Send email saying, hey, I'm onboard, I want to do this.  And we'll see how many people we get.



LEO:  What a hoot.



STEVE:  It just is.  It's a kick.  And Leo, I could just see it in the background there on the shelf.



LEO:  Well, that's what I'm thinking, exactly.  Having it blink there, right there, it's a piece of history.



STEVE:  Such a piece of history, yes.



LEO:  Well, maybe we'll - Colleen really wants to build it.  The problem is it's one of those things that, oh, I would love to do that.  But it's just, you know, it's hours and hours and hours.  Not merely the building, but understanding it and hooking it up.  And it's a big commitment.



STEVE:  I can't think of anything more fun.  Actually, I have to tell you.  When this happened, when it turned out I could actually have a couple of the real antique PDP-8s, and not even knowing that I'm going to be able to get one, I mean, definitely the boards are available.  So there's a real piece of PDP-8 hardware.  My plan...



LEO:  Well, you've got a PDP-8.  You've got a couple of them already.



STEVE:  Yes.  My plan, when the world has decided it no longer needs me, when it turns me out to pasture, you know, in 30 years...



LEO:  You'll be the dotty old guy in the nursing home...



STEVE:  When I'm 83, yes.



LEO:  [Indiscernible] make it work.



STEVE:  My plan is to start from scratch and write everything for the PDP-8.



LEO:  SpinRite?



STEVE:  An editor - no.  I've never taken an empty machine and created an entire environment - editor, assembler, compiler, operating system, everything.



LEO:  That's what Kernighan did with UNIX.  I mean, that's - you sit there.  Here's the hardware.  We need, you know, everything.



STEVE:  Right, right.



LEO:  I mean, there is exists - you could use OS, as you said, OS/8.  But I think fun, I mean, really fun project.



STEVE:  And, I mean, it's not interesting to do it on an Intel chip.  First of all, there isn't documentation for, like, everything.  I can't write from scratch a driver for my graphics card because they just give you the drivers.  And that doesn't - it doesn't interest me.  It's too easy to do that for a contemporary chip.  But imagine, like, a real editor, a full-screen editor, an assembler, an operating system for a chip with no XOR and no OR, where you have to do a combination of instructions to do that.  I mean, no stack.  It'd be a real, I mean, I'd be sitting there with a pencil thinking, okay, how am I going to do this now on this thing?  Anyway, I just think it would be a really, really fun puzzle for, like - I'll have come full circle.  The first machine I ever saw and the last machine I ever program, both a PDP-8.



LEO:  I remember this.  Oh, I love it.  So it's all there.  We have snipurl.com/sn177.  You can go there to get all the details.



STEVE:  And you see pictures of it immediately.  I put a picture of this beautiful thing on our site, and you can also see it on Bob's site at SpareTimeGizmos.com.



LEO:  Before we get to the capacitor story, I just want to mention a story that's breaking now as we record.  We're recording this the last day of 2008.  You're going to hear this the first day of 2009.  Apparently Zunes stopped working at midnight last night.  They're calling it Z2K.



STEVE:  Oh, no.



LEO:  Microsoft says, yeah, we know there's a problem.  It's apparently only affecting the 30GB Zunes.  I have a 4GB Zune that's not.  But many of them just frozen up.  Some people are reporting that popping the battery and restoring the system essentially to earlier firmware - it's apparently a firmware issue.  Can you imagine the nightmare that Microsoft - first they've got this Red Ring of Death on Xboxes.  And now this.  The Zune just stops working on December 30, 2008.  Unbelievable.  Let's talk about capacitors.



STEVE:  Yes.  Okay.  I've sort of been watching energy stuff, sort of in the background, for quite a while.  I'm one of these people, I've read a bunch of books about various topics surrounding this issue of peak oil.  You know, are we going to get to a point where oil availability is going to become a problem.  And I'm not an apocalypse guy.  I don't think the end of the world is going to happen.  Obviously we're not going to suddenly run dry of oil.  But the earth originally had about two trillion barrels of oil.  And we've pulled about one trillion out of it, about half.  And the...



LEO:  Right.  It gets harder and harder, of course, to get.



STEVE:  Yes.  And, well, we've got the easiest...



LEO:  We got the easy stuff, yeah.



STEVE:  ...one trillion.  You know, this all began when some farmer in Pennsylvania was pissed off because there was black goo coming up in the middle - it was, like, upsetting his crops.  And of course the rest is history.  So until 1970 the U.S. was a net exporter of petroleum.  I mean the whole Texas Tea, I mean, we've got grasshoppers pumping on stuff over here in Southern California even.  But what happened was the U.S. hit its peak and has been in production declining ever since.  We still produce oil, but we don't have enough to export to the rest of the world.  And of course Saudi Arabia is the famous producer now.  Their fields are aging.



Anyway, the point is that long-term, at some point we're going to have a problem where we're no longer able to grow production, even though consumption is still growing.  And it is still growing.  Now the worldwide economic slowdown that we're one year into in the U.S., I mean, that's certainly going to slow down demand.  It has slowed down demand.  And in fact last summer's high prices slowed down driving a lot, and so demand got cut.  So it's impossible to know when this is going to happen.  And when it does, it's not like the oil's gone.  It's just like, wait a minute, now we'd like to have more than we're able to get.  And so you can imagine prices are going to go up and probably stay up.  They're not going to be - there's no way they're going to go back down again to the level that they have again.



So this puts a lot of pressure on alternatives.  Certainly we can get a lot more efficient.  Cars can get much more fuel-efficient.  We've seen the hybrid model where it's a hybrid electric and gas.  There's wind and solar and so forth.  But one of the problems with cars is batteries because what many current hybrids have has a limited life.  It lasts maybe three years, and then it needs to be replaced.



LEO:  It's also - they're also very heavy.  The Tesla has a thousand pounds of battery in it.



STEVE:  And they cost about half the price of the car, Leo.



LEO:  Right, right.  And they're explosive.  And they take forever to charge.



STEVE:  They take forever to charge, and they're toxic.  I mean, lithium is not something that you want out in the environment.  Lithium-ion cells, I mean, and lead acid is the same way.  All these battery technologies have serious downsides.  But one of the things that I noticed was people are talking about if Detroit ever survives and gets its act together and is actually producing electric vehicles, as I understand it they're talking about you buy the car, and you lease the battery.  That's how they're going to solve the problem of these things having limited life.  But the lease charge is, like, $200 a month is the lease on the battery.  But that way you don't own the battery, so you're not upset with the manufacturer when it really no longer gets you over to the market any longer.



LEO:  Plus they can force it to be recycled and so forth.



STEVE:  So against this background there's been operating in Cedar Park, Texas, some sort of a company under wraps of secrecy called EEStor, Inc.  EEStor, all that was known about them was that they had some amazing next-generation energy storage technology.



LEO:  Now, this isn't like those guys who claimed I can run my car on a teaspoon of water, is it?



STEVE:  Well, no.  The reason I'm excited, the reason I'm taking our listeners' time with this, is you know I'm a double-E.  As I said, I was wiring electrical things before I was five years old.  And it was all hardware until I switched over - in fact, when I was at Berkeley, people used to say, oh, are you hardware or software?  It's like, you know, you couldn't be a hybrid.  You were either a programmer or you were a nuts-and-bolts guy.  But those people didn't know about computers and software, and the software guys didn't know about the hardware.  I had the advantage of sort of having come through both eras and was able to mix it.  Which actually is probably where SpinRite came from.  But what excites me about this is that it makes sense.  I once heard the notion of a supercap, a supercapacitor.  And I thought, wow, that's a neat idea, the idea of making a bigger capacitor, a capacitor that would store more energy.



LEO:  So, but you have to understand what a capacitor does for this to be...



STEVE:  And we're going to talk about that.



LEO:  Okay, okay.



STEVE:  So this company, no one really knew what they did.  There were some press releases.  People I think knew that they were funded by Kleiner Perkins Caulfield & Byers.  Well, Kleiner Perkins, as they're known, is one of the more successful venture capital firms in Silicon Valley.  They have, for example, financed little companies called Google and Amazon and Netscape and AOL.  I mean, these guys tend to know what they're doing.  They do make some wild bets, but with potentially wild upside.



So what happened, what finally brought this to my attention is on Tuesday, December 16th of this year, a few weeks ago, U.S. Patent 7466536 was granted.  And as happened with a granted patent, the content of the patent is then put into the public domain.  The inventors or their assignees have 17 years of exclusive rights to the intellectual property described in the patent.  But part of the idea is - the idea is that other people can build on that.  So it's made public.  The title of the patent is "Utilization of Polyethylene Terephthalate Plastic and Composition-Modified Barium Titanate Powders in a Matrix That Allows Polarization and the Use of Integrated Circuit Technologies for the Production of Lightweight, Ultrahigh Electrical Energy Storage Units."  Which is a mouthful.



What these guys have succeeded in doing is using integrated circuit production technologies and essentially nanotechnology to revolutionize capacitors, the fabrication of capacitors.  Okay.  Now, a capacitor in its simplest form is - you can visualize it as two parallel plates that are spaced close together, that are connected, and there's a wire running from each plate off to somewhere else.  The characteristic is there is no flow of current across the plates because they're separated, like by an insulator.  The insulator is called a dielectric in the case of a capacitor.  But an electrostatic field is created when a charge is placed on this.  That is to say, if you were to hook this up, this capacitor up to a battery, like maybe through a light bulb or some resistance, the voltage in the battery would flow through the circuit, essentially charging the capacitor.  So the battery would give up some of its energy to this capacitor, which stores the energy in the form of an electrostatic field between these plates.  So the amount of capacitance is a function of the size of the plates - the bigger the plates, the more capacity in the capacitor - and the proximity of the plates to each other.  The closer together they are, the greater the capacity.



Now, the amount of capacitance in a capacitor is measured in something called a "farad."  And the problem is a farad is impractically large.  So all the capacitors I have in the garage, the capacitors we've got in our computers, they're microfarads.  You might have 25 microfarads or 100 microfarads.  Or maybe 250 microfarads.  That is to say, millionths of a farad, because the actual value of a farad represents so much capacity that no one's created capacitors in high volume and practical applications that are many farad before.  So, and these typical capacitors we have in our consumer electronics will maybe have, like, a 25-volt rating, meaning that the way they're built, they have, for example, 100 microfarads of capacity at 25 volts.  So you can put 25 volts of charge on the capacitor, and that's all the manufacturer is guaranteeing them for.



If you crank them up much above that, what voltage is, and to use a water analogy, voltage is pressure.  So current is the actual flow of electrons.  Voltage is the pressure behind that flow, if any.  You may not have any flow.  You might just have pressure.  For example, if you were, like, holding a garden hose closed, you could feel the pressure even though there's no flow.  Current is the actual flow of the water from the hose.  So you might be able to have 25 volts on this 25-volt capacitor.  I'm sure there's some leeway, some headroom.  But if you went way higher, this thing would end up overheating because you would - essentially the voltage would end up creating a stress in the capacitor that would cause a perforation through this dielectric which is insulating the two sides of the capacitor.



And if people are familiar with the way these things look, they typically look like little tanks.  What they actually are typically is two pieces of long aluminum strip, which is then rolled up.  And it's really - it's interesting.  It's rolled up because then you get sort of the effect of interlacing plates.  If you don't have just two plates, but if you roll those over on themselves, then you have the electrostatic field sort of on both sides of alternating plates in order to form the capacitor.



Okay.  So what these guys have done is they've been working in quiet in Cedar Park, Texas, for many years.  They're about a year behind schedule.  But little bits and pieces have been coming out.  For example, Lockheed-Martin, the largest aerospace contractor in the United States, has an exclusive contract with them now for military and aerospace applications.  So that sort of lends a little bit of credence to what these guys are doing.  Also they're clearly working in the right area because Georgia Tech has been working with the same, this barium titanium oxide, which is known as barium titanate, is the material used as the dielectric.  It's a nanoparticle-fine powder that has extremely high breakdown voltage.  And that's what you want.  You want to be able to put as much voltage in a capacitor as possible.  And the measure of energy that you can store in a capacitor is the capacitance, the capacity value, times the square of the voltage.  So that's why the breakdown voltage being high is so important.  The more voltage you can pressurize this capacitor with, the energy goes up by the square of that voltage pressure.  So you want it to be as high as possible.



Okay.  So take an existing battery pack that's well known, like the Tesla Roadster.  I know that you had someone on the show recently, Leo, who is a Tesla Roadster...



LEO:  Yeah, Jason Calacanis.  He owns it.



STEVE:  And loves it.



LEO:  And loves it.



STEVE:  And for people who don't know, this thing is - it can do zero to 60 in, what is it, four seconds?



LEO:  Yeah.  But this is typical of electric motors.  They have huge torque.



STEVE:  Yes.  And so essentially what happens is you are - the electric motor is nearly a dead short.  I mean, its own resistance is so low.  And so you just - you take this huge lithium-ion battery pack, which has been charged up, and you dump its power as quickly as you can across this electric motor, and it just kicks you, literally, into high gear.  Okay.  The...



LEO:  Tony, who edits the show and is sitting in the other room and is a fan buff, as is Colleen - a car buff, as is Colleen, says you get maximum torque at 1 rpm.



STEVE:  Wow.



LEO:  So that's, like, right away, basically; right?



STEVE:  Yes, instantly.  Like from a dead stop.



LEO:  Yeah.  Amazing.



STEVE:  The Tesla Roadster can go about 240 miles on its battery pack.  And it stores about 52 kilowatt hours is the amount of storage, 52 kilowatt hours.  So that's - a kilowatt hour, or a watt hour, is a measure of energy because it's an amount of power times time.  So it's like, for example, 52 kilowatt hours would be 52,000 watts for one hour, or one watt, 52,000 hours, or any ratio in between.  So it's a measure of energy storage.



Well, the patent is linked on the show notes page.  Every detail, I think it's an 11-page patent that describes in detail the manufacturing procedure and the composition of what these guys have done.  They have created, essentially, an ultracapacitor that is substantially more dense than lithium-ion in terms of its energy density.  It weighs less.  It's about - I think it's about half or less, a little less than half of the volume, yet stores the same amount of power.  They talk about this prototype being 300 pounds and occupying about 2.6 cubic feet and storing the same 52 kilowatt hours of energy that the Tesla Roadster lithium-ion pack does.  But because it's a capacitor, it first of all has no toxic substances at all, no hazardous material.  If you have enough power to charge it, you can charge it in five or six seconds.



LEO:  There is an issue, though, that you can't plug it into your wall and charge it in five or six seconds.



STEVE:  Correct.  So...



LEO:  You don't have enough juice.



STEVE:  So what this is, this is a 31-farad capacitor.



LEO:  Wow.



STEVE:  31 farad.



LEO:  Not microfarads.



STEVE:  Right.  So think of it for...



LEO:  What the heck?



STEVE:  If we put it in terms of microfarads, it would be 31 million microfarads.



LEO:  Jiminy.



STEVE:  And...



LEO:  So we're talking a signif- I mean, like, many orders, a thousand orders of magnitude improvement here.



STEVE:  Yes.  31 million microfarads at a breakdown voltage of about 5,000 volts.  They run it at 3,500 volts.  So they've, again, got some headroom.  But so remember that the energy storage goes up with the square of the voltage.  So the key is to run these ultracapacitors, if you want ultracapacitors for energy storage, they want to have the highest possible breakdown voltage.  But we mentioned charging them up.  Okay.  To charge this 31 million microfarad capacitor, or 31 farad capacitor, up to 3,500 volts, and let's say we gave it five minutes.



LEO:  You need a power plant.  You need a nuclear power plant in your backyard.



STEVE:  Well, 360 amps.



LEO:  Okay.  And the typical house has, what, 20.



STEVE:  Well, yeah.  A 15- or a 20-amp circuit.



LEO:  Right.



STEVE:  And so, for example, that would take about 30 hours.



LEO:  Okay.  But there are talks of, like, you could have another capacitor that you're trickle-charging.



STEVE:  Exactly.  You would have one that sits there charging.



LEO:  Like a reservoir.



STEVE:  The cool thing is that you would charge this at night when the electric power rates are lower.



LEO:  Cheap, yeah.  This is actually something people talk about.  If everybody bought Teslas, there'd be this sudden drain on the electricity.  You need this kind of capability of spreading it out to non-peak hours.



STEVE:  Well, and in fact I think Tesla owners end up with, like, specially wired circuits in order to...



LEO:  They don't have to.  But it's certainly beneficial.  It charges faster that way.



STEVE:  Right.  So anyway, I wanted to bring this to people's attention.  This relates - oh, also they have cycled, and this is in the patent, they have cycled one of these - I should mention that anyone who's interested can read the patent.  It's actually made up of almost 32,000 small subunits.  So it's through an integrated circuit-style printing technology.



LEO:  Oh, interesting.  So very cheap.



STEVE:  Yes.  And...



LEO:  Ultimately.



STEVE:  ...mass producible is their goal.  They were certified...



LEO:  How big are they, though?  I mean, how - are they giant?



STEVE:  Well, no.  I mean, it's like a third the size of the equivalent lithium-ion pack.  So you could have two of these in a Tesla Roadster and get 500 miles.  And as I understand it, I haven't done the math, but I think it's like, at 20 cents per kilowatt hour, it takes $10 to charge it up.  And you get 240 miles out of it.



LEO:  Unbelievable.



STEVE:  Well, the other thing that is interesting is now scale this down.  This changes cell phones and laptops.  I mean, now you don't mind that the Air, the Apple Air, has a nonremovable battery.  Doesn't have a chemical battery at all.  It's got a supercap in it.  And you plug it into the wall, count to five, and pull it out.  I mean, it's the way it should be.  And, oh, what I mentioned was, in the lab they cycled their ultracap, one of the smaller subcomponents, because it's all built up out of little cubes, and they have diagrams and show this in the patent, they've cycled it a million times...



LEO:  Wow.



STEVE:  ...and then remeasured it for capacity and leakage and various other physical properties.  No change.



LEO:  So this stuff doesn't degrade.



STEVE:  It never degrades.



LEO:  Doesn't wear out.



STEVE:  There's nothing there to wear out, Leo.  It's ceramic separating plates that have been printed...



LEO:  This is huge.



STEVE:  ...and bound together.  It's why I'm so excited about it.  Oh, and self-discharge.  Self-discharge is a problem with all regular electrochemical batteries.  They tend...



LEO:  They leak.



STEVE:  Normal batteries will discharge, like, 10 percent per month, for example.  This is 0.1 percent per month.



LEO:  So you could charge it up, and a year later get in, and it's all there.



STEVE:  Yes.



LEO:  Wow.



STEVE:  Yes.



LEO:  Now, they have an exclusive deal with a company called Zenn, out of Toronto.



STEVE:  Zenn is a Canadian car company, a strange little car manufacturer.  I, for the life of me, I don't know why they would sign an exclusive deal with anybody.  Zenn gave them some money.  Kleiner Perkins gave them $3 million.  I mean, if I had $3 million I would have given them $3 million.  I mean...



LEO:  This sounds like something that'd be worth investing in.



STEVE:  Yes.  The problem is, though...



LEO:  Production.



STEVE:  ...that they're not the only game in town.  I mentioned Georgia Tech is working on this.  BASF has a patent on barium titanium oxide capacitors.  So we know that - and you cannot patent a capacitor.  So there may be other useful ways to build an ultracapacitor.  What has got me so animated is that here's one.  I mean, this thing, if you read the patent, and you believe their claims, they're in production soon.  And we're going to be seeing cars that have removed the problem of lithium-ion battery packs.  It no longer dies after a few years.  You can charge it as fast as your electrical supply will because it'll just suck in energy at the maximum possible speed.  And you can imagine why Lockheed-Martin is interested, too, because capacitors will give up all their charge immediately.  So you could imagine some sort of space-based lord knows what, charging with solar cells and just waiting to dump the ultracapacitors into some sort of beam weapon and just punch a hole in whatever it's aimed at.



LEO:  This is amazing.



STEVE:  It is really cool technology.  And it also is important for solar and wind.



LEO:  Oh, yeah.



STEVE:  Because the problem with solar and wind is that they are non-uniform.  You only get solar power when the sun's shining on it.  You only get wind when the wind is spinning the turbine.  And so you want some way, some economical means of storing that power for use when you don't have raw input coming in.  And the problem is lithium-ion cells have all the downsides to them.  Ultracapacitors have none of them.



LEO:  Now, we should point out that this is just a patent.  They haven't shown they can produce this thing.  They actually haven't even tested it.  I mean, the Patent Office doesn't verify the claims.



STEVE:  Right.  They can claim anything they want to.



LEO:  Yeah.  Zenn believes that they'll be producing a car this year based on this.



STEVE:  Right.  Right.



LEO:  I would buy that car in a minute.  You know there's a Zenn dealer down the street from here.



STEVE:  No kidding.



LEO:  Yeah.  In Petaluma.  I would buy that car in a heartbeat.



STEVE:  My feeling is this is the future.  I mean, I read an article a couple weeks ago saying that I think it was Toyota was going to build a lithium-ion battery plant in the United States.  And I'm thinking, stop.  Why bother?  Build an ultracapacitor plant.  I mean, it is so clearly the right solution.



LEO:  Unbelievable.



STEVE:  Yeah.



LEO:  And I tell you, I mean, what I can see people doing is generating solar electricity.  And now you have a very efficient storage medium for that, really could change everything.  I mean...



STEVE:  Well, and in fact I was talking to Mark Thompson, my buddy in Phoenix.  He was talking about in regions where the daytime power cost is so much higher than the nighttime, you could imagine people getting an ultracapacitor and charging it up at night and then using the power during the day.  Which the power companies would love because they have a hard time delivering power at peak demand.



LEO:  Right.  They'd like to spread it out themselves.



STEVE:  Yeah.



LEO:  Well, I'm sure when the first person said I've got this thing called a microprocessor, that people laughed and scoffed.  And some people, maybe somebody like Steve Gibson, said that's going to change everything.  This is, I think, on that order of magnitude.



STEVE:  I do, too.



LEO:  And boy, I hope it's real.  That's exciting.  That's real exciting.



STEVE:  Well, these guys who founded the place are from IBM, a senior manager of disk-storage technology, and Xerox PARC.



LEO:  Okay.



STEVE:  I mean, these are not fly-by-night con artist people.  And Kleiner Perkins is not known for wasting their money.



LEO:  Yeah.  It's pretty credible.



STEVE:  I just - it was such a cool thing, the patent was just granted, all the details are there, linked from our show notes for this episode.  I just wanted to cue our listeners in and let them know that this had happened because I think it is potentially big news.



LEO:  Very exciting.  Very exciting.  Steve Gibson, you as always bring us great stuff.  Normally security stuff, but today two very interesting stories that don't have a security angle on it.  Next week we'll go back to doing our Q&A, our regular Q&A.



STEVE:  Yep, go back to our original phase.



LEO:  And we mentioned at the beginning of the show you can go to GRC.com and get all the information.  Steve's made a special SnipURL for you, snipurl.com/sn177.  That's the number of this show.  Or just go to GRC.com/securitynow, and you'll find it there.  You'll also find 16KB versions of the show, if you want to share this with somebody else, our special two-hour 2009 edition.  You can also get show notes there, transcriptions if you'd like to read along, and Steve's great stuff, including SpinRite.  You didn't do a SpinRite letter today.



STEVE:  I didn't.  I have one right here in front of me from Officer Greg.



LEO:  I'd like to hear it.  Officer Greg.



STEVE:  Well, I got a kick out of it.  He titled it "SpinRite Beats the Police."  And he said, "Greetings, Steve.  I just wanted to share my recent experience with SpinRite with you.  I am a police investigator for a medium-sized metropolitan police department in Southern California."  So somewhere down here in my neck of the woods.  He said, "My partner Detective Rick and I are both avid photographers..." - you'll relate to this, Leo.  He says, "...in our off time, and both exclusively shoot high megapixel digital SLR cameras.  Since convincing him to make the digital SLR switch, I've stressed the importance of backing up his image storage drives.  He has always assured me that he was.  Turns out he was just telling me he was backing up to get me off his back."



LEO:  Get him off his back.  Oh, that's terrible.  Ooh.



STEVE:  So he says, "A few weeks ago the inevitable happened.  His hard drive crashed.  Thousands of images were lost.  Detective Rick was devastated, and his wife was PO'd."  He said, "I immediately volunteered to try to save the drive for him using SpinRite.  Unfortunately, Detective Rick didn't believe that a single program could help.  Instead, he took the hard drive to our local computer forensic evidence experts.  After two days our forensic investigator only managed to recover a few files and declared the drive dead."



LEO:  Oh, dear.



STEVE:  "Convinced he now had nothing left to lose, Detective Rick turned the drive over to me.  I took the drive home and let SpinRite have a go.  Two weeks later SpinRite finished its run.  I took the drive back to Detective Rick, along with all of his image files.  He promptly moved the data over to two new drives.  Now he's a firm believer in backups."  So he says, "He moved the data over to two new drives and bought my lunches..." - and says, parens, "(and now he's a firm believer in backups) and bought my lunches for the next week.  Our computer forensic unit, after seeing the results, plans on purchasing a copy for their toolkit.  I run SpinRite on all my drives quarterly for maintenance, and proselytize its virtues to all that I can.  Thank you for providing a great program, and keep up the good works.  Once again, SpinRite saves the day.  Officer Greg."



LEO:  I love the variety of people who use SpinRite.  It's really neat.  That's wonderful.  SpinRite is available at GRC.com.  That's the place to go, the Gibson Research Corporation.  And lots of other great free stuff there, too.  Try out some of his free stuff.  Steve, Happy New Year.  Happy 2009.  Our first show of the new year completed.



STEVE:  Yup.  We've got a ton of Q&A stuff built up from our weeks of prerecording.  So we will be back doing Q&A next week for Q&A #57, Episode 178.  And I will say again, anyone who thinks they are interested in this PDP-8 opportunity, it is truly once in a lifetime.  Bob, I'm glad he's willing to do this again.  And it's only enabled by him having a bunch of these Harris HD-6120 chips.  You can get the PDF for the chip itself and take a look at the chip and the instruction set and all that on his site.  And I think a bunch of us are going to have PDP-8s, which is going to be very cool.



LEO:  Very cool, indeed.  Thank you, Steve.  Happy New Year.  We'll see you next week on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#178

DATE:		January 8, 2009

TITLE:		Listener Feedback Q&A #57

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-178.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 178 for January 8, 2009:  Listener Feedback #57.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now! #178 in a continuing series...



STEVE GIBSON:  And counting, yeah.



LEO:  Yes, Steve Gibson is here, the security guru.  Hi, Steve.



STEVE:  Hey, Leo.  It's great to be with you.  I'm feeling a little bit less like a guru than usual because I said something completely wrong last week that just really pissed me off.



LEO:  I know you hate it when you do that.



STEVE:  Oh, I really do.  And, you know, there's no excuse for it.  I was feeling rushed.  I was worried that we were going to have a show that was too long.  As it was, it was our longest ever.  It was two hours.



LEO:  Have you had any complaints?  Because I haven't.



STEVE:  No.  Actually I was gratified - I was also a little worried that it was a non-security show...



LEO:  Right.



STEVE:  ...largely.  And I got a ton of positive feedback from it.  Some people said they thought it was the best podcast we'd ever done.  Which, you know, I don't want to worry people, we're not going to go wander off the reservation and no longer do security.  But anyway, what I said that was wrong, that just really annoys me, was that I was talking about, in this whole SSL cracked deal - which I'm going to cover clearly and carefully in detail next week because it's a big issue.  In looking carefully at what the researchers did, they did some really clever, fun, and interesting things.  And we've never really talked about certificate chains.  I've referred to them sort of in passing, but we've never done, you know, really explained what that's all about.  And there were a bunch of questions that were raised that I saw in preparing the Q&A questions for this week.  So that's our topic for next week.



But what I said that was wrong was that it was the signature of the root certificate that was the problem.  And, I mean, I knew immediately when it was brought to my attention that I had said that, that I had misspoken.  It's the hashing algorithm of the certificates signed by the root authority that is weak if it's MD5.  So it's like, oh.  Now, it is the case that root certificates that have chosen to sign themselves with MD5 are probably also signing the ones they issue with MD5.  So there's that chance.  But that's really not the nature of the vulnerability.  And also there were people who were arguing that it's only certificates signed from now on that are the problem, not any that already exist.  And that's actually not true.  It's the nature of cryptographic weaknesses that they grow over time.



Anyway, I'm going to cover this.  It's the topic of next week's show.  We're going to go, like, in true to form, no rush, cover it from front to back so that everybody who is listening is going to completely understand this whole chain of trust and certificates and signing and all of that.  But in the meantime there has been an immediate reaction from somebody who is creating Firefox extensions.  There's an outfit called - the URL is CodeFromThe70s.org.



LEO:  I like that.



STEVE:  If you just put in "code from the 70s" into Google, it's the first link that comes up.  There's a Firefox add-in called SSL Blacklist.  And it's now, as of New Year's Eve, at v4.0.  What he just added in v4.0 is a check for whether MD5, the weakened, no longer really very secure hashing algorithm, whether MD5 is in use during the visit to a secure page.  And you'll be notified if it is.  That, of course, doesn't mean that this is a problem.  But it means that, you know, that the known exploit could be employed because the known exploit uses MD5.  So apparently about 14 percent of issued SSL certificates out on the Internet today are signed with MD5.



LEO:  40 percent?



STEVE:  14 percent.



LEO:  Oh, 14.  Oh, good.  Whew.  You scared me.



STEVE:  VeriSign has responded that - they own the RapidSSL guides that were the target of this particular problem.  They have responded that they will replace anyone's certificate free of charge that was signed using MD5.  So essentially what it means is that, if you wanted to sort of help clean up the Internet, you could install this SSL Blacklist 4.0 into Firefox from CodeFromThe70s.org.  And if you visited sites where you got a notice, what you could do is just notify the webmaster, hey, just thought you should know, you're probably going to be hearing this from more people in the future.  You can fix your certificate.  Go ask the people who issued your SSL certificate for an update signed with SHA-1.  And then you're not going to get anybody else bugging you, saying hey, you know, misunderstanding what this really means about whether their site is secure or not.



LEO:  So to clarify, it's not the root certificates that are the issue.  It's the certificates assigned to websites by root authorities that are using MD5 as their hash.



STEVE:  Correct.  Correct.  So, for example, the root certificate could be signed by SHA-1, yet they could be signing the certificates they issue with MD5, or vice versa.



LEO:  Although, as you point out, if somebody's using MD5 as a root certifier, they're probably also using MD5 for everything else.



STEVE:  Yes, yes.  And so, you know, if people had deleted those certificates, then they would be, like, way safe in the case that the same certificate algorithm was being used for the root and for the certificates being issued, which is likely the case.  But anyway, I'm annoyed that I got that wrong.  So for the record, we're fixed, and we're going to do a whole show on it next week to really explain and clarify what all this is about.



LEO:  Excellent.  Excellent.



STEVE:  Sandboxie I have mentioned was in beta with the right-dropping feature.  It's now in public release.  So anybody who is using Sandboxie may want to upgrade, I would think you would, to 3.34.  It just went public a day or two ago.  And Ronen has added the DropMyRights feature so that anything you sandbox has its rights stripped, even a little bit more thoroughly - I'm really impressed with what Ronen has done - than DropMyRights does.  So it's a really nice addition to Sandboxie so that, for example, if you're running email or your web browser, it has even fewer rights than Sandboxie had already removed from it.  He was stripping some, but he wasn't taking away admin group membership, as he is now, and doing the things that dropping the rights does.  So it's a nice update.  Many people commented to me about the YouTube video showing drive latency increase...



LEO:  Oh, yeah.



STEVE:  ...when you shout at the drives.



LEO:  That is the strangest thing ever.



STEVE:  Oh, my goodness, yes.  So I just wanted to acknowledge all the email that we received.  We've sort of referred to this before.  I've talked about how track density has grown so high in current drives that the drives are doing everything they can to stay on track using embedded servo technology, which provides constant feedback as to the position of the head.  And so it literally follows the tracks around.



LEO:  So you don't think that - you're saying this is true, that shouting at the drives really does increase latency?



STEVE:  Oh, absolutely it's true.



LEO:  It's not a scam?  It's not a joke.



STEVE:  No, no, no.



LEO:  Like the popping of popcorn with a cell phone video?



STEVE:  No, no.  It's, you know, it's low-frequency, high-energy acoustics that hits the drive and that tends to knock the head off track.  And so, I mean, it makes sense.  I can't guarantee you that - I haven't tried shouting at a drive myself.



LEO:  You could conceive of a mechanism where this really would work.



STEVE:  Oh, absolutely.  In fact, a very good friend of mine discovered that the fans in their servers, the vibration from the fans were causing the data rate from their drive to drop, from hard drives to drop, just because of the particular nature of the mechanics.  So what is happening when you shout at your drive, which I do not recommend anyone do at home...



LEO:  I shout at it all the time.  Well, I shout at the computer.  There's a drive in there.



STEVE:  Yeah, okay, right.



LEO:  If you want to shout, you want to use a high voice or a low voice?



STEVE:  A low voice will have more acoustic energy.



LEO:  So sound like this.



STEVE:  And it will interact at the right frequency with the rotation rate of the drive.  So anyway, the idea is that, when you're shouting at it, you are vibrating the drive and causing the head to have trouble staying on track.  The reason the latency increases is that the head misses looking for the beginning of the sector or goes off sector while it's trying to read.  And so the drive aborts that transfer, loses a revolution, and then tries to do it again when that sector comes back around.  So, I mean, it absolutely makes sense that shouting at your drive could cause its latency to increase, which is to say its data rate to decrease.



LEO:  It's not scared, it's just trembling.



STEVE:  So don't do that.



LEO:  Okay.



STEVE:  Also someone pointed out, and I love this, that one of my very, very favorite antique sci-fi movies of all time, "This Island Earth," don't know if you know the movie...



LEO:  I don't know that one, no.



STEVE:  I've seen it, I mean, I watch it every few years because it's just so good.  But what they pointed out was that it was a supercapacitor that was the original hook in the beginning of the plot.  And I had, you know, the moment I read this it's like, oh, my god, of course, because I know the plot really well.  But in this plot there's this scientist, Cal Meacham, who is a high-tech aerospace scientist guy.  And they get some parts from a supplier.  And they order really what they expect to be a huge capacitor.  I don't remember now what the specs - a thousand microfarads at 200 volts.  And what they receive is this little tiny bead with two connections on it.  And they're like, well, this can't be right.  But they test it, and it is what the specification calls for.  It's a supercapacitor that's, like, way smaller than it should be.  And they stick it on this machine and crank the voltage up to see at what point it breaks down.  So anyway, I got a kick out of that.  And this is, like, 1950-something.  I don't remember, like '52 or '57 or something.  I mean, it was way old.  But that was the example that they chose for demonstrating advanced alien technology.



LEO:  But that shows that the idea of the consummate supercapacitor is not anything new.



STEVE:  Correct.  Correct.



LEO:  In other words, we've hypothesized about these.  This is the first we've been able to make, is that it?



STEVE:  Well, there are a lot of people who are working on them.  It's the high-voltage claim of EEStor that is the most controversial because that's the most tantalizing.  As we know, the energy storage goes up with the square of the voltage.  So every time, if you can double the voltage, you quadruple the energy storage.  And so ultracapacitors have existed for a long time.  Normally they have been called supercapacitors because they're big.  And, for example, they're used in consumer electronics to, like, keep CMOS memory alive over time.



LEO:  Oh, okay.  Sure, okay.



STEVE:  I did want to mention that we are one week from January 15th, which is when the orders for the PDP-8 system that I mentioned last week, the single-board PDP-8 computer, are sort of informally closing.  At that point Bob's going to add them up and begin placing his orders to fulfill the kits.  So I just wanted to let our users know that, I mean our listeners know that, by the time they hear us again, which will be actually on the 15th, it'll sort of be too late.  So...



LEO:  What's the website again?



STEVE:  That was, boy, SpareTimeGizmos.com.



LEO:  Very good.



STEVE:  And extensive notes in last week's episode with links and things.  So the show notes for Episode 177.  Remember I also created a tiny URL, or a SnipURL, snipurl.com/sn177.



LEO:  Yeah.  And we apologize for not getting those in the show notes when we put it out.  But from now on we'll make sure that we give links to your show notes every time we put out our show notes.  And I'm keeping more elaborate show notes as we talk.  So we'll have better links in future.  I apologize.  That's one of the things we really want to work on is getting more - you're done a very good job of getting textual versions of the audio content out there.  And I think that's really important.



STEVE:  I know that people really love it.  In fact, I've forgotten to update the Security Now! page with the links to Elaine's transcripts for a couple days.  And people said, hey, where are the transcripts?  It's like, oh, I just forgot to update the page.  So then I just copied my copy to the server, and it was all live again.  So I know that people really do like them and rely on them.  And about three or four thousand copies are downloaded every week.



LEO:  It's kind of ironic.  I have for a long time been giving out, in speeches and stuff, saying if you do a blog, you should also do audio, you should also do video, you should do every medium.  And particularly if you do podcasts and video because Google can't search audio.  So it's really important to have textual matter that people can use, not only to get the links, but to follow along, that can be searched by Google and all that stuff.  And you've always done a good job.  I have to follow your model into our other shows because it's really the right way to go.



STEVE:  Well, it's not inexpensive.  But I'm happy to pay for Elaine's quality because, I mean, she really is a stickler for details, which I really appreciate.



LEO:  Yeah, we may have to call Elaine and say, how many shows can you do?  She might have a new career.  The podcast transcriber.



STEVE:  She would love it.  She would love it.



LEO:  Yeah, yeah.  She's really good.



STEVE:  And I have what is perhaps one of the oddest SpinRite stories in a hundred and...



LEO:  Oh, come on.  You've had some pretty odd ones.



STEVE:  I've had some pretty odd ones.  But this one may still - it's definitely up there.



LEO:  Really.



STEVE:  This is from Mike Roberts, whose subject looked rather benign.  The subject was "SpinRite recovers from burned hard drive."



LEO:  Okay.



STEVE:  So he says, "Hello.  I recently had one of my older computers fail to boot.  When attempting to start up, the motherboard would only issue a series of beeps.  I figured the first thing would be to replace each part piece by piece to determine which part was causing the problem.  But replacing each piece failed to solve the problem.  Next, I decided to move the jumper on my motherboard to clear the CMOS.  Reasonable.  As I was turning the machine back on, I accidentally dropped a screwdriver into it, and it began emitting sparks, and parts began to catch on fire.  Within seconds my power was shorted, and the entire house lost  power.  Without even thinking, I grabbed a nearby can of Mountain Dew."  He probably had been drinking too much of that.  Don't know if anyone knows, that's seriously caffeine loaded.  He says, "Without even thinking I grabbed a nearby can of Mountain Dew and splashed it on the burning computer."



LEO:  Oh, my god.



STEVE:  "I realize now that this was an electrical fire, and pouring this on earlier, before the power went out, would have been disastrous.  After turning the power back on from the basement, I went to assess the damage.  Needless to say, pretty much everything was destroyed beyond repair.  Even if it wasn't all burned and/or melted..."



LEO:  It was covered with sugar.



STEVE:  "...it was now covered in Mountain Dew.  The files on my hard drive were not critically important, but I wanted them.  I took the hard drive, pulled the melted plastic off, and wiped the stickiness and black burn marks off.  I connected the hard drive to a clip that I had pulled off an external hard drive and tried to connect it to my computers.  Neither my Windows, Mac, or Linux machines could find the drive.  So I decided to try one more thing.  I connected the drive to a computer and started up SpinRite."



LEO:  Oh, man.



STEVE:  "To my utter disbelief, SpinRite found the drive, and I ran it at level 2 for data recovery.  After SpinRite was finished, the drive was recognized by my computers, and I recovered every single file.  Thank you.  P.S.:  I love the show.  Keep it up."



LEO:  P.P.S.:  I'm going to stop drinking so much Mountain Dew.



STEVE:  Oh, goodness.



LEO:  And don't drop a screwdriver into your computer.  It's a bad idea.



STEVE:  Bad idea.



LEO:  Wow.  What a great - that is a hoot.  What a great story.



STEVE:  Thought [indiscernible] a kick out of that.



LEO:  Yeah, yeah.  The first question of the day, Mr. Steve, and it comes from someone who wishes to remain anonymous.  He's in the business of vehicular travel, wants to comment on what we talked about last week, the UltraCapacitor from EEStor:  Dear Steve and Leo, first I want to tell you Security Now! has kept me company and awake on many a long business trip.  I hope the show continues for many more episodes.  With Steve's "crack the whip" attitude about recording every week, I'm sure it will.  He says:  Regarding EEStor - which, by the way, is EEStor.com.  Not that you'll find anything there, but there is at least a website.



STEVE:  Yeah.  Actually they didn't have a website up last.  They were saying once they finally got it done, then they would have something to talk about.  But in the meantime they're just sort of keeping their head down and...



LEO:  Oh, they don't even have a site.



STEVE:  Yeah.



LEO:  Oh, well, if you Google EEStor, you'll find many sites talking about them.



STEVE:  Yes, exactly.



LEO:  Now, this guy knows what he's talking about:  I'm heavily involved in energy storage research with one of the major companies producing hybrid-electric drive trains.  You correctly pointed out in your show that energy storage is the key technology to making hybrids or pure electric cars a commercial success.  We were visited by EEStor's principles eight or nine years ago.



STEVE:  Yeah.



LEO:  The credentials of the people that started the company were very impressive.  Their product claims were fantastic, although their general method sounded plausible - first red flag, fantastic claims without any accompanying samples or test data.  We said, let us test a sample of any kind, even just a single cell, and we'd love to talk more.  They were to have something within a year.  Since that time there have been only fleeting press releases or news stories every couple of years.  I've never seen any evidence of samples or example systems.  I've discussed their claims with ultracapacitor and battery experts at a number of conferences.  Most experts have doubts about the physics associated with their claims.



There's another issue, even if they're able to produce their ultracapacitor as claimed.  You pointed out the magic of V squared as it relates to the amount of energy stored in a capacitor.  EEStor's remarkable energy density is achieved by operating it over 3,000 volts.  There are plenty of power electronics devices that operate at these voltages used by electric utilities for transmission and distribution of power.  The trouble is, these devices are very large and very expensive.  There would be huge challenges with building a power controller small enough and cheap enough that still would safely operate at these voltages in a passenger vehicle or even a large truck.



So I hate to rain on the parade, but I don't have high hopes that EEStor is going to be a game-changing solution anytime soon.  But I do have high hopes for ultracapacitors in general.  There are a number of good products out there from companies like Maxwell, NessCap, Nippon, and others.  We've used ultracaps as the only energy storage in a number of hybrid vehicles with great results.  They don't have enough energy for electric-only vehicles, but they do have nearly limitless life, as you mentioned.  Keep up the good work.  Note:  Please don't use my name or company name on the air if you use any of this in one of your programs.  My company has rather strict communications policies.



STEVE:  Not that he really said anything very controversial.  I don't disagree with any of that.  I'm just hopeful.  The patent looked like it was about as authentic as could be.  The fact that they've got this contract with the government, I mean, I don't know what it means.  Maybe that is a good thing with military aerospace applications.  And certainly the Zenn car folks in Canada are reportedly gearing up to use this.  So one presumes that these problems have been solved, and somehow they've worked out how they can deal with the 3,500 volts.  I mean, it is a challenge to - you need to step up the voltage, for example, of your charging source, which might just be 110- or 220-volt line power, up to 3,500 volts in order to get the pressure, essentially to pressurize the capacitor at that voltage.  And then you do need to be able to step it down and meter it in order to use it for your drive train.  And if you're going to use regenerative braking, which everyone wants to, you need to be able to have that step-up capability in the car also, not just in a standalone external charging station.  But if you're going to hit the brakes you want to put the momentum from the car back into the capacitor.



So anyway, I just - it looked like a great and interesting piece of work that we saw patented, and we'll keep tracking it.  If anything happens with it, I will let our listeners know.  Because there was a lot of interest in this also from our talking about it last week.



LEO:  Yeah.  I'm glad we raised the subject, anyway.  And maybe somebody else is also - I know many others are also working on this.  Maybe somebody else will come to the forefront, as well.



STEVE:  Yeah, I saw one piece of email from someone who thought I had just absolutely lost my mind, falling into the "peak oil mythology," as he called it.  And it's like, well, okay, I mean, I don't mean to get political.  I've read a bunch about it.  It makes sense to me that at some point in the not-too-distant future the world's increasing hunger, which is growing constantly, we're going to have a hard time meeting demand.  And that's all I was saying, was that at some point prices are going to start really going up because the world's going to want more than producers are going to be able to produce.  The question is, is that accurate or not?  And again, we should know in a few years.



LEO:  Well, it's not like they're making any more oil.



STEVE:  No.  I mean, no one doubts that ultimately we're going to drain the Earth of it.  No one apparently doubts that there's about two trillion barrels total, of which we've used one trillion.  The question is, are we in trouble in 200 years, or are we in trouble in five years?  So...



LEO:  Well, either way I think we should be starting to think about it.



STEVE:  Well, and see...



LEO:  I don't want to leave this problem to my grandkids.



STEVE:  From an economic standpoint, unfortunately, it's going to take energy costs increasing to make these alternative solutions economically viable.  So nothing is, as long as oil is as inexpensive as it is now.



LEO:  Right.  Daniel Farrell, a researcher at the Imperial College in London, knows a thing or two about solar cells:  Hi, Steve.  I really enjoyed your discussion of supercapacitors when listening to the latest Security Now! episode.  You also touched on solar cells.  This happens to be my area of research, and I'd be happy to discuss with you the most recent developments and concepts in the field.  Some of the current buzzwords and phrases that I hope will get you interested are:  down and up conversion of photons; multijunction, multiband, and hot carrier solar cells; and molecular and organic-based concepts.  I have just finished my Ph.D.  I now work as a solar energy researcher at Imperial College in London.  Love the show, have been listening since 2005.  You know, Ray Maxwell also got very excited about what you were talking about.  And he talked a little bit about a fusion project that's up there in Vancouver.  You know, fusion is another one of those holy grails of energy.



STEVE:  Yeah.  In fact, during my recent interest in alternative energy stuff, I took a look at the state of fusion.  There's something called, I think it's the National Ignition Lab.



LEO:  Not aptly named, I might add.  I think probably they should consider a new name for that.



STEVE:  The National Ignition Lab is out of JPL, up in Northern California.  And it's fascinating to look at it.  But it also gives you a sense for how far away we are from  having this stuff able to come online.  I'm not hopeful, unfortunately, about fusion.  The reason I wanted to add Daniel's notion, or his dialogue about solar cells, is just to have an opportunity to mention that I'm extremely hopeful about solar cell technology in the future.  It feels to me like it's sort of where digital cameras were when digital cameras first began to happen.  I remember people, as they began to happen, people were saying, gee, you think I ought to get a digital camera?  And my advice was, I said, well, if you can really use it and really need it right now, then yes.  But you need to be prepared for being really upset a year from now...



LEO:  When something better comes along, yeah.



STEVE:  Right.  I mean, remember the dramatic, I mean, look at the dramatic cost and performance curve that digital cameras went through over the last 10 years.  I mean, they just got incredibly inexpensive.  The battery life shot up, resolution shot up, I mean, it's just transformative.  As opposed to, for example, a mature technology like existing chemical SLR photography, which is just - it was done.  My sense is that we are sort of in the same place with solar cell technology, that once we really bear down on this, we're going to see costs drop and efficiencies increase, which will be really significant for the alternative energy future.



LEO:  Yeah, yeah.  Look, this is all-important stuff, and it's something that's going to be on people's minds and in the newspapers and the news for the next many years, I think.  So it's good that people like Daniel are out there studying it, doing what they can.



James Ortega, in Kokomo, Indiana, needs some YubiKey router configuration clarification:  Steve, you mentioned in your show, Episode 177, that you use the YubiKey to secure your router.  I've contacted their technical support for instruction on how to do this.  Still no response from them so far.  Can you demonstrate on your show how to perform the password generation and authentication of the passwords with the router?  Thanks.



STEVE:  Well, there has been a lot of interest in this notion that I mentioned that Stina has shared with me of the ability to switch the YubiKey from its normal mode, which is a one-time password system based on a secret AES key buried in the YubiKey.  The personalization tool, which is available for free download from Yubico's site, it's able to change the key so that, instead of giving a different password every time, based on a secure cryptographic algorithm, it spits out a fixed, random-looking and certainly randomly generated or pseudorandomly generated once, a fixed long character string.  The beauty of that is that it allows a simple little hardware token to produce a string of gibberish that you just can't memorize when you look at it.  I mean, you can't even type it in, probably, unless you really tried.  And so that can be used anywhere, at any time, in place of a shorter password that might be vulnerable to dictionary attack or guessing or somebody glancing at it and writing it down and so forth.



So the one way that I mentioned of using it where it is in use now is that it could be used as the preboot authentication password by TrueCrypt.  So you have this on your keychain, and you type that in, you use the YubiKey to enter that into TrueCrypt in order to authenticate that, you know, something you have, one type of authentication, as you log into and start up a TrueCrypt whole-drive encryption volume.  Or even to use it as the password inside Windows if you want to mount a TrueCrypt volume.



Well, another way it can be used that we talked about is as a WiFi AES encryption key for WPA2, as it's called.  But it's actually, you know, the AES cipher.  In that case, and this is what James is asking about, it's not that you're using the YubiKey to secure your router, but rather your router's WiFi radio.  And so the idea would be you convert the YubiKey, first using Yubico's personalization tool, into this fixed static random gibberish.  You then use that when your router is - when you're setting up WiFi, and it asks you for your WPA key, you would put the cursor in the field, touch the YubiKey button, and it would type that into the router.  Then it would ask for you again, so you type it in again.  Now you've set up your router with its WPA key from your YubiKey.  Then you go to your various machines and enter those.  And the advantage, of course, is that it's - you don't have to do any typing.  It's incredibly difficult to reproduce or manage.  And if a friend came over and wants to get on your WiFi, you can just stick the key in, touch the button when their Windows is prompting them for the WiFi key, and it's entered.  So it's a neat solution.



LEO:  Very cool.



STEVE:  And a lot of people love the idea.  So there was a strong response that I saw in feedback responses from talking about that, too.  I think that it makes a lot of sense to a lot of people just to have something that they can touch, and it zaps out a really long pseudorandom string which is the same every time.



LEO:  And we'll see an even better idea in just a little bit.



STEVE:  Yup.



LEO:  Coming up.  Mack, I'm sorry, Mike Gillmore in Cedar Rapids, Iowa has a question about Microsoft's Malicious Software Removal Tool:  Hey, guys.  As I was listening to my show, the show 177 last week, something you said took me by surprise.  You reported that the MSRT ran only at startup.  For some reason I thought it ran actively, like an antivirus.  This makes it sound like perhaps I should be booting each of my eight machines every day.  Is that right?  Nope, not a business, I'm just a really big geek.  Eight machines.  Thanks for SpinRite, ShieldsUP!, Wizmo, and other great tools.  Mike.



STEVE:  Actually it's a little worse than that.  The MSRT runs once a month, when you restart your system after Microsoft has given you a new version.



LEO:  So it only runs when there's an update.



STEVE:  Right.  Well, exactly.  And the idea is that, monthly, Microsoft is maturing the tool to add awareness and removability of new malware.  The one that they just released added two new programs.  And on the MSRT site they've got a list, for example, of all the stuff that it knows about and is able to remove.  So what Microsoft is doing is essentially they're adding awareness of new problems that they encounter to this tool, and then running it once just to remove any that may be on the system, or that your system may have acquired in the intervening month.  So they're not trying to be running all the time like an antivirus system.  There is a tool that you can run on demand, a version of this that you can get from Microsoft from the MSRT region of their site.  And so that is an option that Mike has if he really wants to run this all the time.  But my sense is that AVG, which is updating themselves all the time and which is running constantly, is probably doing the job for him just as well.



LEO:  Okay.  Yeah, so I guess Microsoft didn't want to add to the complexity of machines by having it running all the time as an antivirus does.



STEVE:  And I think they probably don't want to stomp on the AV industry, either.



LEO:  Right, right.  It's not - in other words, it's not an antivirus, folks.  It's just every once in a while we're going to check and see if there's anything really disgusting going on.



STEVE:  Microsoft's site does say that they explicitly update this monthly.  So I think we can assume we're going to get a new one every month.



LEO:  And the only issue is you may be getting, in between the updates, you may be getting some spyware on your system.  Right?



STEVE:  Exactly.



LEO:  It ain't going to find it any sooner.  So that's just another reason to have some other antimalware software on there.



Elliott Kopp in St. Louis is worried about why Steve dislikes AT&T.  I didn't know you disliked AT&T.  Steve and Leo, I was listening to 175 the other day; I'm a little behind.  You mentioned you didn't like AT&T.  I use them as my landline and Internet provider because they're the cheapest in my area.  I'm not aware of them doing anything wrong, traffic filtering or logging or so on.  I'd love to hear your thoughts as to why you don't like them.  If they're doing something naughty, I will switch immediately.  Well, I'm an AT&T - I have my home service is AT&T.  I don't - that's the local carrier.



STEVE:  Right.  I thought that I ought to clarify this because I have spoken ill of AT&T.  But it's only that their broadband technology was not up to speed as soon as Verizon and Sprint's was.  They were using Edge technology for broadband; whereas EVDO, which was available over with Verizon and Sprint, was much faster by, like, more than a factor...



LEO:  Oh, I see.  So you're talking about the 3G, the wireless speeds.



STEVE:  Exactly.  That's all it is.  Nothing to do with their behavior or traffic filtering or logging or anything else.  It's just that, in fact, I was over on Cingular, which of course AT&T acquired.  And I deliberately left Cingular and moved to Verizon because I wanted the EVDO broadband speed.



LEO:  Right, right.  I think Sprint and Verizon are still the fastest.  AT&T's new HSDPA is okay.  It's not as fast, I don't think.  And it's not in as many markets.  But if you're using an iPhone, as I do, you don't have any choice.



STEVE:  I was going to say.  And it's one of the reasons that the iPhone has been criticized is that its wireless, its broadband is just not as fast as you can get over on Verizon and Sprint.



LEO:  The story was Apple approached Verizon and got turned down.



STEVE:  Ugh.



LEO:  So there you go.  And Verizon is probably going "ugh," too, because the iPhone has sold a few.  They've sold a few.



STEVE:  Yeah.  Yeah.



LEO:  Burt in Redford, Michigan keeps wanting to install the ill-fated Windows Service Pack 3.  This is for Windows XP.  Thank you for supplying a venue that allows the common Joe - Joe the hacker - to get an answer to a question no one else seems to have an answer for.  I brag about you all the time.  Question:  What is going on with Windows XP SP3?  Like you, I have attempted to install it, in my case on different systems.  They both bombed.  I had to back out of the update.  Can you mention what Microsoft is or is not doing to make this usable, even if no news is available?  I feel like my systems are vulnerable without this update, but I'm helpless.  I can't do anything about it.



STEVE:  Yes.  I've looked around.  I can't find any indication from Microsoft that they're going to address this.  This is the last service pack for XP.  There's not going to be a Service Pack 4, unless maybe they do one to fix the problem with Service Pack 3.  But I'm in the same condition that Burt is.  There are several machines I have where I cannot put SP3 on.  The good news is that you really don't need it.  You can keep current with the patches.  All SP3 was was sort of a catch-up, an omnibus package that did all of the prior updates bundled in one.



LEO:  Yeah.  I wonder what's going on.  I've been able to install Service Pack 3 on all my machines.  Well, I only have one XP machine, but - no, two.  I have two XP machines, and both are running SP3.  But I do get this call a lot on the radio show.  And there's no - doesn't seem to be any answer.  It's just...



STEVE:  And Microsoft never, like, fixes broken service packs.  They just sort of limp along and then replace it ultimately.  But this one, as far as I know, is not going to be replaced.



LEO:  Remember Service Pack 2 was even worse.  At least it seems in most cases with Service Pack 3 it doesn't - Service Pack 2 would just give you a Blue Screen of Death, permanent Blue Screen of Death.  You'd be out of luck.  At least with Service Pack 3 you can roll back.  But he's right, he needs the update for security reasons; right?



STEVE:  Well, no.  I mean, Microsoft has moved forward.  And so you need to say no, I do not want SP3.  But then there's still...



LEO:  Oh, and then - okay.



STEVE:  Yeah, you don't need Service Pack 3.  You can still install all the other incremental updates moving forward.



LEO:  I get it.  Okay.  So you'll be as secure.



STEVE:  Yes, you will.



LEO:  Okay.  I wanted to mention, I should have mentioned it in the security news, but it's relevant that Twitter - I don't know if you know this - Twitter got hacked.  In fact, Twitter's been the subject of a series of attacks lately.  There was a phishing attack where somebody's account got hacked, and they were sending out direct messages to everybody they knew saying, hey, have you seen this funny site about you?  And when you click the link, you get a login page that looks just like a request for your regular Twitter credentials.



STEVE:  Uh-oh.



LEO:  And then people of course don't look at the URL and get phished.  I didn't fall for that.  I did get the direct message, but I didn't fall for that.  I know better than that.  I look at the URL.  And then but there was a much more serious hack a couple of days ago, and I got - I did get bit by that.  A kid on the East Coast, he's 18 years old, he admits it - in fact there was an interview today with Wired magazine, or Wired News - used a brute force attack on an admin account.  He had written his little tool that goes to the dictionary and tries every dictionary word as a password.  An administrator at Twitter, Crystal, her password was "happiness."



STEVE:  Oh, goodness.



LEO:  Kid went to bed.  He didn't really know what Twitter was.  He went to bed, woke up in the morning, he had access to Crystal's account.  Now, he said I don't know what to do with it, so he went to a hacker forum and said, hey, anybody who wants access to Twitter and wants to change some passwords, go ahead, send me a note.  Well, whose account would you like?  Barack Obama was the first, of course.  Fox News.  Rick Sanchez from CNN.  Britney Spears.  So he gave these - he gave the credentials to these people.  They logged in as Britney Spears, for instance, and put a lewd message up.  Obama, everybody.  Twitter caught onto it pretty quickly and deleted the bad messages and has reset the passwords.  I lost access to my account, but I don't think anybody posted on it.  I guess I was one of the people that the kids on the forum wanted access to, but they didn't - thank you for not putting anything stupid up there.  And it wasn't till later in the day that I was able to get a hold of Twitter.  And Crystal actually said sorry about that, here's a new password for you.  But it just shows you, there were two things that they did wrong.  One was that they had an admin who had a bad password, that dictionary word password.  The other was they didn't have a timeout.  You could continue to enter passwords until you got in.  So his brute force tool had no barriers to continuing to hit at it.  Terrible.  I hope they pay a little more attention to security in the future.



STEVE:  Well, it's the sort of thing, too, that, I mean, Twitter began life not being that big a deal, and look what's happened.  I mean, it's become a really big deal.



LEO:  Right.  And I think that's what happened is the kid who broke in said I didn't really know what it was.  I never heard of Twitter.  I just - I got in, I thought, oh, well, no big deal.  What are they going to - who is, you know - he had no idea what a big deal it was.



STEVE:  Right.



LEO:  Apparently the Obama campaign did contact the Twitter management quite rapidly, saying, uh, guys?



STEVE:  We've got to fix this now, yeah.



LEO:  Yeah.  And you have to wonder if somebody like Obama will be on a site like Twitter again, given the risk inherent.



Guillermo Garcia in Santiago, Chile doesn't want to give up and reformat.  He says:  Hi, I'm a long-time listener and a fan of the netcast.  Currently I'm standing up a date, to date with past episodes.  I'm sorry.  Currently I'm getting up to date with past episodes.  I just listened to Episode 172 about Sandboxie.  That made me wonder if there really is anything to do when you get malware on your computer.  Sandboxie prevented this, but what about systems that are already compromised?



I was listening to Leo on another one of his shows some weeks ago talking about how difficult it is to clean a system after it gets infected.  I agree.  I'm an IT person.  I've been working with computers since my first 8088 many years back.  I have some tools that I normally use when my informal clients, family and friends, get in trouble.  But after all you've said I get the impression it's futile.  Maybe Steve could comment on his tools and procedures for an effective cleanup.  I mean, apart from the obvious but normally painful completely system format and reload, is there anything else I could do?  Thanks for the excellent show.  Please keep it coming.  I'm glad he asked this.  I want to ask this because...



STEVE:  Yeah.  And the answer is no.



LEO:  I got a call on the radio show last weekend from a guy who says I fix computers all the time, and I have tools.  He's recommended a website with some tools.  And he says I'm always able to get rid of everything.



STEVE:  He really did say that, huh.



LEO:  He thought he was.  I think it's a kind of arrogance or cockiness on his part, to be honest with you.



STEVE:  Yeah, I think so, too.  I mean, as we've talked about this, I wanted to sort of reiterate.  It's why I chose Guillermo's question is I've heard you, Leo, on the radio show, tell people what I tell people, what I believe, is that it is becoming really increasingly difficult to get rid of these things.  They are - there is so much technology now that is being brought to bear to make these tools impossible to find and impossible to root out, that there just isn't any sort of like a blanket solution.



LEO:  Well, one of the things these guys do, they attach themselves to system files.  So if you were to remove it, you're now deleting the system file.  So now you have to make sure to repair the system file.  If you can.  It's just - it seems to me that there's two reasons.  One is you'll spend - you could spend a lot of time trying to find everything, more time than it would take to just start over.  Two...



STEVE:  And you'd never know.



LEO:  You can never be sure, exactly.



STEVE:  You could never be sure.  What I tell people is pull all your documents and files off, and then start again.  And then put them all back on.



LEO:  This has an advantage.  It takes time, but it has an advantage.  You've got a good backup.



STEVE:  Yes.  And you also end up with a happier system.  I mean, we all know that Windows systems sort of get corrupted over time.  They just kind of get old.  And so anytime you can start over and start fresh, you're not installing software that you installed once, but you never ended up using.  It's sort of a chance to do some housecleaning.  I mean, you might not choose to have spent your time that way.  But I know of really nothing else you can do to be sure.  I mean, these things now are so pernicious that they're just - there isn't a way to know that you got rid of everything.  And so often we see examples of them popping back, that they appear after a few weeks of sort of going silent.



LEO:  Plus I think that you are impacting the stability of your system long term because you've pulled things out, you've torn things out.  You don't know what kind of impact that's going to have.  And I just feel like your system's going to run better.  You're going to be sure you got rid of everything.  You're going to have a good backup.  It's just healthful to do this.



STEVE:  Well, and I've also heard you talking about various imaging tools.  We like Drive Snapshot.



LEO:  Yeah, really great.



STEVE:  And to make a snapshot, then you've got your system in an easily recoverable mode that you can restore, and then do backups from that.  So, I mean, there are now tools.  And it's not like a second hard drive is that expensive any longer.



LEO:  Right, right.  Yeah, every time I install Windows in a new machine I make an image with Drive Snapshot.  Then I make an image of all the applications that are installed.  I get all the drivers, all the updates, so it's just nice.  And that can be restored in 10 minutes.



STEVE:  Exactly.



LEO:  Then you just restore your data.  I mean, that's not a big deal.  As long as you keep that snapshot up to date, I think that that's not a big deal.



STEVE:  Yup.



LEO:  Jason's driving to Dallas.  He's listening to our show, typing from an iPhone.  This guy had to get this question in.  He says:  I'm listening to your latest Security Now! about SSL and MD5 being broken.  It brought up a few questions.  I thought, oh, no, as I'm currently using TrueCrypt on my laptop.  I'm pretty sure I chose AES, but I'm not so sure.  What does this mean for my whole drive encryption?  Even if I chose AES, does TrueCrypt use an MD5 hash to help encrypt my drive?  Do I need to reencrypt my drive?  Is this vulnerability going to impact TrueCrypt?



STEVE:  No.



LEO:  Yay.



STEVE:  Yay.  Yes.  AES is completely separate from MD5 and SSL and SHA-1 and all that.  TrueCrypt just uses, I mean, TrueCrypt may in fact be using hashing internally to verify integrity of things.  I wouldn't be at all surprised.  But in no way does this mean you have a vulnerability because AES is so far completely unscathed in all of this sort of security research.



LEO:  So it's related somehow?  So that - is that why he was concerned?



STEVE:  No, I think it's just because he was - I think probably Jason is, when he's not typing on his iPhone driving to work, he's using TrueCrypt, and that's sort of his interaction with crypto stuff is through TrueCrypt.  And so he was just wondering is there any impact on...



LEO:  Other crypto.



STEVE:  ...his TrueCrypt encryption and anything else.  And there is none.



LEO:  Yeah.  Jared Burford in Australia can't locate PayPal's one-time credit cards.  I had that same problem, Jared.  It was hard to find.  But there may be another reason.  He says:  Hi, guys.  I like the idea of using PayPal's one-time credit card number, but I'm not sure if it's worldwide.  I checked at PayPal.com.au, but I couldn't find it.  Is it only available in the U.S. and Canada?  I currently have my savings set up for PayPal payments because I hate giving my credit card details to anyone, let alone to PayPal.  But the use of this one-time pass might change my mind.  Maybe I'm missing something.  I had a hard time finding it.



STEVE:  Yes.  And I think that's a problem.  Unfortunately, it's sequestered under the main menu as "Plug-in."  And so it's - they don't have, I mean, it's really dumb.  I don't know why, but that's where it is.  It's because it's sort of related to their plug-in, their browser plug-in.



LEO:  But [indiscernible].



STEVE:  Yeah.  So on the main menu you go to "Plug-in," and then you don't need the plug-in.  You don't need to use or install the plug-in or anything because that's where then you can use the browser interface to create a one-time credit card number.  So I wanted to let everyone know that's where they've hidden it.  And it's unfortunate that they've hidden it because it's a super nice and useful feature.  I don't know whether it's available worldwide.  I assume it is.  I can't imagine why it wouldn't be.  But that's where it is located, Jared.  So try taking a look under "Plug-in," and I'll bet you do find it.



LEO:  Yeah.  I mean, these are the kinds of things that maybe there are different features in the world.  For instance, that football's not available worldwide, so...



STEVE:  Exactly. 



LEO:  Michael Kean, in Black Mountain, Australia - also from Australia - echoes the Hamachi death cries of many [simulating Hamachi death cry]:  Hi, Steve.  For the last three weeks, up until two days ago, Hamachi's mediation logon servers have seemed to be more down than up.  They got sold to a company called LogMeIn.



STEVE:  Right.



LEO:  Making it extremely frustrating and mildly embarrassing to use.  See their forums for more.  I thought I'd stumbled onto a good thing with Wippien, another similar program.  Turns out to be particularly unstable.  I could never work out why.  Even four PCs on my own LAN would pop in and out for a smoke whenever they felt like it before hanging with 100 percent CPU two days later.  So please keep thinking about CryptoLink.  The world needs it almost like they needed SpinRite.



STEVE:  Well, I just - I'm absolutely - CryptoLink is the next thing I'm going to do, once I get caught up with my current little backlog of projects.  And I did want to mention that, because we did such a job of putting Hamachi on the map, unfortunately we may have been indirectly responsible for Hamachi's demise because Alex, who wrote Hamachi, sold it to LogMeIn.  And unfortunately it's been having increasing problems ever since.  They've changed the drivers, they've destabilized it, they've broken things.  The server Hamachi depends upon tends to be unreliable.  My own tech support guy, Greg, used to use Hamachi all the time and loved it, but began having more and more problems with it and has begun giving up on it.  So for what it's worth, CryptoLink will be designed not to need any sort of third-party support like this, specifically for this reason.  Because robustness and the ability to really get a connection all the time is one of my main focuses.  So I'm definitely going to move forward on CryptoLink posthaste.



LEO:  I'm happy for Alex.  I'm glad he made some money off of it.  But it's too bad that LogMeIn just can't seem to keep it going.  Hamachi, we should explain, is kind of a virtual networking solution.  But it does require a third-party, well, you can set up a Hamachi server of your own; right?  Or does it need that intermediate third-party server?



STEVE:  I don't remember now.  Of course it came up, but I think that Alex had not made it public at the time.  And I don't think so now.



LEO:  Oh, okay.  So you have to use this third-party server to use Hamachi so the two machines could talk together.  And if that server is down, you don't get a connection.



STEVE:  Right.



LEO:  Ben Franklin - I'm sorry.  Brian Franklin - Ben's brother - in Mesa, Arizona brings us this week's Brilliantly Obvious in Retrospect Idea of the Week.  It's another YubiKey idea.  Hi, Steve.  On Security Now! Episode 176 you mentioned how the YubiKey can now be configured to spit out a static password for use with TrueCrypt - or as we mentioned earlier, with a WPA key, for instance.



STEVE:  Right.



LEO:  However, if you only used the YubiKey's password, this would essentially be single-factor authentication.  In this case, something you have, the YubiKey; right?  It'd probably be worth noting you should use the YubiKey's static password as a supplement to your own password.  For example, type your own memorized password.  Then use the YubiKey to append to what you already have.  Oh, that way you've typed - just like the PayPal.



STEVE:  Isn't that perfect?



LEO:  That's a great idea.  So on PayPal I enter my text password, and then I append to it the six-digit code that comes off the football.  You could do the same with the YubiKey.  This way you both get something you know, as well as something you have, which would be next to impossible to know.  I've been listening since Episode 1.  Keep up the great work.  I look forward to the release of your VPN and DNS utilities.  And actually, if you're doing it for a router, you're already doing that because to get into the router's administration interface you have to know a password, and then you would use the YubiKey.  So that's two factor on a router.



STEVE:  Correct.  Correct.  But in an instance, for example, like TrueCrypt, where they simply want a passphrase...



LEO:  Right, much better...



STEVE:  ...the idea of adding your own stuff, either before or after you touch the YubiKey, I mean, that's perfect.  It gives you two-factor authentication.  That way somebody who gets your keys doesn't have access to your computer.  Otherwise they would because they'd get everything they need to from your YubiKey.  But this way you type your own little secret phrase, which no longer has to be incredibly long and complex because you're able to rely on the YubiKey to repeat the incredibly long and complex gibberish every single time.



LEO:  Right.  I just love that.  I use - I told you my bank does that, Bank of America does that.  They send a key to my cell phone, so I need my password and that key.  I just love that.  If Twitter had used something like that, none of this would have happened.



STEVE:  Right.



LEO:  [Groaning]  Everybody should get Yubico.  And here's another YubiKey from Sean M. Taffert in Montreal.  He has a lot of love to go around, apparently.  He offers the PayPal Solution of the Week:  Steve, let me start by saying thank you for just being you.  I love Security Now!.  I've been computing for 25-plus years.  I'm always eager to listen to your podcasts every Thursday and to glean that little morsel of techno cool from every episode.  I can't thank you enough for telling me about the YubiKey.  Not only is it a great security gadget, they have to be the bestest tech support team ever.  I had a small issue.  They responded immediately, proposed a good solution, even gave me something to offset the trouble I was having.  They were polite, to the point, and did I say this already, they have real people.  I love Yubico.  It's because they're Swedes.  right?  I just think they're nice people.



This all leads me to my actual point.  I believe I've found a solution to the PayPal "I don't have my football" login security issue.  We talked about this the other day.  As you pointed out on one of your shows, the silly questions they ask are really not a great way to go around the fact you don't have your security token.  In fact, they really open a big security hole.  They eliminate really the value that you've gained from the token, I think.



STEVE:  Yes.



LEO:  So I devised a scheme where you can select any of the lame-o questions they have listed.  But instead of using correct answers or even incorrect answers, I use my YubiKey static password.  This way nobody will ever guess the answer, and I can always change it once I get my football back from where I left it. Of course, if you lose your YubiKey, then you're really in trouble.  Please pass this on to all of your listeners as a little extra secure way to use PayPal.  And tell Leo I love him, too, but not in that way.  Not in the way he loves you, apparently.



STEVE:  So I thought that was another good idea.



LEO:  Yeah.



STEVE:  If they want to know your mother's maiden name, just have Yubico tell them, and god help them guessing that.



LEO:  It really is - I love this YubiKey thing.  It's just really cool.



STEVE:  Yup.



LEO:  Really, really cool.  Steve, we've come to the end of a great 12 questions.  Boy, we have listeners that just - I love doing a show where the people who listen are thinking while they're listening.  I mean, they really are thinking hard.



STEVE:  While they're driving and typing with one hand.



LEO:  Yeah, whether it's to catch us out or to understand it better.  I just think that's so cool.



STEVE:  Yup.  I want to encourage people and remind people, I really do, we really do need and love their feedback, which they can provide at GRC.com/feedback.



LEO:  Yes.  Yes, absolutely.  We also encourage you to go to GRC.com in general because of course that's the place where you get SpinRite, the world's best hard drive maintenance and recovery utility, a must-have for anybody.  If you've got a hard drive, you ought to have SpinRite, as well.  And by the way, than you for sending a key along, was it to Ryan Shrout?  Who was it needed a key?



STEVE:  No, I sent a copy of SpinRite to Paul because he was having a problem.



LEO:  Paul Thurrott, that's right.



STEVE:  Yeah.



LEO:  Very kind of you.  That's really nice.



STEVE:  Happy to.



LEO:  I'm sure Paul appreciates it.  We'll talk about it tomorrow.



STEVE:  Yeah.



LEO:  Also there you'll find the show, the show notes, the transcriptions, the 16KB versions of the show, all of that stuff, GRC.com/securitynow.  And when you're there, browse around Steve's free stuff.  There's ShieldsUP! to test your router.  There's Wizmo, that little gadget.  I started recommending that on the radio show, Steve, because we get a lot of callers who say I can't get Windows to shut down.



STEVE:  Yes.



LEO:  And that question we had a couple weeks ago, where the guy said, well, Wizmo did it, not only with the "shut down, dang it" command, but it fixed it permanently.  I thought that was great.



STEVE:  Yeah.



LEO:  So that's a great tool to have.  And a lot of good security stuff.



STEVE:  I'm working right now on a DNS benchmark.  I developed it actually back in '02, back when I was doing that experimentation with DNS.  And it never went public.  It was called DNSRU, DNS Research Utility I called it.  And it's been like the secret favorite of a whole bunch of people in our newsgroups ever since.  I mean, they, like, they keep using it even though it expired, and you have to hold both shift keys down when you start it in order to get around my little not-ready-for-primetime expiration timeout.  Anyway, as part of this final DNS work that I've been doing, I decided we need to bring that back to life because so many people like it.  So I should have another new utility here before long.



LEO:  Well, thank you.  I think it would be great to have a page of people submitting their - we'll do it in the forums - submitting their benchmarks for different DNS servers.  We recommend OpenDNS.  But compare it to your Internet service provider's DNS because, I mean, having a fast DNS server really speeds up your browsing.  It's a good thing to have.



STEVE:  It really makes a difference.  And so for example we've been talking about OpenDNS.  The question is, based on where you're located, are your ISP servers providing you results faster than OpenDNS?  And I developed a bunch of technology where, for example, I'm able to independently show the cached versus uncached performance of DNS servers by server.



LEO:  Wow.



STEVE:  And as far as I know, no one's ever really done a benchmark.  So this'll be a cool little bit, new, a piece of new freeware from GRC.



LEO:  Very neato.



STEVE:  Yeah.  Next week we are going to have a great, I promise a fantastic episode, delving into the intricacies and exactly how this whole certificate chain system operates, so that if people listen, they will come away really getting it and finally not being more confused than when they started.



LEO:  That I want to hear.  But I guess I will.  Because I never miss an episode.  Steve Gibson, thanks for joining us.  Great to see you.  We'll see you next week on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#179

DATE:		January 15, 2009

TITLE:		Cracking Security Certificates

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-179.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo delve into the detailed inner workings of security certificates upon which the Internet depends for establishing the identity of users, websites, and other remote entities.  After establishing how certificates perform these functions, Steve describes how a team of security researchers successfully cracked this "uncrackable" security to create fraudulent identifications.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 179 for January 15, 2009:  Cracking Security Certificates.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show where we cover all things secure.  Like your security blanket, your binky?  No, no, no, Internet security, online security, privacy.  And here he is, the man who knows it all, Mr. Steve Gibson.  And if he doesn't know it, he'll find out.



STEVE GIBSON:  I don't think I know what a binky is.  So right off the bat I don't think I'm quite up to speed on this, Leo.



LEO:  You don't have kids.  If you had kids, you'd know a binky is one of those little pacifiers that kids suck to make them feel secure.



STEVE:  Oh.  Well, you're right.



LEO:  But you're...



STEVE:  I hope your kids, which are now teenagers...



LEO:  No longer, no.



STEVE:  ...no longer are binky enabled.



LEO:  No, no binkies anymore.  So it's good to talk to you.  You know, since we talked last I've been exhausted because I did Macworld Expo, and then of course CES.  And this is traditionally the week of the year that most of the tech industry collapses in a puddle.



STEVE:  Well, you did CES by remote control.



LEO:  I know.



STEVE:  The way most people want to do it, is you basically interviewed people who had actually been there on the floor.



LEO:  It was so much easier.



STEVE:  Yeah.  And it was neat that you had LeVar Burton on.  That's, you know, Geordi La Forge from "Star Trek:  Next Generation."



LEO:  Oh, man.  You know, I was a little reluctant because I don't want to put celebrities on just because they're celebrities.  But LeVar is a complete geek.  He knew, you know, he was completely up to date on all that stuff.  I told him, LeVar, you could come on as many times, any time you want.  He says yes.  And we have some interesting ideas of things we might want to do with LeVar.  So, yeah, he's great.  Wasn't he fun?  He was just really a neat guy.



STEVE:  Really a good show, yeah.



LEO:  Thank you.  So what are we covering today on the program?



STEVE:  Today the title of the show is Cracking Security Certificates.  As I promised, I want to explain, really for the first time ever.  We've talked about security certificates in passing many times.  But I've never gone through the process sort of step by step of what someone does to get one, how they're created, how they're signed, what it really is that a security certificate does for us.  So I want to really lay a foundation of understanding of how they work.  And then we're going to talk about some detailed operations of the MD5 hash, which is damaged to this point beyond recovery, and how these incredibly clever security researchers used this broken MD5 hash to create their own fraudulent certificate.  So this will be high up on the propellerhead scale, but I think very accessible and really interesting for our listeners.



LEO:  Security certificates are really a fundamental technology on the Internet.  I mean, there is no...



STEVE:  Oh, yeah.  I mean, more so all the time.  They give us both the ability to encrypt our traffic; but, more importantly, our browser is making sure that the certificate it is given by a website when it connects to it over a channel that it wants to be secure, there's an authentication process that happens invisibly underneath the - sort of like behind the scenes so that it's easy to take for granted.  But that's always happening.  And sometimes users may see their browser note a problem.  For example, it's surprising, some sites forget about the expiration of their certificates.  And you'll connect to a site, and you'll get a pop-up notifying you that this security certificate of whatever site you're trying to go to has expired.  And you can typically look at the certificate, and you may notice that it, like, expired yesterday.



And so you can imagine that they're getting lots of people complaining that, hey, did you realize your server certificate has expired?  And in fact they're probably already scrambling, trying to get a new certificate reissued while this notice is popping up and, like, no one's trusting their site.  So there's this mechanism going on in the background which we all depend upon to an increasing degree because of course we depend upon the Internet and the Internet's security to an increasing degree.



LEO:  Yeah, yeah.  Microsoft, I remember when Microsoft wanted to use certificates for security for ActiveX that it was a little bit controversial.



STEVE:  Well, yeah, because you need to pay somebody in order to get one.  The idea is that - and we're going to discuss this in detail.  There is an implied trust at some level within the certificate structure.  That is, you know, for example, VeriSign is generally the company I get mine from, although I used GoDaddy this summer when I was messing around with a wildcard certificate because they were so much less expensive.  But the point is none of them are free because, in return for getting the certificate, you have to go through some procedure to prove you are who you say you are.  They are supposed to, in turn, verify that information, make sure that this is coming from Gibson Research Corporation.  I mean, they check our Dun & Bradstreet number, they place phone calls to phone numbers that are known to be associated with Gibson Research that come from sources other than us saying, oh, here, call this number.  So they independently verify as much information as they can, really as a function of how secure you want this to be.  So they want to get paid in return for doing all that.  And that's sort of the ecosystem that we have for certificates.



Now, people have been upset by that because they've said, hey, wait a minute, why do I have to get my ActiveX control signed?  That means I have to pay someone in order to be able to sign my ActiveX controls.  And in fact, for example, Microsoft calls this Authenticode, and I now have an Authenticode certificate.  I need to purchase it every, I think it's every two or three years.  I just checked recently because I'll be doing some work with signed EXEs in the future.  But, for example, the most recent little piece of freeware I did, Securable, is a signed executable.  And so it prevents some of the pop-ups that you get, for example, under Vista when you try to run something that you downloaded from the Internet.  It's able, instead of saying we don't know who this software is from, good luck - actually it says do you want to run this anyway.  Instead it'll pop up and say, hey, this is from Gibson Research Corporation.  Do you want to run this?  But so the environment, Windows, the operating system, the Mac, whatever, is able to assert who this software is from because the executable itself contains a certificate that binds our identity information to the executable.



LEO:  You know, I also think that maybe some people don't really trust this chain of trust notion so much.



STEVE:  Well, exactly.  I mean, remember, I mean, I was the one who first, when I looked several years ago at the number of root authorities in my browser - I hadn't looked for years.  And there used to be a handful.  And in the meantime there had been this explosion of root authorities.  And my immediate concern was, whoa...



LEO:  Who are these people?  Who is this Hong Kong Post Office?



STEVE:  Yeah.  The more you have - essentially what that means is that any certificates signed by any of these people will implicitly be trusted by our browser.  So no warning, no pop-up, no notification, nothing.



LEO:  And that was the issue.



STEVE:  The browser just goes right on ahead without - assuming that everything is legitimate.  And so in the case of this cracked certificate that we talked about a couple weeks ago, it was a valid, solid certificate authority that was issuing the certificates.  There were a number of things that they were doing that were insecure, even aside from the fact that they were signing their certificate with MD5, which is what we'll talk about.  But inherently, just the law of numbers, the more people you're trusting, the greater chance there is for one of them to be mistrustful.



LEO:  Right, right.  Okay.  Well, we're going to talk about that, how it works and what's been going on with these cracking techniques.  Before we do that, any news in the world of security?  Errata from last week?



STEVE:  Oh, we've always got some news because we've always got Microsoft and Windows in the picture.



LEO:  There's always something.



STEVE:  Always something happening.  So we are past our second Tuesday.  That was a few days ago.  And there was a January release, a small one actually in terms of number of problems.  There was only one problem that Microsoft released a patch for.  However, it's potentially significant.  It is in the Windows filesharing protocol, that so-called SMB, the Service Message Blocks.  And it unfortunately is a remote code execution flaw.  It affects all currently supported versions of Windows at the critical level, that is, a critical remote code execution, except Vista and Server 2008.  Those guys are only affected to a moderate level because there's a somewhat lesser exploit against them, not something that Microsoft wants to grade as critical.  But for any people using any versions of XP, both 32- and 64-bit, and also Windows 2000 before that, this is a problem.



The exploit comes in over ports 139 and 445, which are the standard Windows filesharing and many other services ports.  The good news is anybody with a router is blocking that by default.  Anybody with a personal firewall is blocking that almost certainly.  And even many ISPs are blocking those for us.  Now, that doesn't prevent, for example, behind an ISP.  ISPs' own customers might be able to infect each other.  And similarly, computers within an organization are all behind the corporate firewall.  If there was a policy of sharing those ports within an Intranet, within a corporation, then you've got the possibility that something could infect one machine, and it could spread using this remote code execution exploit.



And in fact we are seeing something like that.  There was a report that companies that had, that is, corporate entities that had not applied that out-of-cycle October patch from late last year, that they were getting infected by worms that were using that exploit.  So we've seen this problem where companies are less willing to upgrade, that is, their IT staffs really want to vet these changes before they turn them loose on the whole infrastructure.  That introduces an implementation delay in patching these problems.  And some companies are being bit by the fact that they're not doing it immediately.  So the word to end users, our listeners, typically, is get these things fixed as quickly as possible.  It's annoying, for me at least, to have to reboot my system in order to get these patches operating down in the code.  But it's something you don't want to hold off doing for too long.



So Microsoft had that happen.  And of course we also got a new version of the MSRT, the Malicious Software Removal Tool.  And it's funny, I was looking at that, seeing if there was anything noteworthy about it.  And we were talking last week, one of our Q&A questions was some guy asking, gee, should I be running MSRT all the time?  And we explained that it was something that was run once a month, essentially, when you get a new one, and you reboot in order to get this thing installed.  It's during the reboot that it runs, and not subsequently.  There are ways you can induce versions of it that you can get from Microsoft to run all the time, if that's what you want.  But in the context of that I was noticing that one of their questions was, is this something I can use instead of AV, because we were talking about how Microsoft does not want to step on the toes of the antivirus vendors.  And Microsoft explicitly states this is not a replacement.  The MSRT, the Malicious Software Removal Tool, is not a replacement for AV.  It is explicitly a post-infection removal tool.



LEO:  Oh, so it doesn't block anything ahead of time.



STEVE:  Exactly.  So Microsoft is looking for evidence of infection in the system, not even latent code or files that haven't yet infected.  So they're actively looking for infection, and it's a post-infection removal.  Of course you don't want to get infected.  You want to prevent that.  So the way to think of this sort of in tandem with AV is the AV is your frontline guard, preventing things as they come in, scanning your email and websites and so forth on the way in, preventing infection.  But Microsoft has said, look, if people aren't doing that, if something gets in under their radar, or there isn't a signature available yet for something, but Microsoft has it, we want to be able to disinfect systems.  And they're not saying they do a perfect job.  They're just trying to do the best job they can.



LEO:  Yeah.  And I think they don't want to step on the toes of commercial vendors; right?



STEVE:  I'm sure that's...



LEO:  You don't want to kill that ecosystem.  It's too important.



STEVE:  Yeah, I mean, and we've seen Microsoft sort of slowly creep forward.  They now have a personal firewall that has certainly damaged the sale of personal firewalls to some degree, third-party tools.  It's like, well, I've already got a personal firewall built in.



LEO:  But they had to do it.



STEVE:  Of course.



LEO:  They had to do that.



STEVE:  Yes.



LEO:  And some would argue that, well, nobody better than the operating system vendor to put antivirus in there.  But no other operating system does that.  I think that you kind of like the idea as - in fact, remember Apple put out that note saying it's healthy when you use different antiviruses.  If there's only...



STEVE:  In addition to your own.



LEO:  Yeah.  If there's only one, then it's easier, and it's an easier target for the bad guys.



STEVE:  That's exactly right.



LEO:  Yeah.  So maybe Microsoft, it's not entirely economic or are worried about getting sued, it really is better for the platform.



STEVE:  There was an interesting note also in the security news this week.  A company called CheckFree, which is an electronic bill-paying service that's used by many banks sort of as their backend electronic bill-paying service, their Network Solutions account was hacked.  And this is not the first time we've recently heard of Network Solutions accounts being hacked.  And their assigned DNS servers were changed to point to somewhere in the Ukraine.  So what happened was, unfortunately, this poor company - well, poor, I mean, maybe it's their fault.  Who knows how they were hacked.  But they're having to now notify nearly six million users that, because they don't know who was affected, anybody could have been affected.  And essentially what happened was this fraudulent site in the Ukraine attempted to install password-stealing malware into the machines of anyone who visited believing that they were CheckFree.  So this was a DNS attack.  It was not a spoofing attack, though.  It was actually the source of the DNS was changed.



So the takeaway message is I just wanted to raise this issue to our listeners and say you really do need to make sure that your login credentials for - anyone who's maintaining web servers and websites and web domains, that your login credentials for your registrar are really strong, that you've got a really good password.  It's a perfect instance or a place to have a really strong password because it's not something that you need to do every day.  Typically you log in maybe no more often than every few years to update your domain name registration.  But it's the kind of thing that, without adequate safeguards at the registrar's end, somebody could just sit there and patiently try to crack into a high-value domain like CheckFree's domain.  And ultimately they did.  They got in, and they were able to redirect their DNS.  So that's sort of like a legitimate change to DNS because the registrar's account was hacked.



LEO:  This has been happening a lot.  In fact, Clickjack, one of the uses of clickjacking was to get people's Gmail account, and then once you had the Gmail account request a new password from the domain registrar.  So even if you had a strong password - you have to be really careful all around.



STEVE:  Yeah.



LEO:  It's, boy, that's a terrible thing when you lose your website.  And it's a disaster worldwide if it's somebody like VeriSign or, you know.



STEVE:  Yeah, yeah.  And in one other little bit of news I thought was interesting, there were articles both in the  Boston Globe and the Washington Post.  Actually Brian Krebs picked up the story in the Washington Post from the Boston Globe, that people were noticing 25-cent charges appearing on a large number of credit card statements.  And so there were two theories.  One was - and I think this was probably the more nave theory, that Brian also didn't subscribe to, was that somebody was trying to make money by hiding lots of little small charges on credit cards.  Well, in order to do that you've got to have the ability to charge to the card.  And so Krebs, who is more technical, thought, you know, I doubt that.  What this sounds to me like is somebody offering a service for the bad guys to verify that stolen credit card information is authentic.  And of course what you first see is a 25-cent charge.  And then what happens some length of time later is serious money starts getting charged.  So I just wanted to also put that on our listeners' radar, that they just want to scan their credit card statements for any suspicious small charges that they might otherwise not have made, or just make sure there's not that going on.  Because that would be, could be an early indication of trouble to come.



LEO:  Huh.  So there's a way of them verifying - you know, PayPal does that, and other systems do that.  They do two - for instance, the way they figure out if it's really your account, they'll do two small deposits.



STEVE:  They use it as an authentication loop, essentially.



LEO:  Right.  And then you tell them how much it was.



STEVE:  Yup.



LEO:  So but this is different.  This is a debit, not a deposit.



STEVE:  Yes.  This is somebody charging cards a very small amount of money.  And the number I saw in the article was 25 cents.



LEO:  Yeah, it'd be a way of seeing if you had access, if you were able to - if you got the quarter...



STEVE:  If they could get a quar- exactly.



LEO:  You're in, yeah.  It's amazing.  I'll have to look at my statement.



STEVE:  We've got some interesting errata, too.  There's a contributor to the GRC newsgroups who goes by the handle Bill_Mi.  And I finally ran across a posting of his in our Security Now! newsgroup at GRC, which he said he had posted several times, but I just hadn't seen it before.  And he commented that PayPal only shows the plug-in menu option after you have downloaded the plug-in.  Which I was like, oh, my god.



LEO:  And how would you get that plug-in if...



STEVE:  PayPal bites us again.  So we talked about this also last week.  Somebody was saying - I think he was in Australia saying, hey, I can't find anywhere to generate these one-time-use credit cards.  And so I said, oh, yeah, it's right there on the menu.  The first item is Plug-in.  And even though it's strangely named, you wouldn't think that that's where it is, you click on Plug-in, then you go in, and you don't need to use the plug-in.  You can still have the website generate a secure card for you.  Well, it turns out you may not have the plug-in option on your menu.  PayPal knows whether you have ever downloaded it, even if you're not using it, and you don't have to ever use it.  You just have to download it.  And then your account is tagged as having downloaded the plug-in.  Then the plug-in item appears on the menu.  And you don't have to ever use the plug-in.  But that allows you to get to the ability to generate secure cards.



LEO:  That's just silly.



STEVE:  It's just ridiculous.  I mean...



LEO:  Because I can't use it.  The plug-in is for Windows, so I can't use it on the Mac.  So, but you know what's funny, I must have downloaded it.  I think I did at some point.



STEVE:  And there is a plug-in for Firefox, also.



LEO:  Ah.  Okay.  Because I do have the option.



STEVE:  I'm sure you and I both did.



LEO:  Sure.



STEVE:  And I didn't like it because it kept popping up and asking...



LEO:  Yeah, I didn't want it.



STEVE:  Yeah, exactly.  So I stopped using it.  But since PayPal knows that I once downloaded it, now I've got the option any time I want to generate secure cards using their web interface, and not with the plug-in.



LEO:  That's just goofy logic.  I'm sorry.



STEVE:  So there, for anybody who after last week went looking for the plug-in menu item and still can't find it, try downloading the plug-in.  You don't have to use it, just download it.  And then the menu item apparently appears.



LEO:  [Chuckling]



STEVE:  Another friend of mine sent me something that I thought was pretty funny.  Just it was just some humor that's clearly security related.  Timothy McSweeney has a website, McSweeneys.net.  And he posted some secure website authentication questions that had been put together by someone named Joel Gunz.  And so these were typical questions, or nontypical questions that I guess this person was recommending as something that would be hard to guess.  So we have:  What is your older sister's favorite Monopoly game piece?



LEO:  There you go.  There you go.  That's good.



STEVE:  Who did your paternal grandfather vote for in the 1956 presidential election?



LEO:  I don't know that one.



STEVE:  Why did you choose a liberal arts degree when your entire family urged you to go into finance?



LEO:  I ask myself that every day [laughing].  Now it's comedy.



STEVE:  In what year did you begin working on your novel?  How many weeks away was graduation when you dropped out of college?



LEO:  Oh, well, that one I know.  That might be in my Wikipedia article.



STEVE:  What was your score on the civil service employment exam?  Where were you sitting when your girlfriend told you she was pregnant?  Where did you never end up going for your honeymoon?  In what year did you begin working for the post office?



LEO:  Oh, this is so good.



STEVE:  What is the name of the hedge fund manager your ex-wife married?



LEO:  So this is obviously comedy.  But it raises a serious point, which is...



STEVE:  How many hours did it take you to drink that bottle of Jack Daniels yesterday?  And what time was it when, in a drunken rage, you threw your novel into the fireplace?



LEO:  There you go.  And how many pages long was it?



STEVE:  And then the last one is, if you could do it all over again, what would you do differently?



LEO:  Oh, I love that.



STEVE:  That's a good security question.



LEO:  So these are questions that you would know, but no one else.



STEVE:  Yeah, I mean, and they're just meant to be funny also.



LEO:  But it's a legitimate point.  If you're allowed to generate your own question.  Some places do; some places don't.



STEVE:  Right.



LEO:  I wish they would because that's a much better way of doing it.



STEVE:  Much better.  And then lastly, we've talked of course many times about one of our favorite security authentication gizmos, the YubiKey, where you plug it into a USB port on your computer, and it cryptographically generates keystrokes.  Well, our good friends at ThinkGeek have come up with something that takes advantage of the USB port in a different way. It's called the Phantom Keystroker Version 2.  It's a little dongle-y like thing with a USB connector on it.  There's three little potentiometers, three variable adjustments on this, which determine the delay between things it does that are meant to annoy you.  It will generate random mouse movements on your screen.  It will toggle your caps lock.  Or it will type out odd garbage text and phrases.



So the idea, of course, would be that you set this appropriately and plug it into the computer, like an unused USB port in the back of someone's machine.  And their mouse just sort of twitches or moves around from time to time, or their cap lock toggles.  And so they're typing along, and suddenly everything's in caps.  And they go, it's like, oh, how did that happen?  And they toggle it back off again.  And they're typing along, and after some length of time that you can control, it toggles caps locks on again.  So after a while you begin to think that your computer were possessed.  Or unfortunately you might think it was infected and go off on a wild goose chase, when this in fact is just something that's using USB to simulate keyboard and mouse.



LEO:  That is pretty funny.



STEVE:  Oh, it's pretty...



LEO:  It's a practical joke.



STEVE:  Just a practical joke.  And in fact, since I was first there, I went to their site just to verify that it was still there because I'd made a note of this several weeks ago, and we'd had so much content that I kept bumping this little note about this down.  A new warning has appeared on their site, in red.  It says, "Warning:  The Phantom Keystroker never hits the return key, and it never clicks the mouse button."  Meaning that it's not going to actually do any damage.  It's not going to select anything or do something, it's just going to annoy you.  And then it says, "However, you should not use it on anyone's system who is doing critical work where disruption could cause serious consequences.  The Phantom Keystroker is a joke.  Like any joke, you need to use prudence and judgment when executing it.  You have been warned."



LEO:  I like the - there's switches on it for time delay, caps lock, keyboard and mouse.  So you can switch - you can change its behavior around.



STEVE:  Exactly.  And then they suggest that you not set them to be too quick because it's sort of going to give itself up, if it happens.  You would like to have it happen infrequently enough that someone's like, huh?  What?  Did I bump the mouse?  Or is it, like...



LEO:  That's mean.



STEVE:  Is it drifting on my desktop?



LEO:  Oh, it's so mean.  It's only 12.99.



STEVE:  Yeah.



LEO:  They have - I don't know if you've seen it.  They have another thing called the Annoy-a-tron.



STEVE:  Oh, I've got two of them.



LEO:  No.



STEVE:  Oh, yeah.  I'm a sucker for ThinkGeek stuff.



LEO:  So the Annoy-a-tron just makes this little beep; right?



STEVE:  It's a little twitch, yeah.



LEO:  Every once in a while.  And we all have things that do that when they run out of juice or whatever.



STEVE:  Right.



LEO:  And you just hide it, and it drives people crazy.



STEVE:  And in fact it's got a magnet on it, so to make it easier for, like, sticking it on the back of something.  And so it's like, what?  You're looking around, what's making that sound?  And it's a high-pitched little chirp, and it never lasts very long.  So it really just annoys you.  Because it's like, okay, wait a minute.  What's doing that?  And so you look around, but it's not on enough to allow you to even zero in on it.  And of course the high-frequency sound is hard for us acoustically to locate anyway.



LEO:  Can't hear it anyway.



STEVE:  Yeah.



LEO:  That is mean.



STEVE:  And I have a nice sort of, in the spirit of the holidays, which aren't very far behind us, SpinRite story I wanted to share before it became dated too far.  Garry Weil, W-e-i-l, I think that's how you pronounce his name, Garry Weil sent us a little story about SpinRite saving Hanukkah.  He said, "Steve and Leo.  I'm a long-time listener to Security Now! and other TWiT podcasts.  I bought SpinRite several years ago and use it at work and home."  And actually his email address is Intel.com, so he's - that's where he's using it.  He says, "My daughter requested a couple of PS3 games for Hanukkah, and I dutifully bought them for her.  It was the fourth night of Hanukkah, and it was time to give her the new PS3 game, Mirror's Edge.  A little while after lighting the menorah and giving her the game, she told me that the PS3 was broke.  She had enlisted her 19-year-old brother's help, but the Restore option on the PS3 would not take.  So I pulled the disk drive out and put it in my notebook and booted to SpinRite.  I used Level 2, and it quickly found a single unrecoverable sector.  After SpinRite finished and I replaced the disk in the PS3 and selected the Restore option, within a minute the PS3 was working perfectly, and my daughter was able to start playing her new game.  I received a great big hug and thanked GRC silently.  Thanks for a great utility, and keep up the podcast."



LEO:  Wow.  I didn't know it would run on a PS3.  You're just...



STEVE:  The reason I wanted to share this with listeners is it will fix anything.  If it's magnetic and spinning, SpinRite can fix it.



LEO:  That's pretty amazing.  Wow.



STEVE:  And the other thing, I noted that he said it found a single unrecoverable sector.  One of the other things that SpinRite does that is truly responsible for I think a lot of its capability in recovering things is, as far as I know, it has always been unique in its ability to recover all but the unreadable little bit of a sector.  That is, for example, if a little more than a couple bytes, it depends on the total number of bits that are damaged from the - the distance between the first wrong bit and the last wrong bit is the so-called "burst."  And if that's longer than a certain length, and like 11 is typical, well, okay, a byte is eight bits, so that's less than - it fits within two bytes, or maybe it could straddle three.  But that means that if only two or three bytes are bad, nothing else in the world will give you any of the sector, that is, any of the other 510 bytes.  And SpinRite will.  It's able to say, okay, no matter what we've tried, and believe me we've tried, we cannot get this sector perfect.  But we can give you most of it.  We can give you 510 out of the 512 bytes.  Well, very often, for example, if that's in the directory, or if it's a boot sector or something, you've gone from getting nothing to getting everything you need in order to get the system to boot.  And so that's one of the reasons SpinRite ends up having such data recovery gain is that it can give you most of a sector.  Whereas nothing else will give you any of it.



LEO:  Well, that's very interesting.  I didn't - yeah.  Because normally you'd say, well, if I can't get the whole sector, forget it.



STEVE:  Right.  But it turns out that most of it can be useful.  



LEO:  That's all you need.  Very cool.



STEVE:  Some parts are edible.



LEO:  You're in a mood today.  It's the comedic stylings of Steve Gibson, I swear.  All right, Steve.  It is time to talk about certs.



STEVE:  Certificates.  Cryptographic certificates. 



LEO:  Yes.



STEVE:  Okay.  What a cryptographic certificate is, that is, what it essentially does, is it offers a public key.  What a certificate is publishing, essentially a certificate publishes someone's public key.  So what you want to know is, you want to know that the person whose public key you believe it is, is true.  That is, so the certificate essentially binds together an identity of someone or something with a public key.  And, for example, a web server certificate, it's binding the domain name to the public key.  So, for example, www.GRC.com, we've got an SSL certificate.  And the certificate contains GRC's public key.  So what the certificate is asserting is that these two things go together, the identity information and the public key.



Well, that assertion is being made by a third party, as we were talking at the top of this episode, a third party who has taken responsibility and has put their reputation behind that assertion.  So someone like GoDaddy or VeriSign or Equifax or Global Trust or one of these certificate authorities has gone through some sort of process to be able to assert, to attest that this assertion being made by the certificate is true.  So the way a certificate is created is you create what's called a "certificate signing request."  And certificates are just files, they're just data files like anything else.  You know, a few K in size.  The certificate signing request is something that an individual who wants to create a certificate generates on their computer.  And that process involves creating a public key pair.  And we've talked in years past in detail about public keys.  So I'll just quickly remind our listeners how they work.



The idea is that a so-called public key pair produces, or consists of, two different keys.  That is, they're different, and so we use the word "asymmetric."  We've talked about symmetrical encryption where you use the same key to encrypt and to decrypt.  With an asymmetric key pair, which is normally called a public key pair, one key encrypts, and the other decrypts, although it doesn't matter which is which.  So you could use either key to encipher something, and you just use the other key to decipher it, or to decrypt it.  So somebody who wants to generate a certificate first creates a public key pair.  They then fill out essentially the fields in the standard form.  There's a format for all this called an X.509 certificate.  X.509 is sort of the worldwide accepted standard of format for public key certificates.  So you fill out this information.  Then, using your private key, you sign that information.



Now, we've talked also before about signing.  Signing is the process of generating a hash value for that information, which ends up essentially digesting any amount of information into a small fixed amount, typically 128 bits, which is 16 bytes, or maybe 160 bits, which is 20 bytes.  Some relatively small digest, as it's called, of the input text.  And then that little blob is encrypted using, for example, if we want to generate a certificate signing request, that would be encrypted using our private key.  So we never disclose our private key, even to the entity that we're wanting to have sign our certificate.  We don't need to because what we do is we take that result, that signed certificate request, and our public key, and send them off to someone to sign, like to VeriSign or GoDaddy or someone.  What they're doing then is, because it doesn't matter which of the keys, the public or private, that you use to encrypt or decrypt, they don't ever get our private key.  But they're able to decrypt our signature with the public key that we gave them, that is, the other key is really all that matters.  That gets back the MD5 or whatever hash was used to sign the form.  They then, essentially, they hash it themselves.  They rehash what we gave them, which consists of all the information we provided and our public key.  And they make sure that they get the same resulting hash value as we did, which we encrypted when we sent it to them.



So what does that prove?  That proves that we are in possession of the matching key that we sent them, which in this case we're going to call the private key because we're not letting anyone have it.  So they know that we sent them this request containing the identity information and a public key, and that we're in possession of the private key, because that's the only way that we could have encrypted the signature that we sent them.  So then they say - they do whatever they need to do, depending upon what kind of request this is, to verify that the identity information really is us.  You know, for example, in the case of a website, you have to go through some hoops, phone calls, verify IP addresses or that you're in control of the website, do something to say, to prove to this authority that I'm somebody who has the authorization to request a certificate, for example, for a server at GRC.com.  So once that's done, then the certificate authority creates a new certificate, which is our server certificate.  That's something which they sign in order to prove that they've done this work, they've verified the identity and the public and private key.  And so they're signing this saying that, okay, we've done our due diligence.  These people are who they say they are.



That certificate is then sent back to the requestor.  For example, in the case of a web server, it's installed on the web server.  And now anytime a third party wants to establish a secure connection, at the beginning of that connection the web server provides that certificate to the web browser, saying this is who we are.  And somebody who you trust has agreed with that.  Somebody who you trust has signed our certificate.  So what happens is the web browser looks in its store of certificate authorities for the matching entity that has signed it.  Now, the certificate was signed with their public key.  So the public key is available in this store of certificate authorities.  So the web browser that wants to verify that this is a proper signature is able to duplicate the signing process, verify that they get the same result.  And the only way that's possible is if the certificate has not been changed in any fashion, that is, if the hash value, the so-called fingerprint on that certificate has not had a single bit changed.  So that's sort of the process by which all this operates.



Now, in this example there's only a server certificate and the root, or the certificate authority.  It's possible to have a chain of certificates.  And essentially it works in the same fashion, where, for example, there might be a so-called intermediate certificate authority, or an intermediate authority.  And you could have, in fact, several of those, essentially forming a chain where each certificate is signed by somebody, and then that one is signed by somebody, and that one is signed by somebody.  Ultimately you come back to the root.  And it's interesting because the root certificate is signed by itself.  That is, it's a so-called "self-signed certificate."  They sign their own certificate, meaning that there's nobody here left to trust.  I mean, you have to trust them because you've got no choice.  Ultimately...



LEO:  There's always somebody; right?  There's got to be one final end to that chain.



STEVE:  Well, and of course we're trusting our OS vendor, for example, Microsoft, or maybe Mozilla, that provided this set of self-signed certificates.  So those root certificates are self-signed.  They're just signed by themselves to sort of form an anchor to this chain of trust.  Okay.  So that's sort of the process by which a certificate is created and issued to a server and then presented to the browser for authentication.  What happened back in 2004 is some researchers discovered some problems with the MD5 hash, which is one of the oldest hashes.  There was an MD4 before it.  In fact, there was an MD2, not surprisingly, before that one, which was pretty well destroyed.  MD4 had some problems.  And Ron Rivest at RSA came out with MD5.



Well, as often happens, as our cryptographers analyze and poke at these things over time, some problems surface.  What happened in 2004, so more than four years ago from the time that we're recording this here at the beginning of '09, what happened in '04 is some very clever attacks were designed against the way MD5, Message Digest 5, functions.  Now, what MD5 does - we've talked in detail in the past about various cryptographic algorithms.  I'm going to sort of explain in overview how MD5 actually functions because it's important to understand that in order to get sort of a visual idea of how it's been broken.  MD5 outputs a 128-bit result, that is, 16 bytes of data, 128 bits.  So essentially, from the outside of this, if we think of it for a minute as a black box, we pour any amount of data into it.  It's able to digest texts, plaintexts of any size.  So we pour any amount of data into it.  And when we're done, no matter how much data we've put in, we always get 128 bits.



And what's special about a hash, there are key characteristics that make a hash a good hash as opposed to a useless hash.  And they are that it is supposed to be extremely difficult - computationally infeasible is, like, the technical term, which means you need a huge amount of computation time to deliberately put something in that creates a deliberate result.  So you're not supposed to be able to precompute a complex input that ends up giving you a specific output.  Meaning that you cannot, for example, if you had one document which you hashed into a 128-bit result, you're not supposed to be able to produce, for example, a document with a few changes which will give you the same result.  So it's meant to be sort of a fingerprint, a unique identifier.



But the fact that so many bits are reduced to just a few, that is, if you had a long document, it's always being crunched down, in the case of MD5, to 128 bits.  Well, that means that there are many, many, many different patterns of input bits that will give you the same 128 output bits.  There have to be because you're reducing a huge number of inputs into a much lesser number of outputs.  So there have to be so-called "collisions."  A collision is two different things that result in the same output hash.  But the idea is that none of those different things that might, that would result in the same output, are useful to you.  They're just, you know, they're cryptographically random.  They're not going to be something that is a useful collision.



Well, the way MD5 functions is it starts out with a particular fixed set of 128 bits.  And this is part of the spec.  In the spec it says - and that's 16 bytes of data, or you can think of it as four 32-bit blocks.  So it starts out with these four 32-bit things that are fixed values, specific hex values.  And it digests the data 512 bits at a time.  So it takes - and 512 bits is 64 bytes.  So it takes 64 bytes in and runs an algorithm on those that ends up producing a different four 32-bit blocks.  And so what happens is, as the input comes in, it takes the input 512 bits at a time and runs it through this algorithm.  It's four rounds that takes the data in 128 bits at a time.  So four times 128 is 512 bits that it takes in as a whole block.  And every time it ends up sort of taking that input four 32-bits, and ends up producing an output of these four 32-bit blocks.



Now, the problem is that, because we want to be able to take something of any length, but MD5 only operates in 512-bit chunks, it's necessary to do some padding of the end of what we're feeding it, if it doesn't end up being an exact multiple of 512.  And in fact what happens is it's padded out to - the last block is padded out to 448 bits, and then a 64-bit final piece of data is added, which is the binary representation of the original message size.  So that's how MD5 always ends up with an even 512-bit block size multiple, which is what it needs.  So that's the process of hashing something through MD5, is it's first padded out so that it's a multiple of 512 bits long, the end of it being the size of the original message before the padding.  And then 512 bits at a time are fed into this algorithm which runs through four rounds.  And at every phase it takes in these initial four blocks of 32 bits, or 128 bits.  And then after that there's a resultant 128 bits.  Well, once you're all done, that final resultant 128 bits is the hash value.



Okay.  So what the researchers figured out is that there was a way to choose any beginning input.  Imagine that you take the so-called - this plaintext.  And you're able to specify two different source plaintexts.  Your goal is to have them hash to the same value.  Well, these guys, these security researchers figured out how you could take two different deliberately created source plaintexts and at some point before the end, essentially, make some changes and then add some of your own data to the end that would essentially bring you to identical hashes.  Well, this is never supposed to be possible.  That is, it was absolutely supposed to be that you could not deliberately create a resultant hash value using a secure hashing algorithm.  These guys figured out essentially how, by appending their own carefully designed data to the bottom of two different texts, they could create a common hash.  And that we knew about two years ago, in 2007.  So essentially the technology for damaging MD5 more and more has been advancing, which is exactly, historically, this is what we see in crypto work.



So then the researchers said okay.  I mean, and this work was published in '07.  And people said, oh, gee, that's interesting.  Very theoretical.  Very academic.  And some guy in fact used this as his master's thesis in cryptography.  But it's like, okay, we're not worried about that.  Well, so these researchers in the middle of last year, last summer of '08, they decided, okay, we've got to bring this to everyone's attention.  We've got to explain to people very clearly how badly MD5 is broken, how much of the security industry is still using MD5, despite the fact that we are now able to take two different inputs, and if we are allowed to extend their length, if we're allowed to add our own stuff on the end, we now have the computational ability to make the hashes end up the same.  So how can we shock people?  And they figured out a way to create a fraudulent certificate, a fraudulent security certificate.



It turns out that doing this was extremely difficult.  Essentially they needed, in order to pull this off, they needed to be able to get a security authority, somebody who was going to sign and issue a certificate, they needed to get them to issue exactly the certificate they wanted because they needed to provide a certificate signing request with exactly the data that they needed, where they were going to have a fraudulent certificate match the resulting certificate that they got back.  The problem was that there were some things they could not control.  For example, there's a serial number in certificates that are issued, as well as a first valid date and an ending valid date, which is always based on the instant that the certificate is made.  Normally it's like, it's valid for one year or two years or three years.  But it's, like, it involves minutes and seconds based on when the actual signing takes place.



So they sent - they created a bot to go out and scour the 'Net, which over the course of a relatively short time collected 100,000 website certificates.  They analyzed the website certificates for a number of characteristics.  And it turns out that one particular certificate authority, RapidSSL, they were using a sequential serial number.  That is, it just - it incremented literally by one for every time a certificate was issued.  And to verify that they asked RapidSSL for some RapidSSLs, in rapid succession.  And they got back certificates with serial numbers either one off or a couple off, if somebody else had asked RapidSSL for a certificate in the meantime.  So they were able to verify that the serial numbers were being issued sequentially.



They were also able to - and they did this over time by asking for one certificate every so often.  They were able to look at how rapidly the serial number was incrementing and guess, essentially, what serial number would be issued at a certain time in the future.  They also verified that from the time they clicked the Okay button asking for a certificate, that it took eight seconds.  I think it was - it was either six or eight seconds for the certificate to be issued.  So by deliberately clicking the Okay button on Yes, please issue us a certificate at a certain time, and they had to synchronize their clocks, of course, they were able to deliberately choose the timestamp on the RapidSSL certificate that would be issued.  So they looked at where the serial number was.  They decided it would take them about three days to get everything together, that is, essentially to generate the matching data to be appended in order to make the hashes match.



And so what they did was they created the certificate that they wanted to have forged and the certificate that they wanted to be issued.  They then figured out what needed to be added to the end of those in order to get the MD5 hash to match.  The reason that was important is that the certificate authority was going to sign the resulting certificate that would be issued to them.  Well, they would never have the private key used to sign the certificate.  But if their forged certificate had the same hash as the one that was signed, then the signature would be good for both.



So three days before, they created this pair of certificates, the forged one and the one that they were going to get signed from the certificate authority, RapidSSL.  They cranked this array of 200 PS3s many times in order to do the math to figure out what to add to the certificates.  And they had figured out how to hide that, the added stuff, in the certificate body itself.  And then they started asking for certificates to manually advance the serial number counter until it was one shy from where they wanted.  And then at exactly the right time they said we want a certificate.  And so the serial number jumped to the next number that they had anticipated, issued at the time that they had designed, to issue exactly the certificate that they wanted.  That's what they had to go through.  It turns out the first three times something went wrong.  Somebody else asked for a certificate just before they asked for their final one.  Or the timing of their clocks wasn't quite right so that, like, even one second off would cause the timestamps not to be predictable.  But on the fourth try they got it.  They were issued a certificate by RapidSSL with exactly the serial number that they had anticipated and required, on exactly the timestamp to the second that they required, and all the other information that they had provided.  So they got back from RapidSSL the certificate that they had designed to be given, for which they already had a matching fraudulent certificate.



LEO:  So clever.



STEVE:  And where both of them had the same MD5 hash.  And that meant that they were able to lift the signature off of the certificate, which they didn't even care about.  I mean, they threw that away.  It's the signature they wanted.  They were able to lift the signature off of the one with the matching hash, stick it on the end of their fraudulent one, and it was valid.



LEO:  Wow.  That's so clever.  That's such a great hack.



STEVE:  It's just, I mean, it's just incre- it's brilliant.  And now, of course...



LEO:  But of course it only works because RapidSSL is really flawed in the way it's assigning these certificates.



STEVE:  Well, okay.  So several things.  Many, many other certificate issuers are issuing a random serial number.  In fact...



LEO:  This is very much like that DNS attack we were talking about.



STEVE:  It's very much like that, yes.  And we know, for example, listeners know that the certificate authority could actually have a counter which is just incrementing by one, just like RapidSSL does.  But all you have to do is encrypt it.



LEO:  Right.



STEVE:  You know, just run it through a simple symmetric encryption.  There are, I believe it's 20 bytes available for - maybe it's bits.  I can't remember.  Anyway, there's a big chunk of space available - I think it is bytes - for the serial number.  Because that's 160 bits.  So if you did 160-bit encryption, then every single one would be completely different than the next one.  And that would have blown this hack out of the water.  I mean, and there's even the ability to put private data in a certificate.  RapidSSL wasn't.  But you could have your own fields with some random gibberish.  That would have blown this out of the water.  It was just the fact that they were able to very carefully induce the issuance of exactly the certificate they wanted, where they had precomputed what its hash would be and had their fraudulent certificate ready, so they were able to essentially lift the signature from a valid one and stick it on theirs, making it look valid.



LEO:  Very clever.



STEVE:  And if anything else had been done, it wouldn't have worked.



LEO:  Right, right.



STEVE:  So it's the fact that - so, but they really drove their point home finally by saying, okay, sure.  This is theoretical.  This is academic.  We have just created a fraudulent certificate.  Oh, and the other cool thing is, one of the - there's a bit flag in the X.509 certificate spec which says is this a CA or not?  Is this an authority, or is it sort of like an end-user certificate?  Well, in their fraudulent certificate, they set that bit.  So they didn't just create a single fraudulent certificate.  They created their own signing authority that was signed by RapidSSL.  So now they were able to sign any one, any certificate that they wanted to.  Now they could create website certificates all day and night, and they signed them.  And again, due to the way a chain of trust works, because the root SSL CA was trusted, so was the intermediate certificate authority, which signed the final website.  So they created their own fraudulent, but valid for every web browser on the planet, certificate authority.



LEO:  Now, how repeatable, though, is this?  I mean, it sounds like it's really a lot of work.



STEVE:  Well, they have, in their careful dissertation, I mean, they wrote a really well-written paper where they take us through this.  They also offer all the files that they used, so people can see them for themselves.  They have not gone into the details of how they pulled it off.  They just said, you know, lots of math, lots of PS3s, this is what we did.  And but they said some number of months in the future they're going to reveal this.  They've commented, though, that to their knowledge nobody else has done this.  But we don't know that nobody else has done this.



LEO:  Right, right, right.



STEVE:  People who could do it for malicious reasons certainly aren't going to advertise.  It's the academics.  And, see, this is a perfect example of why we cannot criminalize this sort of work.  I mean, this is what unfortunately the DMCA, the Digital Millennium Copyright Act, has really created a problem because there are many academicians that are now afraid to do research because technically they're breaking the law.  But we need people to poke at these things.  And it's worth mentioning, too, that the more secure, or I should say currently more secure, SHA-1 hash is also under attack.  It hasn't been wounded to the degree that MD5 has.  But there's some concern that it may - it's better than MD5 right now.  But it may not last that long.  So, I mean, we really need to allow cryptographic research to operate in a way that is not fettered by ridiculous law, which is well-meaning but wrong-headed.



LEO:  Well, I think there are some companies that would prefer security by obscurity.  They don't want this stuff to be exposed.



STEVE:  Right.



LEO:  Which is really a problem because of course the hackers will find out, and they aren't going to tell anybody.  I thought it was very interesting they used PS3s, too.  They're really computational powerhouses.



STEVE:  Yeah, well, the way that - there's some types of algorithms which you can run in parallel, and where you don't need, like, lots of branching decisions.  So you're able to write code that just does mass number crunching.  And they were able to map the algorithmic computational work that they needed to have done, they were able to map it into the architecture of the PS3 cell processor and get this bank of PS3s to do a lot of their work.



LEO:  That's really cool.



STEVE:  That's very cool.  The idea that they were able to basically create a pair of certificates, one that they anticipated receiving, and one that was that of a fraudulent certificate authority.  They were able to engineer those two so that they would have the same MD5 hash, then induce a real certificate authority to issue them the certificate they needed that would have a matching signature so that they could take the signature off of the valid one, then throw that one away - it's only the signature that they wanted - tack it onto their fraudulent one, making it a valid certificate authority.



LEO:  Now, we don't know how many times they had to do this.  This could be quite costly if you had to buy a bunch of certificates.



STEVE:  They said they spent about $700, just shy of $700.  However, RapidSSL, unfortunately it's highly automated.  So they were able to - there is a reissue certificate.  And I think they were able to reissue a certificate, like, 22 times, some high number of times.  So they did spend just shy of $700.  But they generated and then canceled and reissued many, many times so as not to just rack up the bill.



LEO:  Oh, interesting.  And that's clever, too.



STEVE:  Yeah.  But again, if anybody were - if there was any oversight over this, that's another thing that is, you know, this would raise red flags by anybody who's saying, wait a minute, what are these clowns doing?  They're issuing certificates and canceling them and issuing and canceling and issuing and canceling.  And so it's like, whoa, stop.  So it was many characteristics of this one certificate authority.  But these guys succeeded in demonstrating that MD5 can be cracked.  And it's worth noting, too, that historically the kinds of limitations that they faced may not stand a year or two or three from now.



LEO:  Why not?



STEVE:  So we need to get away from MD5.



LEO:  You mean in terms of the speed of processors, the technology?



STEVE:  Well, for example, if more - no, no.  If more were learned about MD5...



LEO:  Oh, I see, yeah.



STEVE:  ...it may be possible to take existing certificates and lift the signatures from them and move them over.  Right now this attack required a very precise issuance of a precomputed, predesigned certificate to be signed.  But imagine if you, like, had godlike understanding of MD5, and much more than we have now, where you could just take anyone's signature and move it onto your own fraudulent certificate.  Then the world is over.



LEO:  Oh, boy.  Oh, boy.  Well, I'm glad - this is really interesting stuff.  And I just admire the, you know, it's graduate students.  They've got a lot of time on their hands.  I admire just their persistence and their cleverness.  I mean, there's a huge amount of clever, smart work being done here.  It's really interesting.



STEVE:  Oh, absolutely so.  And this is what we need them for.



LEO:  Yeah, yeah.  That's why open systems work, because people can bang on them.



STEVE:  Yeah, yeah.



LEO:  Steve Gibson, you're the greatest.  Thank you for making that all crystal clear, as usual.  You can find more about all of this in show notes.  And we have a new wiki, wiki.twit.tv, and we're putting show notes there for public consumption.  We will migrate them.  It's really nice because a community is working on them.  We'll migrate them, of course, over to our regular show notes on TWiT.tv.  And then Steve has his show notes.  There are many places to get  more information.  Steve's show notes are at GRC.com/securitynow.  Also that's where you'll find transcriptions.  He does full-length transcriptions.  You've inspired us, Steve.  I think really, it's really clear that from the point of view of Googling things and finding things, you've got to have text.  So I think we're going to talk to Elaine and do more and more of our shows because the transcriptions just really help this show in particular.  This is the one you really want a transcription of, of course.  And 16KB versions for low-bandwidth people.  It's all there, GRC.com.  When you're at GRC...



STEVE:  And the feedback page, GRC.com/feedback.  Next show is going to be a Q&A.  So if you've got questions, you've discovered things, you want to make sure we know things, you've got ideas, whatever it is, GRC.com/feedback.



LEO:  We want your questions.  Also at GRC of course SpinRite, the world's best hard drive maintenance and recovery utility.  And many great free programs like ShieldsUP!, Wizmo.  GRC, the Gibson Research Corporation, GRC.com.  Steve, have a great week.  Let's hope there's no major security backlashes this week, and we can talk next week and answer people's questions.



STEVE:  Either way, we'll keep it covered, Leo.  Thanks very much.



LEO:  That's what we're here for.  Thank you, Steve.  We'll see you next time on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#180

DATE:		January 22, 2009

TITLE:		Listener Feedback Q&A #58

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-180.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 





DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 180 for January 22, 2009:  Listener Feedback #58.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show where we talk about security, privacy, protecting yourself online and off, with Mr. Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Yay.  Hi, Leo.  Great to be back with you, as always.



LEO:  Have you still got the bunting up from yesterday, from the inaugural?



STEVE:  Yeah, I'm doing better now.  This morning was rough.  I was - I was a little hung over, actually.  Probably for the same reason that Barack was; right?  He had to go to 10 balls and wasn't due to finish until 3:00 in the morning.  And then he had a 7:00 a.m. security briefing.  So...



LEO:  Amazing.  I was watching him today on a press conference.  We record this show, we should mention, the day before, on Wednesday.



STEVE:  Right.



LEO:  I was watching him in a press conference today, and he seemed like he was awake.  Joe Biden wasn't, was saying, what do we do?  Didn't I swear them in?  What do I do now?  But, you know, it's kind of funny to watch, it's been a long time, I've forgotten, you know, these people, they don't know what they're doing.  It's kind of funny to watch.  Do I - now what do I do?



STEVE:  Right, right, right, because it's not all a routine for them, yeah.



LEO:  No, yeah, not yet.  Well, Mr. Gibson, what are we doing today?  We're back on track with our mod 2 questions; right?



STEVE:  Yes.  Where Episode 180 is a Q&A.  I think it's our 58th Q&A.  Lots of good feedback from people, good questions, some fun questions.  For some reason they tended to be biased toward login and YubiKey and passwords and that kind of stuff.  That just happened to be what people were asking about.  So we got those.



LEO:  We answer the questions you ask.



STEVE:  Yeah.



LEO:  Coming up also, some errata, fixes, changes, updates from last week.  Before we do that, I do want to mention...



STEVE:  [Indiscernible], yeah, go ahead.



LEO:  No, no, no, what?



STEVE:  No, no.  I was just going to say no security news.  There is news about some GoDaddy problem.  But it just happened, or just came to my attention.  So if it's interesting, I'll talk about it next week.



LEO:  Good.  Steverino.



STEVE:  Hey.



LEO:  We're going to get to our questions in just a sec.  Oh, thanks.  Hey, could you put some soy milk in that?  Just take the bag out?  Thanks.  Getting a little tea from Dane.  I've got a good life, don't I.



STEVE:  Yeah, you do.  Well, you've built...



LEO:  Do you have somebody bringing you coffee?



STEVE:  You've built a good life.



LEO:  I have built a - surrounded myself with wonderful people who really help me get this stuff done.  And you're one of them, by the way, Steve.  This is - you're one of the originals.  You've been doing this longer than almost anybody.



STEVE:  Glad to be.



LEO:  Thank you.  So no security news except maybe that GoDaddy story, which we will look into.



STEVE:  We'll find out what's going on.  During my detailed explanation of security certificates, I properly said what I intended most of the time.  But there was one place where I meant - where I said "public," but I meant "private," where I talked about - many times I mentioned that the certificate authority was signing certificates using their private key, which of course is correct, because it's been verified by somebody with their public key.  Once I said "public key," that is, they sign with their public key.  And a whole bunch of people said, whoa, you know.  Our listeners are really paying attention.  So I wanted to acknowledge everybody who caught me in that slip-up and affirm that, yes, I of course know that certificates are signed with private keys.  That's the whole point.



The only other little bit of news I have is just a little update for people about the PDP-8 kit project.  We had a bunch of listeners who were interested, who joined the SpareTimeGizmos list and have signed up for kits.  They've all - the single boards, which is sort of the base of the kit, have all been mailed out as of today for U.S. customers and domestic, I mean, for, yeah, for U.S domestic customers.  And the foreigners are - Bob is filling out the customs forms.



LEO:  That's right.  You've got to - and that's pretty complicated on something like that.  Looks like a bomb kit.



STEVE:  Oh, yeah.  And then the front panel is being brought back to life and is happening.  So that's - he's just waiting basically on the parts arriving for the front panel kits.  So people will be able to build little PDP-8s, which is going to be very cool.  And I'll have them at one point behind me blinking away, after I've assembled mine.  So that'll be fun.



LEO:  Very cool.  That's exciting.  That's really neat.



STEVE:  And I do have...



LEO:  Did he get enough people signing up to do the front panel?



STEVE:  Yeah.  He didn't need a hundred.  He talked to the front panel fab people.  I mean, this thing, the front panel sounds like it's just going to be gorgeous because it's laser cut.  It's laminated, multiple sheets of something clear plastic-y, like Lucite or Lexan or something.  Five different colors silk-screened on the back and then laminated; and, I mean, it's quite - it's a very detailed assembly process.  But you end up with something, I mean, you know, commercial grade, really.



And of course Bob's put a lot of code into the ROMs that go along with it to build in a debugger and lots of utility stuff.  And it has an IDE interface, so you can put a, like a compact flash card or an IDE drive on it, if you wanted to.  And it emulates the proper DEC hardware.  And he's got drivers, even, for it.  So you can run the original DEC operating systems on this thing.  And they see the IDE drive as being something that they recognize, thanks to the drivers, which are part of the firmware.  So, yeah, I mean, there's a lot in it.  And I'm looking forward to playing with it.



I had an interesting, while I was going through the Q&A, I found a fun - oh, I didn't - I forgot to mute.



LEO:  Did it go "Yabba dabba do"?  What did it...



STEVE:  That's - someone just bought a copy of SpinRite.  Speak of the devil.



LEO:  I don't think you should mute it.  I like hearing that.  So again, for people who are new, and I know most of you know this, but Steve has a whole bunch of sounds that happen when events happen on his network.  And the best one is, when a credit card payment goes through, Fred Flintstone goes "Yabba dabba do."



STEVE:  Yup.  It's always a little crazy around here.



LEO:  Now, do you get a few of those a day, a hundred a day? I mean, is it going on all the time?



STEVE:  Yeah.  Well, I do mute it at night.  I used to, when it was brand new, I would leave it on.  And I'd be sort of like half asleep, and I would hear "Yabba dabba do" out in the front of the house.  It's like, so I just sort of smiled to myself.  But that gets a little old.



LEO:  It would give me a nice, cozy, warm feeling.



STEVE:  Yeah.



LEO:  I should set that up so every time we get a PayPal donation to TWiT I get a "Yabba dabba do."  But people are so generous, I think it would keep me at night.



STEVE:  Well, I wrote a custom UDP client and server system.  So where I am here in my office at home, every two seconds the client sends a UDP packet out to the server, which is at Level 3, which is where our network and servers are.  And that - essentially, sending a packet out creates a reverse path through all of the NAT and other defenses that I've got protecting me here.  And that allows then the server to send a custom UDP packet back which has a chance of getting to me.  And what it does is it basically takes a current status of the server, incoming and outgoing bandwidth, SpinRite sales information, a whole bunch of statistics, and sends it back to me here.  And then the code that I wrote compares that with what it had before.  And if it notices that there's been a change in the number of SpinRites sold from previously, it triggers Fred to say "Yabba dabba do."  So, yeah, it's just fun.



LEO:  That is really neat.  That is really...



STEVE:  So anyway, a listener of ours, Jason Hedges, his subject line, "SpinRite Saved My Rear," caught my eye when I was looking through our mailbag for Q&A.  And he says, "Hi, Steve and Leo.  I've listened to every episode of SpinRite, sometimes two or three times so I can understand what you're talking about, and have loved every one of them.  I always like hearing your SpinRite stories, and now I have one of my own.  I work as the IT director for a small chain of retail cell phone stores.  Our stores use a proprietary Point of Sale (POS) system, running on Windows XP.



"Occasionally for advertising purposes we'll host live radio personalities, which usually dramatically increases traffic to the store.  Last week we were to host one of these radio remotes beginning at 4:00 p.m. on Thursday.  At about 12:15 in the early afternoon, one of the store's employees called to tell me that one of the POS machines had crashed and wouldn't reboot."



LEO:  Ugh.



STEVE:  Ugh.  "I keep a current Drive Snapshot image of every machine in the company on an external USB drive.  I have a BartPE bootable Windows XP disk with the Drive Snapshot executable on it.  And when needed, I boot from the CD and restore the image from the USB drive.  Works slick.  Usually.



"Unfortunately, when I tried to access the USB drive from the ailing machine, the drive wouldn't mount.  That is, the USB drive wouldn't mount.  Almost in a panic, I grabbed my trusty SpinRite disk and ran it on the ailing Point of Sale system.  SpinRite did its thing, and the POS booted back into Windows, literally five minutes before the radio remote began.  The remote drove traffic to the store, and there would have been no way the clerks could have handled the volume on just one POS system.  All I can say is thanks.  I also removed the drive from the USB case, ran SpinRite on it, and was then able to recover all the disk images."



LEO:  Wow.  Wow.  That's...



STEVE:  That's sort of a nice double-header success story.



LEO:  Yeah.  And next time make image backups.  I mean, really, a Point of Sale system, that's a mission-critical...



STEVE:  No, he did make image backups, and he - but unfortunately...



LEO:  Oh, they were on a USB drive, that's right.



STEVE:  And that drive had a problem.



LEO:  Oh, so it was like a double whammy.



STEVE:  It was a double whammy.



LEO:  Make two, make two images.



STEVE:  Yeah.



LEO:  You know, though, I'm in plenty of situations where I only have - I only have one image of the TriCaster, so maybe I'd better make another one.  I do have SpinRite, though.  That's the most important thing.



STEVE:  Well, and he was able to run SpinRite.  First of all, rather than reimaging the system, he ran SpinRite to fix it.  And then he ran SpinRite on his image drive to fix it.  So everything got fixed.



LEO:  Right.  I wonder if he backed up a bad image or - hmm.  That's a scary, scary thought.



STEVE:  No, it's not that he backed up a bad image because he never restored the image to the original system.  He couldn't mount the drive containing all the images.



LEO:  Right, right, right.



STEVE:  So instead of putting the image back on the system, he ran SpinRite on it to fix it that way, and didn't use his image because at that point he couldn't.  So anyway.



LEO:  Steve, are you ready?



STEVE:  Let's do it.



LEO:  Do you put a thinking cap on when you do these?  By the way, I'm looking now at the GoDaddy thing.  And there is a lot to say about that.  But we'll - we don't like to go off half cocked.  Steve likes to do the research.



STEVE:  That never comes out well.



LEO:  We're always sorry when we do.  Starting with Mat Ludlam in Weybridge, London, he wants more of #177.  Hey, guys.  Loved the show, as always, but particularly enjoyed the off-topic stuff that we did about the PDP-8s and the UltraCapacitors.  Made me wonder if you have enough material to do a different podcast, say monthly, on a specific technology subject - solar cells, wind energy, wave energy, your first PC, latest sci-fi releases, whatever.  Here's a fan.  What do you think?  Keep up the great work.



STEVE:  [Sighing]  I wanted to - I put this question in because we got so much positive feedback from that episode.  I was a little nervous about taking us off topic because, I mean, it was off of strict security.  We've never done that before.  But I got a lot of really positive feedback about it.  So I wanted to acknowledge all the people that said hey, you know, that was really refreshing.  I mean, it was nice.  And while I don't, I mean, I just don't have the resources here to spin off another podcast, I will acknowledge that, from time to time, if there's something that really seems worthy of pausing Security Now!'s flow to talk about, we'll do so, because so many people really enjoyed the little bit of a change.



LEO:  Well, you know, we also do - you know Ray Maxwell.  He's a big fan of yours.  And we also do a show every Thursday with Ray Maxwell where we dig into a subject.  So, and he was, by the way, he was thrilled with the UltraCapacitor stuff.  He talked a lot about that.  And there's, you know, fusion, cold fusion experiments in his neck of the woods.  And he also talked about the PDPs, thought that was so cool.  So there's cross-pollination.  And we certainly on the network will cover these subjects.  But anytime you want to, everybody loves it.  And so you're more than welcome to.  We also do a hardware show with Ryan Shrout.



STEVE:  Right.



LEO:  I mean, we've broadened the network.  And I don't want to announce anything till it's done.  We're going to do a hard science show with somebody who is very well known in his field.  And we'll take a single topic and really dig deep into it.



STEVE:  Wow.



LEO:  So I know people love this stuff.  And it's not - don't feel like the burden's on you to do it.  It's important that we have a security show.  But anytime you want to do anything, I think everybody is very open to that.



STEVE:  Well, I didn't have a single complaint that I ran across.



LEO:  That's good.



STEVE:  Only people saying, hey, this was really fun to do a little walk down memory lane.  Lots of people could relate to their first mini computer contact and experience.  And the whole UltraCapacitor thing, I mean, it generated a ton of interesting dialogue and some controversy from people.  I mean, and we've shared some of those, the ones that I ran across, people saying, oh - well, in fact we've got one in here later on.  So...



LEO:  Good.



STEVE:  ...good stuff.



LEO:  Well, you'll get no complaints from me, either.  And like you, I got nobody saying no.  So thank you, Mat, for the encouragement.



Tom in Vancouver, Washington revealed something amazing.  He says:  Hi, Steve and Leo.  I've been a listener since show one.  I'm also a SpinRite owner.  And I want to leave some feedback about Microsoft's MSRT, the Malicious Software Removal Tool.  We've talked about that a couple of times.  You can run this program on demand without downloading anything particular from Microsoft's website.  Just right-click on the desktop, select New, Shortcut, type MRT into the edit field, and hit Enter twice.  This will create an icon for the MRT tool that you can run whenever you want with no hassles and no reboots.  Keep up the good work with Security Now!.  I guess you could also click Start, Run, and type - here, let me do that right now.



STEVE:  I thought, there's no way that that's going to work, hit MRT with no extension.  And that's, like, in the shortcut, and you hit Enter twice?  So I did it.  And it works.



LEO:  Well, there you go.



STEVE:  And does Start/Run work for you?



LEO:  It does not work on Windows - but I wonder if I have to do uppercase.  He says uppercase MRT.  Did you have to do uppercase?  I don't think Windows is case sensitive, is it?



STEVE:  Oh, it does, I did just put MRT into the Run box.



LEO:  And it works.



STEVE:  Bang.



LEO:  Okay, it doesn't work on Windows 7, but it works on Vista.  Well, you're using XP.



STEVE:  I'm on XP.  Okay, so.



LEO:  All right.  Well, let me try, let me try it on Vista just real quick.



STEVE:  What's very cool, and the reason I wanted to share this with our listeners, is you get - it's got a complete UI.  And...



LEO:  It does work on Vista, by the way.



STEVE:  It does?



LEO:  Yeah.  So it was just Windows 7 it didn't work on.



STEVE:  It's got a complete UI.  I didn't download anything.  One of the things that's there is a "View a list of malicious software that this tool detects and removes."  And it gives you this huge scrolling list box of all this gunk that it will deal with.  And then you click Next, and it says, oh, you want to do a quick scan, a full scan, or a customized scan?  I mean, so it's got a complete UI that we've never seen before because normally it's just running, presumably it's running in the background doing, I guess, a quick scan.  Anyway, I said a full scan.  And so I set it off, and it's got a progress bar, and it shows you how many files it's scanning, and it was cranking away.  I think it was almost done after about three hours.  So it was thrashing around in my system for quite a while.



And I don't remember now what interrupted me.  But I went off somewhere and came back, and it was done.  And to my great surprise, I was met with the dialogue "Infected files found."  And it says, "Files on your computer have been modified by malicious software.  To help repair these files, select the following checkbox and click Next.  Note that some data loss is possible during this process and that the tool may not be able to restore some files to the original pre-infection state.  To view the infected files and choose which ones to repair, click on the View Details link."  So of course I did.



And to my relief, what I saw was it had found seven things, but they were all in my mail attachments folder.  So they were nothing that had gotten out into my system.  But they were things that email had brought in.  And I'm using Eudora, I never click on links, so none of them ever ran, so there was no infection loose in my system.  But what's really interesting, and I haven't been able to perform the experiment yet, because I've worked out a system where I, like John now, I get no spam, I mean, literally nothing unsolicited, I'm very curious to backtrack and find out which things people who I know sent me that I didn't click on, but they were sending me infections.  So it was, you know, really interesting.



So I wanted to encourage - now, again, I'm not running any AV.  So presumably, if I were, those things would have been found and spotted on the way in through something that was doing scanning of my system, either on the actual communications channels or on the hard drive.  But this was - it was fun to run this MSRT that's just sitting there in everyone's Windows machine, presumably being run monthly when Microsoft sends us an update.  Although it's also curious that it took a full scan of my system to find these.  That is, these are sitting here, and the MSRT running by itself isn't presumably doing a full scan.  It's performing some sort of quick scan in order to be time efficient.  It took me running it in full depth mode to find these seven files.



LEO:  So you probably recommend people do that from time to time.



STEVE:  Absolutely.  Why not?  You just - you create a shortcut MSRT or just open your Start menu, as you discovered, and type MRT into the Run dialogue, hit Enter, it pops up, and let it go.



LEO:  Microsoft's moving away from this, you know, on the XP where you hit Command, and you open a Command window, and then you do it, or you type Run.  They're really moving away from that in Vista and Windows 7.  You just have this line, and you type something, and it'll either search or it'll launch something.  So it's very convenient to Start, Run, MRT, on Vista anyway.  And it does indeed work on Vista.  Now, they - and we should underscore this.  They say this is not an antivirus.  This doesn't replace your regular security software.



STEVE:  Right.



LEO:  This is just for, I guess, additional - you know, this is another story that we talked about on TWiT.  And not to go back to the security news section, but it kind of blew my mind that the folks who do F-Protect - who I think are pretty credible people, right, I mean, they're not, you know, these were some of the top security researchers, they're from Finland - they announced last week, Toni Koivunen from F-Secure announced last week that there was a worm, Downadup, that they now...



STEVE:  [Indiscernible].



LEO:  You know about it; right?



STEVE:  Oh, yeah.



LEO:  They now estimate it, it's on nine million computers in just two weeks.



STEVE:  Yup.  Actually, as I understand it, it's not on nine million, it has infected a total of nine million.  Because I don't think...



LEO:  What's the difference?



STEVE:  Well, because MSRT is removing it.



LEO:  Oh, yeah.  Well, and that's the good news.  The January MSRT finds it.



STEVE:  Right.



LEO:  But the problem is, the reason it's infecting people's computers, this was the patch that came out in October.



STEVE:  This was the out-of-cycle serious patch that Microsoft fixed.  And clearly this many machines are not being patched.



LEO:  Right.  Which means it's very likely they don't have MSRT updated, either.



STEVE:  Right.



LEO:  Because that's an update.



STEVE:  Right.



LEO:  So it probably is nine million machines that just, boy, I don't know what you say about it.  It just underscores the fact that people are not running updates, and they really ought to be.  Okay.  MSRT.  We like it.  We like it.



Bill Everson in Green Bay, Wisconsin, he says:  I can't wait to be frightened.  Regarding the EEStor capacitor energy storage system - that's the UltraCapacitor that we were talking about a couple of episodes ago, the one that was not about security but everybody loved.  Hey, we just like - we're just geeks.  He says:  Given all the technical hurdles that have to be overcome to make a battery like this work, it's unlikely that we'll see it in a commercially available vehicle for a few years.  There's one aspect of a capacitor this large you haven't mentioned.  What happens if the capacitor fails or is damaged in an accident?  All that stored energy has to go somewhere.  [Gasping]  Ooh.



STEVE:  It's true.



LEO:  Since a capacitor doesn't have any internal resistance like a battery, the energy will be instantly converted to heat.  What we're describing here is a large bomb.  Before such a device would be allowed into the hands of the public, it needs to be made safe.  This will probably take the form of blast shielding that will greatly increase the size and weight of the unit.  Also non-replaceable internal fuses will be required to limit the fault current leaving the enclosure.  With that said, if this technology ever does make it into a car in a reasonably safe form, I will be among the first in line to buy it.  Well, couldn't they put a big old ground, maybe make, you know, attach it to some big old ground or something?  I mean, they don't have to - the capacitor doesn't have to be barebones, standalone capacitor; right?



STEVE:  Well, the way they build this thing, which is made very clear in the patent, which I read with great fascination many weeks ago before I decided, okay, I've just got to talk about this, is it's hierarchical inside.  So it's - basically they're making a huge - it's a huge array of very small capacitors that are all tied together through a series of aluminum bars in part of this manufacturing technique.  So I'm sure what they're doing is, I mean, I would be very surprised if it weren't internally fused all over the place.  So, I mean, basically all kinds of deliberate fusing inside.



And also I saw an analysis which indicated that, if you followed and did all the math on the volume and the weight of the final battery, that is, a battery of capacitors, a whole bunch of individual capacitor cells, that what they were talking about as the final weight of the whole thing was much larger and heavier than just the sum of the capacitors would imply.  So it sounds like they've already done this, that this is a blast shield, there is a serious weight and space that they've devoted to maybe shock-mounting it and who knows what.  But, I mean, Bill's point is certainly right.  If you imagine that energy is energy and that this capacitor is going to have the same amount of energy, for example, as a tank of gas, well, imagine igniting...



LEO:  That's a good point, yeah.



STEVE:  ...a tank of gas. I mean, you're going to...



LEO:  Yeah.  You're already carrying a bomb around.



STEVE:  You are.  And, see, the advantage of gasoline is, unlike other technologies - there was a Ben Rosen who was a major venture capitalist.  He was behind Compaq, and I can't remember if he's behind Google.  But he was an old-school venture capitalist.  He created a flywheel-based power train where they were - a very cool technology.  They were magnetically levitating a flywheel in a vacuum container and spinning this flywheel up as the energy storage technology. The problem was, I mean, this is literally a whirling dervish.  You do not want to be in an accident where this flywheel, again, I mean, one way or the other you're having to store a huge amount of energy.  So you don't want to be in an accident where this flywheel breaks loose from its containment and just goes spinning off down the highway because, I mean, it would just chew up anything in its path.



LEO:  Yeah.  So, look, I guess this is inherent in the nature of an automobile.  You [indiscernible] a lot of energy to move a two-ton vehicle for hundreds of miles.



STEVE:  Exactly.  And gasoline has the very nice property of not tending to explode all at once if you're in an accident.  People are getting in car accidents all the time.  And you see, in an accident where you see leaking gasoline coming out of the car, it's like, oh, that's - we don't want to let that get ignited because then you can have a big problem.  But fundamentally, as you say, Leo, the need to propel a car, to accelerate and decelerate reasonably and travel a long distance, one way or the other you've got to carry a lot of energy with you.



LEO:  Now, when I talked to Ray about the UltraCapacitor, he was a little more skeptical.  He said, you know, this stuff's been - people have been trying to make this.  In fact, I got a lot of email from people saying [indiscernible], this is another putting water in your gas tank kind of thing.



STEVE:  Hey, it's always that way until it's not.



LEO:  Until it's not.



STEVE:  I completely agree.  I just want it to be true.  I also want there to be aliens and warp drives.  So, you know, and teleportation.  I'm not getting those anytime soon.  I'm just hoping I'm going to get an ultracapacitor.  I mean, I would just buy one just to have one.  It's just such a cool thing.



LEO:  We'd keep one here in the cottage.  Look.  Look what I got.  Don't let it explode.



STEVE:  Well, and you could do neat things, like charging it up when electricity is cheap at night, and then dumping it back...



LEO:  I think you'd see them everywhere.



STEVE:  Yeah.



LEO:  Especially if they were relatively cheap to make.  I think you'd see them everywhere.



STEVE:  Yeah, well, and again, you know, you can have small ones that replace small NiCads in consumer products.  So I'm, again, I want it to be true.  I want there to be aliens and warp drives.  And maybe this will come true in my lifetime.  That, you know, I think that'd be great.



LEO:  ericDuckMan says, "I'm still waiting for my flying car.  They've been promising us that for...."  I just saw an article, somebody said we made a flying car.  What was the - was it a Heinlein novel where they were getting energy from the air with little wavy antenna on - it was like magic?  Do you remember that?  It was a - what was the name of that book?  It was a classic, science fiction classic, and I just - it escapes me.  It was the - I think it was Heinlein because I remember there were Waldos also in that.  Was that "Stranger in a Strange Land"?



STEVE:  That was what I was thinking.  I just bought a hardback copy of "Stranger in a Strange Land," not more than a month ago, because it had been so long since I've read it.  And I think actually I was too young at the time when it first came out to really appreciate it.  I thought, oh, read that again.



LEO:  I need to reread it again, and it's on Audible.  I'm going to download it.  Moving on to another question.  We're going to get ready - get ready for the YubiKey onslaught.  Matt in Walla Walla wants to use YubiKey's static passwords.  He says:  Steve, I really appreciate all your hard work with both the show and your software.  Looking forward to CryptoLink.  I'm very interested in using the YubiKey in the static password role as you described.  After the key is set up with the utility, is that the only password that key can ever provide?  In other words, is it kind of one fixed password?  Or can you run the utility again, get another password, and so on?  I'm hoping that losing that one password, though unlikely, doesn't render the YubiKey useless.  Thanks again.  Matt.  How does it work?



STEVE:  It's completely reconfigurable anytime you want.  If people messed around with the personalization tool from Yubico's website earlier, as I did, you want to go back because they've updated it.  I think it's at 1.0.3 or something.  Anyway, it is vastly easier to use than it was before.  The first one surfaced a highly technical interface to the guts of the way that the API essentially works to the key.  And you'd just look at and go, oh my goodness, I don't have time to figure this out.  They fixed all that.  Now there's a very nice interface.  You basically put in a couple of your own passwords, select some obvious and easy-to-understand checkboxes, and then say Store or Update, and it updates the key.  And you can go back and forth.  You can turn it from a one-time password into a static password and back to a one-time password.



The only thing you cannot do is return it to the original state, where Yubico's servers can be used to authenticate the one-time passwordness.  So if you switch it to static, you are then never able again to use Yubico's servers.  You would be able, for example, to use the authentication that I will build into CryptoLink because you'll be able to tell it what the AES password was that you gave it.  And so CryptoLink will know what the sequence is that it's generating.  But you won't be able to do that with Yubico.



And in static mode you are able to change it as much as you want to.  You give them sort of a passphrase, and then they turn it into something which generates a given static key.  And if you ever [indiscernible] the same passphrase, you get the same static key.  So you're even able to have multiple of those and switch it around if you wanted to.  If you had some reason, for example, for it to be generating one long static passphrase today, a different one tomorrow, and then go back to what it was today, you're able to do that using this little, simple, easy-to-use tool.  I was messing around with it this morning to make sure I had a comprehensive response to Matt's question.  And it works beautifully.



LEO:  Wow.  Very cool.  I have to - I haven't used it much.  And I've really got to get going on this.  I feel bad.  I've got this YubiKey they sent me.



STEVE:  Well, and a ton of our listeners are all Yubikized.



LEO:  I think I want to use it with - that's the problem, is I have so many ways I can use it.  I think I want to use it with a password manager, to provide the password for the password manager.



STEVE:  You're right, provide some very secure way of unlocking your own password safe.



LEO:  And then the password safe generates safe, secure keys.



STEVE:  Right.



LEO:  So it would be a good kind of combination.  Number five, Wes in Boise, Idaho wonders why so little email is secured.  Oh, boy.  Don't get me started.  Hey, guys.  I know you can explain this one for me.  Companies rely so heavily on email now.  The data is very often confidential.  In fact, you see that all the time in signatures now:  If you got this by accident, erase it immediately, it's confidential.  Like that's going to make a difference.  Ideally this stuff would be encrypted.  Many companies have workaround methods via a secure website with just a link transmitted by email.  Well, now, okay.  My question is why is it so difficult to move to a universal secure method to transmit between email servers?  You know, some sort of standard?  I'm constantly amazed that there is no massive movement to push toward secure email by corporations of the world.  What's the deal, Steve?



STEVE:  The other thing that I love in email that I receive is when, down at the bottom, and this is sent in the clear, it says:  This email was checked by such-and-such virus scanner.  It's like, oh, thank you.  Okay.  Seems to me that's a good thing for a virus to tag on the end of the email as it infects it.



LEO:  Yeah, that's really...



STEVE:  Don't worry, this has been checked.  It's like...



LEO:  Well, you know what that really is.  That's just an ad.  The free antiviruses all do that.  It's just a way to, you know, it's an ad.  They're putting an ad in the bottom, really.  You're right, it has nothing to do with security.  Anybody can say that.



STEVE:  And to answer Wes's question, I mean, I don't know why more email isn't secured.  I mean, I know that if I send something - and I don't often.  But if I need to send something through email securely, I will encrypt a document and attach it to wherever it's going.  And so it travels as an encrypted document.  I think really what's the problem is there hasn't been a huge demand, and we don't have easy-to-use standards that allows us to easily, and without a lot of mess, send encryption from point to point.  And mostly email isn't confidential by nature, it's just random conversation.  I mean, I almost never need encryption.  When I do, I use a workaround, as I said, by encrypting something and then attaching it.  But when I think about it, all of my email is just random dialogue with people, and I don't need confidentiality.  But certainly in a corporate environment I can see a much greater need for that.



LEO:  Well, I think interoper- what happens is people default to interoperability.  And so if you're going to use a standard, everybody has to - it needs to be a standard, in other words.  I mean, I could, you know, you could say we're going to sign everything with PGP from now on, and we're going to encrypt it.  But then everybody's not using PGP, it's nothing.  I always sign my emails with the GNU Privacy Guard, GPG.  And I often get emails from people saying I got an attachment .sig.  What is that?  What am I supposed to do with that?



STEVE:  Right.  So it just creates more pain.



LEO:  Right.  I suppose I should put in my signature, "The .sig is an email signature to verify the email.  And if you have GPG it'll work.  If you don't, forget it, you don't need it."  But it's just because there's no standard.  You know, and you could use Hushmail.  You could say corporately we're only going to use Hushmail, which is always encrypted.  But then when you have to send a message to a client, it ain't gonna work.



STEVE:  Yup.



LEO:  So I don't - I think there's really - that's the real issue is we need to commun- but who's going to enforce something like this?  It's an anarchy.  Microsoft tried.



STEVE:  Yes.  Well, and for example, the beauty of something like HTTPS SSL connections is that it was able - it was added later.  But it was, because of the nature of a web client and a server, it could be added completely transparently.  It didn't impinge on the user's experience at all.  Somebody might say, oh, what's this "S" in the HTTP?  Well, don't worry about that, that "S" means secure.  So it is.  It's like, oh, okay, good.  But we have all this - a large variety of email clients now.  And as you said, we're lacking a single standard that everything is able to understand.  And I would argue we're lacking the pressure.  There isn't the pressure for it.  Otherwise we would have solved this problem already.  It's just most people are just gabbing in email, not sending secure things.  And those who do need to send secure things have come up with a proprietary solution of one form or another.



LEO:  Right.  Well, one day maybe this will be solved.  It just seems unlikely to me, just because it's - that's the nature...



STEVE:  Because I don't think there's the need, frankly.  I mean, if there was a need, we would have solved it.



LEO:  Right.  It's the same issue that President Obama is going to face now, which is - I guess they've figured it out.  I'd love for you to find out how is he using his Blackberry?  What are they doing?



STEVE:  There are secure Blackberries available.  There are - there is the technology, and it's NSA approved.  It's a bulkier thing, based on a Palm Pilot.  But there are secure solutions that will allow him to, with full approval of the NSA, to do wireless email.



LEO:  Ah, interesting.  And that probably just puts a bunch of encryption on top of it.



STEVE:  Yeah.



LEO:  Jim in Washington, D.C., he wants to use the YubiKey, too.  Me, too.  Me, too.  I want to use the YubiKey.  But, he says:  Hi, Steve and Leo.  I'm fairly new to the show.  I'm an IBM software engineer working out of D.C.  I'm currently making my way back through your back catalog of Security Now!.  Okay, 179 shows.  That's a lot of listening.  I love the show.  I wanted to say this show has certainly made me much more security aware.  Yay.  Thank you for a very entertaining and informative show.



I've come to love your Perfect Passwords application.  I secure my router at home with it.  I'm currently storing passwords in an encrypted text file.  I thought it would be very cool to have a physical token that would allow quicker authentication using the static password feature of YubiKey.  My question has to do with YubiKey password complexity.  After looking at the YubiKey static password site, the how-to, the PDF guide there on the Yubico website, I noticed that the password examples they were generating were only using a to z in lower case.  I'm wondering, does a YubiKey - can it do the whole ASCII character set?  After listening to the security - or is it, given that you're IBM, EBCDIC?  After listening to the Security Now! discussion about the YubiKey I was very excited, but reluctant to purchase one when I see that it's only a through z because that really decreases the complexity of the password.  We always say use punctuation, upper and lowercase.  What are your thoughts on this?



Also kudos to your listener with the idea of using a concatenation of the static YubiKey in addition to a memorized password.  That would add an extra layer of protection in case you were to lose your key.  Thanks again for the great show.  And I certainly would do that if I were going to use a YubiKey with my passwords vault, have my password plus the YubiKey.



STEVE:  Yes, exactly. 



LEO:  Something you know and something you have.



STEVE:  Exactly.  You've got multifactor authentication.



LEO:  Right.



STEVE:  Okay, now, the situation is even worse than Jim thinks.



LEO:  Whoa.



STEVE:  Because what looks like lowercase a to z is actually only 16 characters.



LEO:  So it can't - oh.



STEVE:  It's, yeah, it's a particular 16-character set.



LEO:  Oh, that's not good.



STEVE:  Meaning that they're only encoding - well, hold on.  They're only encoding four bits per character.  So the reason they chose that, and this is part of what they have in their patent, and it's sort of clever, is that various keyboards in different languages, through the internationalization, map to different scan codes.  And what happens at the USB interface is scan codes are transmitted, not ASCII characters, or EBCDIC or anything else.



So what they had to find was, they had to find a subset of the alphabet that, independent of language, would always have the same scan code.  And so there is - and I remember we - in the newsgroups at GRC when I was doing the Perfect Paper Passwords, there was a whole issue of whose keyboards had which characters because it'd be a problem if you printed out something that wasn't on your keyboard.  You'd have a hard time typing it.  And the same is true with the YubiKey.  So what they did is they came out with a reduced size alphabet, four bits per character.  The static password that the YubiKey can generate is 44 characters long.  So 44 characters at four bits per character gives you a total of 176 bits.  Now...



LEO:  Well, that's enough.



STEVE:  That's a ton.  I mean...



LEO:  I mean, we talk about 128-bit being really secure.



STEVE:  Exactly.  Exactly.  So it's 176 bits.  Which, if you do the math, is just shy of 10^53.  So that's 53 zeroes after a one.  So, I mean, that is a huge number of possibilities.



Now, whatever it is that you provide, for example, if you were using this as a WPA key, that ends up being hashed using the algorithm that was created to turn passphrases into a final hashed key, which is actually used.  So that key, the WPA key, ends up resolving to 256 bits for that security.  But we're talking about the YubiKey being able to generate an absolutely random 176-bit equivalent string, which, while, yes, it's not upper and lowercase and using the full alphabet, you have the advantage that it's going to be universal on whatever device you plug it into, thanks to the work that Yubico did.  And it's 176 random bits.  Which the only thing you can do is brute-force it.  So that's 10^53 different possibilities.



LEO:  I think that's sufficient.



STEVE:  Yeah.



LEO:  And Jim, since you work at IBM, I know that you can understand that math.  Boop.  Right over my head.  Boop.



STEVE:  And I'll mention that when you tag on your own passphrase...



LEO:  There you go.



STEVE:  ...that's all in addition to that 156 bits.  So it's - 176, rather.  176 bits from Yubico plus whatever you add in your own passphrase.



LEO:  I've been using 1Password on the Mac and RoboForm on the PC.  They're both commercial products.  But somebody's been telling me about an open source product.  These are the password vaults that I want to use?



STEVE:  Right.



LEO:  There's an open source free product I think works on both.  That would be awesome.  That would be the way to go.  I hate having to have two different password stores.  And then I have the YubiKey, and I'll be great.



STEVE:  There you go.



LEO:  Jon in Duluth, Georgia wonders how secure that PayPal football really is:  Hi, Steve.  I was thinking the PayPal footballs suffers from a similar vulnerability to that of CAPTCHAs and of Bank of America's SiteKey, you know, click the picture of your teddy bear, which drives me crazy, authentication.  Someone could create - which, by the way, have we not agreed that SiteKey, that idea of having a unique picture and a unique phrase that you know is - absolutely no way protects you against phishing?  We agree on that; right?



STEVE:  Correct.



LEO:  Okay.  It's just a pain.  Someone could create a fake PayPal website or a fake storefront that sends people to the fake PayPal website.  The fake PayPal - actually he's going to describe right now why SiteKey doesn't work.  The fake PayPal site would prompt the user for his username, password, and football token.  That's the fake site.  Now, for this to work you'd have to be fooled by the URL.  But okay.  Next, the website could turn around, take the username, password, and football token, log onto the real PayPal site.  Once logged onto the real PayPal site the fake PayPal site could do whatever it wants.  The football is supposed to be a one-time password, but it doesn't prevent a malicious program from using it that one time.  It seems this would need to be a malicious program instead of a malicious user in order to be able to log in before the token expires.  Right, it has to do it right away.  Is this a vulnerability?  You think there's a way to protect against it?  I love the show.  I've been listening since Episode 1.  Keep up the good work.  It's kind of a man-in-the-middle thing.



STEVE:  Well, that's exactly right.  And the reason I thought this was a great question from Jon, and one for us to discuss, is that it brings up the question of what is it, what problem is it we're trying to solve with a given security device?  Because the problem we're trying to solve, if stated correctly, makes it clear that there are problems that we're not trying to solve, and that we don't solve.  So, for example, what any kind of a one-time password system is trying to do is to prevent a replay attack.  It's trying to prevent somebody from logging your keystrokes and sending them off to some bad people who then use your username and password as logged to impersonate you.  So that's what the PayPal football or the VeriSign one-time token credit card solution offers is that prevents a replay attack.



None of that, however, prevents a man-in-the-middle attack, which is exactly what Jon has described, where you're going to a phishing site that presents you with a copy of the real site's pages, prompts you to enter the information, and because it is intercepted, your attempt to go there, it then turns around and logs in as you, impersonating you.  So he's absolutely right that, similarly, the PayPal football, like a one-time password system, will not prevent a man-in-the-middle attack.  And you mentioned that you'd have...



LEO:  Nothing will.  I mean, that's a tough...



STEVE:  Well, the only thing that will is secure authentication.  And secure authentication is possible, but unfortunately it's still on the user to verify that.  I mean, I notice, whenever I'm - you know I'm a heavy PayPal user.  I've been getting into the antique computer business a little bit lately.  So I've been...



LEO:  You bought more?



STEVE:  I've been poking around, oh, yeah, I've been poking around in eBay.  And any time I get, for example, an email, somebody will - I'll buy a couple things, and I'll go, hey, can you combine these for me into a single purchase.  So then I receive a piece of email that's got an updated price with combined shipping.  And I click the link, and it looks like I'm going to PayPal.  It's like, okay, wait a minute, is this really where I've gone?  I mean, certainly our listeners understand that this is the kind of vulnerability that we have.  And so I will go to the trouble of making sure that I've got a valid certificate chain, that I'm secure in HTTPS as I enter it and so forth.  So the problem is not all of that is done for the user.  And it requires a trained user to go through that.  And for example, you mentioned that, if you didn't notice that the URL were wrong, well, we still have 25 percent of the Internet's DNS servers are spoofable.  And what Dan Kaminsky's revelation about spoofing the cache does is allow you to put in www.paypal.com and go to a malicious site where the URL is correct because you've gone to the wrong IP.  And if the site, then, if you don't notice that you're not on a secure page, then everything looks just fine as you enter your information in.  So...



LEO:  And that's the key, I mean, users have to be trained, I guess.  You know?



STEVE:  Well, yes.  And it's - one of the reasons that I do think that this extended validation certificate is a nice thing, I mean, it is a good thing...



LEO:  To see the green bar, anyway, yeah.



STEVE:  Yes, to have it come up and say - for your browser to take responsibility for the only way I'm going to show you this green bar is if everything matches and makes sense.  And so, I mean, it's more obvious than having to check for the little padlock being closed.



LEO:  Yeah, but you do a poll of users.  I mean, lookit.



STEVE:  I know.



LEO:  Nine million, one third of all users haven't updated since October.  That's why this Downadup's everywhere.  I mean, you do a poll and say what does the green thing mean, nobody...



STEVE:  Yes.



LEO:  I was explaining to Jennifer, who is - actually Jennifer is a good test, my wife is a good test for me because she's smart, but she's a novice user.  And I had to explain to her, this is why you want to hand - I said open the browser, she doesn't even know what I'm talking about.  I said, you know, the Internet, open the Internet.  And I have to explain to her why you want to hand enter URLs and not click links.  And it's not obvious for those users.  And, I mean, we want more and more people to use computers.  But on the other hand, they're having a hard time, frankly.



STEVE:  Yeah.



LEO:  You have to be a security wiz.



STEVE:  Yeah.  We've not made it easy.



LEO:  No.  I don't know what the solution is.  Angus Scott-Fleming, Tucson, Arizona, brings up a good point about WPA laptop keys.  He says:  Leo and Steve, I've been listening to Security Now! since Episode 1.  Another Episode 1-er.  Good stuff.  It's my first-choice podcast when I have time to listen.  And I always go back and catch up when I get a few weeks behind.  I've owned SpinRite since SpinRite 2.  I didn't even know there was - SpinRite 2?  Was I born then?  And use it often.  With respect to your enthusiasm for the secrecy of wireless WPA passwords, when you use your YubiKey to "type in" the WPA passwords in visitors' computers, you really should be aware that nothing in a Windows computer is really secret.  For instance, NirSoft makes a freeware utility - they make good stuff, actually.



STEVE:  Yeah, they do.



LEO:  ...called WirelessKeyView that instantly shows the WEP/WPA keys stored by Windows' Wireless Zero Configuration Service.  Oh, that's nice.



STEVE:  Yeah.



LEO:  They're not - they aren't even hashing it.  It's just stored right in there.  I carry this around in my USB toolkit.  The only time I haven't been able to recover a wireless key using this utility is when the laptop isn't using Windows to manage its WiFi keys.  Ah, that's interesting.  You know, that's actually a compelling reason to use a third-party software.  IBM/Lenovo, he gives an example of the IBM/Lenovo laptops, have a very good wireless profile manager that I always use on them.  But if you're using the standard Windows tool for your WPA passwords, anybody can see them with a tool.  So that means it's not encrypted?



STEVE:  No.  This is a little bit confusing.  What Windows does is it's going to be...



LEO:  It has to store it.  I understand it has to store it.



STEVE:  Right.  And it can't store a hash of it because it needs to use it in order - in the same way that the access point needs to use it.



LEO:  Right.



STEVE:  What it does is it does the same thing the access point does.  It does the same thing that the WPA protocol requires.  There's a funky acronym, PBKDF2.



LEO:  Which is just a little close to PEBKAP.



STEVE:  It is a PKCS standard, public key standard.  Stands for Password-Based Key Derivation Function, PBKDF2.  And it's the second one because the first one didn't allow for arbitrary length output.  We need 256 bits to feed into WPA's 256-bit key for WPA2's AES encryption.  So what Windows does is it runs that algorithm which involves 4,096 passes of hashing, which mixes in the SSID for the access point and basically performs the same function.  And it results in a 256-bit value.  That's what it stores.  So this view wireless key, it's not able to show you the original passphrase, but you don't need it because Windows allows you to either supply the passphrase or the hex for the actual key.  And that's what Windows stores.  So someone cannot get your passphrase, but they can get essentially the digested equivalent, which is enough to get you on the network.



So this was an important point I wanted to make to our listeners is that, again, we want to be sure what it is that - what we are securing and what we think we're securing.  If we give - if we use the YubiKey, for example, or just give a visitor, or we type it in for them because we don't want them to know it, our passphrase, well, their computer has it.  And if they were to run this utility, they could capture the hex of the literally digested passphrase...



LEO:  Of course, yeah.



STEVE:  ...and get back on our network in the future.



LEO:  Of course.  And now then that means it's not Windows.  It would happen on any operating system if you had the appropriate tool to do it.



STEVE:  Correct.  And...



LEO:  And with the Lenovo tool, software would, too.  It's just that the NirSoft stuff is designed for Windows, not Lenovo software.



STEVE:  Correct.  Exactly that, Leo.  So all we're really getting is a little bit of security through obscurity by not using the Windows Wireless Profile Manager and using something else.



LEO:  And for all we know there's some other utility that's widely used that does it with any other store.  So it can't.  So that's the point, is it can't.  It can't encrypt it.  It can't hash it.



Gustin Johnson in Calgary, Canada offers Firefox thoughts and a plug-in suggestion.  I'm not sure why it only just occurred to me now, but isn't Leo exactly the sort of person that should be using NoScript?  Oh, boy.  No.  It seems to me, since he's viewing a large number of sites, his attack surface is much larger.  I agree with you.  Yes, that's true.  I know for me I don't try to add sites to the whitelist since I knew that even if they're safe today, they may not be safe tomorrow.  Also true.



On a related topic, I have a couple of Firefox plug-in suggestions.  Jsview:  This plug-in allows you to view the source of all JavaScript and CSS code sent to your browser.  Oh, that's cool.  ShowIP:  This plug-in displays the IP address of the web server your browser downloaded the current page from.  In addition there are two menus full of options, one accessed by a left click; the other right.  Things like DNS and WhoIs information, Netcraft lookups and more.  Oh, that'd be very handy.  Firebug:  I do know about this one.  This plug-in's a great way to explore how a site is put together.  The Inspect option is quite handy for tracking down errors in your own site.  It is additionally handy for inspecting suspicious elements of websites or their login methods.  Keep up the great work, guys.



So, all right, let me defend myself.  Yeah, you're right, I have a big attack surface.  But on the other hand, I need to - and this is what I mentioned before.  I need to look at sites as you will see them.  So if I have - and I've run into problems with NoScript running, I forget it's running,  I'm not seeing the full site, and I say, well, this site would be better if it had a login page.  And then people say, well, it does.  What are you, on crack?  So I can't - this is why I can't.  I'm risking myself for you.  That's why.



STEVE:  And Leo, we all appreciate it.  I wanted to take this opportunity to give everybody an update just on my own experiences with NoScript and to further promote it.  Having disabled the annoying notification, I'm completely happy with NoScript.  When I go to a site, and it's, like, kind of funky, doesn't seem to be working right, but I don't think I'm ever going to go there again, then I just - I use the "temporarily allow" so that I'm not building up just a huge long list of sites that I've allowed scripting for.  But I have relatively little trouble with it, relative to the security that I know I'm getting by not allowing scripting, which is significant security.



I would - the only solution that would work for you that I can imagine would be a Typhoid Mary computer, you know, one where it's completely separate, and this is the one you don't - that you have configured for minimal security so that you're going to see everything that the websites provide, but you don't allow - and if it got infected, some way you've arranged to sequester it from the rest of your network.  And then again, that's where practicality falls down because it's just not practical to do that.



LEO:  I'm just going to have to live with it.  I haven't gotten burned.  You know, we had an interesting question, I meant to raise this with you, on the radio show this weekend.  It was fascinating.  Guy called in, and he said I'm, you know, I'm a photographer.  And I have a website.  When you go, when you go, when you type into the browser the address of my website, it pulls it up just fine.  But then do a Google search for me - it was Joseph Orsillo, Joseph Orsillo - and click the link.  Whenever a search comes in from Google or Yahoo!, instead of getting my site, you get Antivirus 2009.  You get a popup that says you may have viruses.  Click this link to get scanned.  You never get to his site.  And I said wow.  But that only happens through a Google and Yahoo! search.  Let me think about that.  And actually one of our chatroom guys, [Ben Fransky ph], who has a lot of server experience, says, you know, that sounds like maybe a modified HT access or maybe a modified web server configuration that's looking at the referrer.



STEVE:  Right.



LEO:  And that makes sense.  And in fact we looked into it, and there's a host, a very big host, iPower, who either their configura- I've heard two stories.  I've seen this happen to other people on iPower.  And it may be that their file permissions aren't well set.  Or it may be that their users, because they have a lot of inexperienced users, aren't using good passwords.  But for whatever reason, their .ht access file is being modified to do this redirection.  So, now, if you have NoScript - it didn't harm me because I was on a Mac.  And it made me, wanted me to download this EXE file.  And I know perfectly well it's Antivirus 2009.  It's spyware.  But I imagine a lot of people get bit by this.  And I imagine a lot of websites that think they're fine, they're being - they've been modified.



STEVE:  Right.



LEO:  To run this little script.



STEVE:  Right.



LEO:  It was a shocker.  And by the way, it took him several days to get this fixed.  But finally iPower said, well, we've just changed the password on your control panel.  Which I don't think was sufficient.



STEVE:  Well, I did want to share - I know that we've got listeners who would love to know about these tools, these additional...



LEO:  Oh, yeah, the Firefox plug-ins, yeah.



STEVE:  So it's Jsview and ShowIP and Firebug that really do look like they're useful for further drilling down in sites and keeping an eye on what's going on.



LEO:  We have a new show notes mechanism that's been really great.  We have a TWiT Wiki, wiki.TWiT.tv.  It's a little slow right now.  It turns out that wiki - it's running MediaWiki, which is the Wikipedia stuff.  It's killing our server.  So we're doing a lot of caching.  And Bear, who's our sysadmin, is really working hard to get memcache and some other stuff working on it to speed it up.  But people are keeping show notes while we're talking, Steve.



STEVE:  Wow.



LEO:  And they're doing a great job.  So we now have very thorough show notes on all the shows at wiki.TWiT.tv.  And we'll make sure that those plug-ins, all three of them are linked there.  And I know you'll put them on your page at GRC.com, too.



Kerry, Santa Cruz, California, my old stomping grounds.  Go Banana Slugs.  That's the UC Santa Cruz mascot.  Did you know that?



STEVE:  Santa Cruz was your stomping grounds?



LEO:  Oh, yeah, went to high school.  My dad taught at UC Santa Cruz.  I went to Santa Cruz High.



STEVE:  Cool.



LEO:  We were the Cardinal.  Wonders about needing to trust anyone.  He says:  I recently obtained a Thawte personal email certificate.  I'm wondering how secure these really are.  I realize it's safe enough to protect me from a man-in-the-middle attack.  However, is it as secure as a "trust no one" technology?  In other words, does Thawte or any other certificate provider keep a copy of the private key?  I hope you can answer this.  I can't seem to find any information about it on Google.  I've tried using PGP.  But as you know, it isn't free, and it isn't easy for many users to set up.  I also wanted to thank you for the show.  When I discovered it last winter, I downloaded every edition and listened to them all over again within a couple of months.  I now stay caught up every week.  I use GNU Privacy Guard, which is an open source free PGP clone, by the way.  And that is free and freely available.  And very effective.



STEVE:  Well, to answer Kerry's question, the issue is how was the certificate generated?  As we talked about last week, one of the beauties of the way the public key system operates is it is definitely not necessary for you to give somebody your private key in order to get them to sign a certificate for you.  The idea is that you use - that you generate your certificate request, having had your system produce the public and private key pair.  That is, you do it at your end.  Then you sign the request with your private key and provide the request and your public key to the entity who you're asking to sign, that is to say verify, this information.  They are able to verify that you are in possession of the private key that matches the public key which you gave them by decrypting the signature that you encrypted with your private key, decrypting it with the public key that you provided.  Only if you have a key pair that are matched will that succeed.



So if the Thawte email certificate generation is wholly on their site, that is, for example, if it's a web-based system where you click a few buttons and they say, oh, here's your certificate, well, in that case absolutely yes, they have your private key.  We don't - because they perform all the work for you, and part of that had to involve generating a public and private key pair.  They would be providing you with the private key along with the resulting certificate.  But the fact that they have provided it to you means that they had it.  I don't know whether they kept it.  We hope they don't.  I would presume they don't.  But you are trusting them not to keep it.



The safer, better approach is clearly for you to generate that private and public key pair yourself.  Or, for example, them to provide an application so that you're able to do it on your machine.  Or maybe, for example, it could be an ActiveX control or an applet or a plug-in, for example, that one way or another generates it on your system so that they never get the private key half of that pair.  So it's possible to do it in a "trust no one" mode.  It's also possible that you do need to trust them, based on how the certificate is actually manufactured.



LEO:  All right. Very cool.  Moving along to Sean - by the way, the certificate thing is mostly for Outlook users because Outlook likes a certificate.  But other email programs you don't have to use certificates.  You can use S/MIME or PGP, and it works fine.  Or GPG.  In which case you generate your own codes.  You don't have to use a certificate.



STEVE:  Well, I'm a little bit partial to S/MIME, only because it is built in, and it is a standard that's all there.



LEO:  Right.  S/MIME's what I use, but that's where you get that weird - sometimes you get that weird attachment that baffles people.



STEVE:  Right, right.



LEO:  So there is this kind of, you know, PGP and GPG offer this kind of bulletproof, it works for everybody, but it's a little confusing where you actually - there's actually a hash at the bottom of every message.  But then people go, what is that?  What is that?  But in both cases you're keeping the key to yourself.  Nobody knows your key.



STEVE:  Correct.



LEO:  You publish your public key so that people can send you encrypted email.  But your private key is yours.



STEVE:  Right.



LEO:  Scott Pritchett in Kidderminster, U.K. provides some additional PayPal info.  He says:  Searching for "plug-in" on PayPal.com gives "PayPal Plug-in.  Shop securely online.  We're sorry, but the PayPal plug-in is currently only available in the United States and is not offered in any other country at this time.  More information:  Clicking the "More Information" link gives an out-of-date error.  Nice job, PayPal.



STEVE:  Yeah.



LEO:  I think this proves it's U.S. only, and that by extension one-time cards must be, too.  And that would make sense because the credit card system is a national system.  I mean, what they do in Britain is, it may say Visa, but it's really different.



STEVE:  Right, right.  Anyway, I just wanted to share this because there's been a lot of interest among our listeners about the availability of this one-time credit card system in PayPal.  And this information from Scott really strongly implies that this is just U.S., and that it's not available, no matter whether you download the plug-in first in order to get the menu option on the UI or not.



LEO:  All right, Steve, our last, our final question from Dan in the U.S. of A., and no further information is provided, and you'll see why.



STEVE:  Yeah.



LEO:  Steve, on Security Now! 179 you mentioned better security questions a user had submitted.  It was a blog post.  It was a very funny post.  One in particular perked my attention as a very bad security question:  What was your score on the civil service exam?  As a civil servant myself, I can tell you this is not a good idea because in many states, including mine, civil service results are posted online and fall under public information.  All someone would need - ooh, yeah.  All someone would need is a name, address, and SSN, a Social Security number - of course if they have that you're in trouble anyway - and they can get the results of not only that person's score, but scores from everyone else who took the same test.  Oh.  That's a problem.



Granted, the question could be referencing a score from many years ago.  But there could be a chance the information is preserved.  God only knows how far identity thieves will go.  The odds are they have some of this information already on hand.  Civil servants are subject to a bit of public scrutiny, and therefore the public can get a lot of info from the state, including start dates, years of employment, salary, job title, and so on.  Basing any security question on any employment info, bad idea.  And that's a good point.  That's a really good point.  Anyway, just thought I should give you and the listeners a heads up.  Love the show and love my SpinRite.  I think, you know, these were comedy questions.



STEVE:  They were.  And it's funny, too, because somebody else made a comment similar to this, a little less extensive, who said, you know, I don't think that the security question, "Who did your grandfather vote for in the 1943 presidential election?" is a very good one because how many choices are there?



LEO:  There's only two.



STEVE:  Uh, yeah.



LEO:  That's a very good point.  And I think everybody in '43 probably voted for Roosevelt anyway.  So it's a pretty good bet.



STEVE:  It was, you know, we did intend those just to be humorous.  And I thought there were some that were pretty funny, so.



LEO:  It would have been '42.



STEVE:  I just wanted to make sure that people understood that we were not serious about those.  We were not proposing those as useful security for anybody.



LEO:  It was comedy.  However, I think that there is a good point, which is the best thing to do is to either make up your own question and lie about the answer and remember your lie; or, if you can't make up your own question, just lie and make up, you know, what grade school did you go to, Mortimer Snerdly High, and make it up.



STEVE:  Right.



LEO:  And then nobody's going to guess it.  It's not going to be on record anywhere.  It's only in your mind.  It's just like another password.  But I guess the point of security questions is they're easy to remember the answer to, which of course makes them inherently insecure.



STEVE:  Which defeats the security, yeah.



LEO:  That's the problem.  Security, convenience, never the twain shall meet.



STEVE:  Indeed.  They are not friends of each other.



LEO:  I'll tell you one place you should go, GRC.com.  That's your friend online for security information; those great programs like ShieldsUP!, Shoot The Messenger, DCOMbobulator, the wonderful Wizmo - which again I recommended on the radio show this weekend because somebody wanted a quick way to - was it to shut down?  Oh, no, I know what it was, reveal his desktop.  And he lost the reveal the desktop icon.  I said, I bet you Wizmo can do that.  Wizmo can do everything.  Anyway, it's all there.  It's free.  And of course when you're there, don't forget, it's not free, but it's a must-have, SpinRite, the world's finest disk maintenance and recovery utility.  Really the only one that does what it does.  GRC.com.  Also have show notes there, including Elaine's great transcriptions - hi, Elaine.  Does she have to write that when I say that?



STEVE:  Yeah, she does.  She's very faithful about this.



LEO:  Hi, Elaine.  [Hey, Leo.]  Elaine's really great.  [Awwww.]  She does a great job with the transcriptions.  We also have 16KB versions for the bandwidth-impaired.  It's all at GRC.com.  And if you want to ask a question next time in Episode 182, two episodes hence, SecurityNow.com - I'm sorry, GRC.com/feedback.



STEVE:  Exactly.



LEO:  That's the place to go.  Well, Steve, go to bed.  Take a nap.  You were up late partying, celebrating.  We will talk to you again in a week.  And by then you'll have recovered.



STEVE:  Yes, and we'll have another great episode, I am sure.  I have no idea what it'll be about, but it'll be good.



LEO:  There's always something to talk about on Security Now!.  We'll see you next week.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#181

DATE:		January 29, 2009

TITLE:		Crypto Rehash

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-181.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION: Before tackling the complete description of the operation of the SSL (Secure Socket Layer) protocol, this week Steve and Leo take a step back to survey and review much of the cryptographic material they have covered during past 3+ years of podcasts.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 181 for January 29, 2009:  Crypto Recap.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show where we talk about - it's the geekily informative show, where we talk about all things security oriented with Mr. Steve Gibson, who is the king geek here.  Hi, Steve.



STEVE GIBSON:  Hello, Leo.  Great to be with you, as always.



LEO:  I have - where did I put it? - my Steve Gibson cap now with a little bill on it.  Yeah, in France I got - you know how you wear that little cap?



STEVE:  Oh, yeah, yeah, my little chapeau.



LEO:  Your chapeau.  I got one in - my wife gave me one for Christmas.  So now I have a Steve Gibson hat to wear.



STEVE:  Ah, cool.



LEO:  Today we're going to need our thinking caps because we're going to recap.  Get it?



STEVE:  [Laughing]  Ouch.



LEO:  Yeah, that was pretty bad.



STEVE:  Yeah.  What I want to do is I want to do a couple seriously propeller-spinning episodes, one to discuss something we've never discussed before, a cryptographic component known as a keyed message authentication code.  And that's the last piece we need for understanding all of the SSL protocol, which is going to be the episode that follows that one.  But before we plow in, I thought, you know, let's just sort of step back for a minute and do a cryptographic review, sort of a review of where we've come, what we understand, just sort of an overview.  Everyone can - maybe this one they'll only have to read the transcript once to get it all.  But I just sort of thought, before we go any further, let's sort of just lay down a little bit of very clear foundation about where we've been.



LEO:  Sounds like a great idea.  In fact, I was saying before we started, when you mentioned that, I said this is how I learn.  I learn - and I guess the best term is "recursively," where you go back again and again, and it gets a little deeper and deeper and deeper each time.  I can't absorb it all until I kind of learn some stuff, apply it, and then realize where my gaps are.



STEVE:  Right.



LEO:  That's how you learn computers, I guess, and programming, too, and all of that stuff.



STEVE:  Oh, I think so.  In fact, one of the best methods now we're seeing, when I look at curriculum, programming curriculum, they talk about, like, starting early, getting students to, like, write simple programs, get them on the machine and doing things.  They'll sort of inherently sort of explore and mess around and change the code and see what happens.  But instead of, like, loading people down with a whole bunch of theory first, where you're sitting around saying, wait a minute, how do I use this, what do I do with this, you get them right in and sort of hook them, and then add successive layers of successive refinement.



LEO:  Yeah.  Well, we're going to do that.



STEVE:  Very fractal.



LEO:  When we - fractal.  There maybe is a better word.



STEVE:  Fractal learning.



LEO:  Well, fractals are recursive, too, aren't they.



STEVE:  Yeah, exactly.



LEO:  So maybe for those of you who have heard our other crypto discussions, maybe it kind of gave you a beginning.  But we're going to recap, refresh, revive...



STEVE:  Review.



LEO:  ...review.  All right.  Time, Mr. G, to - first of all, I guess, before we do - I talked about our recap on encryption.  Maybe - are there any updates from last week, any...



STEVE:  Oh, yes.  Well, don't know how long or how often you've had your Macs turned on.  But there was a very big - for me on the Mac platform I think it was 76MB - it's a major update, Version 7.6, to QuickTime.



LEO:  Oh, yes.



STEVE:  Which fixed seven different critical remote execution vulnerabilities.



LEO:  Oh, you're kidding.



STEVE:  And one with the MPEG-2 player.  So it's very important.  It's across all - it's both platforms.  Both Mac and Windows versions of QuickTime really do need to get updated.  The exploit is just visiting a site.  Most experiences will start playing QuickTime without any user interaction.  That is, QuickTime is there, and it's ready to go.  When you go to a site that's got some QuickTime content, it immediately plays.  So there's some concern that this is going to get exploited.  At this point there isn't anything known that is exploiting these.  But Apple had been informed as early as, like, middle of last year.  So these are a little while in coming.  So I would say it's absolutely worth taking the time.  When I turned my Mac on, it announced that there was the update, which I was expecting it to.  But it was so big, and it was, like, 10 minutes before we started recording, I thought, eh, I can - I'll wait till afterwards.  But...



LEO:  Yeah, I downloaded it on all my machines, yeah.  And I didn't realize it was - I knew it was a security update.  I didn't realize there were seven remote exploits.  That's incredible.



STEVE:  It's a biggie.  Also there was a note that I saw that I thought was interesting, just to sort of warn our listeners.  There are illegal copies of Apple's iWork '09 appearing on filesharing websites.  It's estimated about 20,000 users have downloaded this.  The bad news is it contains a trojan...



LEO:  Oopsies.



STEVE:  ...known as iServices.A, which runs with root access.  When you run it, and it installs itself with root access, it downloads - it contacts remote servers, downloads a bunch of additional software to deeply infect your Mac with a botnet.



LEO:  You know, this is taking advantage, I think, of the ARD Agent, the Apple Remote Desktop Agent bug that's been around for some time.  And the key on these things is, still on the Apple, you've still got to get - you've got to trick the user into installing it.



STEVE:  Yes, exactly.  But, and again, I just wanted to warn people that there are - this Apple's iWork '09...



[Talking simultaneously]



LEO:  ...BitTorrent, you nitwits.



STEVE:  Exactly.  Exactly.  And I've never mentioned it.  I've referred to pirated copies of SpinRite a few times.  We have been sent trojans which were called SpinRite, and people anonymously said, hey, I just wanted to let you know your SpinRite trashed my machine, here's a copy of it.  And it wasn't SpinRite at all.  So it's like, oh, you really do need to be careful when you run things that you get from questionable sources.



LEO:  This is a very common way for spyware folks and virus authors to get you to install their stuff.  You're installing something from somebody you don't know.  This is one of the five rules I tell people on the radio show.  Do not accept files from strangers.  And BitTorrent is accepting a file from a stranger.



STEVE:  Yes, oh, exactly.  And in fact remember that last week, when I ran Microsoft's - the MSRT tool, and it found seven viruses sitting in my email attachment folder.  I had never run them.  They were there.  There was no one loving them, to start them and let them go.  But, and so nothing had gotten into my machine.  But some email that I received brought those in.



LEO:  Wow.



STEVE:  So that absolutely happens.  You know, we've remarked in the past on this show about how can it be that people don't have Windows Update running, for example, with regard to this Confickr worm, also known as the Downadup, which has infected at this point tens of millions of machines.  It's still causing problems.  And remember that this is - it's using something that was patched in October.  Well, I ran across an interesting discussion about this because five hospitals in Sheffield in the U.K. had more than 800 of their 7,000 PCs infected by this worm.  Okay?  Why did they have Auto Update disabled?  It turns out they had administratively disabled Auto Update, on purpose.  Okay.  Are you sitting down?



LEO:  Because?  Because?



STEVE:  Because, in the middle of surgery, a bunch of their PCs in the operating theater...



LEO:  Rebooted.



STEVE:  ...rebooted and shut down life-critical equipment which was running on Windows.  It's like, oh, god.



LEO:  The same thing on the TriCaster.  The same thing has happened to me many times.  Our stream has been shut down.  I finally had to turn it off on my machines.



STEVE:  Yeah.



LEO:  This is a stupidity that Microsoft - now, I think they've fixed this, this automatically installing and rebooting.  Haven't they?



STEVE:  Well, it's still an option.  I mean, I noticed that on machines that I don't use often - like I've got a little PC set up with a stamp printer and label printer and a little scale for, like, mailing things.  And when I turn it on, and that's only every couple weeks, it'll say, oh, I've got updates.  And I've got mine set not to auto reboot.  But it is a user-choosable setting, like just notify me, or download and notify me but do not install, and then finally is, like, do the whole thing.  And so what I - what happens is when I'm shutting it down, it'll give me the option to install updates and shut down.  Which is really nice because I can then say, that's what I want, and I walk away and leave it, and it does its thing and then turns itself off.



LEO:  I have a download - this is what I ended up doing.  Download and notify on all of them.



STEVE:  Right.



LEO:  But never install.  In fact, I remember it was doing it with - as we recorded shows it would say, okay, in 10 minutes I'm going to restart.  And I'd have to - every 10 minutes I'd look, click, click, click.  So, yeah, I think that's a little annoying, Microsoft.  But so the default is to do that, I think, as I remember.  But the notify - download and notify is good.



STEVE:  Right.



LEO:  Because it says we've got new updates.  Let us know when you want to install them.  And it will even do it when you shut down automatically, right, if you just - because it puts that little shield up on the shutdown button.



STEVE:  Yes.  And, well, it does in Vista.  It doesn't under XP.  But you do this...



LEO:  No, it does in XP.



STEVE:  The shield?



LEO:  Yeah.



STEVE:  Okay.



LEO:  Maybe that's something new in the Service Pack 3, because we have one XP machine.  And I saw that shield, yeah.



STEVE:  Good, good.  Anyway, so for anyone going into surgery, a good idea...



LEO:  Ask if it's using Windows.



STEVE:  ...is to ask, yes, ask your hospital, do you have any Windows machines on the Internet that'll be in the operating room with me?  Because I'd like you please to disconnect them from the Internet so they don't update themselves and reboot in the middle of surgery.  That's just nuts.



LEO:  That's a good point.  Why are they on the Internet?



STEVE:  Exactly.  They're on the Internet in the operating theater.



LEO:  That's a very good point.  That's a dumb thing.



STEVE:  Yeah, exactly.  I mean, they were on the network, receiving updates.  It's like, oh, goodness.  And I wonder if they might have the Downadup worm, and they're participating in a botnet, and maybe have time to keep your oxygen levels regulated.



LEO:  No reason for a computer in surgery to be on the Internet.



STEVE:  Yeah.



LEO:  I don't want it surfing the 'Net.  Maybe the doc wanted, like, to look up Wikipedia on how to do this.



STEVE:  Streaming his classical music while he...



LEO:  Betcha, you know what...



STEVE:  ...opens up your chest.



LEO:  ...exactly what it was.  He's watching TWiT Live.  That's exactly what it is.  Stop watching.  Go back to work.



STEVE:  Okay.  We have some errata, as well.  A poster in the GRC newsgroups, using the handle "ferrix," has been working with the YubiKey at a relatively low level for some time, and responded to last week's discussion of the limited size of YubiKey's static password, which I think was 192 or 176, I think it was 170-something bits.  He said it is, although he doesn't understand why the little customizing personalization app that Yubico produces generates these shorter static passwords, he is absolutely sure that it is possible for the YubiKey to generate a full 64-character, 256-bit static password.  So it is as long as any passphrase you could ever give to, for example, a WPA router.  It ends up hashing it down into, actually into a 128-bit key for AES.  So this is twice that long.  So it's absolutely as secure as you could ask for.  And maybe Yubico will fix  their little gizmo.  He's got a script which he's been posting links in our newsgroups.  We have a GRC Security Now! newsgroup which sort of follows the show, where we have some dialogue about what goes on.  And so that's where he's been participating.



LEO:  Excellent.



STEVE:  Somebody else made a note that our recommendation, our Audible recommendation, ["The 7 Habits of Highly Effective People"], was not available to him in Australia.



LEO:  Oh, I have to say this every time.  I should be much more clear about this.  Everything we talk about is U.S.-only.  The Audible ads are paid for by the U.S. agency.  And any deals or offers we do may be available in other countries, but we do not guarantee.  So I don't want say U.S.-only because it isn't necessarily U.S.-only.  And the real problem is not Audible.  It's the way the book publishing industry, which is a throwback to, like, the 1850s, the way the book publishing industry works, it's hyper-aware of national boundaries.  So I'll give you an example:  Harry Potter was published in Britain by, I think, Penguin, published in the U.S. by Scholastic.  J.K. Rowling, the author, goes to each country and negotiates a different deal in each country.  No publisher is international.  I mean, Penguin is.  It's owned by Pearson, which is international.  But each deal is national.  So when Audible makes a deal for the recorded rights, it goes to the national publisher.  The one in Australia is different from the one in the U.S.



STEVE:  Wow.



LEO:  They may not even have an audiobook.  When you got the audiobook of Harry Potter in England, Stephen Fry was reading it.  When you got it in the U.S. Jim Dale was reading it.  They're different versions.  They recorded two different versions.  And you can't get one in the other country.  So it's just - it's not Audible's fault.  It's the way the crazy publishing industry works.  It's likely that they didn't have rights for an audio recording in Australia. So I do apol- I'm not saying this to be angry.  I apologize.  And I should, I guess, from time to time I do mention that, whenever we're doing the Audible ads, these are for - generally these offers are U.S.-only.  But I don't say it because sometimes they work in other countries, and I certainly want people to take advantage of them if they do.  So, yeah, I'm sorry.  We have that deal again.  I'll talk about it in a bit.



STEVE:  Oh, cool.  And my last little bit of errata is that I received a nice notice in the mail a couple days ago.  CryptoLink trademark has been granted.



LEO:  Congratulations.



STEVE:  So I have the trademark for CryptoLink.  That's been underway for some time.  I got the domain, CryptoLink.com.  Not that I expect really to use it.  Everything will be GRC.com.  But for a product like this, which I expect to be significant, I wanted to grab the associated domain.  So that I've had.  But now I also have the trademark for that.



LEO:  I should show people my - you get a nice, suitable-for-framing thing, don't you, with the trademark on it.



STEVE:  Yeah.



LEO:  I should frame the TWiT ones.



STEVE:  Actually my law firm keeps it for me because it's better for them to have it than - I'd be like, okay, where did that go?  I'm sure that's around here somewhere.



LEO:  I can see mine.  It's on the shelf right there.  And you get a little, I don't know, I guess you got one probably too, you get - no, I guess this was the corporate seal.  I love that, too.  I stamp things with my corporate seal.  I'm such a kid.  I never thought I'd have trademarks and a set of corpor- this is silly.



STEVE:  Good stuff.



LEO:  Yeah.



STEVE:  And then I do have a fun Security Now! testimonial.  This one, the subject of this one was "SpinRite Equals Marriage Enhancement Tool."  So I wasn't quite sure what he meant by that.  But he said - he's a Security Now! listener.  He said, "Steve, I've been listening since day zero to Security Now!, 'As the Worm Turns,'" which I remembered was the first episode we ever did.



LEO:  Was it?



STEVE:  I think we talked about a major worm on the 'Net.



LEO:  Oh, wow.



STEVE:  Anyway, he says, "I owned Version 5 of SpinRite, and I thank you for the upgrade to Version 6.  It's my normal process when I get new hard drives installed to run SpinRite at Level 3 and only change levels when I detect problems.  So I recently gave my wife a mega-souped-up system, blue LEDs, blue neon, 2+GHz AMD, 2GB of RAM, and a 250GB SATA Seagate drive."



LEO:  Yeah, baby.



STEVE:  "After the OS install, security lockdown, and transferring from backup all of her class documents, our multi-gigabytes of family pictures, et cetera, I ran SpinRite at Level 3, and all was well.  Well, that was some time ago.  My wife wakes me up one night, stating her Win2K system locked up.  And when she tried to restart, the BIOS just sat on the SATA drive detection screen.  Resetting the PnP and VRAM nearly got the OS to boot.  But the F8 screen progress bar was [chuckily ph] progressing forward, then locked.  And it had been several weeks since she last ran the Robocopy backup to server BAT file.  So while running at Level 4, SpinRite began listing countless entries of SpinRite-detected damaged sectors dot dot dot, and all the data has been recovered dot dot dot.  And after about 24 hours, SpinRite finished the 2.5GB C partition with more than 50 "R" entries," meaning it found problems and fully recovered all the data.



"I reran at Level 5 on C, root, which finished this time with no errors after two hours."  Which meant that, you know, SpinRite did fix them during its first pass, and he was rerunning a second pass and found no problems because of the approximately 50 recoveries that SpinRite had done the first time.  He said, "My wife was then able to happily boot into her system, check the financial websites that were needed, and all of her files on the D partition were once again accessible.  Thank you again, Steve.  Your expertly developed program allowed for a Merry Christmas night indeed."  And this is signed Christopher A. H.



LEO:  And he's a guy after our own heart.  He's running Windows 2000.



STEVE:  Yup.  2K on a super-hopped, speeded-up, all-blue-glowing neon LED machine.



LEO:  Isn't that funny.  Now, I wonder how safe that is to run Windows 2000.  They aren't patching it anymore, are they?  Or are they?



STEVE:  Frankly, I don't think I have a Win2K box around.



LEO:  I think if you lock it down, I guess you're probably - you know, when I set up my mom with Windows - she's on a Mac now.  But when I set her up with Windows, that's exactly what I did.  I set her up with Windows 2000.



STEVE:  And he talked about security lockdown.  So, yeah, you probably move to Firefox, and you don't use IE, and you maybe use Eudora instead of Outlook.



LEO:  It's not that, though.  I worry about the fact that there may be holes that aren't getting patched.



STEVE:  Yup.



LEO:  You know?  And then it doesn't require any effort on your part.  It's, you know, like Downadup or Confickr just [sound effect]...



STEVE:  Gets you.  Yup.



LEO:  So let's talk about encryption.  We've done many - how many shows have we done on encryption technologies?  Seems like a dozen.



STEVE:  I would say over the last four, or three and a half years, we've touched on the topic often because it's, I think, certainly it's interesting.  And we rely on it constantly.  What we're going to do in several episodes from now is go over in detail, I mean, literally the packet-by-packet operation of the SSL protocol.  SSL is - we've talked about it many times - Secure Socket Layer.  We've talked about asymmetric encryption, symmetric encryption.  We've talked about recently, of course, digital certificates and certificate signing and the recent exploits against the MD5 hash and how that has affected the integrity of SSL.  But there is no protocol, no security protocol that any of us use more than SSL.  What we've never done is look at exactly how it works.  How does it provide these features that we all, to varying degrees, take for granted?  So I wanted to do that.



But before we do that, we need to lay a little bit more foundation.  And before that I thought, you know, I see people who are - who send notes saying, wow, you know, I had to read the transcripts of that episode three times and, like, slowly, and repeat it to myself in order to understand what you guys were talking about.  So I thought - and because, as you mentioned, Leo, we've had so many discussions about various aspects of security, and frankly very little repetition among them, I thought this would be a nice time, before we go any further, to just sort of have a little bit of a timeout and say, okay, hold on, let's step back from the minutiae and from the detail and do sort of a review of the major concepts and components of this that we've talked about over the last three and a half years.



LEO:  That's - I'm ready for it.  That's fantastic.  Because, you know, I've pieced it together, listening to the show.  And, you know, I've been here for every episode.  But it's nice to kind of get an overview and see if at all the pieces fit together, and then fill in the holes, too.



STEVE:  One of the analogies that we've used often, I think, that I always get a kick out of, is the Mayberry RFD Opie and Aunt Bee characters because they remind us, by looking at what security is implicit in physical, real-world contact, you're sort of able to better understand what is missing from that implicit security when you get on the Internet.  And of course in a physical model, where for example Aunt Bee calls the pharmacist to say hey, I've asked Opie - I guess that was her grandson? - to come over and pick up my prescription.  So the pharmacist knows Aunt Bee, knows Opie, recognizes them on sight, recognizes Aunt Bee's voice on the phone, and so there's authentication happening.  She dialed the pharmacist, so she's got a good reason to believe that that's the pharmacist on the other end, even though there may be multiple pharmacists, and she may not know them, which one, but she initiated that connection.  So she has some reason to believe that that's who she's talking to.  Opie has been around town for a while.  He knows where the pharmacy is, he knows that the pharmacist knows to expect him and so on.  So in the real world, we have a number of things that we sort of tend to take for granted, all of which are missing in this increasingly sort of hostile, security-hostile and predatory environment of the Internet.



One of the things that we need to do is to be clear about the so-called "threat model."  That is, what is it that we can do, what is that we intend to achieve, and what things are we not trying to do?



LEO:  So in other words, constrain the - not try to do too much, or do stuff that's not needed.



STEVE:  Well, yes.  For example, in our discussions of security we've made the implicit assumption, for example, that it's the communication between two endpoints that we are trying to protect, but that the endpoints themselves have not been compromised.  And the point is, if the endpoints are compromised, the game is up.



LEO:  Right.



STEVE:  I mean, if something, for example, a keystroke logger, a keystroke logger will log your keystrokes as you're typing them.  It doesn't matter if, once they get on the wire, they're authenticated and secured and boy, you know, nobody can get them during transit.  Well, they got them beforehand.



LEO:  The other reason for that is it's extremely difficult to protect yourself against physical access.  I mean...



STEVE:  Well, yes.  And the other example at the other end of this connection is we keep hearing how remote facilities, whether they're, for example, Network Solutions we heard about the other day, and other sorts of attacks at the remote end, like loss of confidential security information.  We hear about how that information is getting away.  Well, once again, it may have been absolutely secure and authenticated, and we had a fantastic experience hooking up to our banking site, and nobody was able to get the data as it was going from us to there.  But unfortunately, it then sits there on some database on the banking servers, where it's vulnerable.  So, again, in talking about what it is we're trying to protect, we need to delineate what it is, what the threat model is, and exactly what it is we're hoping to achieve.



We also make some assumptions.  We make, for example, one assumption is that there is non-infinite computational power.  That is, that there are not literally infinite resources that can be applied.  Because all of the crypto that we've been talking about, for example, every single one of these things we've been talking about is subject to brute-force attack.  No matter how long the key is, even though 128 bits or 256 bits, that's a lot of combinations, that's two raised to that power combinations.  Well, it's not infinite.  It's still a number that we're able to write down.  And if we had time, we could test them all.  One of them is the right combination of bits.  One of them decrypts this.  It makes you even feel a little uncomfortable to say that.  It's like, wait a minute, you mean there's an answer to - there's a way to crack this encryption.  Yes.  It's you try all the combinations.  But the point is, we've made it so difficult, there are so many combinations, that you can't, it's not feasible in a reasonable amount of time to try them all.  But it's always worth remembering that it's not perfect security.  It's just really, really, really, really, really good.



LEO:  Well, there's no such thing as perfect security.



STEVE:  No, there is.



LEO:  Is there?



STEVE:  Well, there's the potential for it.  We talked a long time ago about a one-time pad.



LEO:  Right.



STEVE:  And if you had a one-time pad that was absolutely random, and the other person at the other end had a matching copy, that is, you're not basing it on a key that's generating pseudorandom sequence, it's truly random, and the other person has it, then - oh, and you absolutely never reuse it.  I mean, again, there are restrictions.  But there's absolutely no way to crack that.  Period.  Absolutely no way.  Now, the only thing you could do would be to, like, guess every character of the message.  But then you could make up any message you wanted.  You have no way of knowing which is the right message except by the message length, and you could also pad the length in order to throw somebody off.  But in fact there were times during various world wars where this approach was used.  You know, ping-pong balls were chosen completely at random.  Unfortunately there was one instance where they literally were using ping-pong balls, and there was a bias in the ping-pong ball generator, so that caused a problem.  But the biggest mistake made is ever using the one-time pad a second time.  It's called a one-time pad for a reason, not just a not-often pad.



LEO:  Right.



STEVE:  So - go ahead.



LEO:  If somebody - you could still be compromised by somebody with physical access; right?  I mean...



STEVE:  Oh, that's a very good point.  Because, again, we were saying that our end points are secure.



LEO:  Right.  You could have perfect security between points, of course.



STEVE:  Yes, exactly.  And - exactly.  Now, another - a couple of other instances where we're assuming non-infinite computational power is with factorization.  There are two things that a lot of our crypto depends upon, that is, our public key crypto.  One is that it is very easy to multiply two prime - two big prime numbers together.  But it is, as far as we know, there is no similarly easy way to unmultiply the result, that is, to factor that big multiplicand into its two components.



LEO:  Its constituent parts, yeah.



STEVE:  Yes.  And so much of cryptography, surprisingly enough, depends upon that one simple fact, that it's easy to multiply two big numbers.  It's extremely difficult and time-consuming to figure out which two big prime numbers the result was made from.  And tons of time and brain power has gone into this, and no one's found, I mean, and there's lots of factoring theory and lots of factoring, like, improvements.  But those are, like, so far away from giving anyone the leverage that weakens our crypto that it's holding up very well.



The other interesting sort of like one-way function is that it is also very easy to take an exponentiation, to raise something to some power.  It's extremely difficult to go the other way, and that is to take the logarithm, to get the discrete logarithm of something raised to some power, and then you do a modulus function and take the remainder of this modulus function.  That's something that, again, we haven't been able to reverse.  And that's another sort of fundamental hard problem that we're assuming no one is going to come up with an easy solution to.  If they did, that would be bad.



LEO:  Yes.



STEVE:  Because we'd be in serious trouble.



LEO:  Well, every once in a while, when people talk about things like quantum computing, they say, "And it's so good, it could factor these big prime numbers, and security would be changed forever."  But so far it's not - nobody's been able to make one.



STEVE:  No, no.  And then another thing about the design of a secure crypto system is you want there not to be any single point of failure.  That is, you'd like to have, in a communication network of people communicating, you would - if one dialogue between two parties were to somehow be cracked, you would like all of the other dialogues between other groups of parties, even involving the same endpoints, to retain their security in the face of that crack.  That is, for example, if the security only involved everybody using a single preshared key, a single static key, then that would be an example of a system not well designed because the disclosure of that single key would not only allow you to crack the dialogue that was your target, but all the other dialogues that were unfortunately sharing the same key.



So one of the other things that we've seen and that we will be talking about shortly in a couple weeks, is this notion of coming up with some key agreement somehow, but never actually using that key for your live encryption.  Instead you'd always use derivative keys that have various limited lengths of life, so that you're not actually using the sort of like the root key that you originally came up with.  And so if we assume that the endpoints are secure, that is, they've not been compromised because, as we said, keystroke loggers get in before the encryption, database compromise happens after this encryption, and so we're limiting ourselves to this notion of, okay, let's assume that we have control of each end, but we have no control at all of the link between, i.e., the Internet.  So that means that our communication is subject to having bits dropped, bits added, bits changed, and even bits replayed, things, packets replayed.  And so we need to also guard against this notion of an attacker somehow, like, redoing something.



For example, say that a communication link with a server involved transferring a chunk of money to PayPal.  Well, we would like to prevent somebody recording that whole dialogue, even if they can't understand it, and replaying it to transfer the same amount of money again.  So guarding against a replay attack in addition to the idea of injecting new traffic, modifying traffic, or dropping traffic is another aspect of what any truly secure protocol would be able to do.



So finally, let's step back a little bit and say, okay, what do we mean by security?  Well, security in this context, in the context of this threat model, where we're wanting to protect communications between two endpoints over the Internet in the face of injection, dropped traffic, modified traffic, and replayed traffic, we want three things.  We want confidentiality of our communication, that is, we want nobody, no matter what they do, no man in the middle, whether they're able to intercept the traffic and see everything we do, change it in any way, we want them to be absolutely the case that we're going to have...



LEO:  I heard Fred Flintstone, so I [indiscernible] server's back up.



STEVE:  There's Fred in the background, yup.  Somebody purchased a copy of SpinRite.  Thank you.



LEO:  I love Fred [laughing].



STEVE:  Well, I did leave him unmuted this time because I know you get a kick out of that thing, so...



LEO:  It makes me laugh every single time.  I love it.  I'm sorry.  Go ahead.



STEVE:  Makes me smile every single time.



LEO:  Yeah, I bet it does.



STEVE:  So what we want is we want confidentiality.  We've looked at ways, well, okay, confidentiality.  We also want to guard against the message that we're sending being modified.  So we need to verify the message's integrity.  And lastly, we also want to authenticate the endpoints.  We want to make sure that at least one, maybe both, are who we think we're talking to.  We talked about this with regard to phishing attacks often, and the Kaminsky attack against DNS that has you talking to a wrong server, to certificate problems.  So we want no one to be able to hear what we're doing.  We want no one to be able to change what we say.  And we want to absolutely be sure we're talking to the endpoint we think.



And so if you think about it, all of that is implicit in real-world communications, in the Opie and Aunt Bee Mayberry scenario.  In this case, confidentiality in that example isn't required.  But the other things that we take for granted about a physical real-world communication are present.  And so what we're really trying to do is we're trying to extend that model across the Internet.  With regard to confidentiality, we have talked in the past about encryption, the notion of using - of symmetric encryption, where we share some sort of a key, and we use the same key at each end, thus the symmetry, to encrypt and decrypt.



We've talked about asymmetric encryption, also known as public key encryption, because in the general case we're normally keeping one key secret, the other key is private, although neither has to be the case, but that's normally the way it's used.  And because asymmetric encryption is so computationally burdensome, we don't asymmetrically encrypt an entire long message.  That would just take forever.  Instead what we do is we choose a random symmetric key, and we use the asymmetric encryption just to encrypt it.  That way that allows us to transport it to the other end, where the public key, or asymmetric encryption, is used to decrypt that.  That creates a sort of a transient shared secret, a shared secret that is just going to be used for some length of time.  We're able to get it to the other end, even in full view, by using public key encryption.  Then it's used in order to symmetrically encrypt and decrypt our communication.



And finally, key management is an aspect of confidentiality, whether we're using, as I just gave the example of using, public key encryption to encrypt a shared secret.  There's another approach, which is known as "key agreement," where it's possible for the ends to publicly disclose what they're sharing, yet maintain full confidentiality.  So that someone, an attacker, can see a dialogue going back and forth in the air, essentially.  Yet even so, someone watching it can't intercept or can't end up with the knowledge of the key which is agreed upon.  So those are sort of the aspects of confidentiality, encryption and key management.



The next thing, the second of these three, of confidentiality, message modification prevention, and endpoint authentication, is this message integrity.  We've talked about using hashes.  Of course we've talked about MD5 a lot, the notion of creating a signature.  And there are the SHA-1 hash, there are more modern hashes that use larger hashing results that are increasingly secure.  So...



LEO:  Yeah, in fact that's what PGP does, right, when I'm using it to sign as opposed to encrypt.  It's hashing it.



STEVE:  Yes, exactly.  And so the idea is that we've talked about a hash being a digest of a much larger communication, where it reduces it to essentially a fingerprint, something such that any modification to the original document would end up changing the fingerprint completely.  And it is not computationally feasible - here we go again, we're assuming non-infinite computational power.  It's not computationally feasible to make a change that results in a deliberate result.  Well, a couple weeks ago we talked about this breach in MD5 where, within limits, these cryptographers figured out how MD5's algorithm is not as strong as we hoped or wanted, where they were able to deliberately get an MD5 digest to come out exactly the same as another document's, which allowed them to take the signature from a certificate authority and apply it to their bogus certificate.



So what we're going to talk about in a couple weeks is a type of digest we've never discussed before, which is a keyed digest, that is, where you mix the notion of a cryptographic key with a digest.  And that's important for authentication of the person who did the signing.  I've always sort of chuckled a little bit to myself when I've seen download sites that give you the MD5 and even the SHA-1 hash for the file you're downloading.  That's always seemed dumb to me because, if somebody was able to put a fraudulent file there, well, then they're also able...



LEO:  To change the hash.



STEVE:  Exactly.



LEO:  I never thought of it that way.



STEVE:  Exactly.  They're able to say, you know, here's the MD5 and the SHA-1 for the file.  And so you think, oh, good, I'm going to download that, and I'm going to check the MD5.  Well, if the file's bogus, then so is the hash.  Or it could be because they've obviously compromised the server.



LEO:  I guess the idea is that you put the hash on a website, but you're getting the file from an FTP server.  So you'd have to compromise two different locales.  At least when it's done in open source I think that's the idea.  But you make a very good point.  Trust no one.  That's the Trust No One model.



STEVE:  Well, it's like the email that says "This email has been scanned and verified by an antivirus."  It's like, well, if I were going to write a virus, that's the first thing I'd have added to the end of the email.



LEO:  Sure, that says that everywhere, yeah.



STEVE:  Exactly.  So we're going to talk about a way of keying these digests in order to create essentially an authenticated signature, which we don't have at this point because, again, imagine that a communication were going across the wire, and it was signed, even by a really good hash, like by SHA-256, which as far as we know has no weaknesses.  Well, some bad guy, since the algorithm is public, a bad guy could replace the message with his own and sign it with SHA-256.  And so it would get to the other end, and if the digest were checked, it would match.  I mean, it would be properly signed.  So this notion of coming up with a keyed digest is one aspect.  It's like it's the final thing we haven't talked about that we need to discuss before we get into how, in detail, SSL gives us all the things that we've just been talking about.



LEO:  Right, right.



STEVE:  And the last thing is endpoint authentication.  That is, we have confidentiality and protection against message being modified and then endpoint authentication.  And that we've covered extensively in the last few weeks when we've been talking about certificates and the way we have a chain of trust which is anchored to a root certificate authority, so we're able to follow the chain all the way to the certificate.  And given that every link in the chain is trusted, and the certificate root is trusted, then we can trust the certificate that results to verify the identity of the endpoint.



LEO:  I've always thought the chain of trust is kind of an elegant concept.



STEVE:  I really like it, yeah.



LEO:  Yeah.  All right.  So you've covered a lot of ground here.



STEVE:  Well, so those are, yes, those are - I wanted to sort of review.  Those are all the elements of crypto systems that we've talked about.  And the things that we want to achieve, that we will in two weeks, after next week's Q&A, we're going to talk about keyed digests, essentially, how we introduce the notion of who signed this rather than just using a common, fixed algorithm that always results in the same signature.  That's the last piece we need before we talk about how SSL actually delivers all of this for us, every time we go to a secure website.



LEO:  Very cool.  You know, in the security news there was one thing I forgot to mention.  Did you see that the My.BarackObama.com site had been hacked?  It's a public site that allows people to create groups so that they - it was used during the campaign for fundraising and for organizing.  And as with any forum, if you give people access to it, they could put links to trojans and stuff like that.  So I guess it's not really that it was hacked, but just that there were - people were putting trojans up on there for people to download.  Isn't that terrible?  But it's a reminder of what we said at the very beginning.  Do not accept files from strangers.  And when you see an executable, whether it's on a forum or on a BitTorrent site or anywhere, just stay away from those.  Those things are dangerous.



All right.  I feel ready.  I feel my brain has grown.  Everything you said, I understood.



STEVE:  Isn't that great?



LEO:  I understood it.



STEVE:  This is stuff we've all talked about before.  I just wanted to kind of gather it all together in one place so that we have a common glossary, and to move forward.  And in a couple of weeks we're going to tackle, finally, how all this fits together into a complete crypto system, and talk a little bit about the history of SSL.  It turns out that Version 1 of SSL was not very good.



LEO:  Oh, really.



STEVE:  They used our old friend RC4.



LEO:  Right.



STEVE:  This was from Netscape.



LEO:  Netscape, yeah.



STEVE:  Of course RC4 is the pseudorandom sequence of bytes which just used XOR.  And they only protected it with a CRC, with a standard checksum, which meant it made it very prone to being manipulated.  Fortunately, that never got out in the world.  It was replaced by Version 2 very quickly.



LEO:  They also offered 40-bit and 50-bit, 56-bit, I think, encryption.



STEVE:  Yeah.  Well, there were - 56 was of course DES encryption that was there.  And that's a good point.  One of the things that they took into account, which the original WiFi spec that also uses 40-bit encryption took into account, was U.S. export restrictions.



LEO:  Right.



STEVE:  Until 2000, the year 2000, I mean, really a problem.  It was nutso that, I mean, here all this is in the public domain.  All of it's in magazines and on the 'Net and fully available.



LEO:  Oh, yeah.



STEVE:  The U.S. government is saying, oh, no, this is - they were calling it "munitions."



LEO:  Munitions, yeah.  That didn't last, though.  Remember the hacker who put the code on his T-shirt and said - and got on an airplane?  They just couldn't - they couldn't protect it.  The secret had gotten out.



STEVE:  It was just nuts.



LEO:  And they just couldn't protect it.  So fortunately we all use 128-bit secure SSL, using - it's RSA now; right?  Is that what they use instead of RC4?



STEVE:  Well, that's what we're going to talk about in a couple weeks.  We're going to go over all of that because the way this has evolved is interesting.  And we now have all the tools in our toolkit for understanding this.



LEO:  Wow, I didn't mean to do a preview.  By the way, next week we do answers to your questions.  So I want you to go to Steve's site, GRC.com/feedback.  If you heard something today, or you've heard something on another show that raised an issue, a question, a lot of times we get great ideas, too.  So don't hesitate to go there and say, hey, what about this, I think this might work, or I've got a better way of doing it, or whatever you have to say.  You're full of it, Leo.  That's okay, too.  GRC.com/securitynow.  That's the place to go.  By the way, while you're at GRC, man, we've got some great stuff, Steve's got some great stuff there for you.  Not only all the podcasts going way back to Episode 1, "As the Worm Turns," both in 64K full quality as well as 16K for the bandwidth impaired.  He's got transcripts - you don't have transcripts for every show, do you?



STEVE:  Every show.  I had Elaine go back, and we caught up from the very beginning.  I said, look, let's lay down a foundation here.  So yes, every single show.



LEO:  Wow.  I would really like to start doing that for other shows.  We've got to put transcripts out because that just makes it easier to find stuff.



STEVE:  I will say the wiki stuff that's been done is just spectacular, Leo.



LEO:  Thank you to our wikiarians, wikarians.  It's wiki.TWiT.tv.  It's an official wiki.  We put it up on our servers.  And it's using MediaWiki.  So if you've ever edited Wikipedia, please go in there, create an account.  We are all invited.  And really the community has stepped up, and we've got great show notes there now.  As you're talking, Steve, they're typing.  They're going for it, man.



STEVE:  That's a little freaky.



LEO:  Oh, man, they do such a good job.  So thank you to our wiki editors.  They're just - and anybody could be one.  That's the beauty of a wiki.  So, yeah, TWiT.tv, wiki.TWiT.tv is the place to go for show notes.  Steve's got his complete show notes, as well, on his site.  And of course once you get to GRC.com you're going to find all sorts of great software, ShieldsUP! to test your router, DCOMbobulator, Wizmo.  Somebody asked in the chatroom, I need more instructions on Wizmo.  Is the ReadMe not enough for some people?  I think it's all there.



STEVE:  It's all there.  I mean, and the page, go to GRC's Wizmo page because I've got, like, a paragraph for every single verb.  So there's much more on the website than there is in the app itself.



LEO:  Ah, okay.  So read the website.  That's the thing.  Wizmo is cool.



STEVE:  Yup.  And I will mention where my time at the moment is.  Actually it's a couple things.  I have successfully built three of the little PDP-8 kits.  That was over the weekend I did that.



LEO:  Now, do you have to solder those, or you just snap them in?



STEVE:  Oh, it's major solder.



LEO:  Oh.  You built three of them?



STEVE:  I built three of them.  And it's amazingly fatiguing because I have got this little wacky magnifying headgear that I wear that allows me to see really close.  But like I'm holding my breath as I'm touching the soldering iron and the solder to every single one of the little legs.



LEO:  Oh, man.



STEVE:  I'll have one with me next week and hold it up for our live video people to see.



LEO:  That's so cool.  You built three of them.



STEVE:  Yeah.



LEO:  Why did you build three of them?



STEVE:  And they came right up, responded to the console.



LEO:  You're kidding.  Oh, that must be a good feeling, when you build something like that and it works.



STEVE:  Yeah, yeah.  Although it's, I mean, it's advanced kit construction; but all the pieces are there, and all the work has been done by Bob Armstrong, who designed it.  And probably about a month from now the front panel kits will come, which are the front panel with all the switches and lights and things.  And so those get - I'll build those, and then mate the two boards together and have some blinky lights.



LEO:  You are - we've got to do a show on, you know, just I don't know what.  You program it or something, I don't know.



[Talking simultaneously]



LEO:  ...a separate sidecar show.  We'll do a...



STEVE:  I'll do it.  I'll have to write a program specifically to make the lights all blink in a good way.  And then where I've been in coding mode, I'm working on bringing what used to be called DNSRU - it's a utility from 2002.  I found it was dated 2002 when I opened up the source code.  So it's seven years ago.  And it stood for DNS Research Utility.  I was experimenting with a whole bunch of things about DNS.  But it's always been like the secret favorite of the denizens of the GRC newsgroups.  It expired, and so you had to hold down a shift key when you started it in order to get around the expiry notice.  But it's, as far as I know, it is the most comprehensive benchmark ever created for DNS.  And now that OpenDNS has come to the fore, and there are a bunch of other public DNS servers, it'll be very easy for people to run this and compare their ISP's DNS servers, or whatever DNS servers they're using, to a bunch of others.  And so it gives you statistics and performance and characterizations and just a whole bunch of stuff.  And I'm in the process of finishing it, which is like it's the final piece of this whole DNS region that I've been assembling for GRC, which started with the whole check your DNS servers for their spoofability.  So it's all coming together.



LEO:  Very cool.  So this is a lot of stuff Steve's working on.  Again, GRC.com.  And it'll all be unveiled there.  And let's not forget, there is something called SpinRite there that you just should have a copy of.



STEVE:  That makes it all possible.  It makes everything else that I do possible.



LEO:  You just ought to have a copy of that.  That's at GRC.com.  Steve, thanks so much.  Great fun.  I felt like I learned something, as always.  And we'll be back next week to answer questions.  And I'll see you then, Steve.



STEVE:  Talk to you then.



LEO:  Bye bye.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#182

DATE:		February 5, 2009

TITLE:		Listener Feedback Q&A #59

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-182.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 182 for February 5, 2009:  Your questions, Steve's answers, #59.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, time for us to talk about protecting yourself online and off, protecting your privacy, protecting your special precious assets.  And there's no one who knows more about this subject than Steve Gibson from GRC.



STEVE GIBSON:  Hey, well, I don't know that I would put it that way.  But I'm the only one you can get in front of a microphone with.



LEO:  That can actually speak.  No, that's true.  I mean, there are security researchers, there are wonderful security researchers out there.



STEVE:  Oh, I worship them.  They're...



LEO:  I should finish the sentence.  You know more about it, and you're better able to explain it, than anybody else.



STEVE:  I enjoy communicating what I have figured out and learned.  That's definitely the case.



LEO:  I did an interview last night with Marc Germain, who's been in L.A. radio for years.  And he said, well, you know, I listen to Steve, but I don't understand.  It goes right over my head.  And I said Steve is not for everyone.  I'm not saying this is a show that everybody should listen to, although everybody should learn from it.  But this is for people who really want to know the inner workings of this.  But you're very clear and very explicit about how it all works.



STEVE:  Well, we have a Q&A episode this week.  And I just - I love reading the feedback from our listeners.  And once again I ran across somebody who had written in the last two weeks - because I normally dump the mail bag every two weeks.  And there were 384 submissions from the last time I'd dumped it two weeks ago.



LEO:  Wow.



STEVE:  And, I mean, I'm just - and I'm so heartbroken that I just - I can't respond to them all.  Just there isn't time.  I mean, if I did nothing else, then I could.  But then nothing else would happen.  So, but once again, I ran across one person who'd written that the podcast had inspired them about computers to go back to get their degree.  They're doing some post-degree work.  And, I mean, because of the podcast.  Which is way cool.  I really like...



LEO:  Wow.  Wow.



STEVE:  That's spectacular.



LEO:  Yeah.  Well, and that shows that people really want to know this stuff.  And I guess that's what I would say is this is the show, if you really want to know this stuff, this is where you're going to hear it.



STEVE:  Well, and I know that we talk about this all the time.  But life is more and more on the Internet, and more and more of our life is on the Internet.  And one of the other things that I keep running across as I'm reading feedback from people is they comment that they're so much more aware now, after listening to the podcast, of the issues.  I mean, and certainly, it certainly raises some concern.  But on the other hand, you can't be concerned about what you don't know.  So in knowing what's going on, it's natural to get more concerned.  But I would argue, well, people should be, I mean, to some degree.  Not all freaked out and paranoid.  But, I mean, take reasonable steps, given that you know what the dangers are.



LEO:  Yeah, that's one thing Marc said is that I don't do everything Steve recommends.  I just find it overwhelming.  And I said, you know, I don't either.  But it's good to know.  It's good to know, in other words, instead of just wandering blithely...



STEVE:  Make an intelligence choice.



LEO:  Yes, exactly.  The more you know, the more you can make that choice.  So that's really the value of this.



STEVE:  Yeah, we were talking before we began recording a little bit about some of the issues that we're going to discuss today.  And I mentioned that we've got a couple more new bonehead security moves on PayPal's part.  And I was saying they're so dominant and so important that they really ought to hire someone who knows security to, like, fix this stuff.  Because it's just - the two things we're going to wrap up the Q&A with at the end of the show are just, I mean, it's like, oh, my god, you're kidding.



And I was mentioning to you that I've been using PayPal a lot recently because I've been doing some antique collecting of old machines.  You started this, again, because you held up that damn plane of core memory, and I thought, I gotta get some of that.  And that of course led me back to the PDP-8 and the whole PDP-8 construction project.  But then, as I sort of remembered those machines, I thought, well, now, what about an 11?  And what about a VAX?



LEO:  Oh, no.



STEVE:  And so, and I have been reading a couple books about the history of Digital Equipment Corporation and remembering that the PDP-11 is one that I never had the chance to program.  I sort of just stepped over that into the microcomputers, you know, the 8008, the 8086, and the 8088, and never got into the VAX.  But DEC deliberately designed the instruction sets of the VAX and, well, of the PDP-11 and then the VAX, which was sort of an expansion of the 11's instruction set, to be pleasant to program in Assembly language.  I mean, they designed them for me.  And a consequence of that was that they would be efficient for compilers to produce code for.



But I thought, okay, I gotta get me some of these before they all disappear because they are, I mean, they are beginning to disappear.  These machines are, unfortunately, even collectors who end up with a collection that they're proud of, you know, they die, and their wives don't know what to do with them, or the family doesn't know what to do, I mean, they end up just being scrapped one way or the other.  So I thought, okay, I've got to get busy now, protect this equipment.  Because I figure in about 30 years, when I'm 80-something, that'll be about the time that I want to sit down and do some PDP-11 programming and some VAX programming.  So anyway, I've been using PayPal a lot.  And I've got my little football with me all the time.  And I'm happy with it.  But I'm less happy with it now than I was yesterday, before I read the two things that we're going to wrap up this Q&A with.



LEO:  Oh, oh, oh.



STEVE:  Yeah.



LEO:  Okay.  So just off the top of your head, you've got, you said, how many, two PDP-8s...



STEVE:  No, actually, I ended up - the gal that I connected up with tossed in a couple others in unknown condition.  And they're not nearly as nice as the ones I had, but they're workable.  So at some point I will - I need to do some restoration because they're - I couldn't - you couldn't plug them in and use them right now.



LEO:  And you bought three kits.



STEVE:  So then I bought three of the really neat PDP-8, the SpareTimeGizmos kits.



LEO:  So you've got, like, five or more, five-plus PDP-8s.



STEVE:  Yeah.  Well, on the other hand, I mean, consider how many PCs I have.



LEO:  I'm not knocking you.  I'm trying to get an inventory here.



STEVE:  Oh, okay.  And then there was...



LEO:  I just bought two laptops.  Believe me, I'm not the guy to knock you.



STEVE:  Okay, yeah.  And then I also got, sight unseen, a pair of PDP-11s.



LEO:  Now, how big are those?



STEVE:  They're, well, they come in a whole range of sizes.  I mean, and in fact the 11 was designed deliberately to be a scalable computer.  And one of the things that I've really enjoyed about reading the history of this is that - I can't think of his name.  Not Gordon Moore.  That's Intel.



LEO:  Oh, Gordon Bell, yeah.



STEVE:  Gordon Bell, exactly.



LEO:  Of DEC, yeah.



STEVE:  Gordon Bell, who was the original DEC guy.  He really understood about Moore's Law, and that in their terms Moore's Law means that about every - I don't remember now what the numbers were exactly.  But it's like...



LEO:  Every 18 months, I think, it doubles, yeah.



STEVE:  Every year and a half you needed two more bits of addressing, from their standpoint.



LEO:  Ah, interesting.



STEVE:  And so they literally looked at it in terms of, as computers grow, the one thing they keep outgrowing is memory.  I mean, Bill Gates, as we all know, famously said that you would never need more than 640K in a PC.  640K.



LEO:  K.  K.  K.



STEVE:  Not even a meg.  So, and that was when the Apple II had 64K.



LEO:  Right.



STEVE:  And so this was, oh, 10 times that much.  You could never fill that up with anything.  So anyway, it's been an interesting adventure.  The PDP-11 was - it also outgrew itself.  But it grew for many orders of magnitude and lasted for a long time and was a really popular machine.  So, sight unseen, I bought two from the same gal.  And one of them has all of its boards, but it's pretty banged up.  I mean, it's just sad to see a classic machine just brutalized.  The other one is in better shape, but is empty, no boards.  So I figure between the two I've got a nice chassis, and then the other one's got the boards.  But again, they need - it needs to be, like, completely taken down to its constituent parts, everything cleaned.  Probably I would have the cases repainted.  And I would like to restore them to, like, museum-grade mint condition.  I think that'd just be really fun.



LEO:  Very cool.



STEVE:  So sort of like somebody who, like, works on old cars, that kind of thing.



LEO:  You going to get any VAXen?



STEVE:  I have some.



LEO:  You've got VAXes?



STEVE:  I have VAXen.  The VAX went from being a really monster machine - it also lived a long time and got well into the LSI microcomputer era.  So there are MicroVAXes which are cute little one-inch-high things.  There's even called - there's a VAX Station 4000 VLC that stands for Very Low Cost.  And they literally go for a hundred dollars.



LEO:  Wow.



STEVE:  On eBay.  They run a strong flavor of UNIX, so you can run UNIX on it, and a lot of people do.  But also VMS was the operating system DEC created special, I mean, they wrote VMS for the VAX.  And it's often called VAX VMS.  And then, of course, DEC got purchased by Compaq that got purchased by HP.  So now HP has it, and it's called OpenVMS.  And there's a hobbyist license for free.  You can sign up for and get everything, the whole - the VMS and all what they call their layered products, which are, like, all the languages that are available, and everything is.  And there's a really nice macro language which is the macro assembler.  So anyway, I've sort of been pulling all that together in the background.



LEO:  You going to stick with minis, or you going to go to - you're not going to have VIC-20s and Commodore 64s and...



STEVE:  Oh, I have all those already.  I've got the whole Atari line, the Apple line, I mean, all of that stuff I had because I was using them.  And I just - I never threw them away.  I kept...



LEO:  Where do you keep them?  Do you have, like, a storage locker?  I mean, how do you keep all this stuff?



STEVE:  Yeah, they're all offsite in a good, well-secured location, so...



LEO:  It'd be really cool to - I think we need to set up a Steve Gibson Computer Museum.



STEVE:  Well, and to put this in perspective, too, there are many other collectors.  There are collectors where you think, my god, this guy must have his own warehouse.  I mean, where they've, like, got multiples of every PDP machine ever created, I mean, just phenomenal collections.  And the question is, what's going to happen to that collection when they lose interest, or when they need money because the economy is in bad shape or whatever.  So it's like, okay, I can't count on other people's collections to stay around.  And I've also been scraping the 'Net for all of the software and documentation, so I'm getting my own copy.  Because you run across lots of broken links, links of people's sites who used to be - who used to have all this documented and aggregated that are - they're just gone.



LEO:  Right.



STEVE:  So I said, okay, now I've got to get it before it goes away any further, so.



LEO:  There's, of course, it can be - in fact, we've been thinking about doing a show, and if we do this, we'll get you to come up, at the Computer History Museum in San Jose, which is a great place.  In fact, it was Gordon Bell's wife, Gwen Bell, who founded that, with Gordon's help.



STEVE:  Well, you know, he's now at Microsoft.



LEO:  Yeah, I know, he's a...



STEVE:  He's a Microsoft researcher.  And in fact some of his pages from Microsoft are what I was reading where he was, like, talking - he has papers, you know, "What We Learned From the PDP-11."  And, like, of no interest to anyone but someone like me, who's like, oh, I want to know what you learned from the PDP-11.



LEO:  Yeah, no kidding.  And then there's also the DigiBarn.  We've interviewed them.  I think they're up in the Santa Cruz Mountains.  And he's, like you, he's just collected a ton of stuff and has people come up and so forth.  It's Bruce Damer who does that.  So he has a Cray in there, among other things.  He's got an amazing collection.  So I think you're right, I think there are a lot of hobbyists like you who do this.  I think one of the big differences with you is that you really want to program these things.



STEVE:  Yes, exactly.  I don't want to just run it.  I mean, I actually want to write code for it.  I think that would be really interesting.



LEO:  I agree with you.  I hope you get around to that project.



STEVE:  I will.



LEO:  But not soon, because that means you'll have been retired for some time.  And we don't want you to retire.



STEVE:  Yeah.  I'm sure it's necessary for us to keep ourselves active and keep our brains going.  And there are a number of things, projects that I would like to execute on those classic machines.  And the fact is, newer machines are just not so fun to program in Assembler.  They're all getting very sort of RISC-like, and they're not designed to be really people friendly at the machine level.  And these DEC machines, they really were, the 8 and the 11 and the VAX.  It's funny, too, because I actually read where Gordon Bell was saying, you know, our customers are programming in Assembly language, writing code for our minicomputers in Assembly language.  So we need it to be a good Assembly language.  It's like, wow, when did you last hear that?  I mean, I'm the only one I know who programs in Assembly language still.



LEO:  No kidding, no kidding.  Well, do we have any notes...



STEVE:  Oh, we've got a bunch of notes and stuff here, Leo.



LEO:  Okay.  All right.



STEVE:  Security-wise it's been a very quiet week.



LEO:  Hallelujah.



STEVE:  Of course, it was...



LEO:  Patch Tuesday is coming next Tuesday, so...



STEVE:  That's true.  And so we'll have news of that.  But at this point the only really interesting story that I ran across and I thought our listeners would get a kick out of, and I'm sure you probably picked up on it because you're wired into what's going on, and that was about the road sign in Austin, Texas that was hacked.  A temporary electronic road sign near, probably not coincidentally, the University of Texas at Austin, was hacked in the wee hours of the night to say "The end is near!  Caution, Zombies Ahead!  Run for Cold Climates!"  And the reason this is of interest to Security Now! listeners is, get a load of this.  The hack depended upon the fact that the equipment was using its default password.



LEO:  No.



STEVE:  No one who had ever set this up, the city employees don't change the passwords on these things.  So a lock was broken that gave the vandals access to the computer inside, which they were only able to reprogram because the password was the default for...



LEO:  "Caution!  Zombie Ahead!" is what it says.  Oh, that is so funny.



STEVE:  Yeah.  Yeah.  So because the password was default, they were able to change the text.  Oh, and then they changed the password to non-default, which further thwarted the city's efforts to change the text away from the zombie warning.



LEO:  They had to take the thing home, back to the shop, to reprogram it.



STEVE:  It took a number of hours for the manufacturer to get involved and reset the password so that the employees could then put the text back to what it should be, so...



LEO:  "Zombies in area!  Run!"  What do you think?  Do you think people saw that and believed it?



STEVE:  No, I think people got a kick out of - I hope.  I hope just the fact that it was on sort of an official electronic billboard wouldn't give it too much credibility.  I think in this day and age people are like, okay, we're near the university, gee, what a coincidence.



LEO:  "The end is near!  Zombies in area!  Run!  Nazi zombies!  Run."  That is very funny.



STEVE:  Now, in other errata, I was listening to you a few days ago when you were going through a dictionary definition.  You were saying that you had some show where you read definitions...



LEO:  Oh, I was joking around, but I have - somebody gave me this book, "Radio-Television Electronics Dictionary."



STEVE:  Well, and the word that you jokingly talked about, but then did not answer...



LEO:  Hysteresis?  Was that it?



STEVE:  Was very close to my heart, hysteresis.



LEO:  Well, now, why is that close to your heart?



STEVE:  Well, because it's the way core memory works, and I've got core memory all over the place at the moment.  Hysteresis refers to a feature of magnetization and other properties where it's sort of difficult...



LEO:  Well, I can just read - shall I read the definition out of here?



STEVE:  Okay.



LEO:  The response of a magnetic material to an alternating magnetic field.  The lagging of the induced magnetism behind the magnetizing force.  2.  of an oscillator, a behavior that may occur in which multiple values of the output power and/or frequency will correspond to given values of an operating parameter.  In radiation counter tubes, the temporary change in the counting rate versus voltage characteristic caused by previous operation.  And then there's, you know, hysteresis error, hysteresis heater, hysteresis loop, loss, motor.  This is clearly an important part of the "Radio-Television Electronics Dictionary."  It's almost a quarter of a page there.



STEVE:  One way to think of it is if you, for example, in the case of magnetization, if you apply a magnetic force against something which is ferrous, and you don't reach a threshold, then you haven't, like, pushed it over this hump.  And so when you back off, you end up with no residual magnetization.  But if you do reach this hump, it sort of - it pushes it past a point where - in the so-called "hysteresis curve" such that then it takes a greater reverse force to get it back.  So it's sort of a - it's a nonlinear response in the case of a magnetic field, and so something that you're magnetizing.  And it's the reason we have magnetic memory back in the old days.  You know, core memory.



LEO:  How interesting.  Hysteresis.



STEVE:  So, hysteresis.  Yeah, I mean, it's a well-known concept in engineering.  And I can sort of, you know, close my eyes and see this sort of a boxlike curve which is called the "hysteresis curve," where it goes - you follow one path on the way up.  And instead of retracing your path on the way back, you take a very different path on the way back, due to the fact that you've affected some object of physics.  Through moving up you've changed something such that coming back to where you came from, you take a different path.  So it's cool.



LEO:  I guess once they discovered it, they thought of ways to use it.



STEVE:  There's some sci-fi news that I wanted to bring to our listeners' attention.  Our old friend Joss Whedon is back.  He's our old friend because he gave us "Firefly"



LEO:  Yes.



STEVE:  Which was a spectacular series.  What I was surprised about is that his new series is premiering on Fox, even though Fox screwed him.



LEO:  You would think he'd have learned his lesson.



STEVE:  It was Fox who, after 11 episodes, canceled his series, even though there was already, what, three more that had been made.  They didn't even bother to finish airing what he had made.  And they played them all out of order, so they didn't make as much sense as they should have.  I mean, they just really messed him up.  And he was pissed off at the time.  And then there was a huge fan outcry because "Firefly" was just so fun.  And then it was generally regarded as having been a mistake for them to have canceled it because, I mean, it was like this - it was like, okay, why did you cancel this tremendous show?



So of course, as sci-fi followers know, he did produce a feature-length film, "Firefly," which I thought was fantastic, although I don't think, at least in terms of box office revenue, it did not even break even.  I don't know what's - I haven't kept track of it.  I don't know if, like, in long-term DVD sales he ended up making money on it.  But the point is, he's back with a new series that is premiering this coming Friday the 13th, February, Friday the 13th, 2009, at 9:00 p.m., obviously on Friday, which follows the new timeslot for "Terminator" on Fox, you know, "The Sarah Connor Chronicles," which I'm also loving.  I think it's a good show.  Anyway, I've seen a premiere of it, and it's about what they call "programmable people."  And Wikipedia has a nice treatment of it.  Reading from what Wikipedia wrote, it says "Eliza Dushku plays a young woman named Echo, a member of a group of people known as 'Actives,' or 'Dolls.'"  Oh, and the series is called "Dollhouse."



LEO:  What?



STEVE:  "The Dolls have had their personalities wiped so that they can be imprinted with any number of new personas, including memory, muscle memory, skills, and language, for different assignments.  They're hired out for particular jobs, crimes, fantasies, and occasional good deeds.  On missions, Actives are monitored internally" - whatever that means - "and remotely by Handlers.  In between tasks they are mind-wiped again back into a childlike state and live in a futuristic dormitory/lab, a hidden facility nicknamed 'The Dollhouse.'  The story follows Echo - or I guess the series, the series story arc follows Echo - "who begins in her mind-wiped state to become self-aware."  So I don't know anything about it.  I'm not saying it's...



LEO:  Sounds cool.  Sounds really cool.



STEVE:  And Josh has done good things.



LEO:  Joss.



STEVE:  Josh.  Joss?



LEO:  I think it's J-o-s-s, yeah.



STEVE:  Okay.  Oh, you're right.  I wrote "Josh," that's why I'm reading it, but it's Joss.  He's done good things.  My tech support guy, Greg, was a big fan of "Buffy the Vampire Slayer."  And I used to tease him about it endlessly.  I'd go, Buffy?  Really?



LEO:  I have to go back and watch it because people loved that show.



STEVE:  Well, and apparently it was the writing.  He kept saying it's the writing.



LEO:  The writing.  Joss Whedon, again.



STEVE:  The writing is so good.  And then "Angel" was spun off from "Buffy."  And Joss did those things, too.  So anyway, I have hopes.



LEO:  I like the idea of dolls that can be programmed with your...



STEVE:  Oh, I love it.  And I saw, in this preview, it's wonderful looking.  It's like, okay, we're good.  I hope 9:00 o'clock is a late enough timeslot for this because looks like it could be way good.  And during the Super Bowl I picked up, I saw, it was toward the beginning of the game was a new Star Trek trailer that's got me, you know, panting yet again.  The good news is we don't have to wait forever.  The new Star Trek movie comes out on May 8th.  And the existing trailer that everyone has seen, I hope has seen, has the young Jim Kirk at maybe, I don't know, age 12, driving that classic red - is it a Corvette, I think?  Have you seen that trailer?



LEO:  No, I haven't seen it yet.



STEVE:  Oh, I can't give it away, then.



LEO:  I know it's there.  Well, yeah, we have to be careful because not everybody's seen it.  But it's Jim and Spock back at Starfleet Academy; right?



STEVE:  Well, I mean, that is the - this is when they meet.  This is when Kirk and Spock first meet.  And apparently Kirk grabs some people and commandeers a ship and runs off with it or does something...



LEO:  Oh, he was always bad, wasn't he.



STEVE:  He was always, yes, he was always different.



LEO:  Always a rebel.



STEVE:  And so, okay, so that's May 8th.  On the 22nd of May is the fourth "Terminator" movie.  So we get the fourth installment of a feature-length "Terminator" movie, "Terminator Salvation," that of course I'll be there for.  And finally what's interesting is that that was the weekend that another much-anticipated major sci-fi movie was going to be released, but it got bumped back to Christmas.  In fact, that same week that his other major movie, little something called "Titanic," was released.  And this is James Cameron's "Avatar," that he's been wanting to do and working on for 12 years.



LEO:  Holy cow.



STEVE:  This is his major return to the big screen.  The plot is something like a wounded veteran goes to some planet where there's an indigenous people and somehow combines or merges or does something.  A bunch of this is computer generated.  So it's a hybrid of live actors and computer-generated characters.  And we have Sigourney Weaver, one of Cameron's great friends, is going to be in.  They were going to - for a while they were going to call her Shipley in "Avatar."



LEO:  Oh, that's her name in "Aliens"; right?



STEVE:  Well, no, Ripley, of course, famously.



LEO:  Ripley, that's right, yeah, yeah.



STEVE:  So but clearly making it similar as a little play on that.  But they ended up changing her name to something else.  So, and it's some sort of 3D technology.  One of the benefits for Cameron is that, by moving it back from May until December, that will allow more theaters the opportunity to install 3D screens, whatever that means.  I've not looked into what this 3D technology...



LEO:  Yeah, I'm not crazy about those 3D things, but...



STEVE:  Yeah, I'm not, either.  I'd rather not bother with it.  But, you know, what the hell.  And that's all of my random news.



LEO:  That's the sci-fi news of the week.



STEVE:  The sci-fi update, yeah.  I did have a very short little fun quip about SpinRite.  John Salter wrote - I ran across his note when I was going through the mail bag.  He said, "Hi, Steve."  Oh, interrupted by Fred.  Coincidentally, he's just sold a copy of SpinRite, and I'm reading a SpinRite story.  "Hi, Steve.  I was making a video for Yubico on using the YubiKey for TrueCrypt whole-disk encryption using a YubiKey preprogrammed for generating a static 44-character password.  While TrueCrypt was encrypting the disk for this video, it started complaining when it reached a bad sector.  Of course I just deferred the encryption."  He says, "TrueCrypt has really thought of everything.  Rebooted from my SpinRite CD and let SpinRite do its stuff.  Sure enough, a bad sector was found, and DynaStat kicked in.  I rebooted, and TrueCrypt came back and offered to complete the decryption from where it was interrupted.  Which it completed successfully.  Very cool."  He says, "When I finish the video, I'll send you a link."



LEO:  Wow.



STEVE:  So, and I remember when I was myself vetting TrueCrypt, I mentioned some time ago, some versions ago that I was really wanting to put TrueCrypt through its paces.  So I used some tools that I have, some proprietary hard disk technology that I developed for SpinRite, to deliberately damage sectors, making them unreadable on the drive, which I'm able to do, which is part of what I do for testing SpinRite.  And sure enough, TrueCrypt ran across, stopped cold, refused to go any further.  Then I fixed the sector with SpinRite, and I basically deliberately did what John inadvertently did, which was he actually had a bad sector on a disk.  And TrueCrypt can't go past it.  But running SpinRite on the disk fixes it, of course, and then TrueCrypt is able to proceed.



LEO:  Well, there you go.  Pretty cool.  Thank you, SpinRite, once again.  Steve, you ready for some great questions from our great audience?



STEVE:  No.



LEO:  Okay, well, then, thanks for joining us, and we'll - no, I'm...



STEVE:  I'm actually not.  I forgot one.  I forgot...



LEO:  You forgot something?



STEVE:  I forgot something that I wanted to bring to our listeners' attention because I am just so excited about it.  This is dumb.  But strange things get me excited.  You know?



LEO:  We learned that.



STEVE:  You know how I love my window borders to snap to the edge of the screen and to each other.  I mean, that little allSnap utility, a-l-l-S-n-a-p, that I've talked about a couple times, I just, when I'm using a machine that doesn't have it, I'm thinking, okay, what's wrong with this?  Something's broken.  Well, I was - I've been allowing myself to spend a couple hours every morning working on the - laying out the protocol for CryptoLink, even though I can't really start working on CryptoLink full-time because I've got to get the DNS thing finished and the cookie thing finished, and I'm going to get those things done first.  I've just, when I was working on the SSL protocol stuff for Security Now!, I kind of got myself all wrapped up again in security protocols.  And I thought, okay, I just have to spend some time getting this stuff down on - getting it down.  To do that I wanted to use an outliner that I had not used for years called ECCO, which was purchased by NetManage for a long time.  Many people still consider it the ultimate PIM of all time.  The problem is it's old, and...



LEO:  You still use ECCO?



STEVE:  Well, I've gone back to it.  I've been using it now for the last week, just as an outliner.  It does all this other kind of stuff.  In fact...



LEO:  Oh, yeah.  Oh, it's the most complicated PIM ever.



STEVE:  I was going to say, I don't even understand how it works.  I never really did.



LEO:  I tried it.  I love it.  But it's one of those things, it's a lifestyle.  It's not a program.



STEVE:  Yeah.  Anyway, but what happened was, ECCO doesn't know about the mouse wheel.  And I didn't realize until running across ECCO how much I take the mouse wheel for granted.



LEO:  Yes.



STEVE:  It is a wonderful thing to be able to scroll like a web page just, I mean, it's - the mouse wheel is as correct as you can get a UI.  The definition if a good user interface is one that disappears, one that you can use without thinking about it.  And when you have something that isn't mouse wheel aware, it's annoying.  And so, for example, I deliberately build mouse wheel support into all the apps that I write now...



LEO:  Oh, that's neat.



STEVE:  ...just to make sure that, if you're on a - I'll embed a little rich text format, an RTF control, in my app for, like, help or information or whatever.  And it's just nice to be able to scroll it with a mouse wheel.  And of course what that saves you is needing to go over to the scroll bar and find it and then drag it.  I mean, it's just a win.



Okay.  So after five days of frustration, I thought, I'm going to go - there's got to be somebody who's, like, maybe has made a better mouse wheel.  Sure enough, this thing is free.  I cannot recommend it highly enough.  Windows, of course, only, unfortunately.  Sorry, Leo.  It's called KatMouse, K-a-t-M-o-u-s-e.  Just put it into Google, "KatMouse," and you'll find it.  It is very tiny.  It's free.  It does exactly what you want and even more than I was hoping for.  It mouse wheel-enables everything that scrolls.  And you're able to even - you don't even have to give the thing you're scrolling focus.  In Windows, one control or another always has so-called "focus."  You know, when buttons have focus, they're highlighted.  Normally, like when scrolling areas have focus, you can't see them.  You can't see that it has focus.  So you'll - and this is something that even people who use the mouse wheel are experiencing all the time.  You've got to click on the thing first, and then the mouse wheel will work on it because, until you click on it, it doesn't have focus.



This little KatMouse knows what you're hovering over and scrolls that, even if it's not on top.  So you could have - in fact, I'm looking right now.  I have the PDF of our Q&A is underneath the notes that I had.  And so I'm able to simply move the mouse over either of these two windows.  And when I scroll it, the proper pane scrolls.  Anyway, I love it.  I mean, I'm addicted to this thing.  It's so nice to be able to scroll whatever the mouse is over.  So I just wanted to let our listeners know, if they're similarly mouse wheel people as I am, that this little KatMouse, it really makes the mouse wheel much better under Windows.



LEO:  Very cool.  I'll have to give it a shot.  That looks really cool.



STEVE:  It's perfect.



LEO:  Yeah.  I'll see if it works with Windows 7.  I'm pretty much Windows 7 everywhere now.



STEVE:  And Leo, that's just a miracle.



LEO:  Well, no, I still use Macs.  I just say when I use Windows I'm using Windows 7.  It is a miracle.  It's the most, you know, in some ways it's Mac-like.  It's very clean and simple, and you will like it.  You will be glad.  In 12 years when you move to it.



STEVE:  That's right, when I get ready...



LEO:  You will be very happy.  All right.



STEVE:  It's funny because I have heard you talking about it, like with Paul, often.  And I just - I sort of smile because when you're talking about, like, oh, no driver problems and all this, it's really clear, and I'm sure it is to you, too, that it's just Vista.



LEO:  It's Vista.  That's why there's no new driver model.



STEVE:  Right.



LEO:  But I'm not praising it for its lack of driver issues, I'm praising it for cleaning up the UI, primarily.



STEVE:  Yes.  I think they clearly did that.  On their web page they talk about how they listened to us.  And I think it's interesting, too, that they changed the name.  It reminds me of when OLE, that was just stillborn at Microsoft, you know, the Object Linking and Embedding technology, OLE, so-called OLE...



LEO:  Right, right, which became DOM, and which became...



STEVE:  Well, they couldn't get it off the ground.  It was - it initially was - it was so confusing and strange that programmers disliked it.  And nothing Microsoft could do could change that.  And then Microsoft applied, as they often do, marketing.  When technology fails, fall back to marketing.  And so some guy at Microsoft said, hey, you know, we've got this new thing.  And the other person said, well, what?  And they said, it's called ActiveX.



LEO:  [Laughing]



STEVE:  And the other guy [gasping]. ooh, ActiveX, I love that.  What is it?  And he said, OLE.



LEO:  OLE.



STEVE:  And the other guy, well, really?  But it sounds so much better.  And the marketing guy says, I know.  And so people will love it, even though it's the same old dried fruit we had before.  Still...



LEO:  That's Microsoft right there.



STEVE:  So now we have Windows 7.  Basically it's Vista with less noise.



LEO:  Right.  Right.



STEVE:  But I'm really glad you like it.  That's good news.



LEO:  And it has some window-snap features.  You'll probably like them.



STEVE:  Ooh.



LEO:  Yeah.  You just stay tuned.



STEVE:  Okay.



LEO:  All right.  Now it's time for our questions.  We're going to begin with Iain Alexander from Nottingham, England - always a great place.  We get lots of letters, it seems, from Nottingham, I'm not sure why - wrote to Leo, and it says Paul.



STEVE:  Yeah, Paul Thurrott.  You forwarded his note.



LEO:  I did forward this to you, that's right, okay.



STEVE:  Yup.  And so I figured, oh, we ought to talk about it.



LEO:  I thought you might want to know and share with your listeners - we were talking about the Microsoft Malicious Software Removal Tool, the MSRT.  He says you can run the MSRT utility on demand in Windows 7, but it ain't called MSRT or even MRT.  You have to, to manually start it in Windows, you have to type kb890830 in the Start Menu Search box.  You'll see the results, hit return, and there's MSRT.  Knowledge base 890830.



STEVE:  Yeah.  Now, okay, this was - I thought, well, okay.  You forwarded this to me and to Paul.  I thought we ought to discuss it because essentially you're not putting it into the Run box because that's not the name of a program.  You're putting it into the...



LEO:  You're searching for the name, which is longer, yeah.



STEVE:  Exactly.  And so windows-kb890830-v2.5.exe is, you know, is the full name.  So it's just sort of a quick way to get it.  And of course the danger is that I don't know how static that name is, whether they're changing that every month.  The fact that it says v2.5 leads me to believe that they're evolving that particular entry.



LEO:  Right.



STEVE:  So for Windows 7 people, you can run MSRT also.  And the way you do it for now is with this kb890830.  Just, you know, a little FYI there.  Write that down on the back of your hand.



LEO:  Yeah.  Memorize that, then destroy it.  Speaking of MSRT, Corby in Reno, Nevada shares his findings.  He says:  Steve, I'd almost written to you about a very similar finding that you had with MRT and the Eudora attachments.  Like you, I ran the full version of the Microsoft Malicious Software Removal Tool, and it detected some viruses in some very old Eudora attachments that were on my computer.  However, MRT was not able to clean them, so I ran the corporate edition of Symantec AV against the same files. SAV said the files were clean.  I removed SAV and installed eEye's Blink, scanned the same files.  It reported the files were clean.  Since these attachments were very old, and they had a file extension I wasn't familiar with, I ended up just deleting them.  Also I traded Eudora for Gmail several years ago.  I'm pretty sure I didn't need those files.  I just thought you might be interested to know that two different AV programs said the files were clean, but Microsoft said they were infected.  My guess is MRT was showing a false positive, but I don't know for sure.  That happens a lot with viruses, doesn't it.



STEVE:  Well, it certainly can.  The problem of course is that, as viruses have become trickier, the scanners have had to become increasingly heuristic.  So they're not just matching a rigidly known pattern.  They're having to essentially introduce some grey area and say, oh, this - well, they're just saying, oh, this looks like a virus.  I got myself off the track here.  Because, for example, it happens to GRC's freeware from time to time.



LEO:  Right.



STEVE:  Some version of AV will suddenly decide that my DCOMbobulator is evil, and we get a bunch of email from people saying, oh, your DCOMbobulator I downloaded directly from your website, my AV program says it's malicious.  And it's like, okay, wait till they update again, and they'll fix it because - and in the meantime please tell them that they're giving a false positive.  So that does happen.  And so I wanted to share this with our listeners in case other people have this experience.  My experience is somewhat different.  I do think that, given what I saw, that this thing had found evil stuff in my Eudora attachments folder.  But it certainly is the case that false positives occur. 



LEO:  And so what we're saying is we don't know who's false positive.  We don't know if it was Microsoft making a mistake, or the other antiviruses not detecting it.



STEVE:  Or if they keep missing it.



LEO:  Right, both of which happen.  False positives and false negatives.



STEVE:  It's also possible that those AV tools at some point, when something gets really old and there's no more incident of it, they may well be removing detection just for the sake of keeping their own pattern updates a modest size.  Whereas Microsoft might choose to just let theirs continue.  I did look at the MRT.exe, oh, I think as a result of the question we're about to get to.  And it's more than 20MB in size.



LEO:  Wow



STEVE:  It's a monster.



LEO:  See, you couldn't do that in the old days.  I mean, you couldn't silently, without warning, deliver a 20MB file and say, here run this.



STEVE:  Only Microsoft.



LEO:  I mean, it just shows you how much, I mean, broadband has just changed a lot.



STEVE:  It really has.



LEO:  Mike Siwinski in Rochester, New York encountered an old copy of Microsoft Malicious Software Removal Tool:  Steve, listening to SN-180, thanks a lot.  You gave a tip for launching MRT using Start->Run->MRT.  The reason this works is that Windows finds MRT in the System32 folder.  Note:  The copy of MRT on the hard drive is an old copy.  This trick does not find the latest copy of MRT and download it.  I just tried this, and it launched the December 2008 copy of MRT.  I went to Windows Update, and the January '09 MRT was there.  If someone's having trouble with an infection, running last month's MRT probably won't help them.  Thanks for all the good work on Security Now!.  So then how do you run the Malicious Software Removal Tool?



STEVE:  Well, and this brought up an interesting point because it made me think, oh, what's going on here?  And I would recommend our users do this, our listeners do this, too.  It's fun to just search your C drive for MRT.  That is, anything with MRT in it.  You'll find - I found - a bunch of fonts that had MRT embedded in their name.  I also found something I didn't know was there, which was interesting, is an MRT.log.  And that's very cool.  It's under the - in my case it was under the Windows debug directory.  And it is a log that the MRT appends to every time it's run.  And in this log was an entry for every single month.  Actually there were a few earlier months skipped a year or two ago.  But then Microsoft got rigorous about publishing a new one every month and running it every month.  And so this log shows you every single time that it's been run silently in the background.  I mean, and also when you run it manually.  But so there's a whole log of it running on my system for quite - for several years, even though I had no idea it was doing that.  And the time that I ran it manually, when it found all this stuff, there's a log of everything it found.  So the log is also very cool.



But there was just one copy on my system, MRT.exe in the Windows System32 folder.  When I ran it, in the title bar it told me that it was the January '09 MRT.  So I think what happened in Mike's case is, for whatever reason, his Windows Update did not download, or he doesn't have it configured, but one way or another it's not running the current MRT.  So what I wanted to - the point I wanted to raise to our listeners is just put MRT in the Run dialogue under your Start Menu.  It'll take a few seconds, because it's 20MB, to load.  And that was funny, too, because when I ran it I was thinking, okay, did I type that right?  Why is it taking so long to come up?  Well, it's a 20MB executable.  Takes a while to suck that in off the drive.



LEO:  And I'd be glad to know that they're not storing 20 different copies of this 20MB executable on the drive.



STEVE:  Exactly.  But the point is that it's instantly visible in the menu bar.  When you run MRT.exe, it'll tell you what month you've got.  And it's worth just doing a double check.  Mike sort of did it inadvertently.  But I had this month's, the most recent MRT.  I imagine a week from now, when we pass over another Patch Tuesday, I'll have February.  But I'm going to check.  I'm going to just put MRT in after we're talking about it next week and say, okay, yeah, now mine says February '09 rather than January '09, as it does now.  If by any chance you don't have the current one, there's probably a reason.  Well, there obviously is a reason.  But you may want to figure out what that is because it means you're not being updated as you probably want to be.



LEO:  So what he found was not the January edition, but just a stub or something.



STEVE:  No.



LEO:  It was there, but it wasn't getting installed.



STEVE:  Yes.  He found December '08's copy, which is the only one on his system.  And he should have had January's.  But he didn't.  So...



LEO:  I'll have to run it on my systems and now check.



STEVE:  Yeah, just...



LEO:  It'll say.  It says in the title bar.  You just...



STEVE:  Yup, bang, comes right up.  Well, it doesn't come right up.  It takes a while to load itself.



LEO:  Now, we're going to get a new one in a week, so this Tuesday.  So, okay.



STEVE:  Exactly.  Exactly.



LEO:  Probably a good idea at the beginning of every month to check that.



STEVE:  It's a neat tip.  I like that.



LEO:  Very good.  Moving on to our next question...



STEVE:  Because otherwise you don't know.  It's running in the background silently.  The log does tell you, so you could check the log.  But this is a simple, easy way to know, hey, look, I got a new copy, and presumably it ran.  And in fact you could check the log to see if it did.



LEO:  Derek Robson, UNIX geek, takes issue...



STEVE:  That's what he called himself.



LEO:  UNIX geek - with YubiKey as a second factor.  He says:  Steve, for a second week you've spoken of using a YubiKey in static password mode and got it wrong.  You talk about having a password and then adding a YubiKey password to it, making a very long password.  This is good.  I have no problem with the idea.  But then you say it's two-factor authentication, something you have and something you know.  The problem is, YubiKey in static mode really isn't something you have.  It's something you're too lazy to remember.  It's no more like something you have than writing your password maybe on a Post-it note.  Since it would be very possible to remember a static password if you try, it really isn't a second factor.  You don't need to have it.  You could have it memorized.  And what's more to the point, a keystroke logger will remember the static password quite well.  It doesn't need the YubiKey.  Therefore the something you have aspect is valid only when a YubiKey is used in its one-time password mode.  As soon as you remove the one-time function, you lose that something you have function.  It's just a second password.  I know you know this, but got mixed up with the wording.  But let's put it right.  Love the show, says Derek.



STEVE:  Well, I thought that was interesting.  I mean, he's right that it's not something you have to have.  It's something you want to have because it's typing out 64 characters in the 256-bit mode, 64 characters of gibberish, I mean, that you probably couldn't even type in correctly.  I have enough trouble typing in the Windows product code correctly, let alone 16 characters of really gibberish stuff.  So, yeah...



LEO:  I mean, technically, if it's static, it's no different than having - it's just remembering something for you.



STEVE:  Right.  And so I guess it's sort of a question of, a little bit of a question of definitions because he's right that it is static, so the vulnerability is that a keystroke logger could log it and remember it, so you don't have the strength of it being a one-time password.  So it's not something you have that's a one-time password that uses the one-timeness to be provably something you have.  But due to its nature, it's something that you want to have.  So it's like, okay, maybe it's not two-factor.  But maybe it's one and a half factors.  I'm joking.  Maybe it's one and three quarters.  It's something you're really glad you have because, if you didn't, then you'd have to type this thing in by hand.  So I agree with him pedantically.  It's not the same as something that you have no alternative but to have because it's going to generate a one-time password, and you won't know it until it does, and it'll never do it again, so you're thwarting keystroke loggers.  So yes, I agree that it's not the same as two-factor authentication where it's two different things that you know.



LEO:  Right.  You'd agree, if I wrote the password down and pasted it on a Post-it note to my screen, that doesn't - a second password doesn't make it two-factor.



STEVE:  Correct.  One really good factor.



LEO:  Well, I use - and actually this is to the point.  I use a program that generates a password, a hashed password based on mixing a password I know with the top-level domain name of the site I'm on, and then generates a unique password for that site.  But that's not two-factor authentication.  Even though it's using two things, it's not two-factor.  It's something I know.



STEVE:  Correct.



LEO:  Paul in Portland, Oregon says, "Secure email can be easy."  Hi, Steve.  In response to Wes's question in the Q&A episode we did last time about secure email, I've been wondering the same thing myself, which is how do I send an encrypted email to someone without forcing them to do the whole key dance thing.  I'd like the ability to send the occasional encrypted email should I need to send my Social Security number or other sensitive information to someone.



Well, I recently discovered Comodo has a new free product called SecureEmail.  The idea is only the sender configures their email client using free certificates provided by Comodo to send encrypted email.  If the receiver is not set up for decryption, they're given a one-time session certificate and the option to decrypt it using a web reader service.  I'd really like your thoughts on this product.  It's http://secure-email.comodo.com/features.html.  Thanks, love the show.  Oh, this is interesting.  But, see, on the face of it, I don't understand how it would work.  How would it guarantee that the person asking for decryption is the person you sent it to?



STEVE:  Yeah.  And first of all, I went to that link, and there's a Comodo page with a whole bunch of bullet points and all kinds of features and stuff.  And I immediately, my eyes went out of focus.  It was like, okay, wait a minute.  I thought that we wanted to make this easy.  So this is certificates on the sending end, and then you send the receiver a certificate.  But if they're not set up, then you give the - you get a one-time certificate from Comodo, and then you go to Comodo's website, and you have their server do the decryption for you.  So now you're trusting them not to care about what's being decrypted.  You've lost...



LEO:  Oh, that's true, you're giving them the information.



STEVE:  You've lost the TNO, my favorite acronym, Trust No One, because now you're trusting them.  And it's like, okay, wait a minute.  There was a little, cute, perfect little decryption program that I've talked about before called AxCrypt, A-x-C-r-y-p-t.  It's open source.  It's free.  It's a perfect little - it uses AES long key encryption.  The guy is into encryption.  It's simple to use.  And in fact there's an AxDecrypt which you don't even have to install.  So I would say, for somebody who just wants to occasionally send something encrypted, you just encrypt the file and email it and a little AxDecrypt program to a friend, or tell your friend to download AxDecrypt, which is also free.  And then what you have to have is some sort of an out-of-band conversation, that is to say, you want to get the secret passphrase to your friend, maybe over the phone, somehow secure.  And then it's just an easy matter to encrypt a file, email that, and then your friend uses AxDecrypt to decrypt it using the password.  So to me, I call that easy.  And that makes sense for someone who only occasionally needs to send something encrypted.  And of course you can store files encrypted.  You can use AxCrypt for all kinds of purposes like that.



LEO:  I do wish everybody would just install OpenPGP or GNU Privacy Guard and would just...



STEVE:  Yeah.  They will after I start using Windows 7.



LEO:  I love it.  I use GNU Privacy Guard.  I install it on every machine.  I use a plug-in for Apple Mail.  I use Enigmail on Thunderbird.



STEVE:  Boy, are you secure.



LEO:  Well, it's not, you know, I actually don't encrypt very often.  If there is somebody...



STEVE:  [Indiscernible] signatures.



LEO:  I use it for signatures because people impersonate me.  So if you get an email from me that is not signed, then it's not me.  And if it's signed, and you're running one of these programs, and GNU Privacy Guard is free, you can verify that it's me.  And then I upload my key to the key servers and hope that people who know it's me sign it.  And I change - I just changed the key.  I've changed the key at the beginning of the year every year.  They expire.  I learned that because I had about 15 unexpired older keys on the key servers.  They're still there.  Use the most recent key if you're going to do that.  And then if somebody wants to send me encrypted email, they can go to Leoville.com or go to the key server, download my public key, and send me encrypted email.



STEVE:  Yup.



LEO:  And once we've had an encrypted dialogue, all of our conversations are encrypted automatically from then on.  I think it's a very simple system.  There are some programs, I play with a program in Windows that I really like called The Bat!.  It's a kind of high-end email program.  It's from Russia.  I don't know if I should trust it.  But I love it.



STEVE:  I looked at it a long time ago.  I think maybe it was when Eudora was [indiscernible].



LEO:  It's Eudora-like, yeah, it's very powerful.  35 bucks.  But it has built in, and I love - this is one of the reasons I really recommend it, is it has built-in OpenPGP or S/MIME certificate encryption.  You choose which you want.  It'll generate a certificate for you.  That's pretty easy.



STEVE:  Nice.



LEO:  If Outlook would do that - for instance, why doesn't Microsoft build in certificate, you know, just self-signed certificates, at least?



STEVE:  Right.



LEO:  Just build that in.  If it's built in, then everybody can use it, and it's transparent.  All right, I'm sorry.  I'm going to get off my high horse.



STEVE:  No, I mean, I think in an environment where high value content is being shared, for example, all the attorneys in a law firm should have their own certificates.



LEO:  Oh, yeah.



STEVE:  And on their laptops so when they're mailing client confidential contracts and things around, they're just automatically encrypted, like within the firm.  And then maybe even set up some of their more important clients the same way.  Say look, if we're going to be sharing email, we need to do this in a safe way.



LEO:  I would really appreciate that.  Instead of those silly signatures that say, if you got this by accident, don't read it.  Yeah, that'll work.  That'll work.  Dick - I'm sorry, yeah, Dick Victor in Milwaukee, Wisconsin has some Yubico and YubiKey news.  I think this YubiKey thing is the single most popular thing you've ever done, I'm starting to think.



STEVE:  Well, believe me, as I'm - the way I choose questions is I sort of scan through the subjects.  And people are just super excited about the YubiKey.



LEO:  I know you and many listeners are YubiKey fans.  So I thought you might be interested to know that Yubico is planning a small change in the firmware of the YubiKey in the next firmware version, so that it can be used - oh, I'm loving this - in static password mode for preboot password entry for a TrueCrypt-encrypted system partition.  The present firmware does not provide for the YubiKey to get recognized preboot.  And he's got a link in here in the Yubico forums.



http://forum.yubico.com/viewtopic.php?f=2&t=221&p=880&hilit=truecrypt#p880



Seems there's a lot of interest in the static mode, probably because it's something we can use even before there's widespread adoption of YubiKey in its more secure OTP mode, and also because it works offline when there's no authentication server available.  And 64 characters of total gibberish with 256 bits of entropy ain't bad, even if they're using that limited mod-hex alphabet.  Good point.



STEVE:  Okay.  So here's the story.  I've had a dialogue with Yubico because I wanted to understand what this change was.  And I have some interesting news for our listeners relative to getting their keys updated, which Yubico will do for free, for anyone who really needs it done.  They'd rather not have everyone who they ever sold a key to send it back if it's not necessary.  But they can do it for some  people.  The way people have been using their TrueCrypt, I'm sorry, their YubiKeys with TrueCrypt has been post-boot, when TrueCrypt is running, and they'll use the key rather than entering the password into TrueCrypt in Windows to put a partition online or unlock a directory or whatever they're using TrueCrypt for.  The reason it has not been possible to do it for preboot is there's a bit in the configuration header of USB devices which specifies whether the device is a boot device or not.  That is, does it have any semantic meaning in a boot environment.  And that's why people may wonder, like, why some USB drives can be recognized by the BIOS, where others won't be.  It was because back in the beginning of USB drives no one was really thinking of them in terms of boot devices for BIOSes.  So even some drives don't have that bit set, which means the BIOS which looks at the - a USB boot-enabled BIOS, a modern BIOS that looks at USB devices will see that this bit is not set, will ignore it.  And it's not until Windows or whatever OS you're using is running that that bit is no longer important.  So what the Yubico folks have done is in v1.3.3, this firmware update, they are now deliberately setting this bit.  I had a dialogue in email with Stina's husband Jakob, who was the engineer on this.



LEO:  Ha ha.  You sold two in the show.



STEVE:  Thank you, Fred.  And he explained that he deliberately left that bit clear because he thought, who would want to use the YubiKey before the OS is booted?  Because after all, it was at that time only a one-time password device.  So you'd have to have networking running in order to contact a remote server in order to do anything with it.  Then this static password mode of the YubiKey has become so popular that now there's a non-communications, non-networking application.  So v1.3.3 of the firmware has the YubiKey as a boot device, which means it will be seen as a keyboard by a BIOS, and you can use it, when properly configured for static key mode, as your boot-time log-in, boot-time password for TrueCrypt.  Which is very cool.  And they have said that anyone who wants to do that can send their key back to them, and they will update its firmware and return it for free.



LEO:  So they don't have a way to do that online without sending it back to them.



STEVE:  Precisely.  I'm sure there's, like, something they've got to do where - and I don't know for sure that they're not going to exchange it for a new key.



LEO:  They may just put a new key, yeah.



STEVE:  They may do that, or they may update the firmware.  I don't know whether they're able to write new firmware into the existing key.  But it is the case that, if you send them a key that won't work, they will one way or another send you one back that will.  And you can send it either to the U.S. or their main offices, and they'll take care of that for you.



LEO:  Excellent.



STEVE:  So it's very neat.



LEO:  Excellent.  I'm really - the YubiKey is so cool.  Although I hate to use it in static key mode.  I guess I could get another one.  But I just love the idea of having new keys all the time, you know.



STEVE:  That's very cool.  I think you're right, the solution is to have two keys.  One, for example, that you use for your WiFi WPA password, or you use it to preboot TrueCrypt in order to have TrueCrypt do on-the-fly decryption of your whole drive.  And then you've got the other one, which is used for, like, online purposes, where it does make sense.  So you really need two.



LEO:  Maybe three.  The more, the merrier.



STEVE:  Really would be cool if they could have a dual-function single YubiKey that works both ways.



LEO:  Oh, yeah.  Poojan Wagh in Chicago, Illinois suggests a cheaper solution than YubiKey.  Another way to do it.  Hi, Steve.  It pains me to discourage your listeners from buying the YubiKey, since it's a very good technology that is already inexpensive, is only going to get less expensive the more that people use it.  However, I wanted to point out a  much cheaper alternative to YubiKey for some applications.  In Episode 180 you discussed the use of YubiKey's static password.  Leo commented he'd like to use that static password as the master password for a password utility.  You don't need YubiKey to do this.  I use a password utility called KeePass.  That's a really good one.  That's the open source one.  It allows you to use keyfiles in addition to an optional password.  Oh.  Of course.  As a result, I save a keyfile on a USB stick and have it automatically search for keyfiles on removable media.  As a result, I get two-factor authentication....



STEVE:  Oh, well, maybe not.



LEO:  One and a half.



STEVE:  One and three quarter factor.



LEO:  ...a keyfile on a USB key, and a manual password entry.  I've noticed that TrueCrypt also has a similar keyfile capability, with the ability to designate a default keyfile on an external USB stick.  I haven't tried it, but I doubt that a keyfile could be used with preboot authentication.  These days USB keys could be had for a few dollars.  You don't need more than a few kilobytes of space for a good keyfile.  Great point.  What's even cooler, I store my keyfile on a very small SDHC.  That's, of course, the high-capacity - what does the SD stand for?  I can't even remember.  Smart Digital?



STEVE:  Secure Digital.



LEO:  Secure Digital, that's right.  Secure Digital High Capacity camera storage card that slips into my wallet very easily.  Many computers nowadays come with built-in SDHC readers.  However, I happen to have one that folds into a USB connector.  Very slick.  To make things clear, I think YubiKey is still a very good solution for things like preboot authentication.  And its one-time password feature is awesome.  But not the only way to do it.  I should have mentioned that.  Of course KeePass will do that.



STEVE:  Well, and we've never really - we've brushed on the idea of a keyfile, but we've never really talked about it in depth or in detail.  And it's certainly an interesting solution.  I guess I'm less rah-rah about it because it's always felt to me a little bit like it's security through obscurity, the idea being that the encryption system knows where to find key material in a file.  The file's not changing.  It's static.  It's true that if you make it a removable file, then somebody's completely out of luck without that.  And I guess the thing it brings you is absolute proof against a weak password.  You would certainly, I think, would always still want to use a passphrase of some kind in addition to the keyfile, obviously to prevent somebody from using that by plugging his HDSC into a laptop, and if that was the only thing that it needed, then it would be able to access his files without him at all.  So it's, again, it's certainly stronger than nothing.  But a really good passphrase that is sufficiently long is going to provide you with the same security.



It's worth noting that the contents of the keyfile is going to always end up being hashed down to the length of the encryption key, whether it's 128 bits or 256 bits.  But as we've seen, only 64 characters, and that's 64 limited characters, is 256 bits.  So, and so what, 32 characters of a 16-character alphabet, that's 128 bits, if that is the key length that you're using for decryption.  So the notion that you're getting more security from some multi-K file is really not the case.  You only need a relatively short phrase in order to get as much security as is available.  Anything longer ends up being hashed down.



Now, again, it is true that a bad passphrase that isn't really random gibberish will be inherently, have inherently less entropy than some file.  And a big file, by virtue of its size, will end up approaching the maximum entropy that you can get out of 256 bits, or whatever the file is hashed down into.  But it's not the case that, like, a big file ends up having, like, that big a key.  You end up, there's diminishing returns as the file size increases.  So, yes, it is, as we've seen earlier in this episode, it's not a true, full, second factor because it's static, and in that sense it's like a YubiKey running statically.  But I would argue, I mean, I would agree that a keyfile is better than not having one, unless you have a really good static passphrase.  And, for example, a YubiKey running with the full 64-character static password is going to be good.  Oh, and one other benefit of the keyfile is, by not being input through the keyboard, whereas the YubiKey is, by not being input through the keyboard, you are immune to any kind of keylogger of any sort.  So that's another benefit of it.



LEO:  Oh, yeah.  But no good for logging in at boot because nothing would know to check that.



STEVE:  Yes.  And in fact, even if the SD card were recognized, we know that TrueCrypt's boot sector is probably - I'm sure it doesn't today recognize a keyfile.  But it would have to then be modified and made substantially more sophisticated in order to be able to recognize a FAT file system on that SD card and do something proper with it.  So it seems a little bit out of reach.  But again, it's useful in that it's not - the data from the keyfile is not coming in through the keyboard.  And combined with a passphrase, I think it's better security than a passphrase alone.



LEO:  Jim in Westchester, Pennsylvania is not happy broadcasting his passwords all over the neighborhood.  Hi, Steve.  Forgive me if you've covered this previously on Security Now!.  But what if, for reasons of circumstances, you're temporarily working from someone else's office location?  You're not employed there.  The only Internet access available is an open WiFi hotspot.  No telephone line equals no modem.  Huh?  Oh, I see.  You have to use their Internet.  I get it.  The owner of the premises tells you that all the tenants and temps use it without problems or complaints, and it's darn fast.



By the way, that's how we - if you come here, you have - we don't give you access to our internal network.  You get access to an open WiFi access point.  Everybody else is using a wired system that's on a separate router.  But that's - you would be in the same situation if you came here and started to use our WiFi.



So without making it too cumbersome, but some reasonable expense is okay, what would be a good way to reasonably protect one's computer in this situation, without the visiting guest - me - giving the owner and other tenants and temps any grief about running a open WiFi?  Thanks, and great job on Security Now!.  Regular listener Jim.  Jim must have visited the TWiT Cottage.  That's how we do it.  But not for our business.  Just for visitors.



STEVE:  I'm glad to know that.  Not for your financial banking.



LEO:  Nothing.  We don't use the WiFi for anything.  Any of our - it's all wired.  But we have an open access point as a convenience for people who come to visit us.



STEVE:  Well, to answer...



LEO:  Actually, it's not open.  We give them a password.  Never mind.



STEVE:  Oh, good.



LEO:  Yeah, it's WPA2.  Of course, what am I thinking?



STEVE:  Okay, yay.  That's better.



LEO:  Yeah.



STEVE:  Well, first of all, this is one of the main reasons that I've got CryptoLink in my future is it's for exactly this kind of application.  If Jim had a machine running at home, then he could robustly, and with a high chance of succeeding, access his machine at home from anywhere he was on the planet, and then surf or use the Internet back out through his home connection, exactly as if he were at home, not needing to trust anything between where he is and home.



Now, there are other VPN solutions, but traditionally extremely difficult to configure.  I mean, remember that I started doing an OpenVPN configuration guide.  And, I mean, I use it.  But you really need to have your propeller spinning pretty much 24/7.  And, due to some quirks of it, you cannot guarantee a connection.  For example, if you happen to be in a local network whose IP address range is the same as the network at the other end, then routing doesn't work because OpenVPN is routing based.  So there are all kinds of little gotchas that make it much less robust than, well, than I believe a VPN could be and should be.  Which is why that's GRC's next product.



But there are some commercial VPN solutions.  There are some free ones that make me a little nervous because you wonder what their economic model is.  How and why are they free?  But there's also one that we've talked about, and you and I have both used, Leo, called HotSpotVPN.



LEO:  Yes.



STEVE:  And I jumped over to see what the pricing model was.  Now, Jim said it didn't have to be free, but he wanted it to be reasonable.  Well, HotSpotVPN 2, which is their SSL-based, and it's OpenVPN-based SSL, that's $10.88 per month.  And you can buy it for one month, so it's a little less than $11.00.  And I think in a temporary office mode where you're otherwise being forced to use open WiFi, it's a perfect solution.  You download their little installer that basically installs OpenVPN, does all the configuration and sets things up.  I mean, it's very easy to use and set up.  And then you simply fire that up.



Because they're out on the Internet, you know that you're with a high likelihood able to access them.  They use maybe port 80 and 443, both HTTP and HTTPS?  It's been a while since I used them.  Or maybe it was FTP and HTTP.  Anyway, there were a number of ports that you were able to use to maximize your chance of being able to connect to them.  And they make a lot of sense.  They have a less expensive version, HotSpotVPN 1, which is traditional PPTP VPN.  Now, that's the VPN technology that Windows has built in.  So I like that from the standpoint of you not needing to install anything on your machine, even temporarily.  And it's less expensive.  That's $8.88 a month.  And they even offer it in one, three, and seven-day packages for 3.88, 5.88, and 6.88.  So 6.88 for a week, for example.  But because it's PPTP, you're not quite so sure that you're going to be able to access.  You could have an ISP that's blocking that traditional VPN port, or the local network could be blocking it, although in Jim's case, with an owner that's boneheaded enough to be running open WiFi for his whole company and employees and temporaries, I doubt that they're blocking anything.



So for as little as 8.88 a month, you could use the HotSpotVPN 1 version, which doesn't require that you install anything, and they help you get set up and configured in order to be able to use their VPN.  That solution, of course, fails my TNO, my Trust No One goal, because you are trusting them.  But they're a commercial outfit.  You're trusting them because all of your traffic goes through them and then emerges unencrypted onto the internet at their location.  So they're also someone where, if our U.S. government wanted to be snoopy, they would tend to be looking at traffic at those sorts of aggregation points because a lot of people who for some reason feel that they have something to hide, are going to be using this kind of a service.  So I like the idea of staying a little bit further under the radar by using your own existing, for example, residential Internet connection for your own traffic.  But that's not available yet.  It will be as soon as I can get to it.



LEO:  There's one out that a lot of people have been telling me about lately called Hotspot Shield.



STEVE:  Yup, that's the free one.



LEO:  That's free.  What do you think of that?  Have you looked at that?



STEVE:  I haven't looked at it closely.



LEO:  It's by a company called AnchorFree.  Same idea as HotSpotVPN.  HotspotShield.com.  I like the idea of paying somebody because I figure they're going to have faster servers.  They're going to be around.



STEVE:  Yes, I do, too.  I mean, and 10.88 a month, I mean, that's $10.88 for one whole month of use.  And you and I both use HotSpot, and they do have multiple locations and servers and really good performance.



LEO:  Yeah.  And I like SSL, I mean, that's really great.  That makes it a lot - that makes it so easy.  Moving right along, Dixon in San Francisco wonders about YubiKey and keystroke loggers.  In Episode 180 of Security Now! you discussed knowing what tools are supposed to combat what threat.  I know YubiKey's function is to prevent dictionary attacks.  Can you clarify whether YubiKey has any meaning against keystroke loggers?  In other words, do keyloggers work before the full OS is booted?  If I use a YubiKey to log onto Windows and boot up, would a keylogger be able to see that?  How about after the full OS loads?  I notice that Windows Vista and 7 no longer require Ctrl-Alt-Del to get to the login screen.  My understanding was that little requirement was supposed to thwart keyloggers.  Is that true?  Thank you.  Would Ctrl-Alt-Del thwart keyloggers?



STEVE:  Well, actually yes.  From the minute NT was created, and they were talking about how it had the S3 security certification stuff, which it never really had, by the way, because you cannot be on a network and get that certification.  So the moment you put yourself on a network...



LEO:  Oh, well, then, never mind.



STEVE:  ...the computer loses the ability to have S3 government certification for security.  It's like, uh, sorry.  You plugged this into something else, so we don't trust you anymore.  Okay.  So it is conceivable that you could have a boot virus keylogger that could co-reside with YubiKey.  We know, for example, that Adobe's DRM is able to, thanks to - I'm sorry.  The keylogger could co-reside with TrueCrypt.  And we know that Adobe's DRM forced the TrueCrypt guys to reduce the size of their footprint down in Track 0 and create redundant copies so that, if Adobe's DRM stomped on one of them, you'd still be able to access your computer.



So it's conceivable that a keylogger could install itself in Track 0, co-reside with TrueCrypt, and get control before TrueCrypt, hook the BIOS keyboard interrupt, which is how it would read keystrokes, feed those to TrueCrypt.  Maybe TrueCrypt wouldn't notice that.  I don't know whether TrueCrypt checks for that happening, although it's possible that it could.  On the other hand, if it did, the keylogger could also neuter that check in TrueCrypt before TrueCrypt gets running.  So, I mean, it's theoretically possible for preboot authentication to log what you type when you're logging yourself in for whole system decryption.  I mean, I could write something that would do that, which means other people could, too.  So it's not the case that you could - that it's absolutely impossible for a keystroke logger to watch you do preboot authentication.  So that's a possibility.



It is the case that this whole login screen was deliberately designed by Microsoft to thwart any sort of keystroke logging.  That Ctrl-Alt-Del changes sessions, it raises security, it's really supposed to, like, put you into a whole - there's a whole desktop technology.  It moves you to a different desktop.  And I don't know now in this day and age if that's been bypassed.  I do know that Microsoft went to some lengths to make that Ctrl-Alt-Del and the password screen really mean something from a security standpoint.  And so you do wonder if they've backed off on that, if they've managed to maintain the login security with the same strength as they had before.  And I don't know one way or the other.



LEO:  Okay.



STEVE:  So YubiKey and keyloggers, this is the problem with static keys.  I mean, this has come up several times in this one hour, is that YubiKey is very convenient to use in a static key mode, but it doesn't really represent a full 'nother factor of authentication.  And because it's the same, it is prone to being recorded.  So, you know?



LEO:  So there.



STEVE:  There.



LEO:  Alex B, lurking somewhere in Minnesota, wants a reality check.  He says:  Hi, Steve and Leo.  I'm guessing, hoping actually, that others have already alerted you to this.  But if not, here goes.  Oh, first things first.  I love the podcast.  It makes my commute so much more enjoyable.  On page 77 of the January issue of PC World, a writer had a small article entitled "Stop Your Neighbors From Stealing Your Wi-Fi Bandwidth."  Quoting from the last paragraph of the article:  "You could just turn on your router's built-in WPA encryption, but that won't do you much good if your kids blab the family's WiFi password to everyone on the block.  Instead, turn on MAC address filtering in your router's security settings.  You'll have to spend a few minutes entering the MAC hardware addresses for all your devices.  But after that you won't need to use any additional security at all."  Oh, my god.  "Only known" - I added the ohmygod.  I don't think it was in the article.  "Only known devices will be allowed to connect, so a password's not required."



Alex goes on:  To say that I was stunned after reading this is an understatement.  Who in the tech world really thinks it's okay to disable encryption for any reason, let alone in favor of MAC address filtering?  MAC address spoofing, as we Security Now! listeners all know, is trivial.  Not only that, but simply preventing someone from joining your network doesn't mean they can't sniff all your unencrypted packets floating around the neighborhood.  What do you think?  Thanks again, and keep up the good work.  Wow.



STEVE:  Yeah.  He was actually even more upset than that.  He named the writer, and I took the writer's name out of this because I didn't want to lambaste anyone.  It's, well, everyone listening to this podcast knows that Alex is right, that MAC address filtering is no protection against somebody who maliciously wants to get onto your network because the MAC addresses are on the unencrypted front of all the packets traveling on your network, so they're easily copied and spoofed.  You simply clone the MAC address, and then the router that's got MAC address filtering thinks it's you.  We do know that MAC address filtering is convenient for preventing inadvertent use of the network.  So it does, if for some reason you had to have your router open, that is, nonencrypted, then you could at least use MAC address filtering to prevent somebody, a neighbor, from mistakenly using your network because their MAC wouldn't match, and your router would not acknowledge their broadcast for access.



I would say a couple things.  First of all, you should not have a WPA passphrase that is easily stated.  That is, we've talked about using the YubiKey, for example, as a beautiful way of quickly entering your WPA key into visiting computers, rather than having to type something long and laborious in.  So one solution is for the family's router to have a really nasty, gnarly passphrase which, you know, where you've got to have a piece of paper, and where it's written down and you type it in.  So all you need to do is configure the younger member of the family's laptops once, not giving them the paper, but typing it in for them.  That's not then something that they can give to their friends because there's no way that they're going to know it or memorize it.



The alternative is to use both.  That is, because there's nothing to prevent you from using MAC address filtering and WPA encryption at the same time.  That has the advantage, if you wanted to use a passphrase that was memorable, it has the advantage of being easily entered by somebody who wants to add a machine to the network or if a machine loses its password or becomes disconfigured.  But then you'd still need to log into the router and manually add the machine's, the new machine's MAC address into the permitted list for communications.  So I would say use both as opposed to either one in this situation.  And it really is unfortunate that a writer in this day and age is saying, is recommending to turn off encryption and use MAC address filtering because obviously, as Alex points out, and as all listeners of this podcast know, those are not the same at all.



LEO:  Yeah.  Use WPA.  It's all you need, and it works, and it's simple, and it just works.



STEVE:  Yup.



LEO:  And I'm seeing another article on PC World where the guy says use SSID hiding.  I wonder if they've got editors who know what the hell they're talking about.  I mean, how is this stuff getting through?  It's very frustrating to me because of course people read this, and then I have to explain it on the radio.



STEVE:  Right.



LEO:  But they said so in PC World.



STEVE:  Yeah, who's right, Leo?



LEO:  PC World's a magazine.  They must know what they're talking about.  Please.  Geez, Louise.  Okay.  Now let's go to our PayPal questions here, starting with Brian in Raleigh, North Carolina, who has discovered that PayPal's security key is worthless when faced with social engineering.\:  I recently lost my PayPal security key, but I needed to log onto my account.  So I tried to log onto PayPal.com.  I selected the "I don't have a key with me."  Then I selected "I lost my key."  The website said call customer service because my identity couldn't be verified.  All right.  Good so far.  When I called customer service, though, I discovered all I needed was the last four digits of my credit card, and my name.  Then they would deactivate the security key, even let me reset my password.  This, of course, terrified me.  With the information available on any restaurant credit card receipt - because that's what they put on there, isn't it, the four digits of your credit card.



STEVE:  Yes.



LEO:  Or a little dumpster diving plus some basic social engineering to get the logon email address, you could have full access to anyone's PayPal account.  Yikes.



STEVE:  Yeah.



LEO:  This is a serious security flaw that shocks me.  They should at least ask for the full credit card number, if not some security questions.



STEVE:  Or maybe the second group, the second to the last group of four.  I mean, it's so common for everyone to show the last four digits in order to identify which card among multiple cards.  So that means that that's now public knowledge.  The idea of asking two public knowledge questions, the last four digits of your credit card and your name, I mean, and then, okay, fine, and that's the entire barrier for resetting the security on your PayPal account.  That's just nuts.



LEO:  Wow.  I guess there's nothing we can do about it except to say, PayPal, fix it.



STEVE:  Oh, but wait.  There's more.



LEO:  Oh, wait, there's more.  Robert in San Francisco with another PayPal screw-up.  All right.  Get this.  I had two PayPal security keys, the footballs, one for home, one for office, and I lost one of the two keys.  Now, PayPal has a page where you can report the key is lost.  After reporting, it shows as lost.  The other key shows as active.  Then I received an email from PayPal stating that my key had been reported as lost, and it would no longer be required for login.  So get this.  When I went to log in again, it accepted the password alone and did not prompt me for my remaining, still active key.  The non-lost key still shows up in my profile as active.  Now what?  So it just says, okay, fine, you don't need it anymore.



STEVE:  So you have multiple keys protecting your account.  And you can use any one of them to log in.  You lose one of those keys and report it as lost.  Now your account, even though you still have other keys, no longer requires them.  No longer gives you the option of using them.



LEO:  And you can't turn it back on?



STEVE:  How would you?  They're already shown as active, but the system just doesn't need them.  I mean, it's like, come on.



LEO:  If there were only some other choice.



STEVE:  I know, like I said, there has never been a company that needs competition more desperately than PayPal.



LEO:  Well, I'm of the opinion eBay is about to go under anyway, so maybe the whole thing will collapse, and we can go somewhere else.



STEVE:  You think so?



LEO:  You and I totally rely on PayPal.



STEVE:  Yeah.



LEO:  Well, I just think eBay is not doing well.



STEVE:  Are they really not?



LEO:  Yeah, I think people have started to realize that it's just not a safe place to do business.  And those lax practices...



STEVE:  [Indiscernible] me like just too many scams.



LEO:  Yeah.  And those lax practices are spreading to its subsidiary.



STEVE:  In fact, there were several times in the last couple weeks where I bought a couple things from a single eBay seller.  And I said hey, you know, eBay seems to really misjudge shipping costs at the high end.  It's like, wait a minute, this cannot cost $50 to ship this from Raleigh, North Carolina.  So I said - I wrote to one guy in particular, I said, hey, you know, I bought these two things.  Could you put them together, combine the shipping, and send me a request for payment that has them combined?  And apparently they used to do that, but there was some scam that purchasers were perpetrating where they would do that, and then say that - I guess tell eBay that...



LEO:  They only got one of the two.



STEVE:  Yes, one of the two, and the cheaper of the two, and then get a credit for the other one or something.  It's like, oh, goodness, okay, fine.  So what are you going to do?



LEO:  I just, you know, I don't know what to say.  It's got to get better.  It's got to get better.



STEVE:  It's a great concept.  I mean, I love the idea.



LEO:  I do, too.  And if it weren't for all these scammers out there...



STEVE:  Yup.



LEO:  But they're just out there.  I guess we have to live with them.  Watch out.  Zombies are on the way, folks.  Run.



STEVE:  Head for colder climates.



LEO:  Head for colder...



STEVE:  [Indiscernible] warm climate.



LEO:  Oh, zombies, do they not like colder climates?



STEVE:  I don't know.  I didn't think zombies were really temperature sensitive.



LEO:  I didn't think so either.



STEVE:  No.



LEO:  They go where the brains are.  Steve, it's great talking to you.  Thank you so much for being here.



STEVE:  Always, my friend.



[Talking simultaneously]



LEO:  Go ahead.



STEVE:  I'll remind our listeners one more time, KatMouse, K-a-t-M-o-u-s-e.  It will change your life if you like the scroll wheel on your mouse and you're a Windows user.  Oh, my god, it's just wonderful.



LEO:  I'm putting it on all my Windows machines.



STEVE:  And believe me, I mean, you'll just, like, oh, it just - and not to have to click in the window first in order to get its attention.  It's wherever the mouse is hovering, that gets scrolled.  It's tremendous.



LEO:  Steve's at GRC.com.  That's his website.  You can find 16KB versions of this show.  You can find transcripts, show notes, all that information.  We also have now very complete show notes, thanks to our listeners to the live stream on the wiki, at wiki.TWiT.tv.  When you go to GRC, don't forget to get a copy of SpinRite.  Everybody should have that.  Everybody needs...



STEVE:  Yabba-dabba-do.



LEO:  Yabba-dabba-do, SpinRite, the ultimate file, I'm sorry, disk maintenance and recovery utility.  And of course lots of great free programs there, as well.  GRC, Gibson Research Corporation, dotcom.  Thank you, Steve.



STEVE:  Leo, talk to you next week.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#183

DATE:		February 12, 2009

TITLE:		Modes of Encryption

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-183.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  In preparation for a deep and detailed discussion of Secure Sockets Layer (SSL), Steve and Leo first establish some formal crypto theory and practice of encryption operating modes.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 183 for February 12, 2009:  Modes of Encryption.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all your security needs - privacy, online security, encryption.  Here's the man who put it all together, Mr. Steve Gibson of GRC.com.  Good morning, Steve.



STEVE GIBSON:  Leo, let's do a podcast.



LEO:  Let's do - it's a beautiful day.  Let's do two.



STEVE:  It's a beautiful day for a podcast.



LEO:  Yeah, it always is because we're inside, actually.



STEVE:  Yeah.



LEO:  And I've got all the windows closed.  So I don't even know.  Day or night, it's like Las Vegas in here.



STEVE:  What was it I heard happening during - I picked up a little bit of it during Mac Break Weekly, some modifications you're making to the structure or something?



LEO:  The structure.



STEVE:  Did something fall down?  You had to post a bond?



LEO:  What?  I probably was joking around.



STEVE:  Oh, okay.



LEO:  Did we have to post a bond?  I don't think so.



STEVE:  Sounded like some modifications made to the cottage, anything about that?



LEO:  Oh, I was joking around with the Giz Wiz that we'd moved the cottage six inches to the left.



STEVE:  That's what it was.  It was...



LEO:  That was a joke.



STEVE:  It was while I was watching the playback of Giz Wiz.



LEO:  Yeah, yeah, yeah.  I was just joking around.



STEVE:  Oh, okay.



LEO:  Never believe anything you hear on the Giz Wiz.



STEVE:  Oh, no.



LEO:  It's all pretty much made up, yeah.



STEVE:  Yeah.



LEO:  So today we're going to talk about encryption.



STEVE:  Once again.  It's obviously a continuing topic because it's hard to argue that there's anything much more important to security than issues of encryption.  We're heading toward a podcast where we're going to really clearly, thoroughly discuss the number one most used encryption protocol, I mean, like, that there is, that all of us use, which is SSL.  And I had said that I was going to - this week we were going to talk about so-called "keyed hashing" algorithms.  But in laying that out and sort of getting it, like, put together, I realized, wait a minute, there's something - there's a little bit more foundational stuff we need that leads into that, that we really need to cover first, and that is also necessary for discussing SSL protocol.



So this is - I guess the title of this week's would be "Modes of Encryption," which is something we've touched on a little bit, but never really talked about.  And there's also so much security news this week that I thought, if I tried to cram all that into one, it would just - I don't know.  People would fall off, I mean, they'd get to work and still have podcast left.  They'd fall off their stair climbers.  It would just be going too long.



LEO:  You're doing this for our protection.



STEVE:  I always have our listeners in mind.



LEO:  Thank you very much.  Yeah, sometimes I find that there's a lot to digest in a show.  And...



STEVE:  That ball you're bouncing on would end up deflating by the time...



LEO:  That's why the transcripts are great, and people, you know, it's a podcast.  You can go back and listen again and again.  This show especially, even though we do cover security news and so forth, most of the content is really timeless.  And today's will be a good example.  The topics we're going to talk about are things you'll need to know about this stuff for a long time to come.  But before we get going, I know there's some errata, and there's some security news.  And I think Tuesday was a Patch Tuesday.  I don't know, I didn't see any patches this...



STEVE:  Oh, baby.  That's where a lot of it comes from.  Yup.



LEO:  Oh, all right.  Well, we'll talk about that in just a second.  So let's, I guess, get the news and errata out of the way.  And then...



STEVE:  Yeah, out of the way, Leo...



LEO:  First let me get the box over your face out of the way.  Okay, now.



STEVE:  This is a major feature of our podcast.



LEO:  Out of the way?  This is what people tune in for.



STEVE:  Everyone looks forward to what new nightmares have surfaced in the last week.  And in this case of course we are just past the second Tuesday of the month.  So Microsoft has dropped another load of bits on us.



LEO:  Yes.



STEVE:  They're, oh, you know what I meant to - I did the update specifically so that I could do MRT and see - confirm that it did say February.  And there, sure enough, MRT.  I did MRT from the Start=>Run dialogue, and up comes Microsoft Windows Malicious Software Removal tool, February, 2009.



LEO:  Excellent.



STEVE:  Confirming that all the update happened, and I do have the most recent version of that.  And of course it would have done a quick scan after the reboot, and then you can optionally do the deep scan and go away for a long time.  Actually, you have to go away for a long time when you download this month's updates.



LEO:  Is it that big, really?



STEVE:  Oh, my god.  Well, first of all, the big bad news was that IE7 has a critical problem that affects XP and Vista, but not IE5 or 6.  So if you're using IE5 or 6, you don't have a problem.  If you are using - if you are now up to IE7 - which of course is the current browser, and they've got 8 in beta.  If you're up to IE7, then there is a, just by going to a site that's malicious, you can have your machine compromised.  Or, since Outlook and Outlook Express by default use the IE viewer, if you click on a link in email that you receive, that can do the deed, as well.  So there were a number of critical problems that were fixed in IE7.  So that's been fixed.



There is a new version of the MSRT, as I mentioned.  And that was about - a little less than 10MB, about 9.8MB.  Then there was this cumulative security update to IE7 is what they've called it.  That was 8.6.  There's an update rollup for ActiveX kill bits.  And remember from us having discussed that before, the kill bits are a feature that Microsoft added to prevent ActiveX controls from running in IE because that's one of the major exploit vectors is IE, you're able to script a page in IE that invokes ActiveX controls.  And they can be any ActiveX controls in the system, even those for which it makes no sense to run them on a web page, which has been a source of many vulnerabilities and security problems in the past.  So Microsoft is now doing a continually better job of deliberately setting kill bits, as they're called, for ActiveX controls that should not be allowed to run under an IE context or by a web page because it just makes no sense to do that.  So that's been updated.



There were - I'm still using Office 2003.  So I can't speak to what may have happened with 2007.  But for me, there were two updates that affected Office 2003.  Then the big mother was a .NET Framework update.  And it's 250MB.



LEO:  Oh, please.



STEVE:  So it's one of those...



LEO:  Now, is this required?  Because .NET didn't used to be required; right?



STEVE:  Well, and technically it's still not.  But it's one of those things where you'll run across applications.  And it's going to be increasingly the case in the future where they say "Requires the .NET platform."  And so there's - we're now at 3.5 is the current version of .NET.  And so this was the .NET Framework 3.5 Service Pack 1, and the .NET Framework 3.5 Family Update, whatever that is.  But together they were 250MB.  They downloaded at no great speed and then took forever to install.



LEO:  What if people - they couldn't have done this until everybody had broadband.  What do people, you know, 57 percent of the nation has broadband at home.  But that means that there are 20 percent or something that don't have high-speed Internet.



STEVE:  Can you imagine.



LEO:  What do they do?



STEVE:  With a modem.



LEO:  What do they do?



STEVE:  Yeah, every four weeks, gulp, here comes another one.



LEO:  So cumulatively this is probably almost a third of a gigabyte download from Microsoft.



STEVE:  Yeah, you're right, you're right.



LEO:  Their bandwidth bill must be astronomical.



STEVE:  Yeah.



LEO:  I hope they're using P2P.  You know, somebody's laughing at me because I said 57 percent and 20 percent.  But remember a lot of people aren't online at all.  So that's where that number comes from.



STEVE:  And I know...



LEO:  I think dialup is only 14 percent.



STEVE:  They're not listening to us, either, Leo.



LEO:  That's right.



STEVE:  Cannot reach - cannot reach them.



LEO:  Well, we make a 16KB version for dialup people.  We do.



STEVE:  Bandwidth-impaired, as you so delicately put it, yeah.



LEO:  I just read a stat.  That's about 14 percent of the population now.  But those people are out of luck.  They're not going to be updating.



STEVE:  Yeah.  Well, they also don't have security problems, do they.



LEO:  Well, do they?



STEVE:  Not if they're offline.  As long as they lock their door.



LEO:  So if they have dialup, and they are surfing to these malware sites, you bet they have security...



STEVE:  Oh, oh, oh, I thought you meant completely out.



LEO:  Oh, no.  What does that leave left?  The 30 percent who are not online at all.  Maybe not 30 percent.  20 percent are not online at all.  Those people, we don't have to worry about them.



STEVE:  Well, we also had a Firefox and Thunderbird update.  And SeaMonkey, for that...



LEO:  I like SeaMonkey.  Mozilla, yeah.



STEVE:  Yeah.  Firefox needs to be at 3.0.6.  So you'll want to make sure that you got that.  And Thunderbird needs to be at 2.0.0.21.  And that fixed six flaws, some of which were critical, meaning that even in the Mozilla parlance, doing something innocently can cause your system to be remotely compromised, a remote code exploit.  So you'll want to make sure that you're updated there.  And I picked up on another little thing that I thought I would just mention.  It's sort of obscure.  But VNC is a remote desktop application that I know many people use, and probably many of our listeners.



LEO:  Oh, yeah.



STEVE:  There's a client-side vulnerability in both UltraVNC and TightVNC, which are probably the top two most popular versions of VNC, such that if you went to a malicious server - which I think is unlikely because normally you're going to your own server.  But if a VNC client for whatever reason were to connect to a server that was misbehaving, there is a way that such a malicious server can take over your machine remotely.  So again, I think it's unlikely to happen.  Normally VNC users have, like, they're running the server on their system at home so that they're able to, if they're out roaming around, they're able to connect to their desktop at home, which is obviously a server you trust because it's yours.  But I just wanted to bring it up to let people know, if they're running UltraVNC, you want to be at v1.0.5.4; and if you're running TightVNC, you want to be at 1.3.10.



LEO:  Okay.



STEVE:  To be current there.



LEO:  Got it.



STEVE:  And lastly, sort of another obscure, but again the most popular one of its class, there's a download manager called Free Download Manager, FDM.  And it has a remote execution vulnerability such that, if you were to download a file, using Free Download Manager, from a malicious download site, it can take over your computer.  So I think that's not quite as obscure.  That's something anyone using FDM, Free Download Manager, would definitely want to know about and update themselves to the latest version to avoid this because it seems to me it's rather common that you might be going to a site that you don't know you should not trust and say, oh, I'm going to grab this file, and bang, get your machine taken over.



LEO:  Yeah, I had DownThemAll!, which is a Firefox plug-in, because I was trying to download a large file, I never could, and I put it on there.  And I noticed it was really trying to - wanted to download everything from a page.  And I thought, you know, I don't feel right about this.  That's not good.  It was too easy to download a bunch of stuff.  So I just - I took it off.  I said, you know, I think it really should be that I explicitly say I want this.



STEVE:  Oh, yes, Leo.  I'm sure that's the case.  And in interesting news relating to Windows 7 - I know that you and Paul are talking about it a lot.  I've been listening to you guys talk about it.  And of course the controversial, from my standpoint, security aspect of the reduced strength of UAC, the User Account Control that we covered in detail when it first appeared in Vista, Microsoft softened the UAC operation so that it wasn't popping up so much.  And what they attempted to do in Windows 7 beta - we should remind ourselves that it's beta.  And by the way, there will be another one.  That was not the last one.  And so it's a good thing they didn't release it already as Windows...



LEO:  Well, there'll be one more RTM.  I mean, this is really pretty much it.



STEVE:  Right.  But they're changing the functionality of UAC.



LEO:  They're turning up that UAC, which is really good, yeah.



STEVE:  Exactly.  Because unfortunately they turned it down too far.  There are now proof-of-concept code on the 'Net which is able to disable UAC.  Essentially it's sort of scripting code that scripts the actions that a user would perform in going into the control panel and using the UAC control in the control panel to turn off UAC.  And so Microsoft said, uh, whoops, that's not what we intended, of course.  And so what they're doing is they're still going to keep UAC less noisy, which people really want.  However, what they're doing is they're specifically and explicitly protecting that particular attack vector.  That is, it will be - they're protecting the control panel interface to UAC with a much more - by using a much higher...



LEO:  That's a good solution.



STEVE:  Yes, by using a higher privilege process.  And they're adding one more thing that they didn't have, which is, I mean, again, in retrospect, like so many of these simple security mistakes, it makes a lot of sense.  And that is, if the strength or configuration of UAC is changed, it absolutely requires manual user confirmation.



LEO:  Yes.  Yes.



STEVE:  Which it didn't before.  That will be in the next release of Windows.



LEO:  See, that's the way to handle this.  And you could even use that lower setting as long as it said anytime anybody wants to change this setting you've got to...



STEVE:  Yes.



LEO:  You know, your password or [indiscernible].



STEVE:  Exactly.  And so, I mean, so there's...



LEO:  It's like that's a case where I think, even if you're running as admin, you should have to enter your password.



STEVE:  Yes.  Yes.  For something that is that critical and security-based and has global effect, you absolutely need to prove that you are who you say you are.  And it's not something that you would be doing often.  You would not be changing the level of UAC operation that often.



LEO:  Yeah, exactly.



STEVE:  And then the last little bit of security news was a little embarrassment that Kaspersky encountered.



LEO:  Saw that.



STEVE:  For about 10 days one of their main corporate databases was exposed through an SQL, a SQL injection attack.  We did a podcast some time ago that explained exactly what SQL injection attacks are and how they work.  So essentially they had their database exposed, hanging out on the network, out on the Internet.  And there were bad guys who were able to access their database.  And it was finally those bad guys, after a week and a half, who said, uh, by the way, you might want to fix that.



LEO:  Hmm.



STEVE:  So Kaspersky stated that - and this was corporate, this was their user, I mean, their customer database that was exposed.  Kaspersky said that confidential data was not taken or lost or exposed.  And so certainly that's good news.



LEO:  Kind of embarrassing, though, when that happens to a security company.



STEVE:  Oh, yes, indeed.



LEO:  That's kind of not what you want to have happen.



STEVE:  We have some interesting news from our friends at Yubico.  They've got a new wiki up on their site and are announcing on their site the YubiKing awards.  The YubiKing awards are, essentially, are starting now.  The idea is to find the best applications and ideas or online services or developer tools or pretty much anything involving the YubiKey.  Anyone who contributes on the wiki, which is where these awards will be, or the submissions will be made, and there's a whole bunch of categories for them, will - anyone who submits will get three free YubiKeys.



LEO:  Oh, wow.



STEVE:  Well, but the winner - three winners will be chosen.  50 percent of the choosing comes from participants in the wiki itself.  The other 50 percent comes from a jury that I am leading...



LEO:  Ah, cool.



STEVE:  ...for YubiKey applications of any sort.  We will feature those three winners on an episode of Security Now!.  They will receive five Special Edition YubiKeys that nobody else in the world will ever be able to get.  So very special YubiKeys.  And this is something that I discussed with Stina when she was out visiting.  Remember many months ago she was down in San Diego and swung by Starbucks and had coffee with me for an hour or so in the morning.  And we were discussing her notion of a YubiKing award.  And she's like, what can we give people?  And I said, how about something absolutely special that no one can ever get any other way?  And she said, oh, I like that idea.  So Special Edition YubiKeys.  And finally, the three winners get to attend this year's RSA Security Conference, with Yubico paying their travel, hotel expenses, and conference fees.



LEO:  Wow.  That's pretty cool.



STEVE:  So it's going to be very neat.



LEO:  That's pretty cool.



STEVE:  So the challenge is up.  If you go to Yubico.com you can click - there's many ways to get at the wiki.  But you can click the Developers Menu at the top of the screen, and then you'll see the wiki there.  Also, for any YubiKey owners, their wiki is a really nice example of using the YubiKey.  That is, it's easy to join.  I did it a few hours ago.  You say, you know, sign up, and it asks you for your handle.  You are never asked for a password because you don't need one.  You're a YubiKey owner.



LEO:  Right, right, right.



STEVE:  And they're doing all the online authentication.  So it's really - it's an interesting feeling signing up for something that is more secure than any signup you've ever done before because you're using the YubiKey in its one-time password mode with online authentication.  Yet it's so simple because you just put in your handle, and then you touch the little button.  And it's funny, too, because you don't even have to click, like, log me in because the YubiKey logs you in.  I mean, it enters it.  The page sees you enter the key and says, okay, let's authenticate and log the person in.  Anyway, it's sort of a neat experience.  If you're anyone listening to this who has a YubiKey, I would urge you to go try that experience, if you haven't before, of a really well-integrated YubiKey logon experience using the wiki that's now at Yubico.com.



LEO:  I now have to get more YubiKeys.  I only have one.  One is not enough.  I need many YubiKeys.



STEVE:  Well, I think we've stated that two, one that is in static...



LEO:  One static, yeah, yeah.



STEVE:  Yes, static password mode, and one that is in its original one-time password mode, where it's changing every time.  And then you've sort of got your bases covered.  And it would be nice to have one YubiKey that could do both.



LEO:  Do you have a lot of people, now, if you get the one that's not in static mode, it's going to Yubico's servers, and they're using the Yubico server.  But are people starting to implement their own YubiKey servers?  Because ultimately that's what you want to do; right?  Like Bank of America would have its own key server.



STEVE:  Correct.  And, for example - well, okay.  The problem with your own key server is that Bank of America would then need to know what the secret AES key was inside your YubiKey.



LEO:  But that's what they do with those cards, the VeriSign cards, or the footballs that are sent out by PayPal; right?  That's how that works.



STEVE:  Except that they're all using VeriSign as their back end.



LEO:  Oh, okay, okay.  So it's normal to use a third-party back end.



STEVE:  Exactly.  And...



LEO:  Oh, okay.  So having Yubico be the back end is not a problem.



STEVE:  Exactly.



LEO:  I see.



STEVE:  Yes, yes, yes.  And so, for example, in my own forthcoming VPN product that we've talked about before, CryptoLink, I'll allow a user to do it either way.  They could, for example, when they're out roaming around and want to authenticate - actually three ways - and want to authenticate, they could use static password mode for if that's the way their YubiKey was set up.  Or they could either have the CryptoLink endpoint that they're connecting to, that would be in this case acting as a server, they could have it know the YubiKey algorithm which is publicly known, and have it also know the private key, which would require that they have sort of, like, privatized their key.  It would no longer then work with other back-end services because they would have changed their key in order for CryptoLink to know it.  Or they could just have CryptoLink use Yubico as the third-party authenticator for their key, depending upon how they want to operate.  So all possible modes.



LEO:  And we - and, okay, forgive me for asking a - I don't want to insult Stina.  But we trust Yubico.  I mean, it's not like VeriSign.  I mean, everybody knows VeriSign.  But Yubico, maybe people don't know Yubico so well.  But does it matter?



STEVE:  Well, I mean, that's - I absolutely trust them.



LEO:  Of course you do.  You work with them.



STEVE:  But remember that one of my acronyms, which is...



LEO:  Trust No One.



STEVE:  ...fundamental to what I'm doing with CryptoLink, exactly, is Trust No One.  And no one means no one.



LEO:  Right.



STEVE:  And so I wanted to provide a mode for VPN authentication where there was nobody involved except equipment you own - your client and your server - yet still give you the benefit of one-time password, super-strong, non-keystroke-recordable sort of logon.  Well, that requires that you then take your key algorithm private so that, without using a third-party back end, you're able to authenticate.  But there is the extremely useful mode, for example, of using OpenID, where you really - you inherently need to trust a third party to do your authentication.



LEO:  What is the - okay.  Let's say that somebody, not Yubico, but somebody like Yubico was doing this, and they weren't trustworthy.  What would be - would it be a man-in-the-middle attack?  What would the threat be?



STEVE:  Okay.  The threat would be that...



LEO:  They would know your password, I guess.  But they wouldn't know your password.  They'd only know one part of it because you're using multifactor authentication.



STEVE:  Anyone who could authenticate, by definition, knows the internal state of your key, the whole internal state.  They know the value of the counters, which are incrementing, and they know the secret key which is applied - which those counters are applied against in order to generate the result.  So anyone who had that could impersonate your use of that key.  So if they knew, for example, your username and a site where you authenticate, they could generate the next series of logins into the future for your key.



Now, at the same time, if they're the people doing the authentication, they don't really need to do that.  They just have to say, I mean, they could login as you, see the request come back to them and say, oh, yeah, that's fine.  So you are definitely trusting an authenticating agent significantly.  You're really - you're trusting their complete disinterest in having...



LEO:  In your stuff.



STEVE:  Exactly, in having any reason for impersonating you.  And of course, in the case of a real crypto company, their entire reputation is on the line.



LEO:  Oh, yeah, yeah, yeah.  And please, nobody, am I in any way impugning Yubico.  But this is what we talk about, I mean, is what is the risk of trusting somebody.  And...



STEVE:  Yes.  You're exactly right, Leo.  I mean, everything about security is understanding what we talked about a couple weeks ago, which is the threat model.  What does it mean to have what type of vulnerability, and what is the exposure?  So it's absolutely useful to discuss that.



LEO:  Okay.



STEVE:  Also you and I were talking before we recorded, but I wanted just to mention I have here in my notes the Kindle 2 has been announced by Amazon.



LEO:  And guess who's ordered Kindle 2s?  Just take a wild guess.



STEVE:  You and I were first in line.



LEO:  Because, you know, you can't have too many Kindles.  I have two Sony eBook Readers which I don't use anymore.



STEVE:  I have two also.  I've got the 500 and the 505.



LEO:  Me, too.  And I bought the Kindle.  But we use the Kindle.  We love the Kindle.



STEVE:  It's the one.  I mean, it absolutely is the one.



LEO:  But what we've never liked is the form factor.  It's ugly.  It's too easy to turn pages.  I've never been happy with it.  This might improve that.



STEVE:  Well, it's - what I love about this one is it is thinner.  And even though the existing Kindle is not that thick, it is funky looking.  So this one is classy looking.  They've pulled the page turns away from the corners, so now you're able to, like, slip the Kindle into a number of different cases that use little corner elastic straps in order to hold it in.  Their mechanism for holding the first Kindle into that little binder was really strange.  I mean, it was kind of clever, but it didn't work very well.  So it was often falling out by itself.



LEO:  I only used it when I was going to throw my Kindle into a briefcase, and I wanted a little extra protection.  The rest of the time, right now it's sitting on my bedside table, and it's just...



STEVE:  Yeah, exactly.  And it was like from a material that didn't want to fold back nicely.



LEO:  I didn't even know what it was.  It was like - it was pressed paper or something, some weird material.



STEVE:  Yeah.  It was not good.  And in fact this new Kindle does not come with one.  There is no cover provided by Amazon.  If you want one, you've got to purchase one from a number of different third parties.



LEO:  Okay.  So they don't come with a cover at all.  They offer their own leather cover, which is 30 bucks.  I bought, you know, and then I looked at there's a very fancy leather cover for 100 bucks.



STEVE:  Cole Haan.  Cole Haan has, like, five or six different versions of those.



LEO:  But I bought the nylon one that has...



STEVE:  Yeah, do you mean the neoprene one?



LEO:  Yeah.



STEVE:  Yes, I did also because I think that would be...



LEO:  And it said it has protection for the screen and stuff.  So we'll give you a review.



STEVE:  So you and I will have ours coming before the end of February.  And I do like the fact, I mean, I'm encouraged by the idea that it's 16 levels of grey because that would allow them to do a little bit better anti-aliasing and to show images, photos and things better.



LEO:  So it's a better screen than the old one.



STEVE:  It's a better screen.  It's faster page turn.  They did away with that funky weird LCD stripe along the side, where you had the little roller ball in order to, like, do selections.



LEO:  Yeah, I'm a little concerned because I used that.  I don't know how - they have a five-way thumb thing now; right?



STEVE:  Well, they have a joystick.  It's like left, right, up, down.  And so they move an onscreen cursor around.  So they must have improved, like, the real-time refreshability of the screen in order to, like, move an eInk object around the screen.  And they also increased the battery life.  They're saying now that, if you leave the cell modem on all the time, you can get four days of use with the cell modem on 24/7.  And if you turn it off, as I only turn it on in order to, like, refresh and update magazines and newspapers and things for a few minutes in the morning, then you can get as much as two weeks of life out of it.  Which is pretty much what I get now.  So I guess, I mean, it's obviously how many hours per day.



LEO:  They measure it by page turns, not by time so much.



STEVE:  Right.



LEO:  Because it doesn't use any power till you change the page.  Although it does use power with that wireless thing, and that's the - yeah, I, like you, I turn that off except when I want to download something.



STEVE:  And so they've moved that control into the UI.  Right now in the first Kindle there were two switches, one for main power and one for WiFi, I mean one for cell modem.  And now it's in the UI.  So that'll be interesting to see how that is.  It'd be nice if you could just say, turn on until you've checked, and then turn yourself off.  So I'm really interested to see, you know, what other tunings and tweakings they have done to the UI.  But it does look like a nicer solution.



The problem remains, the number one problem, as you and I were discussing before we began recording, is the price.  It's $359.  It's not something that people can casually purchase.  And as you said, if it got down to 200, 199 - and I said 99 - then it would really, you know, people wouldn't just be knocked over.  But when people admire it when I'm in a restaurant reading, and then it's like, oh, my god, they want to see it, and they love it, and it's like they read a lot.  Then I tell them it's $359, they're like, whoa.



LEO:  Yeah, sticker shock.



STEVE:  Yeah.



LEO:  And you do save money on the books, but not a lot of money.  The best ones are 10 bucks.



STEVE:  Yeah.  And I'm finding some of the higher end technical books are still...



LEO:  Very expensive.



STEVE:  ...$45.  It's like, ow, you know, it's like, what, for some bits.



LEO:  There's no reason.  That's outrageous.



STEVE:  Yeah.



LEO:  Now, there's one other feature you didn't mention.  It can read to you.



STEVE:  Oh, yes yes yes.  That'll be interesting to see, you know, how that works and what kind of, well, what the quality is of that.



LEO:  They must have put a much better processor in this thing.



STEVE:  If so, it's not using that much power.  But you're right, I mean, you're right.  I mean, doing text-to-speech is not nearly as simple as just decompressing text onto a page.  So you're right...



LEO:  So the idea is you're reading along, and you're going to get in the car, you're going to go to work or whatever, you plug it into your stereo in your car and now say read to me, and you continue to read.  I think that's really cool.



STEVE:  I think, if it works, it could be very nice.  But you're right.  So, like, you're in the middle of a book, and it's like now you're no longer able to read visually, so it reads to you.  It does text-to-speech built in.



LEO:  It'll take some getting used to because computer text-to-speech is never quite as good as, say, somebody on Audible.com.  But handy to have.  Especially if you're reading the newspaper.  You know, I get the Times on there.  And what a great way to just keep up to date.  I'm very cur- well, you know, that's why - you buy it because you're into it.  I buy it because I have to review, I really want to review it for people.



STEVE:  That's just an excuse for you, Leo.



LEO:  It's why I got into the business.



STEVE:  Oh, don't give me that.



LEO:  This is why - of course it's - I acknowledge that.  But it's the whole reason that 25 years ago I got into this business, is so that I could get this stuff for free.  And now I don't get it for free, I buy it, but so that I'd have an excuse, a way to keep up with this stuff.  When I first started writing for - in 1978 when I started writing for computer magazines, it was just a way of getting free software.  And I've never stopped, really.  It was really just more ways to get stuff.



STEVE:  Well, at least you're able to write it off.  I mean, it is a business; it's a business expense.  And you can tell your wife, hey, honey, I had to buy this.



LEO:  Well, and I admit, I mean, I could go to Amazon and say I'd like a review unit.  That's what Andy Inako does.  But, see, I don't like to send the thing back after two weeks.  I want to keep it.



STEVE:  Nope, exactly.



LEO:  So I have to buy it.



STEVE:  They're never getting mine back.



LEO:  All right.



STEVE:  And then a last little bit is we are beginning to see ultracapacitors in consumer products.



LEO:  Oh, you're kidding.  This is the thing we were talking about, the EEStor thing.



STEVE:  Put in snipurl.com/ultracap1.  I decided I would start numbering these because - of course now other people could take them.  But this is the first example of an ultracap-based - this is Coleman has an ultracapacitor-based electric screwdriver which charges in 90 seconds.



LEO:  [Gasping]



STEVE:  So you stick it on the base.  The little meter goes [sound effect].  And 90...



LEO:  Oh, my god.



STEVE:  Isn't that cool?  No electrochemical, no batteries to change, no batteries to age and get old.  You use it, you know, [sound effect] being an electric screwdriver until it begins to slow down.  Then you stick its rear end into the charger, watch the little meter go back up, and in 90 seconds it's 100 percent full charge.  And if you're in a hurry, you can just stick it in for 15 seconds and get proportionally that much charge.



LEO:  Coleman's calling it FlashCell.  So this isn't the EEStor ultracapacitor.



STEVE:  No, this is not theirs.  There are some other ultracapacitors.  And in fact there's also a tactical flashlight, but it's still preorder, not yet available.  So I'm not talking about that yet.  But there is also a very nice-looking, but much more expensive - I think this is $80, isn't it?



LEO:  Yeah, it's 79.99.  Now, I wonder how long it will go for on that charge.  They don't...



STEVE:  Good question.  You don't know.



LEO:  If you could charge it in 90 seconds and it runs for 90 seconds, that's not so hot.



STEVE:  That's not so exciting.  There you just want to put a crank on the side of it and say, okay, I'm just going to go back to the old-fashioned way.



LEO:  But that is one of the problems with cordless screwdrivers frequently is that it runs down.  I have one that has two batteries, so you swap the other battery in.  Okay, I'm reading the copy here.  It's powered by the new supercapacitor technology.  With this new technology you can recharge/discharge 50,000 times.  It'll last a lifetime.  What they don't say, and I've got to find out, is...



STEVE:  How many screws you can screw in.



LEO:  How many screws you can screw.  5.4 volts.  220 rpm.  35 lb. inch torque.  They don't say anywhere how much you get per charge, and that's what I'd really like to know.  Very interesting, though.



STEVE:  Yup.  I will be keeping an eye on that and let our listeners know as supercapacitors continue to emerge.



LEO:  Yeah.  Very cool.



STEVE:  Meanwhile, I've got a great, short, fun little SpinRite success story to share.  David, looks like Hoeflein.  And I'll spell that for Elaine, for her transcript, in my communication to her.  He wrote that his computer would not reboot, not even in safe mode.  He said, "An attempted system repair revealed that Windows did not recognize the partition type."  Hate when that happens.  Everybody hates when that happens.  I don't think there's anybody who likes when that happens.



LEO:  And it says, would you like to format or eject?  I mean, that's it.



STEVE:  Oh, yes.  Let's see, A or B.  How about SpinRite instead?  So he says, "I went to my wife's computer and bought SpinRite, since everyone raves about it on TWiT.  After an hour of running, SpinRite detected a sector that it could not repair, but brought back most of it, and that was enough.  Windows rebooted, did its disk check, and fixed a lot of indexes, et cetera, and rebooted again.  All is as good as new now.  This disk had all of my documents for the past 20 years, passwords to everything, and, well, the loss would have been awful for me.  I set my new Acronis Scheduler to do weekly full image backups."  And then signed "David Hoeflein, new SpinRite customer."



LEO:  So that actually raises an interesting question.  When it can't recover the whole sector, does it recover part of the data?



STEVE:  Oh, yeah.  That's one of the - as far as I know, that makes SpinRite completely unique among any recovery utility ever written, is that SpinRite is able to, I mean, it tries like crazy to read the sector.  It drops into something called DynaStat mode, which annoys some people because it can take so long because SpinRite, essentially it takes 2,000 samples of the sector.  But in doing that, it's actually reading the unreadable data.  And it does an analysis of it, working to determine where and what the region it cannot read contains.  And very often during that time it gets just enough to perform a correction which allows it to recover all of the data and then work with the drive to get rid of this bad sector and swap a good one in in place of it.  Then it writes the data that it was able to recover back into the sector.



LEO:  So it's hit or miss whether that'll be enough to say tell Windows your partition is okay.  But...



STEVE:  Well, but no.  But here's the other thing is that, remember, a sector is 4,096 bits.  It's 512 bytes, 4,096 bits.  Only about 11 or 12 bad bits in a row will prevent error correction from figuring out what they are.  That's less than two bytes.  So that's enough bits to spoil the entire sector.  Normally that's it.  Except SpinRite is definitely able to give you the rest of them.  And so you're able to, for example, out of 4,096 bits, you can get 4,080 bits correctly.



LEO:  Oh, interesting.



STEVE:  And it's very often, for example, if that was a directory sector or even like a part of the boot system, it might be that those two bytes you can live without, literally, and SpinRite will get the rest of them for you, make the sector readable as is.  Whereas before it was completely unreadable, it will be readable with the caveat that, okay, we lost two bytes, but you got all 510 other bytes.  And oftentimes that's where the miracles that SpinRite performs comes from.



LEO:  Amazing.  That's really, yeah, so it's that error correction that's really - once you get the sector recovered, the error correction...



STEVE:  Well, and the fact that SpinRite will give you the data it could read, even tolerating the fact that it couldn't read at all.



LEO:  Right.  Amazing.



STEVE:  And very often that's enough gain to make a difference.



LEO:  Hey, mewhoelse in our chatroom referred me to a Popular Mechanics review of that Coleman screwdriver.  And Popular Mechanics says, yes, it really does charge in 90 seconds, and you get about 30 minutes of screwing.



STEVE:  Very nice.



LEO:  So that's efficient.  I mean, if you use it for 30 minutes, and now it dies, and you put it in there, and a minute and a half later you're ready to go again, that's plenty.



STEVE:  Well, and I'll tell you, do you have Makita?



LEO:  Mine is a Black & Decker, I think.



STEVE:  Okay.  I've got two Makitas.  And the problem with them is the normal self-discharge.  I don't use them very often.  So they're sitting in the garage most of the time.  When I do need it, I'd like to have it now.  And so but the batteries are always discharged, so I always have to anticipate my need, or wait around for them to get a charge.  The beauty of this is, first of all, ultracapacitors have an extremely low self-discharge rate.  So if you left, when you were done using it, you left it on its charger for 90 seconds before putting it away, chances are it's still going to have a fully useful charge when you grab it.  But even if you ended up leaving it discharged, when you want to use it, you only need to wait a minute and a half.



LEO:  I love that.



STEVE:  And you've got a 30-minute charge now.



LEO:  Yeah.  I'm actually very tempted to buy one of these, I have to say.  That's really cool.



STEVE:  Just to have the technology, yeah.



LEO:  Yeah.  Yeah.  And the fact that the batteries never wear out is a...



STEVE:  Never.



LEO:  ...pretty good thing, too.



STEVE:  Yup.



LEO:  All right.  We are going to take a break, come back.  We're going to talk about modes of encryption, kind of more ground-setting for...



STEVE:  Foundation-laying, yes.



LEO:  Foundation-laying for our SSL segment, which is going to come up in a couple of episodes.  So let's get the foundations down of encryption technology.  What do we need to know, Steve Gibson, to go forward here?



STEVE:  Okay.  We've discussed at length the concept of symmetric and asymmetric ciphers.  An asymmetric cipher, also sometimes called "public key encryption," is one where you use one key to encrypt and the other key to decrypt.



LEO:  Which is a wonderful technology.  I have a - if you go to my website, you could download my key.  And people will say, well, wait a minute, I'm downloading your PGP key?  No, that's the public key.  Anybody can have that.



STEVE:  Right.  It's the key of the key pair that you chose to make public.  And again, it's one of the things that's very cool about this is that somebody could use it to decrypt something that you encrypted with your private key, meaning the one that you have not disclosed.  Or they could use your public key to encrypt something that they would know only you could decrypt.  So it works both ways.  If somebody used your public key to decrypt something, they'd know that it came from you because only you could encrypt something that your public key could decrypt using your private key, and vice versa.  So it's handy.



The problem is, it's extremely computationally intensive.  The keys are long.  They need to be long.  They're, like, 10,000, I mean, 1,024 bits.  They're like 1K bit long or longer, sometimes 2K bits because the algorithm requires that much bit length in order to get the equivalent security of much shorter keys using symmetric or private key encryption as opposed to public key encryption.  So that length requires, and the nature of the public key algorithms requires, much more computation.  So it's never feasible to encrypt an actual communication with public key crypto.  Technically you could, but it would just be hugely slow.



So instead what's done is that a random number is picked, just out of the air, a big cryptographically strong, really high-quality random number.  And that is used as the key to a symmetric encryption algorithm.  And then that key, only that key is encrypted using the public key technology.  So then so what happens is, the encrypted document and the encrypted key are sent to someone, and they use the public key technology to decrypt the key, which they then use with a symmetric key algorithm to decrypt the document.



LEO:  Isn't that clever.



STEVE:  It's very clever.  And in fact what we're going to talk about today is symmetric key algorithms.  We've talked about symmetric key ciphers.  And of course the famous one that's become very popular is the so-called "Rijndael" cipher that was chosen as the Advanced Encryption Standard, the AES cipher, after much competition among many different competing ciphers.  And we did a whole episode some time ago on exactly how Rijndael works.



Just to refresh people about, in general, the way a symmetric cipher looks from the outside, sort of treating it as a black box, you have some number of bits.  You can think of them sort of like signal lines, like electrical wires going into this.  And they're either - each bit is a one or a zero.  And older block ciphers had sometimes, for example, 64 bits was popular.  The problem was that, as computers have gotten stronger, the concern has been that there aren't enough combinations of 64 bits to really make the result strong.  So modern block ciphers have doubled that to 128 bits.  And it's important to remember that when we double the number of bits, we're not doubling the number of combinations.  Every bit we add doubles the number of combinations.  So when we go from a 64-bit block to a 128-bit block, we're adding 64 bits, meaning that we're doubling and doubling and doubling and doubling the number of combinations 64 times.



LEO:  Wow.



STEVE:  So the total number of possible combinations is - it's computable, but it's really, really huge.



LEO:  2^64.



STEVE:  It's 2^64 times more than there were before.



LEO:  Wow.



STEVE:  So imagine we've got 128 bits going into this black box, and 128 bits comes out.  So the idea is, I mean, that's the Rijndael cipher, or any similar symmetric cipher.  And these 128 bits are transformed through the algorithm in the cipher into a different 128 bits.  And the nature of the - essentially it's a permutation.  It's not like one bit goes in and comes out somewhere else.  It's that, for example, if you were to change one bit going in, on average half of the bits coming out would change.  And you never know which half because, if you changed a different bit, a different set of bits on average would change.  And not always exactly half, but on average half.  Or another example of this is if, say that you had all zeroes, but then you turned on five different bits going in.  Well, you would end up with about half of the - a half of one's one bits coming out.



The point is that this is for any pattern of 128 bits you put in, you get out a completely different specific 128 bits.  Always the same.  When you put the 128 bits in, you get the same 128 bits out, given the key.  Because the other input to this black box, in addition to the block of data going in, that is, this block of bits going in and a block of bits coming out, the other factor is the key.  And keys can range basically, for example, DES was a very popular - the Data Encryption Standard, basically the prior main government standard, DES, that used a 56-bit key.  And in fact that was the source of concern over DES was that, gee, you know, before we had computers, or when they were a lot slower, that seemed to be just fine.  But 56 bits just doesn't have enough combinations.



So, for example, the Rijndael cipher allows you, and the AES standard allows you to use a key of 128 bits, 192 bits, or 256 bits.  Which is just an insanely long key.  I mean, already 128 bits is a huge amount of combinations, so much so, I think I remember reading that, if it took you a second to crack DES with a 56-bit key, it would take something like 142 trillion years with the same amount of processing power to crack it with 128 - crack a cipher with a 128-bit key.  So, I mean, so that's the difference in key length in terms of just, you know, the actual number of possibilities given binary bit length growth.  It's easy to underappreciate what it means to increase the length of these things.  I mean, these things get stronger exponentially as you increase their length, every bit doubling the number of prior combinations.



So we have this cipher, this symmetric cipher.  We've put a combination of 128 bits in under the influence of a key that's probably going to be 128 bits.  And out comes a different pattern.  What's cool about this is that it's a one-for-one mapping.  Every 128 bits we put in, we get out a different, I mean, unrelated 128 bits.  There's no way looking at this to figure out what magic is going on inside this box that gives us this result.  In other words, it is a pseudorandom output.  But it's always the same, and it's reversible.  So that gets us encryption.



So say that we now - the question is, and the real focus of what I wanted to explain today, was how do we take that and actually do something useful with it?  Which is something we haven't really covered explicitly.  That is, say I've got a document with multiple pages.  How do I take this symmetric cipher, assume that I've got a secret key that I know, that is, we talked about how the key can be known.  It could have been encrypted with a public key technology so that when I got the key, the document was encrypted and the key was encrypted.  I used the public key technology to decrypt the key, so now I've got the key.



Or going the other direction, say that we have a plaintext document, that is, a document not yet encrypted.  I use a pseudorandom number generator to generate a random 128-bit key.  Now, that's the key I'm going to use to encrypt the document.  And I will use a public key technology to encrypt that key when I send it with the document, knowing that only the person who's got the matching public key to my private key that I use to encrypt the random key used for the symmetric cipher, will be able to do the decryption.



So the question is, I've got my 128-bit pseudorandom key, and I've got this cool cipher algorithm, this Rijndael AES, or any other symmetric cipher.  Now what do I do?  Well, the most obvious thing to do is take bytes of the document at a time.  128 bits is 16 bytes.  Is that right?



LEO:  No.



STEVE:  No.



LEO:  Yes.



STEVE:  32 bytes.



LEO:  No, 16, yes.



STEVE:  So 32 bytes is 256 bits, so it's 16 bytes.  So I take the first 16 bytes of the document, and that makes 128 bits, put them into the cipher, and out comes gibberish.  I mean, just noise, nonsense, nothing.  But I write them down.  Then I go to the next 16 characters, or 16 bytes of the document, put them into the cipher, and out comes, again, nonsense, gibberish, completely different, given that the second set of 16 bytes are different than the first set of 16.  So it's just no relationship that I can see between what goes in and what comes out.  And then I take the third set of 16 bytes, put it in, and out comes another 128 bits of garbage, as far as I can tell.  And I proceed.



So now you would think, okay, fine, we've successfully encrypted the document.  And in fact we have.  But there is a problem with this that makes the crypto people feel uncomfortable.  And that is, any time we put in the same 16 bytes, we're going to get out the same 16 bytes, or 128 bits, of garbage.  Well, in other words, even though we don't know what the 16 bytes were that we put in, someone looking at the enciphered, the encrypted result could say wait a minute, here's the same phrase, here's the same expression.



Now, obviously those bytes would need to be aligned on the block boundaries in the same way.  But the point is, there is some information leakage happening.  There is something you're able to glean from looking at the pseudorandom noise.  Even though it's pseudorandom and it's noise, it's noise with the possibility of a pattern.  And that pattern is, I mean, the pattern reflects, one for one, a pattern in the plaintext.  And that's not good.  You would say, well, they don't know what the plaintext is.  But you've leaked some information.



And, for example, in the case of a - say that we were, instead of encrypting a static document we were encrypting packets.  And every packet that was being encrypted was using the same key, which was negotiated once at the beginning of the connection.  Well, now all these packets are going by, and there's things that are known about the unencrypted format of the packet, like the header of the packet that contains IP and port number and so forth.  And so, if you had enough samples of these packets, and you know that the key was the same, and you know that, because the assumption is always that an attacker knows everything that is known publicly about the protocol, they know you're using Rijndael; they know you've got 128-bit blocks; they know you've got a 128-bit key.



The point is that, in cryptography, you define well what is secret, and you define well what is public.  And the whole goal is that the only thing we have to keep secret is the key.  If we keep the key secret, we can publish everything else that we are doing, and the result is still private.  We still have security.  So that we clearly delineate what it is that we're requiring for security.



So the problem we've got now with this first approach is that patterns will easily show through our encryption because we've got a nice cipher which takes blocks at a time.  But because the same input always produces the same output, just by looking at the output we can see that what we're seeing we've seen before, and that's information leakage.  Well, so this simple approach is known as electronic code book, or ECB, algorithm.  Because, think of it, a code book traditionally takes some input and gives you some output.  It says here's my code book.  I look up this word, and I get this word.  I look up this word, I get this word.  So that's essentially what this is doing.  ECB just - it takes whatever you give it, and it gives you something else.  But when used as a protocol, the problem is that it always gives you the same thing out for the same thing in.  We need something a little fancier.



So the first thing people came up with was something called "counter mode."  Or whereas this first one was Electronic Code Book, ECB, the counter mode just has the acronym CTR.  So with counter mode, we operate a little differently.  We imagine that we have going into the encryption block, instead of actually putting the data to be encrypted into the top of this cipher, instead we put a counter.  We have a binary counter which starts at some particular value.  We could start it at zero, but not starting it at zero gives us some additional strength.  So imagine for now we just - we'll start our counter at zero for the sake of explanation.



So this 128-bit counter feeds into our encryption algorithm.  Well, we already know that what's going to come out is pseudorandom data, even though we're putting all zeroes in, then 000001, 000010, 000011, you know, we're basically doing a simple binary progression feeding into the cipher.  What comes out is noise.  Thanks to the brilliance of a good symmetric cipher, you can even just put simple progressive counts in.  And what you get out is just static.  There's no discernible pattern.  And remember that, again, this is under the influence of the symmetric key, which is also going into this black box.  So now we've got noise coming out.



Well, we've talked a lot about the XOR operation, the exclusive OR, where the idea is that essentially one bits in one of the terms of the XOR serve to invert the bits of the other term of the XOR.  In other words, if you were to XOR something with all zeroes, you'd just get it back out again. There's no change.  If you were to XOR something with all ones, then all of the input bits would be inverted when they come out.  So if you XOR something with random noise, this is one of our other, like, cool fundamental principles.  You XOR data, good, normal, plaintext data, with random noise.  What you get out is random noise.  The XOR, I mean, even though it doesn't seem like you've done enough to, like, really encrypt something, if it's random noise, what it's done is it's randomly inverted the bits of your data.  And when you do that, your data is gone.  They're just like they were as random as if you had random data coming in in the first place.  So this...



LEO:  But it's reversible.  That's the key.



STEVE:  Exactly.  Because, exactly, because since the bits are being inverted under the influence of one of the terms of the XOR, when you do it again, those bits that were inverted get reinverted, which puts them back the way they were.  So exactly.  It's reversible.  Okay.  So now we have our counter set to zero.  We feed that zero value through the cipher under the influence of the key, and out comes 128 bits of noise.  We then take the first 16 bytes of our document and XOR them with the first 16 bytes of noise, and we get more noise.  But we get special noise because it encodes, it encrypts the original plaintext.  Now we increment the counter to one, and we feed that through the cipher and get a new 16 bytes of new noise, which we XOR with the second 16 bytes of our document.  And now we get a second block of 16 bytes of noise.  And we proceed with each 16 bytes at a time, with the counter incrementing by one every time.



Well, now it looks like - now look at what we've got.  We're using our cipher to turn a sequential count into a keyed sequential system of noise.  That is, even though the counter might start at zero and go one, two, three, four, five, under one particular input key we'll get one series of pseudorandom noise.  Under a different input key we get a completely different series.  But unlike electronic code book mode, notice that even if we gave the same 16 bytes into this system some time later, the counter is guaranteed to be at a different count because it's counting sequentially.  So it won't - and it's 128 bits long.  It's not going to repeat in the lifetime of the universe.  So that means that even the same data being encrypted with the same block alignment will give us a completely different output.  We've solved the problem of there being any patterns.  That is, we've solved the problem of any pattern that exists in the plaintext surviving and showing up in our cipher text.  So we've got an improvement.



Well, this was better.  But there was one next stage that the cryptographers decided would make them feel more comfortable because there is still a property that we have which we could improve on.  And that is, each block stands alone.  There is no interblock influence.  That is, for example, nothing that we're encrypting is dependent upon anything that came before.  And it would be nicer, even though this seems strong, it would be nicer if a change in the input text that we're encrypting changed more than just its 16 bytes.  Remember, since we're doing this right now a block at a time, block of 16 bytes at a time, each block is isolated.  Well, it would be nice if changing - if there was, like, more influence with our plaintext.



And it turns out it's simple to do that.  All we have to do in order to create that is, again, change our algorithm a little bit.  We'll step back from this counter mode and imagine that we sort of go back now to this electronic code book mode, remember, where we're actually encrypting our data through the block cipher to get our encrypted result.  Now imagine that we take the encrypted output from the first block and XOR that with the second block's plaintext, the source data, before we encrypt it.  What that does is, that essentially it takes that pseudorandom output from the first block of encryption, and by XORing it with the second block's input, it completely randomizes it, then encrypts it, giving us our second block of encrypted data.  And we similarly, we take that and use it to XOR the input of the third block, and so forth.  And this has turned out to be - that algorithm is called Cipher Block Chaining, or CBC.  And it is the - one of the most popular encryption protocols because it is very fast.  An XOR operation is something computers just do, I mean, they've got instructions built in, unless you're a PDP-8, and in that case you don't even have an XOR.  But every computer built in the last...



LEO:  How do you do an XOR if you don't have an XOR?  Can you do it with bit shifting or...



STEVE:  You can actually simulate it with - I'm trying to think if the PDP-8 has an OR.  I know it has an AND.  But you are able, there is a series of instructions...



LEO:  You just write the macro that does it and use...



STEVE:  Yeah, exactly.  Or, well, yeah, exactly.  I was going to say I tend to use XOR a lot because it's there and it's cool and it's free for, like, different things.  But I imagine if you didn't have one you would tend not to use it that much.  You'd come up with other ways of doing things.



LEO:  Right.  It's just great that it's reversible like that.  That's what's cool about it.



STEVE:  Yes.  And it is extremely efficient.  So what the industry has settled on for many of its operations is this thing called - this protocol called Cipher Block Chaining where, again, you encrypt the first block of data, and you take the result of that and XOR it with the second block before you encrypt it, and then take the result of that and XOR it with the third block before you encrypt it.  And if you think about it, you write it down, like, get a napkin out, that process is reversible, that is, you can - if you decrypt the first block, then you get - I'm sorry.  Well, it is reversible.  You take the...



LEO:  I'll take your word for it.



STEVE:  You take the first block of cipher text and decrypt it.  But then you take it and XOR it with the - and then you take the second one and decrypt it and then XOR it with the second.  It's harder to describe the reverse process.  But it's reversible.



LEO:  Right.



STEVE:  But one thing we haven't said is, okay, wait a minute, we're XORing each block of plaintext before we encrypt it, except the first one.  What about the first one?  And so we would rather not have that one even always be the same.  Remember that the electronic code book approach, well, this is similar to that, where we're just encrypting a block at a time.  We would rather not even have the first one not XORed.  So we introduce something called an "initialization vector" that we talked about way back in the dawn of this podcast, the so-called IV, because it was used, for example, in various other encryption protocols.  And so the initialization vector is a first - it's something in addition to the key which is initially used to XOR the data.  And in this case, in this particular mode, you'd like to keep that secret.  Because if an attacker knew what the initialization vector was, well, you might as well not have it.



So you use the 128-bit key to key this - to key all of these ciphers in this algorithm.  And then you have another chunk, which is the same length as the block length, which in this case is also 128 bits.  So it forms another portion of your secret.  And that is the so-called initialization vector, which is used to XOR the first block.  Once you've done that, then you take the output from each successive encryption and XOR the next block's input with that.  And in that way, the point of this is, by chaining these operations, any change in any of the output data is propagated through the entire rest of the document, making it essentially completely - you just have more randomness built up and propagating, and that makes the cryptographers happier.



LEO:  Of course it does.



STEVE:  And then one interesting thing, and this leads us into our next topic in two weeks, and that is, imagine if you didn't care about the output of each of these blocks.  You have the CBC, the Cipher Block Chaining.  And you don't care about the output of each of these.  You merely take it, and you chain it to XOR the input.  Well, what you end up with at the end is very much like a digest, a hash, because you end up with a final block which, thanks to the cipher block chaining, is dependent upon all the data that preceded it.  And any change in the data changes the final result.  And that is the definition of a good cryptographically strong digest, or a hash.



LEO:  Well, there you go.



STEVE:  And there you go.  And notice that it's one which is keyed.  That is, it's not like MD5 or SHA-1, which are non-keyed hashes, where every time you put the same thing in, you get the same thing out.  In this case it's a digest which is generated under the influence of a key.  So when you change the key, you completely change the result.  And we'll talk about why that's important and what that means in two weeks.



LEO:  I can see why it would be important.  But we'll do - I think I can see why it'd be important.



STEVE:  It's very cool.  And that's where message authentication codes, MACs, come from.



LEO:  Aha.  You know, it's funny, you say we talked about all this before, but it all sounds brand new to me.  So it must have gone in one ear and out the other the last time.  



STEVE:  Well, it's complicated stuff.  And we're in our fourth year, too, so.  And that's why I think that some bit of continually bringing some of these...



LEO:  I agree.  I agree.



STEVE:  ...older ideas back and refreshing them is also useful, especially when we're going to be going out and pursuing some new territory in cryptography.



LEO:  Yeah, no kidding.  I mean, it's tough stuff.



STEVE:  But I think it's neat stuff.



LEO:  It is.  It's very elegant.  And it makes total sense.  And without it, I mean, you know, we wouldn't be able to do what we do on the Internet.  I mean, that's what makes all the transactions secure on the Internet.



STEVE:  Yes.  Everything we do.  I mean, encrypted databases, encrypted communications, I mean, I don't know where we would be if we hadn't come up with this technology because we absolutely and utterly depend upon it in order to - in order for what is otherwise uncontrolled communication, to keep it safe.



LEO:  This would be a good one, if you wanted to review the transcript - and I think I do - to go to GRC.com.  That's Steve's website, Gibson Research Corporation, GRC.com.  And if you go to GRC.com/securitynow all the shows are there; transcripts; 16KB versions, as we mentioned, for the bandwidth-impaired.  The podcast is there, too.  You can listen to it over again.  And that's a really great resource.  Plus show notes.  We've now got show notes on the TWiT wiki, too, although I wonder what sense they'll make out of this.  It'll be very interesting to see.  But we certainly have links to all the news stories and everything.



And of course, while you're at GRC.com, do not forget, that's where you can get SpinRite.  You see why Steve is so good at this kind of stuff.  He gets this low-level stuff, and he loves it, and he digs into it, and that's what makes SpinRite such a great program for disk maintenance and disc recovery.  GRC.com.



STEVE:  And I will remind our listeners that next week is a Q&A.



LEO:  Oh, yeah.



STEVE:  And you want to go to GRC.com/feedback.  And by all means, send me your feedback.



LEO:  By all means.  Yeah, we'd love to hear your questions.  Not just feedback, but questions, too.



STEVE:  Yeah.



LEO:  All right, Steve.  Hey, thanks so much.



STEVE:  Always a pleasure.  We will be moving forward for a couple more weeks with some similarly propeller-winding crypto stuff that I think people are going to find interesting and, I hope, comprehensible.



LEO:  Very good.  Steve Gibson, thank you for joining us.  All the rest of you, too.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo. 



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#184

DATE:		February 19, 2009

TITLE:		Listener Feedback Q&A #60

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-184.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 184 for February 19, 2009:  Your Questions, Steve's Answers #60.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



Time for Security Now!.  We're going to talk about all those things that happen on the 'Net that can scare the pants off of you - your privacy, your security.  Steve Gibson is here.  He knows more about it than practically anybody because he's on the front lines.  GRC.com is his site.  Creator of ShieldsUP!; the discoverer of spyware.  He's like Christopher Columbus.  He discovered spyware.  Hey, Steve Gibson.  How are you today?



STEVE GIBSON:  Hey, Leo, it's great to be with you again, as always.



LEO:  Great.  Today it's a Q&A segment.



STEVE:  Yes, Episode 184, and this is our 60th, six zero.  That's a decimal six zero.  I've been deep into octal notation recently because I've been learning about the PDP-8, like relearning.  It's funny because the book I was reading says "Introduction to Programming."  And it was sitting on the coffee table at Starbucks.  And the baristas there pretty much know me and sort of have a sense for where my area of expertise is.  I've been there for years.  And one of them looked at it and says, "'Introduction to Programming.'  You're reading an introductory book?"  And, you know, DEC printed it on non-acid-free paper, so it's very yellowed and aged looking.



LEO:  Oh, how funny.



STEVE:  And I said, "Well," I said, "let me put it this way.  I first read this book when I was 16 years old."



LEO:  It's an oldie but goodie.



STEVE:  So I am rereading it and enjoying it.  And in fact that is a perfect opportunity for me to mention that I'm going to be joining Ray Maxwell over on his podcast that you and he do.  I guess you record it live on Thursdays.



LEO:  Yeah, we do.  It's called Maxwell's House.



STEVE:  Maxwell's House.



LEO:  Yeah, it's really fun.  It's 2:00 p.m. Pacific, 5:00 p.m. Eastern on Thursdays.  And it's, you know, Ray is like you.  He's an autodidact, and he's got wide-ranging interests.  So it covers...



STEVE:  And I had no idea he was, like, a computer developer.



LEO:  Oh, yeah.



STEVE:  I was listening to him talking about the old days.  And it's like, my goodness, I mean, he and I, there's a tremendous overlap between what he's done and what I've done.  I just thought he was Mr. Photography.



LEO:  Oh, gosh, no.  You know, that's the hobby.  So it's fun.  And so, yeah, so you two are going to do an old-timers' show.



STEVE:  On February - is it the 28th?  It's not this coming...



LEO:  It's the 26th.



STEVE:  It's not the Thursday that this show airs.



LEO:  That's the 26th, a week from today.



STEVE:  The 26th.  So I wanted to advise our listeners, if they want to listen live, they can certainly do so.  It'll be Thursday afternoon at 2:00 Pacific, 5:00 Eastern on  Thursday the 26th?



LEO:  Yeah.



STEVE:  And then of course they could also explicitly grab that podcast.  What we're going to be doing is talking about old times, old-time computer technology stuff.



LEO:  But we don't do a podcast of it, Steve.  It's just live.  But I think that one...



STEVE:  Oh, no kidding.



LEO:  Yeah.



STEVE:  So you're not recording it.



LEO:  Well, we record them, and we play them back as reruns.  But we have, you know, this is a video show, and we haven't yet really figured out how to do those.  But this might be the exception.  And if we do it, what we'll probably do is put it out on YouTube or somewhere.  But I'll make sure people know where they can see it again.



STEVE:  Well, and I...



[Talking simultaneously]



LEO:  And of course you have ODTV.  And ODTV at ODTV.me records many of these shows and makes them available.



STEVE:  Okay.  Well, I would definitely like to get the audio, and I'll host it on my server because I'm going to...



LEO:  Oh, good.



STEVE:  ...spend the time to - anyway, so he and I are going to hang out and talk about, sort of do a nostalgia computer episode that he's eminently qualified for.  And I've been living in the past a lot recently myself.  So I think it'll be - we're really going to have some fun.



LEO:  You know what we could do is release it as a auxiliary - like an extra show on this feed.



STEVE:  Yeah, that's a good idea.  I mean, why not?



LEO:  Yeah.  And so if you're already a subscriber to the Security Now! feed, whether it's on iTunes or your podcatcher of any kind, we'll just have, you know, it'll be Episode 185-A or something like that.



STEVE:  Yeah.  You'll just get it.  And if you don't want it, you can delete it.



LEO:  Throw it out, yeah.



STEVE:  Yeah.



LEO:  Good.  That's what we'll do.  That'll solve that.  So an extra Security Now! next week.



STEVE:  Yeah.  So anyway, I'm excited about it.  And as I said, I've been studying these older machines.  And I've - I realize and appreciate some things I never appreciated when I was 16, you know, from the vantage point now of looking back, how many years is that, 33 or something?



LEO:  Long time.



STEVE:  Yeah.  So it's going to - I've got some interesting observations I think people will - certain Ray and I will have fun talking about it.  And I think our listeners will find it interesting, too.



LEO:  Why do they work in octal?  I mean, isn't - well, we know that binary is the natural state of a computer.



STEVE:  And that's the heart of what - and that's, of course, I was looking at six zero, Q&A 60, and that's the hardest problem I'm having is, I mean, I live in hex.  Unlike, you know, almost all programmers now...



LEO:  Hex is base 16.



STEVE:  ...who live in decimal.  Yes.  I mean, my world is hexadecimal because I'm programming in Assembler.  But back then the machines used three-bit groupings, so you had zero through seven, instead of four-bit groupings.  And DEC produced minicomputers with bizarre word lengths.  There were some that were 18 bits long.  Some were 36 bits long.  Some were 12 bits long, and 16.  And so they had multiples of nine and multiples - and so it made sense to have, like if you had an 18-bit word, you'd do multiples of three bits in order to represent that.



Anyway, so it's difficult for me because I'm so used to a computer representation being hex that, I mean, it's been interesting because I haven't appreciated the degree to which I translate hex now automatically into binary and into decimal.  It's just - it's automatic.  But if it's octal, that automatic reflex is wrong.  And so I'm having to catch myself constantly, say whoa, wait a minute, this is not, you know, 200 when I'm seeing it in octal is a very different number than it is in hex, so.



LEO:  That's really, really geeky, but very cool.



STEVE:  Yeah.  Oh, but I've got more for you in two weeks.



LEO:  I can't wait.



STEVE:  I've got some serious geekdom.



LEO:  So, Steve, dare I ask, are there any news and errata from...



STEVE:  Well, yes.  We have lots of errata and a little bit of news.  It's been a relatively quiet security week since last week when we had the big Apple second Tuesday of the month update.



LEO:  Hallelujah.



STEVE:  In this case, the only real big security news is Apple.  There is a new Mac OS X update and Java update.



LEO:  Yeah, I got those, yeah.



STEVE:  The Mac was about 44MB.  They fixed a whole bunch of problems, more than two dozen security flaws.  There was an arbitrary code execution flaw in Safari's RSS handling.  There was an information disclosure flaw in Apple's Remote Events, a denial of service flaw in the AFP server, arbitrary code execution in Core Text, and a bunch of other things.  So definitely something that Mac users will want to make sure they get.  And they didn't really talk about what they fixed in Java.  They just said "addresses security and compatibility issues."  So...



LEO:  They never say much.  They're very tight-lipped about that kind of thing.  What do you think of that?  I think their thinking is we don't want to say too much because we don't want to tell people what we're doing.  On the other hand, I would really like to know what they're fixing.



STEVE:  Yes.



LEO:  And what they haven't fixed, more to the point.



STEVE:  It's my feeling is that we're used to Microsoft giving a relatively full disclosure of what's going on.  And of course this has come back to bite Microsoft.  So I think Apple is saying, uh, we're going to fix it, and why do they really need to know?  I mean, you might argue that the typical Mac user, being less screws and knobs and widgets, just wants to know that they're secure...



LEO:  I don't think that's true anymore.  I think a lot of programmers and techies use Macs.



STEVE:  Yeah, well, as I look around Starbucks, I am seeing a clear shift towards Macintoshes; although I'm right next to UCI so we're in student land there, too.



LEO:  Well, I mean, because the Macs come with all the programming languages and so forth, I think, and it's a UNIX [indiscernible] terminal, I think a lot of geeks just kind of shifted over to the Mac platform.



STEVE:  Yeah.



LEO:  And they want to know.  I mean, especially because, it's actually related, a lot of the Mac software is UNIX software.  So some of these patches and some of these exploits are in the UNIX software.  And if you know of a problem, for instance, in the version of Bind that OS X is using, you want to know if they've patched that or not.  I guess you could figure it out, but it's nice to have a list.



STEVE:  Right.  The only real interesting security news I have, aside from Apple, was just a note...



LEO:  A yabba-dabba-do.



STEVE:  There's a yabba-dabba-do.  I'm going to talk about that a little bit when I talk about SpinRite later.  But there was a - the trial has started in Stockholm of the four founders of Pirate Bay.



LEO:  Yeah.  It's closely watched by a lot of us.



STEVE:  Yeah.  I'm interested to see what happens.  They're facing charges of accessory and conspiracy to break copyright law.  Their defense is that the software is not stored on their servers.  So they're not breaking the copyright law.  Thus they're not being sued for copyright violation, but rather accessory to and conspiracy to break copyright law.  The lawsuit is seeking about $14 million U.S. in damages and interest.  It's estimated that Pirate Bay has about 25 million users, if you can believe that.  I mean, that's just amazing to me.  And if, I guess, based on the nature of the charges, if they were convicted, these four guys could face sentences of up to two years in prison and fined as much as $180,000.



So the only thing that I have found annoying about them, I mean, I recognize the reality of software piracy and the way the Internet works, is just - and I'm sure you've seen this, too, Leo - is the brazenness of these guys.  I mean, all kinds of companies large and small have sent them letters asking that their software be removed.  And they post them and laugh at them, saying nani nani nani nani, you can't get us.  So it'll be interesting to see how that turns out.



LEO:  The first day of the trial was a couple of days ago, and they already have thrown out one of the charges because they couldn't prove they had a - I think the prosecution is fairly inept.  They were unable to prove that the actual - that the torrents they were - the torrent files they were showing actually were on Pirate Bay, and there was no evidence that they were.  So the judge said, uh, hmm, guess that one's out.  So now the only charge remaining is making available of copyrighted works.  You know, to be honest I think it's going to be a very tough one to prove because they don't make available copyrighted works.  All they publish is this little tiny torrent metafile.



STEVE:  Right.



LEO:  I don't know how you prosecute that.



STEVE:  Yeah.  And, I mean, I don't wish them any ill.  I just - I don't - certainly obviously I don't condone software piracy.  I'm a person, you know, when you hear that yabba-dabba-do it's because an honest person purchased a copy of SpinRite.



LEO:  Yeah, and I guarantee you that SpinRite is one of the things, one of the torrents on Pirate Bay.  I haven't looked, but I wouldn't be surprised.  Everything else is.  So you're, you know, these guys are stealing from you, too.



STEVE:  Now, I have my own horrific PayPal story.



LEO:  Oh, no.



STEVE:  Not just a caller-in.  This is something I stumbled on that is a complete dongle bypass, believe it or not.



LEO:  Okay.  Because that dongle we use seems to secure PayPal better because, you know, enter that number in, only I have that dongle, and...



STEVE:  Yup, multifactor authentication.  And in this case the second factor is a one-time password that gives you proof against keystroke loggers or somebody looking at what you're typing in and then going and trying to use it because it will have been used, and it expires.  I've been buying a lot of things off eBay.  You know, I'm in the antique or vintage computer mode at the moment, thanks to you having started me off by holding up that plane of core memory, and I thought, I gotta get some of that.



LEO:  Get me that.  I gotta get me that.



STEVE:  Before it goes away.  So now, that, I stumbled back into, you know, DEC, the world of DEC and my first minicomputer, the PDP-8, and then the 11.



LEO:  Boy, two in a row.



STEVE:  Well, okay.  I'm going to hold off talking about that till I get there.



LEO:  Okay.



STEVE:  So I've been buying a lot of things from eBay.  And eBay of course is closely affiliated - that's putting it mildly - with PayPal.  And so all the eBay sellers want you to use PayPal in order to complete the purchases.  So I went to pay for something, and went to the sort of the summary screen where this is what it's going to be, and here's the shipping costs and so forth.  And you're still sort of in eBay land, and you click to confirm that to go over to PayPal.  So I did that, went to the PayPal screen, which asked me for my username and my regular password, the first factors of authentication, which I entered.  Then I clicked Login, and it took me to the - it recognized in its database that I had the security token associated with my account.



And so I looked at that screen, I thought, wait a minute.  I had meant to add a comment to the purchase I was making.  There's a, you know, two screens back when you're agreeing that this is the price and shipping and so forth, there's an option to send a comment to the purchase - to the seller.  And I don't remember what it was.  But so I hit back screen and went to the login page, and back again and got back to the eBay page.  Opened up the little dialogue area where I could put a comment in and typed something to the guy.  Then I clicked on Confirm.  This time, when I went to the eBay login page, the fields were grayed out, you know, because I had done that already.  So I clicked Login, bang, and I was at eBay, logged in, never having to use my football.



LEO:  Whoa.



STEVE:  So, and I did it...



LEO:  And not asking security questions, either.



STEVE:  No.  It happened once before.  And then yesterday I remembered that it had happened and so I deliberately duplicated it.  So I've done it now twice.  I don't know for sure how far back it's necessary to go.  I went back two screens.  It may only be necessary to go back to one, where the login fields were grayed out.  And then clicking Login might jump you over.  My guess is that would.  Next time I buy something I'm going to try that.  So I'll...



LEO:  Do you think it's something that has been cached?



STEVE:  Well, it just means there's a bad implementation.  I mean, we keep seeing example after example of people at PayPal just not having their act together from a programming standpoint.  And, you know, and also from a security philosophy standpoint.  But here, I mean, this is something where you just - it bypasses the whole requirement of entering any sort of a second authentication credential.  Not good.



LEO:  It's a handy tip, though, because if I forget my key at least I can get in.  [Laughter]



STEVE:  There's a handy tip for you.



LEO:  How to bypass all the security at PayPal.  Just in case you forget your password.



STEVE:  Oh, yeah.



LEO:  Wow.



STEVE:  Many listeners have thanked me for my mentioning and recommendation of KatMouse, the little Windows scrolling utility.  I mean, people are just as nuts over it as I am.  So I just wanted to acknowledge all the people who wrote and said thank you, thank you, thank you, I would have never found out about this if it weren't for you mentioning it.  It's changed my life.  I mean, there are people who have, like, they've changed their habits, where they're deliberately now scrolling Windows that are behind other windows, like they can see part of it, but they don't have to, like, make the windows come forward.  So they just put the mouse over it, scroll that one, then go back to the window where they were actually working.  So, I mean, it's been a huge, life-changing event for a lot of our listeners.  I just wanted to thank them all for the feedback that they appreciated that.



Last week was the first episode of "Dollhouse" that I mentioned, Joss Whedon's new series.  I just wanted to say that I was kind of underimpressed, underwhelmed.



LEO:  Yeah, you were not alone.  I didn't see it, but a number of people said, eh.



STEVE:  Yeah.  It just doesn't grab me.  But I saying that, I wanted to say that my absolute number one favorite show on television is now, and has been for some time, but I haven't mentioned it again, "Fringe."



LEO:  Is it back?



STEVE:  Oh, it never left.  We're in the first season.  And it is just - I look forward to it every week, more than any other show on television.  "Terminator" sort of seems to have lost its way.  They're running around in circles every week, and I don't really know where it's going.  But "Fringe," for what it's worth, I mean, I know there'll be listeners who are like, yeah yeah yeah yeah yeah, I agree completely.  Maybe there'll be people who disagree.  But I just love it.  I think it is really well written.  And it's another J.J. Abrams production.  I think J.J. Abrams.  I'm pretty sure.  And it's just spectacular.  I love the writing.  I love the casting.  And last week this episode with the light box, the episode was titled "Ability," a whole 'nother layer of story arc was unveiled.  It's like, oh, goodness, I hope this show is doing well enough to be continued because I'm really enjoying that hour of television.  Or 40 minutes after TiVo gets through with it, so.



LEO:  40 minutes.  It's true, it's true.



STEVE:  And then, on the topic of collectibles, I have an offer for some lucky listener or listeners.  A listener of ours, who's also jumping in with the SpareTimeGizmos, building the PDP-8 kit, Lance Reichert, said - he wrote and said, "I have an Osborne 1 - late-model, light-blue case - and a Kaypro 4, both in storage, with bundled software and manuals, plus several programming languages, as well as symbolic math package.  The Ozzy even has the original box and packaging.  Could you please connect me with someone who might be interested in these free-for-the-cost-of-shipping machines?"  He says, "I already checked DigiBarn, and neither is on their list of machines they're looking for."  And so I wrote back, and I said, well, "Why don't you create a throwaway email account that you can use, and I will give everybody who's listening to Security Now! that throwaway email account so that they can contact you if they're interested."  And so his email account, it's Gmail, it's kaypro.iv - as in Kaypro IV - at gmail.com.  And anybody who is willing to pay the shipping cost for either this late-model Osborne 1, which was a little CPM machine...



LEO:  Oh, I'd love to have that, wow.



STEVE:  Huh?



LEO:  I'd love to have that.



STEVE:  Well, you can have it, Leo.  I'm sure Lance would just send it...



LEO:  Wonder what the shipping cost would be, though?  That was a - that, quote, "portable" was 30 pounds.



STEVE:  Well, yes.  Remember that the term "luggable" was coined for that machine.  Or maybe it was the Compaq.



LEO:  I wanted that Osborne so badly.  Does he have a Kaypro, too?  Is that what...



STEVE:  Yeah.  An Osborne 1 and a Kaypro IV is the - both of them in storage.  You know, if you'd - can you display them somehow?



LEO:  Well, that's the thing.  I think that - yeah.  My problem is, unlike you, while I would love to have a computer museum in here, I don't really want - I could be bulging at the seams here with all the stuff that I would love to have.  And that's a bulk- both of those are bulky units.  That Osborne had a little tiny screen.  That was a tough - but the Kaypro was bigger.  It was nice.



STEVE:  Right.  And the Osborne was what, it was like eight-inch diagonal?



LEO:  Yeah, it was teensy.



STEVE:  Little micro, and it was, you know...



LEO:  But it was 80x24, I think, wasn't it?  Or no?



STEVE:  I'm sure that - I'm sure it was 80x24 characters, probably text.  I don't know, I don't remember if it did graphics.



LEO:  No.  No no no no no.  No graphics.



STEVE:  It was just a CPM machine, so probably just text.



LEO:  Yeah, yeah.  And they came with, as did the Kaypro, WordStar.



STEVE:  Yup.  Hey, now, careful, Leo, I'm still using WordStar keystrokes for all of my editing.



LEO:  Control - wait a minute, don't tell me, Control KS to save?  Is that right?  Control KV?



STEVE:  Yes.  Yes yes yes.



LEO:  Some things never leave the mind.



STEVE:  And, I mean, what I love about it was that your pinky sat on the Control key, which is now where everybody has moved the Shift Lock, which is just...



LEO:  Which is really frustrating, yeah.



STEVE:  ...the dumbest thing.  When was the last time you ever hit Shift Lock on purpose?  I mean, it's just...



LEO:  I always map it to the Control key.



STEVE:  Yes, actually there is a simple little registry hack you can use that'll map it in Windows machines so it is the - exactly.  And so both my Shift Lock and my Control key are Control keys.  But, yeah, I just, I mean, it's the definition of a perfect UI because it disappears.  I just will the cursor to go or the screen to scroll, and my left hand does it for me using the Control key and the little alphabetic keys over in that area.



LEO:  But you don't have a program that does it automatically.  You have to map the keystrokes to whatever program you're using.



STEVE:  No, well, in my case I'm still using Brief, which is an old 16-bit DOS box editor.  And I've completely rewritten it - Brief has a list-like macro language which I customized about 20 years ago.  And it's still running strong.



LEO:  And if you tried to change it one line today, you'd probably break the whole thing.



STEVE:  Oh, yeah.



LEO:  I'm sure there's no way you could look at that and say I know what it's doing now.



STEVE:  I'm not touching it.



[Talking simultaneously]



STEVE:  A person posted in the GRC SpinRite newsgroup really kind of a fun and, again, different sort of testimonial.  The subject was "Thank You, SpinRite," and he posted on January 6th.  And he said, "Okay.  I'm sure you're all sick of thank yous."  And I guess he's speaking now to everybody in the newsgroup.  "But this disk just saved me a lot of time, even though it didn't touch the drive."  He said, "I bought SpinRite a while ago to support Steve and Security Now!" - oh, so he's a Security Now! listener also - "but never had the need to use it until last week.  With the Christmas shutdown, I was looking to get out and away on the last workday, but I got stuck with a service call to one of the offices with a computer hard drive failure.  The staff there are actually pretty good.  So when they say it's a hard drive failure, I tend to believe them.



"Anyway, I go there, boot the computer, and it comes up with nonsystem disk message.  So I can see some time being wasted recovering data that should have been stored on network drives that are backed up, and not on the actual PC.  Oh, well.  I popped in SpinRite, and it comes in with a cabling error message.  A quick Google didn't really come up with much, but I had a few days to turn this unit around, so I posted the question on GRC's newsgroups.  Within a day I got a reply to check the cable.  So I popped the box, then reseated the SATA cable."  And he says, parens, "(They should design these so you have the option of connectors locking in), and I rebooted.  The computer came right up, Windows loaded, and it all works.  Nothing was lost."



LEO:  Wow.



STEVE:  "Needless to say, they walk in on the first day of work and are impressed that I sorted it all out over the Christmas break, and even more so when I mention the mystery disk that diagnosed the problem."  I guess he means SpinRite.  "So just one more for the records.  Thank you, Steve.  And even though SpinRite never really touched the drive, it was still worth every cent.  Signed, Tim in Perth, Australia."



And what SpinRite does is - this is sort of a consequence of the product's maturity over time.  I remember clearly adding this in SpinRite 3.1 because we were seeing instances where people were running SpinRite when they didn't really need SpinRite.  A classic was that their BIOS had lost its drive settings.  And so they would run SpinRite, even though there was nothing wrong with their drive.  The reason their OS wouldn't boot was the BIOS had lost its drive settings.  And so I added code to check the BIOS drive settings and tell them, Hi there.  You probably don't need SpinRite.  Thank you very much, though.  But here's what the problem is.  And I would, you know, take them through fixing that.



Well, one of the other things that was happening was that cables were becoming unseated.  And there is a protocol from the IDE drives forward which does a CRC of the data transfer across the cable.  And so I added some code in SpinRite - of course, and if the cable's loose, there's really nothing wrong with their drive.  It's an electrical problem.  So I added some code in SpinRite to test the cable separately from testing the drive.  And that's been in there ever since.  So, and of course it's a problem running SpinRite if your cable's flaky because we're testing, we're trying to correct electrical errors rather than magnetic data errors.



So, you know, that's been a real boon to SpinRite users.  And of course this just fixed Tim's problem, which wasn't with the hard drive, but rather was with the interconnection of the hard drive to the motherboard.



LEO:  Very cool.  So if you test it, will you warn?



STEVE:  Yes.  SpinRite pops up and says, wait.  Before we go any further, you've got a problem with your cabling.



LEO:  That's so cool.



STEVE:  Fix that, and then try again.



LEO:  I wish more software would do stuff like that.  So you could tell because it's kind of distinctive?



STEVE:  Well, yeah.  I'm able to transfer data back and forth across the cable to the hard drive's buffer without actually reading or writing the hard drive.  And I can pick up CRC errors in the transfer.



LEO:  I see.  So you know it's not the drive.  You know it's the connection.



STEVE:  Exactly.  Exactly.



LEO:  Oh, that's very interesting.  See, it's little things like that that make - that really make you an exceptional programmer.  I mean, I think that's really cool.  You're using your head every time.  You're thinking about this.



STEVE:  Well, and with SpinRite 3.1 it was a major rewrite.  It took a long time.  But I was committed to doing everything I knew I could possibly do in that program.  And, you know, I have the advantage also of being the boss.  So the boss is never annoyed with me that it's not done.



LEO:  It's not going to ship because I haven't put in the cable check software. 



STEVE:  Yeah, yeah.  And in fact I got into trouble with my wife at the time because SpinRite 3.1 was really late.  And she came home from work one day, and I was jumping up and down, all excited because I had invented this brand new way of doing surface testing.  And she was an attorney, and not really into computers at all.  Which was fine with me.  I was happy to have that be my little world.  But I just wanted to - I was sharing my excitement over this really phenomenal surface analysis system that I had come up with that afternoon.  And so when she finally understood what I was talking about, she said, wait wait wait wait wait.  Stop.  You're telling me that you're putting something new in this?  And I thought, uh-oh.  And I said, uh, well, yeah.  But I always knew I was going to get around to doing this.  I just hadn't gotten to it yet.  And she said, Steve, you already have their money.  It doesn't matter what you send them.  And I...



LEO:  Ooh, that's an attorney talking.



STEVE:  I just thought, boy, have I made a mistake.



LEO:  You went, oh.



STEVE:  And I explained to her that the reason I had everyone's money who were waiting for me to ship this upgrade was that they knew when I got it done it would be everything I could possibly make it.  And so I wasn't doing this for the money, I was doing it to create the best product I knew how to create.  And anyway, I'm no longer married.



LEO:  [Laughing] I'd break up with her, too, over that.



STEVE:  Yeah, well...



LEO:  Steve, you already have their money.  Why make it better?



STEVE:  I know.  I just - I thought, you know, the reason I have it is that everyone trusts me to do the best job I can.



LEO:  Yeah.  This is why I don't talk about TWiT with my wife.



STEVE:  Yeah.  Well, we've had a couple yabba-dabba-dos that we've heard in the background.



LEO:  Yeah, what's that all about?



STEVE:  Well, as we know, that's when someone purchases a copy of SpinRite.  Because I've got systems here that are monitoring our network health and what's going on with the server over at Level 3 where our datacenter is, the facility we use.  Last week I muted that, as I normally always do, and as I historically have.  Oop, there's another one.



LEO:  Wow.  And I have to say, that's more than I've ever heard before in one...



STEVE:  Well, and this is the point that I was going to make, is that we had a - I didn't mute it the week before.  I muted it last week.  But I noticed that there seemed to be an unusual number of sales...



LEO:  People are trying to get on the show.



STEVE:  Yes.  That's what I think.  And so I felt...



LEO:  So if you're going to buy the product, buy it during - between 11:00 and 1:00 Pacific Time on Wednesdays because you'll get a yabba-dabba-do.



STEVE:  And I could imagine somebody on TWiT Live, listening live, clicking the Purchase It button and then hearing yabba-dabba-do come out.  And that's like, hey, that's my yabba-dabba.  So...



LEO:  You've come up with a remarkable new way to sell products.



STEVE:  Well, it wasn't deliberate.  And, I mean, I'm sort of self-conscious and embarrassed a little bit.  But...



LEO:  I think you should turn it up a little bit.  We just barely hear it.



STEVE:  So I muted it last week.  And there, like, seemed to be, I mean, again, it's anecdotal.  Maybe it's just my imagination.  But there seem to be an unusual number, a concentration of purchases during the time we were recording Security Now!.



LEO:  So you feel guilty because of the people last week didn't get their yabba-dabba-do.



STEVE:  That's exactly where I was headed was then I felt badly that people bought SpinRite hoping for the yabba-dabba-do treat, and they didn't get one.  So we're not muted this week.  And we won't mute it next week because if there's a week delay in people hearing the podcast and then saying, oh, good, I'm going to get my own yabba-dabba.



LEO:  Steve, I've always said, not only should you not mute it, you should turn it up so we can really hear it.  And if it goes on, you know, if you get a hundred during the show, well, what's wrong with that?  And in fact, if I can only - if I can figure out - you've got to show me the code.  Because if I could figure out a way to have a yabba-dabba-do go off every time somebody donates to TWiT, I think it would be a very smart thing to do.



STEVE:  Seems a little exploitive to me.



LEO:  No, it's - if somebody's going to buy it anyway, and they want to hear their purchase go through...



STEVE:  Their own purchase, yeah.



LEO:  I think it's a great idea.  I should have - I might put - I might figure out a way.  I guess I could do that.  Wait a minute.  Let me think about that.  Because I get an email from PayPal.  It's a little bit of a lag, though.  You really want to have it when you press that button.



STEVE:  Yeah.  For me, that's what it is.  They push the button, and within a second I get a yabba-dabba-do at this end.



LEO:  It's like, you know, they ring the bell when somebody gives them a tip.  I think that works.  It's just psychology.  People want a little extra.  Little shout-out.



STEVE:  Well, they get it here.  Whether they want it or not.



LEO:  Yeah, because I've never heard - we just - we had three in half an hour.  I've never heard that many before.



STEVE:  Yeah.



LEO:  And I think now we're going to have a few more.  Well, before we do our questions, because we have 12 good questions for you all, I am going to...



STEVE:  Neat, neat feedback, as we always get from our listeners.  I just - there were 374 pieces of mail since I last pulled them down.  And, yeah.



LEO:  They're saying they can't hear it on TWiT Live.  They want you to turn up the yabba-dabbas.



STEVE:  Oh.



LEO:  Steve, I've got questions, 12 of them, sitting in front of me.  Are you ready?  Do you feel ready to answer?  Do you want to take a break?  Do you want to go yabba-dabba-do or anything like that?



STEVE:  Someone posted that they want a copy of the yabba-dabba-do WAV file.  I will - I'll put it somewhere on GRC and...



LEO:  I think you can find that online, too.  I mean...



STEVE:  I did.  It was just really just a...



LEO:  There's another one.



STEVE:  Just an enthusiastic, happy Fred Flintstone.  And it just, you know, makes me smile, so.



LEO:  I think it's just - if I had a little light behind me that lit up every time, or maybe we could have a little angel fly across the screen every time somebody donated - I think that's a great idea.  I like it.



STEVE:  Oh, here's another one coming.



LEO:  You're kidding.



STEVE:  No.



LEO:  Wow.



STEVE:  As they're filling out the form, there's a cash register sound, kaching-ching, kaching-ching.  And then the yabba-dabba on successful completion, so.



LEO:  I just love it that you do that.  I think that's cool.  You have a bunch of other sounds, too, I know.



STEVE:  Oh, and actually I've got some really nice synthetic voice sounds that monitor my network here.  And it's like I've got one that says, "Your primary Internet link has gone down."



LEO:  Oh, geez.



STEVE:  And "Your primary Internet link has come up."  And then I also have this - I wrote some tools that monitor workstations that are doing, like, AV compression.  And it'll say, "AV workstation is now idle," because I'm working and I want to know when another machine is done so I can go over and...



LEO:  Oh, that's good.  We need to do all of that stuff.



STEVE:  Yeah, it's really cool.



LEO:  That's really good.  And you wrote those scripts in...



STEVE:  In Assembler.



LEO:  In Assembler, of course.



STEVE:  Of course.  What else?



LEO:  Question one, Alesia Ketchie, who is otherwise anonymous - okay - is very upset that Microsoft uninstalled her new antivirus program.  Steve and Leo, she writes, I turned on my computer a few days ago, and I got a message saying that Microsoft MSRT had removed AV 2009 from my computer.  So now I don't have an antivirus installed.  I tried to download another copy of AV 2009, but I couldn't remember where I got it.  Can you tell me - this is not - this is a joke.



STEVE:  No.  I'm not kidding you.



LEO:  This is a joke.



STEVE:  I am not kidding you, Leo.



LEO:  This is a joke.  Can you tell me where to find it, or recommend a free AV program? 



STEVE:  [Sighing]



LEO:  Oh, boy.



STEVE:  Isn't that perfect?



LEO:  I can't believe it.



STEVE:  I mean, maybe she's pulling our leg.  If so, I take my - I tip my cap, my hat to her...



LEO:  It's pretty funny.



STEVE:  ...whatever I'm tipping, something.  I'm tipsy.  I just thought this was fantastic.



LEO:  Oh, my goodness.



STEVE:  Of course AV 2009 is a virus.



LEO:  Yeah.



STEVE:  It's bad.



LEO:  Yeah.



STEVE:  And a lot of people have been getting it.  And MSRT has been removing it from a lot of machines.  So in case that Alesia is serious, we're not laughing at you, we're laughing with you.



LEO:  Yes, because you're not alone.  There are many, many, many people who've fallen for this.  I get - literally I get this call on the radio show all the time.



STEVE:  Yes.  Yes.  So do not go looking for another copy of it.  Actually it'll probably find you, without you having to look for it, and happily crawl into your computer.  It is malicious.  It's good that Microsoft MSRT removed it.  And Leo, you're probably more on top of what's the best free AV program to recommend, so I defer to you.



LEO:  I'll tell you a couple of things.  First of all, the guys, the clever fellows at AV 2009 are now calling it AV, in some cases, AV 360, or 360 Protection.  Because what they're doing is they're trying to trick you into thinking it's Norton because Norton Antivirus 2009 and Norton 360.  So you may see other names for this.  The way you get it is you will go to what you think is a normal website, and all of a sudden you'll see a popup on your screen that says, wait a minute, you have some spyware or viruses on your system.  We'd like to check.  Click okay.  By the way, if you click okay or cancel, no matter what you click, the same thing happens.  You get sent to a site where it says - it shows you a phony clicker going [indiscernible].  And I know it's funny because I've seen it on my iPhone, and I've seen it on my Mac, neither of which get any of these viruses.  And so it goes click click click click click click click.  And it says, yeah, yup, yup, you're infected.  But we've got the free solution for you.  Click this, download it.  You download an executable and install it.  And that's of course AV 2009 or AV 360, and it is a virus.



So there's a good program to get rid of this, Malwarebytes.org.  They've been doing a good job keeping up with the latest iterations of this.  Malwarebytes.org.  A lot of people have good success removing it with this tool.  MSRT will also remove it.  And for an antivirus, you know, I personally don't think it's - I think it's a foolish economy to get a free antivirus when a better one is 30 bucks a year.  But there are good free ones.  AVG is a good one.  AntiVir is from Free-AV.com.  And there's Avast!.  Those are the three biggest names.  But frankly, I would spend 30 bucks and get a better one that's faster and more accurate.



STEVE:  And is going to be supported by its company and receiving viral signature updates in a timely fashion.



LEO:  The reason AVG gives it away is because they want you to upgrade to their paid version.



STEVE:  Right.



LEO:  So their free version, mostly it's just slow.  It doesn't scan quite as fast.  It uses more system resources.  I like NOD32.  That's what I use.  But there's a lot of good choices out there.  And I certainly think that, you know, spending 30 bucks a year is not too much to spend for an antivirus.



Moving along, question number two.  This is from Jan Hertsens.  Another Yubico question.  He wonders whether Yubico might be missing the obvious.  We're talking about the YubiKey security dongle.  In your last podcast you  mentioned the need to trust the verifier of the key to be able to authenticate a key.  So why not have the key use public key asymmetric encryption?  You supply the user with his public key via download or whatever, keep the private key on the device.  This way any entity can independently verify a token, but can't fake it.  Trust No One?  That seems like a good idea.  Would that work?



STEVE:  Well, let's talk about it.  First of all, there are so many - so much feedback about Yubico and YubiKeys that we received that, I mean, I know we talk about it a lot.  But it's just it's captured our listeners' imagination.  So I thought this was an interesting notion.  There are a couple problems with the idea.  And so let's work through how such a thing would work.  If the YubiKey, or some future variant of it, or a hypothetical dongle like that were to use asymmetric encryption, then the idea would be that one side of the asymmetry of the key, that is in this case we would call it the private key because it would be kept private, although I keep reminding users that they are interchangeable.  One undoes what the other does, essentially.



So in this dongle would be the private, asymmetric key.  And no force on earth could cause it to disclose the key.  So the whole idea would be you need to prove that you own the thing that contains this private key.  So that means that it would have to accept something that was encrypted with your public key that anyone could have access to, and then decrypt it using the other key, the private key, and then demonstrate that it had done so by returning that decrypted thing.  So, for example, you go to a website that has access somehow to your public key.  Like when you originally authenticated yourself with the website, you said hi, you know, I'm Steve Gibson.  Here is my public Yubico - we need to have a different name, though, because I don't want to confuse people.  It is not a Yubico.



LEO:  This is some other Yubico-like dongle.



STEVE:  Yes.  Here's the public key associated with my account and with my authentication device, and that's the key, so to speak.  And this is who I am.  So please authenticate me against this public key.  So you would go through whatever it is you do to authenticate yourself the first time, giving the site that, you know, your public side of your authentication device.  So then, every time you logged in, the site would, for example, just generate what we call a nonce, an n-o-n-c-e, basically a pseudorandom blob which it only ever uses once.  It would encrypt that with your public key, that it and anybody could do.  But the only way to decrypt it is with your private key.  So you would then provide that that encrypted nonce to your authentication device.  And it would decrypt it using the private key that it will never divulge.  It will only do the work that that key allows it to do.  And then it would return the decrypted nonce to the site, confirming to the site that whatever it is, you've got the matching private key that matches the public key.



LEO:  It's like signing.  It verifies your identity.



STEVE:  Yes.  And this concept works.  Here's two problems.  First is, it means that you need data going into this device.  That is, that encrypted blob has to go into the device.  Which means that it can no longer just be a keyboard.  And one of the elegant things about Yubico's solution with the YubiKey is it's just a keyboard.  When you hold your finger over the little contact, it spits out the next little blurch of stuff.



LEO:  It's not that smart, in other words.  It's just a little...



STEVE:  Well, and that's part two, is it is really not smart.  It's very inexpensive because it doesn't take much to do that.  Suddenly now we're asking it to do public key encryption, which is very processor intensive.  And so it would radically change the form factor, the cost structure and essentially the technology that you would need to have in there.  Which is not to say that it can't be done.  There's crypto chips all over the place.  So it could certainly be done.  Somehow you would have to get the data into the key.  The only way I could think of doing that when I was brainstorming is there is communication for the lights on a USB keyboard, you know, the Scroll Lock, Caps Lock, and Num Lock.  And so it is possible for the computer to get data into a keyboard by using those.  And I've not looked at the protocol closely.  There may be even a wider channel than just three lights' worth.  But certainly you could serialize the key's binary bits in order to send that into the key, in order to get the data in.  It would then process it and then spit out the matching crypto.



So it's certainly possible to do - I think you could solve these problems.  I don't know if it could be as inexpensive as the YubiKey, and maybe in the future there will be something like this.  As far as I know, it doesn't exist now.  But I completely agree.  This is cool because it does solve the problem of a third party.  You give anyone who you want to be able to authenticate you your public key, and nobody who doesn't have your private key can do so.



LEO:  Yeah, I love it.  It's risky because you're carrying your private key around on a device.



STEVE:  It's actually no riskier than the YubiKey.  The YubiKey has a secret key also.



LEO:  That's true.



STEVE:  It just encrypts a counter in order to spit it out.



LEO:  Well, and here's one other thing.  The way typically your public key/private key works, isn't there a passphrase or some other way of matching yourself to the private key?  I guess [indiscernible].



STEVE:  You could certainly add...



LEO:  ...[indiscernible] signing, there is.



STEVE:  Yeah.  You could certainly add authentication.  And you could also even do it - I wonder if you could do it at your end, where you have to type in your passphrase that stays local; so you're authorizing the key to do the decryption, and that way we've now made it multifactor, too.



LEO:  I think really the issue is totally cost.  I mean, now you're putting a processor in here.



STEVE:  Yeah, it's, well, yeah, yeah.



LEO:  You know, prices are falling.  Someday somebody's going to do this.  It's just how do you get it down to the nickel.



STEVE:  It certainly makes sense.  And it's a cool thing to imagine that you've got your private key locked up in this little thing on your key ring, and you can - now you no longer need a third party.  See, the point of the third party is they know your secret key.



LEO:  Right.



STEVE:  But if you use public key crypto, you don't need that third party.  You just need more power at your end.



LEO:  Although ultimately - at least PGP works with a chain of trust.  You always have a third party who's validating that you are you.  Otherwise you can make up a key.  I'm Steve Gibson.  See, I've got the key that says it.



STEVE:  Well, no.



LEO:  Somebody has to verify that that really is Steve Gibson's key.



STEVE:  Well, remember that I said we originally need to go through some sort of authentication.



LEO:  Yeah.  There's always trust somewhere, is what I'm saying.



STEVE:  When I'm giving them my private - when I'm giving them my public key.  That is, the matching public key.  And so you could imagine that this thing, if you, like, hold the button down for a long time, it spits out the public key that it's willing to give to anyone, anytime.  But and that way, you know, it's like it's got them both.  But it will never release the private key.  It will only use the private key to perform a decryption operation on your behalf.



LEO:  Right.



STEVE:  Anyway, it could absolutely work.  It just, you know, it would require more processing power in the key.  You really don't want to, like, let the key out even into the CPU.  You could say, well, I've plugged my key into a PC.  Modern PCs could do that in a blink of an eye.  Yes.  But then as soon as you let the private key out of the hyper-strength YubiKey, future YubiKey thing, then it's subject to compromise.  So you never want to let it out.  You only feed something in for it to do the work on.  I mean, that's certainly an upgrade to the concept.



LEO:  Thinking on - I have a question, thinking on this note.



STEVE:  Yeah.



LEO:  Because I use PGP to create a public/private key pair that I use to sign all my mail so that people know it's my mail.  Now, of course, anybody could do that, make a key that says it's, you know, Leo Laporte.



STEVE:  Actually all they know is that it came from your machine.  Right?  Somebody else could use your machine and be signing mail from you.



LEO:  No, no.  You could create - because of the nature of PGP, anybody can create a key with any address.  But what you do is you ask people do sign it.  So people who know it's you would then sign the key.  And so the trust goes up.  It's called a chain of trust.  And it is kind of a flaw in the PGP system, unlike a certification system.  If you get a certificate, you prove to Thawte or VeriSign that you are you and at least prove that you have that email address  because they send a cert to that email address.  Not with PGP.  You're generating the key locally.  So there's no central authority.  But at the same time there's no central authentication, either.



But what you do is you ask people to sign it.  In fact, they have key-signing parties where you'll go, and a hundred geeks will bring their PGP key, and I'll look at your driver's license, say yeah, that's you, and I'll sign your key.  And then it says, well, Leo Laporte says it's him, and Steve Gibson says it's him, I guess it must be him.  It's not tied to the machine.  I carry my PGP private key with me.



STEVE:  The problem is we're mixing up certificates with...



LEO:  Exactly.  This is a different system.



STEVE:  Right, right, right.  And so this is a certificate-free system where we're simply using the...



LEO:  You know what it's like?  It's a self-signed certificate.



STEVE:  Well, no, it's not a certificate at all.  It's just crypto.



LEO:  It is.



STEVE:  It's raw crypto.



LEO:  But I'm saying, in terms of trust, it's like a self - you can make a certificate for yourself, self-signed.



STEVE:  Absolutely.



LEO:  But no third party has verified it in any way.



STEVE:  Right.



LEO:  That's what these are like.



STEVE:  So the idea is, if this next-generation key, if you bought one, it would have two modes of operation.  You hold the button down for a long time, so that you don't do it inadvertently, and out comes your public key.  So it's able to dispense your public key whenever you need it.  You can write it down.  You can store it in a text file.  You could use to enter it into a website.  Doesn't matter.  Because, I mean, that's freely offered.



LEO:  It's public, yeah.



STEVE:  It's public.  Then as you normally touch it, it will wait for a something to come in.  And when that whatever that is, that is an encrypted something, it will apply your private key to decrypt it and then type it back out.  I mean, and that - if that system existed, it would be a tremendous authentication tool.  And what it proves is, it proves you're in physical possession of that object which contains that private key.



LEO:  Precisely, my friend.



STEVE:  Yeah.



LEO:  Darren Tieu in Redwood City, California wonders whether a VPN is really necessary.  Do I really need a VPN, he says?  I'm using an open WiFi in a hotel.  Is a VPN necessary?  If I'm transmitting information I don't want anybody to see, shouldn't that be on an SSL connection anyway, you know, a bank, Amazon, whatever?  Any sensitive information should never be transmitted over a non-SSL site, whether it's through a VPN connection or not.



I really don't see the need to spend money for a VPN connection.  I don't care if people in the hotel know I'm on ESPN.com to see if the Cal men's basketball team beat Stanford.  I don't care if people are reading my - oh, I'm sorry.  I care if people are reading my email, but Gmail is through an SSL connection, so they can't see my email anyway, with or without a VPN.  If I'm checking my balance at a bank site SSL, people can't see the traffic.  I understand I need a VPN if I connect to a work network, but that's different than surfing on the web.  In terms of protecting someone from hacking into my computer, a firewall protects me, but not a VPN connection.  Am I correct?



STEVE:  Absolutely.



LEO:  The rub is, not everything is SSL.



STEVE:  And even, as we know, Gmail is not SSL unless you explicitly start your session with HTTPS in Gmail.  Many people just do Gmail.com, which defaults to non-SSL.  You're taken briefly into a secure session for your login, and then you revert to nonsecure.  So all of your Gmail is passing in the clear.  It is certainly the case that, if someone is really vigilant with what they're doing and whether they're secure or not from moment to moment, I agree with Darren that a VPN in an open WiFi scenario is not necessary for typical use of the web, if he doesn't care what he's doing.  But if he - most email is just standard IMAP or POP or SMTP, which is not over an encrypted connection.  So email is classic for just being totally readable and, arguably, somewhat private, especially login credentials that are often easily captured, username and password for login.



So again, if you're really careful, then I agree, something like HotSpotVPN we were talking about, and this is probably what triggered Darren's question, where you wanted to be protected in an open environment, you know, you decide if you want it or not.  Remember that two weeks ago we had the question from someone who was for some reason, or for a limited length of time, being forced to work in an employer's office that had open WiFi, and he didn't want to stir things up and cause a lot of ruffled feathers.  So he was asking us how can I protect myself?  I'm a Security Now! listener.  I understand the importance, the danger of open WiFi.  I want to protect myself.  So it's like, there, something like HotSpotVPN which is very economical and available on one- or two-day contracts, or a week, made a lot of sense for him.  If Darren is feeling VPN-hostile, then fine.  I mean, I completely agree with him.  You have to be vigilant, though, moment to moment, action to action, and aware that unless you are over a secure connection, anyone can see what you're doing.



LEO:  You can in the Gmail settings now turn on Always Use HTTPS in the browser.



STEVE:  Good.  I thought I remembered that they made some change.



LEO:  Yeah.  And that's highly recommended.  I think the real problem is a lot of Internet service providers' email is in the clear.  The password's sent in the clear.  And so that's kind of the nightmare scenario, where you check your email, and then you leave, but the password's been sent in the clear.  Now the guy's got access to your email until you change your email password.  And how often do you do that?



STEVE:  Right.



LEO:  And once somebody has access to your email, I mean, there are all sorts of threats.  So, yeah, if you're vigilant.  But that's always the case.  If you're vigilant you don't have to worry. 



Larry Strope of Streamwood, Illinois is describing his love/hate relationship with NoScript.  Dear Steve and Leo, I've been with you guys since the beginning.  I've enjoyed all the various topics you've covered over the years.  Some topics have done fly-bys on my senior-sized, shrinking brain.  Most of them have stuck in some fashion or another.  All good stuff, mind you.  And I've been a SpinRite user since v2 or 3.  Wow.  Can't exactly recall which.  I still have an Apple II+.  Will SpinRite work on that?  Just kidding, just kidding, but not kidding about having an Apple II+.  That goes back to the time before consumer hard drives, a.k.a. "The Chronicles of Apple."



My topic is NoScript - this is almost a Shakespearean sonnet here - and my love/hate relationship with it.  I love the added protection it offers against script baddies, but I hate the added time spent in trying to decide which of the listed blockages I need to clear that will allow me to, say, push a button required to continue or accept or submit, among the list of allows that extends from the bottom to the top of the screen.  When I look at the list, I have no idea at all which item is controlling the button I am trying to use.  And frequently I find that certain links contained on a page won't work at all without making additional allowances.  I usually end up in frustration saying to hell with it and allowing the entire page.  That's what I always do.  But doesn't that kind of defeat the purpose of NoScript?



STEVE:  No.



LEO:  One would think that a modicum of common sense would prevail in these situations.  After all, if I have chosen to sign up for a newsletter or register or make a purchase from a site I believe - a key word here - to be trustworthy, then one would think allowing the entire page would be safe.  The offset is, however, that overall trustworthiness of websites has diminished considerably over the years, and a sense of wariness is usually present in the subconscious (clicking with your fingers crossed behind your back).  This is particularly true when you see things like DoubleClick and Google Analytics showing up in the list.  I suppose this has been more of a rant than a question.  But do I need more caution?  Less caution?  A therapist?  Thanks for a great series.  What a great letter.



STEVE:  Yeah, I really liked it.



LEO:  So this is what I had.  That's the same problem I have.  But I always just say, oh, allow the site.



STEVE:  Yeah.  For me, okay, again, the recurring theme we have here is know the risks and know your options.  And so I have no problem with Larry saying allow the whole page.  NoScript is one tool that I haven't abandoned after I've turned off the popup notices, which really are annoying.  I think the default for that should be the other way around.  But I understand why a new NoScript user might want to have those.



For me, every time I run across a site that's got a problem, it's like, oh, okay, fine.  And I just go down, and I allow it.  I'm not running a personal firewall that manages all of my outbound traffic.  I'm not running an antivirus.  There are many different security solutions that get in my way more than I'm willing to tolerate, but NoScript is not one of them.  I'm so cognizant of the tremendous ease of stumbling onto a site that hurts me without any ability to control it.  I mean, I can control not clicking on links in email.  I can control having a sense of responsibility for what software I've got installed on my machine and how it's phoning home and what it's doing.  But I can't control ahead of time what a page that I'm about to receive when I click on a link is going to do to me.



So there's a real threshold in my thinking about scripting.  And, you know, we all know that I've been anti-scripting for a long time.  Clearly, the 'Net needs scripting more and more.  And I don't - I can't argue against the functionality the scripting provides.  It's so useful.  Unfortunately, with that usefulness comes exploitability.  So for me, I guess I would say think of NoScript as a tool, a useful tool that you can use any way you want it.  But it's better to have it than not at all.



I just - who knows what kind of junk, I mean, remember the first Q&A was with, I think, Alesia, who got AV 2009 installed on her machine.  Well, the way that original popup happened was scripting.  The site she went to used scripting to produce a popup which had malicious intent, which then induced her, as you said, doesn't matter whether she clicks yes or no because a script is behind that, that took her to the website that performed a fake AV test.  All of that is the fault of scripting.  If scripting was disabled, she would have never had that trouble and would not have had that malware installed on her machine.



So I'm really bullish on NoScript.  I just think it's the right tool.  Again, I'm not telling everyone to run with it all the way up and fight with a site.  It's up to you.  But having that choice is what NoScript gives you.



LEO:  Actually, I don't know if NoScript would have protected you against AV 2009.  The way it works is, at least in one - in the instance I'm aware of is that somebody's website is hacked.  Their .ht access file is modified to check the referrer.  If the referrer comes from Google or Yahoo!, it replaces the page that you would - and this is all happening server-side - replaces the page that you would get with another page that says you've been hacked.  So it - and that could also...



STEVE:  So it's not a popup window.



LEO:  It looks like a popup window.  It's just a sized HTML page.



STEVE:  That requires scripting.



LEO:  You can't just size a page, huh?



STEVE:  No.



LEO:  Okay.  Yeah, because it does, yeah, I guess in order to trick you it needs to look like a dialogue box.



STEVE:  An OS dialogue.



LEO:  Yeah.  So that's done by scripting.  Okay, yeah, you're right.  Of course anybody who falls for that probably isn't running NoScript.  Do you, so when you get to a site, do you say Trust All, or do you say one by one, okay, you can allow that script, allow that script?



STEVE:  I've certainly seen sites where the page has resources coming from all over hell and gone.  I mean, it just, you know, you - there's George.  You click the little blocked S for Script, and up pops a menu of just it lists all of these different domains that the site, that the page is trying to pull from.  Well, first of all, there's a good clue that this is a sophisticated page.  I mean, I would look askance at a page that was doing that.  Most sites don't give you a huge list of domains.  But I normally just allow the main page.  And for me, 99.9 percent of the time it works.



LEO:  Yeah.  Yeah.



STEVE:  Or you could just say allow everything.  Again...



LEO:  I'm not saying allow everything, but I'm saying allow this site.



STEVE:  Yes, yes, allow this - allow everything on this page.



LEO:  Right.



STEVE:  And again, even doing that, even that gives you a chance.  It says wait a minute, you know, you've seen most of the page.  Something's not working.  I mean, my point is you've arrived, and you can evaluate.  If you had scripting enabled by default, blanket scripting, you don't have a chance to evaluate.  You don't have any opportunity to make a decision about whether you want to go further or not.  I mean, and when you click a link, you're blind.  You don't know where you're going.



LEO:  Right.



STEVE:  Until you get there.



LEO:  What a world, what a world.



STEVE:  Yeah, well, it's why we have a podcast.



LEO:  Alistair Kidd in "Larbert," wherever that is, suggests that Steve's AxCrypt encryption advice requires a knuckle rap.  Dear Steve, from the last SN Q&A when talking about email encryption, you mentioned AxCrypt."  And he quotes you.  He says, "So I would say" - you say - "So I would say, for somebody who just wants to occasionally send something encrypted, you just encrypt the file and email it and a little AxDecrypt program to a friend, or tell your friend to download AxDecrypt, which is also free."  But saying you could send a binary attachment, expecting the recipient to run it?  Doesn't that contradict all sensible advice about email attachments?  I guess it does.  If I got an email saying that I had to run an attachment to decrypt it, it would go straight into the bit bucket.  Same with an email containing a link asking me to download an executable.  Yours in flippancy, Alistair.  P.S.:  Any thoughts about Microsoft's Fix It button idea?  Ill-considered?  Rank rotten?  P.P.S.:  Love the show to bits.  That is a good point.



STEVE:  Yeah.  And I don't disagree with it at all.  My assumption is that, if you're sending someone an encrypted file, you know them.  It's your attorney.  It's somebody you have some sort of a relationship with that requires encryption, and that that's a little bit off of the normal beaten path.  So I would have no problem if someone said, hey, I encrypted this with this program, go get it.  Especially if they were a trusted friend.  Go get it from the site or put AxDecrypt, Google it, into the - run a Google query, find it yourself, I mean, whatever.  Or you've arranged to have the program before, and it's what you guys use when you're sharing things back and forth.  So, I mean, I guess I understand his position.  But it seems to me that it's - the idea is it's someone you have a relationship with, rather than spam being sent out saying, hey, here's an attachment, go here to decrypt it, and the spam is coming from someone you don't trust and have no knowledge of.



LEO:  Right, right.



STEVE:  By the way, there was some dialogue after this in GRC's Security Now! newsgroup indicating that there are flavors of ZIP which use AES encryption, which I was unaware of.  And apparently not all flavors of, but some.  But that's an interesting notion, too.  So here's a mainstream ZIP program, and I don't know if it's the ZIP built into Windows.  I will try to do some research about this because it would be terrific, for example, if there was a platform-neutral ZIP format where encrypting the ZIP actually did encryption, rather than putting the weak password protection on ZIPs that they used to.



LEO:  Yeah, used to be really crackable, yeah.



STEVE:  Used to be very easy to crack it, yes.



LEO:  Yeah.  I use PGP.  I actually use GNU Privacy Guard, which is an open-source PGP.  And I sign all my messages with it.  And I publish my public key.  So if somebody wants to encrypt mail to me, they have my key.  And they just use it, and they encrypt it, and they send it to me.



STEVE:  Yup.



LEO:  I wish more people did that, but it's just too geeky.  Nobody does it.  Jonathan in Roseville, California resists the "YubiKey for static password" notion.  Steve, you've been talking about the YubiKey from Yubico for a while now.  I really like the idea.  I use an RSA key for one of the sites I use, but the YubiKey would be much more convenient except that I usually get the RSA key over the phone.  However, you've mentioned using it in static password mode, as well.  I listened to your episode going into detail about the YubiKey, and I didn't hear anything that makes it sound any more secure than writing down a strong password and entering it on the keyboard accurately every time.  You would be vulnerable to key loggers still, and this time it would matter because it is not a one-time password.  Would this be more secure than just storing the key in a text file on a thumb drive?



For my wireless router I use one of your 64 hex character Perfect Passwords as an AES encryption key, then store that string in a text file, because you're not going to type it, on a removable drive.  I then copy and paste it into the appropriate field when setting up a new wireless client.  Is there something I'm not thinking of?  I could even encrypt that file.  That would add security.  But I use this drive every day for school, and I don't worry about using it.  I'd love to know what you think about this.  Thanks for the netcast.  Exactly what I love to listen to - in-depth technical discussions of IT issues.



STEVE:  Okay.  Once again, I bring this up because there's so much traffic in our feedback about the YubiKey.  And I've thought about why there's the amount of people questioning this notion of static password.  And I think that I should have said something when we first discussed this that I never said because I sort of took it for granted more than I should have.  And so I want to make it very clear, sort of once and for all, that when you change the YubiKey from its one-time password mode to static, you've completely changed everything.  I mean, everything that was special and originally really cool about the one-time password mode of the YubiKey is changed.  It's gone.  Now what you have is something completely different.  I mean, you can literally - and I wanted to be really clear about this - think of it as two entirely separate devices.  You know, they live in one piece of plastic, and it's one or the other at a time.  But, I mean, they really are completely separate.



So we've had a lot of listeners questioning the security of the static password.  Well, I'm glad they're questioning it because they've been listening to the show.  It means they understood what the nature of the coolness of the whole concept of a one-time password.  He mentioned his RSA fob.  I've got the little eInk credit card in my wallet which I'm able to use interchangeably with my football if I'm away from home.  You know, I mean, all of these one-time password schemes are uniquely secure because they don't use the same thing twice.  So they're fundamentally different from anything which is static.



And so I completely agree with Jonathan's comment that the YubiKey in static mode is nowhere near as secure as the YubiKey in one-time password mode.  But it's not intending to be.  It's not saying it is.  It's a very different model.  And once again we need to kind of come back to the security model and just understand what that is. So now with this static password mode we're generating 64 characters from a 16-character alphabet which has the entropy, the randomness of 256 bits, when the YubiKey is configured in static password mode with a maximum-length output.



So what it is, is useful for what it is.  It's 64 characters, the same 64 every time.  You can use it as your WPA key.  You can use it as a password on a website.  Every time you use it, you need to understand that it's not one-time password, it's the same password every time.  But what you're getting is you're getting its extreme length and the difficulty of memorizing it as its benefit.  And the ease of entering that monster-long, 64-character thing every single time, the ease of entering it just by touching your finger on the button.



So there are scenarios where you could argue that the risk is very low.  For example, in preboot authentication with TrueCrypt, where there's no OS running, there's no Internet connectivity, you're like pre- all of those problems that you typically have.  And you could add your own password after that in order to create a second factor, the YubiKey being one, with its monster-long thing, and then something you add to it.  So again, very much like NoScript where, yes, NoScript has some problems, but it gives you some leverage.  I think the YubiKey in static password mode, let's not think of it as the end-all, be-all solution.  Let's think of it as, okay, that's useful for a certain domain of solutions different from what the YubiKey in its one-time password mode offers.



LEO:  Okay.  That makes perfect sense to me, as long as you understand the distinction.  Right?



STEVE:  My rant is over now.



LEO:  Okay.



STEVE:  They really are separate solution domains.



LEO:  Yes.  It's important to understand.



STEVE:  And this one little bit of plastic is able to function either way, which is I think very cool.



[Talking simultaneously]



STEVE:  ...applications for each.



LEO:  He's right that you could store it on a USB key.  You could do all sorts of things with it.



STEVE:  Well, in fact, until I did this, switched one of my YubiKeys to static mode and used it as my WPA password, which I have, when someone came over - I use my own Perfect Passwords just like he does, and I had that on a file in a thumb drive.  And so when someone came over and wanted to get online with their laptop, I'd give them the thumb drive.  They would get the file, open the file, copy and paste it into the password box twice, and then they were online.  Now it's cooler.  I've got...



LEO:  Yeah, just give them that, and they go, boom.



STEVE:  Exactly.  They go, like, what the heck is that?  I say, ah, well, you're over here in the house of magic and mystery, so what do you expect?  You know, we've got yabba-dabba-do going off all the time.  It's loony over here.  And so I stick this little sliver of black plastic in and touch it, and it goes zoop, and then do it a second time, and bang, they're now online.  It's very cool.



So, yes, understanding where and how it makes sense to use it reduces this to a tool.  Neither of them are perfect because, for example, we saw that the YubiKey in one-time password mode, being symmetric, requires a third party to authenticate.  Okay.  So that's useful for a certain domain of problems.  And the static system doesn't require a third party, doesn't have public key encryption.  But what it does is, is offers you a very complex string which is safe, you could argue is safe to use in an environment where keystroke logging is not a real threat.



LEO:  Right.  Mike Silvers in Salisbury, Maryland wonders why his NAT router isn't protecting him.  Steve, I'm an avid listener and a computer consultant on the east shore of Maryland.  I have a question about the visibility of internal LAN IP addresses through a NAT router.  I visited the site IP-Lookup.net.  When you reach the page, it gives you information about your WAN IP address and ownership of that address.  What concerns me is the little link under the WAN IP address.  When you click on the link, it shows the internal LAN address of my Apple Mac.  I thought the NAT router would shield the outside world from determining my internal IP structure.  How do they bust through the NAT?  Should I be concerned about this?  This is an old trick.



STEVE:  And I have one word, Leo.



LEO:  Yeah.  I know what word it's going to be, too.



STEVE:  Uh-huh.  It's the S word.



LEO:  Yup.



STEVE:  Yup.  Scripting.  Scripting.



LEO:  In other words, the computer, your computer knows its IP address.  So it just writes a script that says publish the IP address.



STEVE:  Yup, it's funny, when I was reading this, I said, I think, I mean, I knew what the answer was, just as you did.  I went to IP-Lookup.net under Firefox, and it completely failed.  It showed me my WAN IP.  It did not show me my LAN IP.  In fact, the link for that didn't work at all.  It was completely nonfunctional.  So then I said, okay, gee, I've got to enable scripting.  So I deliberately enabled scripting.  Even then it didn't work.  And it turns out it's because it uses actual Java, and I've deliberately not installed Java for Firefox's use because I just don't think I need it, and I don't.  However, I opened up IE and gave it a try under IE, and it worked perfectly.  So it's like, yes, thank you anyway.  It's scripting.



LEO:  This is an old trick sites used to use to say your privacy has been compromised, and it would do all this Java script stuff and...



STEVE:  Even worse, what many sites did was, on IE, was they would show you the contents of your hard drive.



LEO:  Right, right.  I remember that.



STEVE:  Oh, my god, I can't tell you how many times, I mean, how much email Greg has answered where they use ShieldsUP!, and we'd say you're secure, and they'd say, hey, I went to this site, and it showed me the contents of my C: drive.  It's like, yes, because your browser was told to show the contents of your drive.  The site just gave your browser a link that said show C:\ and the browser does.



LEO:  Just to make this clear, there's stuff that happens on the server side, and there's stuff that happens on your browser, on what's called client side.  And your browser knows all that stuff.  So your browser can be told to display that information.  It doesn't mean it's sending it back to those guys, either; right?  I guess it could.



STEVE:  Correct.  Good question.  It certainly could.  I don't know in this case if the Java sent it - or JavaScript because either can do it - sent it to their server, and then they displayed it, or whether it just displayed it locally.



LEO:  Oh, I'm sure it just displayed it locally.  But my question is - yeah, because that's all it needs to do.  but my question is, could it be used to - could you query, I mean, we'd have to ask a JavaScript wizard, I guess.  I'm sure there - the theory is that it's sandboxed, and it's prevented from doing stuff like that.  But there might be ways around that.



STEVE:  Yeah.  I would be surprised if you couldn't incorporate the local IP, for example, into a URL query.



LEO:  Exactly, something [indiscernible] like that.



STEVE:  And so have your browser request a resource that had the IP embedded in it, and the server could then capture that request and decode the IP from it.



LEO:  You'd make a good hacker, Steve.



STEVE:  Well, I've got a lot of that technology over at GRC for, like, tracking users who don't have cookies enabled, where I'm wanting to offer them services and, like, keep track of who they are.  I use that in the cookie forensics stuff that is soon to be made public in order to allow people to have everything blocked, yet I still maintain a relationship with them.



LEO:  Jack Scharf has a good question from Longmont, Colorado.  How is he supposed to know that auto updates aren't trojans?  He says on Microsoft, whether it's Windows or Defender, Apple with iTunes or Safari, Adobe with Acrobat, Intuit and any other software vendor, alerts me to install automatic updates, how do I know it's really that company?  Maybe it's just a popup saying you need a new update, and it's a trojan horse.  With all the hacking and spoofing going on, this seems like an avenue into unsuspecting computers which is far overripe.  What are vendors doing to prevent this?  What can users do?



STEVE:  Well, it's a great question.  Really the security answer is, if you're running programs on your computer, you have implicitly trusted them.  That is, you've installed software from Microsoft, Windows and Defender, or Apple iTunes, Adobe Acrobat, TurboTax from Intuit.  The point is you're assuming that they're going to behave themselves honorably.  And in running them, essentially they have the full run of the computer.  From that standpoint it's sort of a little surprising we're not having more problems than we are with programs misbehaving.  Of course, if Apple iTunes did something bad, thanks to the communication network we now have with the Internet, the world would know about it very quickly.  So vendors are doing the best job they can not to cause problems for their users because they recognize that it directly affects their bottom line.



LEO:  Oh, but I think he's saying what it somebody posed as iTunes and said, I'm iTunes, I'd like to update.



STEVE:  Well, then you've got something in your computer which is working against your interests.



LEO:  That can only happen because you've got somebody running on your system already, yeah.



STEVE:  Yeah.  Now, the interesting threat is, what if somebody, for example, used a DNS spoof so that when iTunes tried to get an update from Apple, it actually got an update from a malicious site?  So there they're intercepting a valid software update, and essentially commandeering it in order to get malware installed in your machine.  And we know, for example, that Microsoft understood that problem, and so they've gone to some measures to cryptographically sign and protect all the Windows downloading stuff that is going on.  And we hope that Apple and Adobe and Intuit and the others are doing the same, although there's no guarantee that any random company that wants to do automatic updates is taking every kind of security measures that they can.



LEO:  Okay.  And I guess in a way that's what the Antivirus 2009 thing was, which is essentially trying to pose as a dialogue box from a legitimate company to trick you into downloading something else.



STEVE:  Using a little bit of scripting, followed by a lot of social engineering.  I mean, that was largely a social engineering hack, convincing people that, oh, look, you're infected, click this to get disinfected.



LEO:  You'd know if it were, I mean, it would be hard to spoof one of those Microsoft or Apple windows; right?  I would think.  Maybe not.  I guess if it's a Windows window, anybody can draw it.



STEVE:  Yeah, code running on your machine can look like anything it wants to, essentially.  But by that time you've got code running on your machine.  I guess the danger is...



LEO:  I'm worried about scripting.



STEVE:  Yes, intercepting valid software's automatic update maneuvers and, like, getting your own stuff in instead.  And you could imagine, if they weren't - if software vendors were not careful about the way they were protecting their own automatic update system, that could be a problem.



LEO:  Right.  Hasn't happened yet, to my knowledge.  Todd in New York shares a very interesting VPN story that raised some questions.  He says, guys, I love the show, loyal listener, so on, so forth.  I have a service that is offered through my condo, Verizon Avenue, and I have been suspect for some time that they were throttling my service.  Oh, his ISP is through his condo.  I supposedly have 1MB down - which isn't very much - but for some time I've had certain music services, Rhapsody, that once worked quite well in this building, until all of a sudden I started to have horrible buffering issues where songs would stop in the middle multiple times in the song.  I chalked this up to something that had changed on the side of the music provider, but today I learned otherwise.



I've been working freelance to set up an Astaro Security Gateway, yay, for a client that I consult for.  In testing out the Astaro appliance that I installed in the client's office this past weekend, I noticed something odd.  I was connected into their network over VPN, with all of my Internet traffic routed through the VPN, when, forgetting that I was still connected, I fired up the aforementioned music service.  To my amazement it worked fine.  So he's on the same connection.  It's just VPNed.



STEVE:  Yup.



LEO:  Songs flowed like butter without one hiccup, which had been more than commonplace before.  It was to the point where literally I could not listen to a streaming song for more than 30 seconds before it would stop as the rest of the song buffered.  Now, through the VPN, it was great.  I could even download stuff in the background, still playing songs in the foreground.  This has been a problem for a while, so I really noticed the improvement.  So in order to test, I dropped the VPN connection, and my song-playing ability immediately dropped back to the abysmal zone.  VPN back on, all was good.



So, two questions.  First of all, is Verizon throttling to push their faster FIOS service?  If so, tsk tsk.  And secondly, does a secure SSL tunnel get around this problem?  Obviously going through a tunnel I'm getting reduced throughput.  After all, I have the same amount of bandwidth that I'm pushing through another network and then back out.  But is the fact that this traffic is encrypted getting around their bandwidth-limiting countermeasures?



I love the show.  SpinRite's saved me on numerous occasions.  And Leo is the only reason I'm still an IT professional.  Thanks for your insight.  P.S.:  The Astaro Security Gateway is a godsend and has made me and my client very happy and safe campers.  We like to hear that.  That's great.  So that's a really good test.  Bad bandwidth, run on a VPN, it's better.



STEVE:  Isn't that interesting.  So what this - first of all, to answer his question, he's absolutely correct that if an ISP or anyone out on the Internet were trying to do application-specific throttling, where they're going to throttle only some traffic and not others, they need to see the traffic.  And you cannot see traffic in a VPN because every packet is individually encrypted, so it looks like just - it looks like literally, as we've talked about often, encryption is noise.  It is absolutely random noise.  And so the VPN wrapper encrypts basically all of the packet, including the source and destination port.  So the particular protocol that you're transferring, whether it's email or web or streaming audio, any ports associated with those protocols are obscured completely within the encrypted VPN tunnel.  So if - and we don't know for sure that this is going on, that Verizon is doing this.  But if they wanted to, they would bandwidth-limit based on some aspects of the traffic that their deep packet inspection would be identifying.  And so they would hamper that.  They are unable to do so if that traffic is being enclosed in a VPN tunnel.  And, I mean, based on the evidence that Todd has shared with us...



LEO:  Pretty clear, yeah.



STEVE:  It really looks like that's what's going on.



LEO:  They're probably using some sort of packet sniffing or, you know, actually on streaming audio it's a different port.  So they could even be watching the port.



STEVE:  That's all it would take.  It would be saying, okay, we're just going to, like, give low priority to this port, to traffic on this port.  Sure, we'll let people transit it.  But if we're busy, and we've got other things to do, we'll just drop some of those packets and let them worry about getting them resent later, which is all it takes to throttle and cause problems for that kind of traffic.



LEO:  That happens to our streams.  We have an audio stream on port 80 as well as port 8000, so that just kind of eliminates that because you don't usually throttle port 80.  That's the web surfing port.  But our video, our TWiT Live video is on a different port.  Although it's got some smart technology in there that will change ports, depending on how it's being handled.  It ultimately ends up on port 80, if it has to.



John Ratzlaff in Candler, North Carolina wonders about eInk.  I wonder, too.  eInk.  Hi, Leo and Steve.  You have mentioned the new Kindle 2.  You said it had 16 levels of gray.  How are they doing that?  My understanding of how eInk works is it consists of microscopic balls, white on one side, black on the other, which rotate in place according to the charge applied, which would result in either black or white.  How do you get levels of gray?  Dithering?  Yes.  Right?



STEVE:  It's interesting.  If we're talking about, well, first of all there's not just one kind of eInk.  There are a number of different technologies.  The early stuff did use bicolored spheres...



LEO:  Oh, really.



STEVE:  ...which were black on one side, white on the other.  And they were suspended in an oil suspension and then rotated electrostatically so that their white front - the white side, the white hemisphere was aimed at the reader, or the black hemisphere was.  So that was that technology.  However, in the case of the current eInk that is used in the Sony readers and also in the Kindles, they use an entirely different approach.  They have a high number of little black particles.  And those black particles are pushed to the front of the screen or pulled to the back.  And so you get a somewhat lower contrast ratio.  But that's the technology they use is a very high number of black particles within each pixel region.



And in fact if you've ever had an occasion to look at the Sony or the Apple screen, for example, through a jeweler's loop or a good magnifying glass, you can see sort of dust.  It's like not all the black particles obeyed their instruction to go to the back of the bus and get out of sight often.  In fact, you and I have talked about how there sometimes is a ghost left behind.  When you turn the page you can see sort of a dim ghost of the contents of the prior page.  And that's literally - it's a little bit sort of reminiscent of phosphorescence and the way phosphor fades.  But it's just that the greatest percentage of the particles did make the migration, but some didn't because it's sort of a statistical thing.  So what they're doing in the case of the Sony reader and the Kindle is they're deliberately pulling different percentages of the particles away by having carefully designed their technology so that they're able to get shades of particle propagation within a single pixel.  So it's a cool technology.



LEO:  Very, very interesting.  See, I never really was aware of how they did it.  I thought it was that charged ball thing, too.  So it's more like an Etch-A-Sketch.



STEVE:  Yes.  It's very much like an Etch-A-Sketch.



LEO:  With static.



STEVE:  With electrostatics, yeah.



LEO:  Also, frankly, a little bit like how a laser printer works.  Isn't it?



STEVE:  Uh, yes.



LEO:  I mean, in effect, because it uses - it charges the drum, which attracts the toner.



STEVE:  And, exactly, and a laser printer has ink in the form of so-called "toner," which is super small little black particles.



LEO:  Which everybody who has ever gotten it on his hands knows.



STEVE:  Very much like that.



LEO:  So, yeah, they charge it.  It attracts the particles in the places that you want.  And of course a laser printer can do really good grayscale.  We'll get ours in a week.  We'll give you our review.



STEVE:  Yes.



LEO:  Probably not in time for the next Security Now!, but the one after.  Regina Gannaway, Great Mills, Maryland, wonders if the Sony PRS-505 is more secure than a Kindle?  It's Sony's answer to the Kindle.  Actually it predates the Kindle.  Dear Steve and Leo, love the show.  On Episode 183 you both expressed your love for the Kindle and your not-so-glowing opinion of the Sony eBook Reader.  I have a security-related question, reason, rather, why I prefer the  Sony eBook Reader to the Kindle.  My main reason for purchasing the eBook Reader from Sony is to have a compact way to read documents for my job.  They're usually in Microsoft Word format or PDF format.  Putting them on my Sony eBook Reader helps reduce the weight of how much I have to carry around to read in those spare moments here and there, not to mention saving trees.  I also convert PowerPoint documents to PDF, read them on the reader, as well.  Big lifesaver there.



My Sony software allows me to just drag and drop these formats onto my PRS-505 reader.  The document never leaves my control.  My understanding is the Kindle requires users to send the document to Kindle.com, where they convert it to their proprietary format.  Then they will send a newly formatted document back to the Kindle device.  I can't do that.  I work for a government agency, and I can't email documents to a third party to be converted to work on the eBook Reader.  I have to be able to maintain control of the documents for various reasons.  Usually it's proprietary information.  Therefore I like the fact that I can transfer a document to my eBook Reader without losing control over it.  Don't you think this is a good reason to recommend the Sony eBook Reader?



STEVE:  Well, I know you know the answer to this, Leo.



LEO:  I do.



STEVE:  Yup.  And I just wanted to put Regina's mind at rest.  You can do exactly the same thing with the Kindle that you do with a Sony.



LEO:  You've done a lot of research on getting stuff onto both the Kindle and the Sony.



STEVE:  Yeah.  When you plug the Kindle, which has a USB connection, into your computer, it switches it into drive mode, and it looks not like a reader, but just like a drive, just like a thumb drive to your computer.  And all your documents are there.  You can browse them with Explorer.  You can easily drag and drop documents onto the Kindle.  Then when you pull it off and essentially disconnect it from the computer, it looks through to see what you've done and registers them and puts them on the Kindle's table of contents.  So essentially you're able, again, to do exactly with the Kindle what you can with the Sony.



LEO:  Now, the Kindle doesn't read PDF format, but you can convert the PDF to the AZW format that Kindle uses.  What do you recommend?  Have you tried that?  What do you recommend to do that?



STEVE:  There's a - gee, it's been so long now since I looked.  There's Mobipocket is the format.



LEO:  That's it, okay.



STEVE:  And the Mobi - there's a Mobipocket - last it was a version 4.something.  And that was the authoring tool, and it does a great job, and it's what Amazon uses.  And they bought Mobi at the beginning of their whole eBook move.  And so, yes, you're absolutely able to create content for the Sony.  I mean for the Kindle.



LEO:  Okay.  And it just requires downloading some software to get...



STEVE:  Yup.  But Regina's concern was that she was losing control of it for legal reasons.  And in this case at no point is it out of her control.



LEO:  We liked - we didn't pan the eBook Reader, by any means.



STEVE:  No, no, not at all.  I mean, we both had both versions of the Sony and loved it until the Kindle came out.



LEO:  And it's mostly because of the wireless, right, that we like the Kindle better.



STEVE:  Specifically because of the wireless.  I mean, for me that did it.  And in fact there was an article in this week's Economist where they were wondering whether eBooks might be the salvation of newspapers because so many people are reading newspapers now on their Kindle because of the WiFi.  I mean, the fact that you can just, I mean, well, the wireless, the cell system, that you can turn it on and get all your magazines and newspapers updated in the morning and then read them all day.  It's just spectacular.



LEO:  They keep adding - they just added The New Yorker, which was really my one true dream.



STEVE:  Oh, no kidding, I didn't know they had The New Yorker, oh.



LEO:  Yeah.  That's really - we get - we subscribe to it.  But between my wife and my daughter, I never really get a copy of it.  When Abby, you know, she's in France.  But when she was home she would just literally, as soon as it would come, she would take it upstairs, and we'd never see it again.  Which I really couldn't very well complain about.  I mean...



STEVE:  No, because she's...



LEO:  She's reading The New Yorker.  That's great, yeah.



STEVE:  Yeah. 



LEO:  But so now my wife does kind of the same thing.  But now I have my copy on my Kindle.  And I get the Atlantic on it, and Salon.



STEVE:  Yeah, I want The Economist.  The Economist is still...



LEO:  I would love it.  But, you know, the fact that The New Yorker has jumped indicates to me that others will.  You know, there was a great study.  Somebody did a little math on the costs of printing The New York Times, and estimated for this - The Times has said we have about 800,000 people who've subscribed for more than two years.  This is the dedicated group, the regular subscribers.  Somebody estimated that the cost for this 800,000 subscribers was about $600 million a year in paper, ink, and trucks.



STEVE:  Wow.



LEO:  And then figured, you know, you could give each one of them a Kindle and deliver it to the Kindle, it would cost half as much in one year.  It would cost $300 million.



STEVE:  Wow.



LEO:  Yeah.  That's the underline on this.  I mean, I prefer a paper.  But...



STEVE:  And newsprint is just gross, too.  I mean...



LEO:  I mean, I like reading it.  I like spreading it on the table and reading it.  But, you know, those times, it's just too expensive.



STEVE:  Yeah.



LEO:  Mark Smith in San Luis Obispo, California, makes some very good points about WPA WiFi security.  Our last question, Steve.  He says, Hi Steve and Leo.  I just finished Episode 182.  You guys really harped on open access points, complaining about the security or lack thereof when you don't have WPA turned on.  I would argue that every link in the path between you and whomever you're talking to - mail server, web server, IRC, whatever - is untrusted, not just the final wireless link.  If there's something you consider to be sensitive that should be protected, protect it at the application layer: SMTP over TLS, HTTPS, IMAPS, et cetera.  If you're already doing this, then the data on the wireless link is already protected.  This is kind of like our question about the VPN.



STEVE:  A little bit, yeah.



LEO:  There are other things that WPA gets you, most notably access control to your access point, for which it's very well suited.  But in many cases an open AP is precisely what you want:  a coffee shop, a visitors network in an office.  If you're correctly protecting your application layer, you shouldn't be afraid of using an open access point.  Let me know if you disagree or if I'm missing something.



STEVE:  Well, again, like I said, Mark Smith makes some very good points about WPA WiFi security.  And the only lesson here for our listeners is, once again, be aware of your situation.  For example, Starbucks, in my case, dropped their T-Mobile relationship, which ended officially at the end of the year, in favor of AT&T.  There was an overlap of about, I don't know, four or five months when they announced that they were going to be switching to AT&T service.  T-Mobile was secure.  AT&T is not.  It's wide open.  And, you know, I've been thinking, you know, I ought to just put a WiFi sniffer on and hang out at Starbucks for a few hours and just sort of see what's going on, just as a little bit of a - as a lesson to why open WiFi is a problem.  Because I bet, with all the UCI students that are there, it would be an eye-opening bit of sniffing of traffic.  And I don't know that any of them are aware that there is no encryption.  They have to log into the AT&T.  And they may think, oh, I'm logging in, I'm encrypted.  But there's no encryption being used on the radio now in Starbucks stores.  Which I think is a real problem.



Again, if people knew, that's fine.  But it's matching up the vulnerability and the environment to what it is that you're using that environment for.  And so I understand Mark's point that WPA is - obviously it's super useful for authentication because it's very strong authentication.  And open WiFi has a place, as long as the dangers are properly understood.



LEO:  Yeah, that's the key.  And I think people, as you say, people don't really.  So I use WPA for those two reasons.  One, to keep people from using my access point.



STEVE:  Right.



LEO:  And there's a real problem with that because, if your neighbor is using your access point and doing something illegal, you're liable.



STEVE:  Right.



LEO:  The ISP's going to contact you, not him.



STEVE:  Well, and we've talked about how that's something where MAC address filtering, which is available probably now on all consumer routers, MAC address filtering, if you really wanted to leave your WiFi open for some reason, MAC address filtering would prevent inadvertent use.  But it would not prevent someone deliberately saying, oh, look, I really want to use Leo's open WiFi.  And gee, he seems to be only protecting it with MAC address filtering.  So they just capture some packets out of the air and use - switch their adapter to use one of the authorized MACs.  And then they're on your network.



LEO:  Right.  And then of course the encryption, in case I forget to encrypt at the application layer.



STEVE:  Yeah.  Again, it seems to me - okay, so here's the rule.  If you have no reason not to be running WPA, run WPA.  If you have no reason not to encrypt...



LEO:  Right, why not?



STEVE:  Exactly.  Absolutely encrypt.  So I would say it's always a good thing.  It gives you authentication.  It protects your information.  You don't have to worry about whether you're running over a separate TLS, SSL, HTTPS, IMAPS, you know, blah blah blah.  That's, you know, the wireless aspect of your work is encrypted.  And we know that having the most security possible is more security than not.



LEO:  Than not.



STEVE:  And so, and again, sure, if there's an application where you can't have encryption - and maybe Mark is also reacting to the question that was asked a couple weeks ago by the guy who was having to work in an office where their WiFi was open.  So he was saying, look, I don't want to give all of them a hard time.  I just want to protect myself because I recognize somebody outside could be sniffing my traffic, and I'd rather they not.  So for him, using a VPN temporarily made sense.  And so he was in an environment where he could not use WPA security.  So I would say, if you can, by all means do it.  Aside from a little bit of inconvenience for having to give everyone the WPA key, it just makes sense to do it.



LEO:  I will give you another example of risk.  FTP, unless you're using secure FTP, SFTP, you're sending passwords in the clear.  And a lot of spy cam, you know, I used to use a program that would send a picture of me every 15 seconds to the server, and you could watch me.  Before we were doing all this.  Most of those don't use SFTP.  So you're sending every 15 seconds, you're sending the password to your server in the clear.  And in fact some of the uploading that we do is not - I do SFTP and SSH whenever I can.  But some of the servers we use, the commercial servers that we upload our podcasts to, for example, don't use SFTP.  So if I used them over an open WiFi access point, I would be - people could go in and delete podcasts and all sorts of stuff.



STEVE:  Well, yeah.  I think there's two classifications of attack.  There's opportunistic attack, and there's directed and focused.  Opportunistic would be somebody sitting with a laptop at Starbucks, sucking in all the traffic and seeing what they can collect.  And then a directed attack is somebody who decides, hey, I'm going to get Leo.  I mean, for whatever reason, I want to do that.  And so they'd arrange to sniff all the traffic on your various links, looking for that one time when, for whatever reason, somebody was doing a transfer who didn't know how to bring up an SSH tunnel first, or something like that, and they said aha, we caught some information in the clear.  Now we're going to be able to leverage that in order to go further.  So again, being as secure as you can all the time I think is what's most prudent.



LEO:  I agree.  Why not?



STEVE:  Yeah, exactly, why not?  We have the tools.  Use them.  We have NoScript.  Turn it on; turn it off when it's in your way.



LEO:  I can think of a reason not to use that.  But that's another matter entirely, for another day.  Ladies and gentlemen, thank you so much.  Steve Gibson, he's done it again, another marathon episode.  But there was a lot to talk about today.  Eat it in two bites if it's too much for you to digest in one.  You will find transcripts online at GRC.com, along with 16KB versions of this file to save bandwidth.  And of course all of Steve's great software, starting with SpinRite, the world's best disk recovery and maintenance utility, but also free stuff like ShieldsUP!, Shoot The Messenger, DCOMbobulator, Wizmo, and on and on and on.  GRC.



STEVE:  Oh, and Leo, a very cool tool coming.  The DNS benchmark I'm working on, that's where all my time has been going when I'm not on eBay.



LEO:  When is SpinRite for PDP-8 coming out?  That's what I want to know.



STEVE:  It's, yeah.  This little DNS benchmark is going to be a popular gizmo.



LEO:  Oh, neat.



STEVE:  It's just - you run it.  It sucks in a list of, well, it contains a list of all the known public DNS servers and instantly, well, very quickly profiles their performance versus all the ones that you're currently using, and ranks them with graphs and statistics and things.  Oh, it's going to be very cool.



LEO:  You probably program like some people do crossword puzzles.  It's just your recreation.



STEVE:  Yeah.  I just love it.  I mean, I just, yeah.



LEO:  That's what you do.



STEVE:  I really do, yeah.



LEO:  Always great, Steve.  Thanks so much.



STEVE:  Even ancient computers with wacky octal codes and 12 bits.  It's like, whoa.



LEO:  I can't wait till that episode.  That's one week...



STEVE:  It's going to be a great episode.



LEO:  Yeah.  That'll be a week from today, Thursday the 26th at 2:00 p.m. Pacific Time, 5:00 p.m. Eastern Time on Live.TWiT.tv.  But we will also take the audio of it and put it out as a Security Now! Special.



STEVE:  That's a perfect idea.



LEO:  Yeah.  Why not?  Why not?  Thanks everybody.  We'll see you next time on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#185

DATE:		February 26, 2009

TITLE:		Cryptographic HMACs

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-185.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the role, importance and operation of cryptographically-keyed message digest algorithms and their use to securely authenticate messages:  Hashed Messages Authentication Codes.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 185 for February 26, 2009:  HMAC.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that talks about all this security stuff, which lately has been quite a bit of security stuff.  Our host, Steve Gibson, is here.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  We have another week crammed with news.  This one will be like your original concept of Security Now!, which was less the sort of the security school that I've had for the last - or the security school that I've been holding for the last three and a half years, and more security news because we've got a whole bunch of interesting stuff to talk about that has happened in the last week, actually.



LEO:  And I don't mean to downplay security school because that's been really important to us understanding the security news, you know, having the ground of being to understand what's going on.



STEVE:  Oh, and I love the school.  And in fact one of the consistent things that I read in people's feedback - at GRC.com/feedback - is that people say "Every single week I learn something."  I mean, even IT professionals, security professionals, everybody says that you'll say something, you and Leo talking, or the content will have something I didn't know.  And so that's really valuable.



LEO:  Yeah.  I think this is, for me, anyway, it's an education.  It's college-level education in security.  But because it changes, I mean, there's some stuff that's eternal.  But there's also stuff that's changing all the time, so.



STEVE:  Well, and the show, the title of this one would be HMACs.  We're going to talk about Hashed Message Authentication Codes.  That's the last bit of technology, sort of fundamental technology that we need in order to understand, essentially to have our toolkit complete so we can then really get a grip on how SSL works.  And I was thinking of doing that week after next.  But I'm going to push it back another two weeks because of something that has happened this week that I want to give - that we'll talk about briefly, but I want to get more coverage to, I want to give it its own podcast - about the new flexibility that Microsoft has added to the Windows AutoRun, where you can, like, individually, granularly control what is allowed to run and what isn't.



LEO:  Oh.  All right, Steve.  Let's get to the voluminous security news today.  You sent me notes.  It's two pages of stuff.



STEVE:  Well, yeah.  Mostly just little - some things I wanted to quote exactly from the reference source.  And mostly things where I just needed to have the details in front of me.  So I figured, you know, mostly I wanted to give you some sense for where we were as we moved through this so that you're not saying are we done yet, are we done yet?



LEO:  Well, and it's very handy because I could put it in the wiki, which I'm doing right now.  So that if you go to Wiki.TWiT.tv, you'll get a complete list of, you know, detailed list of all the notes.  And I'm sure you put those in your show notes at GRC.com, as well.



STEVE:  So we've got security news.  We've got errata.  And my always interesting, that I try to find, fun SpinRite testimonial.



Well, first of all, for Windows users we had an interesting, out-of-band update.  Microsoft called it a "non-security security update."  And in fact in their own FAQ they even asked themselves the question, well, isn't that a contradiction in terms, to have a non-security security update?  Anyway, what they've done is, it turns out that some time ago - and I looked around, I've got the prior knowledge base number, but it's been updated since so I can't tell when the original publication date was.  But some time in the past Microsoft realized that AutoRun disabling - which is standard practice.  We've talked about it many times.  It's one of sort of the first things a guru does when they're wanting to bolt down a system, is they turn off AutoRun.  That's the feature of Windows where, if you put, for example, most commonly a CD in the CD drive, if in the root of the CD directory there's an autorun.inf file, Windows will look in there for instructions and execute code, typically also contained on the CD.



That's been a problem.  For example, this was the way that Sony installed their rootkit into Windows machines, the infamous Sony rootkit that we talked about years ago.  So in general, savvy Windows users dislike the idea that their system is going to run something without their explicit intent for that to happen.  The flipside is that neophytes, you know, people who are not all security conscious and are maybe more trusting, it's advantageous for them not to have to go dig around in the contents of a CD in order to find what it is it needs to run.  I mean, I'm often opening up the autorun.inf file manually, looking at it, seeing what it is that it wants to run, and then going and running it manually because I've told my system don't do this for me.  But that's a lot to ask typical users to do.  So again, it's a feature that Windows has.  Many people disable it. 



Well, it turns out that until this prior update was - security patch was added, it wasn't working right.  And so quoting from Microsoft's new announcement, they said, "Microsoft is announcing the availability of an update that corrects a functionality feature that can help customers in keeping their systems protected.  The update corrects an issue that prevents the NoDriveTypeAutoRun registry key from functioning as expected."  And a little bit later it says, "The updates offered in this article correctly disable the AutoRun features.  These features were not correctly disabled if you followed previously published advice.  The updates that are offered in this article have been distributed to the following systems through Windows Automatic Update," and blah blah blah.



So here's the deal.  This has now been re-released as a Windows Update fix, which it wasn't before.  Which meant that, unless users were aware of this non-Automatic Update, sort of published on the side update, their AutoRun had some holes in it.  And from poking around, it appears to have been network shares which, that is, attached network drives could have AutoRun functionality and would have, even if you thought you had turned that off.



So I want to talk about this in detail in two weeks because it turns out what they've done is they've really sort of bumped up the granularity of this so that users will be able to automatically disable AutoRun on drives of unknown type, on removable drives, on network drives, on CD-ROMs, on RAM disks, and all drives individually, which I think is very cool.  For example, I would definitely want to, in my case, and I think many users' cases, they want to just disable it across the board.  But, for example, we've talked about the removable thumb drives, where you stick them in the computer, and they contain some code that runs when you insert them.  I really dislike that.  And so, for example, it would be possible to disable that while leaving CD AutoRun enabled by using this new granularity feature.



LEO:  Does that even count for those U3 drives, as well?



STEVE:  Yes, exactly.



LEO:  That's the ones that are most scary, of course.



STEVE:  Yeah, now, they look like two different - they have two different profiles.  They have a CD profile, which is the way they get the AutoRun to function.  And then they also have a regular mass storage profile.  So again, you would be able to take control and make this thing work just exactly the way you want to.  They've added some new registry keys.  And in fact, with this update there's another key that they've created in the registry which is called HonorAutorunSetting, which is set to one by default.



And the problem is, Microsoft realized that maybe people had gotten used to the buggy way that it was working, and there ought to be a way to disable the fixed version and have it fall back to the buggy version so that the automatic update which everyone is probably going to get now, and in fact received out of cycle.  They sent it yesterday, on Tuesday, two days before the date of this podcast, the day before we're recording this today on Wednesday.  So Microsoft is concerned, since they moved this thing from you've got to go looking on Microsoft's site to get it, to auto update status, where everyone's going to get it.  Now what's going to happen is - and it does require a reset because they changed the shell32.dll, which is a fundamental intrinsic core of Windows, so you'll definitely be needing to restart your machine.  So since it's going to be an automatic update and fix the problem, suddenly behavior will change, and people might have been dependent upon the old behavior.  So Microsoft has added a feature that allows you to disable the improved, fixed behavior.



Anyway, in two weeks we're going to go over this in detail.  All people have to worry or have to think about now is that, when they update themselves, Windows will be functioning correctly, that is, the way they probably intended Windows to be running anyway.  And so what we'll be able to do is we're going to explore in two weeks how you can back off from that blanket AutoRun, if you want to allow some specific AutoRun behaviors and essentially, with a great deal of granularity, tune it so that it works exactly the way you want it to.



LEO:  That's really nice.  That's a nice update, to be able to say this, but not this.



STEVE:  Yeah, yeah.



LEO:  I mean, I know you would turn it all off.  But it's handy if you put an audio CD in, and it starts to play.  I don't think that's necessarily a security risk.



STEVE:  Or, for example, if you yourself, like, want to use the U3 drives...



LEO:  Yes, right.  I mean, some people want them; right.



STEVE:  Or you have an - you're a little bit more of a guru, and when you plug a USB in that has a program, you can create an autorun.inf file.  So you want to say, look, I don't want CDs to run by themselves, but I do want USB devices.  So it'll allow people to tune it so that it works just the way they want to.



LEO:  Frederique, our office manager, has - and I encouraged her to do this.  She has a U3 drive with a password manager on it.  She uses Roboform.  They make a version for U3 - actually they make even a version, I think, that even if you don't have U3 drive, that will autorun.  So she keeps her passwords.  They're secure.  This is why I encourage her to do this.  She plugs it into any machine that she's going to be using.  Now she has access to her passwords.  And that's a very nice, safe system for her.  That's something that's good to have.



STEVE:  Yup, exactly.  And so you would not want to disable that on a system where you would otherwise want to bolt some other parts of it down.



LEO:  Precisely, yeah.



STEVE:  Yeah.  So anyway, two weeks from now we'll go into that in painstaking detail.  I wanted to mention that some recent changes - this is sort of an obscure one, but it no doubt has an intersection with some of our listeners.  Some recent changes to v7 of my favorite UNIX, which is the FreeBSD version of UNIX, caused a new security problem in the telnet daemon.  Telnet is the remote console protocol.  I would be surprised if any Security Now! listeners had their telnet server wide open and exposed to the Internet.  That is, it's a common attack vector.  Telnet runs on port 23 by default.  And if nothing else you'd want to move it to a different port because port 23 scans have been historically quite common, and a brute-force attack on the login credentials is something that could be happening in the background with you never knowing it.



Anyway, what happened is, even without - as I understand it, even without logging in, there are some telnet-level commands that allow you to configure environment variables such as baud rate and other telnet protocol aspects, which you can imagine you need to do, like, right off the bat.  And these changes in v7 of FreeBSD introduced, unfortunately, a remote code execution exploit which would allow somebody who just found your telnet daemon exposed to cause code that they had somehow gotten onto the server through different means to be executed.  So, for example, if you also had an FTP file upload capability that allowed you to accept files, but you had been safe about not allowing them to be executed, well, this would allow that to be bypassed.



So the patches are available.  I just wanted to notify anybody, any of our listeners using FreeBSD v7, if by any chance they use telnet in a way that has any Internet-facing connectivity, you really want to fix that immediately because that's potentially bad.  And scans for telnet are common and easily implemented.



In other news, we talked two weeks ago - which was our podcast after the Patch Tuesday.  We've had another instance of what's called "Exploit Wednesday."  Patch Tuesday, of course, is Microsoft's patching Tuesday, where they issue all their updates, and we had some big ones.  We had, you may remember, a critical update to IE7.  Well, less than a week after that was released the patch was reverse-engineered, as now unfortunately often happens, and an exploit has been developed which is in the wild.



The current implementation of this is email containing a Word DOC file which itself contains an embedded ActiveX object.  So when you receive the email, if you attempt to open the Word document - and there will be some social engineering thing which will induce a nave person, a trusting person to open the attached document.  After all, aren't documents safe?  Eh, no, because they can have an embedded ActiveX object.



This one causes IE to visit a malicious site which runs a script - and there's my favorite "S" word.  And the vulnerability in IE7 is leveraged by the script to cause malware to be downloaded.  It installs a backdoor in the system which is persistent, and also sends a load of confidential information from your machine off to a server in China.  So you don't want that to happen.  I just want - I know that everyone will have updated their Windows by now.  But the problem, of course, is that corporations often deliberately delay patching their systems by policy because they want to vet them because there's been a history of Microsoft patches messing things up.



LEO:  Right, screwing everything up, yeah.



STEVE:  Yeah.  So this is bad.  And all of that, the Downadup/Conficker worm stuff, I mean, which is becoming a huge problem, this is a problem which was - this was an exploit that's been patched in Windows last October, October of '08.  And here we are toward the end of February '09.  And that demonstrates that there is a huge gap between the availability of a patch and the time that these systems really get themselves updated.  Again, I know it's not our listeners.  But it's certainly, somehow, it's people who don't have Windows Update enabled or are not restarting their machines or whatever.  One way or another, these problems are persisting.  And the fact that this Downadup worm is causing such problems for something that was fixed in October demonstrates that there is this window of opportunity.



So for that reason, patches like the one that was issued on Patch Tuesday for IE7 are being reverse-engineered and exploited.  And these guys know they've got a big window of opportunity during which they're going to be able to install this junk on people's machines.  Now, the AV guys are on top of it.  And the antivirus updates will be catching this, too, even though Windows itself should be patched to avoid the vulnerability.



Next bit of news is rather interesting.  There are two distressing bills, one in the Senate, S.436...



LEO:  I know where you're going.  Oh, boy.



STEVE:  And the other is a House Resolution, HR 1076.  And this is one of those where somebody really struggled to come up with an acronym.  They wanted to call it the Internet SAFETY Act, so SAFETY is an acronym for...



LEO:  This is the worst acronym ever.



STEVE:  I know.  Stopping Adults Facilitating Exploitation of Today's Youth, S-A-F-E-T-Y.  Stopping Adults Facilitating the Exploitation of Today's Youth.  Well, okay.  And the thing that annoys me is they're pulling the child porn card.  That's their whole justification for this is, oh, you know, we've got to protect our children.  Well, we all agree we've got to protect our children.  But get a load of how this thing is written.  Quoting from the bill, and these are identical legislation in both houses because they both have to pass it, then they go to conference, and then the President signs it - if he's asleep.  Okay.



"A provider of an electronic communication service or remote computing service shall retain for a period of at least two years all records" - okay, wait.  Before I go any further, let me say this applies to home - because I want people to listen to this wording.  This applies to everyone hearing this.  Anybody with a WiFi access point that uses DHCP that distributes IPs automatically - businesses, homes, hotspots, I mean, it's unbelievably sweeping - this affects.  That is, all of us end-users must do the following:



"A provider of an electronic communication service or remote computing service shall retain for a period of at least two years all records or other information pertaining to the identity of a user of a temporarily assigned network address the service assigns to that user.  Definition of 'electronic communication service' from the prior sentence is 'any service which provides to users thereof the ability to send or receive wire or electronic communications.'  The U.S. Justice Department's position is that any service 'that provides others with means of communicating electronically' qualifies."



LEO:  Wow.



STEVE:  So that - so literally this proposed law gets not just AT&T, Comcast, Verizon, and so forth, wired ISPs.  They're all using DHCP to give us our IP addresses at home.  But public access points, including password-protected ones.  Individuals, small businesses, large corporations, libraries, schools, universities, and government agencies.  If this law were to pass in its current form - and it's difficult for me to believe that it could because there's got to be some back push against this.



LEO:  Well, and this is not the first time they've tried something like this.  This has been going on since 2006.



STEVE:  True, there was about four years ago it was brought up.  And then so now here it is again.  It's come back again.  And essentially we've talked about the need, for example, for ISPs to log.  But the idea of requiring a chain of login, that is, not only the ISP logging that you have been given an IP, but this legislation as written requires for you to log that you have given a NAT router IP to somebody who's using your WiFi connection.  I mean, it's just, I mean, interestingly, there's a simple way around this.  And that is not to use DHCP, to assign IPs statically within - even within your WiFi network, which we know is able to be done by doing MAC address to IP association.  In that case it's not an automatic assignment, and you're no longer violating this bogus, hope this never passes, law.  But it's there.  And we'll see what happens.



LEO:  Yeah.  This is something that's been really around in conception since the mid-'90s, believe it or not, when the idea of data retention has been proposed.  And it closely mirrors a law that's already in effect in the European Union.



STEVE:  Yes.



LEO:  Now, the EU doesn't require this home stuff.  And I think if that was...



STEVE:  Let's all hook a hard drive onto our $49 router.



LEO:  It's crazy.  And as you point out, this has nothing to do with child pornography.  That's just the easy thing to say because nobody's going to say, well, I'm for child pornography.



STEVE:  It's the hook, exactly.



LEO:  This is all about - and I'm sure this is written by the movie industry and the record industry, who really want to use this to facilitate their lawsuits against people who are pirating.



STEVE:  Yeah, they just have to, I mean, again, it's conceivable that an ISP would log so that the FBI, under subpoena, could say we have criminals at this IP at this time.  We need to know who they are.  And so it's like, okay.  I mean, I can see on that scale it can make some sense.  And we know that to some degree that's being done now.  But to ask, I mean, the way this is written, to require anybody with a DHCP server, which is to say anyone with a router, even wired DHCP because that's automatic assignment - this doesn't say "wireless connections," it says "any automatically assigned IP."  Well, that's what most people use.  So it's just crazy.



LEO:  I think that whoever is writing these just is kind of clueless, to be honest with you.



STEVE:  Yeah, well...



LEO:  They're lobbyists...



STEVE:  Washington?



LEO:  Yeah, Washington.



STEVE:  Washington, are you kidding?  Clueless?



LEO:  The lobbyists come in, and they say, hey buddy, we gave you 10,000 for your campaign.  We really think this is important.  Please, you know...



STEVE:  And besides, you don't want to expose children to pornography, do you?



LEO:  Children, yeah.  Can't lose in that.  It's funny because the Democrat - the member of Congress, I think she was from Colorado, one of the few Democrats who supported this last time around is very active in children's issues.  And so I think what happens is sometimes they're fooled.  And if you don't have a technical background, you may not really understand what's at stake and the difficulty of doing this and the consequences and the privacy implications.



STEVE:  Well, and the only thing that's a concern is we would tend - we would like to have faith in the idea that a bad law cannot happen, except we have the DMCA, which demonstrates that bad laws do happen.



LEO:  So the solution is, for those of you who are listening who are in the United States, write your member of Congress.  Just make sure they understand the technical issues involved here.  You know, what they're - I don't think you have to get into DHCP.  But I think you might explain to them that, as written, this law would require every home user to keep two years of logs.  Do you really think that's a good idea?  Nudge nudge.  That's all you have to say.  I'm glad you brought this up because it's driving me crazy.



STEVE:  Just nuts.



LEO:  Yeah.



STEVE:  We have a zero-day exploit in Adobe's Acrobat Reader for which there is no patch.  And it's actively being exploited in the wild.  This was discovered in the wild, so it's an update - it's a vulnerability that Adobe is now aware of.  They've got a link on their site saying, yes, we know about this.  We're not happy about it.  As a temporary workaround, if you disable - guess what - JavaScript in Acrobat Reader, which you can do, that will be a prevention for instances of the current problem, but it doesn't really fix the underlying cause.  They have said that the most recent version of Acrobat Reader, the most recent major version, v9 is where they are, that it will not be until March 11th that they're able to get a patch out for v9 of Acrobat Reader; and another week after that, March 18th, before they're able to get versions 7 and 8 patched for those users who are still on 7 and 8 and haven't moved up to 9.



So there is an unofficial DLL that's been created by an independent researcher that replaces the acrord32.dll, the Acro Reader 32 dot DLL.  I don't recommend using non-official DLLs from anybody.  I would say disabling JavaScript sounds like a good thing to do in Acrobat Reader if you're a person who uses Acrobat Reader often.  Or maybe just be extra cautious until this update.  And we'll certainly advise everyone that there is a new version available as soon as it is available.  That's not good.



The only cool thing is that our users of Sandboxie could simply make a configuration change in Sandboxie using the forced option.  I've got, for example, Eudora and Firefox and Internet Explorer, although I don't use IE very much any longer, all tagged as forced programs.  So any attempt to run them makes them run in a sandbox.  You could simply do that to Acrobat Reader.  When you click on a PDF in your browser, it runs embedded in your browser, so it's automatically sandboxed by the browser being sandboxed, so it's contained within that container.  But if you wanted to, you could just add the Acrobat Reader executable as a forced program.  And in fact that makes a lot of sense because PDFs are now a constant source of problems.  We're hearing about security problems like this all the time.  So I would absolutely consider adding Acrobat Reader, just as a general safety measure, if you're a user of Sandboxie on Windows.  And then you're safe that way, also.



LEO:  Always Sandboxie.  It always comes back to that.



STEVE:  Oh, it's just a great tool.



LEO:  NoScript and Sandboxie, and you're safe.



STEVE:  And, Leo?



LEO:  Yes?



STEVE:  I got my Kindle 2.



LEO:  I'm jealous.  I know.



STEVE:  I got my Kindle 2.



LEO:  Mine's supposed to come any minute now.



STEVE:  It really shows every characteristic of being a second-generation device.  They've got the battery life extended.



LEO:  Now, you haven't had it long enough to really notice that, have you?



STEVE:  No.  Very good point.  So that's what they're talking about.  The buttons are very clever.  The old buttons rocked from a pivot inside toward the outside.  And that would cause the big problem of, any time you picked it up, someone would just sort of tend to squeeze the edge, and that would cause a page turn.  These buttons, as you'll see when you get yours later today, Leo. they rock toward the inside.  So the button pivot is on the edge, and you cannot push it.  It will not push if you just push on the edge.  So they've flipped that around.  And so it takes a little getting used to.  I mean, basically I was just so in love with my v1 Kindle that it became instinctual to use it.



So these buttons are very clever.  They look a lot nicer.  They're lots smaller, but still easy, when it's in your hand, to press the button.  And so you get used to it.  After a while you can sort of feel the little gap where the button meets the rest of the plastic.  And so you sort of press there, rotating the button into the Kindle, in order to actuate it.  They got rid of that wacky LCD strip and the little roller, the roller wheel that you push down, and instead you move a cursor around using a four-way, or actually five-way little joystick.  I don't like it.  It's smooth on the top, and I can't push it to the sides with my thumb.  It's too smooth.  So I have to kind of, like, get my thumb onto the side and push against one side.  I hope - that's unfortunate.  Maybe someone will come up with a little sticky cap for it or something.  It really needs that.



But the one interesting bit, I didn't expect the text-to-speech to be at all, like, useful or good.  And it actually is.  Here is my Kindle reading from the book I'm currently reading called "The Chip," which is the introduction, or the invention, of the monolithic integrated circuit.



LEO:  I just want to point out, while you're holding it up, that Andy Ihnatko said, and now that I see it...



KINDLE 2:  ...Texas Instruments.  Texas Instruments today, largely because of Jack Kilby, is a global semiconductor giant, one of the world's leading manufacturers of microelectronic devices.  In 1958, though it was just beginning to make a mark in the electronics business - the company had been born in the mid-'20s as the Geophysical Research Corporation...



LEO:  Wow.  That's completely listenable.



STEVE:  I know.  I mean, it really is.



LEO:  It's completely listenable.  Now, I just want to say something.  Hold that up again, for those who are watching at home.  Turn it around.  Andy Ihnatko said, and now that I see it I completely agree, if you flip to the other side, the metal side, he said it looks like it's an iPod designed for Andre the Giant.  And he's exactly right.  It looks like something Apple - it does look much prettier.



STEVE:  Well, and even the packaging, when you see it, it looks like, you know, very Jobsian in packaging.  They went really over the top in terms of the way they packaged the thing.  It's like, okay, this is very familiar looking.



LEO:  We're going to turn you into an audiobook listener, though; because you're right, that's pretty listenable.



STEVE:  Yeah.  I mean, you could, if you were reading, and you wanted to continue that experience while you're in the car, it works.  And in fact, one thing is really funny.  It can't say its own name very well.



LEO:  What?  What does it say?  [Attempting pronunciation]



STEVE:  It's a, well, let me go there.



LEO:  You'd think they would have fixed that.



STEVE:  Exactly.  It reminded me - do you remember the movie "Colossus:  The Forbin Project"?



LEO:  Yeah, yeah.  Loved that movie.



STEVE:  They gave Colossus a voice.  And it was interesting because there was one word that it conspicuously did not pronounce well.  And I don't remember if it was, like, human or something.  But it was like if, you know, ..."and then all humans will be able to," you know it's like, whoa, you know.  Okay, so...



LEO:  Now, the downside on this, it is still very expensive.  It's $359.  But if you travel a lot, or you carry books with you all the time, you are always going out with your books, this is such a boon.  Is it too hard to turn the page?



STEVE:  So here's - no, no.  I'll get to that in a second.  So here is the Kindle reading its own "Hello to the Kindle" book that it comes with.



KINDLE 2:  Thank you for purchasing Amazon Kindle 2.  You are reading the Welcome section of the Kindle 2 User's Guide.



STEVE:  I guess that's not bad.



LEO:  That's not bad.



KINDLE 2:  ...provides an overview of Kindle 2 and highlights of...



LEO:  It's just too - I noticed a lot of words are like that, that they're cut.  They're clipped.



STEVE:  Yes.



LEO:  It's almost they go to the next word too fast.



KINDLE 2:  ...to turn to the next page, press one of the Next Page buttons.  If your Kindle was a gift, you will need to register your device.  Please look at the Getting Started instructions that came with your Kindle for information on registering your device.



LEO:  It's swallowing the word, that's what it is.



STEVE:  Yeah, and you know, Leo, what strikes me is that the intonation is really good.  I mean, it sort of goes up and down, and it has highs and lows. I mean, they clearly gave this thing much more attention in the text-to-speech aspect of it than I expected them to.



LEO:  Yeah, yeah.



STEVE:  But no, the page turning is great.  It is dramatically faster.  They said 25 percent faster paging, turning the page.  I think it's much faster than that.  I mean, it's no longer like - I used to be, and I'm sure you were, toward the end of the last sentence of the last line on the screen I would hit the page turn, knowing that I'd be able to finish reading it before we got to the new page.  And that behavior will get washed away.  Oh, also, many things they fixed.  You can easily delete something from right there on the screen using - now that we have left and right thanks to this little joystick positioner, you're able to just push it to the left, and it says, you want to delete this?  And of course it goes off, if it's a book, it goes back to Amazon land, where your library is archived.  And if it's a periodical, it's just gone.  And their default seems to be not to keep old back issues of periodicals, which I think is a mixed blessing.  You had to use the Content Manager, which was sort of painful, in the first version in order to go in and, like, clean out all the newspapers.



LEO:  Oh, it's so hard, yeah.



STEVE:  It was really annoying.  It was slow and took a long time.  Now there's a menu option right there on the main menu to save this one.  So it knows it's a periodical.  And so you can say "Save this edition."  So my guess is that - and again, I've only had it for one day, so I haven't seen this work.  But by default it will replace the next version of The New York Times with the prior one.



LEO:  That's how it should be.  You don't want to read days-old newspapers.



STEVE:  Right.  And also that marking feature used to be really frustrating because it would only mark the page you were seeing, not the article.  Now it marks the article.



LEO:  Oh, good.



STEVE:  So it knows about that.  It knows about article boundaries, too.  So anyway, I'm very pleased with mine.  I have to say, I mean, I have such an affection for the first version, I kind of picked it up this morning after I'd been using the Kindle all morning at Starbucks, and it was like, awwww, Little Willy, I still kinda like him, you know?  He was...



LEO:  Well, what are you going to do with that?  Are you going to keep it around as a spare, or...



STEVE:  Oh, no, I've got to - absolutely going to keep it around.  I have all the packaging and the original materials.  This all goes into the master GRC archive because someday it'll - in 30 years it'll be like, oh, look at that.  Remember when we thought that was really cool?



LEO:  Yeah, yeah, yeah.



STEVE:  You know, it's when we have automatic eyeballs that are scrolling text on them or something.



LEO:  Well, knowing - see, I always gave away all my old technology.  But knowing now that both of us kind of covet the old stuff, and you're spending money on eBay buying it back, I think it's probably a good idea to keep this stuff, just for...



STEVE:  Well, and I've got to say, the fact that it is without a cover, that's a conspicuous fault, I think.  It is, I mean, it's - you want to take care of it.  You don't want to scuff up and scratch up the brushed aluminum back.  But the fact that it doesn't have any, even a cheesy cover, where you could buy a nicer one for yourself, it's like, I don't know.  I think they made a mistake there.  I've got a couple covers coming.  The neoprene one, I think, is the one I will probably like because I think - because I like holding it without anything encumbering it.  So I was always taking it out of the little book cover that they provided.  But that's where I put it back to protect it.  So anyway, I think they've made a great jump forward.  This is...



LEO:  Which case did you buy?



STEVE:  I got the neoprene one, and I got the top-of-the-line glove leather, the black leather Cole Haan.



LEO:  And which are your thoughts right now?



STEVE:  Oh, neither have come yet.



LEO:  Oh, so you haven't seen them, okay.



STEVE:  So I haven't seen it.  I'll give it to you next week.



LEO:  Good.



STEVE:  Yeah.  And I wanted to remind our live listeners that I'm going to be on Maxwell's House tomorrow, yeah, tomorrow, Thursday at 2:00 p.m. with Ray Maxwell.  We're going to do a sort of really fun walk down nostalgia memory lane, talking about our first experiences computing.  I've had a lot of revelations as I've been relearning the PDP-8 instruction set.  I've got some fun stuff to share with our listeners for that.  Unfortunately, non-live listeners - oh, wait.  We decided we're going to make a podcast of it and just slip it in as an extra Security Now! podcast.



LEO:  Yes.



STEVE:  So even our regular listeners will be able to hear it, but not live.



LEO:  You'll hear it later this week.  We're going to tape it on Thursday.  So - tape.  We're going to record it digitally on Thursday.



STEVE:  Speaking of a walk down memory lane.



LEO:  And we will post it probably Saturday or Sunday.  So this weekend you'll get an extra - just so you know, you'll get an extra Security Now!.  This is 185.  We'll number it 185A.  And just dispose of it if you're not interested.  But I have a feeling anybody who listens to this show will be very interested in this trip down memory lane.



STEVE:  Well, for people who don't know Ray, he's a tremendous wealth of knowledge and experience, and a neat guy.  And I think we're really going to have fun.



LEO:  I can't wait.  I can't wait.



STEVE:  Meanwhile, "Another Success Story" was the subject line.  William J. Burlingame sent this.  He said, "I got an SOS from my daughter this past Wednesday.  Her system wouldn't boot, and she has yet to get the backup religion.  She had the original recovery disk that came with her system; but it indicated it would restore everything to the way it was when the system was first delivered, sans critical data.  She had financial data, pictures, my grandkids' homework, et cetera, that needed to be retrieved.  I packed up my black bag and headed out to make a house call.



"I ran SpinRite in the Recover mode.  It took about an hour to complete.  Although there were two unrecoverable errors on the SpinRite map, the system booted just fine, and we were able to back up all her critical data onto an external drive.  I don't recall which version of SpinRite I first purchased.  But it was before the introduction of Windows.  My first hard drive was a 5MB that was an upgrade to my original IBM PC that came without any hard drive.  It was a full 5.25" full height drive and was quite heavy.  I enjoy the TWiT conversations with Leo."  So, William, thanks for sharing your positive SpinRite experience.



LEO:  That's great.  We just love Spin- everybody here uses SpinRite.  Colleen, you know - and by the way, Colleen is now a full-time employee.



STEVE:  Oh, yay.  I heard that you were going to do that.  That's great.



LEO:  She is - we have converted her into a - she is your best evangelist.



STEVE:  Well, we hear things like, well, SpinRite did what it did.  It fixed the drive, but there were two sectors that were unrecoverable.  Well, it's painful, I described last week or the week before why even that is a tremendous benefit because SpinRite is able to give you all but a couple bytes, even of an unrecoverable sector.  And in doing that I'm pretty sure it's unique in history.



LEO:  Yeah.



STEVE:  But I just think if, again, I recognize I'm not going to get non-owners to do preemptive use of SpinRite, even though people who once discover SpinRite then run it every, well, about every quarter, maybe four times a year, three times a year.  And in doing that, it's able to catch problems that are developing and fix them and/or cause their sectors to be swapped out before you get to this problem of something critical being unrecoverable.



So the one thing I notice that's so redundant about the email that I read, the testimonials, is that time after time it's the system wouldn't boot, the system wouldn't boot, the system wouldn't boot, because that's an all-or-nothing sort of see-your-life-passing-before-your-eyes sort of experience.  But well before the system wouldn't boot, had SpinRite been run, it would have solved the problems, I mean, preemptively, before it got to the point that it wouldn't boot.  And you'd have never had that problem, which can still cause problems.  So anyway, I recognize that we'll convert people when their system finally gets into such bad shape that it will no longer boot.  And at that point they'll be able to run SpinRite preemptively and use it as a tool that prevents them from having that problem in the future.



LEO:  Yeah.  No, Colleen's become the maintenance, SpinRite maintenance queen here.  She goes all over the place, SpinRiting things.  But it's true, as the drives get bigger, this becomes more and more important.  I mean, these drives, I mean, think of all the error correction they're already doing.



STEVE:  And because they have so much valuable information on them now.



LEO:  Right.



STEVE:  Stuff like his grandkids' homework, in this case.



LEO:  Yeah.  Geez.  All right.  HMAC.



STEVE:  Yes.



LEO:  What is it?



STEVE:  Okay.  Well, this is a final piece of sort of core component technology that we need to understand in order to be able to talk about in detail the most used security protocol of all time, which is SSL, that we all use every time we establish a secure connection with our browser to anywhere - to Gmail, to our bank, to PayPal.  Oh, speaking of which, I forgot to add to my notes.  Remember last week I talked about having found, myself having discovered a glitch in PayPal's login that allowed me to bypass the use of my security token, the football.  And I guessed then that what I was doing was more than was the minimal necessary, and I was correct.



If any time you are in eBay, which doesn't require any sort of an authentication token to log into, and you leave eBay to go to PayPal, for example to pay for something through an eBay link, you come to the PayPal login screen.  You give them your email address and password, or your first-stage login credentials.  If you own and have registered any security tokens, you will then naturally go to the next stage, which is it's asking you for your tokens.  All you have to do is hit back arrow.  You go back to the login screen.  Now the text says you're already logged in.  So the fields are grayed out that you filled in, and the button that used to say "Login" now reads "Continue."  So you click that, and you're into PayPal without having to authenticate using your security token.  Not good.



LEO:  Pardon?



STEVE:  Not good.



LEO:  What happened?



STEVE:  No, no, I mean it's not good that you don't have to...



LEO:  You woke me up, I'm sorry.  No, you know what happened?  My Kindle came.



STEVE:  No kidding.



LEO:  I just stepped out for a moment to get it.  And then I come in, and you say "Not good," and I went, what?  So that is not a good thing.  And we'll open the Kindle after the show.  I won't be distracted by opening it now.



STEVE:  Okay, well.



LEO:  It's tempting.



STEVE:  Congratulations.



LEO:  It's tempting, let me tell you.



STEVE:  The other thing that they did that I thought sort of was fun was it used to be that the Kindle would deliberately blank its screen when you turned it off.  And as we know, the screen technology absolutely doesn't require it.  It's literally - in that sense it's like an Etch-A-Sketch.  The Etch-A-Sketch, after you've scraped the light gray dust off the back and so that it's black there, it just sits there.  The Kindle's the same way.  So what I love is that the Kindle ships with a static screen of instructions about how to turn it on.



LEO:  Oh, that's clever.



STEVE:  And but then, from now on, when you turn it off, you get one of those screensaver images that they used to only put on when the Kindle would put itself into sleep mode, if you put it down.  Now it puts it up and turns the Kindle off.  So it used to be that they would blank the screen to give everyone a sort of a warm, fuzzy feeling that, okay, it's turned off now.  But now they deliberately put an image up there.  So it's cool.



LEO:  Very cool.



STEVE:  Okay.  So anyway, so I did verify the minimal approach for logging into PayPal from eBay that is a security dongle bypass.  It works every time.  And it's unfortunate because that's why you told PayPal you wanted a security dongle.



LEO:  Yeah, yeah.



STEVE:  So, whoops.



LEO:  Whoops.  Not good, as you said.



STEVE:  Not good.  Okay.  So, message authentication codes.  We've talked about basically every other aspect of security except MACs.  MACs, Message Authentication Codes, is sort of the complement to security.  That is, as we know, you encrypt a message in order to obscure what its contents are.  But sometimes you don't want to encrypt it.  Or if you do want to encrypt it to hide it, you want to detect any changes.  Now, we've often talked about message digests, MD5, which we talked about weeks ago having been weakened to the point where it's really no longer secure, SHA-1, and then other types of message digests.  Those are all hashes.



And so the traditional way, for example, of verifying the integrity of a document, whether encrypted or not, is that you would run it through one of these digest functions, which cryptographically digests the content you're feeding through, and you end up with essentially a token.  In the case of MD5 it's 128 bits.  In the case of SHA-1 it's 160 bits.  The newer, stronger, so-called SHA-2 functions, which is now what is being recommended, they're even longer.  They're, like, 256, 512, 1024, much longer.  The length gives you more security.  And their newer modern design has also enhanced their security.



So we've also talked about cryptographic signatures, where the way you sign a document is you hash it into one of these tokens that comes out of the digest function.  Then you, for example, if you wanted to sign the document you would use your secret private key to encrypt just that token rather than the entire document because, as we know, public key technology is really too compute-intensive for it to be practical to sign the whole document, or to encrypt the whole document.  And in this case you might want to sign it without encrypting it.



So you sign, that is to say, you encrypt with your secret key just the output of the hash, and append that to the document, send it to somebody.  They apply the same hash function, and that gives them that token.  Then, since they don't have your private key, by definition, your secret key, they're not able to encrypt that.  But they did receive the result of your encryption, which they're able to decrypt with your public key.



So now they've got - they've decrypted the signature that you attached.  They can compare that to the hash they independently made.  And the logic is, the only way those things will compare is if the document hasn't changed.  Well, we know because we were talking about MD5 that, if the hash function is weakened, that creates a problem.  And the problem is - and it's exactly what I just described.  If the attacker has some control over the creation of the documents - and this is still within relatively strict guidelines.  But the point is, since we're encrypting the hash's output, if we can make modifications that cause the hash to give the same output, then we're going to get a valid signature even though the documents change.  So that's a problem.



Message authentication codes, properly designed message authentication codes, don't have this problem.  And in fact, if in the case of security certificates, if they were signed using a properly designed message authentication code, then it turns out that, due to the nature of message authentication codes, they are not as dependent upon the strength of the underlying hash.  And that's really important.  For example, an HMAC could be based on MD5.  And I'll explain what an HMAC is next.  But you could base it on MD5, even in its now-weakened state, and you lose none of the integrity of what the message authentication code is authenticating, which is, not surprisingly, the message.



LEO:  Right.



STEVE:  Okay.  So cryptographic ciphers have been used in the past.  We talked last week, or sorry, week before last, about a so-called CBC MAC, a cipher block chaining MAC, where you take blocks of the text, and you encrypt it, and then you XOR the output with the next block of text and encrypt it, and XOR that with the next block of text and encrypt it, in a never-ending chain until you get all the way done.



The nice thing about that is that it's a strong fingerprint, a strong signature for the text.  However, you're using a cipher.  And traditionally, hash functions are faster in software than block cipher functions.  Also, software implementations of hash functions are freely available.  Whereas ciphers historically have been patented.  And it's only recently that those patents have expired.  So ciphers have tended to be encumbered by intellectual property, whereas hashes have not been.



And ciphers, as we know, have also historically suffered from export restrictions.  Hashes never have because hashes can't encrypt.  They can only digest.  So whereas ciphers can encrypt, and so they were unfortunately qualified as a munition, and exporting them from the U.S. and other countries had been prohibited.  So there were some benefits that hashes had over ciphers.  That is, there were reasons that you would prefer to use a hash function in order to generate a digest of a message than using a cipher.  Otherwise you could definitely use a cipher.



So some of this is sort of historical.  But the crypto guys have looked extensively at the way hash functions are used in message authentication codes.  And the idea is that you want to incorporate a key into the hash function.  Notice that when I talked about the CBC MAC, where you use a cipher block chaining, you use any symmetric cipher to encrypt a block of text and then XOR the output of that with the input of the next block in this chain.  Well, implicit there is that symmetric cipher.  So the nice thing about a CBC MAC is that it's a keyed digest, meaning that the output that you get is a function, not only of the digested content, but of the key.  Whereas, for example, MD5 and SHA-1, any of the standard hash functions, they're not keyed.  They're just MD5.  So the advantage of that is, if you were just using it as a sort of a simple message authentication, or like that a file had been modified - we talked about this in the case of websites where websites will post the MD5 and sometimes the SHA-1 of a file that you download.  The point is you're able to independently run the same function that they ran prior to posting the site on a server and verify the output.



The reason you can do that is MD5 is MD5 is MD5.  Anyone who runs something through MD5, that runs the same thing through MD5, is going to get the same output.  That's its benefit.  However, there are instances where, for example, for authenticating a message, where you want to have a secret key as part of this, that is, you want to be able to say here's the message, yet I want to prove that I signed this.  So you could generate a random number and use the random number to key a keyed hash function.  That generates an output.  Then you use your private key to encrypt that random number.



And so now you send to somebody the document and the result of the hash function.  They have the encrypted random number which was used to sign the document, to run the keyed hash function.  They're able to decrypt it using your public key.  And then, if they apply the keyed hash function using that as its key, they'll see that it matches.  The only way that's possible is if you were the person who encrypted the key using your private key, because in using your public key you're only going to get the proper result if the public and private key match.  So there's sort of another way that you can see that all of this fits together.



So the question is, how do we turn a hash function - which is inherently unkeyed, MD5 or SHA-1, they're not keyed - how do we turn them into something that takes a key?  Well, the simple-minded way to think of it, the first thing people thought was, oh, well, let's just put the key at the beginning of the message, or at the end of the message, just sort of like add the key to the message.  Since we know that any change to the hash function will result in a different output, if we put the key at the front of the message, then every time we change the key we're going to get a different hashed output.  It turns out that, unfortunately, the nature of hash functions makes that insecure.  The crypto guys in analyzing this said, eh, that's not such a good idea.  And then people said, okay - and the reason is, we've seen that one of the main ways of exploiting hash functions is by altering them in a way that changes their length but not their outcome.  That's exactly what we saw in this case of the attack on MD5, with the chosen prefix in an MD5 hash.



So then people said, because they understood that length was the problem, okay, let's put the key and the length and then the message, glom them all together, and digest that.  It turns out that the crypto guys, in analyzing this to death, said nah, that's not good either because there's ways you can exploit that.  And then they said, okay, how about if we put the key at each end?  And it's like, well, okay, that's better.  But we have something that would really work because in pounding on this the crypto guys saw what it was, like what advantage they had.  And the advantage they had is they were able to see the output of the hash function.  They were able to tell what it was.  And that gave them the leverage that they needed against the hashing function in order to make this work.  So it turns out that, if you hash it twice, with a couple tricks, that's the key.  So specifically, this thing called an HMAC is now a formal standard because it's passed through all the crypto analysis.  No one's found any sort of a problem with it.



So here's what you do.  I talked about, when we were talking about hash functions in depth, the idea that a hash function - this was when we were talking about MD5 - a hash function tends to process its input in blocks that are larger than its resultant hash.  That is, for example, both MD5 and SHA-1 take 512-bit blocks.  They take the digest 512 bits at a time and then run that through their algorithm.  And every time through their algorithm it sort of gives them another state.  And then they take that state, sort of like how far they've processed so far, and then they take the next 512 bits and that state and run that through the algorithm and get another state, an intermediate state.  So the final result is 128 bits, or 160 bits, however long the hash function digest output is.



So to securely key any hash function, you take the key and pad its length out using a specific pattern of bits.  What's been chosen for the first hash is hex 36.  So you take - essentially you take hex 36 repeated out 512 bits, and you XOR the key with that.  So what that does is it's sort of a - it gives the hash a good start for the first 512-bit block.  You then process that, and then continue to process the rest of the message.  So essentially what this does is it takes the key you're giving it, and this magic 36 hex that tends to flip some of the bits of the key because we know that that's what XORing does.  And when you run the first cycle of the hash function, it initializes it to, after processing this 512-bit block, to a strong state based on the key.  Then you just run the regular hash over the rest of the content.



Okay.  You take that output, and you do the same thing.  You take its output, and you take the same key.  This time you XOR it with hex 5 Charlie, 5C.  I'll talk about where those two values came from in a second.  So you do the same thing.  You take 512 bits' worth of 5C in hex.  You XOR the key with that, and initialize the hash function using that.  Then you simply hash the result from the first hash.  So you've essentially nested hashes.  You're hashing the output of the inner hash.  That's your final MAC, the Message Authentication Code.  And it has passed all crypto.  I mean, people have pounded on it.  They cannot find a weakness.  They recognize why.  Because of doing such weakness analysis on hash functions, they realize that getting the result of the first hash is the key.  Well, by masking that with a second hash, making that first hash be essentially an intermediate value, they have no access then to what is really going on, and nobody's been able to break it.  And it is so strong that even a weak hash like MD5, where we've learned all this about it, it doesn't weaken the output of this at all.



LEO:  Cool.



STEVE:  And so that gives us a keyed message authentication code.  It is used in SSL.  It is very handy for communications.  And I'll be using it myself in my forthcoming CryptoLink product because a keyed MAC is a very strong way, much stronger even than, as we saw, signing the output of a non-keyed hash, which is where the vulnerability in the SSL certificates was created because they were just using MD5.



LEO:  Now, when I use OpenPGP - and I use it all the time for authenticating messages, verifying messages, not for encryption - it puts a hash string at the bottom. Is that an HMAC?



STEVE:  I don't know.  I've not looked at PGP enough to look at the protocol...



LEO:  I would guess it is.  I mean, what it's doing is it's doing two things.  It's verifying the sender using the sender's public key, but also verifying the message content's integrity.  So it must be hashing the message; right?



STEVE:  Well, yeah. But again, just a standard digest, an MD5 would do that.



LEO:  That would be sufficient, yeah.



STEVE:  My guess is that they're using an HMAC, a keyed MAC, and they're keying it based on your private key.  But I don't know.



LEO:  Private key, not public key; right, yeah, yeah.



STEVE:  Right.  We will be looking at SSL in detail, and it sounds like looking at PGP would be a good thing, too.



LEO:  Yeah.  This is - I'm using OpenPGP, but I think it uses the same standards as PGP.  And then there's GNU Privacy Guard, which is...



STEVE:  GPG.



LEO:  GPG.  And that's what I use to implement OpenPGP, as confusing as that is.



STEVE:  Well, if anybody's still with us, given where we've just gone, I think that was easy compared to understanding the nature of keyed message digests.  But these are super useful, very strong, and they are the final component that we hadn't talked about, that we needed to sort of lay down in order to understand, to look at the SSL protocol, what is it that goes on every day when people hook up their web browser to a server remotely?  How are they safe?  How do they know they're safe?



LEO:  Right.



STEVE:  We've talked about the certificate side.  We haven't talked about the actual communications protocol side.  And we're going to do that in a few weeks.



LEO:  Very cool.  As always, Steve Gibson, fascinating material.  And if you put together this with the last few sessions that we've done on crypto, you have a very strong basis in modern crypto techniques, which is great.



STEVE:  That's what we do here.



LEO:  That's what we do here.  And a little bit of news thrown in.



STEVE:  All kinds of interesting...



LEO:  Little bit of news thrown in.



STEVE:  And a little eBook...



LEO:  And I've been very good.  Lookit, still sealed.



STEVE:  Ah.



LEO:  You know, it's kind of cute.  I actually got two boxes, and I didn't know which one was the Kindle.  But I figured out this is the Kindle because down the side it says "Once upon a time."



STEVE:  Oh, I know.



LEO:  So you're right.  This is the Apple-style packaging inside here, I think.



STEVE:  And I tried to open the box without breaking the little zipper because I thought, you know, I wanted to keep it in, like, really pristine condition.



LEO:  Right.



STEVE:  But they'd glued it all down tight.  So you've got to pull the zipper in order to do that.  So it's like, eh, that's okay.



LEO:  I did get my Patagonia case.  This is the neoprene case.



STEVE:  Oh, good.



LEO:  Yeah, but this, I don't know if this has the hooks.  Because, right, the new Kindle has hooks that go in the leather case.  But this one looks like it's got a pouch.  I can't - well, I'll know...



STEVE:  That's what I was - actually that's what I was expecting.  I think those zipper cases are just - they're just a case you slide it into.  The ones that have, like, a foldable lid, a flap, like a wallet, those have...



LEO:  Those have hooks here.



STEVE:  ...elastic corners.



LEO:  Well, this has elastic corners.  This has elastic corners.



STEVE:  Oh, it does.



LEO:  Yeah.  So that's the mechanism?  Because I also thought there were now - there was some sort of hooking mechanism now on it.



STEVE:  Nope.  They pulled the buttons away from the edges so that your - so that all the corners are now available for tying it down.



LEO:  This is nicely padded and has a little handle.  I think this will be fine.



STEVE:  Neat.



LEO:  Yeah.  But I will be very interested in your lovely leather Cole Haan case, as well.



STEVE:  Well, I'll show it to you next week when we talk.  We'll do a Q&A next week.  And then the week after we're going to talk in detail about - given that nothing else really horrible or significant comes up.  We always reserve the right to change horses here if something happens.  We're going to talk about tuning Windows AutoRun so that you are able to run just exactly what you want and not anything else.



LEO:  That's very useful.  That's a great one to do.  We should mix the really hard academic math stuff, like this, like today's, with useful pragmatic stuff.  That's great to have a little bit of each.



STEVE:  I think so, too.



LEO:  And that's what the Q&A is great for.  We cover everything.  If you've got a question for Steve you'd like to send along for next week's question-and-answer session, go to GRC.com/feedback.  And there's a feedback form there, and you can submit a question.  GRC is his site, the Gibson Research Corporation.  That's where you find SpinRite.  It's where you'll find all those great free tools like ShieldsUP! and Wizmo and Shoot The Messenger and DCOMbobulator, Unplug N' Pray, I can go on and on and on, all the free stuff he's writing.  That's where the new crypto product will be.  Perfect Paper Passwords is there.  Also, oh, don't forget, I kind of remind people, we were talking on the radio show about WPA passwords.  I sent people to GRC.com/passwords, and you can get that great 64-character uncrackable WPA password.  And a new one every time you visit.



STEVE:  You have Windows machines running there; right?



LEO:  Lots of them.



STEVE:  Okay.  Because I've got to say, Leo, this DNS benchmark utility that I'm working on, it's going to be really significant.  It's looking like there are a lot of publicly available free DNS servers that are a lot faster than ISP servers.



LEO:  Good.



STEVE:  And this thing knows about them all.  So you just run it from your machine, and it tests all of the known publicly available DNS servers' performance against all the ones you're using from your ISP, shows you it, ranks them, and says, you know, you switch your DNS to this, and you're going to get this much more speed.



LEO:  Fantastic.



STEVE:  It's really going to be very cool.



LEO:  Fantastic.  We'll give it a big plug.  Don't forget, now, if you're listening to this show - I hope you listened as soon as it came out.  We're going to put it out a little bit early on Thursday to give you a little heads-up that at 5:00 p.m. Eastern, 2:00 p.m. Pacific, Steve will join Ray Maxwell on our show Maxwell's House at Live.TWiT.tv to talk about the old days of computing, the old days of programming, PDP-8 and more.  That should be a lot of fun.



STEVE:  And Leo, when every bit mattered.



LEO:  Those were the days, when you had to really program bare to the metal, and you had to pay attention in memory and things like that.  That was when men were men, and programmers were programmers and strode the earth.  And anyway, it'll be fun.  2:00 p.m. Pacific, 5:00 p.m. Eastern on Thursday, February 26.  If you missed it, don't worry because Episode 185A is the entire audio of that show.  So you'll be able to hear that, and we'll put that out on Saturday the 27th.  Or 28th, I guess that is.



Steve, great to talk to you.  Oh, have I left anything out?  Yes, transcripts available, GRC.com.  Also 16KB versions of this show.  We now have the great wiki.  The show notes are in there, too, at Wiki.TWiT.tv.  That's another great resource with links back to Steve's site.  So we really wanted to make sure there was a lot of text-based support for all this because, you know, it's not enough just to listen.  You've got to read, too.  Thank you, Steve.



STEVE:  Thanks, Leo.  Always a pleasure.



LEO:  See you next time on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#186

DATE:		March 5, 2009

TITLE:		Listener Feedback #61

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-186.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 186 for March 5, 2009:  Listener Feedback #61.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now! with Steve Gibson, the show where we cover all things secure - privacy, online theft, that kind of thing.  Steve is a real expert in the subject.  Partly by force.  I think some of your interest in security began when you were being attacked.



STEVE GIBSON:  It started off defensively.  So, yeah.



LEO:  And of course you found spyware on your system, were the first to coin the phrase "spyware" and write the first antispyware program.  You handed that off to pros.  And I'm sure you're glad.  That's a never-ending job.



STEVE:  Oh, boy, yes.  It was becoming very clear quickly that this would, I mean, it would be a full-time job.  And much as I think spyware is important, it's just sort of not my nature to go running around chasing after these weenies and try to figure out what's going on.  I much prefer sort of the raw technology, let's do something new, than that.  So the guys at Lavasoft sort of picked up the mantle and have done a good job with Ad-Aware.



LEO:  Ad-Aware, Spybot, and now of course everybody.  You know, it's funny, I think for a long time antivirus companies were reluctant to say we will also fight spyware because they didn't - they thought, well, maybe this is commercial speech.  It's not exactly a virus.  I think there's now no question.



STEVE:  Well, yeah.  Remember, too, that early on there was, like, Conducent and Aureate were two commercial companies that were installing this junk in people's machines that really infuriated people, yet they were not rogue malicious hackers.  They were companies that someone had mistakenly given some venture capital to.  So, yeah.



LEO:  Right, right.  Let's see here.  We have...



STEVE:  We've got #186 for Q&A #61.



LEO:  Questions.  You've got questions; Steve's got answers.  And some of them are about our great special that we did.  I hope everybody enjoyed Gray-Haired Computing.



STEVE:  Oh, I got a lot of feedback about that.  I included just a couple little things.  We have a really interesting note from - that I think people are going to find fascinating from the Chief Technology Officer of PKWARE.



LEO:  Oh, you're kidding.



STEVE:  ...who heard me talking about - who listens to Security Now! and heard me talking about ZIP encryption.  So we get the whole story on that.



LEO:  PKWARE.  There's a legendary name in computing.  Wow.



STEVE:  Well, and it was Phil Katz of PKWARE.



LEO:  Phil Katz.



STEVE:  Phil Katz is PK.  That's where that comes from.  And he invented the ZIP file format.  That was his.



LEO:  Oh, that's fun.  Steve Gibson, any news in the security world?



STEVE:  Unfortunately, we do have news.



LEO:  I was afraid of that.



STEVE:  Yeah.  We haven't had a bad Excel exploit for a while.  So I guess maybe one was due.  We have a new zero-day Excel remote code execution exploit which has been found in the wild.  Anyone who has Office installed who opens one of these malicious email attachments that contains an Excel spreadsheet, even though it might be labeled something differently, I mean, so you get a link in the mail, in your email, it could have a name that makes it look like it's not an Excel spreadsheet because someone might be thinking, wait a minute, why is Aunt Mary sending me an Excel spreadsheet?  But it ends up triggering Excel and makes a remote code exploit possible.



LEO:  This is cross-platform, too, by the way, this...



STEVE:  Yes, I was going to say it's Office 2000, 2002, 2003, and 2007 on Windows.  And over on the Mac side it's both Office 2004 and 2008.  So this is clearly code which has been in Excel for quite a long time, and somebody finally found a way of glitching it and leveraging that to be able to get code to run on your machine.  So right now Microsoft has acknowledged it.  They've got their article, it's 968272, which says they know about this.  And I'm sure that, I mean, I imagine that the second Tuesday of next month we will see a patch for this because they're saying it's only being used in targeted instances, which is to say, you know, when someone wants to get a certain executive, they'll send them email hoping to be able to take over their machine because that's the way these things always start.  And before you know it they'll be spamming people en masse, trying to get this to happen.



And then Adobe has a couple problems.  We mentioned a known problem that was not going to be patched until March 11 for version 9 of Acrobat, and a week later, March 18, for the earlier versions.  Exploits are now in the wild, so this is now being actively exploited, as we expected it would be.  So I just wanted to give people a heads-up that about a week from now, on March 11, you'll be able to get an update for Acrobat.  And if you're an avid Acrobat user that's something you want to consider, certainly want to consider doing.  And we'd also talked about last week the idea of putting it inside of Sandboxie, causing Acrobat to run in a sandbox.  And if you open PDFs from your browser, and you've sandboxed the browser, then Acrobat is sandboxed by being part of the browser's sandbox.  So I just wanted to caution people this is out there in the wild, and it's going to take a few weeks for Adobe to catch up.



Meanwhile there are some new problems with Flash.  Adobe's Flash Player has multiple known problems - denial of service, information disclosure, clickjacking attacks, and remote code execution, a whole bunch of things.  For this, however, there is an update.  And my system notified me a couple days ago that there was a new version of Flash available.  So anything that is over on Windows and Mac is 10.0.12.36 and earlier are troublesome.  And over on Linux 10.0.15.3 and earlier are troublesome.  And so what you need is just go to Adobe's site, or see if you can update your Flash Player, and also your player that's embedded in your browser, if you've got a Flash embedded there.  You want 10.0.22.87.  Or if you're still back on version 9 of Flash, you want 9.0.159.0 in order to get the Flash Player that's been patched to fix these multiple problems.



And the last little blurb I have is just to note that Facebook and MySpace are becoming a larger battleground for various types of exploits.  They have, naturally, sophisticated APIs that are allowing these widgets to be created.  And as unfortunately happens when we add complexity in technology, we inadvertently create opportunities and doorways for various kinds of exploits.  So there are now - there's a worm that has sort of resurfaced called the Koobface worm, K-o-o-b-f-a-c-e, which is now back and active over in Facebook.  It takes advantage of the whole social networking mode to send a note to people you know saying that you want them to see something, so click this link to go to on YouTube to see this funny video you've found.  Well, that link, which you don't send, this worm that you've unfortunately acquired by doing this yourself, it sends them to a fake YouTube site that takes advantage of known problems in client systems to install malware and essentially to put a backdoor trojan on all the machines it infects.  And it's spreading widely.



So it's the same story that we've run across before, is we get a new environment.  Obviously Facebook and MySpace have been attracting a lot of people who are less computer and security savvy than they might otherwise be.  They get this kind of a note from someone they know, and they go, oh, look, I want to see the funny video.  And certainly it's not the first time they've received something like that.  So it's another problem just to be aware of.  And if you know people who are less security aware, you might mention that this kind of thing is happening on Facebook and MySpace and to be very circumspect, even if and when these things come from people they know.  If it's in any way different from what they expect, they should be careful about it.



LEO:  I've had this happen many times, or something similar happen many times, I think it was Koobface, on my Facebook.  And what happens is sometimes people's sites, Facebooks get hacked.  And so you get a message, as you said, you get a message from somebody you know, and it just has a link in it.  And it looks completely...



STEVE:  Yup, generic.



LEO:  ...generic and sensible.  It doesn't look like something odd, necessarily.  And so you're very tempted, because you feel like you're in a safe space, to click that link.



STEVE:  Yup.



LEO:  Do you get infected the minute you click it?



STEVE:  Yes, well, you click it, and you go to a fake site, a fake YouTube site.



LEO:  Oh, then they ask for the login.  Or no.  Oh, I know what it is.  You download - you have to download a new player, an upgrade...



STEVE:  That's exactly what it is.  Yes, it says, oh, you need to update your player in order to play this video.  That's exactly what it is, yes.



LEO:  Yeah, yeah, yeah, yeah.  And then of course - see, this is a problem.



STEVE:  It's not a new player you're downloading.



LEO:  Yeah, it's a bad guy.



STEVE:  It's definitely bad stuff.



LEO:  Yeah, that's nasty.  I've seen that's been going on for a while.  It's happened to me several times.  And what I'll do is I'll immediately send a note to that person saying your site has been hacked.  You need to change your password.  Somebody's putting out messages on your...



STEVE:  On your account.



LEO:  ...under your name, and you should also tell everybody don't click that link because it's a bad link.



STEVE:  Right.



LEO:  Well, we've put the word out.



STEVE:  Okay.  A couple last little bits of errata.  I did want to mention, I was listening to you talking about the issue that I have with the Kindle 2, and that is the non-replaceability of its battery.  And I did want to mention that both of my prior Kindle 1s, during the year and a half I had them, had noticeably reduced battery life.  And that unfortunately - and this goes, I mean, this is pertinent not to just Kindle users, but laptop users and iPod users and all kinds of users.  Lithium ion technology not only has a cycle-life limitation, but just a shelf-life limitation of a few years.  That is, even if you were an infrequent user of your Kindle, you would find that the battery itself ages, even when it's not being continually cycled.  And after a few years, you'll see a reduced battery life.



So I'm really not happy that the Kindle 2 has switched over to this non-replaceable battery.  Although you've got to wonder what the battery looks like in there because the Kindle 2 is so thin, it's clearly not something you're able to get off the shelf.  So, but it's unfortunate that they chose for whatever reason not to do what they did before, which was allow it to be opened somehow, and for the user to be able to replace the battery.  I was going to let mine get really bad and then, you know, like, just to see how bad it got.  But it was both of them, because remember I dropped mine on the edge from about two feet, I mean, a little gentle drop on the carpet, and I was surprised that it completely whacked out the display.  Amazon was wonderful about replacing it for me.  But I remember even then that that first one's battery life was clearly shortened by just my regular usage at that point, after less than a year.  And the second one was following the same path.  So I'm a little worried.  And I haven't yet brought my battery all the way down.  But it's looking to me like this battery life is not as much longer as they touted for the Kindle 2.  Have you...



LEO:  Not at all.  I was very disappointed with it.  It's, you know, they said 25 percent greater?  No. 



STEVE:  No, I think it's...



LEO:  I've depleted it in a night or two.



STEVE:  Yeah.  And is that without using any text-to-speech?



LEO:  Without text-to-speech, without any audio playback.  I left the radio on, but you're kind of tempted to do so because it's a software switch, not a hardware switch.



STEVE:  Right, so it's a little less obvious when it's on.  I have also discovered that it was on when I am not using it.



LEO:  Well, and I leave it on because I subscribe to daily stuff.  So...



STEVE:  Yeah, I mean, and that's another thing, too.  I was hoping that when they put it under software control, they would give you an option of, like, have it...



LEO:  Schedule.



STEVE:  Yes, exactly.



LEO:  Good idea.



STEVE:  Have it wake up at - it know what time it is, presumably.  Have it wake up and check for anything new and then immediately go back to sleep.  That way, you know - and if it only did it - it doesn't even have to know what time it is.  If it did it hourly, that would be fine.  Or you choose how often.



LEO:  Like a day, yeah.  You know what, that's brilliant.  And I bet you they'll do that in firmware because they haven't improved the battery life.  It's a little disappointing.



STEVE:  No, I think not.  And in fact my guess is that one of the reasons the page turn is faster, and image display - remember how long the first Kindle took, if you were switching to a page that had, like that was much more complex or had an image, it would kind of [groaning], I mean, it really struggled.  It doesn't do that now.  So my guess is they've juiced up the processor in order to get the next page up on the screen at the cost of some battery life.



And then someone somewhere posted some - I don't remember now where it was.  But I made a note of it here to just mention that it's unfortunate that the Kindle didn't incorporate WiFi because had it, it could be international, if they wanted it to be.  I mean, they argue...



LEO:  Oh, good point.



STEVE:  It's only - it's the EVDO Sprint connection that is sort of locking it to domestic.  Yet there's obviously a huge international interest in this.  And had they given it WiFi, then although you wouldn't have the really cool cellular connectivity, you'd have Internet connectivity which would have allowed them to do the whole content management.



LEO:  Oh, that's a very good point, yeah.



STEVE:  And then finally, several weeks ago I fumbled around, trying to come up with an explanation for hysteresis.  And it's been bugging me ever since that I...



LEO:  [Laughing]  It all started because I read a definition out of an antique radio/television dictionary that Dane got for me.



STEVE:  And I thought of a perfect clear example.  I was discussing keyboards with a friend of mine, and I realized that the snap of a key switch, when you press a button and it snaps, that's a perfect example of hysteresis.



LEO:  Oh, really.



STEVE:  Because it's a nonlinear response.  If you just had a spring where, as you increased the force on the spring, it goes down in proportion to the force, and then smoothly.  And then as you bring the force back off, again you get displacement that is a direct proportion to the force, which is typical spring action.  That's zero hysteresis.  But if instead, like any keyboard that's got - not the mushy keyboards that have no hysteresis.  But anything with a snap in it, when you reach a certain point suddenly something happens, that snap action is a - you've crossed a threshold.  Suddenly the force required drops, and the key moves in.  Now, even if you come back off to the same point where that snap occurred, the key stays down until you go much further back, where you've got the same sort of nonlinear event on the way back.  And it's the separation of those two, the snap where it occurs down stroke, and the snap where it occurs up stroke.  They're at different locations, and that gives you - if you were to plot force versus position, you would end up with not a straight line, not even a curved line.  You actually end up with a loop because the force and position curve is different on the way back than it is on the way down.  And that gives you a loop.  And that's the characteristic hysteresis curve.



LEO:  That's an excellent and accessible definition.  Much better than the one in the book.



STEVE:  Or whatever I fumbled with.  I don't remember what it was a couple weeks ago.  It's just, oh, I thought afterwards, oh, that really clarified everything for everybody.



LEO:  It's a hard thing to come up with an accessible definition of some of the abstract concepts that we deal with in computer science.



STEVE:  Well, and my problem is verbal.  I mean, I could absolutely draw a diagram and wave my hands around.  But the bulk of our listeners are...



LEO:  Listening.



STEVE:  ...listeners.  And so...



LEO:  And that's my skill.  I think if I have one skill it's that I can sometimes, not always, come up with a good analogy that makes this stuff make sense.  But not always.  I remember the time I was using sliced cheese to describe how audio is sampled.  That didn't work so well.



STEVE:  Okay.



LEO:  Not a recommendation [laughing].  So you try.



STEVE:  And on that note I will share a very short SpinRite comment.



LEO:  Okay.



STEVE:  From Germany, a listener in Germany, Arne Klawitter.  He just said, "Thank you/SpinRite."  He said, "Just wanted to say THANKS" - all caps - "for recovering 32 gigs of data when nothing else helped.  I tried so many other programs unsuccessfully.  SpinRite really convinced me.  And additionally, it is so easy and intuitive to use."  That's because he's German, sort of has that strange interface.



LEO:  It makes sense to me.



STEVE:  "So intuitive to use, great product."  And then he signed it.  So I just wanted to thank him for sharing his short, positive experience.



LEO:  It makes sense to me, and I'm not German.  It makes perfect - it's very clean and very simple.  It's just the way, you know, it's the last DOS program I still use, I think.  Now, ladies and gentlemen, without further fanfare or adieu - ado, not adieu, ado.  Without doing no more, I'm going to read you our first question.  Ladies and gentlemen, this comes to you from Listener Mike, with a cool retro-PC tip.  He says:  Hi, Steve.  As you may have gone into retro mode in regard to old PC hardware - I guess this is another guy who heard our last episode, the Gray-Haired Computing episode - I just wanted to give you a tip in regard to the Retr0bright Project.  Do you know about the Retr0bright Project?  I haven't heard of this.



STEVE:  I do now.



LEO:  It's Retr0bright with a zero, not an "o," Retr0bright.wikispaces.com.  Or you can just Google Retr0bright with a zero.  They offer a cool, as in cheap or free, solution to the annoying yellow color old PC equipment tends to get.  Nice.  Yeah, every one of my old beige boxes is now yellowed.



STEVE:  Yeah.  And in fact it's distressing when you see what used to be a nice, like even a gray color will turn really this sort of gross dark orange-yellow color.  What happened was, first of all I wanted to acknowledge that this mention by Mike is the first one I encountered.  But as I was scanning through our mailbag I ran across, like, four or five other people.  So I wanted to acknowledge them, too.  Many people who knew that I was digging around back in nostalgia and old machines sent this news of this Retr0bright.  And on the site they show some before and after shots.  And it is phenomenal what this does.  What happened was some chemical engineers got together, thanks to the Internet, and actually figured out what it was about the plastic that was causing it to yellow.  Turns out it's the fire retardant chemistry which is mixed in, which is one of the reasons why monitors are among the worst yellowers of all.



LEO:  In a few years they turn yellow.



STEVE:  Yeah.  And so they've come up with a formula which, interestingly enough, UV is one of the things that causes the monitors to yellow.  You may have noticed, like if your monitor is in a window, one side of it is, like, much yellower, the window-facing side, than the other.  It's because of the UV that ends up - although I think glass really attenuates UV.  But still there does seem to be some photo-based effect.  Anyway, they use this formula with UV.  One example was it was done in Arizona, and someone in the UK did it with a UV light in order to get enough UV.  But it really returns the plastic to its original look, like a light grey where it had become dark yellow.  They show a Commodore keyboard sort of before and after.  And they've got both a low viscosity liquid and a gel to make it easier to apply this stuff.  So I just wanted to share it with our listeners and to thank the other people who also mentioned it because I thought that was very cool.  It does bring that - it takes that antique look off, which some cases you really want off because keyboards and computers and monitors really get kind of gross-looking over time.



LEO:  Oh, yeah.  And if you're going to collect this old stuff, you're really going to want to make the difference.  That's really, really neat.  Retr0bright.  Question 2, Chad Young in Ann Arbor, Michigan.  He mentions an Apple solution for WiFi guests:  Apple recently added a guest networking feature - boy, that's smart - to their AirPort Extreme and Time Capsule devices.  This appears to be based on their dual band technology wherein they utilize two individual radios in each device.  That's MIMO.  I think all MIMOs do that.



STEVE:  I was just going to say, that's entirely separate from the guest networking; right.



LEO:  Oh,  okay.  I remember this being discussed in a past episode; I thought I'd pass it along.  So what are - do you know what they're doing?



STEVE:  Yes.  What Apple has done, they've really done it the right way.  I wanted to bring this up because I don't think we've ever really talked about this notion of guest networking, although some router manufacturers over on the - like D-Link and Linksys and so forth have begun to offer such a feature; however, not always in the right way.  Apple has done it exactly right.  I don't want to say "as you'd expect."  But I do think that Apple often does things right.  And that is, they have, I mean, if you and I and our listeners were to design this, it's what we would end up with, which is it is an entirely separate configurable page for the AirPort Extreme and the Time Capsule where you give it its own SSID, its own crypto key, and similar configuration.  And anyone who connects has no access to the LAN.  They only have access out to the Internet.  So it is, I mean, it's exactly what you would like if someone comes over and they need to use your WiFi.  You could give it, you know, still use WPA2, maybe give it a long but simple-to-enter password because you're not going to use it, and anyone who does has no access to your network.  They only have access to the Internet.  I mean, it's beautiful.  It's what you want.



LEO:  Great way to do it.  Now, we use - we have a wired router.  Everybody's on the wired router.  And then from that wired router we have a WiFi router for our guests.  Is there a way to do something like that with a multi-router setup?



STEVE:  Well...



LEO:  Or would we have to do that three-way router thing that we talked about?



STEVE:  You really need to do the three-way router.  Otherwise you do - so in what you just explained, where you have your WiFi inside of another router, well, it also has access to the network upstream of it, which is your LAN.



LEO:  Right.



STEVE:  So you really need to do a three-router configuration in order to really create isolation which is enforceable in the face of any kind of spoofing attacks.  But the point I wanted to make about this is that don't assume that guest networking is always done the way Apple did it, which is correct.  There are some guest networking features that you're really going to want to test out before you trust them.  For example, some don't block access to the LAN.  Some don't allow encryption at all, instead of having separate encryption.  So there are guest networking features that are just lame.  I mean, they're really - it's unfortunate they didn't do more.  They just sort of said, oh, we're going to add that feature so we have a bullet-point on our box.  So you really - your mileage may vary.  I wanted to note to people that when they upgrade their firmware they may find that feature beginning to appear in later firmware.  But absolutely check it out and make sure that, when you log in that way, understand what the criteria are because it may not be something that you want to use, certainly not something you want to leave on all the time.  Whereas with Apple's configuration you could absolutely set up basically a parallel WiFi environment that anyone can use where they don't get access to the rest of your internal LAN and other machines, only get access to the 'Net, which is just beautiful.  It's the way it should be.



LEO:  That's excellent.  That's really, yeah, that is very bright.  I guess we'll have to just get - the easiest thing to do is get an AirPort Extreme.



STEVE:  I'm actually considering that myself, Leo.



LEO:  They're not cheap.



STEVE:  Why not?  It's just a beautiful solution.



LEO:  Yeah.  I wish they were less expensive.  Gary S. Martin in Tehachapi, California shares a "gray-haired memory."  Are you gray-haired?  I can't tell.



STEVE:  Oh, yeah.



LEO:  I'm gray.



STEVE:  Oh, it's gray.  It went gray, I don't know when that was, but it sort of snuck up on me.  I've looked at some pictures that aren't that old, it's like, hey, it wasn't gray then.  But sure is now.



LEO:  I sure would love to do another one of those specials with Ray Maxwell.



STEVE:  Well, and I have to say, Leo, we got a phenomenally positive response, much more than I expected.  And interestingly, they were really of two classes.  There was the nostalgic response, which Gary's going to share with us here in a second.  But then there was also, like, the 20-something response, from people who never had an experience before Windows 98.  And it's like they don't remember any of this stuff.  So it was really fascinating to our younger listeners for much the same reason.  Or, I mean, for an entirely different reason, which is, wow, core?  What's core?



LEO:  What's that?



STEVE:  Yeah. 



LEO:  Oh, the good old days.  Well, Gary says:  Your special Gray-Haired Computing episode brought back a lot of memories.  The first computer I ever saw in person was a PDP-8 at Cabrillo High School, Lompoc, California.  I was there for a chess meet.  A nerd after my own heart.  And it was in their computer lab.  They had a Lunar Lander game.  Oh,  yeah, I remember this.  They loaded it from paper tape.  It displayed vertical velocity and altitude on the front  panel lights.  You used a front panel toggle switch to turn on the main engine at the right time to make the vertical velocity go to zero at zero altitude.  I believe that it printed fuel, speed, and altitude to the teletype - it did, I remember this - as the game ran.  It was the first computer game I ever played.  And what a waste of paper.



STEVE:  Well, and you know, it's interesting because I'm planning to do a set of little, short, easy-to-enter programs for the PDP-8.  You know, I call them "toggle toys."  And Gary's note made me realize, that's a perfect, a perfect example.  For some weird reason I've always loved the Lunar Lander game because it's very simple, yet it's very tricky.



LEO:  Yeah.



STEVE:  You turn the thrust of your little spaceship on and off.  And you need to watch your altitude and your height.  And of course the goal is not to crash.  And so it involves, like, turning your engine on and off just enough to bring the altitude down without increasing your speed, and then a little more at the end there in order to slow yourself down when you're just a little bit above ground, and then touch down.  And it's - what I love about is it's pure, simple calculus.  It's just integration and, you know, velocity and force.  So conceptually very simple.  But, you know, it makes an interesting sort of - just difficult enough sort of problem.  So, and what I remember is where it would print out velocity, altitude, and fuel.  And then it would say, like you'd put in a number from one to nine, how hard you want to burn the engines.  And then it would put out velocity - or zero.  And then it would do again velocity, altitude and fuel.  And so you'd be looking at those, trying to judge as time was going by, as it printed out each iteration.  It's amazing.  Back then we just thought that was just way cool.



LEO:  I think it's actually going to be - your little toys will be a very useful way to learn programming also because in a very kind of basic way you can see how you do what you do.  And I think it's not a bad thing to learn how to program at the machine level, to understand what the machine's doing before you get to higher level languages.



STEVE:  Well, and in fact there are - it's surprising how much PDP-8 resource is on the 'Net.  The PDP-8 is specifically often chosen by - like in Assembly language and machine architecture classes, specifically because it is so simple.  It's got six instructions, and then some math, a single sort of math instruction, and an I/O instruction, for a total of eight.  Because there were only three bits for  the opcode.  And so it not only - it's the restriction of it that makes it interesting.  It makes it easy to learn because there isn't much to learn.  But then the way they built it, it's like, okay, how are you going to solve this problem with only two twigs and a toothpick?



LEO:  Right, right.  Very cool.  All right.  We have our next question from New Zealand.  Bill in Auckland wonders about mixing security on web pages.  I see this alert a lot.  I'm a web developer, and on a project I'm working on I discovered something strange that deals with mixing secure pages and nonsecure pages.  Most web developers know if you have a secure page, and you have an item on the page that points to a nonsecure URL - an image, for instance - the browser gives you that warning, you have a mix of secure and nonsecure items on here.  As I understand it, the reason is the potential for information leakage.  That's a good thing to notify people about.



I recently discovered if you have a nonsecure page and embed an iFrame that points to a secure page, you don't see this warning.  Uh-oh.  Also in this scenario the end user has no way of knowing that the page in the iFrame is secure since of course the padlock doesn't appear at the bottom of the browser.  To me, I don't see the difference in security between a secure page with insecure assets and a nonsecure page with secure assets.  Wouldn't both be susceptible to information leakage?  And if not, why?  I know from some casual tests, if you try and get information like cookies from the secure page in the iFrame using scripting, that Firefox will return nothing, not giving the outer page access to the secure page's cookie information; and IE will generate an access violation warning.  But if I were a determined hacker, I'm sure I could find a way around this.  What do you think?



STEVE:  Well, there's a couple things going on here.  First of all, we know how the basic model of a web browser is, that it retrieves the HTML content for the page.  And that content may then contain URLs of additional page assets, which it then needs to go and fetch.  The way URLs can be written is so-called "relative URLs" or "absolute URLs."  That is, oftentimes you'll have a page where the assets on the page just say, for example, \image\reddot.gif, for example.  And so what happens is the browser knows to append the HTTP and the flavor of HTTP, either not secure or secure; also the www dot, or whatever the domain is.  And it assumes, then, that if the secondary URL begins with a backslash, that that means start at the root of that domain.  If it doesn't, if it just said image/reddot.gif, then it would assume that it was relative, that that was relative to the location of the page that's being displayed.  So there's a relatively complex set of semantics that browsers universally agree upon.  And this was spelled out a decade ago, so it's well established.



The beauty of not having to say http:// and so forth for all of the resources on a page is that, if you choose to display the page nonsecure, that is, with just regular HTTP, then all of the assets will be loaded nonsecure, and so everything is of uniform security.  If, however, you did go to https:// and brought that page up, then if the assets did not themselves say https or not, that is, if they just left that part off and said /image/reddot.gif, then the browser, because it uses the whole front part of a URL, or reuses it from the page where the asset is located, it will automatically make connections of the same security as the page.  So web designers that have been around a bit take advantage of that to deliberately prevent those kinds of mixed content messages.



What happens is, if the browser, for example, has brought you a secure page, then you tell it, oh, I want you to show this image, and you explicitly say http:// without the "s."  If the page is secure, and you're telling the browser I want you to load this thing not secure, oftentimes it is generally configurable to suppress it.  But the default setting is the browser will warn you about mixed content.  And that's something that users go, uh, oh, wait a minute.  Because, you know, they're often wanting to be on a secure page for a reason.  And if they get something that pops up and is confusing them, they may just wander away and say, oh, I'm not going any further with this, or I'm not giving you the information that your site is saying that it wants.



Now, the second thing happening is iFrames.  iFrames have been controversial because they're powerful and, unfortunately, very exploitable for malicious purpose.  In the normal case, which we were just discussing, you load HTML, and then the assets that that page requests are not other pages.  That is, they're GIFs and JPGs and cascading style sheets, other non-HTML assets.  An iFrame allows you to embed an entire whole page within a page.  That is, "I" stands for "inline."  So essentially you create, you define a rectangular region, and you say to the web browser, go get another page, HTTP, an HTML page, and render whatever that says in the frame.



Well, it's powerful and useful.  But once again, every time you hear me say "powerful and useful" you think, uh-oh, maybe a mild Gibsonian response there because it means there's opportunities for exploitation.  And of course iFrames have been a big problem for exactly this reason.  Consequently, web browser designers, contemporary web browser designers, have taken a great deal of time and trouble to isolate the iFrame from having any access outside of itself.  That is, they'll say okay, fine, we're going to let you display this.  But we're going to be very careful to restrict what can be done inside that frame.



So my advice is avoid them if it's at all possible.  I had to use an iFrame in the cookie project that I worked on, which we'll be getting back to as soon as I finish the DNS project, because it turns out that there are some mishandling of cookies in iFrames.  And the cookie forensics technology that I've got surfaces those and demonstrates when your browser is not doing the right thing with cookies, is allowing iFrame leakage.  And in fact there's an obscure bug in Opera that we discovered, I'm not even sure they fixed it yet, where it's possible by doing some strange redirections in an iFrame to confuse Opera and get around its management of that.  So they're best avoided, if possible, because they're just an opportunity for problems.



LEO:  But they're so tempting.  They solve...



STEVE:  Well, that's because they're so useful.



LEO:  Yeah, they solve problems so easily, yeah.  But it is really a bad idea, I think.  It's bad design.  Wayne in Waldorf, Maryland disagrees about what "mini" might mean.  He says:  In 185 you said "mini" referred to the instruction set, as in mini computer.  I let it go until I heard you say that again in 185A.  I disagree.  Remember that computers used to refer to the room-filling monstrosities.  The only way a PDP-8 could come close to that was if the room were a smallish closet.  The minimal instruction set type computer was a RISC system, Reduced Instruction Set Computer.  Yes, a PDP-8 may have had fewer instructions than an IBM 360, but a PDP-11 had a fair number of instructions - MOV, CLR, OR, XOR, AND, various types of branches along with a byte version of the same thing.  And yet that PDP-11 was considered a mini computer.  Yeah, I always thought the mini computer was mini because it was smaller than a mainframe.



STEVE:  Yeah, I mean, I read the document in Gordon Bell of DEC...



LEO:  Of Digital Equipment Corp.  Yeah, he's the guy.



STEVE:  Yes.  I've read the document in Gordon's own, I mean, that he wrote, where he was explaining that what they were aiming at was a minimal computer.  And when you look at the PDP-8, I mean, I'm amazed, I mean, the thing has no high-level integrated circuits.  It's just ANDs and OR gates and flip-flops that put this whole thing together.  So, I mean, it is truly a minimal computer.  What Wayne is getting confused about is this notion of RISC versus CISC, as it's called, a Reduced Instruction Set Computer and a Complex Instruction Set Computer.  There the idea was that there was a tendency, as these machines evolved in the early days, and again this is - I've gotten so much insight from reading the original working papers, literally the design papers of the PDP-8 and the PDP-11, which Gordon has published on his own site, where you can really go back in time and remember what these people were thinking.  And I read him saying that, when they were going from the PDP-8 to the PDP-11, which was sort of the logical progression from them, he wrote that because virtually all of these machines are being programmed in Assembly language - which, you know, you don't hear that anymore these days.



LEO:  No.



STEVE:  He said, we want to make these machines easy to understand, and easy and enjoyable to program.  So they were literally deliberately designing a complex instruction set machine that was a joy to program.  And frankly, it's why I can't wait to retire, when I'm 85, and get my hands on one of these, which is why I've been purchasing some of these old machines.  I have PDP-11s now, and VAXes even, because the VAX is a 32-bit extension of the 16-bit PDP-11, because oh, my god, they just - they created the most beautiful instruction set.  Specifically because they knew that that's what people were using.



Well, of course what they found was that many of these complex instructions were difficult to implement, and expensive to implement, and turned out not being used, especially by compilers.  The compilers weren't taking advantage of the power of those instructions.  So what's evolved is sort of a different philosophy of using more simple instructions which can be executed more quickly, instead of more singular, more complex instructions which take many cycles to execute.  If you're a programmer talking at the machine level, you'd rather have more powerful instructions and need fewer of them to express your intent.  If you're a compiler, what's really more useful there is to have fewer, faster instructions that you can mix around in a larger number of combinations.  And that's what the whole RISC instruction set approach does.  So it's reduced, but it's reduced in computers that are no longer mini, they're generally pretty maxi machines.



LEO:  Maxi.  Maxi, not mini.  Tyler Gurney in Orem, Utah has need of Elaine's help:  Steve, Security Now! is my favorite netcast.  I anxiously look forward to it every week.  I'm a SpinRite owner since v5, and I've used it many times.  I'm a proud lurker in your newsgroups, looking forward to CryptoLink, as well as results from the DNS project, the cookies project, the testimonials database, et cetera.  I have about eight hours of audio that I need transcribed.  I was wondering if Elaine would be a good choice.  Do you give out her contact information?



STEVE:  You know, we've run across this.  Normally I just send, when people request it, I bounce email back to them with the URL of Elaine's site.  But I thought I would just give her a moment in the sun because she does such a spectacular job of these transcripts every week.  Most people, I don't know how many people read the transcripts, but they are painstakingly accurate.  I interact with her often several times where she'll need clarification on a term.  She uses the 'Net extensively to get the spelling of everything right.  When we were first talking, she was doing  medical conference transcribing where she's getting every medical terminology correct.  I mean, so I love the accuracy of what she does.  And I just found her by Googling, and I just thank my lucky stars that it was she who I ended up contacting.  I think I did because she has a web-based form that she had at the time, and I was able to fill it out, and she got back to me the next day.



LEO:  That's cool.  See, have a website.



STEVE:  Anyway, she's On-Site Media, On-SiteMedia.com, for anybody who ever has a transcription need.  I just can't recommend her enough.  She's just terrific.



LEO:  She's good.



STEVE:  And she's blushing right now.  [Awww.]



LEO:  Former - she's a court reporter, so she knows how to keep up.  [This is not accurate, although I did study court reporting].  Now, we've been using, as a trial for TWiT, this service, it's called Pods in Print at PodsinPrint.com.  You can now get TWiT transcripts, just This Week in Tech show transcripts, as well as Futures in Biotech from them.  And let us know what you think about this.  These guys, they are a human transcription service.  I think they go to India, though, and I'm not sure how they do it.  But they're not, you know, they're not handcrafted as much as Elaine's are.  But it gives you something to read along, and often can give you some more information as you're listening.  So Pods in Print, we're probably going to do more shows with them because - inspired by you.



STEVE:  Well, I know that Elaine is not the cheapest service around.



LEO:  Yeah, we can't afford her for all our shows, I'm afraid.



STEVE:  Right.  David Lawrence asked me once what I was paying, and I think he was using some farmed-out, out-of-the-country service that was much cheaper.  But there's just, I mean, I care about the quality.  There's no way I would consider anything, so...



LEO:  Well, and your show, I think also, every word counts. On TWiT, every word does not count.  I can tell you right now.  Many words should just be left out.



Let's talk about ZIP security.  Joe Sturonas in Milwaukee, Wisconsin:  Steve and Leo, I'm the Chief Technology Officer of PKWARE - love it - inventors of the ZIP file format.  As such I'm writing in response to the Security Now! Episode 184, where you commented that you heard ZIP uses AES now.  I happen to know a little something about the ZIP file format.  PKWARE is the custodian of the APPNOTE - that's at PKWARE.com/appnote.txt - that defines the ZIP file format.



To answer your question directly, as the inventors of the ZIP format, we have updated the standard format to support strong encryption capabilities using industry standard encryption.  Yay.  Combining AES with X.509 digital certificates provides sufficiently durable file protection that is every bit as strong as PGP.  Support has been added to ZIP files with AES using either a symmetric key, a passphrase; or asymmetric key, which is X.509 V3 digital certificates; or both simultaneously.  Additional security is provided using a digital signature, SHA-1 or SHA-2, to provide authentication.  Signatures can be applied to individual members of the archive and/or to the entire archive itself.



Strong security is built on top of the standard ZIP invented by our founder, Phil Katz, so all the capabilities people have been using for over 20 years are still there.  And now you can strongly protect files as easily as ZIPing.  So you ZIP and encrypt.  ZIP encryption provides a platform-neutral solution which can be used across all platforms.  What other technologies have been able to stand the test of time for over 20 years in this industry?  Okay, other than SpinRite.



Strong security in ZIP was developed as a hybrid cryptosystem.  A hybrid cryptosystem uses an asymmetric public-private key combination to encrypt a symmetric key that is used to encrypt the files.  That's what PGP does; right?



STEVE:  Yup, and that's - and we've talked about that approach many times.



LEO:  It's a good way to do it.



STEVE:  It's exactly the way to do it.



LEO:  Since the hybrid approach applies the compute-intensive asymmetric encryption to only the small symmetric key, it consumes minimal processing while providing fast, effective encryption with standard symmetric algorithms like AES.  So the body of the message is using a symmetric key, but the symmetric key is passed using an asymmetric public-private system.



STEVE:  Right.  So if you were specifying only public key encryption, it handles the symmetric aspect of that transparently for you sort of underneath that.  You don't need to worry about it.



LEO:  PKWARE's solution for strong security is available in SecureZIP, an advanced version of the familiar PKZIP program that includes this strong encryption support as part of the standard feature set.  SecureZIP Express for Windows is free for noncommercial use.  Right on.



STEVE:  Which is really neat, yes.



LEO:  Yeah.  It also includes a Wizard to get a free digital certificate, as well.  SecureZIP.com is the URL for that.  He says it runs on z/OS, which is a mainframe operating system; i5/OS, which is for AS/400; UNIX; Linux; Windows Server and Windows Desktop.  I don't see Mac in there.



STEVE:  I know, I was wondering if maybe being covered by UNIX would do it.  But probably not.



LEO:  You know, Apple builds a ZIP and UNZIP into its OS.  And probably they felt there's not going to be much of a market in that case on the Mac side?



STEVE:  Yeah, but XP has this miserable zipping folder thing, too.  In fact, I just heard Paul denigrating it before we began recording our podcast.



LEO:  Right.  We use IZArc, or he recommended 7-Zip.  But neither of them do this.  Now, it's interesting because it sounds like this is part of the standard.  So presumably it could be implemented by other...



STEVE:  Right.  It is now part of the standard.



LEO:  Yeah.  Thanks for your unrelenting persistence to never miss a week of Security Now!.  Keep up the good work.  Joe Sturonas, CTO of PKWARE.  That's so cool.  It's good to hear about them.  That's a great company.



STEVE:  Well, yes.  They've been around forever.  In fact, I licensed their 16-bit toolkit 20 years ago in order to add inflate and deflate capabilities to something I was doing.  I don't remember now what it was.  But, yeah, I mean, these are the guys.  And I really think it's very cool that SecureZIP Express is available for free for noncommercial use.



LEO:  Isn't that awesome.



STEVE:  I'm going to check it out.  And in this new approach we've talked about of doing some more, a little bit less techie and a little more practical application episodes, if it looks like it's warranted, I'm going to consider doing a Security Now! on exactly what the features are and how they work.



LEO:  Excellent.



STEVE:  Yes.



LEO:  Remember before ZIP it was ARC?



STEVE:  Yeah.



LEO:  And I don't know what there was before ARC.



STEVE:  And in fact there were some - was it, oh, boy...



LEO:  There's RAR.



STEVE:  SEA, SEA.



LEO:  SEA, Self-Extracting Archive.  But that was a ZIP format, I think.



STEVE:  But I thought that there was some battle over patents or formats or something.  I remember there was a big, messy legal battle.



LEO:  Oh, yes.  Yes.



STEVE:  I don't remember, maybe it was between ARC and ZIP.  And one way or another that got resolved, and we ended up with ZIP.



LEO:  Thank goodness there's a standard, de facto.  That was a case where the market really did a good job in settling it.  The market is not notoriously good at creating standards, however.



STEVE:  No.



LEO:  Tom Stewart in Arva, Ontario, Canada wonders about the security of open source software.  I'm ready to put on the gloves on this one.  Hi, Steve.  Love your Security Now! podcast.  My question relates to security and open source.  I probably don't understand the open source process.  My impression is the source code is made available to other parties who could then modify it to suit their needs.  That's correct.  How are standards maintained for open source software?  And what is to prevent a version of Linux or other open source software, even security-focused applications, from having malware inserted and being distributed?  Would it not be easy to put in a trojan which could become active at any future point?  Thanks for the show.  Like many other users I purchased SpinRite in appreciation for your efforts to put this show together.  Well, that's a nice way to donate.



STEVE:  Yeah.



LEO:  I have benefited from both listening to the podcast and running SpinRite on my failed hard drive.  Well, what do you say on that?



STEVE:  Well, I have a much more pro open source position, relative to his question, than you might expect.  I think...



LEO:  Oh, no.  I wasn't going to box with you.



STEVE:  Oh, oh.



LEO:  I wouldn't box with you.  I would box with him on this one.



STEVE:  The way the process normally works, as I have seen it, is you've got a couple custodians of the master source archive, and a lot of people who are involved who come up with basically little patches.  I mean, once the program is pretty much established, there aren't lots of changes you normally need to make to it.  And anything that's changed is done in a highly collaborative mode.  So, for example, someone will submit a patch which says, okay, change the following lines from this to this.  And then a lot of people will look at it, they'll scrutinize it, and if it looks like it does the right thing, it'll get checked in.



Now, certainly errors happen everywhere.  They happen in closed source software.  They happen in open source software.  So my feeling is the process has every bit as much chance to prevent a problem as a closed source approach.  Now, the one thing you don't want to do is to accept a large software system which is open source from somebody who says, oh, hey, I've improved Linux.  Here's Joe's Linux.  Install this on your system and use it and trust it.  Because there Joe has gone off...



LEO:  Well, first - there's a couple of issues.  First of all, you can't call it Linux.



STEVE:  Right.



LEO:  Because one thing Linus did do is preserve the copyright.  So if it says it's Linux, I mean, I guess some guy could be a rogue Linux, but it wouldn't take long before the world would beat a path to his door.



STEVE:  Well, and I'm saying, you know, I didn't mean like in a major production environment where he's gone into business.  But it's like, hey, you know, take my version.  Because the source is open, it is absolutely easy for someone to exploit it for malicious purposes.  And the point is they probably can't get that back into the master source tree, but they could certainly generate their own evil version and then try to get people that they know, or maybe don't know, to somehow run it, and you don't know what you're running.  It's been one of the arguments, for example, against my, for me, publishing the source for my security-related tools because I was concerned somebody could take one - I mean, they're all very small and tight.  The fact that they're in Assembler would tend to hamper most people from messing with it.  But still there are lots of people who know Assembler, especially given something that's working.  My concern was somebody could take it, mutate it into something bad, and say oh, you know, here's a copy of GRC's whatever.



LEO:  Right.  The difference is, in order to do that he'd have to make it open source.  So you could look at it, and you could see what he did.  I think open source is always more secure.  But you have to consider where you're getting software from in any case, in any event.



STEVE:  I guess I would say that with the openness of open source comes responsibility to make sure that the availability of the source code isn't misused.



LEO:  Well, I would submit that you have to be careful who you take applications from in any event.



STEVE:  Right.



LEO:  Any application could be malicious, open or closed.  The advantage...



STEVE:  Yes.  Because mistakes happen.



LEO:  Yeah.  Open source doesn't make it more prone to that.  I can take your source code, disassemble it, and stick a bad thing in it fairly easily - that's not a hard thing to do - and then reassemble it.  And then say, hey, I've got Leo's version of SpinRite.



STEVE:  Right.



LEO:  You'd be stupid to take it from me.  So I don't think open source makes that easier by any means.  It's a trivial thing to add a branch to disassembled code that goes to a bad thing and rebuild it.  That's not hard to do.  The advantage is it's open.  So if you're getting open source code from somebody who's made it closed, he's violating the license.  Don't take it from him.  If it's open, presumably  people are looking at the source code saying, what's he doing here?



STEVE:  Right, and running a big comparison on...



LEO:  And you can do it if you want, yeah, I mean, you can look at it.  And just take it from reliable sources.  But any time you take software from anybody, take it from reliable sources.  That's always a risk.  I don't think open makes it any more risky.  In fact, I think it makes it less risky.



David Popovich, IT Support in Stuart, Florida, wanted some GoToMyPC clarification.  He says:  Steve, I've been listening and learning from you for years.  My question is about GoToMyPC.  Leo's ads often say you can use GoToMyPC anywhere, and because of SSL it's secure.  A few weeks ago I heard Leo say you could use it at an Internet caf.  In fact, I just said it, at a shaky Internet caf on Sunset Strip.  This immediately bothered me because I wanted to hear from you as to why this is considered safe.  If there's a key logging program on the Internet caf computers - well, okay.  You know what, there could be somebody looking over your shoulder, too.  There could be somebody ready to hit you in the head.  That doesn't make it safe.  GoToMyPC is not going to protect you against everything.



A compromised system would be like handing the bad guys the keys to your entire system.  GoToMyPC is only as secure as the system you run it from; right?  Of course, running it from your own laptop in a WiFi hotspot through SSL is okay - see, the guy is misunderstanding.  I'm not saying it's safe in every case.  There could be a camera over your shoulder.  You using your own laptop, it's not safe because it could be looking at your keystrokes.  I'm saying the SSL is like a VPN.  VPN's not safe in that context either.



STEVE:  Just you refuse to get to the end of this question.



LEO:  All right, all right.  I mean, it's - okay.  Of course running it from your own laptop with a WiFi hotspot through SSL is okay.  No, it's not.  Same problem.  Somebody could photograph you.  But the advertisement doesn't clarify this at all.  So using GoToMyPC on relatives' computers, library computers, et cetera, would all be taboo; right?  If the answer to my query is not favorable to GoToMyPC, then I suspect I may not hear a reply to this during your podcast.  I realize they're an advertiser.  If that's the case, I know your time is precious, but I would love to get the answer, even if by email.  Thanks to you and Leo for the great insight into today's wild, wild west online.  Steve?



STEVE:  So I completely agree with you, Leo.  And David is asking for something that even my own program, CryptoLink, won't protect you from.  That is, I mean, the message here, though, the reason I wanted to present the question, is that it's a perfect example of understanding the threat model that we've talked about, what it is you're protected from, and what it is you're not.  So...



LEO:  But he's right to be aware of keystroke loggers, absolutely.



STEVE:  Exactly.  And so certainly it's the case that, if you were at an Internet caf, and you were going to use this system from somebody else's machine that you can't vouch for, or even, Leo, as you said, from your own laptop, but you might have somebody watching you enter your username and password, then that's part of the threat model that you need to understand.  So what a VPN system is offering is protection against a class of problems.  And certainly there are things it's not protecting you from.  For example, if GoToMyPC offered, like, the use of the VeriSign tokens, for example, the little football or the credit cards, a one-time password system, that would change the threat model, change its security in a different way than if you're using a static password.  And that's something certainly our listeners well understand.



LEO:  Yeah, yeah.  I mean, software can only protect you from so much.  Nothing's going to protect you if the ceiling falls in.  Let's see.  Riley Willcox in Truckee, California wonders about sniffing email content:  Hi, Steve and Leo.  Thanks for the great show, keeps my brain stimulated.  I try to be a safe emailer and connect to my mail servers via secure protocols.  However, once email is sent out from these servers, it's no longer protected.  For really critical emails I can encrypt the content, but I'd rather do that only when necessary.  Few people are actually set up to receive PGP or GPG-encrypted email.  My question is, if an email is not encrypted, how hard would it be for someone to grab that content between my email server and the destination server?  What techniques would an attacker use?  That's a good thing - again, a threat model - good thing to keep in mind.



STEVE:  Yeah.  And I thought this was a great question because a lot of people, I think, have a hard time visualizing the inner workings of an ISP, a datacenter, like what is the Internet?  They see it as a box on their desk that they've plugged things into, and then sort of magically disappears.  The question then being, well, okay, are there wires hanging outside of the ISP that some guy dressed in a telephone uniform with spiky shoes could climb the phone pole and connect to.  So I wanted to sort of paint a picture for people about what happens to their data once it goes wherever it goes.



As he says, if he were to use a secure connection to the servers, for example using SSL-encapsulated email, then there's no way for anyone to see his email as it's leaving his machine, as it's getting essentially all the way to the ISP's server; whereas as we know, SSL, because it does endpoint-to-endpoint encryption, it would then decrypt it as it's sitting on a server.  So now it's on the server in plaintext format.  And it's going to remain so from then on.



So the threat really is not, I think, to any degree that's substantial, from random people.  Certainly the ISP, which is to say the ISP's employees, do have access to all that.  I mean, the networking level people, the people in the network operating center, the people who tend the servers, the people who are making sure the connections stay up and running, I mean, they're in the middle of the data.  So they have access to it.  They have access to everyone's email that is in this form, that is not maintained and packaged in its own encrypted envelope as you're sending it to its destination.  So if nothing else I guess the threat is watered down, unless for some reason you were targeted.  In which case, if there was some reason for an ISP or an employee, a rogue employee, to get all of the email or traffic or something to or from one specific customer, they have access to it.  I mean, that's their job.  This data is there, and nothing protects it.



LEO:  You know what I liken it to is the post office.  When you send a - think of it as sending a postcard.  It's going through the post office completely available to anybody who wants to look at it.  And the mail carrier and everybody.  We trust them.



STEVE:  Or we just trust in their disinterest.  And in fact that's one - so that leads me to the other threat, which unfortunately is Big Brother.  We've been through, post 9/11, an increase in surveillance.  We don't know to what degree it affects us individually.  We pretty much - I hope it pretty much doesn't affect me.  That is, I have no reason to believe that it would.  But we know that there have been technologies employed where ISPs have had devices installed that literally read everything, that are filtering for keywords and performing matches.  And this was FBI technology at one point that was discussed and apparently deployed.



LEO:  Carnivore, yeah.



STEVE:  Carnivore, exactly.  So that's really a problem.  We do know that law enforcement is unhappy about VPN, the growing use of VPN technology, because it blinds them to the actions of bad guys.  I'm not happy about blinding anyone to the actions of bad guys.  But I also want to blind malicious hackers and nongovernmental bad guys.  So unfortunately law enforcement loses in the process.  It would be nice if only good guys protected themselves, but everybody can because it's powerful technology.



So I guess, anyway, to wrap this question, the idea is that this stuff is vulnerable.  I think what we have to assume is that the people who are charged with tending it don't care, whether that's Big Brother, who might be scanning everything, or random ISP employees that have better things to do than read random people's email.  We know that random people's email does get read sometimes.  Sometimes it makes the news.  Most often it doesn't.  So I guess the answer is, if it's really the case that you don't want your mail read, you need to go to some measure to protect it until its recipient receives it.  And that's either using something like PGP, or SecureZIP, as we just learned about, or some technology like that.



LEO:  I guess the other difference is the post office there's federal laws protecting you and protecting your privacy.  Which I don't think there is in email.



STEVE:  Sure, wiretapping laws would...



LEO:  Oh, maybe, yeah.



STEVE:  Yeah.



LEO:  Okay.  I mean, I assume that every email that I send could be read unless I encrypt it.  Period.



STEVE:  Leo, mine are boring.  I'm just...



LEO:  Yeah, go ahead and read 'em.



STEVE:  Someone's reading that, it's like, oh, well, then that means they're not doing something else, so...



LEO:  But you could say the same thing about any phone call that you make.



STEVE:  Right.



LEO:  Unless you explicitly enforce privacy, you don't have any.



STEVE:  I've sometimes been cautioned, when I'm having lunch with my attorney, to keep my voice down because it tends to go up.  And I need that reminder.  I'm glad for that reminder because you don't know who's at the table next to you.  I mean, probably no one.  Probably I'm just annoying them rather than interesting them.



LEO:  Well, that's it.  I think relying on disinterest is like relying on security through obscurity.  It works most of the time.  But not all the time.  And the problem is that somebody who is interested probably doesn't have your best interests at heart.



STEVE:  Right.



LEO:  Last question, from Pierre in Canada.  Pierre wonders about the wisdom of defragging today's huge hard drives:  Hi, Steve.  This week a colleague told me about an article I then read on the Internet and asked me what I thought about it.  I wasn't sure what to answer him because the article seems to make so much sense.  So I thought, hmm, who would know better than the maker of SpinRite?  What we're wondering is, according to this article, with hard drives getting bigger and bigger, defragging could have more negative impact on the drive than positive impact.



The two arguments are that, first of all, with a drive of, say, 500 gigs or a terabyte, the time it takes is getting so long, that's a lot of work on a drive for a very long period of time.  The stress could reduce the lifetime of the drive.  Secondly, hard drive transfer rates are getting so fast that the gain is not significant.  Why bother to defrag a drive if you don't need to?  So what do you think about this?  Good job with SpinRite.  I'm a programmer working in an IT department.  We use SpinRite every day.  Wow.



STEVE:  Well, that's an interesting question.  One of the things that we learned with SpinRite 6, when I first incorporated real-time S.M.A.R.T. monitoring, where SpinRite is periodically polling the drive's S.M.A.R.T. data, one of the things SpinRite shows and watches is drive temperature.  And we learned that a lot of drives, especially laptop drives, easily get overheated.  Many people have had SpinRite stop, as it will, and warn them that their laptop drive is now at the manufacturer's upper limit of temperature.  And sometimes this even happens with people who have desktop machines.  Sometimes desktop machines that were designed for an earlier generation, smaller, and less power-hungry drive, people will add a drive to the existing enclosure or replace a smaller drive with a bigger one, which may draw more power and generate more heat.  So the ventilation, which was adequate for the cooler drive, isn't for the hotter, more power-hungry drive.  We've seen that a lot.  So the only real downside I can see is you really want to make sure that your drive is not overheating.  Unfortunately it's not easy to tell that.  I mean, SpinRite has it built in, but defragging programs don't.



The other thing is, I would, if the question is I'm worried that defragging the drive might cause it to fail, then my reaction is, whoa, you absolutely want to solve that problem first.  That is, one way or another you want to be in a situation where a drive failing cannot really hurt you badly.  Which means you either backup enough; or you've got a RAID configuration so you've got some redundancy, so if a drive dies you're able to survive that.  Because, believe me, I mean, I'm in the business.  Drives do die.  SpinRite can fix a lot of them; but, you know, sometimes when the heads fall off or they seize up or they burn out or something happens mechanically, there's nothing any software could possibly do.  So...



LEO:  Do you think you need to defrag drives these days?  Is the speed sufficient that it's not worth it?



STEVE:  Well, it's interesting, the...



LEO:  [Indiscernible] time is always going to be an issue; isn't it?



STEVE:  The transfer rates have gone up, but the hunger for data, I think, has gone up just as fast, if not faster, than the transfer rates.  I mean, our systems don't feel particularly faster than they used to.  I mean, when Windows 7 boots up in less agonizingly long time than Vista, it's like, wow, that's faster.  But we used to turn our machines on, and they were booted by the time the CRTs warmed up.  Those days are long gone.  So my sense is that drives are faster, but everything is bigger.  And so the bigness is completely offsetting the increase in data transfer rate.  I still defrag.



LEO:  You do.  How often?



STEVE:  I don't do it fanatically.  I saw that my defragger was running, that is, the services, I've got two services that run with the third-party defragger that I'm using.  And I thought, oh, that's dumb, and I went and manually turned them off.  But it reminded me that I hadn't defragged in a long time.  My routine is, when I'm - I'm running a RAID, so I've got redundancy all the time.  But every so often I want to take a snapshot.  So what I'll do is I'll just go through a housecleaning.  I will empty caches.  I'll look at the size of my - I'll sort by file sizes, get rid of a bunch of junk that I've just sort of accumulated through daily operation, so sort of trim the system down to a minimum working set size.  Then I defrag it.  Then I make an image of it.  And so that's sort of just an afternoon, or maybe a couple hours of when the mood hits me I decide, okay, it's time to do a little maintenance.  I get rid of everything I can first, then I defrag it, then I make an image, and then I feel good.



LEO:  Good.  I'm glad you feel good.  I've been for a long time kind of one of those guys who says defragging is voodoo; or, not voodoo, but it's overrated.  Do it every few months, that's all you need to do.  And...



STEVE:  It also has the advantage that it's a little bit of a poor man's SpinRite because...



LEO:  Right, it does check it, doesn't it, yeah.



STEVE:  It does make the drive go and move stuff around.  And moving stuff around, it makes it read it.  And if the drive discovers sectors that are beginning to be problematical, the drive can relocate those to better physical sectors.  So it's not just logically moving it, it's actually physically retiring sectors that are bad.  You don't get any guarantees that it hasn't missed spots, which is where SpinRite comes in because it does a whole drive read, essentially, and re-verification.  But it has a beneficial effect, I think, that is probably greater than its deleterious effect, so long as you're not overheating.



LEO:  All right.  So keep it cool, man.



STEVE:  Yeah.



LEO:  Steve, a great 12 questions, as always.  We love our listeners.  You guys are smart and always raise interesting issues, and we're so glad you write.  Go to Security Now!'s web page, GRC.com/feedback, to submit questions for our next Q&A episode, two episodes hence.  Of course, while you're at GRC, buy a copy of SpinRite, download all of those great programs, check out the show notes, the 16KB versions of the podcast, and all of that stuff, too.  It's a great website:  GRC.com.  And Steve, we'll see you next week.



STEVE:  Talk to you then, Leo.  Thanks.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#187

DATE:		March 12, 2009

TITLE:		Windows Autorun-around

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-187.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 





DESCRIPTION:  Steve and Leo discuss the inglorious past of Windows Autorun.  They explain how, until recently, disabling "Autorun" never really worked, how Microsoft hoped to fix it while bringing minimal attention to the problem, and how Microsoft's documentation of their recent fix still "got it wrong."



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 187 for March 12, 2009:  Fixing Autorun.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that talks about security, now.



STEVE GIBSON:  Yay!



LEO:  Yeah.  And here he is, the star of the show, from GRC.com, the Gibson Research Corporation, the creator of SpinRite, the discoverer of spyware, and man about town...



STEVE:  Doo-to-doo.



LEO:  ...devoted cabernet drinker, Mr. Steve Gibson.



STEVE:  Yes, we've got a whole ton of really interesting security news.  And we're going to talk about Windows AutoRun and AutoPlay this week.  Remember I mentioned it a couple weeks ago.  Actually it was part of - this came up because of the February updates that Windows did where they fixed the fact that it was broken.  And it turns out that they still haven't got it right.  Apparently the technology is working, but they forgot to mention something really critical in every page that I have found on their site that talks about how to configure it properly.  They still don't explain that correctly.  So today we're going to.  And it's important because...



LEO:  Now, I know - yeah, okay, I was just going to ask because we're spending a whole show on AutoRun.



STEVE:  Yup.



LEO:  Why?



STEVE:  Well, it's probably one of the first things that a security-aware person does when they want to bolt down a computer.  And what's interesting is the actual back story behind why Microsoft fixed it.  Because there was a patch for it which was only available in Vista and Server 2008.  You had to manually install it.  There was an update, but you had to go manually get it from Microsoft's site, so nobody did.  Well, believe it or not, the Downadup/Conficker worm...



LEO:  Oh, no.



STEVE:  Yes, started exploiting Autorun in order to spread itself.  And so even users who had turned it all off were still getting infected due to this bug that Microsoft knew about, but didn't figure was important enough to push out.  And one of the reasons is they were literally afraid that, if they updated everybody and fixed the fact that it was broken, that people would be more upset that things that used to work no longer did, even though it's what they said they wanted.  So go figure.  Anyway, so we've got a great show today.



LEO:  It sounds very interesting.  Sometimes we get very granular on this show.  And I think this is one of those granular ones.



STEVE:  Well, yes.  We're going to be down in bits because, in order to specify the configuration, you need to understand the way hex bits are merged together to create a composite value.  Microsoft did not make this easy.  So anyway, we've got a whole bunch of stuff to talk about.



LEO:  You said a mouthful.  Microsoft did not make this easy.



STEVE:  Yeah.



LEO:  Well, we'll talk about it in a second.  We'll also get updates on the security news.  There is some, and...



STEVE:  Tons of that.



LEO:  Tons of it.



STEVE:  Tons, baby.



LEO:  So I came in today, and you know we have the new Skypasaurus.  Have you see the Skypasaurus behind me, Steve?  This thing is...



STEVE:  No.



LEO:  We built - Colleen built this.



STEVE:  Oh, is that those four screens that I saw?



LEO:  Yeah.  Colleen built this.  It's four - because we were trying to figure out how can I do TWiT and MacBreak Weekly and Gillmor Gang, the shows that have multiple panelists, how can I get video from them all.  And I wracked my brain.  The only thing we could come up with is, well, we need four computers running four instances of Skype.  And we place four separate calls.  And then we route them all through the TriCaster.  And that's what we did.  It's Colleen - there are four mini ITX cases with four 17-inch screens on one giant multi-screen mount.



STEVE:  Now, this is not the reason that on the Gray-Haired Computing that we did, it's not the reason that Ray's audio was a little crispy?



LEO:  Well, it is, in a way, because that was the first - that was the trial Skypasaurus.  And we almost - I almost abandoned the whole project because of that.  But Colleen updated drivers, we messed with it, we got it to sound - actually sounding...



STEVE:  Oh, yay.



LEO:  ...just as good as you sound.  And so that's much better now.  So, for instance, if we do another Gray-Haired Computing segment you'll both be side by side on Skypasaurus and like that.  But I came in today, and Skypasaurus had rebooted.  All four Windows instances.  That's how I know there's been a patch.



STEVE:  Ah, yes.  We are on this side, or the other side, some side...



LEO:  Of Patch Tuesday.



STEVE:  ...of Patch Tuesday, the second Tuesday of March.  And there was, as usual, a bunch of stuff.  I wanted to start, though, by asking our listeners to do us a favor.



LEO:  Oh, good.  I love that, yes.



STEVE:  There is some voting we need.



LEO:  Uh-oh.  Uh-oh.  Are you running for beauty queen again?



STEVE:  No, no, this is Best Security Podcast.



LEO:  Oh.



STEVE:  It turns out that there is going to be an announcement at April's, that is, this year's RSA conference.



LEO:  That's the big one.



STEVE:  That's the big one.  Remember, that's where I ran into Stina from Yubico and discovered the YubiKey at the top of the escalators, when she was sort of looking around forlornly, wondering how she could come to the world's attention.  That problem got solved.



LEO:  Is it in San Francisco again this year?



STEVE:  Yes.  I think it's the Moscone Center.  I'm not going to go up this year.  It's like, eh, I did it, I saw what was there.



LEO:  I'll accept on your behalf.



STEVE:  Oh, that'd be good.  Anyway, so the URL is strangely named SocialSecurityAwards.com.  It's got nothing to do with Social Security except it's podcasting and blogging, which are social events, social venues.  So that's why they called it SocialSecurityAwards.com, all one word.  The annoying thing for our security-conscious listeners is you must enable scripting in order to do this.



LEO:  Well, that's not very socially aware of security.



STEVE:  Yeah, I know.  They use some monkey program.



LEO:  They probably use - they use cookies to keep you from voting more than once, probably.



STEVE:  They do that, yes.  And so immediately I said, oh, well, I've listened to other security podcasts, and I really do like mine best.  So, hey, I wanted to be fair.



LEO:  That's fair.



STEVE:  I went to Social Security Awards, and all you get is this big black type on the screen:  JavaScript must be enabled in order to proceed.  It's like, okay, fine.  So I enabled it for SocialSecurityAwards.com, and it still wasn't happy with me because there was something monkey or other, Vote Monkey or something, that I also had to enable.



LEO:  See, I don't have to do any of that because I'm not running any of that stuff.



STEVE:  Because you have no security.  That's fine.



LEO:  I have no security.



STEVE:  But that, I mean, if that helps you to vote for Security Now!, I'm all for that.



LEO:  Now, it's going to ask for the name, podcast name.  That's Security Now!.



STEVE:  Security Now!.



LEO:  The URL is TWiT.tv/sn.



STEVE:  That's exactly, hey, I filled it out correctly, Leo.  That's what I put.



LEO:  That's kind of the homepage for it:  TWiT.tv/sn.  And that's where all the shows live.  And that's probably the best place for them to go to find it.



STEVE:  Yes.  So TWiT.tv/sn for the URL.



LEO:  And then of course the reason.



STEVE:  There's no prompting.  It's not multiple choice.  Our listeners are going to have to fill that in.  You only - there's five opportunities, five things, because there's four different blogs and one podcast.  The podcast is the top one on that form.  And all I did, since I am not reading other people's blogs...



LEO:  Oh, I read Brian Krebs.  I want to vote for Brian Krebs's blog.



STEVE:  I would, too.  As a matter of fact, I refer to him in today's podcast because he had a great column about the Tigger trojan that we'll be talking about.



LEO:  Yeah, so, I mean, I'm not going to tell people how to vote on this.  But I'm going to say blog name is Security Fix, and the URL is blog.washingtonpost.com/securityfix.  And Brian really floats my boat.  I don't know.  They want a reason.  Now, I don't read a corporate security blog.  You know, that really should - Brian should be the best non-technical security blog.



STEVE:  There's some sort of a limit to the reason length because I basically typed in a small book about why Security Now! was the best thing.  And then when I tried to submit my vote it said...



LEO:  They don't care.



STEVE:  ...that's invalid.  So I shortened it, and it still didn't like it.  So finally I just said, "Steve needs more hair."  And then, you know, it liked that one.



LEO:  I'm going to put Brian's in the non-technical because he's really a good non-technical security blog.  I don't know who I would say technical.  I'm not sophisticated enough to read a technical security blog.  I certainly read a lot of the stuff, the security websites.  I'll find a good one.  Corporate, don't know.



STEVE:  Anyway, so to our listeners, SocialSecurityAwards.com.  I won't say to vote for Security Now!.  I would just say vote for your favorite security podcast.



LEO:  But I'll be glad to accept when we win.



STEVE:  And Leo will happily accept when we win.  That would be great.  And then...



LEO:  You know what, Steve, maybe we can get you up here.  If you win, I think you should come up.



STEVE:  And after you've lowered all your security down so that you're completely vulnerable during the voting process, you can bring it back up right where it was before and turn off the monkey vote or whatever the hell that thing was.



LEO:  They have to, come on, now, well, maybe you - you're good at doing stuff without scripts.  But seems to me, if they want to kind of make sure only one vote per person, that kind of thing, a script is the best way to do that.  Don't you have to use JavaScript to use cookies?



STEVE:  No.  No.  JavaScript is a horrible idea that came along way after cookies came along.



LEO:  Oh, okay, okay.



STEVE:  No.  No.  Cookies are part of the fundamental HTTP protocol.  HTTP or HTML?  HTTP.  It's the transport layer.



LEO:  So in the GET and so forth you can set and get cookies.



STEVE:  Yeah.  My guess is that they're doing things like probably using Flash cookies in order to be extra sneaky, in order to hook a little bit deeper in so you just can't delete your cookies and vote again.  I mean, I only voted once.  It's funny, too, because then I wanted to go back in order to be able to cite what the other blogs were.  And it wouldn't even let me to the page.  It said, "Thank you very much for your previous vote."



LEO:  You've voted.  You've voted.  Stop it.



STEVE:  Done.  And it probably logs your IP.  I mean, who knows what it does.  I don't care.  I only voted once.  But if all of our listeners would do that, I think we'd have a good chance, so.



LEO:  I think we...



STEVE:  I'll get up off my knees now and stop begging.



LEO:  Okay.  What else is in the news?



STEVE:  Well, we do, as you said earlier, we have our monthly Windows Update drama.  The bad news is there is still no fix for the very bad Excel flaw that we spoke of last week which is being actively exploited in the wild.  Microsoft did not fix that this time.  The general murmur out in the security community is that this is so bad that as soon as Microsoft can, even out of cycle, that is, they should not - given that we now know we're not going to have it for early March, they really don't want to wait another four weeks until the second Tuesday in April because this thing is, I mean, it's a problem we know about.  It's becoming widespread in its exploitive spread.  And Microsoft knows about it.  They've acknowledged it, but they haven't fixed it.  And essentially all it takes is somebody who's got Office installed to open mail and get tricked into clicking the link.  The act of displaying a deliberately maliciously formed Excel page can take over your machine, cause code to be executed remotely.  The proof-of-concept technology is out and floating around the 'Net, so it's as bad as anything can be.  And we didn't get a fix this cycle.



What we did get was the standard monthly critical remote code execution fixes.  Turns out our old friend the Windows Metafile is back.  There is a parsing bug in WMF and EMF, the enhanced metafile parsing, where during the handoff, as the GDI is getting involved and accepting parameters from the user mode down into the kernel, during that user mode-to-kernel handoff there is a problem with the metafile processing, parameter handling, that allows a malicious  metafile to do bad things to you.  So it's important.  And I would say - I mean, they're all important.  This one is as important as ever, that absolutely will require a restart of your machine.  So you're going to want to do that.



We're going to be talking a little bit later about some serious trojans and worms which are still today managing to proliferate based on a patch that was issued in October of last year, October of '08.  So we're now at, what, T plus five months.  And people are still not patched.  So I can't - it's inexplicable why that's the case to the degree that it has been because in this case we're talking about 11.5 million instances of a really bad worm infecting people, although it's becoming increasingly clever in the way it both survives and spreads, which we'll be talking about here in a minute.  But I just want to say I think it's important.  Rebooting is a pain, but you want to do it every so often.  Certainly balance the risk versus the reward.  But a restart of your machine will be required.



We talked a couple weeks ago and then again last week about the flaw in Adobe Acrobat and said that the most recent version of Acrobat would be patched on the 11th.  Well, that's yesterday for the people who are listening to this on Thursday.  It has been patched.  The patch exists.  And that's only for version 9.  I'm still using 8, myself, and I'm happy there.  So I went to their site, and sure enough, the update for Acrobat 9 is available as of the time we're recording this on the 10th.  But there's no available patches for the prior versions.  Remember that this is something which is also actively being exploited.  This was a zero-day flaw, that is, it was found only after exploits were already taking advantage of it.  Then Adobe figured out what was going on, said whoops, we've got a problem, we're going to get this thing fixed for version 9, the most recent version, on March 11th.  And it'll be a week later for the prior versions.  So I'll be keeping an eye out for when the update for my version 8 is available, and I will certainly apply it.



LEO:  Why don't you just update to 9?  I mean, is there some reason that you...



STEVE:  No, I just haven't.



LEO:  I mean, I guess that's what they figure is that, well, update to the latest version, that'll fix it.



STEVE:  Okay.  Yeah.



LEO:  Is there something you don't like about 9?  I mean, is there something we should avoid because 9 has...



STEVE:  No, I just haven't gone there.  I have no need to.  Maybe you're right, this going there, I mean, who knows what the story is.  I don't even know if they'll charge me for an update from 8 to 9.  You know, Adobe tends to be...



LEO:  Oh, I see.  You're not using the Reader, you're using the full Adobe Acrobat.



STEVE:  Correct.



LEO:  Ah.  So you don't want to pay for the update.



STEVE:  Correct.



LEO:  But if you're using Reader, you should just update to the latest Reader.



STEVE:  Yes, absolutely.



LEO:  Because that's free.



STEVE:  Because that's free, yes.



LEO:  Although there are people who say - and that's why I was asking, because there are people who say, you know, they've always - because every time they update Reader they add more stupid features.



STEVE:  Oh, I know.  And I did read something that was not confirmed on the 'Net that non-Adobe PDF readers may also be subject to the same problem.



LEO:  I saw that, too.  Foxit might have the same problem.



STEVE:  Yes, Foxit may well have - and you know...



LEO:  I've been telling people use Foxit instead.  And now I'm going, oy yoy yoy.



STEVE:  Yup.



LEO:  Why would it have the same problem?  Did they copy code from Adobe?



STEVE:  Without looking at it in detail I couldn't guess, although - oh, the other thing I wanted to mention that was important is, when we first talked about this, I said that one short-term workaround is to disable JavaScript for Reader, that unfortunately - now, talk about adding things to it.  Like I just want to open a PDF.  I don't need JavaScript in my PDF reader.  But they all have it.  And it turns out that that was the way the original exploit was being leveraged into remote code execution.  So at that time disabling JavaScript was believed to be a weak, yet sufficient for the current version of exploit, solution.  Well, there's a way around that.  As we expected, disabling JavaScript doesn't - we knew we didn't cure the underlying problem, but it only might solve the problem with this particular approach of exploitation.  It's now the case that non-JavaScript exploits exist for this bug.  And given that Reader may not be actively updated, this is something that could bite people.  So it is the case that disabling JavaScript no longer protects you.



LEO:  What a mess.



STEVE:  Yeah.



LEO:  Big mess, yeah.



STEVE:  It's also Mozilla product update time.  There are multiple vulnerabilities in all of the Mozilla products -  Firefox, well, Firefox, Thunderbird, and SeaMonkey.  In the case of Firefox, 3.0.6 and prior have the problem.  And I'm using 3.0.7 now, so everyone should be who's using Firefox.  Thunderbird 2.0.0.18 and prior are vulnerable, and SeaMonkey 1.1.16 and prior.  And Mozilla's site has updates beyond all of those.  So it's possible to update yourself to, in every case, a secure version.  And you're going to want to do that.  Also we haven't heard from Opera for a while, but Opera has got multiple vulnerabilities.



LEO:  [Muttering]



STEVE:  So version 9.63 and prior are vulnerable.  You want to be using Opera later than 9.63.  And finally, one we've never talked about, but I thought there were some users of it still because it's popular, and that's Winamp.



LEO:  Yeah.



STEVE:  Winamp uses an open source sound file parser called Libsndfile, L-i-b-s-n-d-f-i-l-e.  Turns out that there is a sample processing problem that involves integer processing overflow in this Libsndfile file, and it's necessary to update to Winamp after version 5.55.  So if you are a Winamp user, and I imagine among our listeners there are some people, just wanted to give you a clue that version 5.55 and prior are using the vulnerable version of this Libsndfile, and you should update.  And updates are available from Winamp.



LEO:  It's always scary when an exploit affects data files because everybody who listens to this show, anyway, knows to avoid executables.



STEVE:  Right.



LEO:  And of course you back up data files.  So you don't think, oh, a JPG, a PDF, an MP3.  Those are harmless.



STEVE:  Yeah, or an Excel spreadsheet.



LEO:  Or an Excel.  That, at least, because there's macros,  you go, well, I know that's got some executable code.  But, c'mon, an MP3, there's no executable code in there.  How could that be harmful?  So these are - I think these are really serious.  People ask me all the time, if I back up my data - because I tell them, you know, back up, reformat, reinstall so that you'll get rid of everything - if I back up my data, I'm safe.  And I say, yeah, if you get the data only.  But technically that's not true, is it.  



STEVE:  Not so much anymore.  I mean, as I do the research every week, and I write all this down, I just - I think, my goodness.  It's just - it is never, I mean, literally never-ending.



LEO:  You kind of have to admire the tenacity and, frankly, intelligence of these hackers to find an exploit in Winamp or Reader that they could take advantage of with a data file.  PDF even, because PDF is kind of a programming language.  PostScript is really a programming language.  But come on, MP3?  That's ingenious.  Let's face it.



STEVE:  Well, and somewhere somebody was writing code to  parse and process the samples in an MP3 sound file.  They weren't thinking about security.  They were thinking about getting the darn thing to work so that sounds come out.  And it turns out that, as a consequence of that, if you give it a deliberately specially crafted sound file, an MP3 file, it will cause a hiccup in the processing that allows you then to, like, cause the rest of the sound buffer to be jumped into.  So you have this special set of samples which causes this integer overflow, which causes the execution of the rest of the buffer.  So you literally are putting a program into the sound file with a header that gets this vulnerable version of the library to execute the following code.  And as soon as you do that, it can bring in some more code, take over your machine, go off to somewhere malicious, and install backdoors and trojans and worms.  And, I mean, it's just the reality of computing today.



So really the only thing we can do is hope that vendors and developers continue to function in as responsible a fashion as possible and do their best to keep us safe.  But it's just - and the other thing, too, is that what's really changed from the beginning days, where this was done as a curiosity, is unfortunately, as we're about to learn in a couple of other points I'm going to bring up here, next stories, is that it's big business.  I mean, now this is big business.  This is infecting and taking over people's machines for profit - not just to see if you can, or because you can, but because you can get paid to do it.



LEO:  Somebody in our chatroom sent me a link to Foxit's page.  They do have an update today.  But ironically they say, "We have received a number of inquiries about the latest Adobe vulnerability.  And people say, is Foxit Reader subject to the same kind of vulnerability?  It was caused by a buffer overflow in their JBIG2 decoder.  We use our own JBIG2 decoder, and we are not vulnerable in the same way."



STEVE:  Great.



LEO:  So instead of crashing, you get an empty image display when you get that buffer overflow.  So good news.  But there is an update.  They did update their JBIG2 Reader.  So clearly they took a closer look at it when they saw this Adobe vulnerability, and they found some stuff to clean up.



STEVE:  Good.  In other news, as of the beginning of this month, all of our government's top level .gov domain servers are now running DNSSEC. 



LEO:  You mean they weren't?



STEVE:  No.  They had never been before.  No, DNSSEC is a complex and annoying system to set up.  There's a lot to it.  And our own .gov top level domain had not been using DNSSEC.  It's now - all is in place as of February 28, the end of last month.  So that's a good thing.  I mean, it doesn't mean - that doesn't help us for, like, the .com and the .net and the .org and all the other top level domains.  But at least the .gov top level domain servers can now offer signed and authenticated records.  So anybody who wants to ask them for verifiably nonspoofable signed records can get them from our top level domain .gov servers.  And that's, you know, it's a step forward.  It's not clear that DNSSEC is going to end up being widely deployed soon, or maybe ever.  I know "ever" is a long time.  But this thing has been - the DNSSEC spec that we talked about at length in a podcast not too long ago has been around for a long time.  So it's been available.  It's there.  It exists in all the current versions of the DNS servers.  It's just that no one takes the time to do it because it's like, eh, well, you know, nobody else is, so we're not going to bother.  Well, now the government is.  And so that's at least one small step forward.



LEO:  Did you mention that one of the patches that Microsoft issued yesterday was to fix a Kaminsky-type flaw in IIS?  Or in their DNS server, rather?



STEVE:  No, I didn't.



LEO:  Yeah, there still was a Kaminsky flaw in there.  I'm going to call it a "Kaminsky flaw." 



STEVE:  So a spoofability problem.



LEO:  Yeah, a man-in-the-middle issue.



STEVE:  Right.



LEO:  So they still were working on that, I guess.



STEVE:  And speaking of Brian Krebs, he had a nice little write-up - I ran across a reference to a new, an interesting trojan.  It's called the "Tigger" trojan.  And so in his write-up he explains that what's interesting about it is it is the most tightly targeted trojan we've really seen.  More than a quarter million Windows machines have been infected.



LEO:  [Whistling]



STEVE:  And this thing specifically targets employees and clients of E*TRADE, ING DIRECT, Vanguard, optionsXpress, TD AMERITRADE, and Scottrade.



LEO:  Wow.  Everybody.



STEVE:  In other words, the stock market guys, the people who are doing stock market stuff.  It uses - it's interesting.  It uses a privilege escalation exploit which was patched in October.  So once again, five months ago this thing was patched, but it's still infecting these people.  Maybe their corporate policy is, well, we'll get around to it when we can.  It's hard to account for the fact that here we've got people doing financial services, both employees and clients apparently that have these accounts and this software on their machines, which this thing is working to target.  But even running under a limited user account, which normally protects you from these kinds of exploits, won't protect you because it takes advantage of this privilege elevation fault which, if it's not been patched since October, allows it to install this trojan on your machine.  And then apparently it has code in it, they've analyzed it, where it is deliberately doing malicious things if it happens to land in a machine owned by an employee or a client of any of those stockbrokers.



LEO:  Wow.



STEVE:  Bad news.



LEO:  I guess they didn't have enough money, they probably couldn't fix it.  Too busy doing other things.



STEVE:  Well, and the worm that just keeps on giving.



LEO:  Let me guess.  Koobface?  Conficker?  Downadup?



STEVE:  Yup, it is the multi-named worm - Downadup, Conficker and also Kido.  It's known by all three names.  It was discovered, okay, in November of '08 by a honeypot.  It was found in a honeypot that Symantec was managing and monitoring.  Since then this worm has managed to infect at least 11.4 million PCs.



LEO:  Whoa.



STEVE:  11.4 million machines.  Now, this is according to a census, not from an AV company where it's like, okay, they want to inflate that.  But this was a census carried out on compromised Internet addresses by SRI International.  So a neutral party said 11.4 million machines infected.  Now, get a load of this.  We're now at major version C of this.  What happened was the original - one of the reasons this thing has been hard to contain is that they use an algorithm in the worm to determine what domain name to go to based on any given day.  And so typically the way - and by the way, this installs a botnet.  So you've got a big botnet, a whole large number of machines infected.  Well, they need to go somewhere to get themselves updated and to receive instructions and various specifications for how to function.



So the first thing somebody does who wants to shut them down is they get a hold of one of these, they look at the domain names that are built into it, and then they go to the registrars, people like Microsoft, for example.  It's called the "Conficker Cabal."  There's Microsoft and a bunch of registrars that are all working together, and a bunch of AV firms, to try to control this problem.  So the idea is you cut off command and control so that you shut down the domains that the worm is trying to go to and prevent it from updating itself, prevent it from mutating or getting more instructions or even new sets of domains.  So because this is the way it's always been done, the designers of this new worm Downadup/Conficker/Kido, they said, okay, we're going to use a sophisticated algorithm which is going to be much more difficult for anyone to reverse-engineer and figure out, which will determine - which will essentially set up a large list of domains, but without revealing what they are.



So the original version of this, basically it was able to deal with 250 different domains.  So it was necessary to reverse-engineer the algorithm, figure out in advance what domains this worm would be going to in the coming days, and then beat it to the punch by going to the registrars and getting them to preemptively issue - basically take those domains out of service.  So the C version, which is out just recently, uses a new algorithm to increase this number from 250 domains to 50,000.  So we're now looking at the worm able to, in the future, generate 50,000 domains.  And it isn't only going to one a day.  It's going to many.



LEO:  But they have to register them, too, though.  I mean, it's not like they can just spawn domains, can they?



STEVE:  Well, this thing, as I understand it, what it was checking was it was checking at 250 domains a day before.  Now it'll be checking 50,000.  So the idea is...



LEO:  Oh, I see.  So it's hard to figure out which domain they're going to use.



STEVE:  Well, and you're got to cover all of them on an ongoing basis.



LEO:  Ai yai yai.



STEVE:  I mean,  it really is a problem.  Based on an analysis of traffic, that is, people looking at incoming requests to the known domains, the stats are that three million IP addresses - right now, three million IP addresses are contacting those domains each day.  And that number has been stable over the past two weeks.  So right now there are still - historically, 11.4 million PCs infected with this.  Right now three million PCs are actively contacting these bogus domains.  I mean, these are wacky domain names that no regular user is going to be contacting. 



LEO:  So these are - they're basically botnets.



STEVE:  Yes, this is a botnet.



LEO:  They're creating a botnet at that domain.



STEVE:  Yes.  Well, it's a botnet that is updating itself and mutating by using these - by essentially downloading updates to itself at these domains.  And so it's really, they've escalated this cat-and-mouse game to the point that it is necessary, in order to block it on a given day, you need to prevent accesses to 50,000 domain names.  You miss one, and these things are able to contact that one that you didn't block.



LEO:  Can they tell from looking at the code what the domain names will be?  I mean, is it algorithmic?  It must be.



STEVE:  I don't know.  I can't say definitively.  I haven't looked at it.  But, I mean, certainly that's what it's doing in order to do it.  I just don't know what it's basing it on.  And it seems to me somebody who gets the code and dissects it should be able to figure out the next set.  The problem is it's just a problem of numbers.  They realize that each day having the worm check a different 250 domains is - that's blockable.



LEO:  Right.



STEVE:  Each day having the worm check 50,000 domains, that becomes a real difficult problem, to go and register, preemptively register 50,000 domains, and have that be a moving target over time.  So, I mean, you can really see how this thing has escalated.



Now, interestingly, what happened with the B variant, which of course came between A and C, the B variant added a trick.  And as I said at the top of the show, it's the thing that caused Microsoft to say whoops, because the B variant spreads through open network shares and also weakly protected systems by trying 240 common passwords.  It basically is able to use peer-to-peer technology within a LAN in order to use network sharing in order to spread.  And it's also able to propagate through USB memory sticks by infecting the autorun.inf file of a USB memory stick.



LEO:  Well, now, that's convenient.  We're talking about Autorun today.



STEVE:  Well, exactly.



LEO:  Yeah.



STEVE:  So the problem is that, if you had this thing on your system, and you inserted a memory stick, it can copy itself to the memory stick, alter the autorun.inf, or create one if there isn't one.  Then you go to a different Windows machine and stick this in.  Well, if the owner or corporate IT, for example, had configured Windows Autorun so that USB sticks, that is, removable drives would not autorun, it turns out that feature of Windows was broken until February.  Microsoft knew about it, but they did not push out the patch for it.  You had to go get it manually, which few people did.  They only pushed them out for Vista and Server 2008.  So what we're going to talk about here in a second is the nature of their fix and why, believe it or not, Microsoft still hasn't got it correctly figured out.  Their own documentation misses a critical feature which can cause this thing to even now still auto execute network and USB.



LEO:  Okey-dokey.



STEVE:  I did want to share a little, before we get into the main content here, a fun little note.  This is actually not a success story, but rather a listener of ours who wanted to share with our listeners how he's using SpinRite added to what he called his "tools of hard drive paranoia."  He said:  "I've been listening to Security Now! for a little over a  year and own a copy of SpinRite.  I have used it to recover some of my friends' computers, but have not had a critical issue of my own.  I now have a single internal drive, a front-loading removable SATA bay, and my Drobo.  I run SpinRite on my internal and backup drives quarterly, give or take.  I do a full backup manually every weekend, which I store offsite, and run Carbonite on my system drive.  And every disk in my Drobo has been tested by SpinRite prior to being installed, as well as the spare disk I keep around for replacement if any of them should fail."



LEO:  This person listens to a lot of the TWiT network, I think.



STEVE:  He does.  "It is easy enough to set SpinRite running before I go to sleep, and every time so far wake up to 'No problems detected.'  I just thought I'd toss out my total backup strategy.  I thought it might be nice for other listeners of Security Now! to hear how SpinRite can be used in connection with other programs to protect them from data loss."  And you'll notice that his friends are having problems because they're not doing anything in terms of preventative maintenance.  But he's using SpinRite in a preventative maintenance mode.  Every quarter he'll let SpinRite have the drive overnight and just dust it off and keep it running correctly.



LEO:  So that does make sense to do that?



STEVE:  Oh, absolutely.  Oh, yeah, yeah.  We keep hearing, I mean, the reports we get of, like, critical distress are because SpinRite wasn't run until the system would no longer just - it wouldn't even come up anymore.  And then SpinRite was able to fix it.  Had SpinRite been run, it would preemptively prevent this kind of problem because it's able to see sectors and detect sectors which are becoming problematical before they become completely uncorrectable, unreadable.  And it's able to work with the drive to say, okay, here's the data you want.  Give me a new sector to put this in, and we're going to take that existing sector out of service.  So, I mean, it really, truly is a preventative maintenance tool.



LEO:  That's very cool.  That really was your intent, more than a data recovery tool, was a maintenance tool.  Or maybe not.  I shouldn't put words in your mouth.  I always thought of it as a maintenance tool.



STEVE:  Well, it is, except I don't expect people to buy it that way.



LEO:  Right, right, right, right.



STEVE:  No one's going to buy it typically...



LEO:  Until they need it.



STEVE:  ...until they need it.  Unfortunately, it can be too late.  And so everybody who then discovers it as a consequence of having it save them in a time of need, then they have it, and so they use it quarterly, and they never have problems again.  So, but it's much more difficult to say, oh, buy this because it'll prevent problems.  I mean, it really will, and it does.  But that's a tough sell, which I recognize.



LEO:  Hey, we just got a big box in the mail.  The new Mac Pro is here.  This is what we're going to use for our new streaming setup - $5,000 worth of Nehalem processors.  But look at the corner; look at the corner on this box.  It came a little - it's crumpled.  So I'm a little nervous.  We're going to do - right after, those of you watching live, we're going to do, right after the Security Now! ends at about 1:00 o'clock Pacific Daylight Time, we will do - which is 4:00 p.m. Eastern - we will do an unboxing, and I'll set this thing up, and we'll see if it boots.  Always an adventure.  You never know what's going to happen.  All right, Steve.  We've seen that Microsoft did it wrong.  Is it still doing Autorun wrong?



STEVE:  Well, the technology appears to be correct.  Their documentation for it is not complete.  And it's not complete in a way that's going to probably get most people.  Okay.  So a little bit of background here.  As I said before, this was all a consequence of a problem that Microsoft realized they could not leave up to the user to go and fix because users would not.  They recognized there was a problem with Autorun not preventing running, which was the nature of the problem, is literally you could do all the configuration correctly, and it just was broken.  Quoting from the CVE, the Common Vulnerabilities and Exposures database, they said, quote, "Microsoft Windows does not properly enforce the Autorun and NoDriveTypeAutorun registry values, which allows physically proximate attackers to execute arbitrary code by, one, inserting CD-ROM media; two, inserting DVD media; three, connecting a USB device; and, four, connecting a Firewire device.  Then they have, five, allows user-assisted remote attackers to execute arbitrary code by mapping a network drive; and allows user-assisted attackers to execute arbitrary code by clicking on, six, an icon under My Computer/Devices with Removable Storage; and, seven, an option in an Autoplay dialogue related to the autorun.inf file."  I mean, it's just, like, really bad.



And US-CERT, the Computer Emergency Readiness Team, says, quote, "Malicious software such as W32.Downadup is using Autorun to spread.  Disabling Autorun as specified in the CERT/CC Vulnerability Analysis blog is an effective way of helping to prevent the spread of malicious code.  The Autorun and NoDriveTypeAutorun registry values are both ineffective for fully disabling Autorun capabilities on Microsoft Windows systems.  Setting the Autorun registry value to zero will not prevent newly connected devices from automatically running code specified in the autorun.inf file.  It will, however, disable media change notification messages, which may prevent Windows from detecting when a CD or DVD is changed.  According to Microsoft, setting the NoDriveTypeAutorun registry value to hex FF, quote, 'disables Autoplay on all types of drives,' unquote.  Even with this value set, Windows may still execute arbitrary code when the user clicks the icon for the device in Windows Explorer."



So this has been a big problem.  And the problem is that corporations depend upon disabling Autorun by group policy, where you just blanket all of the machines on the corporate network with a, okay, do not run programs from when CDs are inserted, when drives are mapped, when removable drives like a USB thumb drive is stuck into the machine.  Do not run.  And Microsoft has provided that functionality forever in Windows, and it's always been broken.  So what happened was, when Downadup, the Conficker worm, began to spread this way, Microsoft last month thought, uh, whoops. 



LEO:  Yeah.



STEVE:  So but the mistake they had made was when they found this problem - and they knew about the problem much longer ago, last year this came up - they thought, well, the problem is, if we fix this, then things that people are doing now which is in contravention of their stated desires, meaning that network shares will still run, for example, well, maybe they're depending upon that, even though they told Windows they don't want that.  And so if we go and just fix this in a security update, it'll change that behavior.  So we're only going to do that automatically for Vista and Server 2008.  Anybody on earlier machines, well, we'll hope they upgrade to Vista.  Hmm.  So...



LEO:  That's the solution.



STEVE:  So then when Downadup...



LEO:  You really ought to upgrade.  You ought to buy a whole new version of Windows.  That'll fix it.



STEVE:  Yeah, just hold on for Windows 7, there you go.



LEO:  Oh, geez [laughing].



STEVE:  So they said, okay, well, that strategy is not working.  So we're going to have to push this out to everybody.  So in February they did that.  The problem is that it is, because of the nature of the way this was done, it ends up being extremely complicated because then they said, well, the problem is, if we push this out, and the behavior changes so that it's now correct, that may break things in a way that people don't want.  So we're going to add another registry key to the already convoluted registry key that we'll talk about in a second, and which is still not documented correctly, called Honor Autorun Setting.  Which they will default to a 1, meaning true, meaning yes, honor the Autorun setting which we have now fixed so that it really works.  But in doing so it may have broken some things.  So you now have the option of turning that off, if you want the pre-fixed behavior which sort of worked, but not really.



LEO:  Okay.



STEVE:  Okay.  So what we have now is we have a key in Windows, in the Windows Registry, which is called - I'm looking for it here in front of me, and I can't find it.  Oh, there it is.  I've said it many times, NoDriveTypeAutorun.  What this means is it's saying do not autorun for specific drive types.  And unfortunately, the types that you don't want to autorun for are encoded in bits in the value of this registry key.  So, for example, the 1 bit in the value disables Autoplay on drives of unknown type.  And it's not clear why, but the 80, the hex 80 bit does the same thing.  So, like, this is a 1 byte that is an 8-bit long value.  So the first bit and the last bit both have the same definition.  And they are always both set to 1, if you want to disable drives of unknown type.



And I don't know what unknown type drives are because all the other bits pretty much cover all the types I can think of.  For example, there used to be the 2 bit, that is, the second from the lowest bit, stood for NoRootDirectory.  But that's apparently been deprecated.  They no longer use that bit for that.  But they didn't assign it to anybody else.  They just said, well, we're just not going to have that bit defined that way anymore.  And I'll explain a little bit more about how these bits are addressed in a second.



But the hex 4 bit, which is unfortunately the third bit from the right, the least significant bit, that stands for, if it's set, you disallow removable drives.  Now, that's the key bit, for example, for a USB.  And it turns out that Firewire is also obviously a removable drive.  So USB and Firewire drives are disabled if the hex 4 bit is set.  Fixed hard drives are disabled by the hex 8 bit, which is the fourth bit from the bottom.  Network drives, that is, drives over network shares, and this is key to what was broken before in the previous, the pre-patched version.  You could tell it you wanted nothing to execute, and network drives still would.  Now they won't.  But you need to set this bit for that to be true.  CD-ROMs are governed by the 20 hex bit, RAM disks by the 40 hex bit.  And as I said before, talking about the 1 hex bit, the 80 hex bit also disables drives of unknown type.



So this is really complicated.  The good news is, if you just want them all disabled, that is, all bits on is a hex FF because that's a value of 255, which is what you get if you add 1, 2, 4, 8, 16, 32, 64, and 128, meaning those are the decimal values for each of the bits.  You add those all together, that's 255, which is one less than 256, which is the total number of possibilities of bits in a byte.  So if you set it to FF, Microsoft says that disables everything.  Unfortunately, they're wrong.



LEO:  Oh.  You'd think they'd know.  It's their operating system.



STEVE:  You'd think they'd get it right, yeah.  Well, okay.  So the problem is there are two places in the system, well, at least two, two or more, where this NoDriveTypeAutorun registry key can be.  They only talk about it in the registry under HKEY_LOCAL_MACHINE.  And it's HKEY_LOCAL_MACHINE\software\Microsoft\Windows\CurrentVersion\Policies\Explorer.  And under there you will find NoDriveTypeAutorun.  And this is what they talk about.  They completely forget to talk about the CURRENT_USER branch of the registry.  It's mentioned nowhere.  And it overrides any setting you have in the LOCAL KEY branch of the registry.  So you can follow their instructions, go there, set this key under HKEY_LOCAL_MACHINE and all the other stuff, software\Microsoft\Windows\CurrentVersion\Policies\Explorer, to FF, and think, okay, I got it.  And you don't.  Because if this key also exists under the CURRENT_USER, and the same subtree under the CURRENT_USER key, it takes precedence.



Now, I thought, okay.  Is it the case that LOCAL_MACHINE could override the setting by bit?  Are the bits OR'd for disabling where, like, so LOCAL_MACHINE setting would be a policy that takes precedence over CURRENT_USER?  Anyway, I did a whole bunch of experimenting, and I've confirmed that that's not the case, that bits are not AND'd or OR'd or anything.  If the key exists under the CURRENT_USER tree, it completely replaces anything you have specified under the LOCAL_MACHINE, which is the more global-applied key.



Now, the reason people may have this thing under their CURRENT_USER is the very popular Tweak UI little applet for Windows.  Tweak UI has - one of the settings is to make it very simple to disable or enable Autoplay drive types.  And if you've ever used Tweak UI or anything else where you've explicitly enabled and disabled, then those changes are always put under the current user.  Which means you will have a NoDriveTypeAutorun registry key.  And nothing that you do following Microsoft's instructions under the HKEY_LOCAL_MACHINE registry will have any effect at all.



LEO:  Okay.



STEVE:  So bottom line is, I did create a short little URL, a little SnipURL to Microsoft's page which explains part of this story, the part that they do explain.  And so that's SnipURL.com/snautorun, as in Security Now! Autorun.  And if you put that into your browser right now, Leo, it's SnipURL.com/snautorun, for people who are listening and just want easy access to this page.  It's also support.microsoft.com/kb/967715.  And that explains the part that Microsoft explains.  It completely forgets to talk about the fact that any presence of this key under CURRENT_USER overrides the key under HKEY_LOCAL_MACHINE.



Now, I assume most users just want to disable everything.  It's certainly possible due to this bit-level granularity Microsoft designed into the design of this NoDriveTypeAutorun registry key.  It's possible to deliberately enable specific behavior.  If, for example, you wanted not to allow fixed drives, removable drives, unknown drives, RAM disks, but, for example, you for some reason wanted to allow CD-ROMs, or you wanted to allow network, network shares autorun, you can go in and design your own value for this key to specifically not disable those.  I imagine probably most listeners just want to know that they've got everything disabled.  So setting this value to FF will do that.  And I would recommend, however, setting it in the CURRENT_USER branch of the registry, not the LOCAL_MACHINE.  Or set it in both.  But definitely CURRENT_USER because if anything ever came along and did  put a more permissive value under CURRENT_USER, it would completely override what was already there under LOCAL_MACHINE, and you would not get the protection that you're expecting.  So that's the whole story on this mess.



LEO:  So the CURRENT_USER overrides everything else.  It's like - you'd think it'd be the other way around, that the higher level one would override the lower level one.  But I guess you could have - that way you have per-user settings, I guess.



STEVE:  You have per-user settings, exactly.  And so if it's not specified under CURRENT_USER...



LEO:  Then it goes up.



STEVE:  ...then the LOCAL_MACHINE, then the global settings specify.  Now, what's interesting is the defaults that Microsoft has for this.  XP, Vista, and Server 2008 have a default setting of 91 in hex.  Hex 91.



LEO:  Hex 91.



STEVE:  Yeah.  So that's XP, Vista, and Server 2008 have a 91 setting.  What that means is, if you dissect these bits, then unknown drives and network drives are disabled.  Except they weren't until you patched it because...



LEO:  It just ignored that setting.



STEVE:  Exactly.  It ignored that setting.  And the default explicitly allows removable drives, fixed drives, CD/DVD-ROM, and RAM disks.  Now, that's the normal behavior when you get a brand new XP out of the box.  You stick in a CD, and it launches the CD.  You stick in a thumb drive, and it launches anything that you have in your thumb drive.  Unfortunately, as we now know, worms are taking advantage of this, copying themselves.  I mean, it's very much like the old days of floppy disks and the so-called "sneakernet" where viruses would infect a floppy and just wait around for you to stick that floppy into a different machine, and jump from the floppy into the machine.  That's how viruses proliferated prior to the Internet existing.  What's interesting is that Windows 2000 and Server 2003 have a hex 95 as their default.  And it disables unknown drives, network, and removable drives.



LEO:  Which is something you would really want.



STEVE:  Which is really what you want.  So essentially Windows 2000, Server 2003 did by default disable unknown drives, network drives, and removable.  But Microsoft deliberately made this more permissive under XP, Vista, and Server 2008.  They by default allowed removable drives to autorun rather than not.  2000 and Server 2003 would not run removable drives.  So this problem would not have really existed had Microsoft kept that security higher.  But they decided, well, for whatever reason, we want removable drives to have Autorun enabled by default.  So they changed the 95 to a 91, which changes the 4 bit in the hex value, which governs the enabling or disabling of removable drive Autorun.  So that's the whole story.  We've all got, if we've been patching our machines, we've got the technology working.  It's now necessary to make sure that you've got FF bytes under...



LEO:  That's every bit, and that means they're all disabled, every possibility.



STEVE:  Every bit set, everything disabled, yes.  But you want to make sure you do it in CURRENT_USER, which Microsoft unfortunately doesn't even talk about, because otherwise it's ignored.  If you change it in LOCAL_MACHINE while you have a more permissive entry under CURRENT_USER, the CURRENT_USER one takes over.



LEO:  If somebody wanted to be industrious, you could just write a little registry, just a little reg file that would set this, that would create the key if it doesn't exist and set it to FF.  That would be...



STEVE:  Yes, actually it's trivial to do that, to do a little registry file.  And because it's easy, such a registry file would instantiate the keys if they didn't exist, and would overwrite them even if they did.  And so you'd want to set them both to just FF.



LEO:  Simple enough.



STEVE:  Yup.



LEO:  Very good, Steve.  Again, you can find that discussion at SnipURL.com slash - what was it?



STEVE:  SNautorun.



LEO:  SNautorun.  Which is Knowledge Base article 967715.  But the best thing to do is go to GRC.com.  They've got show notes there.  We also will have them on our wiki, wiki.TWiT.tv.  Steve's got a transcript of every show, all 187 of them, at GRC.com.  He's also got 16KB versions there.  And while you're there, pick up a copy of SpinRite if you don't already have it.  Be proactive.  Don't wait'll you need it.  Get it now.  And also lots of other free stuff like ShieldsUP! and all his free utilities and Wizmo, which I always love.



STEVE:  And more good stuff coming soon.



LEO:  Coming soon, yeah.  Can't wait to see CryptoLink.



STEVE:  I'm working hard on the DNS benchmark that I think is really going to be popular.



LEO:  GRC, short for Gibson Research Corporation, GRC.com. 



STEVE:  And I will remind our listeners that next week is a Q&A Listener Feedback episode.  So by all means, I really love receiving feedback and knowing what you guys are thinking and what questions you have.  That's GRC.com/feedback.



LEO:  There you go.  Thank you, Steve.  Have a wonderful, secure week, and we'll see you next Thursday...



STEVE:  Thanks, Leo.  Talk to you then.



LEO:  ...for Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#188

DATE:		March 19, 2009

TITLE:		Listener Feedback #62

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-188.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 188 for March 19, 2009:  Listener Feedback #62.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now! with Steve Gibson, the show that talks about privacy, security, everything you need to know to stay safe online, and does it with no apology whatsoever, in the absolutely most geeky way possible.  Steve Gibson's here.



STEVE GIBSON:  We do have - I see as I'm running through the Q&A sometimes that people will say, well, I had to read the transcripts on that one three times before I really knew what you were talking about.  But now I do, so.



LEO:  Well, I think that there's plenty of places you can read kind of fluff and generalized stuff about this stuff.  But there's not that many places where you can get the real goods, especially not that many people like you who can really dig into it, understand it, and then deliver it.  So...



STEVE:  And, yeah, I don't really have a choice.  I mean, I truly love this stuff, and I get excited about it.  And it's the details that are really interesting, so.



LEO:  "It's just the way I'm made," says Steve Gibson.  "I don't have a choice."  Well, what are we talking about today?



STEVE:  This is a Q&A episode.  Yet there's so much other stuff that I need to talk about that I only put together 10 questions rather than our normal dozen.  And we may not even get to all of those.  So I put the good ones at the front because...



LEO:  So in other words, this show is going to go down, straight downhill.  Listen now, because the rest of it's...



STEVE:  Actually it was hard because there were lots of really good questions.  So let's just try to move through it quickly and so we can get to everything.  But there's a lot that I want to share with our listeners that happened this week, in the intervening week since we last spoke to our listeners.  And we've got great Q&A stuff, too.  Some, well, PayPal seems to be a never-ending theme, and...



LEO:  I see we have the PayPal Horror Story of the Week.



STEVE:  Oh, this one, Leo, I'm just - you're not even - in fact, well, you ought to read it first when I'm talking about other stuff so you can prepare yourself for...



LEO:  It's that bad my jaw is going to drop?



STEVE:  Oh, it's over-the-top horror.



LEO:  Oh, I like  that, though.  I like being surprised because you can hear me catch my breath, go [gasping], "What?  Oh, my god."



STEVE:  Oh, it's - this is just unbelievable.



LEO:  Also a battery breakthrough from MIT.  I'm very excited to hear about this.  I don't know what you're going to say because I haven't - just before we started, Steve said, "Have you heard?"  And I said no.  So we're going to find out about that.  Or let's start with the tech stories because there's a lot of them, tech news, errata, that kind of thing.



STEVE:  Well, we have, yeah, we do have, we have security news and a bunch of stuff.



LEO:  Right.



STEVE:  So we were talking - we've mentioned several times in the past about the problems with security vulnerabilities in Adobe Reader.  And some people indicated that, well, just switch over to Foxit.



LEO:  Yeah.



STEVE:  Oops.



LEO:  What?



STEVE:  Turns out...



LEO:  No?



STEVE:  ...that Foxit has - the Foxit Reader has multiple security vulnerabilities, which they have just acknowledged and fixed.



LEO:  Well, now, last week we talked about this, and you mentioned there was a patch.  Is this over and above what you mentioned last week?



STEVE:  Well, what I had heard last week was just sort of some rumblings that maybe switching to Foxit wasn't going to fix you up any better, that either the same problems or different problems might be present.  It turns out that these are different.



LEO:  Right.



STEVE:  But these are remote execution code problems that involve specially crafted PDFs.  And it turns out Foxit has a huge following.



LEO:  Oh, yeah.  I love it.



STEVE:  I think it's 20 million copies are in use now?  So it represents enough of a target that you could imagine bad guys saying, well, let's send some PDF files, small ones, off in spam mailings, and we're going to catch some people.  So, and essentially the exploits are known.  Proof-of-concept code is out on the Internet and available.  So it's probably not even a matter of time before this thing gets exploited.  So I wanted just to notify any Foxit users to go back to the Foxit mothership and update their copies, or make sure that they are currently using the most recent version because there has been, just in the last week, an update to fix a number of remote code execution exploits, stack-based buffer overflow.  I mean, the traditional problem that really all software really seems to have when it isn't written with just an absolute focus on security as one of the main things.



And you can imagine that the Foxit guys, like all other programmers, are more focused on getting it to work and getting their particular thing going in it than they are in absolutely thinking about every possible way it can be exploited.  And as a developer myself, I can vouch for the fact that it's very difficult to get your head into that mode.  I mean, it's coming at your software from a direction that you fundamentally don't - that you're fundamentally resistant to.  So, I mean, the bad guys have an advantage because they have no stake in this thing operating correctly.  Their stake is in finding where it doesn't.  And so it's just - it's very hard to make code bulletproof, which is why week after week we keep running across one program or another that's got a problem.



LEO:  I'm looking.  I think this is the update that I mentioned last week, which was Foxit 3, Build 1506.



STEVE:  Yes.



LEO:  So if you get the latest Foxit, don't freak out.  There's not been another.  These are the three flaws, the buffer overflow flaws - yeah, okay.



STEVE:  Yup, exactly.



LEO:  Yeah, yeah.  



STEVE:  You mentioned that last week?



LEO:  I did.  But it was in peripheral - it was peripherally that they had - remember I said they had problems, they fixed those problems with Build 3, they say it's not the same, what was it, big JPEG [JBIG2] issue that the Adobe people had.



STEVE:  Right, it's not the same, although they did have a big JPEG [JBIG2] issue, but it was different from the...



LEO:  Right, different one.  Because they use their own libraries.  They don't use the Microsoft or the Adobe libraries.



STEVE:  Meanwhile in security news, the BBC did a rather controversial thing that upset a lot of security analysts and specialists.  A guy named Spencer Kelly that does security-related work for the BBC went onto an Internet chatroom and purchased on behalf of the BBC a 22,000-PC botnet.



LEO:  Oh, my goodness.



STEVE:  For the purpose of using the botnet to actually do bad things.



LEO:  What?



STEVE:  Well, I mean, not against people.  For example, they set up two email accounts, a Hotmail and a Gmail account.  And he used the botnet to send spam through the botnet, from the botnet to those two email accounts.



LEO:  Oh, just as a test.



STEVE:  Yes, they were spamming themselves.  He also used the botnet to aim a denial of service attack at a cooperating security firm that confirmed that, yes, 22,000 machines it felt like were attacking them.  Then, when all this was done, they recorded it, made the TV show and everything.  They changed the screensaver of those 22,000 machines to alert the owners...



LEO:  Hello, this is the BBC.  You have got a problem.  What a surprise.  Oh, my goodness.



STEVE:  They changed the screensaver to turning it into an alert that would let them know that their machine was infected with a malicious agent.  Which, I mean, I didn't see what the alert said.  But presumably they were saying, "This is the BBC.  We don't know where you are on the planet" - because of course they don't.  These are 22,000 machines located anywhere, that they had control of as a consequence of purchasing this botnet from a chatroom.



LEO:  Did they say how much they paid for the thing?



STEVE:  I didn't see a price.



LEO:  Probably didn't want to mention it.



STEVE:  But they called it an "inexpensive botnet" because...



LEO:  Well, it's not that big, yeah.



STEVE:  Aw, 22,000 machines, what can you do with that?



LEO:  Oh, geez, Louise.



STEVE:  And then, after changing everybody's screensaver to this warning notice, they shut the botnet down.  They used the botnet to remove itself, essentially, well, to shut it down, having taken control of it.  And this notice helped, aimed people at some help that would tell them how to disinfect their machines from this.  The problem is that it violates all kinds of laws.



LEO:  It's illegal to do what they did.



STEVE:  Yes.  It's illegal, I mean, they modified, without permission, the settings and operation of these 22,000 machines.  Even though their intentions were good, hopefully the result was good, you cannot do that.  Even if you're Robin Hood.  It's just not okay.  So it's caused a big kerfuffle.  And they say, well we talked to our attorneys first.  We would never have done this if we hadn't talked to our attorneys first.  But people who are in the know of such things in terms of where this falls says, eh, not so good.  So...



LEO:  Well, I mean, it's pretty obvious it's not so good.  You'd think they would, I mean, forget the attorneys, what about the ethics of it?  I mean, you're modifying somebody's computer.  Now, admittedly, it needs to be modified.  But we've seen this happen before.  We've seen kids write viruses that delete other viruses.



STEVE:  Like antivirus viruses, yes.



LEO:  Yeah.  And that's never a good idea.



STEVE:  Well, it's just not okay.  It's the old "two wrongs don't make a right," even if your wrong is intended to be for good.  I mean, what if it did something bad?  What if, by mistake, they had hurt these?  So, I mean, you really are opening yourself to some liability.  And I wouldn't be at all surprised if, given the grayness of this, if somewhere among those 22,000 people, somebody was really upset by what the BBC did to their machine without their permission.  I mean, they would feel the BBC was in my machine, gained access to my machine and made some change.  It would almost have made more sense, frankly, for them not to acknowledge that they had used a bot in anyone's machine to do this, if they were determined to do it.  It really does seem to me like, well, again, their heart was in the right place, but ooh, boy, are you asking for trouble.  And I'll keep an eye on the story to see whether in fact anything further is done.  It would be sad if the BBC were hurt, but that's the nature of litigation in the world today.



LEO:  The other side of this is everybody knows these exist.  Everybody knows how they operate.  They have - it really is almost a little sensationalistic.  It's not - you don't need to do that.  I guess to prove the point that it's so easy to buy them.



STEVE:  Well, that's a very good point.  What did they achieve by demonstrating that they got - maybe they demonstrated that anyone in a chatroom can buy one of these and do the following things.  So...



LEO:  I guess that's not such a bad thing to let people know.



STEVE:  Today I'm announcing the result, I don't know how much of the email dialogue you saw back and forth with myself and the other judges of the YubiKing Award.  That was in the last couple days.  You may remember that Yubico, the makers of the YubiKey, in preparation for the RSA conference coming up next month in April of 2009, they wanted to create an awards process to encourage people to do things with the YubiKey, and that all the people in their wiki, and there were a couple of hundred people in the wiki, and then a panel of three judges, of whom I am one, or which I am one, would also have a vote.  Well, as it turns out, the top two wiki-voted entries were both by companies who had purchased a whole bunch of YubiKeys.  And they used their YubiKey inventory to vote for themselves.



LEO:  Oh.  Oh.



STEVE:  So there were, like, it was ridiculously lopsided.  I mean, the only solutions that got, like, a whole ton of votes were the two companies that had purchased a gob of YubiKeys.  And the way the voting worked, you had a - the YubiKey authenticated you, so there's no way to vote twice unless you had...



LEO:  A whole gob of YubiKeys.



STEVE:  A whole gob of YubiKeys, and just stuck them in one after the other and touched the little button and voted for yourself.  So not surprisingly, those companies thought that their applications of the YubiKey were better than anybody else's, and they were there to stand behind that belief...



LEO:  Oh, that's so funny.



STEVE:  ...by inserting all their YubiKeys and voting for themselves.  So we discounted all of that, of course, because that really wasn't representative of what seemed good.  There are three winners, sort of in different categories.  And one of them is so cool.  I mean, if nothing else came out of this other than all of our listeners finding out about this one, then it's been worth everything.



So the first is a really interesting sort of cloud-based app or system called Maventa, M-a-v-e-n-t-a.  What they've done is they're working to essentially come up with a secure electronic invoicing system.  They make the point that still today in this day and age, despite the fact that we have the 'Net, and everybody's plugged in and chatting and talking and sending email all over the place, the process of invoicing is still paper.  That is, invoicers print out their payables and put them in envelopes and lick them and put them in the mail, and they trundle across the world wherever they're going, and then they're received, and they're opened up and logged into payables systems where then these things get batched, and checks are written, and that sent back.



And so this company says, okay, this is dumb now that we're not doing e-invoicing.  And there is of course lots of problems.  I mean, you need to do this securely.  One of the things you need is to be able to sign these invoices, and you really need good authentication.  So the way Maventa is using the YubiKey is that a company is able to submit electronic invoices to them, and they go there in a batch.  Then you visit their website and view all of the invoices that you're sending out and agree that that's all correct.  And then you use the YubiKey to - you are the authenticated invoicer for your organization, so you use the YubiKey for that one batch in order to sign them, authenticating them.  And then Maventa turns around and forwards these electronically to the recipients of the invoices.



So anyway, it's a typical, state-of-the-art, this is how, this is like what the future is going to be where we use multifactor authentication, strong authentication, provided in this case by the YubiKey, an inexpensive, lightweight, easy-to-use, deployable token to provide that kind of required authentication that a system like this needs because you certainly don't want any major breaches in a system like this, and authentication of these transactions is required.



The second winner is a company called Collective Software, who has essentially come up with a multi-armed authentication solution sort of for enterprise-class Windows networks.  And there's, like, a bazillion of them.  So any company, this thing integrates with Active Directory for companies that are using Active Directory.  It's called AuthLite, A-u-t-h-L-i-t-e.  And if anyone - and they grabbed that domain, which redirects to the proper AuthLite page on their software site.  So if you just put www.AuthLite.com, that'll bounce you over to Collective Software's page.  And I've looked through it.  It looks very nice.  I mean, essentially they've got the whole Windows logon, Windows authentication, remote network VPN authentication, the whole package associated with Windows enterprise-class networks, implemented with the YubiKey as the multifactor token for logon.  And so it's a soup-to-nuts solution, a company that wanted to increase - that wanted to use the YubiKey for Windows authentication.  They can do that now with this AuthLite solution.



Okay.  And the final winner of the YubiKing Award is a neat guy in Switzerland who - it turns out the company he works for was part of - is in the same building, coincidentally, and Stina didn't even know this until she looked him up after the panel, the judges, including myself, yesterday went back and forth about a bunch of these password sort of solutions and decided this was the guy.  I mean, his was - there's a bunch of honorable mentions I'm going to run through real quickly about other password solutions that people may already be using which are now YubiKey enabled.  But this was such a cool solution that I lobbied hard for this.



The product is - well, it's not even a product.  It's free.  He calls it KeyGenius.  And again, you put "keygenius" into Google, and you'll find it.  The way it works is slick.  You create an add-on for your browser, so it uses a browser add-on, something that is running in your browser, watching you log into sites.  And you essentially, you go to his server, and you create a - you tell his server what the password for any given site is that you want to log into.  You don't tell - you don't have to create an account.  You don't have to create an identity.  You don't tell it what your username is, only what the password is for a given site.  And you authenticate that then with the YubiKey.



So, and then he does a real-time - and this is in one-time password mode, the strongest mode of using the YubiKey.  Then, anytime in the future, when you're online, and you are at that site where you're being prompted for the password, you just touch your YubiKey.  So what goes into the password field is not the password for the site, but the one-time password that will never be repeated by the YubiKey.  That's typed into the password field.  The add-in that is running in your browser notices, it sees you entering a YubiKey-looking password.  And so without you doing anything, it goes, it connects to his server and uses what you just entered to authenticate you because you've got that YubiKey.  It looks up the matching password that you have logged into his site before and, on the fly, swaps it with your YubiKey entry in the password for the proper password, and then hits Enter.



So essentially what this means is that you can take your YubiKey with you anywhere.  This is secure login, for example, even in an insecure caf mode because, even if there were a keystroke logger, it would be logging the YubiKey keystrokes, which is just fine because it's never valid again, thanks to the YubiKey being one-time password.  It would never see, the keystroke logger would not see the actual password because that's never typed at your keyboard.  The add-on swaps it behind the scenes and then submits the login form.  So it's just a very clever, nice solution.  It's free.



The caveats are that this is just, at this point, it's just some random guy that loved the YubiKey and wrote this app because, you know, and set up a server just because he wanted to.  So it's not clear that you can count on this always being up.  I'm hoping that bringing some attention to him and this solution will - maybe someone will come along and buy it from him and turn it into an industrial-strength solution.  I mean, it's just a - it's a clever, simple, nice way of using the YubiKey in a function which is inherently mobile, that is, you don't have to have it, you don't have to carry anything with you.



He's got a nice FAQ where he asks himself all the questions that people who are worried about this in all the different ways you might be, like, well, wait a minute, I'm giving you all my passwords.  And he says, well, true, except you're not giving me any of your userIDs.  I don't know anything about you.  I don't know your email address.  I don't know your name.  I know nothing.  All I know is this one aspect of authentication, not the other.  So there is no way that he's able to take advantage of that.



Everything is encrypted.  If you read the FAQ, it's clear that this guy understands security.  He establishes an encrypted connection between your browser and his server, so all of that is secured.  All of the passwords are stored encrypted at his end.  And even if someone did get them, it doesn't help them because they don't know anything about what they're associated with.  There's no knowledge of - there's no association to you or to the sites where they would be used.  So - but they're encrypted anyway, so it wouldn't - they wouldn't be able to do anything with the information if they were able to get it.  Anyway, it's neat.  I played with it, as did the other judges.  And we agreed that this guy deserves the YubiKing Award for having just created a nice, interesting, new approach for using the key.



I also wanted to mention that the product SoManyPasswords.com now is YubiKey enabled.  LastPass is YubiKey enabled.  KeePass, which is a very popular password management utility, is YubiKey enabled, as is Password Safe.  So all of those were also entries because they are YubiKey capable.  They just, I mean, they did sort of the normal thing you would expect with a YubiKey.  So we wanted to acknowledge them, make sure people knew that they were able to use their YubiKeys with them.  But didn't quite reach the level of something, a new, cool application that we thought was really clever.



I also wanted to mention that Joomla!, Drupal, and Enano are all now also YubiKey enabled, those content management systems.  WordPress blog has a plug-in.  There's an Apache module now for using the YubiKey for Apache server authentication, a Mac OS log-in, Google Apps you can now use the YubiKey for authenticating yourself, and just a bunch of other things.  So overall the YubiKey is continuing to gain traction and is finding homes all over the place.



LEO:  You deserve a lot of credit for that.  I think if it weren't for you running into Stina at RSA a year ago, I don't know how YubiKey would be doing at this point.  Have they made the move to the U.S. now?  Are they in the...



STEVE:  I don't know actually where they are.  I have not kept track.  There's one last thing I wanted to - two last things I want to mention.  One is that there was one really fun entry that I just wanted to mention because it was just great.  The guy called it Yubihome, as in "you be home."  But he uses the YubiKey as his door key.  He didn't win YubiKing Award...



LEO:  As his door key.



STEVE:  As his door key.  It's over on the other side of the door from where the handle is.  He's just got, like, a USB extension cable, the head of a USB extension cable poking out through the...



LEO:  Oh, that's hysterical.



STEVE:  And so he plugs his YubiKey in, and the little ring lights up, and he touches it.  And he's also got a speaker overhead, and it says "Welcome Howard," or whoever his name.  It says, "The door is now unlocked, and you have three new messages."



LEO:  So he somehow tied his lock to a computer.



STEVE:  Well, yeah, he has a motorized lock.  He got a motorized door lock.  And those are available freely.  Companies like Safe House sell those.  So those are for whatever, like security or automated house sort of applications.  And so there is a computer that is at the other end of the USB extension cable, which runs some software that authenticates his YubiKey and unlocks his front door.  So it's clever.  But it's not the sort of thing that everyone's going to go run out and do.  So we wanted to give him an honorable mention as a submission.  And he submitted a video that was really fun, too.



LEO:  Oh, how clever.  That's so...



STEVE:  Now the best news of all.



LEO:  Yes.



STEVE:  They will be announcing next month something that everybody who is using a YubiKey wants, and that is a split personality YubiKey, where a single key can be both one-time password and static password.



LEO:  Oh.  I do want that, very much, yeah.



STEVE:  Yes.  Because so, I mean, it just makes so much sense.  And actually it's more than that.  It's actually a dual personality key where either personality can be any configuration of the YubiKey.  And so the idea would be you touch the circle for one second, and that engages the first personality.  If you touch and hold it for three seconds, it engages the second personality.  And so you could have two different static keys, two different one-time passwords keys, with different secret keys inside.  So for whatever purpose, I'm not sure why you'd want to do that, but, well, for example, one reason is if you were using a third-party server for doing one-time password authentication, yet you still wanted the public side for, like, using the Yubico one-time password server.  Then you would need two different one-time password solutions in a single key.  So they are going to be announcing doubling the functionality essentially of the YubiKey next month.



LEO:  Very cool.



STEVE:  Okay.  So the big news from MIT in the last week appeared in the Letters section of Nature magazine, announcing MIT's, well, two materials scientists, some chemists at MIT, have come up with a major battery technology breakthrough.  What they essentially did was they have come up with a technology for changing the surface crystallization in an otherwise standard lithium ion cell, where the surface is specially prepared to create a much more, effectively a porous to lithium ion surface.  The upshot of this is you can take existing lithium ion chemistry, which is well understood and well developed.  You switch it to using this particular electrode preparation.  And you can now fully charge and discharge a lithium ion battery in a matter of seconds.



LEO:  What?  Charge and discharge in - this is like those ultracapacitors that we were talking about.



STEVE:  Well, exactly.  In fact, in their paper they show the ways in which this technology is similar to ultracapacitors, even though it's entirely different.  I mean, for example, as we know, the ultracapacitor owes its potential for high energy storage by using really high operating voltages.  Now, that's the controversial aspect of an ultracapacitor, and actually it's a problem with its application.  That is, if you were talking about, what was it, 3,500, 35,000 volts of charge, so you need to step up your available charging source up to that level, and you need to step - when you're using the capacitor's stored charge, you need to step the voltage back down to five volts if you're going to be using this technology in a laptop.  So the beauty of using existing lithium ion battery technology is that we understand it, it's mature, fabrication's in place, and the charging and discharging, it's operating at natural use voltages instead of something exotic.



LEO:  Well, how does it charge in nine seconds if it's the same voltage?



STEVE:  Well, voltage and current are different.  So voltage is pressure, and current is flow.



LEO:  Flow.  It would need higher current; right?



STEVE:  Well, and so these guys - oh, yes.  And in fact, the current, the available current is the limiting factor.  For example, you could not - you cannot charge your plug-in hybrid vehicle in 10 seconds because you need too many kilowatt hours of energy.  So a vehicle with this battery technology could technically charge itself up in a few minutes, but you'd have to give it way more than household current.  So what you can imagine is, you can imagine the equivalent of a gas station, but now it's an electron station, where you literally...



LEO:  A tank, you need a tank to fill.



STEVE:  Well, you literally drive your car up when it's near empty.  You have some serious industrial-type connector which looks like some megawatt plug.  You plug it in, and this thing dumps a huge amperage of current into your car.  And in a matter of a minute, just like you're filling your tank now, this thing could recharge your car's next-generation lithium ion battery.



LEO:  That's really amazing.  Now, what about a laptop?  Could you use - I guess you couldn't - could you use it on a laptop?



STEVE:  Absolutely.  I mean, now, we're probably two or three years away from this getting out into the market.



LEO:  Good, because I just bought a laptop.  I don't want to buy a new one.



STEVE:  Yeah.  We're probably two or three years away because, I mean, now, two companies, two producers have already licensed the technology from MIT.  So, I mean, everyone gets it that this is a breakthrough.  I mean, the days of charging up your cell phone or your PDA or your Kindle overnight, that's going to be gone in a few years.  And I can imagine somebody four years from now listening to this podcast, it's like, what?  You had what?



LEO:  All night?



STEVE:  You guys used to have to do that?  That's crazy.



LEO:  This could be a huge breakthrough.  And what I love about this, as opposed to ultracapacitors, is it works with existing battery technology.



STEVE:  Yes, yes.



LEO:  How much of a change is it?  Do they change how they manufacture them?



STEVE:  Well, yes.  Again, this is all in the lab.  And these guys, they talk in this paper, none of the - this is in the press a lot this week.  But all the stuff in the press is just sort of your top-level surface junk, and it didn't really talk about how this works.  So I bought a PDF from Nature of their paper, which is deep in chemistry and material science.  And it talks about how they - what they make this of, that this is a lithium iron phosphate electrode, which they heat to 600 degrees for some length of time, then they raise it to 900 degrees, and they do this and that.  And they understand, being materials guys, that what they're doing is they're changing the surface, the crystalline surface structure at the nano level so that it is far more permeable to ions.  And it's the ionic permeability of the electrodes which have traditionally limited the rate at which you can charge and discharge lithium ion cells.



And they've got charts and diagrams.  And they show, for example, they state in their paper that the typical power rate, okay, so that's not the total amount of energy, but the power rate, the rate at which you're able to take power out of a lithium ion cell, the traditional lithium ion cell, is between 0.5 and 2 kilowatts per kilogram.  So think of it, between half and 2 kilowatts per kilogram.  In their test cells, using their modified lithium ion phosphate electrode, they're able to get 170 kilowatts per kilogram.  So from 2 to 170.



LEO:  Wow.



STEVE:  So it's orders of magnitude.  And that was a full discharge of the battery.  They charged the battery up, topped it off, just like you do any lithium ion battery, although much more quickly, and they discharged it fully in nine seconds.  So they dumped all of the battery power out in nine seconds.  So, I mean, what this means, as you said, you asked for laptops.  We're back again to plugging it in and counting maybe to 10, or maybe to 100.  But, I mean...



LEO:  That's great.



STEVE:  ...no more hours required to charge.  See, right now...



LEO:   But, now, we wouldn't need a special charging station, though; right?  I mean, again, we need extra current to flow that much - or maybe not.  Is a battery, a laptop battery that much current?



STEVE:  And that's my point exactly, is that we're not talking about filling up a car battery.



LEO:  Right, right.



STEVE:  We're filling up a laptop battery, so...



LEO:  You could do it on your standard, whatever it is, circuit.



STEVE:  Well, it will be different charging technology.  So, I mean, it's not like we're going to be able to get new batteries and stick them in our old laptops because that won't happen.  It'll be the next generation of laptop.  It will work only with these next-generation batteries.  And so when you plug your laptop adapter into the wall, okay, the house lights will dim a little bit.



LEO:  That's not good.



STEVE:  But only for 30 seconds.



LEO:  For nine, nine seconds, yeah.



STEVE:  It'd be like running your microwave, where you can sort of, ooh, wow, this is sucking some power out of that.  But in 30 seconds your hamburger is hot.  And in this case...



LEO:  Now, this would also increase the capacity; right?  We should be able to get much longer life out of these; right?



STEVE:  I don't think that's the case.



LEO:  It's not, okay.



STEVE:  Because it's still using - and they don't directly address this in their paper.  And if it did increase the capacity, they certainly would have addressed it.  Because it is using standard lithium ion technology, they just solved the rate at which you can charge and discharge.  Now, the other reason that's important is that, well, first of all, it means that you solved the problem of recharging, given that we actually would create electrical recharging stations the way we have gas stations now.  But say that we stayed with a hybrid model.  The problem with traditional hybrid technology, where you've got a gas engine, an internal combustion engine, is that there are better ways to convert fuel, gasoline, to electricity than an internal combustion engine hooked to a generator.  What you really want is an external combustion engine.  And that's called a turbine.



LEO:  Ahhh.



STEVE:  It turns out that 17 years ago Ben Rosen, who is a very famous venture capitalist - he was the seed money behind Lotus and Compaq and a number of other tech startups back in that era - he decided he wanted to create a hybrid power train for cars.  So he needed a way of converting - he needed two things, just like we do in hybrids now:  a way of converting gasoline to electricity, and a way of storing the electricity.  His solution for converting gasoline to electricity was far more efficient than ours is today because he used a microturbine generator, which had one single moving part, which was suspended with an air bearing and spun at 96,000 rpm.  And so the beauty of this is that you're able - you spin this turbine up.  You feed it gasoline or kerosene or who knows what it takes.  But, you know, something "sene."  Out comes energy with an extremely efficient conversion, much more so than we get with an internal combustion engine driving a generator.



Now, the problem is you've got far more energy than a battery can accept because - I mean traditional batteries, than lead acid or lithium ion.  So you've got too much current.  So he said, okay, we can't use batteries because the idea is we're going to run this turbine on a short duty cycle to recharge something that is able to accept that much energy in a short time.  Then we shut the turbine down.  So instead of running, like, a traditional engine for a long period of time at a relatively low efficiency, the idea is you run it for a much shorter period of time, so your gas mileage is much higher.



What this guy Ben and his team came up with for storing the energy turned out itself to be controversial because he was using a magnetically suspended flywheel which spun, friction free, in a vacuum at 55,000 rpm.  Now, it was cool because you could spin this flywheel up.  That is, a flywheel would accept the energy from the microturbine during the short time it was running, spin it up, essentially giving you storage of energy in a mechanical form.  And then it would work as a generator, dumping its energy into the wheel motors, just as we have with contemporary electric hybrid vehicles.  The problem is, you don't ever want to be in a car accident where you've got a flywheel spinning at 55,000 rpm, a few inches away from your legs.



LEO:  No.



STEVE:  Or the small of your back, or anywhere near you.  And so, I mean, they understood that.  They went to great lengths to make this thing safe, to wrap this thing in shock harnesses and, I mean, literally I'm sure there's like a heavy firewall between you and the flywheel.  But that was the means of storing energy.  They ended up obviously not producing cars.  They made one.  They made a prototype, and the darn thing worked, just like they thought.  I mean, they magnetically suspended flywheels.



That ended up spinning off into a separate company which today spins magnetically levitated flywheels as a replacement for lead acid traditional UPS, Uninterruptible Power Supply systems for datacenters.  And that turbine technology, there's a company called Capstone which they spun off which makes microturbines for all kinds of applications.  So these things never went together in that way.  But now that we've got this kind of lithium ion technology, which can be recharged in, literally, I would say, in a matter of seconds, but we can't source that much energy to it.  But now that we've got it, something like a microturbine-based hybrid suddenly makes a lot of sense because the turbine spins up, does a much more efficient conversion of gasoline to electricity, brings the lithium ion battery back to full charge, and then shuts itself down.



LEO:  That is so cool.  You know, we just bought a hybrid car, Jennifer and I, because she wanted a big car, and the only way I could justify it, it's a Toyota Highlander, is with a hybrid.  But so those are using regenerative technologies.  Do they not use flywheels anymore?



STEVE:  Which?



LEO:  The hybrids, current hybrids out there?



STEVE:  Oh, never did use flywheels.



LEO:  Oh, I thought it was, okay.



STEVE:  No, it was just an idea that Ben had.  And in fact, that's, again, one of the other...



LEO:  It is a good way to store energy, of course.



STEVE:  Oh, yeah.  I mean, and we've talked about electrostatic in the form of an auto-based supercapacitor.  And we've talked about chemical in the form of a battery.  And now mechanical in the form of a flywheel.  But it looks like, I mean, this is really interesting because the battery runs at useful voltages.  Apparently some of the electric cars are not very quick off the line because it is difficult to pull the kind of energy out of an existing lithium ion that you would like to in order to really accelerate well.  Well, that problem is gone now, too.  So we're talking about cars with tremendous acceleration which are able to dump their mechanical energy back into the battery as quickly as they need to when they're braking, so they'll use regenerative braking; and that are able to accept power, either from a highly efficient turbine using external combustion technology, or from - maybe you could charge it in your garage, if you can provide enough power for that to make sense.  Otherwise, there'll be some sort of universal, high-current power plug, and we may see electric charging stations in the future.



LEO:  Very, very cool.



STEVE:  But it's big news that I wanted to share with everybody.



LEO:  Well, really timely, I mean, energy news.  That's so exciting, yeah.



STEVE:  Yup.  And just in the nick of time.  And it's interesting, too, how - back in 2002 I found a paper, they were talking about lithium ion phosphate as having its conductivity dramatically increased, and literally how this could really make sense for batteries and be a breakthrough.  It took seven years from that knowledge being in place, and guys in the materials labs working out, okay, how do we actually solve the problems?  And so it - oh, the other thing I forgot to mention is it looks like this also solves the cycle life problem.  Lithium ion suffers from both a shelf-storage life limitation, where literally the chemistry gets stale, even if you're not using it it's aging; and then also a maximum cycle life of on the order of 350 to 500 cycles.  I know that Apple is bragging about a new technology they have in their latest laptops that's supposed to be a thousand cycles.



LEO:  Yeah, yeah, yeah, right.



STEVE:  That demonstrates that, yeah...



LEO:  We'll see.



STEVE:  That demonstrates that there's some awareness of that.  It looks like in their initial work that this solves the cycle life problem, too.  So, I mean, we're basically talking three or four years from now I expect this era of having to charge our little portable things for almost as long as it takes us to use them, that's gone.  We're going to really change that duty cycle.



LEO:  Well, remember you talked about that screwdriver that charges in 30 seconds.  I finally got it, and it does indeed work.  It does charge in 30 seconds.



STEVE:  And that's a supercapacitor-based screwdriver.



LEO:  Yeah.  It's very cool.  So...



STEVE:  That's neat.



LEO:  Yeah.  It's not the greatest screwdriver.  I don't know if it's because of the supercapacitor, but the barrel is kind of big.  The ergonomics are not great.  But it charges in 30 seconds.  And it does, and it has a good lifetime, lots of torque.  It's a nice design.



STEVE:  Well, it's got an infinite lifetime, technically.



LEO:  Yeah.  I mean, we'll see.



STEVE:  Yeah, there's nothing to die electrochemically in there.  So it's neat, I mean, so we are seeing supercapacitors happening.  It looks like the supercapacitor now is going to have a run for its money with this next generation of lithium ion technology.



LEO:  That's awesome.



STEVE:  I do not have a SpinRite testimonial.



LEO:  What the heck?



STEVE:  I have an amazingly cool tip.



LEO:  Oh, good.



STEVE:  Dave Jones in Birmingham, Alabama says he got SpinRite to boot over PXE.



LEO:  PXE, okay, I have...



STEVE:  Which is network boot.



LEO:  Yeah.



STEVE:  And it's built into all BIOSes now and has been for some time.  So he wrote, he said, "Steve, I thought you might get a kick out of this.  I just bought the four licenses to get a corporate site license of SpinRite for our firm.  We've now successfully gotten SpinRite to work over a PXE network boot.  It involved taking the fdboot.img floppy image from FreeDOS and merging spinrite.exe into it.  We then placed a call to it in FreeDOS's autoexec and put the .img file in our PXE menu.  To my great pleasure, it booted straight away."



LEO:  That's cool.



STEVE:  "We can now run SpinRite on any computer in our firm, almost a hundred machines, directly from the network, without lugging any disks or CDs around the office.  I hope to put up a full tutorial on how to get this working on my blog, and I'll send you a link when I do.  Thanks, as always, for such a great product.  Being an Assembly programmer myself, I truly appreciate the hundreds of hours of careful programming that SpinRite represents.  Regards, Dave Jones, IT Manager."



LEO:  That is really neat.



STEVE:  Well, what's so neat about it is you've got a computer that won't boot.  And so it's like, okay, cool.  You reboot, you go into the boot menu and into the PXE menu and say, "Run SpinRite."  And it provides - it boots FreeDOS that is bound into SpinRite and then runs SpinRite.  So, I mean, it's like - and then SpinRite goes to town and fixes your disk.  So it's just - it's such a cool idea to run a data recovery tool that will solve boot problems.  And it also makes it easier to run in a preventative maintenance way.  You just reboot your machine into SpinRite and let it run overnight, and come back the next morning, and go back to your normal work.  So I just thought it was really cool.  I wrote back to Dave, I said, please, please, please share the way you did this on your blog.  And I will share it with our listeners when he gets his blog up.



LEO:  I'm sure you'd love to have that be part of the SpinRite instructions.  That's really cool.



STEVE:  Yeah.



LEO:  All right, Steve.  I'm ready to read...



STEVE:  [Groaning]  Buckle your seatbelts.



LEO:  This comes from Francis in London, the Horrifying PayPal Revelation of the Week:  A brilliant show - it does seem like it's weekly these days.  A brilliant show, he says, keep it up.  I'll try and keep this as brief as I can because you get so many of these.  I needed to reset the password of a client's PayPal account.  I used the forgotten password link on PayPal, received an email, clicked it - this means that he's on the client's account because the email went to him.



STEVE:  Right.



LEO:  And expected to be asked to verify my identity.  PayPal said the link had expired, even though I had just requested the PayPal reset, so I tried again, same thing.  So I called customer service.  They asked me to quote the last four digits of the bank account number.  It's a client's corporate PayPal account, and I didn't know it, so I said so.  So the customer service guy said, "Why don't you guess?"



STEVE:  He asks him to guess the number.



LEO:  Why don't you guess?  Well, it's four digits.  That means there's, what, 10,000 possibilities.



STEVE:  Uh-huh.



LEO:  I said there was no way I could guess.  He said, "Well, guess the first digit."  I said I couldn't.  He said, "Well, give it a try."  So I guessed five.  He said, "Higher."  So I guessed eight.  He said, "Lower."  I guessed seven.  He replied, "Correct, it's six.  Now guess the second number."  Strangely, I managed to guess all four numbers.  He then sent me an email which, when I clicked, allowed me to change the password and all the basic security questions, et cetera.  What?



STEVE:  Oh, my goodness.



LEO:  What?  Boy.  To make things worse, the company used their main reception email account that more or less everyone has access to.  And finally, thanks for the amazing SpinRite.  I used it a couple of times when I was in tech support.  It really did get the company out of a couple of tight scrapes.  Sigh.



STEVE:  Is that just too...



LEO:  Guess.  High.  High, you're high.



STEVE:  Low, low.  Oh, I don't know the number.  Oh, that's okay, just guess it.



LEO:  That's helpful customer support.



STEVE:  Well, and you know, I guess, what would you do otherwise?  It would probably cause this poor customer service representative more trouble if he just had to say no, I'm sorry.  Or maybe he doesn't want you screaming at him, or who knows what, what it would take...



LEO:  Bizarre.



STEVE:  ...to end up doing this.  And this also indicates that the support guy is seeing the number.  It would be nicer if the system were designed so that he enters the number you give, and then it either says yes or no to him.  So obviously there isn't that aspect of privacy being maintained.  He has the last four digits, so he's able to say, uh, guess a little bit higher.



LEO:  Little higher, little lower.  You're close.



STEVE:  Oh.  Oh, goodness.



LEO:  Guess.  I don't understand how that can happen.  It sounds like a renegade customer service representative.



STEVE:  I would love to have an audio file of that conversation.  That would be a keeper.



LEO:  Guess.  Ian Cummings [laughing].



STEVE:  I know.



LEO:  Ian Cummings reports from Newbury, UK, another UK listener, that PayPal may not be a lost cause:  Hi, Steve and Leo.  Love the shows.  I'm behind and catching up, but listened the other day to the story about only needing the last four digits of your credit card to get through PayPal's security.  This was another story, by the way.



STEVE:  And remember we mentioned there that the problem is that the last four digits of your credit card is so commonly used that it's exposed everywhere.



LEO:  It's on the slip.  It's the one thing they give you.  Well, it looks like they realized that wasn't a great idea, and I just saw this, quote, "Secure Web PIN for Customer Services:  We're always looking for ways to improve your service and security, which is why, after March 31, 2009" - this might be, by the way, British PayPal.  It may not be the same everywhere.



STEVE:  Good point.



LEO:  "We will only discuss your account when you provide a Secure Web PIN.  The last four digits of your bank account or card number can no longer be used to identify yourselves.  When you want to call us, just log on to PayPal, go to the  'Contact Us' page and click on the 'Call Us' link.  On the next page you'll find a six-digit PIN code valid for one hour.  Quote that when you call us."  It's a small step, but in the right direction.  Keep up the good work, guys.  P.S.:  The reason I'm behind and catching up is Leo does so many good podcasts, and has gotten me into Audible, and my journey to work isn't long enough.  He has not enough time to listen to everything.  Hey, but the problem with this is it wouldn't have helped our previous guy because he couldn't log in.



STEVE:  Correct, he was unable to log in.  So this is a customer support authentication loop where you log in, you get a six-digit PIN code, then you use that to talk to a human being.



LEO:  Perfect.



STEVE:  If you're able to log in.  And so what that's doing is that's solving the social engineering problem of pretending to be somebody that you're not.  And they're now saying after March 31st you're not going to be able to use your credit card or your bank account digits.  You're going to have to log in properly first and then use the PIN code which is a one-time password sort of one-hour expiration code.  So, again, it's like somebody's listening, so that's good.



LEO:  That's an improvement, but I don't know what you do if you don't - you can't log in.  But that's...



STEVE:  Oh, you just guess.  I don't know my PIN code.



LEO:  Maybe that's why they have to guess.  Well, we know this doesn't work if you can't log in.  So...



STEVE:  [Sighing]



LEO:  It's bizarre.  Mark McSweeney, Concord, New Hampshire shares his Poor Man's VPN solution with us.  He says:  Steve, I'm a regular listener of Security Now!.  I have a question about the security of what I'm calling my "poor man's VPN."  I have a Linux firewall router set up at home.  It has a SSH server running in it on an alternate port, not the standard port 22.  What I do when I'm away from my home network is to use an SSH client to log onto my SSH server using a public/private key pair for authentication and set up a tunnel dynamically forwarding port 1080.  I then configure my browser to use a SOCKS proxy to use localhost:1080.  I've checked the IP addresses being reported using WhatIsMyIP.com, and the remote address is displayed.  Is this method as secure as an IPSEC or SSL VPN?  Your comments and feedback would be appreciated.



Keep up the great work with Security Now!.  I immensely enjoy the show and learn a little bit every week, although some of the topics such as the recent show dealing with HMAC do sometimes make my hair hurt, so I need to listen to them a couple of times to really grasp what is being discussed.  Hey, this sounds like a very clever - an SSH tunnel, very clever way to do this.



STEVE:  Yes.  And it is - I would say it's every bit as secure as an SSL VPN.  It's using a pre-arranged public/private key pair, so the client which is out roaming around is authenticating itself in a very secure fashion to the server.  I loved it that Mark is not running his SSH server on the default SSH listening port 22...



LEO:  Does that make a difference?  Because I figure, if somebody's trying to find it, they just ping until they get an SSH response.  They try all the ports.



STEVE:  Yeah, but that's...



LEO:  That's more work.



STEVE:  Well, and the typical attack is not scanning a single IP across all of its 65,535 ports.  The typical attack is scanning all the IPs for something listening on port 22.



LEO:  Right, right.



STEVE:  So the idea, I mean, to answer your question, absolutely yes.



LEO:  Okay.



STEVE:  The fact that he moved to an alternate port, you know, he didn't tell us, we don't want to know.  But it's something between 1 and 65,535.  So his server is listening there, and only he knows where that is.  It's true, somebody could find it.  But you really - it's just better not to be answering, not to be running the service on the default port.  So then what he's doing is, the way his SSH client works, is that, when he runs it, it opens and listens on port 1080 of, for example, his laptop, out roaming around.  So he's got the client side.  He makes a connection to his SSH server at home.  The client side opens and listens for any connections to the local machine, that is, the laptop's port 1080.



He then configures his browser.  Instead of going out over the Internet, he sets up the SOCKS proxy in his browser to instead use localhost, meaning the own machine's IP, port 1080.  So the browser connects to port 1080, which the SSH client is sitting in there listening for connections on.  And of course only the browser there is able to connect.  So that gives the browser a connection across SSH, which has been securely authenticated and is encrypted using standard TLS, which is SSL technology.  That gets him to his remote location, where the traffic then comes out of the SSH server and goes out over the Internet.  So he has come up with, you know, it's a little clunky to configure.  It's not a general purpose, complete solution because it's only useful for things that you can get to proxy through SSH.  Browsers are perfect for it, so surfing the web is perfect.  But it's absolutely secure, and it'll work well.



LEO:  Yeah, that's something called SSH tunneling.  And you can get other things to use the SSH tunnel, too.  I mean, the browser's a little easier than maybe other things.  But this is actually a fairly - he didn't invent this.



STEVE:  No, no, no.



LEO:  It's a fairly well-known way of doing this.  And, yeah, it's very secure.



STEVE:  Yup, I just wanted to describe in detail to our listeners how SSH tunneling works.



LEO:  Yeah, it's a great idea.  I keep thinking I'm going to set this up.  I never get around to it, though.



STEVE:  Yeah.



LEO:  Jeff Harmon says he can't get his 16-bit software to go anymore:  Thanks for the great security podcast.  I'm a software architect responsible for the Internet banking application of a midsized bank, and it keeps me up to date on the current security threats and vectors of attack.  That's great, Jeff.  We're glad you listen.  I consider myself to be pretty technical, and I love it when you dive deep into the bits and bytes.  Occasionally I have the netcast playing while driving with my wife in the car.  She laughs at me as I am finishing Steve's sentences or answering the questions Leo asks.  She thinks we're all nuts.  Keep it coming.



My question has nothing to do with Internet security, however, more of a problem that just kills me I haven't been able to solve so far.  I've been having trouble with this for months now, ever since installing Service Pack 3 on my XP machines.  I have a number of old 16-bit children's games that worked fine prior to SP3, but no longer load or install.  The installation starts but hangs partway through with the WOW.exe process taking up a significant amount of CPU.  I've tried letting that process run overnight to see if it ever finishes, but none of that seems to matter.



I believe the WOW.exe process is what makes it so that a 16-bit program can run on 32-bit XP.  Is there something that changed with SP3 that made it so that the 16-bit games can no longer run?  Is there some kind of security issue?  Is there a setting that can be changed to allow this?  I wouldn't do that on all of my machines, only on the machines for my children.  But he would like to run those games.  Do you know about that?  What is that WOW.exe?



STEVE:  Well, WOW stands for Windows On Windows.  And it is Microsoft's technology for essentially hosting an incompatible version of Windows on a different version of Windows.  There was something like it back in the old days.  Remember when we had Windows 3.1, and then there was Win32s?  That was sort of a - that was an introduction to the 32-bit API that Microsoft was in the process of bringing us over on NT.  And so it was sort of a straddling technology.  This WOW.exe process is, essentially, it's the 16-bit Windows API that is then hosted on our 32-bit platforms.  I checked when I saw his note, because I've still got some 16-bit stuff, and I was able to run it on a machine both with SP2 because, like, the one I'm sitting in front of right now, I tried to give it SP3, and it choked on it.  So I backed out of that quickly.  But I do have a SP3 machine that in my case does run the 16-bit software.



The reason I brought up the question, though, is that what we're seeing is, we're seeing Microsoft finally beginning to say, okay, we're no longer going to support this really, really old stuff.  As I remember, and you and Paul may have discussed this, but doesn't Windows 7 formally drop support for 16-bit software?



LEO:  You know, I don't know.  That would make sense.  They still support 32, of course...



STEVE:  Yeah.  I think I remember...



LEO:  ...seamlessly.  But I wouldn't be surprised, yeah.



STEVE:  I think I remember seeing that somewhere.  So this is a place where virtual machines are your friend because I think we're going to be seeing more and more virtual machine technology coming to bear where it's necessary to run, either different platforms on existing platforms, or in some cases really old software.  I was just yesterday, I got a copy of Fusion, VMware Fusion, running on my Mac notebook because I really want to use my DOS, my 16-bit DOS editor, BRIEF, over on my Mac.  And I need to use the Mac because that's where that really cool PDP-8 minicomputer simulator is, is on the Mac.  And but I don't want to use the Mac editor, I want to use mine.  So I've got Fusion running, and I literally have the DOS from Windows 95, or 98, four point - that thing that ended in .2222, which was sort of the classic last version of DOS.



LEO:  6.22, I think, wasn't it?



STEVE:  Yup.  Well, there was DOS 6.22.  But then there was - they carried it on.  There was Windows 95 and 98 and then Millennium.  And but there is the DOS underneath Windows 98 because remember, those still actually booted DOS and then ran an environment on top of the operating system.  So you could either boot to MS-DOS, or you could boot from them back into MS-DOS.  Anyway, the point is that I'm using virtual machine technology to host a foreign operating system.



And so it doesn't sound like this is a big problem for Jeff.  I mean, it sounds like he's wanting to figure out what's gone wrong and why.  I couldn't find anything on the 'Net that said that SP3 killed 16-bit software.  And I did verify that at in at least one case I'm still able to run 16-bit software under SP3, or that would be a real problem for me because I'm a dinosaur still running DOS apps.  But virtualization technology is something to keep in mind because it's not expensive, and it's really become very robust and reliable.



LEO:  Yeah, yeah.  I think it's probably something corrupted when he installed SP3 because I haven't heard the same thing, that you can't - I haven't heard that problem.



STEVE:  Right, right.



LEO:  But you're right, this is where virtual machines are wonderful, wonderful solutions.



STEVE:  They'll certainly solve that problem for him because he could easily install a VM and then put whatever version of Windows he wants to on that, just for the kids' games.



LEO:  Yeah.  Larry in Minnesota's scratching his head about open hotspot WiFi security.  He says:  I hate to beat a dead horse, but I'm a little confused about the whole cybercaf scenario.  In an early episode, if my memory serves me, you had indicated that the personal HTTPS, secure HTTP transactions like banking in the workplace could be subject to a variant of an MIM, man-in-the-middle, attack by your employer since they control traffic between your PC and their outward-facing IP.  Couldn't the same be said of public WiFi access points?  Couldn't Coffee 'R Us, or a disgruntled, out-of-work techie who just took the crumby coffee shop job to get his wife off his back, or an evildoer that realized they're using default admin settings on the router, do the same thing, a man-in-the-middle attack?  How could HTTPS, VPN, or for that matter any reasonable solution protect you from this?  Have I missed something?



STEVE:  Well, it's a great question.



LEO:  Yeah.



STEVE:  Because we have talked about - we've sort of talked about this in all kinds of different ways.  So I just wanted to reassure Larry that, without explicit configuration of his client, that is, of his laptop, for example, in an open hotspot WiFi scenario, there is no way to perform a man-in-the-middle attack on SSL.  I mean, that's the whole point of SSL.  And this gets blurred, and the reason for this confusion is in a corporate environment there are companies that want to perform content filtering on all traffic, including SSL.



And I remember I had an extensive conversation with a company at last year's RSA conference who was offering this.  And I said, so you're installing certificates in all of the machines in the enterprise.  And he said yes, that's the technology we use.  So what that means is that, instead of you accepting the remote server's SSL certificate, you're creating the SSL connection with your employer's or the corporate gateway.  Then it's decrypting that little hop of security, doing content filtering, and then it's working with the regular SSL connection to the remote server.



So that is classic man-in-the-middle, quote, "attack," unquote.  It's not an attack because this is something by policy that the corporation has established.  And your system is cooperating because you have the corporate certificate which allows the corporation essentially access to your connection by virtue of it not - your connection is not going direct to the remote server.  It's only going to the corporate gateway, where it's decrypted thanks to the fact that the corporate gateway has previously provided you, your client in the corporation, with that certificate.



So because that scenario is not the case when you're roaming around in an open hotspot, you will have a direct connection to the remote server, and SSL will protect you.  It's only where, by corporate mandate, they want access to all, even encrypted connections, that your client gets a certificate that allows that to happen.



LEO:  All right.  Let's see, here.  Paul Kucher from Ellicott City, Maryland offers a great example of hysteresis.  This all started because I was reading the definition of hysteresis from this radio/television electronics dictionary that Dane gave me.  And you came up with a definition having to do with a button press.



STEVE:  Yup.



LEO:  He says:  Hi, Steve.  I've been listening to your latest explanation of hysteresis, the nature of a keyboard's snap action.  I think I have an even simpler example with your home's thermostat.  When the temperature rises beyond the set temperature of the thermostat, the heater turns off.  When the heat begins to escape your home, and the temperature begins to fall, the heater does not come back on immediately after it reaches the set temperature.  Otherwise it would be constantly switching on and off.  Instead, the temperature decreases to a lower threshold, whereby it then begins to increase until it shuts off again.  Hysteresis allows the heater to turn of and on at a minimal internal without constantly switching off and on while it tries to converge on the target temperature.  Of course it has...



STEVE:  I thought that was...



LEO:  That's good.



STEVE:  Yeah.  I thought that was another great example.  I don't know if any of us, if any of our listeners are as curious about mechanical things as I.  But I was fascinated when I took the cover off of many different thermostats - it's not that I go around taking the covers off of thermostats, but for some reason I seem to have seen a lot of thermostats in my time.  And maybe you've seen this, Leo.  In some models of thermostat there's a coiled spring and a mercury switch, that is, a glass capsule with liquid metal mercury in it, and two electrodes at one end so that, when the capsule is tilted toward the electrodes, the circuit is completed by the mercury.  When it's tilted toward the other end, the mercury leaves the electrodes and opens the circuit.



And what's clever about this is it implements hysteresis using the movement of the mercury.  That is, as the temperature increases, that coiled spring is actually a bimetallic spring.  It's two dissimilar metals with different coefficients of expansion on the inner and the outer sides of that coil.  So as the temperature changes, the outer one, for example, expanding more, will cause this coil to wind itself tighter.  So the outside begins to pull the mercury switch over center.  And at some point it's just enough the mercury rolls to the other side.



Well, in the process it changes the balance.  Now it's like the thing has switched itself on, and it's going to stay there.  It's got to go much further back now in order to compensate for the fact that the mercury is over on one side to roll up back on the other.  And so the result is hysteresis, with a really simple, very sort of physically obvious technology.  I just thought it was very clever.



LEO:  We got a letter from Allyn Malventano, who is a computer security guy in the Navy, who has done some stuff for us.  He actually reviews solid-state drives for PC Perspective.  He says - he has another definition.  He says hysteresis - now, this is kind of more the radio definition.  "Hysteresis is the tendency of a ferrous metal to retain some of its magnetism.  It comes into play in electronics and radio gear, mostly by the use of transformers.  Hysteresis is the major contributor to any power loss or signal loss to those passing through a transformer because of the residual magnetism of the core is always lagging behind the field induced by the transformer's primary winding.  The constant realignment of the particles within the material causes the lost power to be given off as heat.  That's hysteresis loss."  So there's another...



STEVE:  Cool.



LEO:  ...much less intuitive explanation.



STEVE:  Thank you for that, Leo.



LEO:  He says it takes work for the metal to change poles, and that work eats up some of the signal efficiency of the system.



STEVE:  Yup.



LEO:  And that's what makes unused wall warts warm to the touch.  Did you know that?



STEVE:  Yeah, actually, yeah.  They've got transformers in them, and the transformers are sitting there transforming, whether you need them or not.



LEO:  Yup.  That's why we unplug from the wall now, even if we're not charging.  Glenn Edward in Nottingham, Maryland - actually especially when we're not charging.  Is even AES and PGP secure?  I wonder, queries Glenn.  After reading stories like the one referenced below, I have to wonder if any data encryption algorithm that's allowed to see the light of day hasn't been compromised.  What do you think after reading this?  Some of this was covered in my local newspaper a few years ago:  mediafilter.org/caq/cryptogate.



STEVE:  Well, his link refers to a story that you may have heard about.  It was in the news, as he mentioned, a few years ago, where somebody was grabbed by, I think it was officials in Iran, and accused of - it was a Swiss official accused of planting deliberately compromised with a backdoor crypto machines that came from a highly reputable company.  Crypto AG was the name of the company.  And I don't remember now one way or the other whether it was ever proven.  But the accusation was that the NSA was working secretly with Crypto AG to install cryptographic backdoors in their equipment, and that allowed the NSA to obviously decrypt otherwise unbreakable codes.



The reason I bring this up is that this is a perfect example of the difference between technology and implementation.  That is, in Glenn's citing this example, asking is even AES and PGP secure, well, this is not - it never was the fault of the underlying cryptographic algorithm that was the problem.  It was implementation details.  It was the fact that the algorithm was being misused or abused or something about the system that employed the algorithm was deliberately being made insecure, if this is even true.  I don't know whether this is urban legend or true or not.  But that's not really the issue.  I wanted to draw a clear distinction between the idea of the algorithmic strength versus the application strength.



And actually, Leo, this sort of goes to your point of liking open source software because it helps to bring visibility to the implementation, and it makes it much easier for people to look at the code and go, oh, this was done right.  So we know we have both a really strong algorithm and a really strong implementation of the algorithm.  And those are two very different things.



LEO:  Yes.  As we've learned.  Tazz in Nova Scotia has some relief from PayPal concerns, just in the nick of time.  He says:  Steve and Leo, I'm a little behind on listening to Security Now! due to being busy at work.  I'm catching up.  I have listened to SN-182, and I have a little info for the PayPal football and security question dilemma.  If you log onto PayPal and go to My Account, then Edit Profile, down at the bottom of the account information column there is something called Identification Preferences.



The web page the link points to says:  "When you call customer service, we will ask you to confirm your identity by providing your primary phone number and one other piece of information.  Please let us know what you would like to use for your other form of ID."  The choices are customer service PIN, your Social Security number, the last four digits of the primary bank account number, the last four digits of the primary credit card number.  Choice one lets you create your own six-digit, numbers-only, PIN.  The default setting, I guess, it certainly was mine, it was the bank account number.  If I only had a credit card registered, I'm guessing it would have been the default.  It seems to me, just guessing here, that if Brian in Raleigh, the guy that wrote in at the end of 182, had set up his own unique PIN, the customer service would ask him for that instead of the last four numbers of his credit card.  If that's the case, well, everybody should be going there and fixing that.



STEVE:  And Leo, it is.  I didn't know about it.  I went there, and it's there.



LEO:  I'm going there right now.



STEVE:  Yes.  It's exactly where he said.  You log into PayPal.  And if you can't you just guess, and they'll let you in anyway.  Go to My Account, and then there's a little Edit Profile link.  You choose that, and there's three columns of data.  The left-hand column is called Account Information.  The bottom of that is Identification Preferences.  And sure enough, I mean, I had never been there before.  And mine was defaulted, like everybody else's is, to I think it was the last four digits of my bank account number.  Either that or it was my credit card, I don't remember which.  And the option for customer service PIN was grayed out, non-selectable.  But over on the right was a link to create one.  And it literally - and so I went there, and it says - there's two fields that look like password fields.  And it says, make up six digits.  And so I did that, and put them in twice, and it said good.  We got your own, self-assigned PIN.  And then I went back to the prior page and selected it as my identifier.  So I will no longer be using or asked for, hopefully, my bank account number and credit card number.  And I wanted to provide this "Thank you, Tazz in Nova Scotia."  This is a fantastic tip for all of our listeners who are PayPal users.



LEO:  I'm logging in right now.  That's great.



STEVE:  Yeah, this is just - it's an absolute way of increasing PayPal security.  And lord knows, after what we've heard today, we need all the PayPal security we can get.



LEO:  Just guess [laughing].



STEVE:  Just guess.  No, a little too high.  Guess lower.  Oh.



LEO:  Oh, sorry.  Renee Ann from Birmingham, Alabama describes herself as one of our few female listeners.  We don't know that.  But I think you might be right.  Dear Steve, I'm so glad to hear about the hands-on, how-to episodes you're planning.  I'm embarrassed to ask what is probably a really dumb question, but here goes.  In passing, you and Leo often make mention of making an ISO image of your computer.  While I back up my data regularly, I don't have a clue as to how to make an ISO image.  Could you discuss this, either in listener feedback or as part of a how-to episode, what's the best software to use to do this?  And please talk about the smallest details of how to do this.  Perhaps you could give us a recommended checklist.  Delete old files, defrag, whatever.  Profit.  Thank you.  A devoted female listener, Renee Ann in Birmingham, Alabama.



STEVE:  Well, my favorite imaging tool has changed.



LEO:  Oh.  I've been telling everybody Drive Snapshot.



STEVE:  Yup.  And it had been until I was updating my copy of my favorite boot manager, which is BootIt NG.  This is made by a guy named Paul Terrell, who I think is in Nevada, if I remember right.  And he's got something called Image for Windows.  And I like it better because it will image to NTFS partitions.  Whereas Drive Snapshot is a DOS-based tool, this thing is no OS based.  So you actually boot it itself.  He will create a boot floppy or a boot CD for you, sort of very much the way I do with SpinRite, where you don't need to provide it with an operating system, it solves that problem for you.  And it understands natively Firewire and USB, so you're able to use those; whereas, if you boot DOS, you have to have additional drivers, unless your BIOS provides recognition for those.  Anyway, it's a little more flexible.  It's not as easy to use.  The UI is sort of text screen based, whereas Drive Snapshot is a little bit easier over on the Windows side.  But I do like it.  And I've been using it and recommending it to friends that ask me the question.



LEO:  How much is BootIt NG?



STEVE:  BootIt NG is $34.95.



LEO:  Okay, so it's about the same price, but you get this boot manager, too.



STEVE:  Well, actually they are separate.  BootIt NG is $34.95.



LEO:  Oh, okay.



STEVE:  The Image for Windows is $38.94.  I don't know where that number came from, but...



LEO:  They have Image for DOS and Linux, too.  Okay, that's cool.



STEVE:  Yeah.  I mean, it's really nice stuff.  It works well.  The guy knows his way around imaging and low-level stuff.  BootIt NG is well known among our listeners, I'm sure, because it's been my favorite boot manager for quite a while.  And it itself does some imaging, but not as flexibly as his standalone imaging tool.  But to answer Renee Ann's question, those don't make ISO.  When we talk about a drive image, we're not talking about a CD or DVD image, which are technically and typically ISO images.  That's a sort of a different kind of image.  That's an image of a CD or a DVD.  In this case it's a drive image, which is a file, or multiple files.  Sometimes you break them up into smaller pieces.  If you're, like, using a FAT file system that can't manage a multi-gig file, it'll create a series of smaller chunks.



And I do find myself - actually I was setting up a new machine to try using Skype under Windows for this episode of Security Now! with Leo, and after I got it all set up I made an image.  And so I do the things that you would do if you're about to sort of like make something you care about, like take a snapshot of your drive, which is delete all your temporary files from your browser.  Under Windows there's always a tool under System Cleanup called Cleanup.  And you can check, normally check all the boxes for the types of things you want to clean up.  So I run a Cleanup.  And it'll find and discard a whole bunch of stuff, and also offer to compress files that haven't been used for a long time to sort of keep them in a smaller storage form.



Then after all that, that is, after deleting all this stuff - oh, also empty your trash, if you use trash and have a trash can.  Then basically get rid of all the junk that you really don't need to keep around.  Maybe look at your desktop and delete, take that opportunity to do a little bit of spring cleaning.  And then, finally, do a defrag to sort of get everything in nice shape.  And then take an image of that.  Which is the - that's sort of the routine I go through whenever I'm doing an image.  Sort of get things shipshape before you take a snapshot.  And use a program like Drive Snapshot, which I really recommend for less high-end users, or this Image for Windows, DOS, or Linux from Paul Terrell.  He's at TeraByte, by the way, TeraByte.  And I recommend his stuff without hesitation.



LEO:  Good.  Well, now I have another imaging program to buy.



STEVE:  It's a good one.



LEO:  I've been using Drive Snapshot.  I'm very happy with it.  But this looks like it might be a little easier to restore from.  I mean, the big issue is creating this boot disk to restore from.



STEVE:  Yes.  And...



LEO:  And this seems like it might be easier to do.



STEVE:  That's exactly the case, Leo.



LEO:  Our last question.  Hard to believe.  Rafael Mediavilla in San Juan, Puerto Rico says:  Steve, one simple question.  Why aren't you on Twitter?  Man, I thought we were going to have one show in this whole darn network that we don't mention Twitter [laughing].  No.



STEVE:  Well, I'm going to sort of help you with that, Leo.



LEO:  Oh, good.



STEVE:  What is Twitter?



LEO:  I have no idea.  I can't imagine what he'd be talking about.



STEVE:  I'm Assembly code, and it is fundamentally incompatible with Twitter.  I don't know what Twitter is.  I don't want to know what Twitter is.



LEO:  Good.  I'm not going to tell you.



STEVE:  I don't care what Twitter is.  I know that I'm the only one left on the planet who doesn't know what it is.  But that's just fine with me.



LEO:  Twitter grew in the last year at a rate of 1,320 percent.



STEVE:  And now we have tweeting, whatever tweeting is.  Is tweeting the act of twittering?  Or is that something different?



LEO:  Yes.  Yeah, instead of saying "twittering" you say "tweeting."  And your post is a "tweet."



STEVE:  Yeah, and don't you say, like, things, oh, I just walked in the front door, or gee, you know...



LEO:  Well, you can say a variety - I don't want to get in this discussion.



STEVE:  I saw the strangest looking cloud just now.



LEO:  Yeah, you could tweet that.



STEVE:  But who cares?



LEO:  But you don't have to tweet that.  You could also say, I've learned of a new technique for cracking AES.  See this link.  I mean, who you follow really determines what kind of stuff you're going to read.  You don't have to follow people who say I looked at the sky.



STEVE:  Just push away from the computer, Leo.  Step back slowly and carefully.



LEO:  I've tweeted a lot less lately.  I'm kind of - I'm on the...



STEVE:  Is there an exponential decay curve in tweeting, some people tweet...



LEO:  No.  It's an exponential explosion, exponential explosion curve, unfortunately.



STEVE:  So maybe this is what everyone's doing when I'm seeing them all doing something in the restaurant.



LEO:  Yeah.  You see...



STEVE:  Everybody in the restaurant is, like...



LEO:  They're tweeting.  They're twittering.



STEVE:  ...bent over their little PDA, pushing buttons.  I'm thinking, okay, what the heck are you doing?  Oh, they're tweeting.



LEO:  Yeah, that's almost certainly what they're doing.



STEVE:  There's this weird guy across the restaurant staring at me.



LEO:  Yup.



STEVE:  That's me, yeah.



LEO:  Rickster just said, "Steve Gibson just became my favorite person on the TWiT Network."



STEVE:  Thank you, no.  I don't have Facebook.  I don't have MySpace.  I don't have any of that teenager stuff.



LEO:  You don't have time for that stuff.



STEVE:  Don't have any twit, tweet, or anything else.



LEO:  All right.



STEVE:  Exactly I don't.  I'm happy to do Security Now!, and that's it.  That's my exposure.



LEO:  That's it.  It wasn't easy getting you to do that.



STEVE:  No.  When you first suggested it I was groaning, thinking, ohhhh.  What is this now that Leo's come up with?  Turns out the best thing that ever happened, Leo, so I'm glad.



LEO:  Thank you.  Well, we're very grateful to you because we learn a lot every single week.  You could find, of course, the show notes and transcriptions and 16KB versions of all of this at GRC.com.  And if you'd like to ask a question, we do these Q&A episodes every other show.  You can go to GRC.com/feedback and leave a question.



STEVE:  Please do.



LEO:  Yeah, Steve likes those questions.  And of course, when you're at GRC, the Gibson Research Corporation, pick yourself up a copy of SpinRite, the world's best disk maintenance and recovery utility.  It's a must-have.



STEVE:  Or get four, if you want a site license.  Then you can use it on all...



LEO:  Is that how that works?



STEVE:  Yup.



LEO:  So if you buy as many as four, then you're done.  You can install it now on all the systems in your office.



STEVE:  Yup, exactly.  In a single site.  We use 10 copies if you want a corporate-wide, multi-site capability; and 20 for global.



LEO:  Perfect.



STEVE:  And I just liked it because it allows someone to try it and see if it does the thing for them.  Then they don't have to say, hey, I already bought one copy, or I bought SpinRite, what's the site license plan?  It's like, okay, wait a minute.  Just if we make it incremental - and that way, similarly, when there's an increase, they can upgrade by upgrading that set of SpinRites.  So it just sort of all scales properly.  I just - I liked it.  I thought it solved the problem nicely.



LEO:  I think that's, yeah, it's very clever.  Very clever.  All right, Steve.  We're out of time, my friend.  But...



STEVE:  Oh, boy, are we.



LEO:  Long episode, but full of good stuff.



STEVE:  Yup.  Great to talk to you, Leo.  And we'll do it next week.



LEO:  On Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#189

DATE:		March 26, 2009

TITLE:		Internet Explorer 8

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-189.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo closely examine and discuss Microsoft's just released major version 8 of Internet Explorer.  Steve has studied this major new web browser closely, so he examines the many new features and foibles from the standpoint of its short- and long-term impact on Internet security.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 189 for March 26, 2009:  Internet Explorer 8.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!.  Are you ready?  Fasten your seatbelts, put on your tinfoil helmets, and get ready to find out what the latest security issues are online and off.  Mr. Steve Gibson is here.  He's the king of security, the man who runs the Gibson Research Corporation, home of SpinRite, some great free software like ShieldsUP!.  And he joins us - the guy who discovered spyware - he joins us every week to talk about it.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  I always look forward to my old friend Steve.  The second podcast we did on the TWiT Network was this show.



STEVE:  Yeah.  And when you suggested it, I had never heard the term.  I think Mark Thompson had used it once.  And you said a - I said, a what cast?



LEO:  A huh hah?



STEVE:  I mean, it just sounded like some, you know, pod person or something.  It's like, what the heck?



LEO:  Well, we are glad that you decided to do it.  And you've been the most consistent podcaster we've had.



STEVE:  Oh, I'm stubborn.



LEO:  This show is huge.



STEVE:  Once you get me going, you can't get me stopped.



LEO:  Today.



STEVE:  When you first suggested it, I was thinking, oh, lord, I hope he doesn't ask me again.



LEO:  I don't want to do it.



STEVE:  But it ended up, I mean, it's been the best thing.  I really enjoy it.  It requires some discipline.  But I wrote the column, the weekly column for InfoWorld...



LEO:  It's kind of like that, I guess.



STEVE:  ...for eight years.



LEO:  Yeah.



STEVE:  And never missed one.  Although I did have to shut the column down when SpinRite 3 was late because people were saying, hey, he hasn't shipped SpinRite 3.  Why is he still doing a column?  It's like, okay, fine.  Good point.  So...



LEO:  Well, you don't do a column anymore.



STEVE:  Nope.



LEO:  And SpinRite 6 is pretty stable, so...



STEVE:  Yes, indeed.  We haven't changed a byte of code since release, in five years.



LEO:  What?  Has it been that long?



STEVE:  Yeah, '04.



LEO:  I remember when it came out.  Wow.  And do you plan on doing a 7?



STEVE:  There are some things that I want to do.  For example, Mac incompatibility is a problem.



LEO:  Oh, we would love it if you would make this work on the Mac.



STEVE:  Mac's keyboard is, internally, it's a USB keyboard.  And SpinRite assumes - in order to do the multitasking that SpinRite does, it can't use the BIOS for a keyboard.  It needs to check the hardware directly in order to keep everything running at full speed.  And so I'm literally talking to the PC hardware in order to allow that to - all the SpinRite work to happen in the background.  And I can, you know, I've got new technology now, so I can come up with other ways around that from what I did originally 20 years ago.  But, yeah, so there will be a 7.



I'm going to get a bunch of stuff that's backlogged at the moment.  We will soon be talking about this very cool DNS benchmark, which is running now.  But all the group, the guys in our newsgroups have just asked for a number of additional features that are just going to put some polish on it.  That'll get done.  Then we go, we finish up the spoofability stuff, which is all the technology is finished and done, just not yet public.  Then the cookie stuff.  And all of that's finished, but not yet public.  And then I start serious work on CryptoLink, which I'm real excited about.  So my plan is to end up with two products, CryptoLink and SpinRite, and then switch back and forth, moving them each forward over time.



LEO:  Sounds great.  Sounds great.  So you're not done.  Far from it.



STEVE:  No, I'm not done.



LEO:  No rest for the weary.  You don't get to do your PDP-8 programming for a while.



STEVE:  Well, I'll sneak that in.  I've actually been relearning the 8, as I mentioned on the Gray-Haired Computing extra podcast that we did, and appreciating how cute it is.  I did spend a couple hours over the weekend building one of the - the first of the three front panels for it.



LEO:  Oh, that's neat.



STEVE:  So I'm sort of squeezing a little bit of time in for that, just because, you know, call that my "hobby mode."  



LEO:  You've got to have a hobby, dude.



STEVE:  Got to have a hobby.



LEO:  All right.  So today we're going to talk about the new Internet Explorer.  



STEVE:  We're going to talk about - naturally from a Security Now! perspective.  I mean, I don't care about new UI widgets, the slices, web slices and accelerators.  I mean, those are nice UI things.  My focus, as always, is what does this mean from a security standpoint?  What features have they given IE, which of course IE has notoriously been, is now, the number one vector of infection for machines.  So we'd like to see Microsoft hopefully moving IE forward.  I've spent enough time with it, I've gone over all the developer notes, all of the backgrounders and all that.  And I've got a complete readout for our listeners on IE8, and should they care.



LEO:  Great.  All right, Mr. G.  What's the latest in the world of security?



STEVE:  Two little bits in security news.  One I thought was really interesting.  A botnet has now been found running autonomously in routers.



LEO:  Are you saying it's an artificial intelligence?



STEVE:  Well, no.  It's not a Skynet yet.  Let's hope it doesn't go in that direction.



LEO:  But you wouldn't think routers would have the juice to do that.



STEVE:  Well, it turns out that these routers that are Linux-based, they are running a Linux core.  There was one where this botnet, about 100,000 of them, apparently, it's a router by NetComm called the NB5.  And the problem with this is that for some length of time the router was being shipped with firmware that had the web interface and the SSH telnet protocol both open and exposed to the Internet.



LEO:  Oh, please.



STEVE:  So, I mean, so it's a classic mistake.  So they have this...



LEO:  Was it a default password or something?  



STEVE:  Oh, yeah, yeah.  And in fact there was one version of firmware that needed no password at all, that you just connected to it by stumbling on its port.  And of course, again, we were talking the other day about default, like the default port for SSH.  And one of our - it was in the Q&A last week, in one of the - our listener who asked the question mentioned that he was running it on a different port.  And I said, yay, that's important because - im-port-ant.  Anyway.



LEO:  [Laughing] Im-port-ant.



STEVE:  So this DSL router, it ends up being found by other bots in the net that are scanning; so it's a worm also.  And they then leverage the web interface and the exposed telnet port to transfer themselves into it.  They're not able to write themselves permanently, so they're just living in RAM.  But this botnet agent is able to copy itself, spreading virally, like in a worm, really.  There is, I guess, no verb for that.  "Wormily" doesn't really work.



LEO:  Yeah, I like "wormily."



STEVE:  Okay, "wormilate."  So it just wormilates and worms its way across the Internet.  And apparently where this was found, I mean, it uses standard IRC Chat to organize itself.  And it's apparently about 100,000 routers strong at the moment.  Now, the company NetComm has since fixed their firmware and closed these otherwise default open ports.  Yet firmware is not something that everyone is updating all the time.  And so much so that there's 100,000 of these that, even though the firmware has been patched, these particular routers haven't been.



If we happen to have any listeners who have this NetComm NB5, all you need to do is power cycle it, and that'll flush any worms out that may have crawled in.  And you could use a port scanning site like mine, like ShieldsUP!, because when you scan with ShieldsUP! we will be checking your public IP, not your private IP behind the router.  So we'll show you your own public IP.  That's what we would check.  And we would show you port 80 and 22, the telnet port, as being open by default.  Unless your ISP is blocking that, in which case, you know, some ISPs are, like, do not allow you to run web servers.  So they would be blocking port 80.  So it could be open, but we would still not see it.  On the other hand, nothing else on the 'Net would see it, either, except perhaps somebody who was also on your same ISP, depending upon where that port 80 filter was.



So anyway, you would want to make sure, if you had this NetComm NB5 router, make sure that you've got its WAN-side administration stuff disabled by default because some versions of firmware didn't do that.



The only other real news is I did want to comment that since our last podcast a week ago, Acrobat, Adobe's Acrobat and the Acrobat Reader, for the down version of Reader, that is, versions 7 and 8, now have updates.  I went and checked and updated mine earlier this morning because they were supposed to have it done on the 18th, I think it was.  I think it was the 11th and the 18th.  The 11th for version 9, then they were waiting a week or being delayed a week to update versions 7 and 8.  And I went there on the 18th and didn't find it.  So anyway, it is there now for anybody who's still using Acrobat.  You mentioned, Leo, that why not just update Reader?  And it's because I've got the whole Acrobat package, not just the Reader.  Anybody else probably would be served well to just update their Reader, although you can stay with 7 or 8 and now at least solve these security problems.



LEO:  Very good.



STEVE:  Which brings up an interesting little side note.  I recently accepted responsibility for an infected laptop.  A friend that I set up about a year ago got herself infected on, it happened to be March 12 at 9:15 p.m., because that's the timestamp on all the infected files.  And I found something really interesting.  This was - she got herself infected by sort of a generic trojan downloader that downloaded a bunch of things.



What I found interesting was when, looking at what it downloaded, there was a Windows metafile.  There was a PDF.  There was an HTM file, or an EXE with an HTM extension.  And in looking closely at them, basically this was a spray of all recently known openings in Windows, but all with the same agent, the same infectious agent.  So essentially this was a spray at the machine, looking for any porous openings in the configuration and patch level and security of the laptop.  And something got in one way or the other and grabbed her laptop.  I thought it was interesting to see, like, a PDF with the most recent PDF hack, and the Windows metafile hack, and all the different things we've talked about.  This thing was, whatever it was she did, was spraying her machine, like, trying to find a way in.  And unfortunately it did.



LEO:  We've talked about that before, that these companies in Russia sell kits, exploit kits, with a bunch of exploits in them.  And they put them all in one web page.  And if you happen to hit that web page it's going to try everything because maybe you patched this, but maybe you didn't patch that.



STEVE:  Exactly.



LEO:  And of course, if she hadn't patched anything...



STEVE:  That would have had a field day.



LEO:  I guess just all of them come in; right?  Holy cow.



STEVE:  In classic errata, I misspoke, I think it was last week, one of the Q&As, I mentioned that SSH used SSL.  And it's not the case.  SSH has its own transport.  The reason I got confused was that TLS is Transport Layer Security, and SSH calls their protocol Transport Layer Protocol.  So it's like, okay, let's for the record make that clear, that SSH is not using SSL tunneling.  It's got its own, which is also secure and has virtually the same set of protocols and operation.  And fundamentally it is SSL, but not formally.  It has its own.



LEO:  It's using - what kind of encryption is it using?



STEVE:  Oh, it's got, in the same way - and we'll be talking about SSL protocol here very soon, as I've promised.  SSL has, like, a dictionary of encryption, as does SSH.  So there are mandatory encryption, for example, Triple DES is a requirement for SSH.  But you might also have 128-bit, 192-bit, or 256-bit AES.  And so the endpoints are able to negotiate dynamically and say, here's the encryptions that I know about.  Which do you know about?  And then they end up, like, choosing the strongest that they both know about in order to - and that's a negotiation performed on the fly at the connection initiation.



LEO:  Okay.



STEVE:  Another little tidbit is every so often I find a fantastic little piece of freeware.  And people have said, oh, Steve, you should do that all the time, or tell us what all your freeware is.  And it's like, well, I tell you the good things I find.  I found AllSnap, that I love, where it snaps, for Windows, it snaps the borders of windows to other windows or to the screen, which I really like for quickly aligning things.  Then more recently I told everyone about KatMouse, which has this wonderful effect of automatically scrolling with the mouse wheel whatever your mouse cursor is floating over, without having to click in the window in order to bring it to the top or make it current, you know, in order to give it so-called focus.  It automatically sends the scrolling of your mouse wheel to whatever you're hovering over, which is great.



Well, I don't know what it was that I was looking for, but without really intending to I stumbled on something else which I absolutely love.  It's an add-on called Prio, as in priority.  And the author's focus is to allow you to assign sticky process priorities to things.  For example, if you wanted to make sure that you didn't have a low frame rate in Skype, you could increase the priority of the Skype process, and this thing would remember it.



Now, you can use Windows Task Manager now to change the priority of processes.  And this is something that Windows really does obey very well.  But when you close that process, the system has no sticky memory of that.  Well, what I like about this is that it goes far beyond just that, because that doesn't really excite me that much.  But it does a bunch of interesting things from a security perspective.  It is a very small DLL.  It's like 200-some-odd K DLL, which functions as an extension to Windows Task Manager.  So you install this, and you don't really notice anything happens until you restart Windows.  Then when you run Task Manager, it has added two tabs to Task Manager.  In the normal process view, which is where I spend a lot of time, like just sort of in order to enumerate all the processes that are running, see how much memory they're taking and so forth.  It colors them based on whether they are signed or not.  So you're instantly able to see everything green has a valid digital signature.  Anything red does not.  So that doesn't mean that it's evil, but it just means that, for whatever reason, it hasn't been digitally signed.



LEO:  Nor does it mean it's not evil.  I mean, just because it's digitally signed doesn't mean it's completely safe.  You just know who it came from.



STEVE:  Exactly, exactly.  Then the other two tabs are really nice.  One is a services tab.  So you're able to instantly look at all the services that are running, similarly colored with green and red.  And, you know, non-signed services are much more rare than non-signed executables.  And so there it's like, oh, wait a minute, why is a service that I've got not signed?  I just clicked the tab as I was talking, and I noticed that Parallels' DHCP service for virtual NIC is running.  Well, first of all it's not signed.  But now it's like, wait a minute, why do I even have that running, taking up a chunk of my machine's resources?  So after this podcast I'm going to go disable that.  Which you're able to do from this interface also.



And then the last thing, the last tab it adds is a TCP/IP monitor tab, that is, essentially a real-time netstat that shows all of the connections that - all of the IP connections your system has, the state that they're in, which processes are using them, and whether those processes are digitally signed or not.  Anyway, I absolutely, for people who've been listening to this and saying, hey, that kind of sounds like a good thing, I recommend this without hesitation.  It's a very cleanly written, very small, lightweight, not loading down your system, little add-on.  And, I mean, it's really enhanced my Windows Task Manager.



LEO:  Very cool.



STEVE:  And my last little bit before we get to the topic is I found a really fun little blurb about SpinRite from someone who asked me not to say his name for reasons that he makes...



LEO:  A spy?



STEVE:  No, he didn't want to embarrass the person who he helped with SpinRite.  Actually he sent this on January 1st, 2009, so a couple months ago.  And he said - "SpinRite Eases the Path to Retirement" was the subject line.  He said, "Hi, Steve.  In the unlikely event that you do choose to read this out on Security Now!, I'd appreciate it if you could avoid mentioning my name.  My location is fine to reveal."  Oh, he's in Toronto, Ontario.  He said, "To avoid embarrassing the friend who is the subject of this piece.  Thanks."  Although actually his friend's name I don't think was revealed, so I don't know if she's someone who listens to Security Now!.  But he said, "As a longtime Security Now! listener and a computer user since roughly the dawn of time, I'm suitably paranoid about pretty much everything I do with computers.  Which is why I've always detested Outlook's way of lumping everything about your email into a single file.  I've never been able to shake off the worry.  What happens if the file gets corrupted?"



LEO:  Oh, I agree.



STEVE:  Oh, yeah, I mean, it's bad.



LEO:  It's the main reason I don't use Outlook is that big old Outlook.pst file.  It's just a bad idea.



STEVE:  Well, and, for example, Eudora.  I use Eudora, and every folder is a separate file.  But it's a plaintext file.  You're just able to, like, scan through it and...



LEO:  And it's a standard Internet mbox format, so other programs can read it.  I mean, this is how it should be done.



STEVE:  Yup.  So he says, "What happens if the file gets corrupted?"  So I've stuck to programs that don't put all your eggs in one basket, like Eudora and, lately, Thunderbird.  Well, eventually it happened, but not to me, to a friend who just retired from a firm she founded 20 years ago, and which had recently been sold to a multinational.  She needed to move her email archive over to her newly bought laptop before her old one went back to the company.  Easy enough.  Copy it to a USB storage device and then set things up as they should be.  Except that the 1.4 GB .pst file" - which is what Outlook stores as a single, monolithic file that we talked about.



He says, "The .pst file containing all the email wouldn't copy.  It returned the dreaded CRC check error.  Was there a backup copy of the file?  Of course not.  Despair and gloom pervaded the establishment.  My wife and I were helping our friend and her husband celebrate her retirement and New Year's Eve at her cottage deep in the country amidst the snowdrifts.  Just the way of spending New Year's Eve that we all seek out, contemplating the loss of one's email archive stretching back many years.  Happy New Year."  He says, "You can guess the rest, of course.  It may have been a cottage, but it had an Internet connection.  So I was able to purchase and download a copy of SpinRite and mount it on a small USB drive that I happened to have in my bag.  I've been SpinRiting my hard drives for years, but this was the first time I'd seen it actually find a problem."  That's because he's been SpinRiting his drive for years.  You know, we've talked about it before preemptively and as preventive maintenance.



He said, "...actually find a problem.  DynaStat kicked in and worked away, converting dots" - oh, and says "...worked away and recovered most, not all, of the data.  In other words, actually do something other than just plod through the sectors, converting dots to shaded rectangles.  Very exciting.  And as the New Year arrived and the champagne cork popped, SpinRite finished its work.  Lo, the PST file now copied without trouble.  My friend's retirement could begin.  Thanks for a great product, and thanks to you and Leo for such a stimulating and informative webcast series."



LEO:  Oh, isn't that nice.



STEVE:  Yup.  Happy New Year.



LEO:  Happy.  You know, there's one question I want to ask you before we get to IE8, and it's off the cuff.  I just noticed this, that April 1st is a special day for Conficker, and we don't - I don't think we know what Conficker is going to do on April 1st.



STEVE:  Ooh.  So it's got that date built into it.



LEO:  Yeah, apparently it does.  And I just wondered if you knew anything about it or had anything to say about it because it's going to happen before our next episode.



STEVE:  Actually, no, it happens on our next episode.  So...



LEO:  We'll have to - we can talk about.



STEVE:  Oh, no, no, you're right.  We're recording on the 1st.



LEO:  Yeah, we record on the April 1st.  And you'll hear us talk about it after the fact.  I guess there's nothing much to say except that this would be a good time, if you've got...



STEVE:  So it's an April Fool's - Conficker knows about April Fool's.



LEO:  You might want to scan your computer.



STEVE:  Oh, and speaking of which, Leo.  When I scanned this laptop belonging to my friend, I used both AVG and avast!.



LEO:  Both free.



STEVE:  And avast! found more...



LEO:  Interesting.



STEVE:  ...than AVG, substantially more.  That is, there were - it was the - I mentioned the spray, as I termed it, where the same agent had been encoded in a PDF.  It had been scrambled in some JavaScript.  It had been stuck into a Windows metafile.  Those various ob- obscurations?



LEO:  Yeah.  Obfuscations?



STEVE:  Obfuscations, that's the word I was looking for.  Those obfuscations eluded AVG.  In both cases I set them up to scan slowly but surely, like take your time, do everything you want to.  And so I did the avast! scan separately.  And it found about 50 percent more than AVG did.  So, I mean, that's anecdotal.  It doesn't mean anything conclusively.  But I thought our users would appreciate knowing that in this case avast! came out ahead.  And, I mean, I'm glad to know that those other things that were missed by AVG were found by avast!.



LEO:  Lately a lot of people have been saying that they prefer avast!.  I've been hearing that a lot from people.  I'll have to take another look at it.  Because I think it comes and goes, you know, AVG was better for a while, and I think avast! is now.  I still prefer ESET NOD32.  But I'll send you - actually you can download a free copy.  I'd be curious if you see anything different from that.



STEVE:  I'm going to run - I want to try the MSRT scan that we've talked about, the really deep deliberate scan.  And I made several backups of her...



LEO:  Oh, good.  I was going to say, this is good, you can keep an image of her drive and use it as kind of a test bed for these guys.



STEVE:  I'll do that.  I'll report next week.



LEO:  Oh, good.  Good, good, good.  So let's get to the matter at hand:  Internet Explorer 8.



STEVE:  Yes, well, this is the first major update since IE7, which happened in October of '06.  So a little over, like, almost two and a half years we've been living with IE7.  And in fact IE8 has been in beta for just about a year.  And it's interesting, too.  When I was thinking about this, I thought, you know, we didn't - on this show we didn't mention that the 20th Anniversary of the Web had just recently occurred, a week or two ago.  The World Wide Web turned 20.  At that time IE turns eight.



LEO:  Well, actually that's clever.



STEVE:  So but actually not eight years, but at least eight...



LEO:  Eight versions.  I'm trying to think, let's see, I first - IE, because I remember I did an editorial on the site in 1995, when IE3 came out, saying watch out Netscape, Microsoft's here.



STEVE:  On the march.



LEO:  On the march.  And if I were you I would sell my stock.  Which kind of irritated Marc Andreessen, as I remember.  But it turned out to be right.  So 3 came out 14 years ago.



STEVE:  Wow.



LEO:  IE1, I don't know when it came out.  But it must have been, I think - didn't they buy - they bought Spry's code.  I can't remember whose code they bought.  They started with a code base.  It was either Mosaic or Spry's browser.  Do you remember that?



STEVE:  I think I remember it being Spry, yes.



LEO:  And that would have been - couldn't have been earlier than '93 or '94.



STEVE:  No.



LEO:  So it's probably 15 years old, 16 years old.



STEVE:  Yeah, it's funny, I had an occasion to fire up Windows 98 the other day.  This forthcoming DNS benchmark, which has revealed some really cool things, Leo, about, for example, routers you don't want to have doing your DNS proxying because, well, we learned that it's possible to crash them, but also they just tend to slow things down, and they're unreliable as a DNS proxy.  But we'll be talking about that when I talk about the benchmark.  But it was because there was some - I think there was something, oh, I know what it was.  I had, in the intervening years since I've been programming '98, I had changed the way some of my Windows API code works.  And this benchmark is heavily multithreaded, and there's some parameter changes between XP and the NT-flavor OSes and the older 95/98, so that this thing wasn't working on 98.  So I fired up 98, installed it in a VM so that I could contain it and work with it.  I had the most interesting feeling, though, using it.  And that was, you know, for all of the movement that Microsoft has made all this noise about, really not that much has changed.



LEO:  Yeah.



STEVE:  I mean, you look at 98, it's like, oh, everything's sort of in the same place.



LEO:  Kind of familiar.



STEVE:  The way I remembered it.  And it was like, wow, how long ago was that, and why does it not seem that different from XP at the moment, which is where I still am.  I'm not over on Vista.  Where I guess things really have begun to look a lot different.



LEO:  Vista and then 7 are very, very different.  But one of the things that makes Microsoft successful and one of the things that's always been a benchmark for them is downward compatibility, supporting legacy.  So they don't, because business users are their primary market, they really don't want to change too much from version to version because they don't want to have to do a lot of retraining.  By the way, I found a page on Microsoft's site written by Sandi Hardmeier called "The History of Internet Explorer."  They bought Spyglass's code from Mosaic.



STEVE:  Spyglass, that was it.



LEO:  In 1995 they licensed the source code from Mosaic to Microsoft.  The first version of Internet Explorer was not released with Windows 95, but came out later with the Plus pack.



STEVE:  That's right.



LEO:  And then they put out something called the Internet Jumpstart Kit, and then the Internet Connection Wizard.  So it is - actually it's only about 14 years old.



STEVE:  Wow.



LEO:  Just so you know.



STEVE:  Well, so we've got a new IE8, and I want to talk about the things our listener base cares about.  I did hear you and Paul talking about, from a feature standpoint, the web slices, which are like little mini pages that IE will automatically poll on remote servers, looking for any changes, and then alert you to those, and various other sort of UI things.  But of course my focus is, okay, what kind of a job have they done from a security standpoint?  And, you know, security and privacy.



It's worth mentioning that, unfortunately, it is still the slowest browser among the top five on the 'Net.  Chrome comes in as the fastest in running the SunSpider JavaScript benchmarks; Firefox in number two place; Safari, surprisingly, in number three; and Opera in number four position; and IE8, number five.  Now, Microsoft makes a bunch of noise about how fast it is and that it's the fastest.  It turns out that that's - apparently it's in their testing a little bit faster than something else, not in script performance but in dumb page rendering, which that's valuable, but we're becoming so script happy these days that JavaScript rendering speed is important.  Chrome just apparently is way faster than the rest of the pack, really.  Firefox is 59 percent faster than IE8.



LEO:  I should point out that there's a Firefox 3.1 data that is considerably faster than 3.



STEVE:  Oh, good.



LEO:  Yeah.  So they're paying attention to this.  And Safari 4, which is also in beta, is paying attention to this, and the new WebKit is.  So I think they're all in the pack.  You know, one of the things Paul Thurrott says is, yeah, IE8 is, what did he say, 50 percent slower.  But it's all in milliseconds we're measuring this, remember.  It's pretty fast.



STEVE:  And the fact is your local rendering time is much less significant than your roundtrip packet travel time.  So it's like, yeah, okay, you can demonstrate this.  But in terms of the user experience, when I was using IE8 to poke at it, it seemed very snappy to me.  And that was even then in a VM, in a VMware virtual machine running XP.  It's like, okay, this is - it was working well except that I was able to crash it repeatedly, which we'll talk about in a second.  So one of the things that I saw, that I heard you and Paul talk about, is the so-called "compatibility view."



LEO:  Yes.



STEVE:  I was nervous about IE8 and when it was going to matter on the Internet because my script-free menuing system at GRC had been broken under all of the betas.  And so I was thinking, okay, I'm going to have to go in and do something.  It had a weird effect where the menu items were spaced out by, like, a blank line of blackness.  And it was like, okay.  And I had seen that on a couple browsers during the development of the menuing system, which tended to be highly browser specific because browsers are still, you know, there is no standard.  I mean, I'm really glad that at least Microsoft has made so much noise about IE8 being more standards compliant than any of their previous browsers because I had to do a bunch of things under specific versions, prior versions of Internet Explorer in order to make them work the same way that Netscape and Opera and Safari worked.  So this is generally a good thing.



The way it works is interesting, too, because I'm sure you know from having spoken to Paul that Microsoft has broken many websites, sort of like my menuing system, which had adapted themselves to the fact that prior versions of IE were not very standards compliant.  But the good news is that whatever it was that was broken for me, that was broken with GRC's menuing system under the betas of IE8, they got fixed.  And I checked, it's not because Microsoft special-cased GRC.com.  It's that it was a problem which they fixed, and so it was fixed naturally.  And I did find one strange little rendering anomaly when I was checking IE8's cookie handling, which is still broken, as was IE7.  It turns out you're unable to block all third-party cookies, even if you tell it that's what you want, which has been persistent...



LEO:  You'd think by now they would have fixed that.



STEVE:  I know.  Well, I haven't made a big bunch of noise about it.  And in fact my planned noisemaking has been delayed by this work on DNS because one of the things that I'll be doing is really drawing attention to the fact that no versions of IE allow you to block third-party cookies.



LEO:  Remember that Firefox said we can't do it anyway, so remember they took it out for a while?



STEVE:  Yeah.



LEO:  Saying because it's broken or something.  So maybe that's Microsoft's point of view, too, is...



STEVE:  Well, no, this is - the way this is broken is different.  What happened with Firefox was they took it out, and it was my cookie pages, which are soon to be public, made them put the switch back in.



LEO:  Aha.  Good for you.



STEVE:  Yeah, because they knew that people were going to - you had to go through that weird about:config and then bring up that whole page of stuff, and then type in c-o-o-k to find only the entries about cookies, and then go change some random, I mean, it would have been a real pain for people to fix this.  But we're going to shine a bright light on this.  And it turns out that IE is among the most broken of the browsers in terms of cookie handling.  But anyway, I did see a rendering anomaly which I was able to fix by putting it into compatibility mode.  What compatibility mode does is it causes you to fall back to the IE7 rendering engine, which is the non-standards, or less standards compliant, I don't have any idea how standards compliant IE8 is.  They say they passed the Acid2 test.  Does that matter, Leo?



LEO:  It is a compatibility test.  It's a very difficult test, and a lot of - no browser, to my knowledge, does it a hundred percent.  So, yeah, it's important.  It's a CSS test, so it is - I think there's an Acid3 now.



STEVE:  Well, I'll be interested to find out what this one little rendering deal I saw was because it's - I have used a lot of CSS in my newer pages.  And so something's strange.  So I'll track that down.  But...



LEO:  It's done by the Web Standards Project.  So, I mean, it is, it's the one thing I know of that you can really test...



STEVE:  Well, so that's a good thing.  And I'm glad they're finally doing it.  And they had to bite the bullet in order to make IE8 standards compliant because, as we've just been saying, they've broken thousands of web pages on the 'Net.  And so what they have is they have a built-in list of known incompatible web domains.  And when you go there it automatically drops your IE8 back down to use the IE7 renderer.  In addition, there's a little button, showing like a cracked page button, which you're able to toggle at will on whatever site you're at.  So if you went to a site that looked like stuff was not looking the way you'd expect it to, you can just press this little button, and it drops it from IE8 into IE7 mode and then refreshes the page, which will probably cause the page to look correctly.  The nice thing is that the browser then remembers that that domain needs, apparently, to be rendered in IE7 mode, and that's a sticky setting.  And I found myself thinking, oh, why couldn't they just do this with scripting?  I mean, okay, here they're breaking pages, and then you push the button to fix it.  Well, that's the same as turning off scripting.



LEO:  Sure, sure.



STEVE:  And you push the button to fix the page.



LEO:  Right.



STEVE:  So it's like, okay, well, that's all I would ask for in an IE.  Maybe we'll get one one day.  But so I'm still over in Firefox mode with the NoScript add-on because it allows me to do that.



LEO:  Somehow I doubt that's ever going to happen.



STEVE:  I know.  I don't think so.  Not from a mainstream browser.  But they have done one amazing thing that I will get to here.  One of the things that they have done is they have enhanced the Delete Browsing History.  You are now able to surface a whole bunch of buttons on their little toolbar.  So, for example, Delete Browsing History, you're able to say I want to add that to my toolbar.  What they've done, though, is that you can optionally accept, that is, make an exception for any of the sites which are in your favorites.  They've renamed their Links is now Favorites.  So they sort of merged the terms.  So what they used to call Links is now - everything is just called Favorites.  And so you can optionally cause any sites that you have in your Favorites tree to retain browsing history; whereas Delete Browsing History then gives you some granularity on what kind of things you want to delete - cookies, past history, form content, and a bunch of different things.  You're able to turn those on.  So they've made that very nice, which is good from a privacy standpoint.



Of course the popular feature is the so-called - they call it In Private browsing, which it's funny, as I was reading some reviews and getting some more background, I saw one writer referring to it, it's like "a.k.a. Porn Mode," as he called it.  And essentially what this does is this causes the browser not to write anything permanently to the system, to keep it all internally while you're doing browsing.  So when you click that button - and it's easy to, again, make a little button, or you can find it in the tool menu, when you click it, it essentially opens - it clones the session, opens a new window that very clearly labels itself as In Private.



And as they say, what happens in Vegas, stays in Vegas.  Well, what happens in this window stays in this window.  No trace of any sort is left behind.  And in my testing I verified that.  I could not, like, this is not super deep, I'm absolutely sure.  But all the things that I did, watching my system very carefully, especially playing with cookies to see whether the leakage that Microsoft has was leaking out of that, and they weren't.  So it really does look like they've got good containment using this "In Private" browsing mode.



Okay, now, the thing that they did that I am more excited about than anything else is something that they call In Private filtering.  In Private filtering, I'm surprised they did this.  It's not on by default, so you'll have to turn it on by default.  And I should have said already, I'm not advising anyone use IE8 yet.  The good news is Microsoft's not pushing it.  They're not, I mean, literally pushing it.  It's not part of Windows Update or Microsoft Update.  I'm hoping they wait awhile before they do that because, well, most users, typical users won't know about it until it arrives automatically, until Microsoft decides, okay, it's time for us to push this out to everyone.



The reason I'm not suggesting that people use it is that it's a browser.  You never want to use the initial release of a major update of a browser.  And it's already been hacked.  The first security vulnerability has already been found.  Proof-of-concept code was demonstrated.  I don't know if that code is on the 'Net.  But I do know that Microsoft has been informed.  They have repeated the problem, and they've acknowledged it.  So now they're in their standard, oh, well, we're examining this, and we'll let you know what happens.  But so we already have the first security vulnerability in IE8.



So there's no hurry to update to it.  There are, I mean, I like this very much as an improvement over IE7.  So when it's matured enough, when it's stabilized, I mean, again, we're going to be finding problems with it, I'm sure.  But then we're still finding problems with IE7, so it's not like that's any big change.  But there are some features that I think really make this worthwhile.  This In Private filtering is top on my list of what I love.  If you turn it on - and it's not on by default.  But if you turn it on, the browser, IE7, running in both In Private mode and not - so this In Private filtering is different than In Private browsing.  So this is the normal default browsing behavior.  It looks at third-party content as you browse the web.  And if it sees that you are going to multiple sites, and those sites are receiving - you're receiving the same kind of third-party content from the same third parties, at some point of multiple hits it blocks it automatically.  You choose how many sites, how many times you have to encounter it before the block occurs.



I wish it would let you set it lower than three.  But three is not bad.  You can choose between three and 30, and the default is 10.  So if you turn it on, a privacy-conscious person will probably crank it down to three.  And I experimented with this.  I turned it on, set it to three, and then I went around to places I figured were going to be giving me junk.  You know, MSNBC, Wall Street Journal, CNBC, CNN, Disney.  I just chose a whole bunch of sort of messy third-party junk coming at you from all directions sites.  And sure enough, I quickly accumulated a bunch of debris.



There was one called 2mdn.net, which is owned by DoubleClick, which of course is owned by Google.  On many sites there was something called flashwrite_1_2.js.  Okay, well, we know what that is.  That's doubtless a technology to create persistent tracking by writing cookies into flash cookies.  And this is a little .js JavaScript that is running in browsers.  So after having encountered it three times on different sites, IE stopped requesting it.  It started blocking it, all by itself.  I ran across two things from GoogleSyndication.com:  render_ads.js and show_ads.js.  DoubleClick.net had something called test_domain.js.  I remember dissecting that some time ago and seeing that it was basically DoubleClick probing the settings in your browser to learn about it.  That's why it's called test_domain.  And then it was sending information back.  So again, blocked after having encountered it for the third time.  GoogleAnalytics.com was running ga.js, obviously "ga" for Google Analytics.  And Quantserve.com was running quant.js.  And this is just - this I was able to cause to happen in the course of about four minutes.



So this is a very cool thing.  And what I like about it is it actually shows some innovation from Microsoft, which we rarely see, in this space especially since they seem so determined to be Luddites in terms of browser technology.  Their theory is that, because pages are now often deliberately mixing content, the so-called "mashup" pages where, I mean, for example, you go to MySpace or Facebook or something, and there can be applets which are scripting, which are part of the page being sourced from another server.  Well, the question is, is that bad?  Is that privacy impinging?  Or is that something that you want?



And so Microsoft's concept is, okay, if we set that to 10, so that you would have to encounter the same thing from the same source in 10 different domains, well, the idea is that's unlikely to happen for something that's, like, an add-on to Facebook or MySpace or something.  Typically only that domain, MySpace, would be sourcing a so-called "mashup add-in" in the form of some scriptable agent from one other given site.  So it allows that, even if you've got this thing cranked all the way as tight as you can to only - to block after three different events.  So it would allow it by default.  But things that are truly tracking sorts of things, like all these DoubleClick events and Google Analytics and Quantserve, for better or for worse, those that are being sourced, spread across the web, and they are for the purpose of tracking, IE will adaptively block those.  Which I think is spectacular.



LEO:  So it sounds like you think this is a good, secure update.



STEVE:  Well, I think that this is a - I would call this a welcome feature.  So that's the In Private filtering feature of IE8.  Now, I'm not leaving Firefox.  But IE still has a 65-plus percent market share.  So more than two thirds of the world are going to be using IE8.  Now, unfortunately this is turned off by default.  But for people who for whatever reason want to stay with IE8, it's easy to turn this on and to crank it up to maximum intolerance, which is to say set it to three repetitions.  And then it's also kind of fun, the reason I know all these things are being blocked is that there is a nice user interface where you're able to see that.



And if you decided, hey, you know, I want Google Analytics, that's something I don't want my use of the Internet to block, you're able to go in and not default block, but to choose from this growing list of things it finds.  You can say I want to allow ga.js, and Google Analytics will be allowed to run as you roam the Internet.  And you might want to say I want Google's ads.  So you can turn on render_ads and show_ads to turn that system back on.  So, I mean, they've really done a very nice job.  But you are also able to say block by default after you enable it, which is not enabled by default.  So that's a good thing.



Now, they have an adaptive heuristic reputation-based approach also.  They have something called Smart Screen Filter.  This is a whole bunch of new terminology that over time we'll become familiar with.  But their Smart Screen Filter gives you on-the-fly site warnings based on Microsoft's own reputation database.  There's a local cache that grows in your browser of known okay sites.  So, like, because generally users are going to many of the same sites all the time.  So if your browser doesn't know for sure that some domain is all right, then it'll ask Microsoft, hey, do we know anything about this?  If it's known to be a disreputable site, you get, I mean, the whole world turns red in front of you.  You just about fall off your chair.  There's no way to miss this now.  The whole background goes red, and a pop-up comes up and says, eh, this would be really unhealthy if you go here.  Otherwise, as you roam around, your browser will learn that Microsoft thinks most sites are okay, and you won't be seeing this.  So it won't false-positive.  But it's another nice layer of warning to help prevent people from going to sites that are known not to be safe.



Now, we know how I feel about ActiveX.  ActiveX is, like, the worst idea that ever happened.  It's right up there, it is, it's just a horror.  I mean, look at all the problems that we have with ActiveX.  Basically it's DLLs for the web, which says, oh, yeah, let's - without asking the user we're going to download and run a DLL.  Well, in IE7 we finally got "ask the user."  That was that little bar that you see, the little yellow bar at the top that sort of drops down and says, this site is trying to run an ActiveX control.  And most of us see that when we do a fresh install on a system because we'll go to a site that wants to run Flash, for example, the Flash Player, which so many sites are now using.  So it's like, yeah, it's fine, install the Flash Player.



Well, what's interesting is there's more granularity now.  Microsoft allows you to allow ActiveX controls to run only on specific sites.  So, for example, as I was doing this it immediately wanted to install Flash Player.  When I looked in the permissions, and it's like, oh, do you want to allow this to be run on all sites, or only this site?  So there's per site granularity, and there's also now per user granularity.  So you don't have to globally permit everybody on a computer to run something.  You're able to say only allow myself to run it, but not others.  So that's nice.



They've also got a really enhanced UI for managing add-ons which I really appreciate.  It used to be that you sort of got a rather terse list of things, sort of like Microsoft was thinking in IE7, they were thinking, well, I guess we really have to show these to people, although we'd rather that they just left it all alone.  Now there's a whole Explorer user interface with categories on the left and lots of information.  You're able to right-click and look at properties to see where this add-on lives, when it was installed, what the status is.  And in fact they also show you how long ago it was activated to give you some ability to understand why something is so slow all of a sudden.  Because it might be that an add-on which is able to insert itself into the whole UI experience with the browser, it might be poorly written or be having problems and causing your browser to have various slowdown problems.



One of the other things that they've done that I appreciate is they highlight the domain name.  So if you put in, for example, www.GRC.com slash anything, everything except GRC.com is light gray, and GRC.com stays black.  Or Microsoft.com, or Windows, or Leoville, I mean, whatever.  The browser recognizes the domain name and highlights that in the URL, which has the effect of helping, again, to prevent people from being fooled by domains which are compound, where for example it'll say PayPal.com.something or other, and then .evildomain.ru, where people will look, and they'll see PayPal.com and go, oh, good, I'm on PayPal.  When in fact that's four layers of subdomain underneath evildomain.ru.  So the browser isn't fooled, of course.  But people can be visually fooled.



So what IE8 would do is it would render everything except evildomain.ru in light gray.  Evildomain.ru would be made black.  And so your eye just automatically goes there.  And that's, again, I'm liking all of this.  It's like Microsoft has really sat down and said, okay, here are the problems people are having.  And these are not just with their browser.  This is browsing in general.  It was not designed for safety, unfortunately.  Safety and security wasn't even a consideration when this was all being originally created.  So it's nice that they've done that.



Also, all of the toolbars, any toolbars that you load into IE, or which load on you, because it's so often the case now that you download software, and if you're not really paying attention, oh, yes, install the Google Toolbar will be...



LEO:  Yeah, I hate that.  I hate that when they do that.



STEVE:  Oh, it's so annoying.



LEO:  So frustrating.  You have to really watch closely.  A lot of people do that now.



STEVE:  Yeah.  The good news is there is now a regular little X, red X Close button to the far left of every IE toolbar.  And just for the heck of it, I did install the Google Toolbar, wondering if that was a per toolbar thing or not.  And it's not.  No toolbar has control over it.  So every toolbar gets it.  And so it's easy to just say, whoops, I don't want that.  You just click on the little Close button.  That pops up a dialogue that then allows you to determine how sticky you want this to be, to disable it and any of the components that it invokes, as well.  So that was a really nice addition.



So, oh, and big deal, in IE8, unlike IE7, under Vista, and Windows 7 as well, DEP, the Data Execution Prevention, is finally enabled by default.  And that's a wonderful improvement.  Microsoft is slowly creeping this stuff forward as they gain experience with it.  So IE7 under Vista has the option of turning on Data Execution Prevention, which is a substantial benefit on modern processors.  That uses the so-called "NX," the No Execute bit.  We've talked about it extensively in the past on Security Now!.  And it goes a long way to preventing buffer overrun-style mistakes, the idea being that, well, and the idea being that you don't want data to be executable.



And so for example we've recently had these problems with PDF files and with image files, JPGs, for example, that are leveraging the rendering engine of the image, or the page has a problem.  So essentially the data space is executed.  So people are able to put code in an image and cause it to run.  Well, not if you've got Data Execution Prevention enabled.  The problem is it's disabled by default in IE7.  It is enabled by default in IE8.  And that is a huge win for long-term browser security.  So that's - we don't get it under XP.  We have to wait for Vista.  But of course a lot of the world is either on Vista or getting ready to move to Windows 7.  So that's going to be another really big deal.



Now, in addition to saying don't use IE8 because it's new, I have to say I would be skeptical about it because it's so crashable.  During my brief testing of IE8, because I'm not living there at all, I crashed it a bunch of times.  In fact, I can't get it to display The Wall Street Journal WSJ.com site, and multiple pages there, deliberately.  I wanted to play around with its tab grouping features, where if you open a tab from another one, like you hold Control down when you click, that says don't switch this page to that URL, open another page.  Well, IE claims as a feature that it opens the new tab immediately to the right of the current one, which it does, and that it calls those "similar tabs," and it colors them in order to visually group them.  Well, I wasn't really able to get very far with that test because on the third one that I opened it just completely crashed the browser.



Now, the browser has got anti-crash protection.  One of the features from a user standpoint is that they're saying that they are - that individual tabs are running in their own processes.  So if a tab crashes, then it only crashes that one tab.  I saw the browser trying to do that.  I got a little popup notice, a little balloon that said this tab crashed.  Actually I wrote down what it says.  It says, quote, "This tab has been recovered," unquote.  The second line:  "A problem with this web page caused Internet Explorer to close and reopen the tab."  Unfortunately, it tried.  I don't know if it got in an endless crash loop or what.  But it never came out of that condition.  The processor showed 100 percent CPU utilization.  And the whole UI was destroyed.  I forced it to die.  And then when it came back up it tried to reload.  It asked me if I wanted to reload all the tabs that I had.  So they've got that sort of like crash recovery stuff.  But when I said yes, it all crashed again.



So it's like, okay, I don't think we're quite ready to have everyone in the world be using this.  I like the fact that you can reopen a tab that you closed by mistake.  I sometimes click Close on a tab I didn't mean to.  And it's like, ooh, shoot.  And Firefox allows me to do that.  IE has that now, too.  And they say that they've got really fancy zooming, which I haven't had any experience yet with. But apparently you're able to adaptively zoom a page, which would be nice because one of the machines I use has an 800 pixel horizontal resolution, and sometimes I'm scrolling from side to side a lot.  Apparently this is designed to prevent that from happening, if you want to zoom in, or if you've got a reduced-resolution page.  So lots of good things.



And lastly, they've got some very nice support for development.  They've got a built-in set of development tools which, for example, allows you to obviously view the page source.  We've had that from the dawn of the Internet.  But it's really nicely formatted now.  And you're also able to browse around in the so-called Document Object Model.  And so they have a built-in DOM viewer that allows you, as a web page coder, to look at the page from that standpoint.  There are third-party tools that allow that.  And Microsoft has even had some of their own add-ons.  But normally they are, well, they've never been built in before.  They are in IE8.



So there's the whole IE8 story.  There's a couple things about it that I think they've really done a good job with.  I mean, in general they're moving this forward.  They've still got some - they've obviously got some problems.  But I really very much like this In Private filtering notion, the idea that, adaptively, if they see you encountering the same add-on script in multiple sites, they will adaptively shut it down to prevent you from being tracked, which is very cool.  They've made it easy to flush your history.  And this In Private operation where you're able to - the so-called In Private browsing, where you're able to open up a window that retains no memory at all of what you do, those are all very cool features.  And a lot better control over ActiveX, although we still have ActiveX.  We're suffering with the never-ending problem of that security.



LEO:  Yeah, yeah.  Well, you can't - they'll never get rid of ActiveX.  Too many things rely on it.



STEVE:  Yup, yup.  And as you say, they will never get rid of scripting completely.  So it'll probably be Firefox.  I mean, again, you can do what I used to do when I was under IE, which is you're able to use the Trusted Zone to enable scripting, and let the Internet Zone have scripting disabled.  So you can get some of the effect of Firefox.  But we've got Firefox.  And Firefox has a mature ecosystem of add-ons.  It's doing much more for you, I think, than IE is.  And it's still, Firefox without question is still, in my opinion, the more secure browser.



LEO:  But as you point out, IE is the default browser for the world.  So as Microsoft goes, so goes Internet security.  So I'm glad they're at least paying a little attention to it.



STEVE:  Right.  And so ultimately, when they end up moving this to Windows Update so that everyone starts receiving it automatically and updating themselves, all the 7s will update to 8s.  And to the degree that the default settings are useful, and I think these default settings, there's more attention to not letting users, not letting inattentive users get fooled.  This will move the security bar further along and in general be a good thing.  And there are some features that it would be nice to see Firefox steal.  I mean, this adaptive website tracking elimination, that's a very cool thing.  I like that a lot.  I'd add that to Firefox in a heartbeat.



LEO:  I bet somewhere there's a button that you could change it from three to one or, you know.



STEVE:  Yeah.



LEO:  So that it doesn't wait for three tries to turn it off.



STEVE:  Yeah.  In fact I did try to go down below.  Of course it stops at three.



LEO:  [Indiscernible] somewhere, yeah.  I bet there's somewhere, some setting.  We'll find out when it comes out.  I've been using 8 on Windows 7 for some time, but that was kind of a prerelease.  And now it's out for everything but Windows 7, actually.



STEVE:  And again, no hurry to jump to it.  It crashes on the Wall Street Journal website.



LEO:  That's kind of hard to believe.  That's just hard to believe.



STEVE:  Already it's been hacked.  There's a first vulnerability.  I mean, again, there just isn't - there's nothing so compelling about it that I would think anyone would have to jump to it.  I'm going to wait for it to be pushed onto my system.  And I've got it running in a virtual machine, so I can go visit it if I ever need to.



LEO:  I don't think they'll push it.  I remember when IE7 came out it was almost - it wasn't even like a forced update or a critical update.  It was just you should really use the new 7.



STEVE:  Right.



LEO:  And they'll probably just do the same thing there.



STEVE:  Right.  In the meantime, I think everybody who's listening here is probably happy with Firefox.  And I think they should be.



LEO:  You bet.  All right, my friend.  Thank you very much.  A great subject, and one everyone needs to know about.  If you want to read as Steve talks, you know we have transcripts thanks to Elaine.  She writes everything down.  And Steve puts that on his page, GRC.com.  You can find all the show notes, 16KB versions of the show, and Elaine's transcriptions there.  And while you're there, check out SpinRite, the world's best disk recovery and maintenance utility.



STEVE:  Yay.



LEO:  It's a must-have.  I didn't hear any yabba-dabba-dos.  You turn those off now?



STEVE:  Yeah, 'cause I think they're just a distraction, so.



LEO:  We're going to - I've been inspired by you.  I want to make a device that will pop my ball if somebody donates a thousand dollars to TWiT.  So we're going to work on that.



STEVE:  You want to be careful who you say that to, Leo.



LEO:  My, you know, the blue ball I sit on.



STEVE:  Pop your blue ball.  That's much better.



LEO:  And I'm going to have a Nerf gun that's aimed at my forehead.  And if you pay, you know, $10 it'll shoot an arrow at me.  I figure I'm going to take this yabba-dabba-do thing to the next level.



STEVE:  Maybe we could get some sort of a robot arm where it'll throw a shoe at you.



LEO:  There you go.



STEVE:  Agh.



LEO:  We have a guy, I mean, there's a guy who's an expert in robotics is going to build some stuff.



STEVE:  Cool.



LEO:  And we get a ping, we could set it up to get a ping whenever there's a donation.  So we'll see.  GRC.com, that's the place to go for SpinRite.  Oh, and don't forget ShieldsUP! and all those great free security utilities.



STEVE:  And more stuff coming soon.



LEO:  Yeah, I can't wait, I can't wait.  Thanks, Steve.  We'll see you again next week for Security Now!.



STEVE:  Thanks, Leo.  We'll do a Q&A, and I will remind our listeners, please send me your questions, thoughts, and comments:  GRC.com/feedback.  I go through all of that when I'm preparing for the Q&A episodes every other week, and read as many and answer as many as I can.  And we do a great show with those.  So GRC.com/feedback.



LEO:  Fantastic.  Thank you, Steve Gibson.  We'll see you next time on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#190

DATE:		April 2, 2009

TITLE:		Listener Feedback #63

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-190.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 190 for April 2, 2009:  Your questions, Steve's answers #63.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now! on the most important security day of the year, April Fools.



STEVE GIBSON:  And isn't it perfect that I sound like crap today?



LEO:  I am Leo Laporte, and that guy, way distant far away...



STEVE:  Hello, Leo.



LEO:  ...is Steve Gibson.



STEVE:  Earth to Leo, Earth to Leo, come in, Leo [crackle]. Over.



LEO:  Steve's on the phone today.  He's using his PDP-8 for Skype, and that's what they sound like.



STEVE:  Yeah, I thought I'd have more time to work out the code.  But we seem to have a problem here.



LEO:  That's what happens when you use a 12-bit computer to do an 8-bit job.  But it's a big day.  We're recording on April 1st.  Of course this will air on April 2nd.  But we've got to talk about Conficker.  We've got to talk about that GhostNet, the giant spy network created by some foreign government.  There's lots to talk about.  Plus we've got 12 great questions and answers.



STEVE:  Yup, and another bad problem has been found in Windows kernel.



LEO:  Good lord.



STEVE:  Yeah.  It just never ends.



LEO:  When will it all end?  So Steve, I don't know where to begin here.  This is the day that Conficker was supposed to phone home.



STEVE:  Well, actually, yes.  What happens is on April 1st the security analysis in the industry, looking at the Conficker code, also known as Downadup - and this is actually - so far we've had three variations of Conficker, the so-called .A, .B, and .C.  The .C most recent variation has been - there's been this cat-and-mouse game with the Conficker control masters or bot masters and the security industry.  The key for keeping a worm or botnet - and Conficker is both - essentially alive is allowing it somehow to update itself and to avoid the authorities.  So one of the reasons that this particular worm is doing so well, if you want to put it that way, is that it's able to phone home to get updates to itself.



And normally what happens is, for example, a couple websites will be determined to be, like, control points.  And those will be shut down, thus cutting the worm off from any updates, or in some cases from control.  Well, the earlier versions of Conficker were doing something new; and that is, they were using a pseudorandom algorithm to choose domain names which would extend all the way into the future.  And so the idea would be that, instead of it having a few domain names hardwired into the code, that people could reverse-engineer and claim, essentially register preemptively.  This thing just keeps generating them.



LEO:  It's so smart, so clever.



STEVE:  Oh, it is, unfortunately.



LEO:  Yeah.



STEVE:  I wish these guys would get a real job, in which case...



LEO:  Hey, I bet this job pays pretty well.  I mean, we don't know - do we know what they're up to really?



STEVE:  Well, we know that, I mean, it's a botnet.  It spams.  It attacks.  It also infects.  So what's happened is on April 1st, instead of generating and checking 250, a random set of 250 constantly moving target domains, on April 1st today, or yesterday if you're listening to this on our release date for the podcast of Thursday, that number jumps to 50,000.



Now, that means that the worm will be randomly checking one of 50, or many of 50,000 different sites per day, which makes it, I mean, really difficult for the security guys to preemptively block, to register and block those sites.  All they have to miss is one.  That is, if the bad guys choose one out of the known 50,000 that the worm will try to contact, then they're there, and some of the worms will get there.  Conficker also has a peer-to-peer technology that means that they don't all have to reach the mothership.  They've also formed an interlocking network among themselves.  So if only one gets updated, it's able to update its peers.  I mean, it's beautifully designed to survive.  And so far it has done that.



LEO:  It's pretty amazing.  Now, did this - today was the day it was supposed to go get variant D.  And the last I saw, it hasn't.



STEVE:  I have not been looking at it today.  I've been producing this podcast all morning.



LEO:  I've been watching.  In fact, I started watching because, you know, it's so funny because it's very hard to sort through this because even the tech press seems to be completely incompetent when it comes to analyzing and understanding this stuff.  So you're getting all these variants.  One magazine said it's going to be at midnight, a rolling midnight across the world, which doesn't actually - I don't - maybe that's what it's doing.  Another one said midnight GMT.  So I started looking around 10:00 p.m., which is about three hours in.  And the servers had gone live.  The Confickers had picked the 500 servers they were going to use.  But no data had been handed off yet.  And so I suspect that what's happening is they're - it doesn't have to be now.



STEVE:  No, no.



LEO:  It could be any time; right?



STEVE:  Right.  Right.  Essentially, the code that's already in place, which is the C variant, that code that's in place changes its behavior on April Fools Day of 2009 to dramatically expand its - basically its potential target domains.  Now, there is still a lot more B variant than there is C.  There weren't that many updates to C.  It's still significant, but there's still a lot of B.  The B variant doesn't do this.  It's only the C variant of Conficker which changes its behavior on April Fools Day.  So, and it's funny, too, because, I mean, the popular press has been - anytime something malicious has a trigger date, that sort of catalyzes the press.  It's like, oh, you know, we can talk about this on March 31st.



And I've had people, my regular normal friends, sending me email this morning, oh, should I turn my computer off?  Do I have to worry about anything because of this April Fools Day thing?  It's like, no.  I mean, this doesn't directly affect people.  This changes the behavior of something which, now, moving forward, it can be much more difficult potentially to block this.  But nothing happens, as far as we know, specifically today.  It's just that the behavior changes today.



LEO:  Well, I guess we'll just keep up to date on what's going on and fill you in.



STEVE:  Yup, yup.



LEO:  Once again, though, I'm just impressed by the technical skills these guys have shown.  It's just...



STEVE:  Well, you know, it's a cat-and-mouse game.  And so smart people against smart people.  I mean, these are smart people.  And so as the security industry has come up with and gotten better at blocking the communications, the command-and-control channel of previous botnets, the botnet authors have scratched their heads and said, okay, how do we get around this problem?  And then that one gets fixed.  Okay, how do we get around that problem?  And so...



LEO:  That's why this payload thing is smart because, as new problems arise, you can update your virus.



STEVE:  Yeah, yeah.



LEO:  Not to give them any props whatsoever.



STEVE:  In other happy news...



LEO:  Yes?



STEVE:  ...we do have a new bad kernel integer overflow that's been found in only XP.  So Vista people don't need worry, nor Windows 7.  But it's across all of XP.  It's in the gdiplus.dll, and it's the enhanced metafile, the EMF.  In fact, the formal name is Microsoft GdiPlus EMF GpFont.SetData Integer Overflow.



LEO:  Oh, boy.



STEVE:  What it all means is that, if a maliciously crafted image can somehow be shown on your computer, that's a takeover event.  So put it on a web page, you visit the web page, your machine is compromised.  Send somebody an email.  If they're using, for example, Outlook with the - I was going to say with the preview pane.  But even if you didn't, if you view the email, the act of viewing it displays the image.  Your machine is compromised.  Or even embedding the malicious image in an Office document, and you open the Office document, bang.  And even in a PDF.  I mean, anything that displays, that uses the Windows renderer to parse this enhanced metafile image can cause this integer overflow to occur.



I looked at the website for the guys that have completely dissected it.  And although there isn't - it's not currently known that this is in the wild.  Microsoft knows about it, but there's no patch for it.  So now we wait.  So now it's a question of who's going to get there first.  And here we are at the beginning of April.  So the question will be, will Microsoft be able to get something out the door by Patch Tuesday, which is the second Tuesday of the month.  And what is this?  That will be, well, they have two weeks because it didn't happen this week because this is Wednesday on the 1st.  So they've got two weeks.  My guess is this is bad enough that we will see a patch for this in two weeks.  So there's a two-week window, given that they make it in two weeks, during which time something bad could come out.



LEO:  Remember Microsoft saying with the last WMF exploit - actually, remember, actually it was we said - who thought it might be an intentional plant in the WMF.



STEVE:  Well, that was a...



LEO:  They should really dump this code.



STEVE:  ...very controversial position that I took a little over a year ago.  It was that - and remember that Mark Russinovich looked at the code, and he said, uh, this does look like it was in there from a long time ago.  It was clever.  You could imagine that, like, back before in the days when security was a concern, some guy said, hey, we have an interpreter for metafiles.  That's what this whole metafile thing is.  It's basically - it's a little interpretive language where it's like, move here, draw line here, put cursor here, draw circle of this radius.  It's an interpretive language.  That's what a Windows metafile is.  And you can imagine the developer saying, you know, what if we wanted sort of like an escape hatch where we could actually run native code in the image file, not just interpretive code?



And way before the Internet, I mean, Windows metafiles were there in Windows 1.0.  It's an original core component.  And so security, no one had a concept of a malicious image back then, or the idea of communicating it.  So it was like, that's sort of a harmless extra feature that may never be used.  Well, looking closely at the metafile interpreter, the hackers said, hey, we know how to use that.  So anyway, that's the history of that.  I do think it was intentional.  I don't think it was an intentional backdoor.  I think it was an intentional feature that Microsoft forgot to remove, that was never used or required.  They just forgot to remove it over the passage of time.  Sort of like they forgot to remove raw sockets when they went to XP.



LEO:  Whoops.



STEVE:  Yeah, there's another little problem.



LEO:  Now, this one, I mean, this is an integer buffer overflow.



STEVE:  Yes.  This is not a feature.  This is something...



LEO:  This is bad programming.



STEVE:  Right.  And, I mean, true, it's the programmer's fault.  I will, in defense of programmers everywhere, just say that, whoa, this is - it's just so hard to find every possible way that a program can be abused.  It's just hard.  Programmers look at it in terms of getting it going, not in terms of, oh, how could what's going somehow be made to do the wrong thing?  So it's just difficult.



LEO:  Yeah.  Wow.



STEVE:  Okay.  Also, since we've last spoken, Firefox bumped itself up to 3.0.8.  And the Firefox updates seem to be coming a little more often than they used to.  This fixes two security vulnerabilities that involve, one of them at least, a malicious XML file.  You would have to view a malicious XML file.  So it's not something that's super critical.  But Firefox is good about updating itself.  So I would imagine our listeners have seen their Firefoxes update automatically.  I know that I did a few days ago.  So that's being dealt with.



LEO:  That, by the way, one of the exploits they say they fixed on the Apple version, the Mac version of Firefox, is that instant exploit that was used at Pwn2Own.



STEVE:  Right.



LEO:  I didn't realize it was not just a Safari exploit, but it was a problem in Firefox, too.  So they fixed that, yeah.



STEVE:  Right.  And I don't think we've talked ever about a Cisco router update.  But there is one.  I want to mention it because I know that we've got listeners in IT and who are, like, involved with networking.  And I wanted to make sure they knew that Cisco had released the first in a long while update.  There's eight updates that address 11 security flaws in the IOS, Cisco's router firmware.  So anybody who's maintaining and keeping Cisco routers up will want to make sure that they're aware of that.



And then finally, on the security front, news came out this week about an interesting network, basically a spy surveillance network which has been named GhostNet by its discoverers.  It is the topic of next week's Security Now! podcast.  An old buddy of mine, John Markoff, who used to be at InfoWorld, he's now writing for The New York Times.  And he wrote an article, I'll read a little bit at the beginning of it because it gives our listeners a quick snapshot of this.  The title was "Vast Spy System Loots Computers in 103 Countries."



"A vast electronic spying operation has infiltrated computers and has stolen documents from hundreds of government and private offices around the world, including those of the Dalai Lama, Canadian researchers have concluded.



"In a report to be issued this weekend, the researchers said that the system was being controlled from computers based almost exclusively in China, but that they could not say conclusively that the Chinese government was involved.



"The researchers, who are based at the Munk Center for International Studies at the University of Toronto, had been asked by the office of the Dalai Lama, the exiled Tibetan leader whom China regularly denounces, to examine its computers" - that is, the Dalai Lama's computers - "for signs of malicious software, or malware.



"Their sleuthing opened a window into a broader operation that, in less than two years, has infiltrated at least 1,295 computers in 103 countries, including many belonging to embassies, foreign ministries and other government offices, as well as the Dalai Lama's Tibetan exile centers in India, Brussels, London and New York.



"The researchers, who have a record of detecting computer espionage, said they believed that in addition to the spying on the Dalai Lama, the system, which they called GhostNet, was focused on the governments of South Asian and Southeast Asian countries.



"Intelligence analysts say many governments, including those of China, Russia and the United States, and other parties use sophisticated computer programs to covertly gather information."



LEO:  An interesting point.  We kind of knew that these kinds of things were going on.  Didn't we?



STEVE:  We did.  But what's really cool, and the reason I want to give this next week's episode, is that their report is beautifully written, conservative, no hyperbole.  It's very nicely written.  It's extremely comprehensive.  And so I'm going to absorb it all and distill it for our listeners and really sort of - I think we'll have a great episode next week talking about an instance of this.  I mean, sure, we all sort of presume it's going on.



LEO:  And we're probably doing this.  I would hope we're - in fact, I'd be disappointed if we're not doing the same thing.



STEVE:  It still strikes me as sci-fi, this notion of cyber warfare.  But I guess you need to take it seriously.



LEO:  Well, it'd be imprudent...



STEVE:  Yes.



LEO:  And I have to figure that for at least five years the NSA and others have been working on this kind of thing.



STEVE:  Yeah.  Oh, one hopes and presumes.



LEO:  Yeah.  I would hope our hackers would be every bit as good as theirs.



STEVE:  Right, exactly.  Okay, so that's next week.  Errata, or sort of errata:  Every so often, as our listeners know, I stumble upon something that I think is neat.  I ran across an interesting add-on for Firefox that I wanted to share, which may suit some people and may not others.  The way I run Firefox as my browser is, as I'm researching things or running around during the day, I'll use control-click to open another tab.  And I use it sort of as a placeholder.  Like I'm going to get to that, but I don't want it to distract me right now.  Consequently, I end up with a huge number of tabs open.  I mean, so much so that Firefox gives up trying to show them all, and I get little scroll arrows on the left and right so that I can move through them.  Which is sort of a problem because I'd like to have a better view.



I just stumbled on something, I think it might have been it was suggested to me by Firefox.  Maybe it was a new version or update or something.  Anyway, it's called Tree Style Tab.  And so if you put into your Find Add-ons dialogue in Firefox "Tree Style Tab," it'll take you right to this.  What this does is, there's many different ways it can display.  What I've done is I've opened up, like, a tab list on the left-hand side of Firefox, so that I've got the whole height of my screen now to show me my tabs.  And when you're on a page, and you shift-click to open another tab from a link, it indents it in outline style so you can see the parentage and trace back the relationship.



So anyway, I'm still - I've only had it for a day.  So I still am - my instincts are to go up to the top where tabs used to be.  And I'm not yet retrained.  But already I can see so many more tabs.  And the hierarchical representation is something that I really appreciate.  So it's funny because I told a friend of mine, and he said, oh, no, I just - I only have - I don't like multiple tabs.  I just have one thing at a time.  It's like, okay, this is not for you.



LEO:  No, no.



STEVE:  So I recognize this may not be for many of our listeners.  But if there are people like me who end up with, like, with just tab insanity, this thing really looks like it's going to be a great solution for that.



LEO:  I think power users and techies use a lot of tabs.  Kevin Rose two weeks ago on TWiT was talking about that.  And he said - he just said, okay, how many tabs do each of you have open?  And it was an average, I think, of 17 or 18.



STEVE:  Yeah.



LEO:  It's very common.



STEVE:  And oh, one very cool thing about this, I mean, this thing's got features coming out of its ears.  It's got more features than I've talked about.  But, for example, you can protect tabs, which I really like because, for example, I'm still keeping a track of DEC PDP things on eBay.  So my very first tab for a long time has been a tab open to my eBay page.  My second one is something that I use for kind of keeping track of the stock market.  It's a nice little stock market ticker viewer.  Well, I've gotten used to them being there.  But every so often I'll delete them by mistake.  It's not a big problem to reopen it.  But this allows you to protect the tabs, essentially locking them in where they are and to their page.  So then you just hit refresh every so often.  So anyway, it's got a ton of features.  If people, like, organize their lives through their browser based on tabs, I wanted to let people know about Tree Style Tab.



LEO:  I'm installing it now.



STEVE:  It's cool.



LEO:  Sounds like something I'd use a lot.



STEVE:  In going through the mailbag I ran across a number of people who were a little despondent at being behind in Security Now! episodes, catching up, hearing about the PDP-8 kit that was made available several months ago.



LEO:  Yeah.



STEVE:  And they're still available.



LEO:  Oh, good.



STEVE:  So I wanted to - I just wanted to let people know not to be despondent.  All of the first round of them were made and sent.  I've got my three.  And I'm not parting with any, so don't bother asking.



LEO:  No begging.



STEVE:  But there are still some available, both the full kit for the board itself, and for the front panel, and a bag of add-on parts for the front panel.  So I just wanted to let any listeners know who were saying, gee, I'm really sorry I missed being up to speed on that because I would have loved to do that.  It's SpareTimeGizmos.com is the site.  SpareTimeGizmos.com.  Or you can probably search for SBC, as in single-board computer, SBC 6120.  That's the name of the chip, which is a single-chip PDP-8 this kit is based around.



LEO:  Some people are reporting in our chatroom - I think everybody went off to download that Tree Style Tabs.  And some people are reporting the same experience I had, which is - and I occasionally get this with Firefox add-ons, an error saying the CRC is inaccurate or something.  And just my tip to them, this has happened to me before with these beta - it usually is with beta add-ins.  Right-click and download it, and you'll get a .xpi file which you can then open directly in Firefox, and you won't get that same error.  I don't know why that happens.  I think it's either a bug in Firefox, or it has to do with signing or something like that.



STEVE:  And maybe it's that the site's busy?  Could it be that...



LEO:  Could be we killed the site.



STEVE:  Because it worked for me just, I mean, I just downloaded it directly into Firefox in the normal way.



LEO:  It might be a Mac thing.  I don't know.  But anyway, I've installed it now, and I'm loving it.



STEVE:  Oh, it's a good thing.



LEO:  Yeah, yeah.



STEVE:  A couple people asked, with regard to the multifunction YubiKey, whether or how they could get the newer version.  I sent email off to Stina, which I received a reply to.  Apparently they're going to be using one of the major Swiss or Swedish, I wasn't sure which, automotive key manufacturers to make their next round of keys.  So they're probably ramping up production.  It's not going to be available until after the summer.  And they are going to be offering a discount to existing customers.  So it won't - there's no real way to upgrade your key or to trade the single function for the dual function.  But at least people who have keys will be able to get them at a better price.



LEO:  Yeah, great.



STEVE:  And then one bizarre thing that just sort of crossed my radar.  I was reading in the SANS security list, their newsletter, somebody was talking about - he was actually attending a security conference or event down in San Diego.  And he received in his phone bill an excessive roaming charge from Verizon for his EVDO, which is what he uses to get on the Internet, of $199.



LEO:  Whoa.



STEVE:  And it turns out - get a load of this.  He talked to Verizon.  They said they would remove it from the bill because he said, you know - the point was he was close to the Mexican border.  And the Mexican cell towers are not that busy and have high signal strength.  And so his card was captured by an out-of-country tower, which caused him, even though he wasn't out of country, to be hit with super-high roaming charges.  And apparently the problem is even worse near the U.S./Canadian border.  So I thought that was just, like, the kind of thing you never expect or think about.  But it's like, whoops, gotcha.



LEO:  Oh, man.  Did he appeal it, and will they give him his money back?



STEVE:  Yes.  They said - they did remove it from his bill, they said, but just this once.  So his advice was be careful about what you're being captured by in terms of cell usage.  And it may not be safe to use something that's got high roaming charges near a border point where you're not sure because there's no obvious demarcation.  It's all automatic.



LEO:  Yeah, it should - I guess they don't want to bug you, but they should warn you if they're going to do that.



STEVE:  They really ought to, yes.



LEO:  You can turn off data roaming in most phones, which is probably not a bad idea if you're going to be near the Mexican border.



STEVE:  Oh, so that you would deny any non-local carrier.



LEO:  Data roaming can be very expensive.



STEVE:  Right.



LEO:  Basically what that says is only use Verizon for your 3G data.



STEVE:  Right.



LEO:  And that's probably, you know, a good idea, prudent for most people, anyway, yeah.



STEVE:  Well, we're half an hour in.  And I've got a SpinRite testimonial, but so many people in our Q&A mentioned SpinRite this week that I'm going to skip the testimonial.  We'll do it next week.



LEO:  Who needs a testimonial, my god.  Everybody knows SpinRite's the one.



STEVE:  Well, this is really well written and really neat.  But we'll do it next week.



LEO:  All right.  Yeah, we've got some great questions, 12 questions, coming up in just a second for people who - the questions are really our chance to talk back to Steve and get clarification.  And Steve's so great at answering these questions and explaining what's going on, which is really great.  So we've got questions.  Let's get to them, lots of them, for Mr. Steve Gibson.  Starting with Michael, an expat.  He's using something called TOR, The Onion Router, and he wants more:  Hi, Steve and Leo.  Thanks for the great show.  I'm an expatriate living in Southeast Asia, and I like to use TOR to visit some areas of the web.  I understand why, you know, he wants some privacy.



As I have some interests in U.S. and European businesses that often restrict their services based on the IP address's incoming location, so I've configured my tor.rc to only exit through certain U.S. or European nodes, and not to have the exit node hop around.  Oh, I didn't know you could do that.  That's cute.



STEVE:  Yeah, isn't that neat?  A nice little tip in there, too.



LEO:  So far, so good, as long as I'm only interested in anonymity, that is, in sites that don't need a login.



The problem comes when I try to use TOR's features with sites or services that require a login.  Seems to me there is no way to know if I have picked a compromised exit node - and this is really an important phrase, "compromised exit node" - that can sniff, log, or otherwise misappropriate

my credentials.



Steve, I'd love it if you would run a TOR server.  I feel after years of listening now that your node would be trustworthy.  I think we know that.  I'd be sure to make your server the exit node of choice in my tor.rc file.  What do you think?  Would you consider adding a server to the TOR network?



STEVE:  No.



LEO:  Yeah.  I wouldn't, either.



STEVE:  Well, and here's why, and here's the problem, is that I care passionately about Michael's characterization of me being trustworthy.



LEO:  Yes.



STEVE:  I mean, I would absolutely myself never in a gazillion years consider taking advantage of that trust.  But I don't have control of the traffic once it leaves the wire in my rack at Level 3.  And that's why I thought this was an interesting question, and one that we needed to discuss, is that it's certainly the case that you might have untrustworthy TOR exit points, meaning that there's, I mean, inherent in the TOR network is this notion of aggregation of traffic.  There are only so many TOR exit points.  And everyone using the TOR network has all of their traffic jumping from one server to the next.



And if our listeners, if we have any listeners who don't remember about TOR or don't know what this is, we did a beautiful podcast on it, how we explained why it's called The Onion Router and how each node only knows enough to take one layer of encryption off of the data and then forwards it on to the next so that it really creates a very strongly encrypted, anonymous system, and even when it comes to, like, routing the data between TOR servers.



Ultimately, though, you have to leave the network at a so-called "exit node."  At that point the last, the innermost wrapper of encryption is removed by the exit node TOR server, and your traffic goes onto the Internet without any encryption capsulation.  So you can imagine that anybody, any entity, whether it's governments or malicious people, not to say malicious governments, but anybody who's interested in the kind of traffic that people might want to anonymize, you might imagine that the traffic entering and exiting TOR nodes is more interesting than just the random sea of traffic on the Internet because there is a presumption that there's something, there's some reason that people want to have anonymity and the privacy that TOR potentially creates.



The point is that anyone operating such a node, like myself, can control their own node, that is, can say, okay, I know that I've made it secure, it's got its own firewall protecting it.  I don't care what data comes in or out, I mean, I've got 20-plus years of history of dealing with hard drive data.  And every so often, more in the old days, people would send a drive that they desperately needed repaired, and I'd sort of do it as a favor.  Well, as a matter of honor I never looked at anyone's data.  I don't care about that.  I just - I like the idea of being able to fix it and being able to send it back.  So similarly, I don't care about what is going on, if I were to run a TOR node.



But the point is, ultimately I'm connected to my provider by some wire.  And it goes to a router somewhere.  And off it goes.  At that point I've lost all control.  If I had a TOR node, and it was an exit point, then all the client traffic has been decrypted as it left.  And if, for example, some government were to subpoena an eavesdropping operation on that wire, I would never know.  So with the best of intentions I would - basically the trust that had been placed in me would, through no fault of my own, be subverted.  So that's just not something I would want to do.



LEO:  I'm going to also refer you to a blog post that I read recently from - it's calumog.wordpress.com.  His post is:  "Why you need balls of steel to operate a TOR exit node."



STEVE:  Huh, interesting.



LEO:  And he says, "I totally believe in TOR," as we do.  "I think it's a magnificent force for the circumvention of Internet censorship.  But there's a problem.  I was visited by police in November 2008 because my IP address had turned up in the server logs of a site offering, or perhaps trading in, child pornography.  The date of the offense was one month after I started the server."



So it looks like the site in question had been under surveillance for more than a year.  The police made what's known as a dawn raid.  They threatened to burst down the door.  They had never heard of TOR.  They had no idea what he was up to.  But just the fact that somebody had used TOR to access that server, he was the exit node, so he was the node of record, implicated him.  They took his computer, went through it forensically.  He was never charged, fortunately.  But that's the risk you run.  You don't know what people are using it for.



STEVE:  Right.  Well, and here's Michael, who's living in Southeast Asia.  He'd like to have access to services that are only available to U.S. and European IP addresses.  So it's one of the things that TOR does is allow you to anonymize yourself and lock your exit node to specific IPs, which is very convenient.  So it's a tremendous service.  But as you say, Leo, it comes with a great risk to those who are running those exit nodes.



LEO:  Yeah.  And we thank them for doing that.



STEVE:  Yes.



LEO:  And we encourage you not to do anything illegal on those servers.  Listener Fred says:  What's an HTTPS scanning server?  Steve, I especially enjoyed your series on HTTPS, secure HTTP.  But I have a question about something called an HTTPS Scanning Server.  When I log onto my corporate domain every morning, I have to click through a pop-up window agreeing to be monitored.  The text of the pop-up says, "Users are subject to monitoring at any time, including accessing HTTPS websites using iAccess.  HTTPS scanning servers decrypt all HTTPS traffic."  I am curious about their claim to be able to decrypt HTTPS traffic.  I don't object to this on my corporate domain, but it begs the question, can it really be done?  And what's to prevent any other server from doing it?  We've talked a little bit about this in the past.



STEVE:  We have.  And I don't want to belabor the point.  But I wanted, first of all, Fred says he doesn't object to this on his corporate domain.



LEO:  Doesn't matter.



STEVE:  I want to make sure that he understands this is not just accessing his corporate domain, but accessing anything outside his corporate domain that is being scanned.  So the idea is that, first of all, I did like this question because it demonstrates a concrete instance of this happening.  We've talked about it.  I talked about having gone to RSA and talking to a company that is offering these services.  I wanted to make sure, because I think it's important, that our listeners really get it that HTTPS can be decrypted on the fly if your system has been configured in advance to allow that.



So Fred's question says, I don't object to this on my corporate domain, but what's to prevent any other server from doing it?  Well, it's the configuration, the use of this so-called iAccess approach, where all of the clients in the corporation are accepting a certificate from the gateway which allows a secure - essentially allows the gateway to function as an impersonation of the remote server.  Essentially you're saying that your gateway is trusted like a so-called certificate authority.  And it's that, like a root authority, so the gateway is able to essentially sign the certificates of sites that you think you're visiting.  In fact, you're visiting the gateway.  Your traffic is decrypted there, analyzed, and then reencrypted for its transit across the Internet.  So I just wanted to - I liked this because it says this really does happen.  Here's an example of it.  I'm impressed that every time, every morning when he logs on, he's reminded...



LEO:  That's a good thing.  Because they don't have to do that.



STEVE:  No, they don't.  And I did like that about it very much, that it's like, okay, we're going to - you're going to say "Yes, I agree," every single morning at the start of the day.  And we're going to remind you that this is what's going on.



LEO:  I always encourage - first of all, employees have to remember they're using company equipment.  And so the courts have consistently ruled that companies have the right to do any kind of monitoring they want.  But I always encourage - without notice.  But I always encourage companies to make a written policy, to post it, and to tell employees, regularly inform employees of what they're doing.  That probably has a good kind of preventative effect anyway.



STEVE:  Well, and I've recommended that it be put on a strip like a piece - sort of like a Scotch tape across the top of the monitor so it's just in front of you all the time.  Because it's been well established that companies have the right to do this.  However, the psychological effect of learning about it when you didn't know, I mean, that's what causes people, employees to, like, drive their cars through the front office of the company and really become outraged.  I'm reminded of the original discovery of adware from that company Ad-Aware.  And it was - that's when I coined the term "spyware" and wrote that first little antispyware gizmo Opt-Out back in the old days.  And people were phenomenally upset.  I mean, even though the fine print, they had agreed, that they didn't really know this was going on really upset them.  And so you don't want to surprise people this way, so I just say it makes so much more sense to be upfront.



LEO:  I agree.  I agree.  And it has a good deterrent effect, as well.  Jack Jensen, Tampa, Florida, says "I have unwanted company."  He says:  I'm trying to get help.  I'm hearing the sounds of - this is the kind of question I get on the radio show, by the way, Steve, all the time.  I'm hearing the sounds of mouse clicks and keyboard typing, not mine, coming from my speakers.  Even with the browser closed.  I tried Spybot, Malabyte, SUPERAntiSpyware, CCleaner.  Running free of Comodo Firewall.  I do have snapshots of denials of Firefox requests, while I'm using

it, and also of my active connections, if that would help, and I could attach it.  Thanks, and HELP!



STEVE:  Yeah.  As you said...



LEO:  What's going on?  Because I'm curious.



STEVE:  Well, I don't know specifically.  But if this is going on, and Firefox is denying things or is acting oddly, it really sounds like he's not in control of his own machine.



LEO:  He's hearing typing and mouse clicking coming from his speakers.



STEVE:  Yeah.  There's something...



LEO:  That's bizarre.



STEVE:  ...very wrong in his system.  He's obviously tried all kinds of antispyware stuff.  The one thing that I would recommend is, due to the nature of contemporary malware, we've got this problem that we've talked about often called "rootkits."  Once something gets into your computer, it can be extremely difficult to see it because you're using the operating system and trusting the operating system to do the seeing for you.  That is, anything you run on your computer is a client of the operating system, which uses the operating system's services.  I mean, even doing a directory listing, you ask the operating system for a list of the files in a directory.



Well, if the operating system itself is compromised, that is, something has crawled in underneath it, then that something can filter out the response.  We saw this famously with the Sony DRM, Sony's Digital Rights Management, that installed a rootkit which hooked the response to directory listings and removed itself from those listings.  So no matter how much you tried to look, you couldn't see what was really there.  The only way to deal with this is to take the - well, there are many ways to deal with it.  In my opinion, the most straightforward and in some ways easiest way is to take the drive out of the machine and make it a data drive of another machine, and then scan that drive.  You don't want to run anything on this data drive because you don't want anything to have a chance to get off of this infected drive.



But the problem is all of these scanners are scanning after the infection has taken hold.  So they may not be able to see it.  I did this just a couple weeks ago with a friend's laptop that was infected and found everything on it by catching it as a data drive and running the scanner on a good machine against that data drive.  And it was able to find it.  And there was no chance for the bad stuff to get in there and prevent it from being seen.



LEO:  Yeah.  I'm wondering, maybe, could it be just kind of RF leaking into the...



STEVE:  I was thinking the same thing when he - but it sounds like it's autonomous, like it's happening when he's - when it's not he who is clicking things.  And he also says that Firefox is...



LEO:  That's the thing that's worrisome.



STEVE:  Yes.



LEO:  Those certificates or whatever.



STEVE:  Denials of - so denials of Firefox requests.  So Firefox is trying to do something.



LEO:  Well, this was a symptom of Conficker, a very strong symptom of Conficker, because one of the things I think all variants do is block you from going to antivirus sites.



STEVE:  Yes, I was just going to say, if you hadn't said it, that I forgot to mention when we were talking about Conficker, people have been wondering how to easily determine whether they've got it.  Well, try to go to Microsoft.com...



LEO:  There you go.



STEVE:  ...SANS.org or Symantec.com because Conficker blocks at least those three and more.  And your computer just will not go there.  So if you find that your machine will not go to SANS.org, then game over.



LEO:  It also won't allow you to do Windows Updates.



STEVE:  Right.



LEO:  Yeah.  Game over, man.  You know, I think, given that we know that there's probably somewhere between 9 and 15 million computers that have Conficker on them, that it's a very good likelihood that people listening to this show don't have it.



STEVE:  I think that's true.



LEO:  But that they know people who do.  So it would be the good thing to do, the Good Samaritan thing to do to talk to your less sophisticated computer friends about this and spread the word.



STEVE:  Yes.



LEO:  Paul Harding in Calgary, Alberta, Canada wonders about external drive recovery.  Well, you've got the right guy.  Steve, I have a question you might want to address for all SpinRite potential customers.  Although I personally don't own SpinRite yet, I have heard now hundreds of testimonies that praise the wonders of SpinRite.  I have no doubt that SpinRite is a fantastic product.  My question is in regards

to the usefulness of SpinRite on external USB, eSATA drives and NAS drives.  Currently on my computer I have 5.6 TB of storage.  You know, a few years ago that would seem out of, you know, out of control.



STEVE:  Oh, mainframes didn't have that much storage.



LEO:  Yeah.  But now it's like, eh.



STEVE:  Okay, double drive.



LEO:  Eh, big deal.



STEVE:  I got that in my bathroom.



LEO:  I just ordered 12 gigabyte drives for our NASes, to upgrade our NASes.  It was a terabyte, I mean, 12 terabyte drives.  It was a terabyte, three [indiscernible].  We were going to upgrade the NASes.  And a terabyte is kind of - it's $100.  It's the default size now.



STEVE:  You know, I'll just interject here, I had Mark Thompson visiting twice over the last couple weeks.  He was driving through.  He went up to the Game Developers Conference, the GDC up in...



LEO:  Oh, I wish I'd known, I would have loved him to visit.



STEVE:  Yeah, well, he was with a bunch of friends and back-to-back meetings.



LEO:  Oh, okay.



STEVE:  He's got all kinds of things going on.



LEO:  He's busy, yeah.



STEVE:  So he's super busy.  But he happened to mention that he's using Western Digital drives.  And I remember the days when nothing could make me use a Western Digital drive.



LEO:  I know that's changed, though, hasn't it.



STEVE:  And that's my point.  I wanted to give them real props.  And I know - I heard you speaking, maybe it was to Andy, about some, like the 1 GB Black - the Black Caviar...



LEO:  Caviar Black, yeah, that was to Ryan Shrout we were talking about those.



STEVE:  Right.  And so I just wanted to say that, I mean, I know that there are - it is a moving target.  And it's the case that a company that, I mean, hard drive storage is on the edge.  It's always on the edge.  Because if they could fit any more data in there, they would.  And so they do.  Always to keep themselves on the edge, being as competitive as they can.  But so as a consequence it's sort of - you can go through a bad spot, a rough spot where your process just isn't nailing it down, or that it's got problems after a few months.  And after being burned by a succession of WD drives, I swore them off.  But this was 15 years ago.  On the other hand, those memories are slow to die.



LEO:  They are.



STEVE:  I think it's clear that this memory should be dead, and that I need to give Western Digital another look.



LEO:  You know, Egghead had a deal of $119 for 1.5 TB Seagates.



STEVE:  Wow.



LEO:  But I was a little...



STEVE:  Oh, Seagates.



LEO:  I was a little slow to buy the Seagates.  And I said you know what, I'm going to buy the Western Digital Caviar Greens instead.



STEVE:  Yup, I think they're now the - I think they're the sweet spot.



LEO:  Yeah, yeah.  And the Greens are good because they run a little bit slower, cooler, lower energy, and perfect for a NAS.



STEVE:  Yes.



LEO:  We're going to put four in Drobos - four in a Drobo because we're going to give that away.  And we're going to put four in the NAS, and we're going to use the other four for recording the shows.  I've been using Hitachi.  I know you like the Hitachis.



STEVE:  I do, very much.



LEO:  They bought the Deskstar line.



STEVE:  Yes, from IBM.



LEO:  Yeah.  Let's see.  Moving along.  Oh, we're continuing to answer a question.  I forgot.  We haven't even gotten to the question yet.  I know a little extreme for a home user, he says about the 5.6 TB.  However, I edit video and regularly max out my storage space.  1.5 TB of this space is completely external drives, 1.5 TB in a NAS.  Can SpinRite maintenance be used effectively on the USB or the NAS?  Thank you for your informative podcasts.  I've been a loyal listener since the beginning.  And as an aside, I have a great story about how your podcast helped to catch a criminal.  What?



STEVE:  Mmm.



LEO:  I'm waiting for the trial to begin and will send you the story once I am not in a place that could compromise the case.  By the way, you should do an episode on computer forensics.  I would love that if you did that, Steve.



STEVE:  We'll do it.



LEO:  Yeah.



STEVE:  Relative to SpinRite - and maybe other data recovery utilities, I really can't speak authoritatively about anything other than SpinRite - there really is a difference between external serial interface like - traditional serial interface like USB and Firewire, or network and eSATA.  What I mean is that eSATA is essentially the same, the external SATA, serial ATA, that is just like the ATA interface, but it's been serialized.  So there's the same total access to the hard drive's guts for eSATA, SATA, and PATA, the parallel ATA.  Those are the best way of letting SpinRite have access to the drive, is anything that's ATA, because there's a whole vocabulary of commands which are not about transferring data in and out, but are about the inner workings of the drive, which give SpinRite far more intimate connection to the drive.  It's able to do things that it cannot do if you are over a network, where basically your API, so to speak, your interface is read this block of sectors and write that block of sectors.  That's pretty much all the remote coupled or the USB and the Firewire interfaces allow is read and write data.  They do not allow nearly the same level of recovery and intimacy.



So we recommend to anyone who really wants to maintain their drives, or especially data recovery, it is worth taking the drive out of that configuration, sticking it onto a motherboard, and running SpinRite against it there.  The results, I mean, we hear also people doing data recovery remotely through USB and Firewire.  It can work.  But if it were me, I would always go to the trouble, if this was important data, to give SpinRite the best connection it can have for the drive.



LEO:  Yeah.  I think I told somebody that on the radio show this weekend that, yeah, you want an internal drive.  It's the best.



STEVE:  My neighbor said - she was out watering the lawn yesterday.  She said, hey, I hear you have six Palm Treos, or Palm Pilots.



LEO:  Not the Pilots.  I think I said the T, what was it, the TXes; right?



STEVE:  Yeah.  Yes.



LEO:  Yeah, I think I said the TXes.



STEVE:  I said, what?  How could you possibly know what my Palm Pilot count is?



LEO:  Here's what happened.  A guy called up, was furious.  He had a Palm Pilot.  And basically Palm, it's over for Palm, that Palm OS, and they're going to go to their webOS.  In fact, the jury's still out whether that'll be enough to keep them alive.  And he said, but what about us?  I love my Pilot.  And I said, well, I have a friend, Steve Gibson, who felt the same way, loved the TX so much he bought a half dozen of them and put them in the freezer.



STEVE:  Yup, they're still there.  They're in the refrigerator, just waiting in case I ever need them.



LEO:  [Laughing] Now you're looking pretty smart, Mr. Gibson.  I love that.  I use you as an example fairly frequently on the radio show.



STEVE:  Of over-the-top extremism.  



LEO:  Yeah, the geek, the real, the true - what a true geek is all about.  Mike Nicklin in Eureka, California writes - he's got three questions.  One, do you accept cookies?  Two - this is like a congressional hearing - do you worry about them?  Three, should cookies be accepted just to keep the hassle down?  Three questions, three quick answers.  So let me give you number one.  Do you accept cookies, Steve Gibson?  The world wants to know.



STEVE:  I accept only first-party cookies, never third-party cookies.



LEO:  Number two - we'll let you explain further in a minute.  Number two, do you worry about cookies?



STEVE:  No.



LEO:  Number three, should cookies be accepted just to keep the hassle down?



STEVE:  That's not necessary, Senator.



LEO:  Thank you.  Speak into the microphone, son, and tell us your position on cookies.



STEVE:  I've been exposed to all the extremes of cookie handling.  There are a lot of people who just don't worry about it, don't care.  They just say, well, I have no control over what happens on the Internet.  All of my privacy and my rights are gone anyway.  So I'm not worrying about it.  I've got better things to do than worry about it.  They're at one extreme.  The other extreme is people who, I mean, really focus on cookie management and go through their cookie list and think, where did this come from, and they delete it.  Or they, like, set their cookie files to read-only, so their browsers bang on the door, unable to store a cookie there.  And then they selectively let them in.  I mean, there's all kinds of policies.



I'm much more of a middle-of-the-road cookie person, which is why I don't worry overly.  But I take a simple countermeasure, which is just say no to third-party cookies.  All browsers allow you to turn them off.  Sadly, not all browsers even do that correctly.  But that'll be a topic for a future show since I have got a cookie forensics technology now working on the site for some time which does a good job of allowing people to see exactly what their browser is doing.



But for most people, for Mike, I would just say go find the setting to disable third-party cookies.  It's in IE, it's in Firefox, it's in Safari.  Everybody's got it.  And just turn that off.  You may want to flush your cookies after you turn it off, and restart your browser because that way you've gotten rid of the debris that you've accumulated.  And then don't worry about it because you've really dealt with the major source of tracking.  Now, Flash cookies are a different matter, and they're becoming a little more pernicious over time, and we'll be dealing with that, too.  But just say no to third-party cookies, and you've really done 99 percent of the work for 1 percent of - you've solved 99 percent of the problem for 1 percent of the work.



LEO:  And I have one more question to you.  Did you ride here in a private jet?  All right.  Moving on.  Lee, Lee W., in West Milford, New Jersey, refuses to elevate his rights.  Steve, I'm a faithful listener of Security Now! since Episode 1 and Leo's other TWiT shows.  It has replaced my radio for my two-hour daily commute to work.  I have learned a tremendous amount from your shows.  I'm also a proud owner of SpinRite.  I tell everybody about it.  It's saved me and my family members several times.  I've been following your discussion about the Microsoft Malicious Software Removal Tool and decided to download this month's release, KB890830.  I launched the tool as described by the Microsoft site and then was surprised by the prompt, "You must be logged on as a member of the Administrators group to run the tool."



Sure enough, it does say that on the download page.  You and Leo have me trained well for security, and I simply won't use my PC as admin, period.  I use a limited user account unless I need to install applications or other items.  It just strikes me as funny that Microsoft didn't design a tool to run for limited accounts, where all software should be designed to run for security purposes.  Most average users should use a limited account to protect themselves.  I did not try it with the automatic updates in the limited account.  I just thought I'd share this with you.  This is actually a really good point.



I love the show and want to thank you for your hard work and dedication you give to the world by trying to make it a safe and secure Internet.  I love your precision - yes, I agree - and great care you have for getting things right.  Keep up the great work.  P.S.:  I, too, use Firefox NoScript plug-in and Block All and run only the main sites as temporary allow.  I sometimes enjoy figuring out which scripts allow a page to work.



So I've modified my recommendation, by the way, to run as a limited user because of User Access Control and the way Microsoft works.  But let's talk about rights elevation.



STEVE:  Well, I would say to Lee that I'm really happy he's taken the philosophy and the position he has.



LEO:  I was going to say, yes, yes.



STEVE:  But there are some times when running as an administrator does make sense.  It's what you have to do.  And he cites when he needs to install software, he needs to run as an administrator.  Well, the fact that MSRT will not run as a limited user is really demonstration of the beneficial limitation normally of being a limited user.  I mean, you would want it not to be able to run because the whole point of being a limited user is that what you're able to do is limited.  But unfortunately this is a trusted, authentic from Microsoft tool that needs to get to the deepest roots of the operating system in order to do its job.  By definition, it cannot do that from a limited user account.  And you don't want it to be able to do that.



So but philosophically I just - I wanted to suggest that Lee back off a little bit and to recognize that it's not the case that there is no role for administration other than just installing software.  There are things, and MSRT is a perfect example, where the nature of it is that its operation requires full access to the system.  You don't want your typical user to have that most of the time, but you do want the administrator, the trusted administrator of the system when running trusted software.  Then it absolutely makes sense.



LEO:  Yeah.  And, you know, you can right-click on any application and run it as administrator.



STEVE:  Yes.  You need to provide those credentials.  And so it's very easy to do.  You don't have to go through logoff/logon process.  



LEO:  And that would be the preferred way to do it because then you don't forget to log out and so forth.



STEVE:  Right, right.



LEO:  So but I still run as limited user, even though nowadays running as - because of User Access Control, even nowadays you don't really run as administrator, even when you're running as administrator.  Right?



STEVE:  Well, yes.  And you know, this is another perfect example of the evolution of security.



LEO:  Right.



STEVE:  Today it is much more practical to run in a non-administrative context than it was when we first started recommending it.  I mean, UNIX has always been this way.  Windows was never this way.



LEO:  Right.



STEVE:  Windows didn't have this notion.  So what happened was that people who tried to use good security practice and be a limited user, they kept running into their software that wouldn't work right that way.  It took a while for the software to catch up because - and it took pressure from the users, users saying gosh, you know, I need my email client to run in a limited context.  And it was just sort of because that wasn't being done often originally, that programs that did not need administrative rights assumed them.  And then they would break when you ran them in a non-administrative context.  Well, we've had years of that now, and software has caught up.  So that original barrier to running as a limited user is pretty much gone now.  And that's a really good thing.  But it's another, again, it's an example of this just taking time.  Unfortunately this is all evolution.



LEO:  Welcome to the wacky world of security.



STEVE:  Welcome to reality.



LEO:  Yeah.



STEVE:  Yeah.



LEO:  Ben Pfountz at Virginia Tech - what a great school - needs to reach out and touch clients.  He says:  Hi, Steve.  Long-time listener here.  Keep up the great work.  I have always wondered if there is a client-server type of application for administrators that works similarly to what gets installed on a zombie machine.



I'm thinking I'd set up a nice dedicated server somewhere, install a lightweight "presence and remote control" service/daemon on each client machine.  The service or daemon would maintain a TCP connection back to the

server, just like a zombie would, updating statistics and allowing me to remote-control the machine.



This would be beneficial to me because I'm finding myself supporting machines in more and more locations, and it's often difficult or impossible to connect to the client machines when necessary because of NATs or firewalls or blocked ports, that kind of thing.  Having the client machines maintain a TCP connection to one of my servers would be very nice because it would bypass most of the network issues I've been having.  In other words, it establishes an outbound connection and keeps it open.



I was thinking about how this kind of app could be created.  Then I remembered you discussing your new VPN application.  I know you're currently in the design stage, so I thought, let me throw this idea your way to make sure you put it in.  I am the only IT administrator for our department, so this kind of functionality would be great for me.  Thanks.  That's a really interesting idea.  What do you think?



STEVE:  It's in there.



LEO:  It is.



STEVE:  Yeah.  CryptoLink is the forthcoming VPN that he's talking about from GRC.  And I was very enamored of the ease of setup that Hamachi offered.



LEO:  Right.



STEVE:  Yet I also heard many people complaining that, when Hamachi's servers went down, the whole Hamachi network went down.  So it's nice to have it when it's there.  It's a problem to depend upon it if it happens not to be there.



LEO:  Well, they were doing kind of a triangle, right, so you would contact the server and - that's kind of what I know GoToMyPC does.



STEVE:  Right.  And so CryptoLink will have a number of different ways to operate because, if you want the super-simple drop-in operation where nothing needs to be configured, I mean nothing, and where both endpoints are behind NAT, then because both are behind NAT routers it's not possible for either endpoint to connect to the other because they can both get out of their own NAT, but they can't get into the other NAT.  It'll get blocked.



So what's necessary is for a third party, a so-called "rendezvous server," they'd connect to this rendezvous server.  The rendezvous server is able to look at the nature of the packets coming to it and then inform the other side about how they should try connecting in.  And so you're able often to knit a cross-dual-NAT connection, but you'd absolutely need that external third party.  So the beauty of that is, it just works.  No router configuration.  It just works.



So I absolutely want my system to have all the features that Hamachi did from that standpoint.  But I also wanted not to depend upon that because, trustworthy as I always intend to be, and will be to the degree it's in my control, I don't want to force anyone to trust me beyond trusting that I wrote the code correctly.  So another way for CryptoLink to work will be in a so-called TNO, Trust No One, mode where if, for example, someone like Ben knew he wanted inbound connections, he could configure his router at his end to allow incoming connections.  Then anybody anywhere, even behind NAT, and independent of firewalls and ISP port blockings and everything, I mean, I'm designing this so that it will always get through, they would then be able to make incoming connections into his network.  So it'll definitely, you'll get essentially the best thing that all these approaches have to offer.



LEO:  I can't wait.



STEVE:  I can't either.  As soon as I get this other backlog of stuff done, I'm onto it.



LEO:  Poojan Wagh in Chicago, Illinois, our question number eight, wonders about password strength meters:  I'm wondering how the password strength meters, those bars that go from red to green - some sites have them - depending on the length of your password, work.  I've noticed that Google, when signing up for an account, or Yahoo!, or Microsoft, or anything that has an indicator of how good a password is, I'm wondering is there some mathematical formula?  If so, what is it?  If I type in "7EDAHR7J," Google says it's strong.  However, if I type in "01234567," Google says it's fair.  Clearly there's more than just length involved.



P.S.:  I used SpinRite last week.  It was especially timely since all our music and videos were on the computer, and I had just bought my wife a new iPod so she could entertain the kids on a spring break trip.  Luckily SpinRite came to the rescue just in time so she has a bunch of music and kids' shows on her iPod for the flight.  So what's the story on password strength?



STEVE:  Well, okay.



LEO:  I think they're making it up.



STEVE:  They are.  Which is not to say that's bad.  What I like about these meters is that it's a nice means of educating the typical user.  Lord knows our listeners, I mean, we spent the first three months of this podcast, Episodes 1 through 12, talking about passwords, I think.  So there's nothing that our users, that our listeners don't know about password strength.  But many of us though there are, we're certainly the minority.  And the idea of rating a password as you type it in, of course that requires some JavaScript to be watching while you're typing.  So the JavaScript is running an algorithm to perform a so-called "heuristic."  A heuristic is sort of the fancy term for a rule of thumb.  And so there is no standard for what makes a good password, or when this goes from red to green.



It's encouraging, for example, that Google was smart enough to know that 01234567 had some problems.  You don't know what the algorithm was that had to decide that.  It might be special casing, looking for sequential number stream.  It might be like looking for a sequential difference between them.  The idea is it's sort of anything that the programmers came up with that are sort of guidelines for the obviousness and the guessability of the password could go into this meter and inform the meter how good it should think what's been entered so far looks.  You'd like to see upper and lower case.  You'd like to see mixed numbers and letters.  And you'd like to see length.  So my guess is, if you see mixed case, mixed numbers and letters, and sufficient length, then that's a pretty good password.  You can write a little bit of JavaScript that will look at those things and rank the password accordingly.  And I just think it's good.  I think if someone puts in their name or their...



LEO:  "Sexy."



STEVE:  Yeah, exactly.  It's going to say, eh, try again.



LEO:  [Buzzer sound]



[Talking simultaneously]



STEVE:  ...nice little closed-loop feedback that I think, again, this is the way we move slowly forward.



LEO:  Basically there's no standard algorithm for determining this.



STEVE:  No.



LEO:  But as you say, the most important thing is random.  Random is good.



STEVE:  Oh, random is the best.



LEO:  The more random, the longer, the better.



STEVE:  Entropy.  We like entropy in our passwords.



LEO:  Entropy.  Of course it's also harder to remember.



STEVE:  Yeah.



LEO:  Dain Nilsson, a YubiKing Winner - yay, congratulations, Dain - asks about using hash functions as ciphers:  Hi, Steve.  First I want to thank you for the kind words you said about KeyGenius and for explaining it so well to your audience.  I have one grievance with you, though.  When announcing the winners of the YubiKing competition, you stated that I was some guy in Switzerland.  I'm Swedish, not Swiss.  No hard feelings, though.  After all, you liked my entry.  And if it weren't for you I never would have heard about the competition in the first place.  We have a lot of Swedish listeners.  Despite my bad Swedish chef voice.  They put up with that.



Anyway, on to my question.  On the HMAC episode you mentioned that hash functions are freely available, are not encumbered by intellectual property, and haven't had the export restrictions that ciphers have had.  Now, this got me thinking.  Couldn't you take a hash function and modify it slightly to use it to encrypt and decrypt data?  I mean, I came up with a scheme.  I'm curious to see if you think it would work or, rather, if there are any security vulnerabilities with it.  So here's what I came up with.  Oh, boy.



We know that, if we have a pseudorandom stream of data, this data can be XORed with the plaintext to produce ciphertext.  A hash function will always generate the same output for a given input.  So to encrypt data using a hash function we could do the following:  Generate a random IV.



STEVE:  That's the initialization vector.



LEO:  Initialization vector, okay.  Supply a passphrase to be used as the encryption/decryption key.  Append the passphrase to the initialization vector, and generate a stream of data that is at least the length of the plaintext according to this function:  f(IV+pass) = hash(IV+pass) + hash(hash(IV+pass)) + ...  + hash(...hash(IV+pass)).  In other words, keep hashing it till you have enough.  Now, each time you produce that hash, you're going to hash the hash, so you'll get a different result each time.



STEVE:  And it'll be longer.



LEO:  Yes.



STEVE:  Because when you add the hash to the end, and so that's longer by the hash's result length than what you had before.



LEO:  So you hash the IV+pass, then you hash the hash of the IV+pass, plus then you hash the hash the hash, and on and on and on.



STEVE:  Right.



LEO:  Till you get enough ciphertext.  Then you XOR the plaintext with this data stream to get the ciphertext.  So now he's going to say again what I just said, which is start by generating a hash of the passphrase and IV together.  Then to make the produced hash long enough, keep hashing it again and again, each time appending the result to the stream.



Now, the thing is, this is reversible; right?  Because to decrypt you just do the same thing, the same IV and passphrase used during the encryption.  So the IV would have to be supplied together with the ciphertext.  We'd have to say, here is the ciphertext; and you need this, the initialization vector.  Have at it.



STEVE:  Right.



LEO:  And of course the passphrase you have to provide.  It seems to me that this should work pretty well.  Have I missed something vital?  I haven't thought of a use for this, since standard encryption is pretty readily available nowadays.  I guess he's thinking this would avoid intellectual property, export restrictions, the kinds of things that current ciphers have.



STEVE:  Right.  I thought this was clever.  But I wanted to share this with our listeners because it demonstrates one of the perennial gotchas in cryptography, which is this stuff is really hard.



LEO:  You can think you've got a good one.



STEVE:  Yes.  My golden rule is, keep it as simple as possible, as simple as you can, but no simpler.  And, I mean, this hashing of the hash of the hash of the hash of the hash will definitely generate something.  But, he says, are there any security vulnerabilities with it?  I have no idea.  I mean, and a cryptographer might instantly go, oh, [sputtering], yes, that's not - it doesn't work because when you iteratively hash a hash, the following thing happens, you know, all the bits in the middle go to zero on odd Tuesdays or something.



I mean, it's truly the case that this stuff is complicated.  And it's often discovered that when you repurpose something that was designed in one specific way for one specific purpose, when you repurpose it to something else, it just has horrible problems.  And it looks great until the geniuses, the crypto geniuses sit down who really understand this stuff, and it turns out that, like, all the middle parts might cancel each other out.  I mean, I'm just making this up.  I have no idea.  But I would never do it.  Not without a crypto genius showing why this is a really good idea.



LEO:  Right.



STEVE:  So you never want to just sort of come up with something because lord knows what you end up with in the crypto field.



LEO:  The object lesson in this is WEP encryption, where perfectly intelligent engineers...



STEVE:  Yes.



LEO:  ...created what they thought was a sound system.  But any crypto expert could have looked at it and said, ah, here's the flaw.



STEVE:  Yeah.  That's a great case in point.



LEO:  Yeah.  Those are smart people.  I mean, it's not like these are - we were saying they were bad and dumb.  But they just weren't crypto experts.  



STEVE:  Right.  And in fact Dain's observation was that, hey, since hashes have always been free of intellectual property claims and patent restrictions, why not do a hash-based crypto?  I think there have been some hash-based cryptos.  I'm sure I've run across them.  But at the same time we now have AES.  So that problem is solved.  I mean, we have an absolutely bullet-proof, super-strong solution free of all that.  Oh, and the other problem, hashing the hash iteratively would be very slow.  It ends up being an expensive way to generate pseudorandom data given that it really was high-quality pseudorandom data.  There are certainly easier ways to do that.



LEO:  Right.  Moving on to question 10.  Richard Frisch in Weston, Connecticut wonders about password overload:  Steve, you've often talked about passwords, but I have situation that is significantly worse than most, and I wonder if you know of a solution to password overload.  I have a client who does accounting, bookkeeping, and other functions for over 60 different clients.  Ironically, one of them is Rube Goldberg, LLC.  She has more online accounts and passwords than I could shake a stick at.  As, by the way, does our bookkeeper.  These bookkeepers go from client to client, and each one has their own set of passwords.  I believe she has more than 200 account names and passwords she needs to

know.  Some of the passwords are static.  Some must be changed periodically.  Sometimes she works from her office computer; sometimes she is at the client's.  Now I'm thinking I should probably ask her how she does this because I want to make sure she's doing it securely; right?



STEVE:  Yeah, for your sake.



LEO:  For us, because she has all our account passwords.  Almost all of the work is on PCs, but a few clients have Macs.  Right now she records all this information in a handwritten journal she keeps unsecured at her desk.  This is not good security, and it's a real pain for her, to boot.  Do you have suggestions for a better, easy way to handle this?  Love SpinRite and the Security Now! show.  Hello to Leo.  Boy, now I have to ask Lisa how she's doing it.



STEVE:  Yeah, and I don't have a specific solution.  I mean, we know that the industry is full of all kinds of solutions.  But I just sort of wanted to step back.  I like this as a case study.  And obviously you can relate to it because you've got an accountant in a similar situation.  Look at all of this nightmare for the single need, the single purpose of authentication.  That's what - this all is, am I me?  And again, here we are in 2009, recording this on April Fools Day.  I'll just bet you, I don't know when, but a decade from now, if someone's listening to this, they're going to be going, passwords?  What?  200 passwords written down on paper?  You've got to be kidding me.  I mean, I don't know whether it'll be that you just have your wrist scanned or your retinas flashed or everybody's got...



LEO:  Or a YubiKey.



STEVE:  ...YubiKeys built into them somehow.  I mean, this problem, we are going to solve this problem.  Today we haven't, and it's escalating.  I mean, the need, the pressure to solve it, as demonstrated by this question, is becoming overwhelming.



LEO:  I mean, just from a purely pragmatic point of view, I probably - I think a password manager would be the right way to go.  There is - I've recommended RoboForm on Windows and 1Password on the Mac.  But there is an open source one called Keepass.



STEVE:  Yes.



LEO:  It's cross-platform.  It's open source.  It uses AES and Twofish, so it's very secure.  So what you do is you basically, you've got a database of all these passwords that is secure in itself.  And then you can put that on a USB key.  You can have multiple copies.  There's no reason not to because the database is itself secured.  I should probably help our bookkeeper with something like that.



STEVE:  Yeah, one, I mean, one question or issue, I guess, is whether you carry the database with you, or you place it in the cloud.  And of course that's a choice that's up to the user.  It's certainly the case that, okay, the problem with the cloud - "cloud" is putting it out on the Internet somewhere - is that it's no longer necessary to trust that entity.  That is, we can pre-encrypt the data before it goes there.  I do that with Jungle Disk.  I have an Amazon account, their S3 service, their storage service.  And Jungle Disk uses a key that Amazon never sees.  So everything there is pre-encrypted.  So it's no longer to trust them except you need to trust their availability.  You need to know that when you're going to log on, that they're going to be there to provide your vault.



And you also - you need to be in a situation where you have access to the cloud.  If you're logging on, for example, to TrueCrypt in a full-drive encryption mode, then you're not on the 'Net at that point.  So in that case you need a solution that can be sort of an offline authentication solution.  So I think it's one of the problems is there isn't a single easy answer that solves every problem.  But boy, do we need one.  I mean, we just need to solve this authentication problem.



LEO:  Yeah.  I mean, I like how you took it to the higher level issue, which has to be resolved at some point.  John Paquette in Framingham, Mass., wonders about Granola:  Dear Steve, I often hear you using the word "granularity" as a synonym for "resolution," as in, "Oh, they've really bumped up the granularity of this so that users will be able to automatically disable AutoRun on drives of unknown types, on removable drives, on network drives, CD-ROMs" - that was from last episode.  Doesn't "granular," like "grainy," mean the opposite of "resolute," "precise," or "articulate"?  Oh.  Love the show.  Heard them all.  Own SpinRite.  Well, "granular" is a geek term, I think.



STEVE:  I guess.  And I think he raises a good point because, okay.  I'll say something is more granular.  Now, what I mean is more finely grained.



LEO:  Not more grainy.



STEVE:  Right.  Well, no.  More, well, okay.  Do I mean...



LEO:  I guess it is.



STEVE:  ...fewer big granules?  Is that more granular?  Or is it more granular if you have many smaller granules?  And I decided it has no meaning.  More granular?  That's a non sequitur.  I think...



LEO:  It's only in conjunction with the idea of globular.



STEVE:  [Laughing] So granular and globular are antonyms?



LEO:  Yeah, well, or - yeah.



STEVE:  No.  I don't think.  I don't think you could have more or less globularity.



LEO:  You're right.  Globular, granular, you're right, yeah.



STEVE:  You know, I think it's...



LEO:  It's a colloquialism.  It is not a...



STEVE:  It is not a precise term.



LEO:  Precise term, you're right, yeah.



STEVE:  Yeah, granular just means able to be broken up.  But I don't think being more granular, does that mean the grans are bigger, or are they smaller?



LEO:  Well, for the first time, because I usually don't pan back so far, but I'm watching on the video, I see the Oxford English Dictionary behind you.



STEVE:  [Laughing]



LEO:  So I think - and I have a copy here, too.  I think we should look this up.



STEVE:  I actually did.



LEO:  Oh, you rock.  And?



STEVE:  And I'm using it wrong.



LEO:  Well, but it's colloquially used.  You're using it properly in the computer science context.



STEVE:  Ah, but what does "more granular"...



LEO:  I agree.  It's a meaningless term.



STEVE:  Yes, exactly.



LEO:  But as with all language, it's understood what you mean.



STEVE:  Yeah, well, John didn't think so.  And I think I'm...



LEO:  Okay, we won't use it any more.



STEVE:  I'm agreeing with him.



LEO:  That's good.  No, you're absolutely right.  What does it mean?  It's meaningless.



STEVE:  Yeah.



LEO:  Wow.  John.  You've made a significant change.



STEVE:  Good job.



LEO:  I love the OED.  You have the full set there, it looks like.



STEVE:  I do.  It's just, oh, my god, they weight about 15 pounds each.  And they've got little tiny thin paper.  And oh, if you ever wanted, I mean, you can trace back the history of the words, into how the usage has evolved over time.



LEO:  Well, that's what made me think of it is what we need is a geek OED that we could trace back to the first geek usage of granular, so we could understand what the context was and why.  Yeah, the OED, the only time I really got mad at my wife - I bought the OED, and I love it.  I thought the kids would use it.  They never do.  I kept going, oh, let's look it up in the OED.  But I always wanted it for myself.  Always wanted it.  So I finally bought it.  It's fairly expensive to buy all, whatever it is, 20 volumes or 30 volumes.  I bought it after reading "The Professor and the Madman," Simon Winchester's book about the OED.  That'd be a great Audible recommendation.  It's really fascinating.



STEVE:  I've come so close to getting it on disk a couple times.  If you look around, though, apparently the access software is really bad.



LEO:  Yeah, you know it's going to be.



STEVE:  Yeah, exactly.



LEO:  It's fine to have a book.  It's a beautiful - it's a beautiful thing.  Where was I going with this?



STEVE:  And you don't have to worry about booting them up, either.



LEO:  Oh, the one time I really got mad at Jennifer, after buying the OED, I found it in the garage on the floor.



STEVE:  Ooh.



LEO:  She said it was taking up a lot of space.  I said [flabbergasted nonverbal reaction].  So now it's here in my office.  With another set of volumes that was taking up space, equally unused, The World Book Encyclopedia.



STEVE:  Ah, yes.



LEO:  We're old analog guys, despite our digital heritage.  Are you ready, my friend, for the last question?



STEVE:  Let's wrap this sucker up.



LEO:  Have you ever read that book, "The Meaning of Everything?"



STEVE:  No.



LEO:  You have the OED.  That was what inspired me to buy the OED.  I said, I have to have this.



STEVE:  Well, I also love that whole concept of a bunch of guys sitting around deciding what words are new.



LEO:  Well, the first thing they had to decide was where do we start?  Where does English begin?



STEVE:  Yeah.



LEO:  And I think that they didn't want to go past Old English.  So I can't remember exactly where they started.  But that's a puzzle.  And then every word, they had to go through almost all the canon, every written word in English; and they made out little slips of paper with the word, the first use, the date of the first use, an example sentence.



STEVE:  Wow.



LEO:  I mean, it's a mind-boggling thing.  So what you have there on your shelf, and what I have on my shelf - it's over on his upper left shoulder, upper left corner for those of you who are watching at home, yeah, there it is - is in many ways one of the most significant books ever written in the English language.  It's just amazing work.  And that book will really turn you on to it.  It's incredible.  I can't figure out if "The Professor and the Madman" is the same book or not.  I own them both.  I should really listen to them and figure it out.  I think they might have retitled it.



Anyway.  Last question.  Rick Hughes in Sykesville, Maryland brings in his Q&A Tip of the Day, "An Easier Way to Use Drive Snapshot."  Now, I got a very nice note, by the way.  Did you get that note from the author of the program that you recommended?



STEVE:  I did, and I'm puzzled about it because I was so sure that I once spoke to someone named Paul Terrell.  And I thought that that's what TeraByte, the T-e-r-a, was from Terrell.  I guess I'm wrong because the guy at TeraByte said...



LEO:  I wrote that.



STEVE:  ...who's that, I never heard of him.



LEO:  David F. of TeraByte Unlimited said:  Steve mentioned on Listener Feedback 62 Paul Terrell [indiscernible] TeraByte.  I have no clue who this is.  The president's name and primary developer is me, David Flicek.



STEVE:  Yeah, anyway, it's funny, too, because I meant to go do an email search because I have all my email from, like, forever, and find out.  Because it would have been an email dialogue about - I thought about...



LEO:  Well, you know what I suspect happened is that he, well, of course he would know the guy's name.



STEVE:  Yeah.



LEO:  Maybe he acquired it?



STEVE:  That's what I thought.  I thought the same thing.  I just, you know, anyway, I'll solve the mystery.



LEO:  I bought it immediately after you talked about it, and I've used it now to image a few things.  And the main reason I bought it is because Drive Snapshot makes it hard to make a bootable disk that you can then reinstall.  And that's kind of the key with an image.  What we're talking about is image software that makes a ghost image of your hard drive.



STEVE:  Right, and Drive Snapshot also runs on DOS, so it's only able to see what DOS is able to see.  Whereas Image for Windows, TeraByte Unlimited's Image for Windows, it brings along its own 1394 Firewire and USB drivers.  It's able to enumerate the bus, find the drives.  And it's also both - it's OS agnostic.  It runs on FAT file systems and NTFS file systems.



LEO:  Right.  Yeah, no, I've been very happy with it.  But I also own Drive Snapshot.  On 188, you and Leo were discussing the difficulty of restoring from an image backup using Drive Snapshot's DOS-based restore disk.  As we just said.  An easier way to use Drive Snapshot is to make a BartPE disk, which is at nu2.nu/pebuilder.  This is a free, bootable Windows XP CD that natively understands NTFS, USB drives, networks.  If you copy your licensed Drive Snapshot .exe file to the BartPE disk, you can just boot up from the CD and use the normal Drive Snapshot GUI for backing up and restoring to any drive - this is really what I should have done - without having to fool with the DOS drivers.  I've been using Drive Snapshot this way for a couple of years with no problems.  I know you've switched to TeraByte's Image for Windows, but Leo and others who still use Drive Snapshot might be interested in this approach.  Thanks for all the great Security Now! netcasts and GRC software.  I've been using SpinRite since version 2.  What an excellent product.



STEVE:  You know, we've never talked about BartPE.



LEO:  We should.



STEVE:  Yes, we should.  I had, believe it or not, my first occasion ever to use it within the last week.  I can't even remember now why.  But I got myself painted into a corner somehow, I mean, I'm old school, so I've got old DOS tools that normally still - I've got Partition Magic and Drive Image, and I'm very comfortable with all of that.  So I think that's kept me from having to mess with BartPE.  But somewhere in the last week I needed it for something I was doing.  And I thought, well, okay, I've heard about it.  I mean, I knew all about what it was.  I'd never done it myself.



So I just wanted to bring it up and mention it to our listeners.  I'm very impressed with what it does.  The idea is that it needs access to your original Windows installation CD.  It's from there that it gets the original Windows installation files.  It's not able to get them from your computer because it doesn't know whether they're intact, what shape they're in, whether you can trust them.  I mean, BartPE is often used, for example, as an AV platform for running Windows-based antivirus.  So you wouldn't want to start with an infected Windows boot.



But what this is able to do and what it does is it builds an ISO image of a bootable CD with files that it gets from a real Windows setup/install CD.  And it just works.  It's a script that pulls the files together.  You're able to add your own, put your own stuff in a directory so that you can customize it that way.  And you end up with this CD that boots and runs Windows from the CD, and then you can do other things that you want to with it, as if you had a running Windows.  And if Windows won't boot, it's often a way to have some tools that allow you to figure out what's going on.



LEO:  I tell everybody to make a boot CD for sure.  This is a good one.  Emergency Boot CD is another one.  And just to be fair, TeraByte also offers a plug-in for BartPE.  And when you download TeraByte, you can download the plug-in.  Makes it very easy to make it part of your BartPE build, so that in future, when you build future BartPE disks, it'll just automatically be included.



STEVE:  Cool.  I think I'll probably put it and Drive Snapshot...



LEO:  Do both.



STEVE:  Yeah.



LEO:  You probably have images lying around from both programs.



STEVE:  Oh, yeah.



LEO:  Well, Steve, we've reached the end of 12 fine questions and true from our great listeners.



STEVE:  And so nice to have flawless telephone quality audio, Leo.



LEO:  People are going to the chatroom, going what's wrong with Steve?



STEVE:  Argh.



LEO:  We will get back to Skype next week.  Just a little...



STEVE:  We absolutely will.



LEO:  ...Skype hap, as happens frequently.  But, hey, I understood every word you said.  So that's the most important thing.  If you want to get 16KB versions, in which Steve will sound even worse, and transcripts in which Steve will sound exactly the same, you'll get all of those at GRC.com.  That's of course the home of Steve Gibson and the Gibson Research Corporation.  There you'll find all his great free security software, like ShieldsUP!, Shoot The Messenger, DCOMbobulator, Wizmo, and the world's finest hard drive maintenance and recovery program, a must-have for everybody - can you put that on a BartPE disk?  I bet you could.



STEVE:  Well, you wouldn't need to because it doesn't need to run under Windows, so.



LEO:  Yeah, I wish you - yeah, SpinRite [indiscernible].



STEVE:  It makes its own bootable.



LEO:  I wish Snapshot would do what you do with SpinRite, which is it makes its own bootable.



STEVE:  Right.



LEO:  You can make a boot disk, but you have to - it's complicated.



STEVE:  It is.



LEO:  SpinRite is available at GRC.com.  Get yourself a copy.  It's well worth it.  And we will convene again next week for more security information.  In fact, next week we're going to talk a little bit more about...



STEVE:  The GhostNet.



LEO:  The spy network.



STEVE:  The uncovering, the discovery of this really multinational, 103 different countries, spy network.  Which, incidentally, is able to turn on the camera and the microphone that are built into various machines in order to see what's going on.



LEO:  Oh, boy.



STEVE:  I mean, we're really talking spy technology.



LEO:  Yeah, yeah.  All right, Steve.  We'll see you then.



STEVE:  Talk to you then, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#191

DATE:		April 9, 2009

TITLE:		GhostNet

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-191.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo begin by discussing the week's security news.  Then Steve carefully and completely describes the construction and operation of a worldwide covert cyberspace intelligence gathering network, operating in 103 countries, that was named "GhostNet" by its Canadian discoverers.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 191 for April 9, 2009:  GhostNet.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that talks all about your security, your privacy, how to protect yourself online.  And Steve Gibson's our man.  If Steve can't do it, no one can.  He's from GRC.com, the creator of SpinRite, the world's best hard drive maintenance and recovery utility; also the discoverer of spyware, the guy who coined the term "spyware," and a security advocate going way back.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you this week, as always.



LEO:  How is everything going in...



STEVE:  Really good.  I got distracted for a couple weeks and pulled away essentially from the work on the DNS benchmark that I hope to be, maybe in two weeks, telling our listeners about because it has ended up being very cool, and we've learned some things, interesting things about home routers and why you don't want them to get involved with your DNS, although by default they typically are now, more and more.  And I did also, brought myself up to speed on today's topic, GhostNet, which is an interesting report that was generated by two research groups up in Canada.  And it's got me thinking about the whole botnet tracking deal, and I have half a mind to set up my own little Conficker honeypot, just I think it would be fun to watch Conficker run.  Of course, you know, security firms all over the world have Conficker honeypots.  And it's like, okay, well, it'd be fun to have a little first-hand information about that, too.



LEO:  Conficker.



STEVE:  Yeah.



LEO:  So you could set up your own Conficker receiving center?



STEVE:  Oh, easily.  I'm sure that my attachment folder, my Eudora attachment folder...



LEO:  It's full of Confickers, huh?



STEVE:  ...is full of Conficker.  It's just - yeah.  In fact, what I'll do is I think I'm going to put avast! back on the machine that I used for scanning my friend's laptop a couple weeks ago when hers got infected, and then just drag the whole - make a copy of my Eudora attachments folder over to that machine and then stand back while avast! says, oh, avast ye maties.



LEO:  [Mock screaming] Run, run for your lives, run for the hills.



STEVE:  I'll find some, and then I'll just install XP on a honeypot machine, and not patch XP; open one of those attachments.  That'll infect it.  It'll jump onto the Conficker botnet.  And then of course I'll have packet-sniffing going on, too.  So I can watch it do things, which is...



LEO:  Oh, ought to be very interesting, yeah.



STEVE:  Yeah.



LEO:  Yeah.  You're a brave, braver man than I, however.



STEVE:  Well, I've got a cable modem with two IPs from Cox.  So I can give it its own IP.  I'll put it behind its own router so I'm not looking at the cable modem traffic, but only the infected host traffic.  And, I mean, I've done that before, back when I was tracking down the weenies that were attacking me.



LEO:  Right.



STEVE:  And basically it was - I have a story, of course, that was very much like what we're going to be talking about this week.  But these guys were - the ones that we're talking about this week are clearly politically motivated.  Whereas before it was just, you know, the 13 year olds screwing around with botnets when botnets were in their infancy.  Now, of course, botnets are a big, profitable enterprise.



LEO:  We're going to talk about GhostNet, the spy - and, you know, there was a story in The Wall Street Journal, I don't know if you read this, I think it was yesterday, that there are also spy programs that are being found in our grid, in our national electric infrastructure.  And of course that's exactly where, if you were going to do cyber warfare, the first thing you'd go to is the grid.  And this is a fascinating story.  So I'll read to you a little bit from that, too.  And I think it's probably very similar to the GhostNet story.  All right, let's talk about - do you want to do any errata from previous shows?



STEVE:  Oh, always have security news and a little bit of errata, or miscellanea.  On sort of a separate, not quite really directly related topic, you probably saw yesterday, Leo, that the U.S. Justice Department came down with a very disturbing decision related to warrantless wiretapping?



LEO:  You know, I saw the headline, and I didn't read it.  What did they decide?  Because this is a scary thing.



STEVE:  It's got the constitutional scholars very upset.



LEO:  Oh, dear.



STEVE:  Apparently...



LEO:  I had really hoped for better, frankly.



STEVE:  Yeah, we all had from Barack's administration.  But one of them was explaining that no President has ever walked back any rights which were - that had been obtained by any previous presidents.



LEO:  Of course not.



STEVE:  Which is another way of saying it only keeps getting worse.



LEO:  Yeah, of course.  Why would you give it back unless you had...



STEVE:  Exactly.  Why, well, you know...



LEO:  ...a lot of integrity or something...



STEVE:  Exactly.



LEO:  ...crazy like that.  



STEVE:  And, you know, he's been out of the country.  So but apparently this - this looks like it's clearly coming from the administration.  What the decision was that came down from Justice was that, relative to warrantless wiretapping suits, because several suits have been brought by people, for example, against AT&T, who was one of the participants in the warrantless wiretapping probes that was revealed during the Bush administration, a bunch of people sued them for this being unconstitutional.  The Justice Department said that the government will be held harmless and that no action can be taken except in the instance of deliberate, voluntary disclosure of the information.  Which, you know...



LEO:  In other words, if they leak it, okay.



STEVE:  If they deliberately leak it.  Not even if it leaks.  If it's deliberately exposed, then that opens the government to consequences.  But don't even think about it.  You have no standing in the event that, even if you learn that you've been spied on, that's okay.  And one of the constitutional scholars, I don't remember his exact phraseology, but I found it really interesting.  He said it's not possible to have a right without having the ability to defend it, I think is sort of paraphrasing what he said, which I thought was interesting.  It's like the point is that this has completely removed any defense.  I mean, it's completely removed any action that someone can take when they've been wronged.  Even when it's clear that they've been wronged against the law, then this supersedes that, and there's no action that can be taken.



LEO:  They're claiming that government is, quote, "completely immune from litigation for illegal spying.  The government can never be sued for surveillance that violates federal privacy statutes."  Now, this is just their assertion.  This is just a brief.  It's not the law of the land.  I hope the court goes, ah, excuse me.



STEVE:  Good.



LEO:  Fourth Amendment.  Because that is just appalling.



STEVE:  Well, it's like, okay, wait a minute.  How did this happen?  This is not what we were supposed to get.  But, well, maybe we did.  We'll see.



LEO:  Well, I think you might have hit the nail on the head.  Nobody's ever stepped back from a - that's why we've got to be eternally vigilant in restricting the power of government because, once it gets it, it is...



STEVE:  Once it goes forward, yes.



LEO:  And, you know, they're protect- I think what this does essentially is, the point is, they protect the previous administration, hoping that the next administration might protect them should they do anything like this.



STEVE:  Yeah, and you know, I have been, I mean, I don't want this...



LEO:  It's collegial.



STEVE:  ...to get into politics.  But I've been pleased that there isn't this let's go attack the prior eight years.  I mean, it's like, Barack really seems to have it.  Let's just move on and...



LEO:  I think that's the proper thing.  But this may be the case where moving on is not the right thing to do.  Although maybe the feeling is this is the last thing we want to do is get in a myriad of court cases over NSA wiretaps and so forth, wireless wiretaps.  Good article in this on the Electronic Frontier Foundation site, if you want to read more about this.  They are very active, of course, in these kinds of things.



STEVE:  On an annoyingly related note, the U.K. passed on Monday their version of this EU edict, essentially, which has increased and formally ratified the data retention which is being done of all citizens in the U.K. and which is supposed to be adopted across the whole EU.  They've added to the previous data retention guidelines the requirement for ISPs of all manner to record for a period of no less than 12 months the sender, recipient, date, and time of all email sent.



LEO:  Oh, boy.



STEVE:  So there was - and the caller and recipient of any Internet telephone calls.  There was already legislation in place that required the location and details of regular landlines and cell phone calls to be retained, and even for cell locations to be recorded when they were knowable.  And so what's been added is now any outgoing email, not the body of the email itself because that's just way too much to record, but the sender, recipient, date, and time of all email sent, will now be recorded, retained by the ISP for up to 12 months.  I mean for no less than 12 months.



Sweden is apparently just ignoring the whole thing outright, just saying, uh, no, we're not doing that.  And Germany is challenging it in the courts.  But the U.K. signed into law on Monday an adoption of this.  And so all U.K.-based ISPs, apparently they're complaining about it.  They're complaining about the cost.  And the U.K. said, well, we will pay for the cost.  We will underwrite the cost of doing this.  We need this for the sake of the security.  There's an Isabella Sankey who's a policy director at Liberty said that the directive formalized what had already been taking place under voluntary arrangements for years.  But she said the problem is that this regime allows not just police to access this information, but hundreds of other public bodies.  And, I mean, that's always the concern here is that you end up with this big database.  And then people go, oh, you know, that would be useful for something else, as well.  You know, the repurposing of data is really a concern.



LEO:  Yeah.  Rightly so.



STEVE:  In other news, and this really relates to where we're about to go with the story of GhostNet, there is a newly discovered, zero-day, unpatched, PowerPoint vulnerability which is now being used in targeted exploits.  There have been PowerPoint little PPT files found in email, so-called "spear fishing," where they're sent to specific email accounts, specific individuals, targeting them specifically.  This hasn't been yet found in wide-ranging spam because if anyone finds an unknown - any bad guy finds an unknown, unpatched exploit, they recognize that they only have some length of time to use it before it gets found, and then we start the patching and the AV pattern updating cycle.  So it makes sense that, if a new vulnerability is found, it's going to be kept under wraps, and as much use of it will be made prior to using it widely.  You're not going to want to spam the world with it until you can no longer get maximum value from it by doing targeted attacking.



And so right now we're at the target attacking phase.  Microsoft has a page on their site acknowledging this.  They've seen it.  They know it's happening.  Of course here we are with the second Tuesday of April is the next Tuesday for our recording.  So by the time we hear from you again, or by the time our listeners hear from us again, we'll know whether Microsoft made this into their April patch round.  At this point we don't know, and there is no patch for it, no fix for it.  But Microsoft has acknowledged it.  So it's just one more in a continuing, literally weekly flow of new vulnerabilities being found in the software that most of us are using.



LEO:  That's amazing.  You know, you'd think that it'd slow down after a while.



STEVE:  Gosh.  Well, if the new software kept being...



LEO:  Or we'd find them all or something.  But I guess it's like weeding.  Yeah, exactly right, it's like weeds.  They just - new ones sprout up all the time.



STEVE:  And I also wanted to ask you, because I've seen a whole bunch of positive feedback about my recommendation last week of Tree Style Tabs, are you still using...



LEO:  Been using it.  Love it.



STEVE:  Yes.



LEO:  Not only that, Sarah Lane came in and said, "Where's my tabs?"  And I said, "Oh, they're on the side."  And she said, "Oh, I like that."  So, yes, it's great.  Good choice.  This is a Firefox extension.



STEVE:  Yup.  So everybody using Firefox on any platform can use it.  It seems to have fewer features over on the Mac platform.  I like some of the things I can do under Firefox and Windows with it.  And one person posting in our newsgroup said something I didn't realize.  If you've got a hierarchy of tabs because you've opened some links underneath an existing page, just dragging the parent tab to another Firefox window brings all the kids.



LEO:  Oh, I like that.



STEVE:  Yeah.  So you're able to, like...



LEO:  That's really handy.



STEVE:  ...create a new window that has a whole subset of the tabs that you had opened, the hierarchy underneath a given tab just by grabbing the parent.  Which is...



LEO:  Very clever.



STEVE:  Very cool.



LEO:  Very, very clever, yeah.



STEVE:  Yeah.  So I just wanted to reiterate for people who haven't made the jump or who weren't curious, maybe, you know, we're getting great positive feedback from that recommendation.  You might want to check it out.



LEO:  What's the actual name of the add-on?  Is it Firefox Tabs?



STEVE:  I think it's called Free Style Tab, three words.  I'm sorry, Tree.  Tree Style Tab.



LEO:  Tree Style Tab, that's right.  And the version I'm using on the Mac is 0.7.2.  But I would imagine it's the same, I mean, it gives you a lot of preferences.  You know, actually I haven't really dug into this much.



STEVE:  I know.  It's, like, overwhelming.  I thought, okay, wait a minute, I'm just - I'm going to start using it first because I don't know if I want to change any of these settings yet.  I want to use it the way the author has defaulted it, and then maybe after I'm familiar with it I'll go, oh, look, I can push this button over here, and it'll do something a little better for me.



LEO:  It's even got different views.  Different appearances and...



STEVE:  Yeah.



LEO:  Wow.  Wow.  I didn't - yeah, you're right.  I didn't - wow.  This is quite more - I had never looked at the preferences.  This is quite elaborate.



STEVE:  It's like, okay, wait a minute.



LEO:  Oh, I don't even know what all that stuff does.  Holy cow.



STEVE:  So this was posted by Anthony in Australia.  And I don't recall, I haven't recorded whether it came in through email or the newsgroup or what.  But he sent me a note, he said, "SpinRite on par with Craig Venter's brilliance."



LEO:  Now, you know who Craig Venter is.



STEVE:  Well, I didn't until I got down to the end of his message.



LEO:  We interviewed him on The Screensavers.



STEVE:  Oh, no kidding.



LEO:  Yeah, one of the most important people of our generation, I would say.



STEVE:  Well, I don't think SpinRite's quite on a par with that.



LEO:  Go ahead.  I mean, it's quite - it puts you right up there, I'll tell you.



STEVE:  Oh, it was in his blog.  It was a blog posting...



LEO:  Oh, how neat.  Oh, how neat.



STEVE:  ...he made on February 20th.  And he said - it had tags:  SpinRite, Steve Gibson, and GRC.com.  And then he blogged, he said, "Some feedback I just sent to Steve Gibson, the creator of SpinRite (v6) at GRC.com."  He said, "Hi, Steve.  I'm a long-time Security Now! listener and SpinRite user.  And today was one of those blue moon days where SpinRite saved our bacon.  No dramatic special ops story here."  And he has a little smiley face.  "But satisfaction and gratitude abound, nonetheless.  And perhaps a new point of view on why SpinRite is so awesome."  It's interesting because the other reason I wanted to read this, this is the long posting that I skipped last week because we already had a super-long podcast.



LEO:  We had a long - right, right.



STEVE:  But he brings up something that has been asked before, but we've never talked about.  Anyway, I'll get to that in a second.  So he says, "Our FoxPro developer's old Dell laptop, which had been trucking along fine for years, suddenly wouldn't boot this morning, BSODing during every boot attempt.  And, as usual, Safe Mode was no help.  He's usually a stickler for doing frequent backups.  But when I asked how long since the last backup, I got back only an embarrassed, sheepish smile.  Oh, boy.



"Recognizing immediately that this was probably SpinRite's cue to enter from stage left, I put it to work, and in about an hour it had completed.  Although there was no record of any bad sectors found or corrected, I did notice it churning away for several minutes on a few spots, and I suspected I was on the right track. (No pun intended)," he wrote.  "Sure enough, after SpinRite, the laptop booted right up.  And so far all looked to be intact.  A backup has now been performed, and the impetus to replace the laptop very soon has been renewed.  Just another" - and he says, "Just another day at the office for SpinRite, but a significant potential loss averted for us.  Thank you so much for such a legendary product.  I promise to buy another couple of licenses to reach my consultant's license status ASAP."



And he said, "By the way, while doing a bit of research into SMART a while back" - that's the Self-Monitoring Analysis and Reporting Technology, SMART, acronym that's built into all contemporary hard drives - "I stumbled across a hard drive data recovery expert's site which had a page recommending data recovery and utility software.  At first I was surprised not to see SpinRite at all, let alone at the top of the list where it should be.  Until I saw a note where he explains that he (paraphrasing) 'disqualifies SpinRite because it doesn't make a copy of all the readily accessible data before attempting restorative measures, and thus puts more data at further risk.'"



He said, "I understand the logic behind this argument, and I agree that in rare circumstances a drive may degrade to such an extent or have physical damage to the heads, for example, and not be diagnosed until it's hanging by the proverbial thread, and thence SpinRite's thrashing may snap that last thread.  But you know what?  Having used SpinRite myself since the early '90s, and hearing all your testimonials on Security Now! every week for three years, and hear you explain how it and hard drives work, I've come to realize that most hard drives' magnetic media failures don't fall into that severe category, and that SpinRite's approach offers far more bang for my buck than data recovery specialist services, which are what this guy was recommending.



"Whilst he's probably just taking a very conservative approach, understandable in that industry, someone more cynical than myself might suggest this guy's wowser attitude is not in his customers' best financial interests.  Even more cynical people might wonder if some of these data recovery specialists secretly use SpinRite themselves to recover data from customers' drives and charge traditional (read exorbitant) data recovery prices for it.



"I'm reminded of the race to decode the human genome in the '90s, with the purists using a stubborn, narrow-minded, linear sequencing technique that was threatening to take forever, and Craig Venter's maverick scatter gun recombination approach, which won the race.  I see your unique and novel approach to tackling magnetic media failure in exactly the same light - simply brilliant."



LEO:  Well, there you go.



STEVE:  That was Anthony's note and posting.



LEO:  I'm with him on that one.  I mean, saving the data seems to me unnecessary.



STEVE:  Well...



LEO:  I mean, you could do it if, I mean, often when I tell people to do a drive recovery, I say work on a copy of the drive, if you're really worried about the data.  But that...



STEVE:  Right.



LEO:  SpinRite wouldn't help in that case.  You'd make a copy, then have to work on the original drive, wouldn't you.



STEVE:  I guess I'm of two minds.  The way SpinRite works, that is, doing an in-place recovery, does have, I mean, there is the possibility that, if the drive is absolutely determined to die, then nothing any software can do can prevent that from happening.  And if it's going to happen at some point, then when you're using it is probably when it's going to happen.  SpinRite's in-place recovery probably owes  more to its history than anything else.  You know, I wrote it first back in the late '80s when a 10MB hard drive was a couple thousand dollars.  People didn't have extra hard drives.  You were glad to have one.  I mean, if you had one, your friends who were still shuttling floppy disks in and out of their floppy drives, they were envious of you.  So there wasn't this whole notion of, oh, just get another drive and copy the data over to it.



So doing an in-place recovery really made the most sense.  And the fact is, while I understand the theoretical point that that guy, that data recovery expert was making, I have now 20-plus years of experience with SpinRite's actual use.  And we see virtually no instances of, I mean, yeah, maybe anecdotally it's happened a few times where, while SpinRite was working on the drive, it gave up.



LEO:  Yeah.  I've never seen that.



STEVE:  It almost never does.  And typically what's happening is some sectors are getting in trouble, you just use SpinRite to bring them back, and then you're okay.  And had you used SpinRite the week before, then the problem would have never happened in the first place.  So drives are dense enough that they're always sort of on the edge, but using error correction technology on the fly to keep them looking fine.  SpinRite isn't fooled by that, and so it's able to go in and fix problems before they manifest and, fortunately, to fix them even after they have manifested.  But in all cases, these are not drives that are about to completely go belly up.  Fortunately that happens very rarely.  It's mostly that people's data becomes endangered long before that actually happens.



LEO:  Right.



STEVE:  And of course, as soon as they can't boot, they know something's wrong.  But that's, like, long before the drive is completely toast.  And so SpinRite can typically bring it back to life.



LEO:  All right.  Let's talk about ghosts.



STEVE:  Okay.



LEO:  [Moaning]



STEVE:  So this is a really interesting story with lots of information and details that I think our listeners are going to like.  And I learned something really interesting, too, about the evolution of command and control in these networks that I think everyone will find interesting.



The story begins about nine months ago, when the representative of the Dalai Lama in exile asked an affiliated group - there's something called the SecDev group in Canada and the Citizen Lab, which is at the Munk Center for International Studies at the University of Toronto.  And these two groups work together on, and have in the past, on issues of cyber stalking, cyber terrorism, cyber attacks, that whole sort of area.  And they have a political orientation.  I mean, so the international studies side.



And so about six years before that, in 2002, the group had been involved with the Dalai Lama, with some sort of  malware.  The Dalai Lama's organization was being targeted through direct malware attempts to infect their network.  And so these guys became involved.  So they were asked to, I guess through some sort - there was, like, a meeting where they were just sort of talking casually about, well, maybe we need to do some sort of education to inform the people who work in our offices and on our network what they need to be doing to be safe.



And as a consequence of the conversation, one thing sort of led to another, and the person who was the executive with the Dalai Lama's organization said, well, you know, why don't you just sort of take a look at our offices, meet a couple of our people, maybe check out our network.  I think in the process of having this conversation some concerns had been raised.  So they took a look at a couple machines, and sure enough, they discovered some malware that they were previously unaware of.



They put Wireshark - which is the open source, publicly available sniffer, it's the one I use myself, a very nice program - they put it on the machine and did some traffic captures of traffic that was transacting with that machine.  That allowed them to see a communication that was being made autonomously by this machine to an IP that happened to be on the island of Hainan in the People's Republic of China.  They tracked down the IP, looked at reverse DNS, checked the listings.  It was just a commercial Internet service provider, a standard Internet provider IP.  And what was interesting was that they then checked - they then went to that machine, not physically, but over the 'Net.  And they discovered that the command-and-control system that was at the receiving end of this client-initiated communication was - it had an open access web interface.  So using just a regular web browser, they connected to this server, certainly taking all kinds of precautions themselves, I'm sure, and began the process of figuring what was going on.



What they - in looking at this machine, which this first client machine, which had been infected, they found some - they found this malware content in a number of documents which had been attached to email.  So this is exactly the kind of infection vector we've talked about often, and which I was just talking about relative to PowerPoint slides and this currently unknown or, well, now known.  But it was discovered the wild, so it was a zero-day exploit because it was being exploited before it was known.  In this case it was an old problem in Microsoft Word from 2006 that was still two years later being exploited because this particular machine had not been updated in that length of time.



LEO:  Oh, boy.



STEVE:  So these non-updated machines create this window of opportunity.  So by logging in to this command-and-control web interface with a - they discovered that this was a software system called Ghost Rat, for Remote Access Trojan.  And literally Googling "Ghost Rat" and clicking on, like, four links, I had the source code for it yesterday.  It's an open...



LEO:  Wow, that was easy.



STEVE:  It's an open source...



LEO:  Open source, great.



STEVE:  I have v3.6 beta.



LEO:  Oh, man.



STEVE:  Was the one that I...



LEO:  This shows you, I mean, these are professional programmers writing this at this point.



STEVE:  Actually, it shows signs of not being...



LEO:  Oh, interesting.



STEVE:  ...that professional.  First, well, for all kinds of reasons that we're going to talk about.



LEO:  Oh, interesting.



STEVE:  I want to sort of run through the timeline, and then you and I are going to talk about a lot of what this all means.  But in looking through the source, I saw first of all comments in Chinese, which my own Visual Studio didn't translate for me.  But what I saw was, like, lots of sort of canned chunks of things, like sample code that had been pulled from various Microsoft tools, just sort of glued together by a little bit of custom code.  But this thing is, you know, way bigger than it needs to be.  And it's just sort of pulled together to do the job.  It's been around for some time.  And it's funny because in the forum where I found this there was a bunch of people who were having trouble with error messages.  And well, you know, I didn't - I wasn't sure whether I had to install the DDK or not, and I'm not really quite sure how to get rid of these error messages.  Can someone give me a hand?  And so this is - and this forum where I found it was a trojan horse development forum with, I mean, this is just all now out in the open.  Just, you know, a couple clicks, you Google "Ghost Rat," and you'll find the source code for it.



So interestingly, now, back in the day, as they say now, back when I was first involved in this myself, in backtracking attacks that were being made against GRC, you'll remember that - and we've talked about this a number of times, that the botnet then was based on IRC chat.  So when you got yourself infected, if you were unlucky enough to do so, the client that was the infection would make an outgoing connection to an IRC chat server somewhere.  IRC chat was convenient for the bad guys to use because this IRC chat network is itself a network of interconnected servers that will relay chat messages among them.  So it's not necessary for the bad guys, the bot masters, to be logging into that same server.  In doing so, they would be vulnerable to being caught because that server, I mean, it's easy to find a server.  You just look at the IP that the IRC connection is being made to.  Now you know where this bot is going for command-and-control coordination.  Then you look at all the incoming connections to that channel of the IRC server, and it's easy to track down the IP of whoever is issuing the commands.



So instead, by using IRC, you've got sort of a federation of affiliated servers and the bad guys can enter the channel on a completely different, unrelated server, which will then forward their commands throughout the network until it finds the channel on the server where it's destined.  So it makes backtracking them much more difficult.



So that was the technology, what, six, seven, eight years ago.  Today things are different.  What I found most interesting is that all of the protocol being used for command and control is just HTTP.



LEO:  Really.



STEVE:  Yes.  The...



LEO:  That makes sense, though, because that's least likely to get filtered; right?



STEVE:  Well, get a load of this.  It's even disguised.  That is, the client makes an outbound web connection to this web server, which is the command-and-control web server.  It does it to a PHP page, asking for a PHP page or in some cases running a CGI script, which is very common for any kind of automated pages.  So it's just a standard port 80 HTTP connection.  The commands are sent back encoded in JPEG images.  So even if you were watching the traffic, you'd just see web activity with an image being retrieved in response to a PHP query, which happens all the time every day.  I mean, that's the way the web works now, more often that not, in fact.



But the commands, instead of just being out in plaintext, they're bound into image files, which are being retrieved by the client.  So unless you really knew that a given IP was malicious, you'd have no reason to suspect it from even looking at the packet traffic going back and forth.  And as you said, Leo, it's also not going to be filtered.  You could imagine that all kinds of people are now blocking IRC from crossing their firewalls and routers.  But you can't block regular web traffic without incurring all kinds of problems.  So, I mean, even if you proxy it, you could also have a proxy which is accepting the request, forwarding the request, accepting the returning image, and returning that to the browser.  So even proxies in line would allow this to pass through.  So that represents a real evolution in the way these networks are being organized.



But what's really interesting, though, is when these guys logged into the first of these control servers - they refer to control servers and command servers as separate.  the command servers are the source of updates and images and documents.  So essentially the client contacts the control server.  The control server returns instructions for how to contact the command server, which the client then autonomously does.  It receives commands from this second command server and then returns a status back to the control server once the command has been executed.  So it's a fairly sophisticated relaying system designed to keep one side from knowing what the other is doing, essentially, unless you're really monitoring all the traffic at the common point.



One of the interesting things that they discovered is that the web interface lists all the machines of which it is aware, that is, all the clients, the infected clients which have contacted it, the date of first contact, the date of most recent contact, and includes links that you can click on for sending commands to these things.  So it's got a complete, mature, point-and-click user interface and a database which is maintaining essentially a history of the malware's contact with this control server.  So naturally, I mean, this thing lists all the IPs of the machines that have contacted it.  So the researchers were able to say, oh, we just found the mother lode here.



They of course did reverse DNS lookups on all the IPs.  They did whois queries to find out who the registrars were.  They ended up, it turns out, having access through their connections to a number - many other machines that were either in networks affiliated with the Dalai Lama or in other Tibetan organizations, non-government organizations.  They were able to visit those machines.  They found in some cases multiple instances of this Ghost Rat software.  That's why this whole thing was called GhostNet, by the way, if that wasn't clear.  They found in some cases multiple infections that were contacting multiple control servers.  That allowed them to then expand their search to and access other control servers, which they did.  They ended up finding four control servers, all located on the same island in the People's Republic of China, and six command servers that were not otherwise affiliated.  However, all of the domain name registrations pointed back to the same single individual.  So this network...



LEO:  Oh, that's interesting.



STEVE:  And thanks to this database that each of these control servers was maintaining, they could see that this whole network went back several years, back to the date of that original infection, or that original infection vector, back in '06.  So this whole network had been in place for some time.  Some machines didn't stay infected very long.  That is, they could see from the logs that the date from the first contact to the last contact was only maybe 10, 20, 30 days.  Some machines were infected for several years.  They got themselves infected, and that infection just sat there for several years, contacting the control server periodically to see whether there was anything that the control server wanted them to do.



They were able, of course, now that they knew what the software was, and they could look at the command interface, they were able to see that these things could basically take an inventory of the client, the infected client machine; could exfiltrate, using their term, any and all documents on the infected machine; could turn on a microphone, if present, and stream audio out of that client to a given target; and the same with the webcam - turn on the webcam and stream video in real-time out of there.  So, you know, basically - oh, and execute any arbitrary command on the machine that they wanted to as a remote access software.



So fundamentally they had complete ownership of these machines.  And in some cases they saw evidence of the commander who was running these control servers watching an email dialogue between affiliated entities and inserting a spoofed email towards a not-yet-infected endpoint.  And having been able to see the conversation, the bot master or the net master was able to create an email which flowed with the conversation and contained a malicious document which was opened by the recipient, for whom this email made total sense.  They were expecting something like this, or this wasn't out of the ordinary.  They opened it, got infected, and that new client then contacted the control server.  So you could see how this network was being perpetuated and being maintained.



In one instance during this investigation, somebody who had worked in some capacity with the Dalai Lama was attempting to go back to visit her family and was stopped at the border, held for two months, interrogated.  And when she claimed that she was not involved in politics at all, there was nothing political going on, she was just doing studies, they showed her, the authorities showed her a complete transcript of her private conversations which she had had previously.  So this was information that the intelligence agencies of China did have in their possession.



LEO:  Wow.  So I was initially skeptical, I think as were you, that it would be China because of course any good hacker covers his tracks.  But this sounds like, all told, given the evidence including the Chinese comments, the location of the servers, the registry, that it's pretty clear it's coming out of China.  But what's interesting is it doesn't sound like it's very well done.  You'd think the Chinese government wouldn't be going to forums to get their code.



STEVE:  Very good point.  And so there are a number of questions which are raised.  First of all, we have the fundamental problem of attribution.  The attribution problem is a classic problem that law enforcement has because, yes, what do we know?  I mean, what is provable?  And that's the problem, of course, is the threshold of provability is much higher than what is guessable.  So we know that there are four servers, all located in an island.  Actually it's the same island as where the Chinese intelligence organization is.  But they're not Chinese intelligence organization IPs.  They're just random ISP IPs.  We don't know that - we know nothing about who is connecting to those servers because these investigators had no physical access to those actual four control servers.  You'd have to have physical access to them to then watch all the traffic coming out of them in order to see who was connecting and accessing that web interface and taking command of it.  So the Chinese government, that obviously and continually denies any involvement, may in fact not be involved.  I mean, we don't have any evidence to say otherwise.



LEO:  I would think, I mean, if our government were doing it they'd have these hack- good programmers at the NSA writing stealthy code that isn't - it's not out on forums anywhere.



STEVE:  Well, Leo, you know, as I've told you, I've declined some of those requests.



LEO:  Right, right.  You can be sure that not everyone has declined those requests.



STEVE:  And my code would not work this way, and no one would find it, and I'd be using packets no one had seen before.



LEO:  And given the resources and the size of China and, frankly, the number of great programmers China has, I find this hard to believe that this is a government effort.



STEVE:  Well, and the fact that the web interface wasn't password-protected.  All you had to do was know what IP port to browse to, and like what directory structure apparently - there was some reference made to needing to guess the location of the page, the web page that contained the interface.  Yet these guys with no specific knowledge were able to guess in four instances and find the web interfaces on four different machines. 



LEO:  That's absurd, yeah.



STEVE:  Which are wide open and unprotected.  So that's nuts, too.  Now, on the other hand you could also say, oh, aren't the Chinese government clever to make it look so amateurish, that is, to use v3.6 beta of the Ghost Rat because we're going to draw all the same conclusions.  I mean, it does give them plausible deniability.  If you have something really high tech and robust, that is, nothing like it exists out on the public domain, then if, or we might say when, it's inevitably discovered, because all these things ultimately are, it's like, ooh, now it's much harder to say that's not, you know, high-end NSA or the equivalent of Chinese intelligence activities.  Here, this looks like random people.  Well, and in fact my personal take is that it's somebody, probably a nonprofessional, who's using public domain tools, who's focused, who's got strong political incentive, who's probably feeding documents that are uncovered to authorities, but that the authorities are not themselves doing this.  It's just somebody who, through nationalistic pride or political beliefs or whatever, is doing it.  I mean, again, we have...



LEO:  Probably with the tacit approval of the Chinese government.  I mean, this is certainly...



STEVE:  It's useful information.



LEO:  ...consonant with their aims.  Yeah, it's useful information.  But it seems a little hard to believe that their government is doing this.



STEVE:  And so the other thing that we have to come away from with this, I mean, if you Google Ghost Rat and you literally, in four clicks, you own the source code - oh, and Windows binaries are available, if you don't want to assemble this or compile it yourself.  You know, what does it take to perform an attack?  It takes having a PC and being a little involved in the underground so that you're in the communication flow of, oh, look, here's servers that are compromisable.  Here's, I mean, it's not even necessary to be on the leading edge because, as we've seen, there are computers that are exposed for years to known vulnerabilities.  So it's not like you've got to be someone using, like, this PowerPoint exploit that we just talked about.  Clearly you can be - the way Conficker is working, you can be using something that was fixed in October of last year and still a huge number of machines are available.



You know, to me it looks like this particular trojan is being used specifically for politically oriented work.  In fact, what they found, what these researchers found, they found the four control servers, six command servers.  By processing all of their logs, they ended up tracking down 1,295 discrete machines.  And these are - the machines all have IDs.  So even if they're on dynamic IPs, the logging technology recognizes the machine is connecting from a different IP.  So this is all - the IPs have been disambiguated, or the machines have, rather, independent of whatever IPs they happen to have from time to time.  So there's 1,295 individual infected machines in 103 countries.



LEO:  Wow.



STEVE:  30 percent of those are what this group considered high-value targets.  You're going to end up picking up some debris from just random machines that get infected.  But, for example, the machines that they were able to find and track down using reverse DNS on the IPs, and in many cases the machine names, the names of the machines are also posted in the log on the control servers.  They confirmed that they found machines that were infected in the ministries of foreign affairs of Iran, Bangladesh, Latvia, Indonesia, the Philippines, Brunei, Barbados, and Bhutan; and the embassies of India, South Korea, Indonesia, Romania, Cypress, Malta, Thailand, Taiwan, Portugal, Germany, and Pakistan.  They found machines in the Association of Southeast Asian Nations Secretariat, the South Asian Association for Regional Cooperation, the Asian Development Bank, a number of news organizations, an unclassified computer at NATO headquarters, and - I got a little kick out of this - and one machine in Deloitte & Touche in New York.



LEO:  Why Deloitte & Touche?  That seems like the outlier there, doesn't it.



STEVE:  Yeah.  It's just - and there were a bunch of others that weren't even worth naming.



LEO:  But these are for sure all in the same net.  I mean, they're not...



STEVE:  They're absolute - yes.  They're known in the same net.  Those machines were repeatedly contacting these control servers.  And these control servers, this whole technology has a database which it maintains of first contact, last contact, commands, the name of the computer, the name of the logged-in user, all this information is sent back through just regular web queries in order to get this to the server which is controlling the network.  So this stuff really exists.  It is really happening.



And unfortunately, thanks to vulnerabilities in Windows, I mean, as far as we know all of this is Windows hosted.  There's none of this that is nearly as well known or prevalent over on the Mac side, or Linux for that reason.  But as a consequence of these vulnerabilities which are constantly being found, it's possible to use social engineering to get somebody to open a piece of email, maybe open a document, get themselves infected, put their machine under control, and in some cases these infections last years before anyone is suspicious.



LEO:  Wow.  Well, okay.  Now let me tell you the story that I mentioned.  This was in The Wall Street Journal yesterday.  And the title, you should look for it, it's written by Siobhan Gorman, and the title is "Electricity Grid in U.S. Penetrated by Spies."  The companies that run these grid computers, by the way, generally aren't discovering these tools.  It's U.S. intelligence agencies, which are kind of chartered to protect us against cyber warfare, who come in and do assays and find this stuff.  Tools have been left behind on many of these systems that could be used to attack and to take down the power grid.  They don't make any assertions about who they're from.  But U.S. officials said investigators have followed electronic trails of stolen data to China and Russia.  It's kind of the same thing; right?



STEVE:  Yeah...



LEO:  Both the Chinese and Russians deny it, as you would expect.  So this is even more scary.  I mean, it's one thing to get in an embassy computer and try to steal state secrets.  But it's pretty clear that the next form of warfare will be cyber warfare.  What's the first thing you do?  You take down the grid.  The grid goes down, a lot of what we do in this country stops.



STEVE:  Yeah, well, the Internet stops if you take enough of the grid down.



LEO:  Right.  You don't attack the Internet, you attack the grid, the power that runs it.  The good news is that the effort is going on to be aware of this, to discover it, and to protect us against it.  But I thought, this is just - it seems like another side of the same story, in effect.



STEVE:  Yeah, and all of this just, I mean, as someone who lives this technology, I mean, who recognizes how easy it is to do these things today, it's wrong that it's easy as it is to do these things today.  I mean, this all makes me feel like we're in the Wild West phase of, I mean, just the infancy of this technology.  You know, I remember - I mean remember, not just stories of a time, I mean, I remember when there was the argument of, well, the Internet won't happen because of the chicken-and-egg problem.  No one's on the Internet, so no one's going to want to get on the Internet.  And it's like, whoa, well, that problem got solved.  Now the Internet has happened.  It's obviously here.  It's obviously a huge win and a massive asset from an ability to leverage this kind of real-time communications and control and information flow and everything that we use it for.  Well, it's not that long ago that no one really was taking it seriously.  Now we are, but unfortunately all of the technology that we've got can be repurposed for non-intended purposes.



LEO:  Yeah.  And it's the same - really kind of stunning is it's the same holes that regular people are, you know, the same - these big government computers are falling prey in exactly the same way regular people are falling prey.  They're doing the same dumb things, the same unpatched systems.



STEVE:  Well, because they're running Windows, of all things.  I mean, I'm sure, Leo, you've seen the photos of, like, major light boards in Vegas that have a Windows error dialogue?



LEO:  Blue Screen of Death, yeah.



STEVE:  It's like, oh, my God.



LEO:  Well, I don't think running Windows, I mean, can't you harden Windows sufficiently?  I mean, can't you make it secure?  Or would it - what should they be running, if not Windows?  You're running Windows.  You must be able to secure it.



STEVE:  No, I mean, I'd use a nonstandard real-time operating system.  There's all kinds of embedded operating systems around that no virus has ever attacked because it's not a target for anybody.



LEO:  Or a NetBSD or, you know...



STEVE:  Yeah, exactly.  I mean, when you see that, it just looks like amateur league.  It's like, okay, fine.  There was a...



LEO:  Not just Windows, Windows 98.



STEVE:  There was some kiosk in an airport that I remember seeing where there was, I mean, they normally covered up the fact that there was Windows running underneath it.  But it had an error, and up came a Windows dialogue box, right through this otherwise nice-looking turnkey - oh, and it was  VB, I remember now seeing that it was Visual Basic that they'd written this.  It's like, okay.  You get what you ask for.



LEO:  Yeah.  Wow.  It's fascinating stuff.  And a little scary at the same time.



STEVE:  Well, it's real.  I mean, anyone - the thing I like about this story and sharing it with our listeners is this makes it so clear that it is this easy and that this stuff is real.  This is not sci-fi.  This is not...



LEO:  Get your code on a hacker forum.



STEVE:  Oh.



LEO:  That's what cracks me up.  I had no idea this was just kind of commonly available stuff.



STEVE:  Yeah.  Ghost Rat.



LEO:  Ghost Rat.



STEVE:  Google it.  Four clicks away, you've got the source code.  And, if you're not quite sure how to compile it, well, just follow along in the forum.



LEO:  Yeah, we'll give you binaries, yeah.



STEVE:  Follow along in the forum because they're all trying to figure it out, too.



LEO:  Lots of helpful hackers, ready and willing.  You probably get better support on Ghost Rat than you can get on most commercial software.



STEVE:  Oh, it's real-time, yeah.



LEO:  Steve Gibson is at GRC.com.  That's the website, Gibson Research Corporation.  You'll find SpinRite there, the world's best file and - I'm sorry, disk recovery and maintenance utility.  And of course a lot of free stuff, too, including ShieldsUP! and Shoot The Messenger, DCOMbobulator, Unplug n' Pray - I love his names - Wizmo.  It's all at - and soon some new stuff, all at GRC.com.



STEVE:  Yup, coming soon.



LEO:  Also there are show notes, 16KB versions for the bandwidth impaired, and Elaine's great transcripts so you can read along, as well, and pass it along.  We have a wiki site with much of that stuff, too.  I'm really pleased with the TWiT wiki.  It's really moving along.  Wiki.TWiT.tv.  Thanks to all the volunteers who scribble, scribble, scribble while Steve talks.  Thank you, Steve.  We'll see you next week.



STEVE:  Right-o, Leo, thanks.



LEO:  On Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#192

DATE:		April 16, 2009

TITLE:		Listener Feedback #64

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-192.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 192 for April 16, 2009:  Listener Feedback #64.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all your security needs from soup to nuts.  And here he is, our chief nut, Mr. Steve Gibson.



STEVE GIBSON:  Chief security nut.



LEO:  You are, you know, some would say, and in fact I think you've probably heard this from time to time, that you are a security nut.



STEVE:  I am fascinated by the technology and the issues that it brings up with security, yes.  I certainly know many people conversationally in newsgroups and through email contact who are, I would say, more security focused than I am.  But...



LEO:  It's not your only job.



STEVE:  It's not my only job.  I just - I love it because it's an area of applied technology which is certainly very interesting.



LEO:  Yeah.  Well, today we have the question-and-answer segment we do every other show, which means we've got questions from the listeners, 12 good and true listeners.



STEVE:  Really interesting comments, lots of interesting stuff to talk about, and a bunch of front of show errata and security news and our regular startup stuff.



LEO:  Well, let's get right to it.  What's the latest?



STEVE:  Latest is I did close the show mumbling that I may set up a little Conficker honeypot.  That's been running for five days.



LEO:  Oh.



STEVE:  So I have my own copy of Conficker and some interesting observations.  There's so much interest in it that I've decided - and we haven't done a podcast on it.  We really need to do that.  So next week's topic is Conficker.



LEO:  Oh, good.



STEVE:  I'm going to attempt to do a complete timeline, a very clear, thorough, technical analysis of it, and really explain how it's changed over time.  I mean, the fact that it is changing as rapidly as it is, is interesting, too.  And also the fact that in several cases recent security innovations have been incorporated into updates, I mean, within days of them becoming available.  There's an amazing amount of technology in there.  I mean, none of it's ground shaking.  None of it's new.  But it's unusual for the kind of authorship we have seen of these things in the past.  I mean, there's a lot here.



For example, its update payloads have full cryptographic digital signatures as part of them.  So that prevents any non-Conficker authors from commandeering Conficker by tricking it to upload their own payloads because Conficker checks the digital signature of anything it's accepting to make sure that it was signed by its authors.  And as we know, that's not spoofable when it's been done right.  So there's lots of stuff there.



My own little copy here has been patiently chunking away, chugging away for the last, I guess about five days.  It's fun.  A number of things have happened.  For example, it stumbled into a couple tarpits.  And the tarpits it stumbled into are run by the National Center for Supercomputing Applications.



LEO:  That's interesting.



STEVE:  They've set up a large block of IPs specifically to monitor the behavior of worms and viruses and things.  And as we remember from talking about tarpitting, what a tarpit is, is Conficker sent out a connection-opening SYN packet, and the responding server or service sent back an acknowledgment saying, yeah, I'd be happy to accept your connection.  But, oh, I don't have any available buffer space.  So hold on a second.  And what that does is that shuts down the connection, but prevents it from timing out.  And so for days now an increasing number of connections which my little copy of Conficker has sent out have stumbled into tarpits.  There's actually two different ranges that I've seen that have grabbed those connections and never let go of them.



So, now, again, the author is so responsive that, if this became commonplace, we know that he'd update the payload.  And it's easy to disconnect those connections.  All you have to do is look at how long they've been open versus how much data has been transferred.  And if that falls below a certain threshold, you abortively disconnect a TCP connection, which can be done easily enough.  But that hasn't happened at this point.



So anyway, next week we're going to talk all about Conficker, and I'll basically give a complete technical explanation.  Okay, I mean, it's got many different things it's doing.  It's probing my local network for any other machines on the LAN by sending out ARP queries, looking for IPs, so we can talk about that.  It's very patiently sending out UDP packets scattered all over the Internet, but carefully avoiding a bunch of Class A networks that it knows it shouldn't waste its time on.  It's just doing all kinds of things.  So it'll be fun to talk about what I've seen and what the whole industry has seen.



LEO:  Would you say Conficker is a well-designed worm?



STEVE:  I have to be very careful to make sure people don't misunderstand my appreciation of it because, yes, I mean, it is beautifully designed.  And I don't want, I mean, I want people to understand that I recognize that it...



LEO:  You're not applauding the creator, yeah.



STEVE:  Yes, exactly.  It's a bad thing.  I mean, it's causing all kinds of concern.  And it's obviously very effective at infecting and holding onto machines that it commandeers, which in no way am I condoning this behavior.  But I respect its authorship.  So, yes.



So here we are, a couple days from the second Tuesday of April, where we had the standard big monthly update - five critical vulnerabilities, two that were important, and one that was moderate, so a total of eight patches from Microsoft on Patch Tuesday.  Everyone needs to do this sooner or later.  There were a couple bad ones where there were problems found in the HTTPS protocol on the client side, meaning that if you were induced to - you, a Windows user, were induced to going to a malicious secure website, you could have a remote code exploit against your machine based on the certificate, the security certificate that has been exchanged.



So it's an interesting type of exploit we haven't seen before, I mean, in these details.  But fundamentally it's the standard math problem buffer overflow, integer overflow type problem.  But it's something you definitely want to get your machine patched against because, just as we've seen with Conficker, where back in October this was fixed, a bunch of machines haven't been patched.  We've got some interesting Q&A about that also.  And speaking of SSL, many people are wondering, I mean, I'm reading in their feedback, hey, Steve, whatever happened to the SSL protocol podcast that you promised?  And my answer is, it's coming.  But this is Security Now!, and so I'm giving priority to things that are newsy and happening now, like Conficker, for example, which is happening now.  The SSL protocol, well, that's, you know, something I want to talk about, but it's static technology that we will get to, I mean, literally as soon as something doesn't preempt us with something that is now.



LEO:  SSL ain't goin' away.



STEVE:  It's not going anywhere.  Also, for anyone using VMware, there was the first major set of security updates in quite a while for VMware Workstation, both for Linux and for Windows, VMware Server and Player, ESX, ESXi, and ACE.  So I was on 6.5.0, that is, Workstation for Windows.  Anyone using VMware needs to go over to VMware and make sure they're current.  If they haven't updated for a while, you're going to want to because there were some interesting exploits.  And in fact one is interesting enough that I've got it queued up for a podcast soon because there are some problems with VMware which have been discovered.  And they're not fundamental problems with virtual machines.  But as always, if mistakes are made in virtual machine implementation, and those are found, they can be leveraged.  So I don't regard it as a huge, glaring problem like we have if a Windows user goes to a malicious website because certainly the cross-section of VMware users is much smaller than all Windows users.  On the other hand, many people are using VMware specifically for the security encapsulation it provides.  And in this case it's not.  So you want to make sure you update VMware Workstation.



Also, many people wrote to tell me, if I didn't already know, and I do, something that I wanted to share anyway.  And that is that Phorm, the evil, behind-your-back, intercepting your web connections, and loading your machine with cookies in order to track you technology, which was surreptitiously tested by BT over in the UK, it was on its way back.  There was some news about Phorm returning.  And the European Commission, the EC, has decided, eh, not so fast.  We're going to initiate legal proceedings against British Telecom because we feel that their prior tests, which were undisclosed, involving Phorm violated privacy rights, which are well understood and established.  Phorm is saying, we did nothing wrong.  Both we and BT consulted our legal counsel before executing these tests, and we think we're going to be fine.  Anyway, the EC says, eh, we're not so sure, let's put this to the test.  So basically the problem was there was non-consent, there were non-consent complaints raised, and the EC is going to look at those and say, well, we agree that there's a problem with consent, which was not clearly given before.



The other interesting change we're seeing, sort of in the security landscape, aside from of course Conficker's happening, is something we've talked about but never really addressed directly.  But one of my favorite security columnists, Brian Krebs, who I've referred to frequently here, who writes a security column for the Washington Post, talked about how one of the newest sort of latest changes is this notion of scareware, which is causing people to visit bogus AV sites and install and register bogus AV software.  What's happening is that referral fees turn out to generate tens and in some cases hundreds of thousands of dollars per month for anyone who is able to get people to visit and install this basically bogus AV software.



So essentially what's happened is viruses happened.  The AV industry then responded.  Then awareness was raised so that everyone who's using PCs now is aware of the virus problem, and we've worked on educating people about how to avoid being taken over by viruses.  And then almost, in retrospect, almost obviously, what's then happened is fake antivirus tools and warnings and so forth have occurred.  So people are now being confronted with pop-ups, for example, that say this system is acting like it has a virus, please check to see, you know, click this link to have your system scanned.  So that will install something which then beats on them to register until they finally do.  And affiliation fees are, like, on the order of 50 percent in these cases.  So there's a strong incentive for the people who want these affiliate fees to do whatever they can to generate the scareware warning because there's real money in it now.  So unfortunately we know that, where there's strong economic motivation, those things tend to happen more than when there isn't.  And now we have that for this kind of - sort of this new class of scareware.



LEO:  Yeah.



STEVE:  I also wanted just to comment, I was listening to you and Paul last week talking about, among other things, cellular connectivity.  And he was talking about the experience he was having with his EVDO card, which runs on Sprint or Verizon.  And I just wanted to chime in that, I mean, I've been an EVDO user, as you know, Leo, for years.  And, I mean, it really is a spectacularly functional system.  It is completely usable bandwidth, unlike, unfortunately, what you get with the iPhone in most locations, where if you don't have 3G it's just painful.  But this little EVDO card, and now it's not even a card, a PCMCIA card, as I have had, but of course they have a little USB dongle that you just plug in...



LEO:  Yeah, I use that just because it's easiest to move it from computer to computer, so, yeah, very convenient.



STEVE:  Yeah, it's just a spectacular solution.



LEO:  Oh, I love it.  I'm a huge fan.  We can actually stream video with it, it's that good.



STEVE:  No kidding.



LEO:  Yeah, when Dane was - when we were covering Roz's arrival in Hawaii, on her trip across the Pacific, I sent Dane with a laptop, an EVDO card, and a camera, and we got streaming video of her arrival via EVDO.  It was amazing.



STEVE:  It's great.



LEO:  Yeah, yeah.  And it's getting better.  They're really upgrading these services as we go.



STEVE:  Yeah.  Well, because it's popular, and it's profitable.  I mean, I did also hear you make a - I think it was Paul who mentioned the fact that there are total bandwidth caps on those.



LEO:  Yes.



STEVE:  They say unlimited Internet, but they also say in their terms of service that it's for web browsing and email, not downloading movies.



LEO:  Exactly.



STEVE:  And so they absolutely do, I mean, I've had this long enough, I've never run across any kind of a limitation because I just use it, and I don't have a need to download movies when I'm in laptop mode.  But...



LEO:  Oh, five gigs goes fast, believe me.



STEVE:  I know of many people who have run up against the cap and have had their provider say, look, sorry, we're cutting you off.  I mean, often the accounts are just canceled.  It's like, sorry, you violated our terms of service.  That's it.



LEO:  I really am - we're judicious.  We don't use it except when we need it.  Streaming video would use - and by the way, it's up and down, total of five gigs.  So streaming video would eat it up pretty quick.  So we have to be a little judicious in our use.  But it is convenient.  I carry it with my little Netbook so that I have always-on access wherever I go.  It's really great, yeah.



STEVE:  Right.  And I had a short little interesting SpinRite anecdote to share because it involves the Mac, and SpinRite not being the sole solution.  I discovered this when I was going through the Q&A postings for today's episode, from Rabbe Sandelin.  His subject was "Interesting Dual Rescue Operation."  He said, "I have twin nieces who one day called me.  Their old iBook had refused to boot.  They were devastated, as many important documents and pictures were on it.  I have one of the better Mac recovery tools, and it sort of saw that something was on the disk, but could not recover any of the files.



"So I bought SpinRite, removed the drive from the Mac, and popped it in a PC laptop.  SpinRite warned about a drive about to physically die at any minute.  Then it went to work and finished two days later with reporting some unrecoverable sectors and quite a few repaired ones.  I pulled out the drive and connected it via USB to my own Mac.  No luck.  It would still not mount.  I was getting desperate.  So as a last resort I once again fired up my Mac recovery tool."  Which he doesn't name.  I wish he had.



LEO:  Well, there's only a couple of choices.  It's either Alsoft's DiskWarrior, probably is that, or Micromat makes a program called TechTool.  There are really only the two.  We don't have a huge choice.



STEVE:  So he said, "Once again I fired up my Mac recovery tool, and now it could find all the files on the disk."



LEO:  Aha.



STEVE:  "SpinRite obviously had been able to repair it, although it still had some problems mounting on the Mac.  I'm now a very happy SpinRite owner, and I also have two very happy nieces, who also now are aware of the importance of making backups.  Thank you very, very much."



LEO:  So that's a case where you don't look at the file system.  SpinRite looks at the underlying guts of the hard drive...



STEVE:  Physical sector of the hard drive.



LEO:  ...fixed whatever was wrong there.  And then the Micromat or the DiskWarrior, whatever tool he was using, which doesn't operate, I mean, they say they do, nothing like...



STEVE:  Clearly they don't.



LEO:  Nothing like SpinRite.



STEVE:  They didn't do what SpinRite did.



LEO:  No.  But once SpinRite got those sectors readable, then they could recover the file system and get things back to normal.  Yeah, that's not uncommon.



STEVE:  Exactly.  So I thought that was, you know, good to share with our listeners, an interesting hybrid solution.



LEO:  A good one-two punch.  Same thing happens in Windows, though, where you have file system level tools.  You don't do file system.  You need a lower level tool to recover it.  The file system level tool can then take over.



STEVE:  Yeah, although with NTFS it seems to be a robust enough structure that we're seeing fewer problems for whatever reason.



LEO:  I'm with you.  You don't really need those tools.  Someday I'd love you to take a look at ZFS, which we've been all excited about here at the TWiT Cottage, and you know we did an interview with Sun about it.  It's the Solaris file system.  You will not believe this file system.  I don't know if you're into file systems at all.  But it's incredible.  I mean...



STEVE:  I'm into everything that's got to do with computers.



LEO:  I know you are.  It's next generation.  You'd be very interested.  Does things like it has built-in rollback, lot of redundancy.  I mean, it's a rock solid - it's basically like a RAID 5 in a file system.  It's amazing what you can do with this thing, lot of virtual hardware and so forth.



Hey, before we go to the questions - and we've got some great ones.  I see you've put together 12, including a...



STEVE:  We have our dozen interesting questions and topics and anecdotes and things, yes.



LEO:  All sorts of good stuff.  Steverino, you ready for your first question, my friend?



STEVE:  Ready.



LEO:  Ready.  From Phil in Montreal.  Phil in Montreal asks:  "Running Windows isn't professional?"  Last podcast, about GhostNet, you mentioned at the end of the podcast that running Windows is a bad idea.  In fact, you said that they should run other OS or embedded ones that have not been targeted with virus or attacks.  Doesn't this same argument go against what you preach?  Isn't this security by obscurity?  Why do you assume that other operating systems would be better?  Who's to say there aren't other security holes?  Seems rather bold of you to say that anything else is better than Windows.  If all the airport terminals switch from Windows to a embedded Airport OS 2000, who's to say that hackers who love to crash those terminals aren't going to continue?  By the way, I don't think it's hackers crashing those.



STEVE:  No.



LEO:  Windows does a perfectly good job all by itself.  That was me editorializing.  Plus, why do you assume that non-Windows programmers would be better than others?  Seems if the programmer creates buggy software on Windows, he or she will do the same on any operating system.  I'm not a Visual Basic programmer, and personally I call it Very Bad, not Visual Basic.  But your last remark about saying you get what you pay for, oh dear, oh dear, oh dear, Steve.   We can't all program in Assembly.  Software costs would be five or ten times more expensive and longer to program, compared to people working on Visual Basic or other Rapid Application Development (RAD) tools.  And just imagine how much more it would cost when you factor the cost of training on another OS and an API that is not common like Windows.



Windows does have its flaws.  But the assumption that anything else is better than Windows seems wrong to me.  I've used Linux, BeOS, Mac.  And coming from the VIC-20 and the Commodore 64, I can honestly say I've crashed them all.  Well, it's pretty hard to crash BeOS, but okay.  They are all flawed; and a bad programmer will always be a bad programmer, no matter what platform he is working on.  And many times it has nothing to do with the programmer, it has to do with time, pressure to do things faster than the competition, especially when the competition is international, hint hint.  Sorry if this comes out mean or insulting, but I really don't think those comments were correct.  Your opinion.



STEVE:  [Sighing] Well, you know, I'm normally - I normally work to be PC, as they say.



LEO:  Yeah.  You use a lot of Windows.



STEVE:  Politically correct.



LEO:  Oh, that kind.



STEVE:  Yes.  Windows is a steaming pile of crap.



LEO:  Okay.



STEVE:  It is.  Look what we put up with.



LEO:  Yeah.



STEVE:  I mean, it is just unbelievable what the Windows community puts up with.  Now, what this author of this post doesn't appreciate is that I wasn't talking about Linux or Be or Mac or any consumer operating system.  There's a whole 'nother class of operating systems, RTOSes, Real-Time Operating Systems, and for embedded applications, which are a whole 'nother class of bulletproof and solid.  So when I see a marquee system in Vegas with a Blue Screen of Death or a Windows dialogue, I mean, what's funny is there'll be, like, you have to click OK.  But there's no mouse.  There's no way, I mean, I guess you can climb up on a ladder.  No, I'm just kidding, of course, because it's not a touchscreen.



But, I mean, the idea that a kiosk in an airport or a big screen in Vegas has Windows underneath it is appalling to me because that says that these people who created this are so far away from the way that kind of a turnkey system could be  built with a low-volume embedded system with a real-time operating system which is fundamentally vastly more robust than this ridiculous second Tuesday of the month cycle that we're in now.  I mean, I hear you laughing in the background.  But, I mean...



LEO:  I'm with you.  I'm with you.  You sing it, sister.



STEVE:  We've been bent so far away from what is reasonable.  And we've gone kicking and screaming, one insult after another after another.  Old-school people, when this whole auto update started, said oh my goodness, no, I want control of this, I'm going to decide what goes in my computer or not.  And now, I mean, and IT got pissed off because they were sending updates all over the place, and they began lumping them up in groups.  And, I mean, where we are is ridiculous.



Now, I take my hat off to Microsoft.  I salute them for somehow managing to keep this massive Hindenburg called Windows aloft as long as they have.  I mean, it is becoming unbelievably cumbersome and burdensome, even for Microsoft to understand their own creation.  And it's a consequence of evolution.  Again, they're still running programs from the early '80s and carrying all of that technology forward, which is not an easy thing to do.  And they're only slowly removing those old features from their newer systems.  And we talked about, for example, the eventual loss of 16-bit Windows support.  So, I mean, I understand that this is not an easy thing for them to do.  But where we are today is just - it's an atrocity.  It's just - it's ridiculous.



And then, for example, you mentioned last week, Leo, that the electrical power grid of this country has been taken over, and essentially there's spyware that's been installed, apparently, the news reports say, by China and Russia.  I haven't reported much on that here because not much is known, I mean, not much is known publicly.  I'm sure that our intelligence community has much better information about that.  But again, what you find when you look is that these systems are running Windows.  Somebody built some nuclear reactor control system on top of Windows.  Which is just like, oh, my goodness.  It's inexcusable.



So when I read this posting I just thought, okay, wait, time out.  Let's have a little reality check about what it is that we're all dealing with and how ridiculous this is.  I mean, this is ridiculous.  But it's what we've got.  And so that's what we're using.



LEO:  Yeah.  Okay.  I'm trying to - I also want to be politically correct here.  So I want to defend Microsoft a little bit.  I'm kind of, you know, my visceral reaction is yes, I agree with you.  But the issue is that Microsoft needs to be in that position because they're a business operating system, so they have to support the legacy hardware and software that they've accreted over time.  I mean, in order to make it a better operating system they need to cut bait and start over, don't you think?



STEVE:  No, you're absolutely right.  For example...



LEO:  It's a business problem they have.



STEVE:  I've continued to study computer instruction set architectures for the last few months.  And actually I'm finding myself feeling really interested in the PowerPC, which I think was a really spectacular piece of work.  And it's sad that we've seen its arc sort of diminish, as it has over time.  But Intel is where they are today because they're still supporting an instruction set that basically still runs 8080 or 8008 instructions and have dragged it all forward.  If they were to start from scratch today, they could design a spectacular chip, because they know how, which would be far more powerful and require much less energy, much less heat, much less drive space.  It would be much less expensive.  They're paying an awful price for their backward compatibility several decades back.



But we use the Intel chip because of the compatibility.  I mean, that's the benefit for us.  And just as we do with Windows, for its compatibility, the fact that it runs - anything it ever ran, it still runs today, while Microsoft attempts to bring new technology into it.  I mean, we grumble about all this .NET stuff that's having to be loaded now.  Well, that's like the next, the next way of talking to Windows, the next API layer, while they're still supporting the old ones.  So, I mean, I really do see that, too, Leo.  But I just - this note sort of said, wait a minute, let's understand how bad the situation has become.  And some of the other notes that we're going to be talking about in our Q&A today highlight additional aspects of this.  It's just ridiculous.  But...



LEO:  So you're saying there's a reason why we're seeing all these security flaws in Windows.  It's, at this point, it's a can of spaghetti.  It's unfixable.



STEVE:  Well, you've heard me often defend the programmers, as one myself, recognizing how strangely difficult it is to write code which is absolutely bulletproof.  It's just - it's amazing how difficult it is.  But this is not an insolvable problem.  I mean, we've got such a ridiculous amount of power now in contemporary processors that it would be possible to essentially run a protected emulation layer around everything in order to prevent these kinds of problems.  There are things we could do.  So I'm just saying.



LEO:  I think that's where Microsoft is actually moving.  I think Hypervisor in the hardware and the virtualization that Microsoft is promoting, I sense, and I'm not an expert on this, but from talking to Paul Thurrott, is that the future, Microsoft feels that the future of Windows is totally virtualized.  And that does solve a lot of these problems, doesn't it, because it isolates stuff.  It puts it away out of the core.



STEVE:  Right.  I just, again, I never rant.  I don't think I've ever ranted before.  But I just - it was sort of a wakeup call for me.  It's like, wait a minute, let's just - yes, we're going to move forward.  We're going to keep patching on the second Tuesday of the month.  We're going to put up with this, I mean, with this huge, bloated OS.  And again, I accept what Microsoft has done.  But I just wanted to stand back for a minute and just say, hold on a second.  This is ridiculous.  This is horrific.  And what's happened with Conficker and with hospitals being brought down and with identity theft and, I mean, all the things.  And in the license agreement that you check it says we're not responsible for any of this.  You bear the full responsibility for your use of this.  No other industry ever has gotten away with that except the PC software industry.  That's just phenomenal.



LEO:  And yet, I mean, does NASA use it for launching rockets and things?  I mean, it's used in some really pretty mission-critical situations, I think.



STEVE:  You mean Windows?



LEO:  Yeah.



STEVE:  It's used foolishly because...



LEO:  [Laughing]



STEVE:  Oh, it is, because you've got tools like Visual Basic that allow monkeys to program.



LEO:  [Laughing] I love it.  Steve's in a fine fettle today.



STEVE:  Okay.



LEO:  Moving along.  Next question.



STEVE:  Okay, I'm going to calm down now.



LEO:  You know, right on.



STEVE:  It's how I really feel.  And I...



LEO:  It's important to say this.



STEVE:  I don't normally share it.  And I'm not going to make this the rant podcast.  But if this was, like, okay...



LEO:  Well, I do get a lot of heat from it.  I mean, there are people who, oddly enough, there are people who feel about computers and their operating systems the way they do about Mom, apple pie, you know, it's this kind of ownership of it, this very strong ownership of it.  And so I think that people who get het up about this and feel hurt about this are people who kind of, you're attacking my operating system.  It's just a piece of code, folks.



STEVE:  Yeah.  Well, and I think part of this is that I've been spending a lot of time looking at history and looking back at the fundamentals.  And I have remembered that there are alternatives, I mean, not for Mom and Pop, not for you and me.  I'm not complaining that I'm on Windows.  I mean, this is where everyone is.  It's where I need to be.  But there are really robust, small, fantastic operating systems that should be used for things like kiosks and shuttle systems.  I mean, that's what they use are these really good operating systems which are not anything that consumers touch.  But there is a whole different way for computers to work than this disaster of barely functioning and stumbling along and weird things happen and people don't know why they can't print anymore or their Windows Update doesn't update anymore, or one of their two screens just doesn't work anymore, I mean, things are just falling off because it's barely functioning.  And...



LEO:  We've kind of come to accept that, haven't we.  I mean, we kind of have come to assume that's just the way it is.



STEVE:  Yes, look, that's my point, look what we put up with.  We put up with something that is ridiculous.



LEO:  You're saying it doesn't have to be that way.



STEVE:  It's all our fault, Leo.  It's our fault for visiting that website.  It's our fault for clicking that link.



LEO:  Right, right.



STEVE:  It's our fault for not rebooting often enough.



LEO:  You know, I do say this on the radio show.  That's the tagline of Call For Help on the radio show.  It's not your fault.  And I think, you know, we put - there's a huge burden on users to be security experts, to protect themselves.  And it's only because the stuff that we're using is so poorly designed.



STEVE:  Yeah.



LEO:  Okay.  Question two.  Dan Rector in Rochester, Minnesota - no, is that, yeah, it is question two, page eight, but question two - wants a page of Steve's software picks:  Steve, first of all, thanks for the work and dedication you do in producing Security Now! each and every week.  I've been a listener since show one.  Could you create a page, if there isn't one already - if there is, I haven't found it - that has links to or at the very least lists the software you've found over time and have become things you use all the time or are your favorites, tools like Taskbar Shuffle, allSnap, Image for Windows - which we mentioned the other day.  I often hear you talk about these programs when listening to the podcast, and it plants a seed.  When I have a need for one of these programs or am installing on a new computer, it takes quite a while to search the transcripts to find the reference to the program.  I know what he means.  I mean, I'd love that, too.  I don't know if that's something we should do, or you could do, or...



STEVE:  Well, I've made - I stuck it on my to-do list.  I will get to it when I can.  I just wanted to post the question because so many people have asked for that.  And I don't want to get into this mode of, like, Steve's Pick of the Week sort of deal.



LEO:  Yeah, yeah, yeah.  We do that already on Windows Weekly.  We have quite a few of them, actually, yeah.



STEVE:  And my problem is, what you tend to do, then, is to feel like you have to come up with something.



LEO:  Right, you force it.



STEVE:  I want to be driven by the excellence of what I find, rather than the need to find something.  So but it absolutely makes sense for me to have a page where I can say, oh, and I've added that to my favorite software page on GRC.com.  I don't have that yet, but I'm going to put that together with the stuff that I've talked about so that there will be a place where everyone can go to go through that.  And, you know, I'll use it myself when I'm setting up a new system.  It'll just be easy to go click click click click click click click and suck all those things down.



LEO:  I mean, we have - that's kind of what the wiki is for, and it may be that somebody would like to volunteer and do that on the wiki, as well, wiki.twit.tv.  Anybody can edit, create pages, add content.  And if you've already been keeping such a list, it would be a simple thing to paste it in and then keep it up to date.  You get help from the community, as well.



J.T. Aaron in Houston wonders if Steve isn't way too trusting.  Steve, you're way too trusting.  He says:  You talked on a recent show about installing, trying, liking, and then recommending a brand new Firefox plug-in.  How do you know if a new plug-in just released is a security threat?  Especially when the new cool app is not from an established company?  Great shows, by the way.  Good question.



STEVE:  It is a good question.  And I think I agree that I'm probably too trusting.  It is certainly the case that I take a look at sort of the motivation, the site where the plug-in came from, try to get some feeling, as soft and fuzzy as that is, it's certainly not scientific.  But get some feeling for where this came from and for why, what the user designed it for.  Often their sites will say, yeah, I was struggling with this for some time, and I decided just to write my own sort of thing.  Now, it's absolutely the case that there could be a security problem with a plug-in.  That is, an inadvertent problem as opposed to something malicious.  On the other hand, established companies have those just as often as guys working from their bedroom and publishing these.  So I don't think there's any reason to believe an established company's plug-ins are going to be in any way more fundamentally secure than something that an individual writes.



And again, it is the case also that things that have very low yield tend not to be targets.  I mean, Windows is a much bigger target than the Mac because it's what 90-something percent of the world is using.  And as we'll find out later in this podcast, a big chunk of the world isn't using legitimate copies of Windows, and those are even a bigger problem.  So it's the case that it seems very unlikely that, were there to be a problem in my hierarchical tab tree organizer, that some malicious software is going to target that because the chance of someone using that is diminishingly small, even among Firefox users, who are still in the minority of all browser users.  So I agree with J.T.,  I think I tend to be too trusting.  I also think that the actual target surface is small for these, relative to the whole browser or the whole operating system that have much larger attack surfaces.



LEO:  If you were going to do it, how would you go about that?  Would you put a network analyzer on it and stuff like that?  I mean, how would you test it?



STEVE:  Well, yeah.  You can't.  I mean, the presumption is that it's non-malicious intent, that is, that there might be a mistake made.  In which case, I mean, who knows where the problem is, what particular set of coincidences of traffic could cause there to be a problem, and what the result would be.  I mean, probably what would happen is it would become unstable.  It would be crashing; and you'd go, oh, I think I want to remove that from Firefox.  So you'd take it out because there was a buffer overflow that was producing a denial of service attack, that is, denying you the service of your browser.  And certainly that happens.  We know that there are poorly written add-ons which crash your browser.  So what do you do?  You take them out.  So here's a poorly written add-on which works for some subset of people until it crashes them.  Well, during that little Window of opportunity, maybe that crash could be turned into an exploit.  But before that has a chance to happen you've removed it because you decided, well, this is buggy software.  So the bugs which created the opportunity for an exploit you've removed because you say, okay, this thing's not ready for primetime yet.



LEO:  All right.  Moving on.  Taylor Schreck - no relation -  in Rochester, Minnesota - I made a little joke, a little funny there - in Rochester, Minnesota shares some thoughts on Conficker:  Hi, Steve.  I'm a few episodes behind, so I 

apologize if you've already discovered this.  In the episodes I've listened to recently you've commented on how amazing it is that it's taking so long for computers to be updated with critical security patches.  I agree with your assessment that the corporate review of Microsoft patches may be partially responsible.  However, I read a blog post this morning that brought up another probable factor.  Many people cannot install updates.



Here's the relevant excerpt, quote, "Relatively few of the infected computers, about 4 percent, are in the U.S., according to a report issued by SRI International in March.   About half the Conficker infections were Chinese computers, at more than 10 times the rate of U.S. infections.  That makes sense, Wisniewski said, because there are now more web-connected computers in China than anywhere else.  There's also a high incidence of pirated copies of software in China, meaning users there cannot keep their machines up to date with security patches."  I just wanted to provide that as food for thought.  Thanks to you and Leo for the work you do on Security Now.  It's been a great way for me to learn and stay current.  That's a good point.  If you don't, well, is that true?  If you don't have a legitimate copy, you can't update?



STEVE:  Yes.  And I remember when that change was made.  And I thought, oh...



LEO:  That's a mistake.



STEVE:  ...goodness.  You are forced now to install the Genuine Update or Windows Genuine Verifier or whatever they call it.  And it's like - or Genuine Advantage, that's it.  And I love it, too, because when you agree to this, it brings up a dialogue, and it says, when you're done, we'd like to show you some of the many benefits of Genuine Advantage.  And it's like, uh, no, thank you.



LEO:  Many benefits to us.



STEVE:  Exactly.



LEO:  To Microsoft.  Yeah.



STEVE:  So I remember thinking, oh, goodness, now we're not going to get the updates on all versions of Windows.  You've got to pass the Genuine Advantage, which I've heard derisively referred to as Genuine Disadvantage.



LEO:  Right.



STEVE:  But it is the case that those machines which are running Windows but not able to be updated for this reason, they didn't get the fix in October.  They didn't get fixed until Conficker infected them and then closed the backdoor behind it.



LEO:  Yeah, yeah.  And there's also a lot of - I'm surprised, 4 percent seems like such a low number.  I am actually shocked that it's so low in the U.S.  I guess we're doing our job, we're getting the word out.  But I think there's also a lot of people in the U.S. who choose not to update.  And there are a lot of people in the U.S. who can't update because their updates are blocked.  I get this call a lot.  People had a bad update, and they haven't been able to update ever since.  A failed update will block future updates; right?



STEVE:  We've got that in a coming question.



LEO:  Oh, you're way ahead of me.  Well, then, let's move along.  Nick Antonizick in Las Vegas, Nevada wonders about "Mitigating the Buffer Overflow Threat."  Dear Steve and Leo:  First, thank you both to the tenth power for the Security Now podcast.  It has become my favorite source of information and entertainment.  Because of you both, I am always looking forward to Thursday nights every week.  That's when the show comes out.  I have a question regarding buffer overflows:  I operate my computers from limited user accounts.  I also force high-risk applications to operate under Sandboxie.  And he includes Firefox, Foxit - the PDF viewer we talked about - image viewers, and office applications in that list.  So if an application is victim to a successful buffer overflow attack, and the application is contained inside a sandbox in a limited account, is the injected hostile code constrained or confined in any way?



As I examine the process stack, even from a limited account, over half of the processes running the system are system processes.  I'm guessing, if the hostile code is injected into a system-owned portion of the stack, that any precautions I take will not provide any protection or containment at all.  Likewise, if the hostile code lands in a limited portion of the stack, it will not have much authority to modify the system.  Am I correct?  And when faced with the practicalities of implementing or suffering a buffer overflow attack, is hostile code more likely or less likely to be injected into a system-owned area of the process stack?  Thanks again for a great show.  As always, I'm looking forward to hearing Thursday's episode.



So what he's saying is, I take the precautions that you guys have recommended, particularly the limited user and running Sandboxie.  But there are still escalated code running on my machine.  What happens if that's where the malware strikes?



STEVE:  Right.  I think what Nick doesn't understand, and I just sort of wanted to make sure that our listeners understand, is that even though a sandboxed program can see both system processes and its own limited account processes - and he's certainly right about that.  If you use a process viewer from within the sandbox you can see those.  What the sandbox is doing is preventing modification to the system.  So what the sandbox can't tell, can't see, is that when a process in the sandbox makes a modification to a file, it's actually sort of it's caching the modification so that the actual file is not modified, but what happens is a copy of the file is brought into sort of a holding area, and that copy is modified.  Then if this application checks to see if its modification was successful, it's actually checking - it's sort of redirected, and it's checking that modified version, not the real one.  So something malicious can think, ha ha ha, you know, I've got the guy now, and be making changes to the registry, to files on the hard drive, I mean, to in-RAM processes, to anything, and it thinks it's succeeding.



Well, this is actually all a charade that the sandbox creates that prevents things in the sandbox from making permanent changes.  They make them only locally to their own copies.  And so when that thing terminates, when you reboot your system, when you shut down the sandbox, those changes are flushed, and no permanent changes have been made.  So it really doesn't matter whether something thinks it's trying to modify system processes or perform process injections or do anything it's doing.  It's all been carefully orchestrated so that those changes are simulated for the sandboxed environment, and nothing actually has changed.  There's no rights of any kind that escape that out into the system externally.



LEO:  Good.  So you are safe.  What about if you do a process viewer, you'll see there are system processes running, if you're not running Sandboxie, there are system processes running.  Is it the same for them?  Are they not accessible by malware?  Can malware not leak into them?



STEVE:  Correct.  I mean, and that's exactly the question he was asking was...



LEO:  Even without Sandboxie.



STEVE:  Yes, does it really - oh.  Without Sandboxie, no.  I mean, the problem is there are all kinds of ways, for example, of performing a privilege elevation attack where, even though you're in a limited account, you jump to some piece of code in the kernel that has the side effect of elevating your permission.  Then you come back.  Now you have full admin permissions.  And then the changes you make that would normally not be permitted by that account are permitted.



LEO:  Right, right.  So that's why these exploits are an issue, because even if you're running as a limited user you can get in trouble.



STEVE:  Yes.  I mean, you're not supposed to be.  But there are privilege escalation exploits which get around the whole limited user...



LEO:  To make it clear, those require that there be a hole in the operating system.



STEVE:  Yes.



LEO:  There is malware that doesn't require that, that you run an application that does stuff.



STEVE:  Correct.



LEO:  If you run that as a limited user, generally it won't be able to elevate its privileges, and you're safer.  But if there's a hole in the operating system, all bets are off.  Doesn't matter what you're running as.



STEVE:  Well, yes.  Or if you're a victim of a social engineering attack, where something says, "Hi.  We're Happy AV.  We need you to authenticate your admin account so that we can install our system drivers."  Well, you've just given some bad thing complete access to your system.



LEO:  Right.  And we should also mention, we've said this several times, but just so people know, in Vista and OS X nowadays you don't have to run as a limited user because even when you're an admin you're really not an admin.  You're always a limited user, and you have to escalate using User Account Control or OS X's equivalent before you're able to do anything anyway as an administrator.



STEVE:  Right.



LEO:  You have to give it an administrator password.  Moving along to the next question.  This comes from Robert Harder in Monterey, California.  Robert asks:  Why do all CDs, or why do some CDs stall the whole system?  Thanks for the great tidbits we learn about the down-and-dirty on hard drives when we listen to Security Now!.  I have all the episodes way back to #1 in iTunes.  But what I really want to know is why optical drives have the power to bring a computer to its knees?  On both Macs and Windows, and for many years, computers seem to really choke and stall when CDs or DVDs are inserted or have bad parts or whatever.  What's wrong?  How come something like a bad disk can bring the whole machine to a crashing halt?



STEVE:  I saw this, and I just chuckled to myself because this is one of the continuing annoyances I have with Windows.  I hadn't experienced it as much with the Mac.  And I was going to ask you, Leo.  Is it the case with the Mac as much as it is with Windows?



LEO:  I'm trying to remember.



STEVE:  Because with Windows, I mean, if you do anything involving a CD drive, it literally - your UI locks up.  It's just everything waits.



LEO:  And that's because these are not asynchronous, I mean, synchronous reads; right?  They're asynchronous in the operating system or...



STEVE:  It's because the system is as I described it in question number one.  It is ridiculous.



LEO:  Well, remember Windows did not have CD-ROM support.  It was added after the fact.



STEVE:  And that's the reason.  It's the heritage.  It's the fact that we - okay.  We know Windows has never been comfortable with the idea of removable file systems.



LEO:  Right.



STEVE:  It didn't have them in the beginning, and it has never really had them done right.  It's ridiculous that having the CD in sort of an unknown state - and CDs take a long time, and an increasingly long time also in the case of DVDs - to sort of get themselves up to speed and "seeked" and logged in and all happy.  Meanwhile, nothing else, I mean, literally the whole system comes to a halt while you wait for the CD to decide if it's good or bad or what condition it's in.  And it's purely a function, there's nothing, nothing from a technology standpoint that enforces this, except just the legacy of design which has been dragged kicking and screaming forward to where we are today, and this annoyance, which just, who knows if it's ever going to go away.



LEO:  These are called blocking applications.  It is possible on the Mac to have that happen.  I mean, the beach ball - they call it the Beach Ball of Death sometimes, where the little waiting, lurking, spinning thing...



STEVE:  The little spinning color wheel...



LEO:  ...just starts and will not stop.  So I don't think OS X is immune to this, either.  But a good operating system should handle this kind of stuff.  What, do they get in endless loops or something, or they're waiting for a read, or they're just hung up until the read completes, or...



STEVE:  I mean, it's definitely the case that it's easy to take proper operation for granted.  Operating systems are super complex.  There's a phenomenal amount of synchronization and interlock going on.  And the problem is that the designers from a decade ago didn't anticipate some things that we have today.  And so the result is a kludge.  It's no one's fault except the fault of evolution.  I mean, that's - our own DNA has all kinds of gunk in it that we no longer need.  And that's just a function of history.  So Windows is the same way.  It's evolved over time.  And there are things that just - that were not a big problem, that have become a larger problem as we move forward, that sort of never get fixed.  And this is one of those.  Just sort of it's something that annoys me all the time about Windows.  So when I saw this, I said, yes, Robert.  Boy, do I agree with you.  This is just ridiculous.  And there's no good reason for it except heritage, except legacy.



LEO:  I'm going to jump back a little bit just because, I don't know if you noticed, I missed question five, Casey Clingan.



STEVE:  Yes, I noticed.



LEO:  In Hattiesburg, Mississippi.  He says that people never cease to amuse:  Hey, Mr. Gibson, let me start by saying that I really enjoy your weekly podcast, Security Now!, with Leo Laporte.  It's always very informative.  Lately you've been discussing the newest version of the worm known as Conficker and the importance of always staying up to date with the latest Windows updates in order to make your PC as secure as possible, though we all know that Windows PCs are never really totally secure.



Well, as I've been listening I've noticed that a great deal of the time those who get infected or hacked by worms and viruses like Conficker are those who do just the opposite of what I just said.  Now, to be honest, in the back of my mind I have been saying to myself, come on, who is really dumb enough to deny Windows Updates?  I mean, for me, every time that little balloon in the task bar appears I get excited, like I've got a gift.  All right, so I'm easily amused.



Well, as the title of this post says, people never cease to amaze me.  I noticed the other day as I was using one of the computer labs on my college campus that auto updates were turned off.  Needless to say, the first thing that came through my little mind was, what idiots.  So as any responsible geek would do, I proceeded to correct the issue.  I came to find out that the machine I was using hadn't even updated to Service Pack 3.  Yes.  It didn't even have Service Pack 3.  I was totally at a loss for words.  Needless to say, I then immediately proceeded to Microsoft's website, downloaded and installed all available updates.  This leads me to wonder how many other computers on this campus are in the same predicament?  Anyways, all this to say you were indeed correct about the fact that many Windows machines are running unsecure and on outdated software.  Thanks again for your helpful info, and please continue to keep us updated on everything security.



That's a case, I think a common case, of neglect.  Machines that are on big networks that nobody's responsible for just get neglected.



STEVE:  Yeah, and computers in a lab would be a good case.  You can imagine, I mean, we don't know specifically and when auto updates were turned off and why.  We know that Microsoft has them on by default, prompts you, bugs you until you turn them off.  And it's difficult to have them off.  But something somewhere deliberately said I want auto updates off on this machine.  Maybe they were in the middle of something, they didn't want to be forced to reboot.  I mean, we just don't know.  But it certainly is the case that in this instance there was this important system, which is arguably very important, was disabled.



Now, you might say, oh, well, certainly they're on a big private network behind a big university routing system.  They probably don't have public IPs.  Incoming traffic is probably heavily filtered and blocked.  That may be so.  But one of the things that Conficker is now doing is sending out ARP probes across the entire subnet where it's located.  So even if that machine was protected, if there was any other instance, for example, of a machine being outside the network, getting infected, which is then brought into campus, that machine can infect across the entire sub-network through this next-generation LAN technology that Conficker has that we'll be talking about in detail next week.  So it really is the case with state-of-the-art malware that things can get you even when you believe it's safe to depend upon further exterior resources, like the fact that you're behind a router, and all the machines in your own network can be trusted.  If one stops being trustworthy, then the rest of your network can go down.



LEO:  Moving to Jesse in Madison, Wisconsin, who says, "I know why Windows machines don't get patched":  Steve, I'm sure that you have been reading the stories about how many Windows computers aren't yet patched for Conficker.  I think you know why computers aren't patched, even though the default Windows settings might even be set to automatically install.  I think "I" know why, he says.  I was helping my mom with her laptop, which is running Windows Vista Home Edition.  I noticed that Windows Update hadn't installed any patches since [fanfare] November.  I confirmed her settings.  It was indeed set to automatically download and install updates.  So I ran Windows Update manually.  It failed.  I didn't write down any error messages, but the gist of it was it couldn't find or download any updates.  This is bad.  I Googled for hours to see if anyone had seen this problem and if there were any solutions that worked.  I found hundreds of forum postings with people having this problem.  No one had a surefire solution that worked for me or other commenters on the forums.



I tried many things to fix the problem.  I won't bore you with the details.  But be assured, as a Linux user I am not afraid to get into the guts of the system.  I even ran SpinRite.  There's a little happy face there.  In the end, the only solution, reinstall Windows.  Luckily, my mom only used the computer for browsing the Internet and checking her email, so the reinstallation was relatively painless.  However, if I hadn't been around to help her, I'm sure she would have never even, not only not fixed the problem, she may have not known.  Her computer would have just been another drone in a botnet army.  Or worse, her identity might have been stolen.  Most people are no more computer literate than my mom.  So if Windows is failing to update itself for a significant portion of the population, this could explain why so many Windows computers are not being patched properly.  Thanks for the show.  Wow.



STEVE:  And that's similar to what you said you deal with on the radio show all the time, Leo.



LEO:  Yup.  Yup.



STEVE:  I've seen, I've had it happen to me.  I've had systems where one particular security patch won't take.  I'll try it over and over and over.  It just says no, sorry, can't install that.  And here again I salute Microsoft for doing something as difficult as this is.  I mean, this is not an easy thing to do when you think about how complex Windows has become, how many individual components it has, how they're all interlocked and interlocking, I mean, dealing with managing the problem of keeping it up to date, it's just a phenomenal job.  And the whole sort of almost-on-the-fly updating where you're bringing in new code, you're somehow arranging that next time you boot the new code will be running, and it will replace the old code.  You also need to guarantee that you can roll back these changes if they hurt you so that there's undoes on all of this.  I mean, this is a huge problem.  But it's also a problem of their creation.



So it's the case that Windows Update is complex and delicate and fragile.  And unfortunately it breaks.  At the same time, we now depend upon it more every day because of these evolving threats from malware and worms like Conficker.  We have to have it working.  So when it breaks it's not optional to have it working or not.  It's like, oh my god, this guy reinstalled Windows is the only thing he could do after spending a great deal of time struggling to keep the current installation.  He had no choice.



LEO:  Yeah, I'm going to have to start telling my listeners on the radio show, check to see if you're getting updates.  Because the class of calls I get is I have an update that won't finish.  So every time I reboot, I start my machine up, it says, okay, we've got to do this update, and it never does finish.  It happens all the time, you get an update that is incomplete.  Something went wrong.  And Microsoft has a fairly lengthy page in its knowledge base on what to do if Windows Updates breaks.  And there is no one fix.  There are a lot of different things to try.  You clean out - there's a folder, temporary folder where updates are stored.  You clean that out.  You might have to clean the registry by hand.  It's a mess.  Who would have ever thought that we would be in a position where we would need to update this operating system, or any operating system, so often?



STEVE:  Yes.  Yes.  That's exactly the problem.  It's like, okay, throw some cold water on us and wake us up.  It's like, wait a minute, look at the degree to which we're just putting up with nonsense.



LEO:  I can imagine that this is costing Microsoft a huge amount of resources to keep up with that they never anticipated.



STEVE:  Well, and any surprise that they were so reluctant to get themselves involved in security?  It's expensive.  It's difficult.  I mean, it is a whole 'nother class of hard.



LEO:  Jonathan Issler, Mount Airy, Maryland.  Is that the same Mount Airy?  No, I don't think it is, that Andy  Griffith was from Mount Airy?  It was in - wasn't in Maryland.  I have a mug from there.  Anyway, he wonders about the blocking of HTTPS traffic, secure HTTP:  Steve, I recently had an issue providing support for a school because their IT director had blocked all HTTPS traffic on their network.  Okay.  I'd like to hear the rationale for that.  In particular, this user was unable to go to GoToMeeting because the site automatically redirects users to HTTPS, as many security-conscious sites do.  The IT director said allowing HTTPS access for certain sites is difficult, and asked us to find a different way to provide the support.  I cannot possibly understand why an IT director would be blocking all HTTPS traffic on a network that people need to do work on.  What are your thoughts?  I love Security Now! most of all of the TWiT podcasts.  They definitely keep me sane during a three-hour daily commute.  Wow.  Thanks, Leo and Steve.  Wow.



STEVE:  Well, he said this was a school.  And the short answer is the IT director can't easily monitor and filter HTTPS because it's encrypted and secure.



LEO:  Right.



STEVE:  So his answer is disallow it.  Force all connections to be standard HTTP, which much less technology can be brought to bear on for filtering and monitoring actions of users within the school.  So we know that it's absolutely possible to filter HTTPS, but it requires much more expensive systems, and it requires proxying connections and putting custom root certificates on all the web browsers that are going to do it.  We've talked about how this is done in enterprises often.  In this case the school IT just said, well, we're not going to go through all that.  We're just simply going to deny HTTPS because we can't see what's inside, and our policy apparently is we want to be able to see everything that's crossing our network.  I'd be surprised if it weren't just that simple.



LEO:  Wow.  Yeah, I think you're exactly - that's probably exactly right.  But you can't use Gmail, I mean, there's a lot of legitimate stuff you'd want to use.  Is there a...



STEVE:  You can't even log in to Gmail because it forces you to do a secure, if only briefly, to do a secure connection to log in.  So you're right, I mean, it really does limit you.  On the other hand, the school policy might be, sorry, you can't do anything that requires that kind of security.



LEO:  Right.  We don't want you doing that anyway.



STEVE:  Right.



LEO:  Would there be a way that they could allow GoToMeeting only to have HTTPS?  Is there some...



STEVE:  Yeah, certainly.  Given that GoToMeeting servers are on relatively fixed IPs, they could certainly make an exception...



LEO:  Just allow that IP, okay.



STEVE:  ...in their blanket block, in their blanket traffic filter for that range of IPs, yes.



LEO:  Number ten, Zurahn in Ontario, Canada wonders about Conficker.  Who isn't?  We're all wondering about Conficker.  This is going to be a good episode next week when you cover this in great detail.



STEVE:  Yeah.



LEO:  He says:  Recently, considering the fervor surrounding Conficker, I thought of something that seems too obvious to work, but I'm not sure where the issue is.  If I understand correctly - this is a whole category of questions we get.  "What did I miss?" we call this.  If I understand correctly, the Conficker worm generates a list of domain names which it checks for updates, the most recent one the April Fools update, 50,000 domains a day, and some Internet service providers have been pre-registering domains to prevent the updates.  Legality and ethics aside, would it be possible to go a step further and not only register the domain, but use it to create a rogue update for Conficker that tells it to destroy itself?  Whether or not this is possible, I'd really like to hear why.  Could you do that?  I mean, it is illegal.



STEVE:  Legality and ethics aside, yes.  The first, I mean, I'm glad he said that because you're right, we've discussed many times the idea of white hats going in and leveraging the worm against - or the virus or the trojan or whatever against itself and using it for "good," unquote, as opposed to evil.  And remember we had the one story about the BBC who - I think it was the BBC that used a botnet and demonstrated that it worked, sent spam, did a denial of service attack against a willing ISP, and then modified all of the bots' screensaver to inform their owners that their system was infected and please go here to find a cure.  I mean, that was a controversial thing to do, and arguably everything that the BBC did was against the law.



Was it unethical?  I don't think probably.  And probably maybe not even illegal, depending upon what country you're in and who wants to form a complaint.  But, and I referred to this earlier in the show, one of the things that Conficker does is very clever.  And that is, it specifically blocks this kind of effort, not only being taken over by good guys, but by other bad guys who would like to commandeer the Conficker worm army that's been built.  And that is, I mean, exactly as Zurahn says, you've got 50,000 domains.  The worm's going to check every day for a small subset of those.  So you could potentially set up your own server at some of those domains, and Conficker would, statistically, some Confickers would contact that domain.  In which case you've got a connection to it.  Why not do something?



Well, the reason is that the authors are on the top of their game.  They have a requirement that any packages coming into Conficker contain a valid digital signature, signed by them.  And because this is public key technology in a digital signature, even reverse-engineering Conficker, all we could get - and we have determined all we can get, we'll be talking about this next week - is the public key.  There's no way, and this is how public key technology works, asymmetric cryptography, there's no way even from having the public key for us to know what the private key is.  The author of Conficker, or authors, have the private key.  So anything that they want their worm to update, they package up, and they sign with their private key, and they stick it out on the Internet on these prearranged servers for it to be discovered by the worm.  The worm discovers it, downloads it, and then uses its public key contained in its own code to verify the signature before it allows it into the system.



So, I mean, it's the same way, frankly, Windows Updates work.  Windows Updates are signed by Microsoft's private Windows Update key.  That prevents Windows from being spoofed and us accepting any malicious Windows Update packages.  Conficker does exactly the same thing.  So, I mean, it's using state-of-the-art cryptography to protect itself.



LEO:  Wow, that's kind of amazing, yeah.



STEVE:  Yeah.



LEO:  So you couldn't do this.  Conficker would say no,  you're not allowed, sorry.



STEVE:  It'll say sorry, that doesn't look like it came from us.



LEO:  Wow.  We're going to take a break and come back with Gerco Dries in The Netherlands.  He's worried about information leakage using VPNs.



STEVE:  Great question.



LEO:  And Brad has a cookie management scheme he'd like to - another one of those questions, you know, what am I missing?  Gerco Dries in The Netherlands is being bothered by information leakage when using VPN software.  He says:  Hi, Steve and Leo.  I first wrote to you about this a month ago or two, but you either decided not to discuss it on the show, or you might have missed it in the daily torrent of feedback.  I decided to mention it again just in case you missed it.  I think it's an important question.  When using any kind of VPN - Virtual Private Network - software, any kind known to me, anyway, on a laptop, I find that some information always leaks to the network you're connected to.  When waking up or booting a computer running any operating system out there, usually programs like an email client or Skype or Gmail notifier or whatever start up and immediately try to connect to their respective services.  This is before the VPN has been established.  And at that point you're leaking information about who I am, my email provider, for instance, what programs I use.  This could enable an attacker on the network to figure out what attacks to use against my machine.  Do you have any ideas on how to counter this type of information leakage?  Isn't it just a problem of what starts when?



STEVE:  Well, it's such a great question.  And I immediately put it into the feature list for CryptoLink.



LEO:  Oh, good.



STEVE:  CryptoLink will have essentially a hooking intercepting driver which installs at boot time.  And so, I mean, this is just a perfect example of why I'm excited about doing my own and why I'll be enjoying having a protracted development period which is interactive like this, so that people who say, hey, here's what I need, hey, what about this, and what about that, I will be able to incorporate that wish list into the product.  And so, I mean, it's there now.  It's going to have it, this notion of - and you'll be able to configure it so that, until you establish the link, no traffic flows out of the interface other than what's minimally necessary, which is basically just establishing the interface's IP address.  But no protocol traffic.  So that's a great question.  I don't know of any other VPN that addresses it.  But it's one more reason why I've decided I'm going to write my own for everybody.



LEO:  So it is really an issue of kind of saying don't start until I'm started.



STEVE:  Well, yeah.  The idea is that, if you installed a shim down in the network layers, down in the so-called NDIS layer, CryptoLink's driver will install itself between the NIC and the rest of Windows, the whole driver stack.  And it's easy enough for it to simply block, just like a personal firewall would, to block any and all traffic that is not running through the VPN.  So you'd be able to go somewhere, boot the machine, confident in knowing that none of the other junk like Windows Update, for example, that wants to get on the network and see what's going on, can establish, can leak any traffic at all, if that's the way you've configured CryptoLink.  It'll only be running through - traffic is only allowed running through the VPN, even before CryptoLink starts, since that driver will be down there preemptively blocking any traffic.



LEO:  Perry's saying in our IRC chatroom that Windows does allow you to start a VPN before you log in, which would presumably be soon enough to prevent that kind of thing.



STEVE:  I wouldn't know without, well, before you log in...



LEO:  Like on boot-up?



STEVE:  I don't know what services would be running.  Certainly Windows Update does not require you to log in.  So system-level services that aren't log-in required would still be, could still be a problem.



LEO:  Interesting.  Well, I'm glad you're addressing that.  That's great.



STEVE:  I'm going to.  It was a great question.  It's like, oh, yeah, there's a great additional feature, yes.



LEO:  Well, the best software is really developed in that kind of collaborational environment.  I mean, that's one of the things that's really changed nowadays because of the Internet, because of Web 2.0, is you can have this iterative software design situation where people are giving you feedback as you work, and it's great.



STEVE:  Well, I've been doing a lot of that, thanks to the newsgroups that I run at GRC.com.  This DNS benchmark owes many of its features to ideas that people have had.  I mean, there is a tradeoff because it tends to be - I have to guard against people saying, oh, but what about this; and what about that; and, hey, I'd like to have this and so forth.  I mean, you can end up running around in circles.  And so I have to control myself not to endlessly be adding features.



One of the things that I'm going to do with CryptoLink is do the UI last, that is, deliberately have a temporary interim user interface so that I don't invest in UI design until all the features are there that I want to have there.  Because what I've noticed over time is one of the most expensive things to do is for someone to say, oh, here's a great - how about this idea?  And I'm thinking, oh, that's fantastic, but I don't have anywhere to put the button.  So, I mean, an amazing amount of time gets spent in, like, reengineering, rejiggering the UI in order to accommodate great ideas.  So I've decided I'm going to deliberately forestall the UI side.  There will be a UI, but it'll just be just enough to exercise the product and have it all working.  And my intention is to have, to very quickly get something going, and then have a timeline of other features, and just add feature after feature after feature until it's feature complete.  At that point we'll let everyone play with it, see if there's anything I've forgotten.  And when it looks like it's stable, I'll put the UI on it, and we're done.



LEO:  Cool.  Very cool.  Last question.  This comes to us from Brad Beyenhof, San Diego, California.  He's got a cookie management scheme he'd like to run by you:  Steve, you mentioned in Episode 190 about the two extremes of cookie management - the one, "let every cookie in" crowd; versus the two, "scrupulously inspect everything" crowd.  I used to be in that second group, but I think my current system nicely fits between the two.  It's very no-fuss but still very restrictive.



In Firefox, I have the browser set to accept all cookies, even third-party cookies [gasp].  However, it is also set up to remove cookies every time the browser is closed.  To allow for persistent logins on the sites I use most, I have added my most-used domains to an "Allow" whitelist in the Cookie Exceptions dialog.  So what this means is all cookies are accepted during a session.  No sites get broken for a refusal to accept cookies.  But all cookies from domains I haven't specifically whitelisted get thrown out when Firefox closes, so there's no persistent tracking by unknown sites.  I think this sounds like a good system.



STEVE:  It does.



LEO:  What makes this whitelist so easy to administer is an extension called Permit Cookies.  It puts an icon in the status bar.  You just click the icon to change the default cookie exception rule for the site you're currently visiting.  Oddly, the copy on the Mozilla add-ons site won't install because its maxVersion doesn't extend to the current Firefox, but you can get it from the author's website with no problems.  Apparently it works.  What do you think?  That seems like a good idea.



STEVE:  It's a really nice idea.  I'm aware of people who use the "keep cookies until I terminate my browser" option.  It is right there in the user interface.  There's Allow First-Party Cookies, Allow Third-Party Cookies, and then underneath that is a dropdown box where you're able to choose the option Allow Until the Browser Is Terminated, some logic or some statement to that effect.  And so what it does is it allows, it holds the cookies in memory, never writes them to disk, so your system is fully functional until you terminate.  In which case it flushes all of those cookies out.



I did pursue the Permit Cookies add-on because I've become [clearing throat] admittedly something of a Firefox add-on junkie.  And it's exactly as Brad said.  If you put "permit cookies" into the Find Add-ons dialogue built into Firefox, it'll say that nothing is there.  But there's a link that says, like, find all versions or something to that effect.  If you click that, it will take you to the page.  And if you click the author's name, it takes you to the author's page, which is sort of a different name, it's like Gloria's something or other [Gorgias' Firefox Extensions].  And he's done a bunch of different kind of add-ons.  Down toward the bottom is Permit Cookies.



That one - and he acknowledges the fact that there's a version problem, that his latest one on his site installs.   Permit Cookies is a very small add-on.  It puts a little "C" down in your toolbar.  And what I like about it is, if you visit a site which you have whitelisted, or in this case greenlisted, the little "C" turns green.  So if I go to Amazon.com, it's green.  It knows that I have got Amazon.com in my whitelist saying I'm going to allow persistent cookies of whatever kind.  And the same thing for eBay or for other sites you visit.  When you go to a non-allowed site, the little "C" is just gray or white, not green.  And then you're able to click on it, and it pops up a dialogue if you want to change that site's permission to allow persistent cookies.



So it's another - I would recommend this for people who like the idea of having that kind of control.  Allow all cookies, first- and third-party cookies.  Flush them when you leave Firefox so they don't persist across startup sessions of Firefox, which means you're not going to be tracked more than across your current session, and then whitelist the sites where you want to keep cookies permanently.  That's another nice solution.



LEO:  And of course somebody is pointing out in our chatroom Flash cookies, but that's another topic for another day.



STEVE:  Ah, yes.  Yup.



LEO:  Because we are out of questions and out of time, Mr. Gibson.  Always a great pleasure.  Next week, Conficker, the ins and outs of the most famous worm of our time.



STEVE:  I think it probably is.  I mean, we had Code Red, and we had Blaster back in those days.  This one has really had the industry chasing its tail.  And it's becoming, it has turned out to be extremely difficult to deal with.  And one of the interesting things is that the authors are tracking the anti-Conficker work closely.



LEO:  Wow.



STEVE:  That is, everything that is done to try to thwart it, they respond - he or they; he, she, or they, the authors - respond to directly.  So they are - it's not something that they just sort of put out into the world and forgot about.  This is a project that they have been pursuing for six or seven months, and all leveraged from one particular Windows exploit.  The problem is, this is not the last exploit we've seen.  We're seeing them all the time.  This is a worm because it allows, if a Windows machine is not behind a NAT router so that its ports are directly exposed to the Internet, it allows other instances of the worm to infect unpatched machines.  And that's how these machines have become infected.  That's what I'm going to do next, by the way.  I deliberately manually infected my test machine that I've been watching it on for a while because it is behind a NAT router.  The next thing that I'm going to do is to set up a clean, virgin build of XP and put it out on the 'Net and see how long it takes for it to get taken over automatically.



LEO:  Minus the patch that Microsoft put out in November or October, whatever it was.



STEVE:  Precisely.



LEO:  Yeah.  That'll be - I can't wait to hear more about this.



STEVE:  Next week.



LEO:  We will dissect it all.  Now, if you want to know more about what we just talked about, you can find a transcript, 16KB versions of all the shows, show notes, and more at Steve's site, GRC.com.  That stands for Gibson Research Corporation.  That's where you'll also find SpinRite, that great program we always talk about, the hard drive maintenance utility that is just - there's nothing better.  Just the king of the hill, has been for years.  And of course a lot of free stuff that Steve gives away, useful tools like Shoot The Messenger, ShieldsUP!, DCOMbobulator, Unplug n' Pray, Wizmo.  It's all at GRC.com.



We also have show notes at wiki.twit.tv.  They're created by the listeners, which is always handy, usually with lots of links in there.  We have a FriendFeed room now called TWiT Conversations, if you're on FriendFeed it's TWiT-conversations, that people partake in during the live taping, and you can comment after the fact, as well.  And of course the live show is every Wednesday afternoon at 2:00 p.m. Eastern, that's 11:00 a.m. Pacific or 18:00 UTC at live.twit.tv or twit.am, if you just want to listen to the audio.  And that way you can listen, comment in our chatrooms.  We have many of them on Stickam, on Ustream, on IRC, and on FriendFeed now so that you can comment.  And we monitor them all and try to feed the comments back into the show.  So we always appreciate it when you do that.  If you aren't listening to the show every week, you might want to subscribe.  In iTunes you can get it automatically by going to the iTunes store and searching for TWiT.  You'll find all the TWiT shows there, including this one, Security Now!.  They're free.  You get them automatically the minute they ship.  Security Now! comes out next.  Thank you, Steve.



STEVE:  Thanks, Leo.  Always a pleasure.  Talk to you next week.



LEO:  Next week we Confick together on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




